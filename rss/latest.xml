<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Jun 2022 11:00:02 +0000</lastBuildDate>
    <item>
      <title>Unsupervised Deformable Image Registration with Absent Correspondences in Pre-operative and Post-Recurrence Brain Tumor MRI Scans</title>
      <link>https://paperswithcode.com/paper/unsupervised-deformable-image-registration-1</link>
      <description><![CDATA[Registration of pre-operative and post-recurrence brain images is often needed to evaluate the effectiveness of brain gliomas treatment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-deformable-image-registration-1</guid>
    </item>
    <item>
      <title>Disentangled Ontology Embedding for Zero-shot Learning</title>
      <link>https://paperswithcode.com/paper/disentangled-ontology-embedding-for-zero-shot</link>
      <description><![CDATA[In this paper, we focus on ontologies for augmenting ZSL, and propose to learn disentangled ontology embeddings guided by ontology properties to capture and utilize more fine-grained class relationships in different aspects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disentangled-ontology-embedding-for-zero-shot</guid>
    </item>
    <item>
      <title>Autoregressive Perturbations for Data Poisoning</title>
      <link>https://paperswithcode.com/paper/autoregressive-perturbations-for-data</link>
      <description><![CDATA[Unfortunately, existing methods require knowledge of both the target architecture and the complete dataset so that a surrogate network can be trained, the parameters of which are used to generate the attack.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoregressive-perturbations-for-data</guid>
    </item>
    <item>
      <title>pFL-Bench: A Comprehensive Benchmark for Personalized Federated Learning</title>
      <link>https://paperswithcode.com/paper/pfl-bench-a-comprehensive-benchmark-for</link>
      <description><![CDATA[Personalized Federated Learning (pFL) has gained increasing attention in recent years due to its success in handling the statistical heterogeneity of FL clients via utilizing and deploying distinct local models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pfl-bench-a-comprehensive-benchmark-for</guid>
    </item>
    <item>
      <title>Mathematical model bridges disparate timescales of lifelong learning</title>
      <link>https://paperswithcode.com/paper/mathematical-model-bridges-disparate</link>
      <description><![CDATA[Our model connects previously disparate timescales -- and the subdisciplines that typically study each timescale in isolation -- to offer a unified account of the timecourse of skill acquisition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mathematical-model-bridges-disparate</guid>
    </item>
    <item>
      <title>FedHPO-B: A Benchmark Suite for Federated Hyperparameter Optimization</title>
      <link>https://paperswithcode.com/paper/fedhpo-b-a-benchmark-suite-for-federated</link>
      <description><![CDATA[Due to this uniqueness, existing HPO benchmarks no longer satisfy the need to compare HPO methods in the FL setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedhpo-b-a-benchmark-suite-for-federated</guid>
    </item>
    <item>
      <title>Sparse Fusion Mixture-of-Experts are Domain Generalizable Learners</title>
      <link>https://paperswithcode.com/paper/sparse-fusion-mixture-of-experts-are-domain</link>
      <description><![CDATA[To this end, we propose Sparse Fusion Mixture-of-Experts (SF-MoE), which incorporates sparsity and fusion mechanisms into the MoE framework to keep the model both sparse and predictive.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparse-fusion-mixture-of-experts-are-domain</guid>
    </item>
    <item>
      <title>Sampling-based techniques for designing school boundaries</title>
      <link>https://paperswithcode.com/paper/sampling-based-techniques-for-designing</link>
      <description><![CDATA[Motivated by these recent developments, we develop a set of similar sampling techniques for designing school boundaries based on the flip proposal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sampling-based-techniques-for-designing</guid>
    </item>
    <item>
      <title>Neural Diffusion Processes</title>
      <link>https://paperswithcode.com/paper/neural-diffusion-processes</link>
      <description><![CDATA[Gaussian processes provide an elegant framework for specifying prior and posterior distributions over functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-diffusion-processes</guid>
    </item>
    <item>
      <title>SYNERgy between SYNaptic consolidation and Experience Replay for general continual learning</title>
      <link>https://paperswithcode.com/paper/synergy-between-synaptic-consolidation-and</link>
      <description><![CDATA[Continual learning (CL) in the brain is facilitated by a complex set of mechanisms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synergy-between-synaptic-consolidation-and</guid>
    </item>
    <item>
      <title>Blind Face Restoration: Benchmark Datasets and a Baseline Model</title>
      <link>https://paperswithcode.com/paper/blind-face-restoration-benchmark-datasets-and</link>
      <description><![CDATA[To address this problem, we first synthesize two blind face restoration benchmark datasets called EDFace-Celeb-1M (BFR128) and EDFace-Celeb-150K (BFR512).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blind-face-restoration-benchmark-datasets-and</guid>
    </item>
    <item>
      <title>Generative Myocardial Motion Tracking via Latent Space Exploration with Biomechanics-informed Prior</title>
      <link>https://paperswithcode.com/paper/generative-myocardial-motion-tracking-via</link>
      <description><![CDATA[In contrast to most existing approaches which impose explicit generic regularization such as smoothness, in this work we propose a novel method that can implicitly learn an application-specific biomechanics-informed prior and embed it into a neural network-parameterized transformation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-myocardial-motion-tracking-via</guid>
    </item>
    <item>
      <title>Unsupervised Learning of 3D Scene Flow from Monocular Camera</title>
      <link>https://paperswithcode.com/paper/unsupervised-learning-of-3d-scene-flow-from</link>
      <description><![CDATA[Unsupervised learning of scene flow in this paper mainly consists of two parts: (i) depth estimation and camera pose estimation, and (ii) scene flow estimation based on four different loss functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-learning-of-3d-scene-flow-from</guid>
    </item>
    <item>
      <title>Language-Bridged Spatial-Temporal Interaction for Referring Video Object Segmentation</title>
      <link>https://paperswithcode.com/paper/language-bridged-spatial-temporal-interaction-1</link>
      <description><![CDATA[Referring video object segmentation aims to predict foreground labels for objects referred by natural language expressions in videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-bridged-spatial-temporal-interaction-1</guid>
    </item>
    <item>
      <title>Proactively Reducing the Hate Intensity of Online Posts via Hate Speech Normalization</title>
      <link>https://paperswithcode.com/paper/proactively-reducing-the-hate-intensity-of</link>
      <description><![CDATA[Curbing online hate speech has become the need of the hour; however, a blanket ban on such activities is infeasible for several geopolitical and cultural reasons.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proactively-reducing-the-hate-intensity-of</guid>
    </item>
    <item>
      <title>Metric Based Few-Shot Graph Classification</title>
      <link>https://paperswithcode.com/paper/metric-based-few-shot-graph-classification</link>
      <description><![CDATA[In this work, we tackle the problem of few-shot graph classification, showing that equipping a simple distance metric learning baseline with a state-of-the-art graph embedder allows to obtain competitive results on the task. While the simplicity of the architecture is enough to outperform more complex ones, it also allows straightforward additions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metric-based-few-shot-graph-classification</guid>
    </item>
    <item>
      <title>Designing Reinforcement Learning Algorithms for Digital Interventions: Pre-implementation Guidelines</title>
      <link>https://paperswithcode.com/paper/designing-reinforcement-learning-algorithms</link>
      <description><![CDATA[Online reinforcement learning (RL) algorithms are increasingly used to personalize digital interventions in the fields of mobile health and online education.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/designing-reinforcement-learning-algorithms</guid>
    </item>
    <item>
      <title>Large Loss Matters in Weakly Supervised Multi-Label Classification</title>
      <link>https://paperswithcode.com/paper/large-loss-matters-in-weakly-supervised-multi-1</link>
      <description><![CDATA[In this work, we first regard unobserved labels as negative labels, casting the WSML task into noisy multi-label classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-loss-matters-in-weakly-supervised-multi-1</guid>
    </item>
    <item>
      <title>Sharp-MAML: Sharpness-Aware Model-Agnostic Meta Learning</title>
      <link>https://paperswithcode.com/paper/sharp-maml-sharpness-aware-model-agnostic</link>
      <description><![CDATA[Model-agnostic meta learning (MAML) is currently one of the dominating approaches for few-shot meta-learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sharp-maml-sharpness-aware-model-agnostic</guid>
    </item>
    <item>
      <title>Controlling strokes in fast neural style transfer using content transforms</title>
      <link>https://paperswithcode.com/paper/controlling-strokes-in-fast-neural-style</link>
      <description><![CDATA[To demonstrate the real-world applicability of our approach, we present StyleTune, a mobile app for interactive editing of neural style transfers at multiple levels of control.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controlling-strokes-in-fast-neural-style</guid>
    </item>
    <item>
      <title>Wavelet Regularization Benefits Adversarial Training</title>
      <link>https://paperswithcode.com/paper/wavelet-regularization-benefits-adversarial</link>
      <description><![CDATA[Since adversarial vulnerability can be regarded as a high-frequency phenomenon, it is essential to regulate the adversarially-trained neural network models in the frequency domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wavelet-regularization-benefits-adversarial</guid>
    </item>
    <item>
      <title>Stabilizing Voltage in Power Distribution Networks via Multi-Agent Reinforcement Learning with Transformer</title>
      <link>https://paperswithcode.com/paper/stabilizing-voltage-in-power-distribution</link>
      <description><![CDATA[Utilizing MARL algorithms to coordinate multiple control units in the grid, which is able to handle rapid changes of power systems, has been widely studied in active voltage control task recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stabilizing-voltage-in-power-distribution</guid>
    </item>
    <item>
      <title>Robust Deep Ensemble Method for Real-world Image Denoising</title>
      <link>https://paperswithcode.com/paper/robust-deep-ensemble-method-for-real-world</link>
      <description><![CDATA[In particular, we take well-trained CBDNet, NBNet, HINet, Uformer and GMSNet into denoiser pool, and a U-Net is adopted to predict pixel-wise weighting maps to fuse these denoisers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-deep-ensemble-method-for-real-world</guid>
    </item>
    <item>
      <title>Dual-Distribution Discrepancy for Anomaly Detection in Chest X-Rays</title>
      <link>https://paperswithcode.com/paper/dual-distribution-discrepancy-for-anomaly</link>
      <description><![CDATA[During training, module A takes both known normal and unlabeled images as inputs, capturing anomalous features from unlabeled images in some way, while module B models the distribution of only known normal images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-distribution-discrepancy-for-anomaly</guid>
    </item>
    <item>
      <title>Latent Boundary-guided Adversarial Training</title>
      <link>https://paperswithcode.com/paper/latent-boundary-guided-adversarial-training</link>
      <description><![CDATA[Adversarial training is proved to be the most effective strategy that injects adversarial examples into model training to improve the robustness of DNN models to adversarial attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-boundary-guided-adversarial-training</guid>
    </item>
    <item>
      <title>Masked Unsupervised Self-training for Zero-shot Image Classification</title>
      <link>https://paperswithcode.com/paper/masked-unsupervised-self-training-for-zero</link>
      <description><![CDATA[We demonstrate the efficacy of MUST on 8 downstream tasks across a variety of domains, where it improves upon CLIP by a large margin and narrows the performance gap between unsupervised and supervised classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-unsupervised-self-training-for-zero</guid>
    </item>
    <item>
      <title>DeepCAVE: An Interactive Analysis Tool for Automated Machine Learning</title>
      <link>https://paperswithcode.com/paper/deepcave-an-interactive-analysis-tool-for</link>
      <description><![CDATA[Automated Machine Learning (AutoML) is used more than ever before to support users in determining efficient hyperparameters, neural architectures, or even full machine learning pipelines.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepcave-an-interactive-analysis-tool-for</guid>
    </item>
    <item>
      <title>Tutel: Adaptive Mixture-of-Experts at Scale</title>
      <link>https://paperswithcode.com/paper/tutel-adaptive-mixture-of-experts-at-scale</link>
      <description><![CDATA[On effectiveness, the SwinV2-MoE model achieves superior accuracy in both pre-training and down-stream computer vision tasks such as COCO object detection than the counterpart dense model, indicating the readiness of Tutel for end-to-end real-world model training and inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tutel-adaptive-mixture-of-experts-at-scale</guid>
    </item>
    <item>
      <title>Asymptotic Stability in Reservoir Computing</title>
      <link>https://paperswithcode.com/paper/asymptotic-stability-in-reservoir-computing</link>
      <description><![CDATA[Reservoir Computing is a class of Recurrent Neural Networks with internal weights fixed at random.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asymptotic-stability-in-reservoir-computing</guid>
    </item>
    <item>
      <title>Learning Backward Compatible Embeddings</title>
      <link>https://paperswithcode.com/paper/learning-backward-compatible-embeddings</link>
      <description><![CDATA[We formalize the problem where the goal is for the embedding team to keep updating the embedding version, while the consumer teams do not have to retrain their models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-backward-compatible-embeddings</guid>
    </item>
    <item>
      <title>Assessing Project-Level Fine-Tuning of ML4SE Models</title>
      <link>https://paperswithcode.com/paper/assessing-project-level-fine-tuning-of-ml4se</link>
      <description><![CDATA[We evaluate three models of different complexity and compare their quality in three settings: trained on a large dataset of Java projects, further fine-tuned on the data from a particular project, and trained from scratch on this data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/assessing-project-level-fine-tuning-of-ml4se</guid>
    </item>
    <item>
      <title>Computational Doob's $h$-transforms for Online Filtering of Discretely Observed Diffusions</title>
      <link>https://paperswithcode.com/paper/computational-doob-s-h-transforms-for-online</link>
      <description><![CDATA[This paper is concerned with online filtering of discretely observed nonlinear diffusion processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/computational-doob-s-h-transforms-for-online</guid>
    </item>
    <item>
      <title>Revealing Single Frame Bias for Video-and-Language Learning</title>
      <link>https://paperswithcode.com/paper/revealing-single-frame-bias-for-video-and</link>
      <description><![CDATA[Training an effective video-and-language model intuitively requires multiple frames as model inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revealing-single-frame-bias-for-video-and</guid>
    </item>
    <item>
      <title>Building Robust Ensembles via Margin Boosting</title>
      <link>https://paperswithcode.com/paper/building-robust-ensembles-via-margin-boosting</link>
      <description><![CDATA[Consequently, an emerging line of work has focused on learning an ensemble of neural networks to defend against adversarial attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/building-robust-ensembles-via-margin-boosting</guid>
    </item>
    <item>
      <title>Localizing Semantic Patches for Accelerating Image Classification</title>
      <link>https://paperswithcode.com/paper/localizing-semantic-patches-for-accelerating</link>
      <description><![CDATA[This ensures the exact mapping from a high-level spatial location to the specific input image patch.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/localizing-semantic-patches-for-accelerating</guid>
    </item>
    <item>
      <title>Utility of Equivariant Message Passing in Cortical Mesh Segmentation</title>
      <link>https://paperswithcode.com/paper/utility-of-equivariant-message-passing-in</link>
      <description><![CDATA[Our evaluation shows that GNNs outperform EGNNs on aligned meshes, due to their ability to leverage the presence of a global coordinate system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/utility-of-equivariant-message-passing-in</guid>
    </item>
    <item>
      <title>The Devil is in the Labels: Noisy Label Correction for Robust Scene Graph Generation</title>
      <link>https://paperswithcode.com/paper/the-devil-is-in-the-labels-noisy-label-1</link>
      <description><![CDATA[Then, in Pos-NSD, we use a clustering-based algorithm to divide all positive samples into multiple sets, and treat the samples in the noisiest set as noisy positive samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-devil-is-in-the-labels-noisy-label-1</guid>
    </item>
    <item>
      <title>Federated Hetero-Task Learning</title>
      <link>https://paperswithcode.com/paper/federated-hetero-task-learning</link>
      <description><![CDATA[To investigate the heterogeneity of federated learning in real-world scenarios, we generalize the classical federated learning to federated hetero-task learning, which emphasizes the inconsistency across the participants in federated learning in terms of both data distribution and learning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/federated-hetero-task-learning</guid>
    </item>
    <item>
      <title>Integrating Random Effects in Deep Neural Networks</title>
      <link>https://paperswithcode.com/paper/integrating-random-effects-in-deep-neural</link>
      <description><![CDATA[We propose to use the mixed models framework to handle correlated data in DNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/integrating-random-effects-in-deep-neural</guid>
    </item>
    <item>
      <title>Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances</title>
      <link>https://paperswithcode.com/paper/shedding-a-pac-bayesian-light-on-adaptive</link>
      <description><![CDATA[The Sliced-Wasserstein distance (SW) is a computationally efficient and theoretically grounded alternative to the Wasserstein distance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shedding-a-pac-bayesian-light-on-adaptive</guid>
    </item>
    <item>
      <title>Combining Genetic Programming and Particle Swarm Optimization to Simplify Rugged Landscapes Exploration</title>
      <link>https://paperswithcode.com/paper/combining-genetic-programming-and-particle</link>
      <description><![CDATA[The proposed algorithm, called the GP-FST-PSO Surrogate Model, achieves satisfactory results in both the search for the global optimum and the production of a visual approximation of the original benchmark function (in the 2-dimensional case).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/combining-genetic-programming-and-particle</guid>
    </item>
    <item>
      <title>Unsupervised Context Aware Sentence Representation Pretraining for Multi-lingual Dense Retrieval</title>
      <link>https://paperswithcode.com/paper/unsupervised-context-aware-sentence</link>
      <description><![CDATA[On the multilingual sentence retrieval task Tatoeba, our model achieves new SOTA results among methods without using bilingual data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-context-aware-sentence</guid>
    </item>
    <item>
      <title>The Influence of Dataset Partitioning on Dysfluency Detection Systems</title>
      <link>https://paperswithcode.com/paper/the-influence-of-dataset-partitioning-on</link>
      <description><![CDATA[This paper empirically investigates the influence of different data splits and splitting strategies on the performance of dysfluency detection systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-influence-of-dataset-partitioning-on</guid>
    </item>
    <item>
      <title>Improving Fairness in Graph Neural Networks via Mitigating Sensitive Attribute Leakage</title>
      <link>https://paperswithcode.com/paper/improving-fairness-in-graph-neural-networks</link>
      <description><![CDATA[Motivated by our analysis, we propose Fair View Graph Neural Network (FairVGNN) to generate fair views of features by automatically identifying and masking sensitive-correlated features considering correlation variation after feature propagation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-fairness-in-graph-neural-networks</guid>
    </item>
    <item>
      <title>Siamese Encoder-based Spatial-Temporal Mixer for Growth Trend Prediction of Lung Nodules on CT Scans</title>
      <link>https://paperswithcode.com/paper/siamese-encoder-based-spatial-temporal-mixer</link>
      <description><![CDATA[In the management of lung nodules, we are desirable to predict nodule evolution in terms of its diameter variation on Computed Tomography (CT) scans and then provide a follow-up recommendation according to the predicted result of the growing trend of the nodule.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/siamese-encoder-based-spatial-temporal-mixer</guid>
    </item>
    <item>
      <title>One Ring to Bring Them All: Towards Open-Set Recognition under Domain Shift</title>
      <link>https://paperswithcode.com/paper/one-ring-to-bring-them-all-towards-open-set</link>
      <description><![CDATA[In experiments, we show: $\textbf{1)}$ After source training, the resulting source model can get excellent performance for $\textit{open-set single domain generalization}$ and also $\textit{open-set recognition}$ tasks; $\textbf{2)}$ After target adaptation, our method surpasses current UNDA approaches which demand source data during adaptation on several benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-ring-to-bring-them-all-towards-open-set</guid>
    </item>
    <item>
      <title>From "Where" to "What": Towards Human-Understandable Explanations through Concept Relevance Propagation</title>
      <link>https://paperswithcode.com/paper/from-where-to-what-towards-human</link>
      <description><![CDATA[In this work we introduce the Concept Relevance Propagation (CRP) approach, which combines the local and global perspectives of XAI and thus allows answering both the "where" and "what" questions for individual predictions, without additional constraints imposed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-where-to-what-towards-human</guid>
    </item>
    <item>
      <title>Towards a General Purpose CNN for Long Range Dependencies in $\mathrm{N}$D</title>
      <link>https://paperswithcode.com/paper/towards-a-general-purpose-cnn-for-long-range</link>
      <description><![CDATA[The use of Convolutional Neural Networks (CNNs) is widespread in Deep Learning due to a range of desirable model properties which result in an efficient and effective machine learning framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-a-general-purpose-cnn-for-long-range</guid>
    </item>
    <item>
      <title>Beyond spectral gap: The role of the topology in decentralized learning</title>
      <link>https://paperswithcode.com/paper/beyond-spectral-gap-the-role-of-the-topology</link>
      <description><![CDATA[In data-parallel optimization of machine learning models, workers collaborate to improve their estimates of the model: more accurate gradients allow them to use larger learning rates and optimize faster.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-spectral-gap-the-role-of-the-topology</guid>
    </item>
    <item>
      <title>PyTSK: A Python Toolbox for TSK Fuzzy Systems</title>
      <link>https://paperswithcode.com/paper/pytsk-a-python-toolbox-for-tsk-fuzzy-systems</link>
      <description><![CDATA[This paper presents PyTSK, a Python toolbox for developing Takagi-Sugeno-Kang (TSK) fuzzy systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pytsk-a-python-toolbox-for-tsk-fuzzy-systems</guid>
    </item>
  </channel>
</rss>
