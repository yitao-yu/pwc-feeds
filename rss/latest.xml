<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 27 Nov 2024 09:17:31 +0000</lastBuildDate>
    <item>
      <title>A Novel Word Pair-based Gaussian Sentence Similarity Algorithm For Bengali Extractive Text Summarization</title>
      <link>https://paperswithcode.com/paper/a-novel-word-pair-based-gaussian-sentence</link>
      <description><![CDATA[Here, we propose a novel Word pair-based Gaussian Sentence Similarity (WGSS) algorithm for calculating the semantic relation between two sentences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-novel-word-pair-based-gaussian-sentence</guid>
    </item>
    <item>
      <title>Can LLMs be Good Graph Judger for Knowledge Graph Construction?</title>
      <link>https://paperswithcode.com/paper/can-llms-be-good-graph-judger-for-knowledge</link>
      <description><![CDATA[We seek to utilize the capacity of LLMs to function as a graph judger, a capability superior to their role only as a predictor for KG construction problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-llms-be-good-graph-judger-for-knowledge</guid>
    </item>
    <item>
      <title>Learning Monotonic Attention in Transducer for Streaming Generation</title>
      <link>https://paperswithcode.com/paper/learning-monotonic-attention-in-transducer</link>
      <description><![CDATA[Streaming generation models are increasingly utilized across various fields, with the Transducer architecture being particularly popular in industrial applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-monotonic-attention-in-transducer</guid>
    </item>
    <item>
      <title>SAMWISE: Infusing wisdom in SAM2 for Text-Driven Video Segmentation</title>
      <link>https://paperswithcode.com/paper/samwise-infusing-wisdom-in-sam2-for-text</link>
      <description><![CDATA[Referring Video Object Segmentation (RVOS) relies on natural language expressions to segment an object in a video clip.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/samwise-infusing-wisdom-in-sam2-for-text</guid>
    </item>
    <item>
      <title>TinyViM: Frequency Decoupling for Tiny Hybrid Vision Mamba</title>
      <link>https://paperswithcode.com/paper/tinyvim-frequency-decoupling-for-tiny-hybrid</link>
      <description><![CDATA[Based on the analyses, we introduce a novel Laplace mixer to decouple the features in terms of frequency and input only the low-frequency components into the Mamba block.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tinyvim-frequency-decoupling-for-tiny-hybrid</guid>
    </item>
    <item>
      <title>Star Attention: Efficient LLM Inference over Long Sequences</title>
      <link>https://paperswithcode.com/paper/star-attention-efficient-llm-inference-over</link>
      <description><![CDATA[Inference with Transformer-based Large Language Models (LLMs) on long sequences is both costly and slow due to the quadratic complexity of the self-attention mechanism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/star-attention-efficient-llm-inference-over</guid>
    </item>
    <item>
      <title>Disentangled Interpretable Representation for Efficient Long-term Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/disentangled-interpretable-representation-for</link>
      <description><![CDATA[Existing deep learning and linear models often suffer from excessive parameter complexity and lack intuitive interpretability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disentangled-interpretable-representation-for</guid>
    </item>
    <item>
      <title>DROID-Splat: Combining end-to-end SLAM with 3D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/droid-splat-combining-end-to-end-slam-with-3d</link>
      <description><![CDATA[Recent progress in scene synthesis makes standalone SLAM systems purely based on optimizing hyperprimitives with a Rendering objective possible \cite{monogs}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/droid-splat-combining-end-to-end-slam-with-3d</guid>
    </item>
    <item>
      <title>P2DFlow: A Protein Ensemble Generative Model with SE(3) Flow Matching</title>
      <link>https://paperswithcode.com/paper/p2dflow-a-protein-ensemble-generative-model</link>
      <description><![CDATA[Biological processes, functions, and properties are intricately linked to the ensemble of protein conformations, rather than being solely determined by a single stable conformation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/p2dflow-a-protein-ensemble-generative-model</guid>
    </item>
    <item>
      <title>PassionSR: Post-Training Quantization with Adaptive Scale in One-Step Diffusion based Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/passionsr-post-training-quantization-with</link>
      <description><![CDATA[Diffusion-based image super-resolution (SR) models have shown superior performance at the cost of multiple denoising steps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/passionsr-post-training-quantization-with</guid>
    </item>
    <item>
      <title>X-MeshGraphNet: Scalable Multi-Scale Graph Neural Networks for Physics Simulation</title>
      <link>https://paperswithcode.com/paper/x-meshgraphnet-scalable-multi-scale-graph</link>
      <description><![CDATA[In this work, we introduce X-MeshGraphNet, a scalable, multi-scale extension of MeshGraphNet designed to address these challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-meshgraphnet-scalable-multi-scale-graph</guid>
    </item>
    <item>
      <title>Enhancing Imbalance Learning: A Novel Slack-Factor Fuzzy SVM Approach</title>
      <link>https://paperswithcode.com/paper/enhancing-imbalance-learning-a-novel-slack</link>
      <description><![CDATA[In real-world applications, class-imbalanced datasets pose significant challenges for machine learning algorithms, such as support vector machines (SVMs), particularly in effectively managing imbalance, noise, and outliers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-imbalance-learning-a-novel-slack</guid>
    </item>
    <item>
      <title>On the Efficiency of NLP-Inspired Methods for Tabular Deep Learning</title>
      <link>https://paperswithcode.com/paper/on-the-efficiency-of-nlp-inspired-methods-for</link>
      <description><![CDATA[Recent advancements in tabular deep learning (DL) have led to substantial performance improvements, surpassing the capabilities of traditional models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-efficiency-of-nlp-inspired-methods-for</guid>
    </item>
    <item>
      <title>Grounding-IQA: Multimodal Language Grounding Model for Image Quality Assessment</title>
      <link>https://paperswithcode.com/paper/grounding-iqa-multimodal-language-grounding</link>
      <description><![CDATA[Experiments demonstrate that our proposed task paradigm, dataset, and benchmark facilitate the more fine-grained IQA application.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grounding-iqa-multimodal-language-grounding</guid>
    </item>
    <item>
      <title>OSDFace: One-Step Diffusion Model for Face Restoration</title>
      <link>https://paperswithcode.com/paper/osdface-one-step-diffusion-model-for-face</link>
      <description><![CDATA[Moreover, existing methods often struggle to generate face images that are harmonious, realistic, and consistent with the subject's identity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/osdface-one-step-diffusion-model-for-face</guid>
    </item>
    <item>
      <title>ShowUI: One Vision-Language-Action Model for GUI Visual Agent</title>
      <link>https://paperswithcode.com/paper/showui-one-vision-language-action-model-for</link>
      <description><![CDATA[In this work, we develop a vision-language-action model in digital world, namely ShowUI, which features the following innovations: (i) UI-Guided Visual Token Selection to reduce computational costs by formulating screenshots as an UI connected graph, adaptively identifying their redundant relationship and serve as the criteria for token selection during self-attention blocks; (ii) Interleaved Vision-Language-Action Streaming that flexibly unifies diverse needs within GUI tasks, enabling effective management of visual-action history in navigation or pairing multi-turn query-action sequences per screenshot to enhance training efficiency; (iii) Small-scale High-quality GUI Instruction-following Datasets by careful data curation and employing a resampling strategy to address significant data type imbalances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/showui-one-vision-language-action-model-for</guid>
    </item>
    <item>
      <title>Accelerating Vision Diffusion Transformers with Skip Branches</title>
      <link>https://paperswithcode.com/paper/accelerating-vision-diffusion-transformers</link>
      <description><![CDATA[Diffusion Transformers (DiT), an emerging image and video generation model architecture, has demonstrated great potential because of its high generation quality and scalability properties.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-vision-diffusion-transformers</guid>
    </item>
    <item>
      <title>Box for Mask and Mask for Box: weak losses for multi-task partially supervised learning</title>
      <link>https://paperswithcode.com/paper/box-for-mask-and-mask-for-box-weak-losses-for</link>
      <description><![CDATA[Making use of one task's information to train the other would be beneficial for multi-task partially supervised learning where each training example is annotated only for a single task, having the potential to expand training sets with different-task datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/box-for-mask-and-mask-for-box-weak-losses-for</guid>
    </item>
    <item>
      <title>cWDM: Conditional Wavelet Diffusion Models for Cross-Modality 3D Medical Image Synthesis</title>
      <link>https://paperswithcode.com/paper/cwdm-conditional-wavelet-diffusion-models-for</link>
      <description><![CDATA[This paper contributes to the "BraTS 2024 Brain MR Image Synthesis Challenge" and presents a conditional Wavelet Diffusion Model (cWDM) for directly solving a paired image-to-image translation task on high-resolution volumes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cwdm-conditional-wavelet-diffusion-models-for</guid>
    </item>
    <item>
      <title>Learning Explainable Treatment Policies with Clinician-Informed Representations: A Practical Approach</title>
      <link>https://paperswithcode.com/paper/learning-explainable-treatment-policies-with</link>
      <description><![CDATA[Our main contribution is to reveal the importance of clinical domain knowledge in developing state and action representations for effective, efficient, and interpretable targeting policies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-explainable-treatment-policies-with</guid>
    </item>
    <item>
      <title>2D Matryoshka Training for Information Retrieval</title>
      <link>https://paperswithcode.com/paper/2d-matryoshka-training-for-information</link>
      <description><![CDATA[In this reproducibility study, we implement and evaluate both versions of 2D Matryoshka Training on STS tasks and extend our analysis to retrieval tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2d-matryoshka-training-for-information</guid>
    </item>
    <item>
      <title>DreamMix: Decoupling Object Attributes for Enhanced Editability in Customized Image Inpainting</title>
      <link>https://paperswithcode.com/paper/dreammix-decoupling-object-attributes-for</link>
      <description><![CDATA[Extensive experiments demonstrate that DreamMix effectively balances identity preservation and attribute editability across various application scenarios, including object insertion, attribute editing, and small object inpainting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreammix-decoupling-object-attributes-for</guid>
    </item>
    <item>
      <title>WF-VAE: Enhancing Video VAE by Wavelet-Driven Energy Flow for Latent Video Diffusion Model</title>
      <link>https://paperswithcode.com/paper/wf-vae-enhancing-video-vae-by-wavelet-driven</link>
      <description><![CDATA[However, as the resolution and duration of generated videos increase, the encoding cost of Video VAEs becomes a limiting bottleneck in training LVDMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wf-vae-enhancing-video-vae-by-wavelet-driven</guid>
    </item>
    <item>
      <title>Path-RAG: Knowledge-Guided Key Region Retrieval for Open-ended Pathology Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/path-rag-knowledge-guided-key-region</link>
      <description><![CDATA[Admitting the complexity of pathology image analysis, Path-RAG adopts a human-centered AI approach by retrieving domain knowledge using HistoCartography to select the relevant patches from pathology images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/path-rag-knowledge-guided-key-region</guid>
    </item>
    <item>
      <title>Distractor-free Generalizable 3D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/distractor-free-generalizable-3d-gaussian</link>
      <description><![CDATA[To achieve these objectives, DGGS introduces a scene-agnostic reference-based mask prediction and refinement methodology during training phase, coupled with a training view selection strategy, effectively improving distractor prediction accuracy and training stability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distractor-free-generalizable-3d-gaussian</guid>
    </item>
    <item>
      <title>A Distractor-Aware Memory for Visual Object Tracking with SAM2</title>
      <link>https://paperswithcode.com/paper/a-distractor-aware-memory-for-visual-object</link>
      <description><![CDATA[We argue that a more sophisticated memory model is required, and propose a new distractor-aware memory model for SAM2 and an introspection-based update strategy that jointly addresses the segmentation accuracy as well as tracking robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-distractor-aware-memory-for-visual-object</guid>
    </item>
    <item>
      <title>Emergenet: A Digital Twin of Sequence Evolution for Scalable Emergence Risk Assessment of Animal Influenza A Strains</title>
      <link>https://paperswithcode.com/paper/emergenet-a-digital-twin-of-sequence</link>
      <description><![CDATA[Despite having triggered devastating pandemics in the past, our ability to quantitatively assess the emergence potential of individual strains of animal influenza viruses remains limited.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emergenet-a-digital-twin-of-sequence</guid>
    </item>
    <item>
      <title>Pre-training for Action Recognition with Automatically Generated Fractal Datasets</title>
      <link>https://paperswithcode.com/paper/pre-training-for-action-recognition-with</link>
      <description><![CDATA[We extend this trend to the video domain applying it to the task of action recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pre-training-for-action-recognition-with</guid>
    </item>
    <item>
      <title>NumGrad-Pull: Numerical Gradient Guided Tri-plane Representation for Surface Reconstruction from Point Clouds</title>
      <link>https://paperswithcode.com/paper/numgrad-pull-numerical-gradient-guided-tri</link>
      <description><![CDATA[Recent advancements address this problem by training neural signed distance functions to pull 3D location queries to their closest points on a surface, following the predicted signed distances and the analytical gradients computed by the network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/numgrad-pull-numerical-gradient-guided-tri</guid>
    </item>
    <item>
      <title>StableAnimator: High-Quality Identity-Preserving Human Image Animation</title>
      <link>https://paperswithcode.com/paper/stableanimator-high-quality-identity</link>
      <description><![CDATA[During inference, we propose a novel Hamilton-Jacobi-Bellman (HJB) equation-based optimization to further enhance the face quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stableanimator-high-quality-identity</guid>
    </item>
    <item>
      <title>Open Vocabulary Monocular 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/open-vocabulary-monocular-3d-object-detection</link>
      <description><![CDATA[In this work, we pioneer the study of open-vocabulary monocular 3D object detection, a novel task that aims to detect and localize objects in 3D space from a single RGB image without limiting detection to a predefined set of categories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-vocabulary-monocular-3d-object-detection</guid>
    </item>
    <item>
      <title>Ca2-VDM: Efficient Autoregressive Video Diffusion Model with Causal Generation and Cache Sharing</title>
      <link>https://paperswithcode.com/paper/ca2-vdm-efficient-autoregressive-video</link>
      <description><![CDATA[For causal generation, it introduces unidirectional feature computation, which ensures that the cache of conditional frames can be precomputed in previous autoregression steps and reused in every subsequent step, eliminating redundant computations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ca2-vdm-efficient-autoregressive-video</guid>
    </item>
    <item>
      <title>Gaussian Process Priors for Boundary Value Problems of Linear Partial Differential Equations</title>
      <link>https://paperswithcode.com/paper/gaussian-process-priors-for-boundary-value</link>
      <description><![CDATA[In this work, we propose Boundary Ehrenpreis-Palamodov Gaussian Processes (B-EPGPs), a novel framework for constructing GP priors that satisfy both general systems of linear PDEs with constant coefficients and linear boundary conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaussian-process-priors-for-boundary-value</guid>
    </item>
    <item>
      <title>Exploring Discrete Flow Matching for 3D De Novo Molecule Generation</title>
      <link>https://paperswithcode.com/paper/exploring-discrete-flow-matching-for-3d-de</link>
      <description><![CDATA[Several discrete flow matching methods have been proposed recently to address this gap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-discrete-flow-matching-for-3d-de</guid>
    </item>
    <item>
      <title>Batch Bayesian Optimization via Expected Subspace Improvement</title>
      <link>https://paperswithcode.com/paper/batch-bayesian-optimization-via-expected</link>
      <description><![CDATA[Most of current batch approaches use artificial functions to simulate the sequential Bayesian optimization algorithm's behavior to select a batch of points for parallel evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/batch-bayesian-optimization-via-expected</guid>
    </item>
    <item>
      <title>SplatAD: Real-Time Lidar and Camera Rendering with 3D Gaussian Splatting for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/splatad-real-time-lidar-and-camera-rendering</link>
      <description><![CDATA[Ensuring the safety of autonomous robots, such as self-driving vehicles, requires extensive testing across diverse driving scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/splatad-real-time-lidar-and-camera-rendering</guid>
    </item>
    <item>
      <title>Sparse patches adversarial attacks via extrapolating point-wise information</title>
      <link>https://paperswithcode.com/paper/sparse-patches-adversarial-attacks-via</link>
      <description><![CDATA[Our approach enables simultaneous optimization of multiple sparse patches' locations and perturbations for any given number and shape.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparse-patches-adversarial-attacks-via</guid>
    </item>
    <item>
      <title>UltraSam: A Foundation Model for Ultrasound using Large Open-Access Segmentation Datasets</title>
      <link>https://paperswithcode.com/paper/ultrasam-a-foundation-model-for-ultrasound</link>
      <description><![CDATA[Methods: We compile US-43d, a large-scale collection of 43 open-access ultrasound datasets with over 280, 000 images and segmentation masks for more than 50 anatomical structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ultrasam-a-foundation-model-for-ultrasound</guid>
    </item>
    <item>
      <title>FUN-AD: Fully Unsupervised Learning for Anomaly Detection with Noisy Training Data</title>
      <link>https://paperswithcode.com/paper/fun-ad-fully-unsupervised-learning-for</link>
      <description><![CDATA[Our method is motivated by two observations, that i) the pairwise feature distances between the normal samples are on average likely to be smaller than those between the anomaly samples or heterogeneous samples and ii) pairs of features mutually closest to each other are likely to be homogeneous pairs, which hold if the normal data has smaller variance than the anomaly data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fun-ad-fully-unsupervised-learning-for</guid>
    </item>
    <item>
      <title>Augmenting Multimodal LLMs with Self-Reflective Tokens for Knowledge-based Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/augmenting-multimodal-llms-with-self</link>
      <description><![CDATA[Multimodal LLMs (MLLMs) are the natural extension of large language models to handle multimodal inputs, combining text and image data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/augmenting-multimodal-llms-with-self</guid>
    </item>
    <item>
      <title>TreeFormer: Single-view Plant Skeleton Estimation via Tree-constrained Graph Generation</title>
      <link>https://paperswithcode.com/paper/treeformer-single-view-plant-skeleton</link>
      <description><![CDATA[While recent graph generation methods successfully infer thin structures from images, it is challenging to constrain the output graph strictly to a tree structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/treeformer-single-view-plant-skeleton</guid>
    </item>
    <item>
      <title>Understanding GEMM Performance and Energy on NVIDIA Ada Lovelace: A Machine Learning-Based Analytical Approach</title>
      <link>https://paperswithcode.com/paper/understanding-gemm-performance-and-energy-on</link>
      <description><![CDATA[Through analysis of both naive tiled matrix multiplication with varying tile sizes (1 to 32) and 16, 128 CUTLASS GEMM operations across diverse configurations, we identified critical performance patterns related to matrix dimensions, thread block configurations, and memory access patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-gemm-performance-and-energy-on</guid>
    </item>
    <item>
      <title>Glo-In-One-v2: Holistic Identification of Glomerular Cells, Tissues, and Lesions in Human and Mouse Histopathology</title>
      <link>https://paperswithcode.com/paper/glo-in-one-v2-holistic-identification-of</link>
      <description><![CDATA[In this study, we leverage the Glo-In-One toolkit to version 2 with fine-grained segmentation capabilities, curating 14 distinct labels for tissue regions, cells, and lesions across a dataset of 23, 529 annotated glomeruli across human and mouse histopathology data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glo-in-one-v2-holistic-identification-of</guid>
    </item>
    <item>
      <title>MVGenMaster: Scaling Multi-View Generation from Any Image via 3D Priors Enhanced Diffusion Model</title>
      <link>https://paperswithcode.com/paper/mvgenmaster-scaling-multi-view-generation</link>
      <description><![CDATA[We introduce MVGenMaster, a multi-view diffusion model enhanced with 3D priors to address versatile Novel View Synthesis (NVS) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mvgenmaster-scaling-multi-view-generation</guid>
    </item>
    <item>
      <title>Language Driven Occupancy Prediction</title>
      <link>https://paperswithcode.com/paper/language-driven-occupancy-prediction</link>
      <description><![CDATA[To alleviate the inaccurate supervision, we propose a semantic transitive labeling pipeline to generate dense and finegrained 3D language occupancy ground truth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-driven-occupancy-prediction</guid>
    </item>
    <item>
      <title>From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge</title>
      <link>https://paperswithcode.com/paper/from-generation-to-judgment-opportunities-and</link>
      <description><![CDATA[Assessment and evaluation have long been critical challenges in artificial intelligence (AI) and natural language processing (NLP).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-generation-to-judgment-opportunities-and</guid>
    </item>
    <item>
      <title>TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment</title>
      <link>https://paperswithcode.com/paper/tifed-a-tiny-integer-based-federated-learning</link>
      <description><![CDATA[Training machine and deep learning models directly on extremely resource-constrained devices is the next challenge in the field of tiny machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tifed-a-tiny-integer-based-federated-learning</guid>
    </item>
    <item>
      <title>AnonyNoise: Anonymizing Event Data with Smart Noise to Outsmart Re-Identification and Preserve Privacy</title>
      <link>https://paperswithcode.com/paper/anonynoise-anonymizing-event-data-with-smart</link>
      <description><![CDATA[The increasing capabilities of deep neural networks for re-identification, combined with the rise in public surveillance in recent years, pose a substantial threat to individual privacy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anonynoise-anonymizing-event-data-with-smart</guid>
    </item>
    <item>
      <title>VidHal: Benchmarking Temporal Hallucinations in Vision LLMs</title>
      <link>https://paperswithcode.com/paper/vidhal-benchmarking-temporal-hallucinations</link>
      <description><![CDATA[Through our benchmark, we aim to inspire further research on 1) holistic understanding of VLLM capabilities, particularly regarding hallucination, and 2) extensive development of advanced VLLMs to alleviate this problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vidhal-benchmarking-temporal-hallucinations</guid>
    </item>
    <item>
      <title>LLM Augmentations to support Analytical Reasoning over Multiple Documents</title>
      <link>https://paperswithcode.com/paper/llm-augmentations-to-support-analytical</link>
      <description><![CDATA[Building on their demonstrated ability to perform a variety of tasks, we investigate the application of large language models (LLMs) to enhance in-depth analytical reasoning within the context of intelligence analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-augmentations-to-support-analytical</guid>
    </item>
  </channel>
</rss>
