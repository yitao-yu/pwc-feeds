<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 09 Dec 2024 21:09:42 +0000</lastBuildDate>
    <item>
      <title>Wavelet Diffusion Neural Operator</title>
      <link>https://paperswithcode.com/paper/wavelet-diffusion-neural-operator</link>
      <description><![CDATA[Recently, diffusion generative models have emerged as a competitive class of methods for these tasks due to their ability to capture long-term dependencies and model high-dimensional states.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wavelet-diffusion-neural-operator</guid>
    </item>
    <item>
      <title>Probing the contents of semantic representations from text, behavior, and brain data using the psychNorms metabase</title>
      <link>https://paperswithcode.com/paper/probing-the-contents-of-semantic</link>
      <description><![CDATA[We carry out the first systematic evaluation of the similarities and differences between semantic representations derived from text, behavior, and brain data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probing-the-contents-of-semantic</guid>
    </item>
    <item>
      <title>NLP-ADBench: NLP Anomaly Detection Benchmark</title>
      <link>https://paperswithcode.com/paper/nlp-adbench-nlp-anomaly-detection-benchmark</link>
      <description><![CDATA[This work fills a crucial gap in the field and establishes a foundation for advancing NLP anomaly detection, particularly in the context of improving the safety and reliability of web-based systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nlp-adbench-nlp-anomaly-detection-benchmark</guid>
    </item>
    <item>
      <title>Two stages domain invariant representation learners solve the large co-variate shift in unsupervised domain adaptation with two dimensional data domains</title>
      <link>https://paperswithcode.com/paper/two-stages-domain-invariant-representation</link>
      <description><![CDATA[We perform two stages domain invariant representation learning to bridge the gap between source and target with semantic intermediate data (unsupervised).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/two-stages-domain-invariant-representation</guid>
    </item>
    <item>
      <title>Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model</title>
      <link>https://paperswithcode.com/paper/stag-1-towards-realistic-4d-driving</link>
      <description><![CDATA[To address these limitations, we propose a Spatial-Temporal simulAtion for drivinG (Stag-1) model to reconstruct real-world scenes and design a controllable generative network to achieve 4D simulation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stag-1-towards-realistic-4d-driving</guid>
    </item>
    <item>
      <title>DEYOLO: Dual-Feature-Enhancement YOLO for Cross-Modality Object Detection</title>
      <link>https://paperswithcode.com/paper/deyolo-dual-feature-enhancement-yolo-for</link>
      <description><![CDATA[To fuse the two modalities to maximize the advantages of cross-modality, we design a dual-enhancement-based cross-modality object detection network DEYOLO, in which semantic-spatial cross modality and novel bi-directional decoupled focus modules are designed to achieve the detection-centered mutual enhancement of RGB-infrared (RGB-IR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deyolo-dual-feature-enhancement-yolo-for</guid>
    </item>
    <item>
      <title>PanoDreamer: 3D Panorama Synthesis from a Single Image</title>
      <link>https://paperswithcode.com/paper/panodreamer-3d-panorama-synthesis-from-a</link>
      <description><![CDATA[In this paper, we present PanoDreamer, a novel method for producing a coherent 360$^\circ$ 3D scene from a single input image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/panodreamer-3d-panorama-synthesis-from-a</guid>
    </item>
    <item>
      <title>ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges</title>
      <link>https://paperswithcode.com/paper/conqret-benchmarking-fine-grained-evaluation</link>
      <description><![CDATA[To validate the proposed techniques, we introduce ConQRet, a new benchmark featuring long and complex human-authored arguments on debated topics, grounded in real-world websites, allowing an exhaustive evaluation across retrieval effectiveness, argument quality, and groundedness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conqret-benchmarking-fine-grained-evaluation</guid>
    </item>
    <item>
      <title>Momentum-GS: Momentum Gaussian Self-Distillation for High-Quality Large Scene Reconstruction</title>
      <link>https://paperswithcode.com/paper/momentum-gs-momentum-gaussian-self</link>
      <description><![CDATA[To further ensure consistency across the blocks, we incorporate block weighting, dynamically adjusting each block's weight according to its reconstruction accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/momentum-gs-momentum-gaussian-self</guid>
    </item>
    <item>
      <title>TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft</title>
      <link>https://paperswithcode.com/paper/teamcraft-a-benchmark-for-multi-modal-multi</link>
      <description><![CDATA[Collaboration is a cornerstone of society.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teamcraft-a-benchmark-for-multi-modal-multi</guid>
    </item>
    <item>
      <title>Sparse autoencoders reveal selective remapping of visual concepts during adaptation</title>
      <link>https://paperswithcode.com/paper/sparse-autoencoders-reveal-selective</link>
      <description><![CDATA[Adapting foundation models for specific purposes has become a standard approach to build machine learning systems for downstream applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparse-autoencoders-reveal-selective</guid>
    </item>
    <item>
      <title>DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling</title>
      <link>https://paperswithcode.com/paper/demo-reframing-dialogue-interaction-with-fine</link>
      <description><![CDATA[Large language models (LLMs) have made dialogue one of the central modes of human-machine interaction, leading to the accumulation of vast amounts of conversation logs and increasing demand for dialogue generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demo-reframing-dialogue-interaction-with-fine</guid>
    </item>
    <item>
      <title>MixedGaussianAvatar: Realistically and Geometrically Accurate Head Avatar via Mixed 2D-3D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/mixedgaussianavatar-realistically-and</link>
      <description><![CDATA[We attach the 2D Gaussians to the triangular mesh of the FLAME model and connect additional 3D Gaussians to those 2D Gaussians where the rendering quality of 2DGS is inadequate, creating a mixed 2D-3D Gaussian representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixedgaussianavatar-realistically-and</guid>
    </item>
    <item>
      <title>Uncertainty-aware retinal layer segmentation in OCT through probabilistic signed distance functions</title>
      <link>https://paperswithcode.com/paper/uncertainty-aware-retinal-layer-segmentation</link>
      <description><![CDATA[To address these shortcomings, our methodology refines the segmentation by predicting a signed distance function (SDF) that effectively parameterizes the retinal layer shape via level set.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncertainty-aware-retinal-layer-segmentation</guid>
    </item>
    <item>
      <title>DrIFT: Autonomous Drone Dataset with Integrated Real and Synthetic Data, Flexible Views, and Transformed Domains</title>
      <link>https://paperswithcode.com/paper/drift-autonomous-drone-dataset-with</link>
      <description><![CDATA[However, drone detection accuracy is significantly affected by domain shifts due to environmental changes, varied points of view, and background shifts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drift-autonomous-drone-dataset-with</guid>
    </item>
    <item>
      <title>Towards Flexible 3D Perception: Object-Centric Occupancy Completion Augments 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/towards-flexible-3d-perception-object-centric</link>
      <description><![CDATA[Recognizing that foreground objects only occupy a small portion of the scene, we introduce object-centric occupancy as a supplement to object bboxes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-flexible-3d-perception-object-centric</guid>
    </item>
    <item>
      <title>One-shot Federated Learning via Synthetic Distiller-Distillate Communication</title>
      <link>https://paperswithcode.com/paper/one-shot-federated-learning-via-synthetic</link>
      <description><![CDATA[Additionally, they may encounter scalability issues with complex datasets due to inherent two-step information loss: first, during local training (from data to model), and second, when transferring knowledge to the server model (from model to inversed data).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-shot-federated-learning-via-synthetic</guid>
    </item>
    <item>
      <title>HOLa: HoloLens Object Labeling</title>
      <link>https://paperswithcode.com/paper/hola-hololens-object-labeling</link>
      <description><![CDATA[In the context of medical Augmented Reality (AR) applications, object tracking is a key challenge and requires a significant amount of annotation masks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hola-hololens-object-labeling</guid>
    </item>
    <item>
      <title>Prompt Transfer for Dual-Aspect Cross Domain Cognitive Diagnosis</title>
      <link>https://paperswithcode.com/paper/prompt-transfer-for-dual-aspect-cross-domain</link>
      <description><![CDATA[PromptCD is designed to adapt seamlessly across diverse CDCD scenarios, introducing PromptCD-S for student-aspect CDCD and PromptCD-E for exercise-aspect CDCD.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-transfer-for-dual-aspect-cross-domain</guid>
    </item>
    <item>
      <title>OCEAN: Open-World Contrastive Authorship Identification</title>
      <link>https://paperswithcode.com/paper/ocean-open-world-contrastive-authorship</link>
      <description><![CDATA[In an era where cyberattacks increasingly target the software supply chain, the ability to accurately attribute code authorship in binary files is critical to improving cybersecurity measures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ocean-open-world-contrastive-authorship</guid>
    </item>
    <item>
      <title>Unifying Dual-Space Embedding for Entity Alignment via Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/unifying-dual-space-embedding-for-entity</link>
      <description><![CDATA[Entity alignment aims to match identical entities across different knowledge graphs (KGs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unifying-dual-space-embedding-for-entity</guid>
    </item>
    <item>
      <title>Transformers Can Navigate Mazes With Multi-Step Prediction</title>
      <link>https://paperswithcode.com/paper/transformers-can-navigate-mazes-with-multi</link>
      <description><![CDATA[We train parameter-matched transformers from scratch, under identical settings, to navigate mazes of varying types and sizes with standard next token prediction and MLM-U, an objective explicitly predicting multiple steps ahead and backwards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformers-can-navigate-mazes-with-multi</guid>
    </item>
    <item>
      <title>LinVT: Empower Your Image-level Large Language Model to Understand Videos</title>
      <link>https://paperswithcode.com/paper/linvt-empower-your-image-level-large-language</link>
      <description><![CDATA[Large Language Models (LLMs) have been widely used in various tasks, motivating us to develop an LLM-based assistant for videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linvt-empower-your-image-level-large-language</guid>
    </item>
    <item>
      <title>BIAS: A Body-based Interpretable Active Speaker Approach</title>
      <link>https://paperswithcode.com/paper/bias-a-body-based-interpretable-active</link>
      <description><![CDATA[The results show that BIAS is state-of-the-art in challenging conditions where body-based features are of utmost importance (Columbia, open-settings, and WASD), and yields competitive results in AVA-ActiveSpeaker, where face is more influential than body for ASD.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bias-a-body-based-interpretable-active</guid>
    </item>
    <item>
      <title>Mixed Blessing: Class-Wise Embedding guided Instance-Dependent Partial Label Learning</title>
      <link>https://paperswithcode.com/paper/mixed-blessing-class-wise-embedding-guided</link>
      <description><![CDATA[In partial label learning (PLL), every sample is associated with a candidate label set comprising the ground-truth label and several noisy labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixed-blessing-class-wise-embedding-guided</guid>
    </item>
    <item>
      <title>SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot</title>
      <link>https://paperswithcode.com/paper/surgbox-agent-driven-operating-room-sandbox</link>
      <description><![CDATA[To address these cognitive challenges in surgical training and operation, we propose SurgBox, an agent-driven sandbox framework to systematically enhance the cognitive capabilities of surgeons in immersive surgical simulations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surgbox-agent-driven-operating-room-sandbox</guid>
    </item>
    <item>
      <title>Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</link>
      <description><![CDATA[We present Infinity, a Bitwise Visual AutoRegressive Modeling capable of generating high-resolution, photorealistic images following language instruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</guid>
    </item>
    <item>
      <title>p-MoD: Building Mixture-of-Depths MLLMs via Progressive Ratio Decay</title>
      <link>https://paperswithcode.com/paper/p-mod-building-mixture-of-depths-mllms-via</link>
      <description><![CDATA[In this paper, we propose to build efficient MLLMs by leveraging the Mixture-of-Depths (MoD) mechanism, where each transformer decoder layer selects essential vision tokens to process while skipping redundant ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/p-mod-building-mixture-of-depths-mllms-via</guid>
    </item>
    <item>
      <title>Mask of truth: model sensitivity to unexpected regions of medical images</title>
      <link>https://paperswithcode.com/paper/mask-of-truth-model-sensitivity-to-unexpected</link>
      <description><![CDATA[We show that all models trained on the PadChest dataset, irrespective of the masking strategy, are able to obtain an Area Under the Curve (AUC) above random.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mask-of-truth-model-sensitivity-to-unexpected</guid>
    </item>
    <item>
      <title>Soft Tensor Product Representations for Fully Continuous, Compositional Visual Representations</title>
      <link>https://paperswithcode.com/paper/soft-tensor-product-representations-for-fully</link>
      <description><![CDATA[To fully align compositional representations with continuous vector spaces, we extend Smolensky's Tensor Product Representation (TPR) and propose a new type of inherently *continuous* compositional representation, *Soft TPR*, along with a theoretically-principled architecture, *Soft TPR Autoencoder*, designed specifically for learning Soft TPRs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/soft-tensor-product-representations-for-fully</guid>
    </item>
    <item>
      <title>Mask-Adapter: The Devil is in the Masks for Open-Vocabulary Segmentation</title>
      <link>https://paperswithcode.com/paper/mask-adapter-the-devil-is-in-the-masks-for</link>
      <description><![CDATA[Mask-Adapter integrates seamlessly into open-vocabulary segmentation methods based on mask pooling in a plug-and-play manner, delivering more accurate classification results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mask-adapter-the-devil-is-in-the-masks-for</guid>
    </item>
    <item>
      <title>Aligned Music Notation and Lyrics Transcription</title>
      <link>https://paperswithcode.com/paper/aligned-music-notation-and-lyrics</link>
      <description><![CDATA[This paper introduces and formalizes, for the first time, the Aligned Music Notation and Lyrics Transcription (AMNLT) challenge, which addresses the complete transcription of vocal scores by jointly considering music symbols, lyrics, and their synchronization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligned-music-notation-and-lyrics</guid>
    </item>
    <item>
      <title>Magnetic Resonance Imaging Feature-Based Subtyping and Model Ensemble for Enhanced Brain Tumor Segmentation</title>
      <link>https://paperswithcode.com/paper/magnetic-resonance-imaging-feature-based</link>
      <description><![CDATA[These results demonstrate the effectiveness of our approach in improving segmentation performance and generalizability for various brain tumor types.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magnetic-resonance-imaging-feature-based</guid>
    </item>
    <item>
      <title>LaserGuider: A Laser Based Physical Backdoor Attack against Deep Neural Networks</title>
      <link>https://paperswithcode.com/paper/laserguider-a-laser-based-physical-backdoor</link>
      <description><![CDATA[Based on the laser-based backdoor triggers, we present a physical backdoor attack, called LaserGuider, which possesses remote control ability and achieves high temporal stealthiness, flexibility, and mobility.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/laserguider-a-laser-based-physical-backdoor</guid>
    </item>
    <item>
      <title>HumanEdit: A High-Quality Human-Rewarded Dataset for Instruction-based Image Editing</title>
      <link>https://paperswithcode.com/paper/humanedit-a-high-quality-human-rewarded</link>
      <description><![CDATA[HumanEdit bridges this gap by employing human annotators to construct data pairs and administrators to provide feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/humanedit-a-high-quality-human-rewarded</guid>
    </item>
    <item>
      <title>Learning Speed-Adaptive Walking Agent Using Imitation Learning with Physics-Informed Simulation</title>
      <link>https://paperswithcode.com/paper/learning-speed-adaptive-walking-agent-using</link>
      <description><![CDATA[Virtual models of human gait, or digital twins, offer a promising solution for studying mobility without the need for labor-intensive data collection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-speed-adaptive-walking-agent-using</guid>
    </item>
    <item>
      <title>Retrieval-Augmented Machine Translation with Unstructured Knowledge</title>
      <link>https://paperswithcode.com/paper/retrieval-augmented-machine-translation-with</link>
      <description><![CDATA[In machine translation (MT), previous work typically retrieves in-context examples from paired MT corpora, or domain-specific knowledge from knowledge graphs, to enhance models' MT ability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retrieval-augmented-machine-translation-with</guid>
    </item>
    <item>
      <title>MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model</title>
      <link>https://paperswithcode.com/paper/mind-effective-incorrect-assignment-detection</link>
      <description><![CDATA[The rapid growth of academic publications has exacerbated the issue of author name ambiguity in online digital libraries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mind-effective-incorrect-assignment-detection</guid>
    </item>
    <item>
      <title>Training MLPs on Graphs without Supervision</title>
      <link>https://paperswithcode.com/paper/training-mlps-on-graphs-without-supervision</link>
      <description><![CDATA[We provide a comprehensive theoretical analysis, demonstrating the equivalence between SimMLP and GNNs based on mutual information and inductive bias, highlighting SimMLP's advanced structural learning capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-mlps-on-graphs-without-supervision</guid>
    </item>
    <item>
      <title>Deep Causal Inference for Point-referenced Spatial Data with Continuous Treatments</title>
      <link>https://paperswithcode.com/paper/deep-causal-inference-for-point-referenced</link>
      <description><![CDATA[Causal reasoning is often challenging with spatial data, particularly when handling high-dimensional inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-causal-inference-for-point-referenced</guid>
    </item>
    <item>
      <title>Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion</title>
      <link>https://paperswithcode.com/paper/florence-vl-enhancing-vision-language-models</link>
      <description><![CDATA[We present Florence-VL, a new family of multimodal large language models (MLLMs) with enriched visual representations produced by Florence-2, a generative vision foundation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/florence-vl-enhancing-vision-language-models</guid>
    </item>
    <item>
      <title>Multi-View Pose-Agnostic Change Localization with Zero Labels</title>
      <link>https://paperswithcode.com/paper/multi-view-pose-agnostic-change-localization</link>
      <description><![CDATA[Autonomous agents often require accurate methods for detecting and localizing changes in their environment, particularly when observations are captured from unconstrained and inconsistent viewpoints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-view-pose-agnostic-change-localization</guid>
    </item>
    <item>
      <title>Monet: Mixture of Monosemantic Experts for Transformers</title>
      <link>https://paperswithcode.com/paper/monet-mixture-of-monosemantic-experts-for</link>
      <description><![CDATA[Understanding the internal computations of large language models (LLMs) is crucial for aligning them with human values and preventing undesirable behaviors like toxic content generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monet-mixture-of-monosemantic-experts-for</guid>
    </item>
    <item>
      <title>Graph-Sequential Alignment and Uniformity: Toward Enhanced Recommendation Systems</title>
      <link>https://paperswithcode.com/paper/graph-sequential-alignment-and-uniformity</link>
      <description><![CDATA[Graph-based and sequential methods are two popular recommendation paradigms, each excelling in its domain but lacking the ability to leverage signals from the other.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-sequential-alignment-and-uniformity</guid>
    </item>
    <item>
      <title>DiffSign: AI-Assisted Generation of Customizable Sign Language Videos With Enhanced Realism</title>
      <link>https://paperswithcode.com/paper/diffsign-ai-assisted-generation-of</link>
      <description><![CDATA[Our goal is to make media content more accessible to the DHH community by generating sign language videos with synthetic signers that are realistic and expressive.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffsign-ai-assisted-generation-of</guid>
    </item>
    <item>
      <title>EmbodiedOcc: Embodied 3D Occupancy Prediction for Vision-based Online Scene Understanding</title>
      <link>https://paperswithcode.com/paper/embodiedocc-embodied-3d-occupancy-prediction</link>
      <description><![CDATA[3D occupancy prediction provides a comprehensive description of the surrounding scenes and has become an essential task for 3D perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embodiedocc-embodied-3d-occupancy-prediction</guid>
    </item>
    <item>
      <title>YOLO-CCA: A Context-Based Approach for Traffic Sign Detection</title>
      <link>https://paperswithcode.com/paper/yolo-cca-a-context-based-approach-for-traffic</link>
      <description><![CDATA[Due to the complexity of driving environments, traffic sign detection frequently encounters a range of challenges, including low resolution, limited feature information, and small object sizes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-cca-a-context-based-approach-for-traffic</guid>
    </item>
    <item>
      <title>Bench-CoE: a Framework for Collaboration of Experts from Benchmark</title>
      <link>https://paperswithcode.com/paper/bench-coe-a-framework-for-collaboration-of</link>
      <description><![CDATA[Large Language Models (LLMs) are key technologies driving intelligent systems to handle multiple tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bench-coe-a-framework-for-collaboration-of</guid>
    </item>
    <item>
      <title>Boundary-Guided Learning for Gene Expression Prediction in Spatial Transcriptomics</title>
      <link>https://paperswithcode.com/paper/boundary-guided-learning-for-gene-expression</link>
      <description><![CDATA[In the spot and in-context branches, boundary information, including edge and nuclei characteristics, is extracted using pretrained models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boundary-guided-learning-for-gene-expression</guid>
    </item>
    <item>
      <title>Socially-Informed Reconstruction for Pedestrian Trajectory Forecasting</title>
      <link>https://paperswithcode.com/paper/socially-informed-reconstruction-for</link>
      <description><![CDATA[Pedestrian trajectory prediction remains a challenge for autonomous systems, particularly due to the intricate dynamics of social interactions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/socially-informed-reconstruction-for</guid>
    </item>
  </channel>
</rss>
