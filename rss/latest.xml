<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 15 Dec 2024 09:15:28 +0000</lastBuildDate>
    <item>
      <title>Temporal Action Localization with Cross Layer Task Decoupling and Refinement</title>
      <link>https://paperswithcode.com/paper/temporal-action-localization-with-cross-layer</link>
      <description><![CDATA[Temporal action localization (TAL) involves dual tasks to classify and localize actions within untrimmed videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-action-localization-with-cross-layer</guid>
    </item>
    <item>
      <title>MaskTerial: A Foundation Model for Automated 2D Material Flake Detection</title>
      <link>https://paperswithcode.com/paper/maskterial-a-foundation-model-for-automated</link>
      <description><![CDATA[The detection and classification of exfoliated two-dimensional (2D) material flakes from optical microscope images can be automated using computer vision algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maskterial-a-foundation-model-for-automated</guid>
    </item>
    <item>
      <title>Motif Guided Graph Transformer with Combinatorial Skeleton Prototype Learning for Skeleton-Based Person Re-Identification</title>
      <link>https://paperswithcode.com/paper/motif-guided-graph-transformer-with</link>
      <description><![CDATA[This paper presents a generic Motif guided graph transformer with Combinatorial skeleton prototype learning (MoCos) that exploits structure-specific and gait-related body relations as well as combinatorial features of skeleton graphs to learn effective skeleton representations for person re-ID.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motif-guided-graph-transformer-with</guid>
    </item>
    <item>
      <title>Owl-1: Omni World Model for Consistent Long Video Generation</title>
      <link>https://paperswithcode.com/paper/owl-1-omni-world-model-for-consistent-long</link>
      <description><![CDATA[As videos are observations of the underlying evolving world, we propose to model the long-term developments in a latent space and use VGMs to film them into videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/owl-1-omni-world-model-for-consistent-long</guid>
    </item>
    <item>
      <title>Learned Compression for Compressed Learning</title>
      <link>https://paperswithcode.com/paper/learned-compression-for-compressed-learning</link>
      <description><![CDATA[Linear transform coding and end-to-end learned compression systems reduce bitrate, but do not uniformly reduce dimensionality; thus, they do not meaningfully increase efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learned-compression-for-compressed-learning</guid>
    </item>
    <item>
      <title>Neptune: The Long Orbit to Benchmarking Long Video Understanding</title>
      <link>https://paperswithcode.com/paper/neptune-the-long-orbit-to-benchmarking-long</link>
      <description><![CDATA[This paper describes a semi-automatic pipeline to generate challenging question-answer-decoy sets for understanding long videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neptune-the-long-orbit-to-benchmarking-long</guid>
    </item>
    <item>
      <title>Improvement in Sign Language Translation Using Text CTC Alignment</title>
      <link>https://paperswithcode.com/paper/improvement-in-sign-language-translation</link>
      <description><![CDATA[In this work, we propose a novel method combining joint CTC/Attention and transfer learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improvement-in-sign-language-translation</guid>
    </item>
    <item>
      <title>Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion</title>
      <link>https://paperswithcode.com/paper/filter-then-generate-large-language-models</link>
      <description><![CDATA[Fundamentally, applying LLMs on KGC introduces several critical challenges, including a vast set of entity candidates, hallucination issue of LLMs, and under-exploitation of the graph structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/filter-then-generate-large-language-models</guid>
    </item>
    <item>
      <title>Diffusion Predictive Control with Constraints</title>
      <link>https://paperswithcode.com/paper/diffusion-predictive-control-with-constraints</link>
      <description><![CDATA[Diffusion models have recently gained popularity for policy learning in robotics due to their ability to capture high-dimensional and multimodal distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-predictive-control-with-constraints</guid>
    </item>
    <item>
      <title>SMMF: Square-Matricized Momentum Factorization for Memory-Efficient Optimization</title>
      <link>https://paperswithcode.com/paper/smmf-square-matricized-momentum-factorization</link>
      <description><![CDATA[We propose SMMF (Square-Matricized Momentum Factorization), a memory-efficient optimizer that reduces the memory requirement of the widely used adaptive learning rate optimizers, such as Adam, by up to 96%.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smmf-square-matricized-momentum-factorization</guid>
    </item>
    <item>
      <title>Federated Foundation Models on Heterogeneous Time Series</title>
      <link>https://paperswithcode.com/paper/federated-foundation-models-on-heterogeneous</link>
      <description><![CDATA[Training a general-purpose time series foundation models with robust generalization capabilities across diverse applications from scratch is still an open challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/federated-foundation-models-on-heterogeneous</guid>
    </item>
    <item>
      <title>Loss function to optimise signal significance in particle physics</title>
      <link>https://paperswithcode.com/paper/loss-function-to-optimise-signal-significance</link>
      <description><![CDATA[We construct a surrogate loss to directly optimise the significance metric used in particle physics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/loss-function-to-optimise-signal-significance</guid>
    </item>
    <item>
      <title>USDRL: Unified Skeleton-Based Dense Representation Learning with Multi-Grained Feature Decorrelation</title>
      <link>https://paperswithcode.com/paper/usdrl-unified-skeleton-based-dense</link>
      <description><![CDATA[Additionally, we design a Dense Spatio-Temporal Encoder (DSTE) to capture fine-grained action representations effectively, thereby enhancing the performance of dense prediction tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/usdrl-unified-skeleton-based-dense</guid>
    </item>
    <item>
      <title>Lyra: An Efficient and Speech-Centric Framework for Omni-Cognition</title>
      <link>https://paperswithcode.com/paper/lyra-an-efficient-and-speech-centric</link>
      <description><![CDATA[As Multi-modal Large Language Models (MLLMs) evolve, expanding beyond single-domain capabilities is essential to meet the demands for more versatile and efficient AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lyra-an-efficient-and-speech-centric</guid>
    </item>
    <item>
      <title>Video Repurposing from User Generated Content: A Large-scale Dataset and Benchmark</title>
      <link>https://paperswithcode.com/paper/video-repurposing-from-user-generated-content</link>
      <description><![CDATA[The demand for producing short-form videos for sharing on social media platforms has experienced significant growth in recent times.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-repurposing-from-user-generated-content</guid>
    </item>
    <item>
      <title>UFO: Enhancing Diffusion-Based Video Generation with a Uniform Frame Organizer</title>
      <link>https://paperswithcode.com/paper/ufo-enhancing-diffusion-based-video</link>
      <description><![CDATA[Recently, diffusion-based video generation models have achieved significant success.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ufo-enhancing-diffusion-based-video</guid>
    </item>
    <item>
      <title>Video Seal: Open and Efficient Video Watermarking</title>
      <link>https://paperswithcode.com/paper/video-seal-open-and-efficient-video</link>
      <description><![CDATA[To reduce these gaps, this paper introduces Video Seal, a comprehensive framework for neural video watermarking and a competitive open-sourced model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-seal-open-and-efficient-video</guid>
    </item>
    <item>
      <title>Imitate, Explore, and Self-Improve: A Reproduction Report on Slow-thinking Reasoning Systems</title>
      <link>https://paperswithcode.com/paper/imitate-explore-and-self-improve-a</link>
      <description><![CDATA[We introduce an "imitate, explore, and self-improve" framework as our primary technical approach to train the reasoning model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imitate-explore-and-self-improve-a</guid>
    </item>
    <item>
      <title>Unifying AI Tutor Evaluation: An Evaluation Taxonomy for Pedagogical Ability Assessment of LLM-Powered AI Tutors</title>
      <link>https://paperswithcode.com/paper/unifying-ai-tutor-evaluation-an-evaluation</link>
      <description><![CDATA[In this paper, we investigate whether current state-of-the-art large language models (LLMs) are effective as AI tutors and whether they demonstrate pedagogical abilities necessary for good AI tutoring in educational dialogues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unifying-ai-tutor-evaluation-an-evaluation</guid>
    </item>
    <item>
      <title>Arbitrary-steps Image Super-resolution via Diffusion Inversion</title>
      <link>https://paperswithcode.com/paper/arbitrary-steps-image-super-resolution-via</link>
      <description><![CDATA[This study presents a new image super-resolution (SR) technique based on diffusion inversion, aiming at harnessing the rich image priors encapsulated in large pre-trained diffusion models to improve SR performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/arbitrary-steps-image-super-resolution-via</guid>
    </item>
    <item>
      <title>eCARLA-scenes: A synthetically generated dataset for event-based optical flow prediction</title>
      <link>https://paperswithcode.com/paper/ecarla-scenes-a-synthetically-generated</link>
      <description><![CDATA[We further present a synthetic event-based datasets and data generation pipelines for optical flow prediction tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ecarla-scenes-a-synthetically-generated</guid>
    </item>
    <item>
      <title>Multi-Scale Heterogeneous Text-Attributed Graph Datasets From Diverse Domains</title>
      <link>https://paperswithcode.com/paper/multi-scale-heterogeneous-text-attributed</link>
      <description><![CDATA[Heterogeneous Text-Attributed Graphs (HTAGs), where different types of entities are not only associated with texts but also connected by diverse relationships, have gained widespread popularity and application across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-heterogeneous-text-attributed</guid>
    </item>
    <item>
      <title>MOPI-HFRS: A Multi-objective Personalized Health-aware Food Recommendation System with LLM-enhanced Interpretation</title>
      <link>https://paperswithcode.com/paper/mopi-hfrs-a-multi-objective-personalized</link>
      <description><![CDATA[The prevalence of unhealthy eating habits has become an increasingly concerning issue in the United States.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mopi-hfrs-a-multi-objective-personalized</guid>
    </item>
    <item>
      <title>Finite-PINN: A Physics-Informed Neural Network Architecture for Solving Solid Mechanics Problems with General Geometries</title>
      <link>https://paperswithcode.com/paper/finite-pinn-a-physics-informed-neural-network</link>
      <description><![CDATA[Specifically: a) PINN models generate solutions over an infinite domain, which conflicts with the finite boundaries typical of most solid structures; and b) the solution space utilised by PINN is Euclidean, which is inadequate for addressing the complex geometries often present in solid structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finite-pinn-a-physics-informed-neural-network</guid>
    </item>
    <item>
      <title>MultiEYE: Dataset and Benchmark for OCT-Enhanced Retinal Disease Recognition from Fundus Images</title>
      <link>https://paperswithcode.com/paper/multieye-dataset-and-benchmark-for-oct</link>
      <description><![CDATA[Existing multi-modal learning methods on fundus and OCT images mostly require both modalities to be available and strictly paired for training and testing, which appears less practical in clinical scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multieye-dataset-and-benchmark-for-oct</guid>
    </item>
    <item>
      <title>Dynamic-VLM: Simple Dynamic Visual Token Compression for VideoLLM</title>
      <link>https://paperswithcode.com/paper/dynamic-vlm-simple-dynamic-visual-token</link>
      <description><![CDATA[The application of Large Vision-Language Models (LVLMs) for analyzing images and videos is an exciting and rapidly evolving field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-vlm-simple-dynamic-visual-token</guid>
    </item>
    <item>
      <title>Exploring Enhanced Contextual Information for Video-Level Object Tracking</title>
      <link>https://paperswithcode.com/paper/exploring-enhanced-contextual-information-for</link>
      <description><![CDATA[Contextual information at the video level has become increasingly crucial for visual object tracking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-enhanced-contextual-information-for</guid>
    </item>
    <item>
      <title>GoHD: Gaze-oriented and Highly Disentangled Portrait Animation with Rhythmic Poses and Realistic Expression</title>
      <link>https://paperswithcode.com/paper/gohd-gaze-oriented-and-highly-disentangled</link>
      <description><![CDATA[Audio-driven talking head generation necessitates seamless integration of audio and visual data amidst the challenges posed by diverse input portraits and intricate correlations between audio and facial motions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gohd-gaze-oriented-and-highly-disentangled</guid>
    </item>
    <item>
      <title>Olympus: A Universal Task Router for Computer Vision Tasks</title>
      <link>https://paperswithcode.com/paper/olympus-a-universal-task-router-for-computer</link>
      <description><![CDATA[We introduce Olympus, a new approach that transforms Multimodal Large Language Models (MLLMs) into a unified framework capable of handling a wide array of computer vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/olympus-a-universal-task-router-for-computer</guid>
    </item>
    <item>
      <title>Elevating Flow-Guided Video Inpainting with Reference Generation</title>
      <link>https://paperswithcode.com/paper/elevating-flow-guided-video-inpainting-with</link>
      <description><![CDATA[Powered by a strong generative model, our method not only significantly enhances frame-level quality for object removal but also synthesizes new content in the missing areas based on user-provided text prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elevating-flow-guided-video-inpainting-with</guid>
    </item>
    <item>
      <title>Make Satire Boring Again: Reducing Stylistic Bias of Satirical Corpus by Utilizing Generative LLMs</title>
      <link>https://paperswithcode.com/paper/make-satire-boring-again-reducing-stylistic</link>
      <description><![CDATA[Results show that the debiasing method enhances the robustness and generalizability of the models for satire and irony detection tasks in Turkish and English.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/make-satire-boring-again-reducing-stylistic</guid>
    </item>
    <item>
      <title>Advancing Attribution-Based Neural Network Explainability through Relative Absolute Magnitude Layer-Wise Relevance Propagation and Multi-Component Evaluation</title>
      <link>https://paperswithcode.com/paper/advancing-attribution-based-neural-network</link>
      <description><![CDATA[We utilize this new metric to evaluate the performance of various attribution-based methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-attribution-based-neural-network</guid>
    </item>
    <item>
      <title>Hidden Biases of End-to-End Driving Datasets</title>
      <link>https://paperswithcode.com/paper/hidden-biases-of-end-to-end-driving-datasets</link>
      <description><![CDATA[End-to-end driving systems have made rapid progress, but have so far not been applied to the challenging new CARLA Leaderboard 2. 0.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hidden-biases-of-end-to-end-driving-datasets</guid>
    </item>
    <item>
      <title>InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions</title>
      <link>https://paperswithcode.com/paper/internlm-xcomposer2-5-omnilive-a</link>
      <description><![CDATA[Recent advancements in multimodal large language models (MLLMs) have made significant strides in open-world understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internlm-xcomposer2-5-omnilive-a</guid>
    </item>
    <item>
      <title>MOS: Model Surgery for Pre-Trained Model-Based Class-Incremental Learning</title>
      <link>https://paperswithcode.com/paper/mos-model-surgery-for-pre-trained-model-based</link>
      <description><![CDATA[Class-Incremental Learning (CIL) requires models to continually acquire knowledge of new classes without forgetting old ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mos-model-surgery-for-pre-trained-model-based</guid>
    </item>
    <item>
      <title>Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine</title>
      <link>https://paperswithcode.com/paper/towards-a-multimodal-large-language-model</link>
      <description><![CDATA[In this paper, we introduce a novel end-to-end multimodal large language model for the biomedical domain, named MedPLIB, which possesses pixel-level understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-a-multimodal-large-language-model</guid>
    </item>
    <item>
      <title>Motor Imagery Classification for Asynchronous EEG-Based Brain-Computer Interfaces</title>
      <link>https://paperswithcode.com/paper/motor-imagery-classification-for-asynchronous</link>
      <description><![CDATA[Motor imagery (MI) based brain-computer interfaces (BCIs) enable the direct control of external devices through the imagined movements of various body parts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motor-imagery-classification-for-asynchronous</guid>
    </item>
    <item>
      <title>Reversing the Damage: A QP-Aware Transformer-Diffusion Approach for 8K Video Restoration under Codec Compression</title>
      <link>https://paperswithcode.com/paper/reversing-the-damage-a-qp-aware-transformer</link>
      <description><![CDATA[In this paper, we introduce DiQP; a novel Transformer-Diffusion model for restoring 8K video quality degraded by codec compression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reversing-the-damage-a-qp-aware-transformer</guid>
    </item>
    <item>
      <title>Representing Long Volumetric Video with Temporal Gaussian Hierarchy</title>
      <link>https://paperswithcode.com/paper/representing-long-volumetric-video-with</link>
      <description><![CDATA[In addition, the tree-like structure of the Gaussian hierarchy allows us to efficiently represent the scene at a particular moment with a subset of Gaussian primitives, leading to nearly constant GPU memory usage during the training or rendering regardless of the video length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representing-long-volumetric-video-with</guid>
    </item>
    <item>
      <title>Transfer Learning of RSSI to Improve Indoor Localisation Performance</title>
      <link>https://paperswithcode.com/paper/transfer-learning-of-rssi-to-improve-indoor</link>
      <description><![CDATA[With the growing demand for health monitoring systems, in-home localisation is essential for tracking patient conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transfer-learning-of-rssi-to-improve-indoor</guid>
    </item>
    <item>
      <title>Auto-Regressive Moving Diffusion Models for Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/auto-regressive-moving-diffusion-models-for</link>
      <description><![CDATA[This design aligns the diffusion model's sampling procedure with the forecasting objective, resulting in an unconditional, continuous sequential diffusion TSF model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/auto-regressive-moving-diffusion-models-for</guid>
    </item>
    <item>
      <title>Multimodal Music Generation with Explicit Bridges and Retrieval Augmentation</title>
      <link>https://paperswithcode.com/paper/multimodal-music-generation-with-explicit</link>
      <description><![CDATA[Multimodal music generation aims to produce music from diverse input modalities, including text, videos, and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-music-generation-with-explicit</guid>
    </item>
    <item>
      <title>Uplift modeling with continuous treatments: A predict-then-optimize approach</title>
      <link>https://paperswithcode.com/paper/uplift-modeling-with-continuous-treatments-a</link>
      <description><![CDATA[One common approach involves two steps: first, an inference step that estimates conditional average treatment effects (CATEs), and second, an optimization step that ranks entities based on their CATE values and assigns treatment to the top k within a given budget.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uplift-modeling-with-continuous-treatments-a</guid>
    </item>
    <item>
      <title>OFTSR: One-Step Flow for Image Super-Resolution with Tunable Fidelity-Realism Trade-offs</title>
      <link>https://paperswithcode.com/paper/oftsr-one-step-flow-for-image-super</link>
      <description><![CDATA[Specifically, we force the predictions from our one-step student model for same input to lie on the same sampling ODE trajectory of the teacher model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oftsr-one-step-flow-for-image-super</guid>
    </item>
    <item>
      <title>Mining Word Boundaries from Speech-Text Parallel Data for Cross-domain Chinese Word Segmentation</title>
      <link>https://paperswithcode.com/paper/mining-word-boundaries-from-speech-text</link>
      <description><![CDATA[Inspired by early research on exploring naturally annotated data for Chinese Word Segmentation (CWS), and also by recent research on integration of speech and text processing, this work for the first time proposes to explicitly mine word boundaries from speech-text parallel data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mining-word-boundaries-from-speech-text</guid>
    </item>
    <item>
      <title>Causal Graphical Models for Vision-Language Compositional Understanding</title>
      <link>https://paperswithcode.com/paper/causal-graphical-models-for-vision-language</link>
      <description><![CDATA[Recent work has empirically shown that Vision-Language Models (VLMs) struggle to fully understand the compositional properties of the human language, usually modeling an image caption as a "bag of words".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causal-graphical-models-for-vision-language</guid>
    </item>
    <item>
      <title>A Flexible Plug-and-Play Module for Generating Variable-Length</title>
      <link>https://paperswithcode.com/paper/a-flexible-plug-and-play-module-for</link>
      <description><![CDATA[The NHL framework introduces a novel mechanism to simultaneously generate hash codes of varying lengths in a nested manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-flexible-plug-and-play-module-for</guid>
    </item>
    <item>
      <title>RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios</title>
      <link>https://paperswithcode.com/paper/rulearena-a-benchmark-for-rule-guided</link>
      <description><![CDATA[This paper introduces RuleArena, a novel and challenging benchmark designed to evaluate the ability of large language models (LLMs) to follow complex, real-world rules in reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rulearena-a-benchmark-for-rule-guided</guid>
    </item>
    <item>
      <title>OLA-VLM: Elevating Visual Perception in Multimodal LLMs with Auxiliary Embedding Distillation</title>
      <link>https://paperswithcode.com/paper/ola-vlm-elevating-visual-perception-in</link>
      <description><![CDATA[The standard practice for developing contemporary MLLMs is to feed features from vision encoder(s) into the LLM and train with natural language supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ola-vlm-elevating-visual-perception-in</guid>
    </item>
    <item>
      <title>DrivingRecon: Large 4D Gaussian Reconstruction Model For Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/drivingrecon-large-4d-gaussian-reconstruction</link>
      <description><![CDATA[To this end, we introduce the Large 4D Gaussian Reconstruction Model (DrivingRecon), a generalizable driving scene reconstruction model, which directly predicts 4D Gaussian from surround view videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drivingrecon-large-4d-gaussian-reconstruction</guid>
    </item>
  </channel>
</rss>
