<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 11 Jun 2024 09:15:48 +0000</lastBuildDate>
    <item>
      <title>Is Value Functions Estimation with Classification Plug-and-play for Offline Reinforcement Learning?</title>
      <link>https://paperswithcode.com/paper/is-value-functions-estimation-with</link>
      <description><![CDATA[In deep Reinforcement Learning (RL), value functions are typically approximated using deep neural networks and trained via mean squared error regression objectives to fit the true value functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-value-functions-estimation-with</guid>
    </item>
    <item>
      <title>Unveiling the Safety of GPT-4o: An Empirical Study using Jailbreak Attacks</title>
      <link>https://paperswithcode.com/paper/unveiling-the-safety-of-gpt-4o-an-empirical</link>
      <description><![CDATA[The recent release of GPT-4o has garnered widespread attention due to its powerful general capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unveiling-the-safety-of-gpt-4o-an-empirical</guid>
    </item>
    <item>
      <title>Neural-g: A Deep Learning Framework for Mixing Density Estimation</title>
      <link>https://paperswithcode.com/paper/neural-g-a-deep-learning-framework-for-mixing</link>
      <description><![CDATA[Mixing (or prior) density estimation is an important problem in machine learning and statistics, especially in empirical Bayes $g$-modeling where accurately estimating the prior is necessary for making good posterior inferences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-g-a-deep-learning-framework-for-mixing</guid>
    </item>
    <item>
      <title>MATES: Model-Aware Data Selection for Efficient Pretraining with Data Influence Models</title>
      <link>https://paperswithcode.com/paper/mates-model-aware-data-selection-for</link>
      <description><![CDATA[In this paper, we introduce model-aware data selection with data influence models (MATES), where a data influence model continuously adapts to the evolving data preferences of the pretraining model and then selects the data most effective for the current pretraining progress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mates-model-aware-data-selection-for</guid>
    </item>
    <item>
      <title>Recurrent Context Compression: Efficiently Expanding the Context Window of LLM</title>
      <link>https://paperswithcode.com/paper/recurrent-context-compression-efficiently</link>
      <description><![CDATA[To extend the context length of Transformer-based large language models (LLMs) and improve comprehension capabilities, we often face limitations due to computational resources and bounded memory storage capacity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recurrent-context-compression-efficiently</guid>
    </item>
    <item>
      <title>Building Bridges: A Dataset for Evaluating Gender-Fair Machine Translation into German</title>
      <link>https://paperswithcode.com/paper/building-bridges-a-dataset-for-evaluating</link>
      <description><![CDATA[The translation of gender-neutral person-referring terms (e. g., the students) is often non-trivial.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/building-bridges-a-dataset-for-evaluating</guid>
    </item>
    <item>
      <title>Multicam-SLAM: Non-overlapping Multi-camera SLAM for Indirect Visual Localization and Navigation</title>
      <link>https://paperswithcode.com/paper/multicam-slam-non-overlapping-multi-camera</link>
      <description><![CDATA[The proposed Muticam-SLAM includes a unique multi-camera model, a multi-keyframes structure, and several parallel SLAM threads.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multicam-slam-non-overlapping-multi-camera</guid>
    </item>
    <item>
      <title>How Far Can Transformers Reason? The Locality Barrier and Inductive Scratchpad</title>
      <link>https://paperswithcode.com/paper/how-far-can-transformers-reason-the-locality</link>
      <description><![CDATA[Can Transformers predict new syllogisms by composing established ones?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-far-can-transformers-reason-the-locality</guid>
    </item>
    <item>
      <title>Diffusion-RPO: Aligning Diffusion Models through Relative Preference Optimization</title>
      <link>https://paperswithcode.com/paper/diffusion-rpo-aligning-diffusion-models</link>
      <description><![CDATA[Aligning large language models with human preferences has emerged as a critical focus in language modeling research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-rpo-aligning-diffusion-models</guid>
    </item>
    <item>
      <title>CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models</title>
      <link>https://paperswithcode.com/paper/cares-a-comprehensive-benchmark-of</link>
      <description><![CDATA[Artificial intelligence has significantly impacted medical applications, particularly with the advent of Medical Large Vision Language Models (Med-LVLMs), sparking optimism for the future of automated and personalized healthcare.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cares-a-comprehensive-benchmark-of</guid>
    </item>
    <item>
      <title>Generalizable Human Gaussians from Single-View Image</title>
      <link>https://paperswithcode.com/paper/generalizable-human-gaussians-from-single</link>
      <description><![CDATA[To this end, we propose single-view generalizable Human Gaussian model (HGM), a diffusion-guided framework for 3D human modeling from a single image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizable-human-gaussians-from-single</guid>
    </item>
    <item>
      <title>Synthesizing Efficient Data with Diffusion Models for Person Re-Identification Pre-Training</title>
      <link>https://paperswithcode.com/paper/synthesizing-efficient-data-with-diffusion</link>
      <description><![CDATA[In this paper, we present a novel paradigm Diffusion-ReID to efficiently augment and generate diverse images based on known identities without requiring any cost of data collection and annotation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synthesizing-efficient-data-with-diffusion</guid>
    </item>
    <item>
      <title>Generalizing to Unseen Domains in Diabetic Retinopathy with Disentangled Representations</title>
      <link>https://paperswithcode.com/paper/generalizing-to-unseen-domains-in-diabetic-1</link>
      <description><![CDATA[Subsequently, to improve the robustness of the decoupled representations, class and domain prototypes are employed to interpolate the disentangled representations while data-aware weights are designed to focus on rare classes and domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizing-to-unseen-domains-in-diabetic-1</guid>
    </item>
    <item>
      <title>Compute Better Spent: Replacing Dense Layers with Structured Matrices</title>
      <link>https://paperswithcode.com/paper/compute-better-spent-replacing-dense-layers</link>
      <description><![CDATA[We show that different structures often require drastically different initialization scales and learning rates, which are crucial to performance, especially as models scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compute-better-spent-replacing-dense-layers</guid>
    </item>
    <item>
      <title>UEMM-Air: A Synthetic Multi-modal Dataset for Unmanned Aerial Vehicle Object Detection</title>
      <link>https://paperswithcode.com/paper/uemm-air-a-synthetic-multi-modal-dataset-for</link>
      <description><![CDATA[To this end, we propose a synthetic multi-modal UAV-based object detection dataset, UEMM-Air.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uemm-air-a-synthetic-multi-modal-dataset-for</guid>
    </item>
    <item>
      <title>MaskLID: Code-Switching Language Identification through Iterative Masking</title>
      <link>https://paperswithcode.com/paper/masklid-code-switching-language</link>
      <description><![CDATA[This method uses the LID itself to identify the features that require masking and does not rely on any external resource.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masklid-code-switching-language</guid>
    </item>
    <item>
      <title>Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain</title>
      <link>https://paperswithcode.com/paper/language-models-are-alignable-decision-makers</link>
      <description><![CDATA[Such decisions may be guided by different attributes that can be used to characterize an individual's decision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-are-alignable-decision-makers</guid>
    </item>
    <item>
      <title>Diving into Underwater: Segment Anything Model Guided Underwater Salient Instance Segmentation and A Large-scale Dataset</title>
      <link>https://paperswithcode.com/paper/diving-into-underwater-segment-anything-model</link>
      <description><![CDATA[Underwater salient instance segmentation is a foundational and vital step for various underwater vision tasks, which often suffer from low segmentation accuracy due to the complex underwater circumstances and the adaptive ability of models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diving-into-underwater-segment-anything-model</guid>
    </item>
    <item>
      <title>MOSA: Music Motion with Semantic Annotation Dataset for Cross-Modal Music Processing</title>
      <link>https://paperswithcode.com/paper/mosa-music-motion-with-semantic-annotation</link>
      <description><![CDATA[In cross-modal music processing, translation between visual, auditory, and semantic content opens up new possibilities as well as challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mosa-music-motion-with-semantic-annotation</guid>
    </item>
    <item>
      <title>EpiLearn: A Python Library for Machine Learning in Epidemic Modeling</title>
      <link>https://paperswithcode.com/paper/epilearn-a-python-library-for-machine</link>
      <description><![CDATA[EpiLearn is a Python toolkit developed for modeling, simulating, and analyzing epidemic data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/epilearn-a-python-library-for-machine</guid>
    </item>
    <item>
      <title>Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning</title>
      <link>https://paperswithcode.com/paper/husky-a-unified-open-source-language-agent</link>
      <description><![CDATA[Despite using 7B models, Husky matches or even exceeds frontier LMs such as GPT-4 on these tasks, showcasing the efficacy of our holistic approach in addressing complex reasoning problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/husky-a-unified-open-source-language-agent</guid>
    </item>
    <item>
      <title>LLM Dataset Inference: Did you train on my dataset?</title>
      <link>https://paperswithcode.com/paper/llm-dataset-inference-did-you-train-on-my</link>
      <description><![CDATA[Instead, we propose a new dataset inference method to accurately identify the datasets used to train large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-dataset-inference-did-you-train-on-my</guid>
    </item>
    <item>
      <title>Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer</title>
      <link>https://paperswithcode.com/paper/monkey-see-monkey-do-harnessing-self</link>
      <description><![CDATA[Given the remarkable results of motion synthesis with diffusion models, a natural question arises: how can we effectively leverage these models for motion editing?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monkey-see-monkey-do-harnessing-self</guid>
    </item>
    <item>
      <title>UMBRELA: UMbrela is the (Open-Source Reproduction of the) Bing RELevance Assessor</title>
      <link>https://paperswithcode.com/paper/umbrela-umbrela-is-the-open-source</link>
      <description><![CDATA[Copious amounts of relevance judgments are necessary for the effective training and accurate evaluation of retrieval systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/umbrela-umbrela-is-the-open-source</guid>
    </item>
    <item>
      <title>ThaiCoref: Thai Coreference Resolution Dataset</title>
      <link>https://paperswithcode.com/paper/thaicoref-thai-coreference-resolution-dataset</link>
      <description><![CDATA[In this work, we introduce ThaiCoref, a dataset for Thai coreference resolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/thaicoref-thai-coreference-resolution-dataset</guid>
    </item>
    <item>
      <title>LINGOLY: A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low-Resource and Extinct Languages</title>
      <link>https://paperswithcode.com/paper/lingoly-a-benchmark-of-olympiad-level</link>
      <description><![CDATA[In this paper, we present the LingOly benchmark, a novel benchmark for advanced reasoning abilities in large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lingoly-a-benchmark-of-olympiad-level</guid>
    </item>
    <item>
      <title>FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Model</title>
      <link>https://paperswithcode.com/paper/fleur-an-explainable-reference-free</link>
      <description><![CDATA[By leveraging a large multimodal model, FLEUR can evaluate the caption against the image without the need for reference captions, and provide the explanation for the assigned score.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fleur-an-explainable-reference-free</guid>
    </item>
    <item>
      <title>GraphStorm: all-in-one graph machine learning framework for industry applications</title>
      <link>https://paperswithcode.com/paper/graphstorm-all-in-one-graph-machine-learning</link>
      <description><![CDATA[GraphStorm has the following desirable properties: (a) Easy to use: it can perform graph construction and model training and inference with just a single command; (b) Expert-friendly: GraphStorm contains many advanced GML modeling techniques to handle complex graph data and improve model performance; (c) Scalable: every component in GraphStorm can operate on graphs with billions of nodes and can scale model training and inference to different hardware without changing any code.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphstorm-all-in-one-graph-machine-learning</guid>
    </item>
    <item>
      <title>Vript: A Video Is Worth Thousands of Words</title>
      <link>https://paperswithcode.com/paper/vript-a-video-is-worth-thousands-of-words</link>
      <description><![CDATA[Vriptor is also a powerful model capable of end-to-end generation of dense and detailed captions for long videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vript-a-video-is-worth-thousands-of-words</guid>
    </item>
    <item>
      <title>fSEAD: a Composable FPGA-based Streaming Ensemble Anomaly Detection Library</title>
      <link>https://paperswithcode.com/paper/fsead-a-composable-fpga-based-streaming</link>
      <description><![CDATA[Machine learning ensembles combine multiple base models to produce a more accurate output.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fsead-a-composable-fpga-based-streaming</guid>
    </item>
    <item>
      <title>Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text</title>
      <link>https://paperswithcode.com/paper/synth-sbdh-a-synthetic-dataset-of-social-and</link>
      <description><![CDATA[Social and behavioral determinants of health (SBDH) play a crucial role in health outcomes and are frequently documented in clinical text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synth-sbdh-a-synthetic-dataset-of-social-and</guid>
    </item>
    <item>
      <title>A Dual-View Approach to Classifying Radiology Reports by Co-Training</title>
      <link>https://paperswithcode.com/paper/a-dual-view-approach-to-classifying-radiology</link>
      <description><![CDATA[Radiology report analysis provides valuable information that can aid with public health initiatives, and has been attracting increasing attention from the research community.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-dual-view-approach-to-classifying-radiology</guid>
    </item>
    <item>
      <title>Safety Alignment Should Be Made More Than Just a Few Tokens Deep</title>
      <link>https://paperswithcode.com/paper/safety-alignment-should-be-made-more-than</link>
      <description><![CDATA[We refer to this issue as shallow safety alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safety-alignment-should-be-made-more-than</guid>
    </item>
    <item>
      <title>How Useful is Intermittent, Asynchronous Expert Feedback for Bayesian Optimization?</title>
      <link>https://paperswithcode.com/paper/how-useful-is-intermittent-asynchronous</link>
      <description><![CDATA[The gathered feedback is used to learn a Bayesian preference model that can readily be incorporated into the BO thread, to steer its exploration-exploitation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-useful-is-intermittent-asynchronous</guid>
    </item>
    <item>
      <title>Towards Real-World Efficiency: Domain Randomization in Reinforcement Learning for Pre-Capture of Free-Floating Moving Targets by Autonomous Robots</title>
      <link>https://paperswithcode.com/paper/towards-real-world-efficiency-domain</link>
      <description><![CDATA[In this research, we introduce a deep reinforcement learning-based control approach to address the intricate challenge of the robotic pre-grasping phase under microgravity conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-real-world-efficiency-domain</guid>
    </item>
    <item>
      <title>Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation</title>
      <link>https://paperswithcode.com/paper/autoregressive-model-beats-diffusion-llama</link>
      <description><![CDATA[(3) A text-conditional image generation model with 775M parameters, from two-stage training on LAION-COCO and high aesthetics quality images, demonstrating competitive performance of visual quality and text alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoregressive-model-beats-diffusion-llama</guid>
    </item>
    <item>
      <title>SRC-Net: Bi-Temporal Spatial Relationship Concerned Network for Change Detection</title>
      <link>https://paperswithcode.com/paper/src-net-bi-temporal-spatial-relationship</link>
      <description><![CDATA[The bi-temporal spatial relationships between features at the same location at different times play a key role in this process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/src-net-bi-temporal-spatial-relationship</guid>
    </item>
    <item>
      <title>Separating the "Chirp" from the "Chat": Self-supervised Visual Grounding of Sound and Language</title>
      <link>https://paperswithcode.com/paper/separating-the-chirp-from-the-chat-self</link>
      <description><![CDATA[We show that DenseAV can discover the ``meaning'' of words and the ``location'' of sounds without explicit localization supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/separating-the-chirp-from-the-chat-self</guid>
    </item>
    <item>
      <title>Anomaly Multi-classification in Industrial Scenarios: Transferring Few-shot Learning to a New Task</title>
      <link>https://paperswithcode.com/paper/anomaly-multi-classification-in-industrial</link>
      <description><![CDATA[In industrial scenarios, it is crucial not only to identify anomalous items but also to classify the type of anomaly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anomaly-multi-classification-in-industrial</guid>
    </item>
    <item>
      <title>Whose Preferences? Differences in Fairness Preferences and Their Impact on the Fairness of AI Utilizing Human Feedback</title>
      <link>https://paperswithcode.com/paper/whose-preferences-differences-in-fairness</link>
      <description><![CDATA[There is a growing body of work on learning from human feedback to align various aspects of machine learning systems with human values and preferences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/whose-preferences-differences-in-fairness</guid>
    </item>
    <item>
      <title>Mamba YOLO: SSMs-Based YOLO For Object Detection</title>
      <link>https://paperswithcode.com/paper/mamba-yolo-ssms-based-yolo-for-object</link>
      <description><![CDATA[To further enhance detection performance, Transformer-based structures have been introduced, significantly expanding the model's receptive field and achieving notable performance gains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mamba-yolo-ssms-based-yolo-for-object</guid>
    </item>
    <item>
      <title>HDMba: Hyperspectral Remote Sensing Imagery Dehazing with State Space Model</title>
      <link>https://paperswithcode.com/paper/hdmba-hyperspectral-remote-sensing-imagery</link>
      <description><![CDATA[Haze in HSI exhibits spatial irregularity and inhomogeneous spectral distribution, with few dehazing networks available.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hdmba-hyperspectral-remote-sensing-imagery</guid>
    </item>
    <item>
      <title>Scaling Graph Convolutions for Mobile Vision</title>
      <link>https://paperswithcode.com/paper/scaling-graph-convolutions-for-mobile-vision</link>
      <description><![CDATA[To compete with existing mobile architectures, MobileViG introduces Sparse Vision Graph Attention (SVGA), a fast token-mixing operator based on the principles of GNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-graph-convolutions-for-mobile-vision</guid>
    </item>
    <item>
      <title>EmbSpatial-Bench: Benchmarking Spatial Understanding for Embodied Tasks with Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/embspatial-bench-benchmarking-spatial</link>
      <description><![CDATA[The recent rapid development of Large Vision-Language Models (LVLMs) has indicated their potential for embodied tasks. However, the critical skill of spatial understanding in embodied environments has not been thoroughly evaluated, leaving the gap between current LVLMs and qualified embodied intelligence unknown.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embspatial-bench-benchmarking-spatial</guid>
    </item>
    <item>
      <title>Self-Distilled Disentangled Learning for Counterfactual Prediction</title>
      <link>https://paperswithcode.com/paper/self-distilled-disentangled-learning-for</link>
      <description><![CDATA[The advancements in disentangled representation learning significantly enhance the accuracy of counterfactual predictions by granting precise control over instrumental variables, confounders, and adjustable variables.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-distilled-disentangled-learning-for</guid>
    </item>
    <item>
      <title>MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation</title>
      <link>https://paperswithcode.com/paper/mops-modular-story-premise-synthesis-for-open</link>
      <description><![CDATA[In supplementary materials, we provide the MoPS code suite, along with 7. 6k generated premises and 1k extended stories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mops-modular-story-premise-synthesis-for-open</guid>
    </item>
    <item>
      <title>QGEval: A Benchmark for Question Generation Evaluation</title>
      <link>https://paperswithcode.com/paper/qgeval-a-benchmark-for-question-generation</link>
      <description><![CDATA[However, there is a lack of unified evaluation criteria, which hampers the development of both QG technologies and automatic evaluation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qgeval-a-benchmark-for-question-generation</guid>
    </item>
    <item>
      <title>A DeNoising FPN With Transformer R-CNN for Tiny Object Detection</title>
      <link>https://paperswithcode.com/paper/a-denoising-fpn-with-transformer-r-cnn-for</link>
      <description><![CDATA[Second, based on the two-stage framework, we replace the obsolete R-CNN detector with a novel Trans R-CNN detector to focus on the representation of tiny objects with self-attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-denoising-fpn-with-transformer-r-cnn-for</guid>
    </item>
    <item>
      <title>TTM-RE: Memory-Augmented Document-Level Relation Extraction</title>
      <link>https://paperswithcode.com/paper/ttm-re-memory-augmented-document-level</link>
      <description><![CDATA[Document-level relation extraction aims to categorize the association between any two entities within a document.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ttm-re-memory-augmented-document-level</guid>
    </item>
    <item>
      <title>SinkLoRA: Enhanced Efficiency and Chat Capabilities for Long-Context Large Language Models</title>
      <link>https://paperswithcode.com/paper/sinklora-enhanced-efficiency-and-chat</link>
      <description><![CDATA[However, LongLoRA is still not as efficient as vanilla attention, reaching only 39\% of the perplexity improvement compared to full attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sinklora-enhanced-efficiency-and-chat</guid>
    </item>
  </channel>
</rss>
