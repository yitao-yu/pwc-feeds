<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 23 Aug 2023 21:06:22 +0000</lastBuildDate>
    <item>
      <title>High Dynamic Range Imaging of Dynamic Scenes with Saturation Compensation but without Explicit Motion Compensation</title>
      <link>https://paperswithcode.com/paper/high-dynamic-range-imaging-of-dynamic-scenes</link>
      <description><![CDATA[For HDR imaging, some methods capture multiple low dynamic range (LDR) images with altering exposures to aggregate more information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-dynamic-range-imaging-of-dynamic-scenes</guid>
    </item>
    <item>
      <title>Recursive Video Lane Detection</title>
      <link>https://paperswithcode.com/paper/recursive-video-lane-detection</link>
      <description><![CDATA[A novel algorithm to detect road lanes in videos, called recursive video lane detector (RVLD), is proposed in this paper, which propagates the state of a current frame recursively to the next frame.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recursive-video-lane-detection</guid>
    </item>
    <item>
      <title>Domain Generalization via Rationale Invariance</title>
      <link>https://paperswithcode.com/paper/domain-generalization-via-rationale</link>
      <description><![CDATA[Specifically, we propose treating the element-wise contributions to the final results as the rationale for making a decision and representing the rationale for each sample as a matrix.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-generalization-via-rationale</guid>
    </item>
    <item>
      <title>An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification</title>
      <link>https://paperswithcode.com/paper/an-effective-transformer-based-contextual</link>
      <description><![CDATA[The proposed method has achieved an accuracy of 85. 9% with 28. 5M parameters, demonstrating comparable precision to wav2vec2 with 317. 7M parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-effective-transformer-based-contextual</guid>
    </item>
    <item>
      <title>CAME: Contrastive Automated Model Evaluation</title>
      <link>https://paperswithcode.com/paper/came-contrastive-automated-model-evaluation</link>
      <description><![CDATA[In this work, we propose Contrastive Automatic Model Evaluation (CAME), a novel AutoEval framework that is rid of involving training set in the loop.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/came-contrastive-automated-model-evaluation</guid>
    </item>
    <item>
      <title>SwinFace: A Multi-task Transformer for Face Recognition, Expression Recognition, Age Estimation and Attribute Estimation</title>
      <link>https://paperswithcode.com/paper/swinface-a-multi-task-transformer-for-face</link>
      <description><![CDATA[To address the conflicts among multiple tasks and meet the different demands of tasks, a Multi-Level Channel Attention (MLCA) module is integrated into each task-specific analysis subnet, which can adaptively select the features from optimal levels and channels to perform the desired tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/swinface-a-multi-task-transformer-for-face</guid>
    </item>
    <item>
      <title>Using ChatGPT as a CAT tool in Easy Language translation</title>
      <link>https://paperswithcode.com/paper/using-chatgpt-as-a-cat-tool-in-easy-language</link>
      <description><![CDATA[This study sets out to investigate the feasibility of using ChatGPT to translate citizen-oriented administrative texts into German Easy Language, a simplified, controlled language variety that is adapted to the needs of people with reading impairments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/using-chatgpt-as-a-cat-tool-in-easy-language</guid>
    </item>
    <item>
      <title>Pose2Gait: Extracting Gait Features from Monocular Video of Individuals with Dementia</title>
      <link>https://paperswithcode.com/paper/pose2gait-extracting-gait-features-from</link>
      <description><![CDATA[In this work we train a deep neural network to map from a two dimensional pose sequence, extracted from a video of an individual walking down a hallway toward a wall-mounted camera, to a set of three-dimensional spatiotemporal gait features averaged over the walking sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pose2gait-extracting-gait-features-from</guid>
    </item>
    <item>
      <title>How Much Temporal Long-Term Context is Needed for Action Segmentation?</title>
      <link>https://paperswithcode.com/paper/how-much-temporal-long-term-context-is-needed</link>
      <description><![CDATA[In this work, we try to answer how much long-term temporal context is required for temporal action segmentation by introducing a transformer-based model that leverages sparse attention to capture the full context of a video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-much-temporal-long-term-context-is-needed</guid>
    </item>
    <item>
      <title>ViLLA: Fine-Grained Vision-Language Representation Learning from Real-World Data</title>
      <link>https://paperswithcode.com/paper/villa-fine-grained-vision-language</link>
      <description><![CDATA[The first key contribution of this work is to demonstrate through systematic evaluations that as the pairwise complexity of the training dataset increases, standard VLMs struggle to learn region-attribute relationships, exhibiting performance degradations of up to 37% on retrieval tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/villa-fine-grained-vision-language</guid>
    </item>
    <item>
      <title>Exploring Unsupervised Cell Recognition with Prior Self-activation Maps</title>
      <link>https://paperswithcode.com/paper/exploring-unsupervised-cell-recognition-with</link>
      <description><![CDATA[The gradient information in the shallow layers of the network is aggregated to generate prior self-activation maps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-unsupervised-cell-recognition-with</guid>
    </item>
    <item>
      <title>Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models</title>
      <link>https://paperswithcode.com/paper/anonymity-at-risk-assessing-re-identification</link>
      <description><![CDATA[Anonymity of both natural and legal persons in court rulings is a critical aspect of privacy protection in the European Union and Switzerland.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anonymity-at-risk-assessing-re-identification</guid>
    </item>
    <item>
      <title>Explicability and Inexplicability in the Interpretation of Quantum Neural Networks</title>
      <link>https://paperswithcode.com/paper/explicability-and-inexplicability-in-the</link>
      <description><![CDATA[Interpretability of artificial intelligence (AI) methods, particularly deep neural networks, is of great interest due to the widespread use of AI-backed systems, which often have unexplainable behavior.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explicability-and-inexplicability-in-the</guid>
    </item>
    <item>
      <title>Are current long-term video understanding datasets long-term?</title>
      <link>https://paperswithcode.com/paper/are-current-long-term-video-understanding</link>
      <description><![CDATA[In the current deep learning paradigm for automatic action recognition, it is imperative that models are trained and tested on datasets and tasks that evaluate if such models actually learn and reason over long-term information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/are-current-long-term-video-understanding</guid>
    </item>
    <item>
      <title>LAN-HDR: Luminance-based Alignment Network for High Dynamic Range Video Reconstruction</title>
      <link>https://paperswithcode.com/paper/lan-hdr-luminance-based-alignment-network-for</link>
      <description><![CDATA[In this paper, we propose an end-to-end HDR video composition framework, which aligns LDR frames in the feature space and then merges aligned features into an HDR frame, without relying on pixel-domain optical flow.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lan-hdr-luminance-based-alignment-network-for</guid>
    </item>
    <item>
      <title>A Survey on Self-Supervised Representation Learning</title>
      <link>https://paperswithcode.com/paper/a-survey-on-self-supervised-representation</link>
      <description><![CDATA[Learning meaningful representations is at the heart of many tasks in the field of modern machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-self-supervised-representation</guid>
    </item>
    <item>
      <title>Tensor Regression</title>
      <link>https://paperswithcode.com/paper/tensor-regression</link>
      <description><![CDATA[Tensors, as high dimensional extensions of vectors, are considered as natural representations of high dimensional data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tensor-regression</guid>
    </item>
    <item>
      <title>LEAP: Efficient and Automated Test Method for NLP Software</title>
      <link>https://paperswithcode.com/paper/leap-efficient-and-automated-test-method-for</link>
      <description><![CDATA[The widespread adoption of DNNs in NLP software has highlighted the need for robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leap-efficient-and-automated-test-method-for</guid>
    </item>
    <item>
      <title>BELB: a Biomedical Entity Linking Benchmark</title>
      <link>https://paperswithcode.com/paper/belb-a-biomedical-entity-linking-benchmark</link>
      <description><![CDATA[Biomedical entity linking (BEL) is the task of grounding entity mentions to a knowledge base.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/belb-a-biomedical-entity-linking-benchmark</guid>
    </item>
    <item>
      <title>How Expressive are Graph Neural Networks in Recommendation?</title>
      <link>https://paperswithcode.com/paper/how-expressive-are-graph-neural-networks-in</link>
      <description><![CDATA[Most existing works adopt the graph isomorphism test as the metric of expressiveness, but this graph-level task may not effectively assess a model's ability in recommendation, where the objective is to distinguish nodes of different closeness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-expressive-are-graph-neural-networks-in</guid>
    </item>
    <item>
      <title>Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis</title>
      <link>https://paperswithcode.com/paper/evaluating-large-language-models-on-graphs</link>
      <description><![CDATA[Yet, the application of LLMs to graph data remains under-explored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-large-language-models-on-graphs</guid>
    </item>
    <item>
      <title>Composed Image Retrieval using Contrastive Learning and Task-oriented CLIP-based Features</title>
      <link>https://paperswithcode.com/paper/composed-image-retrieval-using-contrastive</link>
      <description><![CDATA[Given a query composed of a reference image and a relative caption, the Composed Image Retrieval goal is to retrieve images visually similar to the reference one that integrates the modifications expressed by the caption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/composed-image-retrieval-using-contrastive</guid>
    </item>
    <item>
      <title>G3Reg: Pyramid Graph-based Global Registration using Gaussian Ellipsoid Model</title>
      <link>https://paperswithcode.com/paper/g3reg-pyramid-graph-based-global-registration</link>
      <description><![CDATA[Utilizing these GEMs, we then present a distrust-and-verify scheme based on a Pyramid Compatibility Graph for Global Registration (PAGOR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/g3reg-pyramid-graph-based-global-registration</guid>
    </item>
    <item>
      <title>Test Time Embedding Normalization for Popularity Bias Mitigation</title>
      <link>https://paperswithcode.com/paper/test-time-embedding-normalization-for</link>
      <description><![CDATA[Popularity bias is a widespread problem in the field of recommender systems, where popular items tend to dominate recommendation results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/test-time-embedding-normalization-for</guid>
    </item>
    <item>
      <title>Dynamic Open Vocabulary Enhanced Safe-landing with Intelligence (DOVESEI)</title>
      <link>https://paperswithcode.com/paper/dynamic-open-vocabulary-enhanced-safe-landing</link>
      <description><![CDATA[This work targets what we consider to be the foundational step for urban airborne robots, a safe landing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-open-vocabulary-enhanced-safe-landing</guid>
    </item>
    <item>
      <title>DALNet: A Rail Detection Network Based on Dynamic Anchor Line</title>
      <link>https://paperswithcode.com/paper/dalnet-a-rail-detection-network-based-on</link>
      <description><![CDATA[In the paper, motivated by the anchor line-based lane detection methods, we propose a rail detection network called DALNet based on dynamic anchor line.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dalnet-a-rail-detection-network-based-on</guid>
    </item>
    <item>
      <title>TOPIC: A Parallel Association Paradigm for Multi-Object Tracking under Complex Motions and Diverse Scenes</title>
      <link>https://paperswithcode.com/paper/topic-a-parallel-association-paradigm-for</link>
      <description><![CDATA[Existing trackers can be categorized into two association paradigms: single-feature paradigm (based on either motion or appearance feature) and serial paradigm (one feature serves as secondary while the other is primary).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/topic-a-parallel-association-paradigm-for</guid>
    </item>
    <item>
      <title>IT3D: Improved Text-to-3D Generation with Explicit View Synthesis</title>
      <link>https://paperswithcode.com/paper/it3d-improved-text-to-3d-generation-with</link>
      <description><![CDATA[Recent strides in Text-to-3D techniques have been propelled by distilling knowledge from powerful large text-to-image diffusion models (LDMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/it3d-improved-text-to-3d-generation-with</guid>
    </item>
    <item>
      <title>Machine learning assisted exploration for affine Deligne-Lusztig varieties</title>
      <link>https://paperswithcode.com/paper/machine-learning-assisted-exploration-for</link>
      <description><![CDATA[We demonstrate that this framework has a potential to accelerate pure mathematical research, leading to the discovery of new conjectures and promising research directions that could otherwise take significant time to uncover.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/machine-learning-assisted-exploration-for</guid>
    </item>
    <item>
      <title>StoryBench: A Multifaceted Benchmark for Continuous Story Visualization</title>
      <link>https://paperswithcode.com/paper/storybench-a-multifaceted-benchmark-for</link>
      <description><![CDATA[To fill this gap, we collect comprehensive human annotations on three existing datasets, and introduce StoryBench: a new, challenging multi-task benchmark to reliably evaluate forthcoming text-to-video models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/storybench-a-multifaceted-benchmark-for</guid>
    </item>
    <item>
      <title>Multi-event Video-Text Retrieval</title>
      <link>https://paperswithcode.com/paper/multi-event-video-text-retrieval</link>
      <description><![CDATA[In this study, we introduce the Multi-event Video-Text Retrieval (MeVTR) task, addressing scenarios in which each video contains multiple different events, as a niche scenario of the conventional Video-Text Retrieval Task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-event-video-text-retrieval</guid>
    </item>
    <item>
      <title>Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection</title>
      <link>https://paperswithcode.com/paper/learning-a-more-continuous-zero-level-set-in</link>
      <description><![CDATA[We pull the non-zero level sets onto the zero level set with gradient constraints which align gradients over different level sets and correct unsigned distance errors on the zero level set, leading to a smoother and more continuous unsigned distance field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-a-more-continuous-zero-level-set-in</guid>
    </item>
    <item>
      <title>Video BagNet: short temporal receptive fields increase robustness in long-term action recognition</title>
      <link>https://paperswithcode.com/paper/video-bagnet-short-temporal-receptive-fields</link>
      <description><![CDATA[Previous work on long-term video action recognition relies on deep 3D-convolutional models that have a large temporal receptive field (RF).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-bagnet-short-temporal-receptive-fields</guid>
    </item>
    <item>
      <title>xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium</title>
      <link>https://paperswithcode.com/paper/xxmd-benchmarking-neural-force-fields-using</link>
      <description><![CDATA[Neural force fields (NFFs) have gained prominence in computational chemistry as surrogate models, superseding quantum-chemistry calculations in ab initio molecular dynamics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xxmd-benchmarking-neural-force-fields-using</guid>
    </item>
    <item>
      <title>Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment</title>
      <link>https://paperswithcode.com/paper/federated-learning-on-patient-data-for</link>
      <description><![CDATA[The field of women's endocrinology has trailed behind data-driven medical solutions, largely due to concerns over the privacy of patient data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/federated-learning-on-patient-data-for</guid>
    </item>
    <item>
      <title>Object Detection Difficulty: Suppressing Over-aggregation for Faster and Better Video Object Detection</title>
      <link>https://paperswithcode.com/paper/object-detection-difficulty-suppressing-over</link>
      <description><![CDATA[The ODD score enhances the VOD system in two ways: 1) it enables the VOD system to select superior global reference frames, thereby improving overall accuracy; and 2) it serves as an indicator in the newly designed ODD Scheduler to eliminate the aggregation of frames that are easy to detect, thus accelerating the VOD process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/object-detection-difficulty-suppressing-over</guid>
    </item>
    <item>
      <title>Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition</title>
      <link>https://paperswithcode.com/paper/learning-from-semantic-alignment-between</link>
      <description><![CDATA[To facilitate the data efficiency of multiview learning, we further perform video-text alignment for first-person and third-person videos, to fully leverage the semantic knowledge to improve video representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-from-semantic-alignment-between</guid>
    </item>
    <item>
      <title>ROSGPT_Vision: Commanding Robots Using Only Language Models' Prompts</title>
      <link>https://paperswithcode.com/paper/rosgpt-vision-commanding-robots-using-only</link>
      <description><![CDATA[ROSGPT_Vision allows the execution of a robotic task using only two prompts: a Visual and an LLM prompt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rosgpt-vision-commanding-robots-using-only</guid>
    </item>
    <item>
      <title>Aspect-oriented Opinion Alignment Network for Aspect-Based Sentiment Classification</title>
      <link>https://paperswithcode.com/paper/aspect-oriented-opinion-alignment-network-for</link>
      <description><![CDATA[In addition, we design a multi-perspective attention mechanism that align relevant opinion information with respect to the given aspect.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aspect-oriented-opinion-alignment-network-for</guid>
    </item>
    <item>
      <title>Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection</title>
      <link>https://paperswithcode.com/paper/expecting-the-unexpected-towards-broad-out-of</link>
      <description><![CDATA[Our findings reveal that while these methods excel in detecting unknown classes, their performance is inconsistent when encountering other types of distribution shifts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/expecting-the-unexpected-towards-broad-out-of</guid>
    </item>
    <item>
      <title>SeamlessM4T-Massively Multilingual &amp; Multimodal Machine Translation</title>
      <link>https://paperswithcode.com/paper/seamlessm4t-massively-multilingual-multimodal</link>
      <description><![CDATA[To build this, we used 1 million hours of open speech audio data to learn self-supervised speech representations with w2v-BERT 2. 0.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seamlessm4t-massively-multilingual-multimodal</guid>
    </item>
    <item>
      <title>Sentence-Level Multimodal and Language-Agnostic Representations</title>
      <link>https://paperswithcode.com/paper/sentence-level-multimodal-and-language</link>
      <description><![CDATA[Our single text encoder, covering 200 languages, substantially outperforms existing sentence embeddings such as LASER3 and LabSE on the xsim and xsim++ multilingual similarity search tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sentence-level-multimodal-and-language</guid>
    </item>
    <item>
      <title>Spatial Transform Decoupling for Oriented Object Detection</title>
      <link>https://paperswithcode.com/paper/spatial-transform-decoupling-for-oriented</link>
      <description><![CDATA[Vision Transformers (ViTs) have achieved remarkable success in computer vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatial-transform-decoupling-for-oriented</guid>
    </item>
    <item>
      <title>CSM-H-R: An Automatic Context Reasoning Framework for Interoperable Intelligent Systems and Privacy Protection</title>
      <link>https://paperswithcode.com/paper/csm-h-r-an-automatic-context-reasoning</link>
      <description><![CDATA[Automation of High-Level Context (HLC) reasoning for intelligent systems at scale is imperative due to the unceasing accumulation of contextual data in the IoT era, the trend of the fusion of data from multi-sources, and the intrinsic complexity and dynamism of the context-based decision-making process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/csm-h-r-an-automatic-context-reasoning</guid>
    </item>
    <item>
      <title>Stabilizing Unsupervised Environment Design with a Learned Adversary</title>
      <link>https://paperswithcode.com/paper/stabilizing-unsupervised-environment-design</link>
      <description><![CDATA[As a result, we make it possible for PAIRED to match or exceed state-of-the-art methods, producing robust agents in several established challenging procedurally-generated environments, including a partially-observed maze navigation task and a continuous-control car racing environment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stabilizing-unsupervised-environment-design</guid>
    </item>
    <item>
      <title>Dataset Quantization</title>
      <link>https://paperswithcode.com/paper/dataset-quantization</link>
      <description><![CDATA[Extensive experiments demonstrate that DQ is able to generate condensed small datasets for training unseen network architectures with state-of-the-art compression ratios for lossless model training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dataset-quantization</guid>
    </item>
    <item>
      <title>UGSL: A Unified Framework for Benchmarking Graph Structure Learning</title>
      <link>https://paperswithcode.com/paper/ugsl-a-unified-framework-for-benchmarking</link>
      <description><![CDATA[We implement a wide range of existing models in our framework and conduct extensive analyses of the effectiveness of different components in the framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ugsl-a-unified-framework-for-benchmarking</guid>
    </item>
    <item>
      <title>X-VoE: Measuring eXplanatory Violation of Expectation in Physical Events</title>
      <link>https://paperswithcode.com/paper/x-voe-measuring-explanatory-violation-of</link>
      <description><![CDATA[Intuitive physics is pivotal for human understanding of the physical world, enabling prediction and interpretation of events even in infancy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-voe-measuring-explanatory-violation-of</guid>
    </item>
    <item>
      <title>Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting</title>
      <link>https://paperswithcode.com/paper/spatio-temporal-adaptive-embedding-makes</link>
      <description><![CDATA[With the rapid development of the Intelligent Transportation System (ITS), accurate traffic forecasting has emerged as a critical challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatio-temporal-adaptive-embedding-makes</guid>
    </item>
    <item>
      <title>Improving the Transferability of Adversarial Examples with Arbitrary Style Transfer</title>
      <link>https://paperswithcode.com/paper/improving-the-transferability-of-adversarial-7</link>
      <description><![CDATA[Deep neural networks are vulnerable to adversarial examples crafted by applying human-imperceptible perturbations on clean inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-the-transferability-of-adversarial-7</guid>
    </item>
  </channel>
</rss>
