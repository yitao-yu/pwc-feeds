<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 30 Jul 2024 21:09:38 +0000</lastBuildDate>
    <item>
      <title>Efficient Face Super-Resolution via Wavelet-based Feature Enhancement Network</title>
      <link>https://paperswithcode.com/paper/efficient-face-super-resolution-via-wavelet</link>
      <description><![CDATA[Previous methods typically employ an encoder-decoder structure to extract facial structural features, where the direct downsampling inevitably introduces distortions, especially to high-frequency features such as edges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-face-super-resolution-via-wavelet</guid>
    </item>
    <item>
      <title>Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/advancing-multimodal-large-language-models-in</link>
      <description><![CDATA[To fill the gap, we propose a visualization-referenced instruction tuning approach to guide the training dataset enhancement and model development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-multimodal-large-language-models-in</guid>
    </item>
    <item>
      <title>F-KANs: Federated Kolmogorov-Arnold Networks</title>
      <link>https://paperswithcode.com/paper/f-kans-federated-kolmogorov-arnold-networks</link>
      <description><![CDATA[In this paper, we present an innovative federated learning (FL) approach that utilizes Kolmogorov-Arnold Networks (KANs) for classification tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/f-kans-federated-kolmogorov-arnold-networks</guid>
    </item>
    <item>
      <title>Collision Probability Distribution Estimation via Temporal Difference Learning</title>
      <link>https://paperswithcode.com/paper/collision-probability-distribution-estimation</link>
      <description><![CDATA[We introduce CollisionPro, a pioneering framework designed to estimate cumulative collision probability distributions using temporal difference learning, specifically tailored to applications in robotics, with a particular emphasis on autonomous driving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/collision-probability-distribution-estimation</guid>
    </item>
    <item>
      <title>AxiomVision: Accuracy-Guaranteed Adaptive Visual Model Selection for Perspective-Aware Video Analytics</title>
      <link>https://paperswithcode.com/paper/axiomvision-accuracy-guaranteed-adaptive</link>
      <description><![CDATA[The rapid evolution of multimedia and computer vision technologies requires adaptive visual model deployment strategies to effectively handle diverse tasks and varying environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/axiomvision-accuracy-guaranteed-adaptive</guid>
    </item>
    <item>
      <title>Interpreting Low-level Vision Models with Causal Effect Maps</title>
      <link>https://paperswithcode.com/paper/interpreting-low-level-vision-models-with</link>
      <description><![CDATA[Based on the causal effect theory, the proposed diagnostic tool can refresh our common knowledge and bring a deeper understanding of low-level vision models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpreting-low-level-vision-models-with</guid>
    </item>
    <item>
      <title>ImagiNet: A Multi-Content Dataset for Generalizable Synthetic Image Detection via Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/imaginet-a-multi-content-dataset-for</link>
      <description><![CDATA[Generative models, such as diffusion models (DMs), variational autoencoders (VAEs), and generative adversarial networks (GANs), produce images with a level of authenticity that makes them nearly indistinguishable from real photos and artwork.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imaginet-a-multi-content-dataset-for</guid>
    </item>
    <item>
      <title>Garment Animation NeRF with Color Editing</title>
      <link>https://paperswithcode.com/paper/garment-animation-nerf-with-color-editing</link>
      <description><![CDATA[Our approach infers garment dynamic features from body motion, providing a preliminary overview of garment structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/garment-animation-nerf-with-color-editing</guid>
    </item>
    <item>
      <title>Yucca: A Deep Learning Framework For Medical Image Analysis</title>
      <link>https://paperswithcode.com/paper/yucca-a-deep-learning-framework-for-medical</link>
      <description><![CDATA[Medical image analysis using deep learning frameworks has advanced healthcare by automating complex tasks, but many existing frameworks lack flexibility, modularity, and user-friendliness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yucca-a-deep-learning-framework-for-medical</guid>
    </item>
    <item>
      <title>SalNAS: Efficient Saliency-prediction Neural Architecture Search with self-knowledge distillation</title>
      <link>https://paperswithcode.com/paper/salnas-efficient-saliency-prediction-neural</link>
      <description><![CDATA[Recent advancements in deep convolutional neural networks have significantly improved the performance of saliency prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/salnas-efficient-saliency-prediction-neural</guid>
    </item>
    <item>
      <title>Can I trust my anomaly detection system? A case study based on explainable AI</title>
      <link>https://paperswithcode.com/paper/can-i-trust-my-anomaly-detection-system-a</link>
      <description><![CDATA[Generative models based on variational autoencoders are a popular technique for detecting anomalies in images in a semi-supervised context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-i-trust-my-anomaly-detection-system-a</guid>
    </item>
    <item>
      <title>Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity</title>
      <link>https://paperswithcode.com/paper/urban-traffic-accident-risk-prediction</link>
      <description><![CDATA[In particular, it should adequately consider the regional background, accurately capture both spatial proximity and semantic similarity, and effectively address the sparsity of traffic accidents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/urban-traffic-accident-risk-prediction</guid>
    </item>
    <item>
      <title>RelBench: A Benchmark for Deep Learning on Relational Databases</title>
      <link>https://paperswithcode.com/paper/relbench-a-benchmark-for-deep-learning-on</link>
      <description><![CDATA[We use RelBench to conduct the first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024), which combines graph neural network predictive models with (deep) tabular models that extract initial entity-level representations from raw tables.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relbench-a-benchmark-for-deep-learning-on</guid>
    </item>
    <item>
      <title>GradCraft: Elevating Multi-task Recommendations through Holistic Gradient Crafting</title>
      <link>https://paperswithcode.com/paper/gradcraft-elevating-multi-task</link>
      <description><![CDATA[GradCraft ensures the concurrent achievement of appropriate magnitude balance and global direction balance, aligning with the inherent characteristics of recommendation scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gradcraft-elevating-multi-task</guid>
    </item>
    <item>
      <title>Reverse Map Projections as Equivariant Quantum Embeddings</title>
      <link>https://paperswithcode.com/paper/reverse-map-projections-as-equivariant</link>
      <description><![CDATA[We introduce the novel class $(E_\alpha)_{\alpha \in [-\infty, 1)}$ of reverse map projection embeddings, each one defining a unique new method of encoding classical data into quantum states.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reverse-map-projections-as-equivariant</guid>
    </item>
    <item>
      <title>Theia: Distilling Diverse Vision Foundation Models for Robot Learning</title>
      <link>https://paperswithcode.com/paper/theia-distilling-diverse-vision-foundation</link>
      <description><![CDATA[Vision-based robot policy learning, which maps visual inputs to actions, necessitates a holistic understanding of diverse visual tasks beyond single-task needs like classification or segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/theia-distilling-diverse-vision-foundation</guid>
    </item>
    <item>
      <title>Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation</title>
      <link>https://paperswithcode.com/paper/emotion-driven-melody-harmonization-via</link>
      <description><![CDATA[Previous research found it hard to alter the perceived emotional valence of lead sheets only by harmonizing the same melody with different chords, which may be attributed to the constraints imposed by the melody itself and the limitation of existing music representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emotion-driven-melody-harmonization-via</guid>
    </item>
    <item>
      <title>Leveraging Foundation Models for Zero-Shot IoT Sensing</title>
      <link>https://paperswithcode.com/paper/leveraging-foundation-models-for-zero-shot</link>
      <description><![CDATA[To address this, zero-shot learning (ZSL) aims to classify data of unseen classes with the help of semantic information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-foundation-models-for-zero-shot</guid>
    </item>
    <item>
      <title>rLLM: Relational Table Learning with LLMs</title>
      <link>https://paperswithcode.com/paper/rllm-relational-table-learning-with-llms</link>
      <description><![CDATA[To illustrate the usage of rLLM, we introduce a simple RTL method named \textbf{BRIDGE}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rllm-relational-table-learning-with-llms</guid>
    </item>
    <item>
      <title>Smart Language Agents in Real-World Planning</title>
      <link>https://paperswithcode.com/paper/smart-language-agents-in-real-world-planning</link>
      <description><![CDATA[Comprehensive planning agents have been a long term goal in the field of artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smart-language-agents-in-real-world-planning</guid>
    </item>
    <item>
      <title>Background Semantics Matter: Cross-Task Feature Exchange Network for Clustered Infrared Small Target Detection With Sky-Annotated Dataset</title>
      <link>https://paperswithcode.com/paper/background-semantics-matter-cross-task</link>
      <description><![CDATA[To address this, we introduce a new task -- clustered infrared small target detection, and present DenseSIRST, a novel benchmark dataset that provides per-pixel semantic annotations for background regions, enabling the transition from sparse to dense target detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/background-semantics-matter-cross-task</guid>
    </item>
    <item>
      <title>Image-text matching for large-scale book collections</title>
      <link>https://paperswithcode.com/paper/image-text-matching-for-large-scale-book</link>
      <description><![CDATA[We show that both the Hungarian Matching and the proposed BERT-based model outperform a fuzzy string matching baseline, and we highlight inherent limitations of the matching algorithms as the target increases in size, and when either of the two sets (detected books or target book list) is incomplete.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/image-text-matching-for-large-scale-book</guid>
    </item>
    <item>
      <title>RSC-SNN: Exploring the Trade-off Between Adversarial Robustness and Accuracy in Spiking Neural Networks via Randomized Smoothing Coding</title>
      <link>https://paperswithcode.com/paper/rsc-snn-exploring-the-trade-off-between</link>
      <description><![CDATA[Spiking Neural Networks (SNNs) have received widespread attention due to their unique neuronal dynamics and low-power nature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rsc-snn-exploring-the-trade-off-between</guid>
    </item>
    <item>
      <title>Practical Video Object Detection via Feature Selection and Aggregation</title>
      <link>https://paperswithcode.com/paper/practical-video-object-detection-via-feature</link>
      <description><![CDATA[In principle, the detection in a certain frame of a video can benefit from information in other frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/practical-video-object-detection-via-feature</guid>
    </item>
    <item>
      <title>MindSearch: Mimicking Human Minds Elicits Deep AI Searcher</title>
      <link>https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</link>
      <description><![CDATA[Inspired by the cognitive process when humans solve these problems, we introduce MindSearch to mimic the human minds in web information seeking and integration, which can be instantiated by a simple yet effective LLM-based multi-agent framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</guid>
    </item>
    <item>
      <title>Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation</title>
      <link>https://paperswithcode.com/paper/prometheus-chatbot-knowledge-graph</link>
      <description><![CDATA[Knowledge graphs (KGs) are essential in applications such as network alignment, question-answering, and recommender systems (RSs) since they offer structured relational data that facilitate the inference of indirect relationships.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prometheus-chatbot-knowledge-graph</guid>
    </item>
    <item>
      <title>Do LLMs Really Adapt to Domains? An Ontology Learning Perspective</title>
      <link>https://paperswithcode.com/paper/do-llms-really-adapt-to-domains-an-ontology</link>
      <description><![CDATA[Empirical results show that, while adapting to the gibberish corpora, off-the-shelf LLMs do not consistently reason over semantic relationships between concepts, and instead leverage senses and their frame.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-llms-really-adapt-to-domains-an-ontology</guid>
    </item>
    <item>
      <title>LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework</title>
      <link>https://paperswithcode.com/paper/latentartifusion-an-effective-and-efficient</link>
      <description><![CDATA[In this paper, we propose a novel framework, LatentArtiFusion, which leverages the latent diffusion model (LDM) to reconstruct histological artifacts with high performance and computational efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latentartifusion-an-effective-and-efficient</guid>
    </item>
    <item>
      <title>Robust Conformal Volume Estimation in 3D Medical Images</title>
      <link>https://paperswithcode.com/paper/robust-conformal-volume-estimation-in-3d</link>
      <description><![CDATA[A potential reason is that it relies on the estimation of the density ratio between the calibration and test distributions, which is likely to be intractable in scenarios involving high-dimensional data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-conformal-volume-estimation-in-3d</guid>
    </item>
    <item>
      <title>BEExAI: Benchmark to Evaluate Explainable AI</title>
      <link>https://paperswithcode.com/paper/beexai-benchmark-to-evaluate-explainable-ai</link>
      <description><![CDATA[Recent research in explainability has given rise to numerous post-hoc attribution methods aimed at enhancing our comprehension of the outputs of black-box machine learning models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beexai-benchmark-to-evaluate-explainable-ai</guid>
    </item>
    <item>
      <title>Contextuality Helps Representation Learning for Generalized Category Discovery</title>
      <link>https://paperswithcode.com/paper/contextuality-helps-representation-learning</link>
      <description><![CDATA[This paper introduces a novel approach to Generalized Category Discovery (GCD) by leveraging the concept of contextuality to enhance the identification and classification of categories in unlabeled datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contextuality-helps-representation-learning</guid>
    </item>
    <item>
      <title>Global Structure-from-Motion Revisited</title>
      <link>https://paperswithcode.com/paper/global-structure-from-motion-revisited</link>
      <description><![CDATA[Recovering 3D structure and camera motion from images has been a long-standing focus of computer vision research and is known as Structure-from-Motion (SfM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/global-structure-from-motion-revisited</guid>
    </item>
    <item>
      <title>ALEN: A Dual-Approach for Uniform and Non-Uniform Low-Light Image Enhancement</title>
      <link>https://paperswithcode.com/paper/alen-a-dual-approach-for-uniform-and-non</link>
      <description><![CDATA[To address this challenge, the Adaptive Light Enhancement Network (ALEN) is introduced, whose main approach is the use of a classification mechanism to determine whether local or global illumination enhancement is required.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alen-a-dual-approach-for-uniform-and-non</guid>
    </item>
    <item>
      <title>Solving Short-Term Relocalization Problems In Monocular Keyframe Visual SLAM Using Spatial And Semantic Data</title>
      <link>https://paperswithcode.com/paper/solving-short-term-relocalization-problems-in</link>
      <description><![CDATA[In Monocular Keyframe Visual Simultaneous Localization and Mapping (MKVSLAM) frameworks, when incremental position tracking fails, global pose has to be recovered in a short-time window, also known as short-term relocalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/solving-short-term-relocalization-problems-in</guid>
    </item>
    <item>
      <title>Improved physics-informed neural network in mitigating gradient related failures</title>
      <link>https://paperswithcode.com/paper/improved-physics-informed-neural-network-in</link>
      <description><![CDATA[Physics-informed neural networks (PINNs) integrate fundamental physical principles with advanced data-driven techniques, driving significant advancements in scientific computing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-physics-informed-neural-network-in</guid>
    </item>
    <item>
      <title>ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding</title>
      <link>https://paperswithcode.com/paper/asi-seg-audio-driven-surgical-instrument</link>
      <description><![CDATA[To address these limitations in operating rooms, we propose an audio-driven surgical instrument segmentation framework, named ASI-Seg, to accurately segment the required surgical instruments by parsing the audio commands of surgeons.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asi-seg-audio-driven-surgical-instrument</guid>
    </item>
    <item>
      <title>Forecast-PEFT: Parameter-Efficient Fine-Tuning for Pre-trained Motion Forecasting Models</title>
      <link>https://paperswithcode.com/paper/forecast-peft-parameter-efficient-fine-tuning</link>
      <description><![CDATA[This tailored strategy, supplemented by our method's capability to efficiently adapt to different datasets, enhances model efficiency and ensures robust performance across datasets without the need for extensive retraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/forecast-peft-parameter-efficient-fine-tuning</guid>
    </item>
    <item>
      <title>XLIP: Cross-modal Attention Masked Modelling for Medical Language-Image Pre-Training</title>
      <link>https://paperswithcode.com/paper/xlip-cross-modal-attention-masked-modelling</link>
      <description><![CDATA[To this end, this paper proposes a XLIP (Masked modelling for medical Language-Image Pre-training) framework to enhance pathological learning and feature learning via unpaired data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xlip-cross-modal-attention-masked-modelling</guid>
    </item>
    <item>
      <title>ClickDiff: Click to Induce Semantic Contact Map for Controllable Grasp Generation with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/clickdiff-click-to-induce-semantic-contact</link>
      <description><![CDATA[To address these challenges, we propose a controllable grasp generation task and introduce ClickDiff, a controllable conditional generation model that leverages a fine-grained Semantic Contact Map (SCM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clickdiff-click-to-induce-semantic-contact</guid>
    </item>
    <item>
      <title>MVPbev: Multi-view Perspective Image Generation from BEV with Test-time Controllability and Generalizability</title>
      <link>https://paperswithcode.com/paper/mvpbev-multi-view-perspective-image</link>
      <description><![CDATA[Unlike prior methods that neglect layout consistency, lack the ability to handle detailed text prompts, or are incapable of generalizing to unseen view points, MVPbev simultaneously generates cross-view consistent images of different perspective views with a two-stage design, allowing object-level control and novel view generation at test-time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mvpbev-multi-view-perspective-image</guid>
    </item>
    <item>
      <title>EPD: Long-term Memory Extraction, Context-awared Planning and Multi-iteration Decision @ EgoPlan Challenge ICML 2024</title>
      <link>https://paperswithcode.com/paper/epd-long-term-memory-extraction-context</link>
      <description><![CDATA[To address the real-world egocentric task planning problem, we introduce a novel planning framework which comprises three stages: long-term memory Extraction, context-awared Planning, and multi-iteration Decision, named EPD.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/epd-long-term-memory-extraction-context</guid>
    </item>
    <item>
      <title>UniVoxel: Fast Inverse Rendering by Unified Voxelization of Scene Representation</title>
      <link>https://paperswithcode.com/paper/univoxel-fast-inverse-rendering-by-unified</link>
      <description><![CDATA[In this work we design a Unified Voxelization framework for explicit learning of scene representations, dubbed UniVoxel, which allows for efficient modeling of the geometry, materials and illumination jointly, thereby accelerating the inverse rendering significantly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/univoxel-fast-inverse-rendering-by-unified</guid>
    </item>
    <item>
      <title>Depth-Wise Convolutions in Vision Transformers for Efficient Training on Small Datasets</title>
      <link>https://paperswithcode.com/paper/depth-wise-convolutions-in-vision</link>
      <description><![CDATA[The Vision Transformer (ViT) leverages the Transformer's encoder to capture global information by dividing images into patches and achieves superior performance across various computer vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depth-wise-convolutions-in-vision</guid>
    </item>
    <item>
      <title>UniGAP: A Universal and Adaptive Graph Upsampling Approach to Mitigate Over-Smoothing in Node Classification Tasks</title>
      <link>https://paperswithcode.com/paper/unigap-a-universal-and-adaptive-graph</link>
      <description><![CDATA[In this study, we introduce UniGAP, a universal and adaptive graph upsampling technique for graph data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unigap-a-universal-and-adaptive-graph</guid>
    </item>
    <item>
      <title>Mixture of Modular Experts: Distilling Knowledge from a Multilingual Teacher into Specialized Modular Language Models</title>
      <link>https://paperswithcode.com/paper/mixture-of-modular-experts-distilling</link>
      <description><![CDATA[Evaluations of modular MoE architectures revealed that Pre-trained Language Experts (PLE) and Joint Expert Embedding Training (JEET) performed similarly, while the MoE with Common Expert (MoE-CE) setup showed slightly lower performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixture-of-modular-experts-distilling</guid>
    </item>
    <item>
      <title>Interpretable Triplet Importance for Personalized Ranking</title>
      <link>https://paperswithcode.com/paper/interpretable-triplet-importance-for</link>
      <description><![CDATA[Personalized item ranking has been a crucial component contributing to the performance of recommender systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpretable-triplet-importance-for</guid>
    </item>
    <item>
      <title>Detached and Interactive Multimodal Learning</title>
      <link>https://paperswithcode.com/paper/detached-and-interactive-multimodal-learning</link>
      <description><![CDATA[Recently, Multimodal Learning (MML) has gained significant interest as it compensates for single-modality limitations through comprehensive complementary information within multimodal data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detached-and-interactive-multimodal-learning</guid>
    </item>
    <item>
      <title>A Bayesian Approach Toward Robust Multidimensional Ellipsoid-Specific Fitting</title>
      <link>https://paperswithcode.com/paper/a-bayesian-approach-toward-robust</link>
      <description><![CDATA[This work presents a novel and effective method for fitting multidimensional ellipsoids to scattered data in the contamination of noise and outliers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-bayesian-approach-toward-robust</guid>
    </item>
    <item>
      <title>Mamba? Catch The Hype Or Rethink What Really Helps for Image Registration</title>
      <link>https://paperswithcode.com/paper/mamba-catch-the-hype-or-rethink-what-really</link>
      <description><![CDATA[Our findings indicate that adopting "advanced" computational elements fails to significantly improve registration accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mamba-catch-the-hype-or-rethink-what-really</guid>
    </item>
    <item>
      <title>Comprehensive Attribution: Inherently Explainable Vision Model with Feature Detector</title>
      <link>https://paperswithcode.com/paper/comprehensive-attribution-inherently</link>
      <description><![CDATA[A pre-trained detector is introduced to detect discriminative features in the masked-out region.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comprehensive-attribution-inherently</guid>
    </item>
  </channel>
</rss>
