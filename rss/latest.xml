<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 03 Apr 2024 09:12:57 +0000</lastBuildDate>
    <item>
      <title>Using Interpretation Methods for Model Enhancement</title>
      <link>https://paperswithcode.com/paper/using-interpretation-methods-for-model</link>
      <description><![CDATA[In this paper, we propose a framework of utilizing interpretation methods and gold rationales to enhance models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/using-interpretation-methods-for-model</guid>
    </item>
    <item>
      <title>Kallaama: A Transcribed Speech Dataset about Agriculture in the Three Most Widely Spoken Languages in Senegal</title>
      <link>https://paperswithcode.com/paper/kallaama-a-transcribed-speech-dataset-about</link>
      <description><![CDATA[To build such technologies, we provide textual corpora in Wolof and Pulaar, and a pronunciation lexicon containing 49, 132 entries from the Wolof dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kallaama-a-transcribed-speech-dataset-about</guid>
    </item>
    <item>
      <title>Cooperative Students: Navigating Unsupervised Domain Adaptation in Nighttime Object Detection</title>
      <link>https://paperswithcode.com/paper/cooperative-students-navigating-unsupervised</link>
      <description><![CDATA[Unsupervised Domain Adaptation (UDA) has shown significant advancements in object detection under well-lit conditions; however, its performance degrades notably in low-visibility scenarios, especially at night, posing challenges not only for its adaptability in low signal-to-noise ratio (SNR) conditions but also for the reliability and efficiency of automated vehicles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cooperative-students-navigating-unsupervised</guid>
    </item>
    <item>
      <title>ContrastCAD: Contrastive Learning-based Representation Learning for Computer-Aided Design Models</title>
      <link>https://paperswithcode.com/paper/contrastcad-contrastive-learning-based</link>
      <description><![CDATA[However, learning CAD models is still a challenge, because they can be represented as complex shapes with long construction sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastcad-contrastive-learning-based</guid>
    </item>
    <item>
      <title>DELAN: Dual-Level Alignment for Vision-and-Language Navigation by Cross-Modal Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/delan-dual-level-alignment-for-vision-and</link>
      <description><![CDATA[For task completion, the agent needs to align and integrate various navigation modalities, including instruction, observation and navigation history.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/delan-dual-level-alignment-for-vision-and</guid>
    </item>
    <item>
      <title>CameraCtrl: Enabling Camera Control for Text-to-Video Generation</title>
      <link>https://paperswithcode.com/paper/cameractrl-enabling-camera-control-for-text</link>
      <description><![CDATA[Controllability plays a crucial role in video generation since it allows users to create desired content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cameractrl-enabling-camera-control-for-text</guid>
    </item>
    <item>
      <title>FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning</title>
      <link>https://paperswithcode.com/paper/flawn-t5-an-empirical-examination-of</link>
      <description><![CDATA[In this work, we curate LawInstruct, a large legal instruction dataset, covering 17 jurisdictions, 24 languages and a total of 12M examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flawn-t5-an-empirical-examination-of</guid>
    </item>
    <item>
      <title>Deconstructing In-Context Learning: Understanding Prompts via Corruption</title>
      <link>https://paperswithcode.com/paper/deconstructing-in-context-learning</link>
      <description><![CDATA[In contrast, the underlying pre-trained LLMs they use as a backbone are known to be brittle in this respect.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deconstructing-in-context-learning</guid>
    </item>
    <item>
      <title>EMONA: Event-level Moral Opinions in News Articles</title>
      <link>https://paperswithcode.com/paper/emona-event-level-moral-opinions-in-news</link>
      <description><![CDATA[This paper initiates a new task to understand moral opinions towards events in news articles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emona-event-level-moral-opinions-in-news</guid>
    </item>
    <item>
      <title>CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions for RAG systems</title>
      <link>https://paperswithcode.com/paper/clapnq-cohesive-long-form-answers-from</link>
      <description><![CDATA[We present ClapNQ, a benchmark Long-form Question Answering dataset for the full RAG pipeline.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clapnq-cohesive-long-form-answers-from</guid>
    </item>
    <item>
      <title>Synthetic Data for Robust Stroke Segmentation</title>
      <link>https://paperswithcode.com/paper/synthetic-data-for-robust-stroke-segmentation</link>
      <description><![CDATA[Deep learning-based semantic segmentation in neuroimaging currently requires high-resolution scans and extensive annotated datasets, posing significant barriers to clinical applicability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synthetic-data-for-robust-stroke-segmentation</guid>
    </item>
    <item>
      <title>Bridging Language, Vision and Action: Multimodal VAEs in Robotic Manipulation Tasks</title>
      <link>https://paperswithcode.com/paper/bridging-language-vision-and-action</link>
      <description><![CDATA[A more lightweight alternative would be the implementation of multimodal Variational Autoencoders (VAEs) which can extract the latent features of the data and integrate them into a joint representation, as has been demonstrated mostly on image-image or image-text data for the state-of-the-art models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridging-language-vision-and-action</guid>
    </item>
    <item>
      <title>Advancing LLM Reasoning Generalists with Preference Trees</title>
      <link>https://paperswithcode.com/paper/advancing-llm-reasoning-generalists-with</link>
      <description><![CDATA[We introduce Eurus, a suite of large language models (LLMs) optimized for reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-llm-reasoning-generalists-with</guid>
    </item>
    <item>
      <title>Tensorized NeuroEvolution of Augmenting Topologies for GPU Acceleration</title>
      <link>https://paperswithcode.com/paper/tensorized-neuroevolution-of-augmenting</link>
      <description><![CDATA[Through evaluations across a spectrum of robotics control environments in Brax, TensorNEAT achieves up to 500x speedups compared to the existing implementations such as NEAT-Python.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tensorized-neuroevolution-of-augmenting</guid>
    </item>
    <item>
      <title>CAM-Based Methods Can See through Walls</title>
      <link>https://paperswithcode.com/paper/cam-based-methods-can-see-through-walls</link>
      <description><![CDATA[CAM-based methods are widely-used post-hoc interpretability method that produce a saliency map to explain the decision of an image classification model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cam-based-methods-can-see-through-walls</guid>
    </item>
    <item>
      <title>BRAVEn: Improving Self-Supervised Pre-training for Visual and Auditory Speech Recognition</title>
      <link>https://paperswithcode.com/paper/braven-improving-self-supervised-pre-training</link>
      <description><![CDATA[In this work, we propose BRAVEn, an extension to the recent RAVEn method, which learns speech representations entirely from raw audio-visual data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/braven-improving-self-supervised-pre-training</guid>
    </item>
    <item>
      <title>Scene Adaptive Sparse Transformer for Event-based Object Detection</title>
      <link>https://paperswithcode.com/paper/scene-adaptive-sparse-transformer-for-event</link>
      <description><![CDATA[However, they display inadequate sparsity and adaptability when applied to event-based object detection, since these approaches cannot balance the fine granularity of token-level sparsification and the efficiency of window-based Transformers, leading to reduced performance and efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scene-adaptive-sparse-transformer-for-event</guid>
    </item>
    <item>
      <title>Red-Teaming Segment Anything Model</title>
      <link>https://paperswithcode.com/paper/red-teaming-segment-anything-model</link>
      <description><![CDATA[Foundation models have emerged as pivotal tools, tackling many complex tasks through pre-training on vast datasets and subsequent fine-tuning for specific applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/red-teaming-segment-anything-model</guid>
    </item>
    <item>
      <title>Laying Anchors: Semantically Priming Numerals in Language Modeling</title>
      <link>https://paperswithcode.com/paper/laying-anchors-semantically-priming-numerals</link>
      <description><![CDATA[Off-the-shelf pre-trained language models have become the de facto standard in NLP pipelines for a multitude of downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/laying-anchors-semantically-priming-numerals</guid>
    </item>
    <item>
      <title>Settling Time vs. Accuracy Tradeoffs for Clustering Big Data</title>
      <link>https://paperswithcode.com/paper/settling-time-vs-accuracy-tradeoffs-for</link>
      <description><![CDATA[We study the theoretical and practical runtime limits of k-means and k-median clustering on large datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/settling-time-vs-accuracy-tradeoffs-for</guid>
    </item>
    <item>
      <title>How COVID-19 has Impacted the Anti-Vaccine Discourse: A Large-Scale Twitter Study Spanning Pre-COVID and Post-COVID Era</title>
      <link>https://paperswithcode.com/paper/how-covid-19-has-impacted-the-anti-vaccine</link>
      <description><![CDATA[The debate around vaccines has been going on for decades, but the COVID-19 pandemic showed how crucial it is to understand and mitigate anti-vaccine sentiments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-covid-19-has-impacted-the-anti-vaccine</guid>
    </item>
    <item>
      <title>Lookahead Exploration with Neural Radiance Representation for Continuous Vision-Language Navigation</title>
      <link>https://paperswithcode.com/paper/lookahead-exploration-with-neural-radiance</link>
      <description><![CDATA[Vision-and-language navigation (VLN) enables the agent to navigate to a remote location following the natural language instruction in 3D environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lookahead-exploration-with-neural-radiance</guid>
    </item>
    <item>
      <title>Pre-trained Vision and Language Transformers Are Few-Shot Incremental Learners</title>
      <link>https://paperswithcode.com/paper/pre-trained-vision-and-language-transformers</link>
      <description><![CDATA[In this paper, we argue that large models such as vision and language transformers pre-trained on large datasets can be excellent few-shot incremental learners.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pre-trained-vision-and-language-transformers</guid>
    </item>
    <item>
      <title>Team UTSA-NLP at SemEval 2024 Task 5: Prompt Ensembling for Argument Reasoning in Civil Procedures with GPT4</title>
      <link>https://paperswithcode.com/paper/team-utsa-nlp-at-semeval-2024-task-5-prompt</link>
      <description><![CDATA[Overall, our system results in a Macro F1 of . 8095 on the validation dataset and . 7315 (5th out of 21 teams) on the final test set.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/team-utsa-nlp-at-semeval-2024-task-5-prompt</guid>
    </item>
    <item>
      <title>GINopic: Topic Modeling with Graph Isomorphism Network</title>
      <link>https://paperswithcode.com/paper/ginopic-topic-modeling-with-graph-isomorphism</link>
      <description><![CDATA[Topic modeling is a widely used approach for analyzing and exploring large document collections.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ginopic-topic-modeling-with-graph-isomorphism</guid>
    </item>
    <item>
      <title>Generalizable, Fast, and Accurate DeepQSPR with fastprop Part 1: Framework and Benchmarks</title>
      <link>https://paperswithcode.com/paper/generalizable-fast-and-accurate-deepqspr-with</link>
      <description><![CDATA[Quantitative Structure Property Relationship studies aim to define a mapping between molecular structure and arbitrary quantities of interest.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizable-fast-and-accurate-deepqspr-with</guid>
    </item>
    <item>
      <title>SPMamba: State-space model is all you need in speech separation</title>
      <link>https://paperswithcode.com/paper/spmamba-state-space-model-is-all-you-need-in</link>
      <description><![CDATA[Notably, within computer vision, Mamba-based methods have been celebrated for their formidable performance and reduced computational requirements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spmamba-state-space-model-is-all-you-need-in</guid>
    </item>
    <item>
      <title>Weakly-supervised Audio Separation via Bi-modal Semantic Similarity</title>
      <link>https://paperswithcode.com/paper/weakly-supervised-audio-separation-via-bi</link>
      <description><![CDATA[Conditional sound separation in multi-source audio mixtures without having access to single source sound data during training is a long standing challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/weakly-supervised-audio-separation-via-bi</guid>
    </item>
    <item>
      <title>On the Role of Summary Content Units in Text Summarization Evaluation</title>
      <link>https://paperswithcode.com/paper/on-the-role-of-summary-content-units-in-text</link>
      <description><![CDATA[At the heart of the Pyramid evaluation method for text summarization lie human written summary content units (SCUs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-role-of-summary-content-units-in-text</guid>
    </item>
    <item>
      <title>Can Humans Identify Domains?</title>
      <link>https://paperswithcode.com/paper/can-humans-identify-domains</link>
      <description><![CDATA[Textual domain is a crucial property within the Natural Language Processing (NLP) community due to its effects on downstream model performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-humans-identify-domains</guid>
    </item>
    <item>
      <title>VSRD: Instance-Aware Volumetric Silhouette Rendering for Weakly Supervised 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/vsrd-instance-aware-volumetric-silhouette</link>
      <description><![CDATA[In the auto-labeling stage, we represent the surface of each instance as a signed distance field (SDF) and render its silhouette as an instance mask through our proposed instance-aware volumetric silhouette rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vsrd-instance-aware-volumetric-silhouette</guid>
    </item>
    <item>
      <title>EGTR: Extracting Graph from Transformer for Scene Graph Generation</title>
      <link>https://paperswithcode.com/paper/egtr-extracting-graph-from-transformer-for</link>
      <description><![CDATA[We propose a lightweight one-stage SGG model that extracts the relation graph from the various relationships learned in the multi-head self-attention layers of the DETR decoder.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/egtr-extracting-graph-from-transformer-for</guid>
    </item>
    <item>
      <title>IISAN: Efficiently Adapting Multimodal Representation for Sequential Recommendation with Decoupled PEFT</title>
      <link>https://paperswithcode.com/paper/iisan-efficiently-adapting-multimodal</link>
      <description><![CDATA[This is also a notable improvement over the Adapter and LoRA, which require 37-39 GB GPU memory and 350-380 seconds per epoch for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/iisan-efficiently-adapting-multimodal</guid>
    </item>
    <item>
      <title>Rematch: Robust and Efficient Matching of Local Knowledge Graphs to Improve Structural and Semantic Similarity</title>
      <link>https://paperswithcode.com/paper/rematch-robust-and-efficient-matching-of</link>
      <description><![CDATA[Knowledge graphs play a pivotal role in various applications, such as question-answering and fact-checking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rematch-robust-and-efficient-matching-of</guid>
    </item>
    <item>
      <title>Spin-UP: Spin Light for Natural Light Uncalibrated Photometric Stereo</title>
      <link>https://paperswithcode.com/paper/spin-up-spin-light-for-natural-light</link>
      <description><![CDATA[Natural Light Uncalibrated Photometric Stereo (NaUPS) relieves the strict environment and light assumptions in classical Uncalibrated Photometric Stereo (UPS) methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spin-up-spin-light-for-natural-light</guid>
    </item>
    <item>
      <title>R^2-Tuning: Efficient Image-to-Video Transfer Learning for Video Temporal Grounding</title>
      <link>https://paperswithcode.com/paper/r-2-tuning-efficient-image-to-video-transfer</link>
      <description><![CDATA[Video temporal grounding (VTG) is a fine-grained video understanding problem that aims to ground relevant clips in untrimmed videos given natural language queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r-2-tuning-efficient-image-to-video-transfer</guid>
    </item>
    <item>
      <title>Breaking the Silence Detecting and Mitigating Gendered Abuse in Hindi, Tamil, and Indian English Online Spaces</title>
      <link>https://paperswithcode.com/paper/breaking-the-silence-detecting-and-mitigating</link>
      <description><![CDATA[Online gender-based harassment is a widespread issue limiting the free expression and participation of women and marginalized genders in digital spaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/breaking-the-silence-detecting-and-mitigating</guid>
    </item>
    <item>
      <title>Universal representations for financial transactional data: embracing local, global, and external contexts</title>
      <link>https://paperswithcode.com/paper/universal-representations-for-financial</link>
      <description><![CDATA[Effective processing of financial transactions is essential for banking data analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-representations-for-financial</guid>
    </item>
    <item>
      <title>A Survey on Large Language Model-Based Game Agents</title>
      <link>https://paperswithcode.com/paper/a-survey-on-large-language-model-based-game</link>
      <description><![CDATA[The development of game agents holds a critical role in advancing towards Artificial General Intelligence (AGI).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-large-language-model-based-game</guid>
    </item>
    <item>
      <title>Procedural Fairness in Machine Learning</title>
      <link>https://paperswithcode.com/paper/procedural-fairness-in-machine-learning</link>
      <description><![CDATA[We propose a novel metric to evaluate the group procedural fairness of ML models, called $GPF_{FAE}$, which utilizes a widely used explainable artificial intelligence technique, namely feature attribution explanation (FAE), to capture the decision process of the ML models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/procedural-fairness-in-machine-learning</guid>
    </item>
    <item>
      <title>Atom-Level Optical Chemical Structure Recognition with Limited Supervision</title>
      <link>https://paperswithcode.com/paper/atom-level-optical-chemical-structure</link>
      <description><![CDATA[Identifying the chemical structure from a graphical representation, or image, of a molecule is a challenging pattern recognition task that would greatly benefit drug development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/atom-level-optical-chemical-structure</guid>
    </item>
    <item>
      <title>PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction in Off-road Driving</title>
      <link>https://paperswithcode.com/paper/physord-a-neuro-symbolic-approach-for-physics</link>
      <description><![CDATA[To bridge this gap, we present PhysORD, a neural-symbolic approach integrating the conservation law, i. e., the Euler-Lagrange equation, into data-driven neural models for motion prediction in off-road driving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physord-a-neuro-symbolic-approach-for-physics</guid>
    </item>
    <item>
      <title>ViTamin: Designing Scalable Vision Models in the Vision-Language Era</title>
      <link>https://paperswithcode.com/paper/vitamin-designing-scalable-vision-models-in</link>
      <description><![CDATA[To this end, we introduce ViTamin, a new vision models tailored for VLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vitamin-designing-scalable-vision-models-in</guid>
    </item>
    <item>
      <title>Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack</title>
      <link>https://paperswithcode.com/paper/humanizing-machine-generated-content-evading</link>
      <description><![CDATA[While well-trained text detectors have demonstrated promising performance on unseen test data, recent research suggests that these detectors have vulnerabilities when dealing with adversarial attacks such as paraphrasing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/humanizing-machine-generated-content-evading</guid>
    </item>
    <item>
      <title>Long-context LLMs Struggle with Long In-context Learning</title>
      <link>https://paperswithcode.com/paper/long-context-llms-struggle-with-long-in</link>
      <description><![CDATA[We find that the long-context LLMs perform relatively well under the token length of 20K and the performance benefits from utilizing the long context window.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/long-context-llms-struggle-with-long-in</guid>
    </item>
    <item>
      <title>ASTRA: An Action Spotting TRAnsformer for Soccer Videos</title>
      <link>https://paperswithcode.com/paper/astra-an-action-spotting-transformer-for</link>
      <description><![CDATA[In this paper, we introduce ASTRA, a Transformer-based model designed for the task of Action Spotting in soccer matches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/astra-an-action-spotting-transformer-for</guid>
    </item>
    <item>
      <title>Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models</title>
      <link>https://paperswithcode.com/paper/confidence-aware-reward-optimization-for-fine</link>
      <description><![CDATA[To investigate this issue in depth, we introduce the Text-Image Alignment Assessment (TIA2) benchmark, which comprises a diverse collection of text prompts, images, and human annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/confidence-aware-reward-optimization-for-fine</guid>
    </item>
    <item>
      <title>WcDT: World-centric Diffusion Transformer for Traffic Scene Generation</title>
      <link>https://paperswithcode.com/paper/wcdt-world-centric-diffusion-transformer-for</link>
      <description><![CDATA[To enhance the scene diversity and stochasticity, the historical trajectory data is first preprocessed and encoded into latent space using Denoising Diffusion Probabilistic Models (DDPM) enhanced with Diffusion with Transformer (DiT) blocks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wcdt-world-centric-diffusion-transformer-for</guid>
    </item>
    <item>
      <title>MESEN: Exploit Multimodal Data to Design Unimodal Human Activity Recognition with Few Labels</title>
      <link>https://paperswithcode.com/paper/mesen-exploit-multimodal-data-to-design</link>
      <description><![CDATA[Human activity recognition (HAR) will be an essential function of various emerging applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mesen-exploit-multimodal-data-to-design</guid>
    </item>
    <item>
      <title>Efficient Online Unlearning via Hessian-Free Recollection of Individual Data Statistics</title>
      <link>https://paperswithcode.com/paper/efficient-online-unlearning-via-hessian-free</link>
      <description><![CDATA[In this work, we propose a Hessian-free online unlearning method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-online-unlearning-via-hessian-free</guid>
    </item>
  </channel>
</rss>
