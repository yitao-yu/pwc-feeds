<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 03 Dec 2023 21:05:58 +0000</lastBuildDate>
    <item>
      <title>Effect of prolonged use of Smartphones on neck and wrist muscle fatigue using surface EMG</title>
      <link>https://paperswithcode.com/paper/effect-of-prolonged-use-of-smartphones-on</link>
      <description><![CDATA[Prolonged smartphone usage is prevalent among young adults in Lima, Peru, with potential implications for musculoskeletal health.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effect-of-prolonged-use-of-smartphones-on</guid>
    </item>
    <item>
      <title>$\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks: Benchmarking against Classical Neural Networks</title>
      <link>https://paperswithcode.com/paper/mathbb-z-2-times-mathbb-z-2-equivariant</link>
      <description><![CDATA[Our results show that the $\mathbb{Z}_2\times \mathbb{Z}_2$ EQNN and the QNN provide superior performance for smaller parameter sets and modest training data samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mathbb-z-2-times-mathbb-z-2-equivariant</guid>
    </item>
    <item>
      <title>Controlgym: Large-Scale Safety-Critical Control Environments for Benchmarking Reinforcement Learning Algorithms</title>
      <link>https://paperswithcode.com/paper/controlgym-large-scale-safety-critical</link>
      <description><![CDATA[This project serves the learning for dynamics & control (L4DC) community, aiming to explore key questions: the convergence of RL algorithms in learning control policies; the stability and robustness issues of learning-based controllers; and the scalability of RL algorithms to high- and potentially infinite-dimensional systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controlgym-large-scale-safety-critical</guid>
    </item>
    <item>
      <title>Exploiting Diffusion Prior for Generalizable Pixel-Level Semantic Prediction</title>
      <link>https://paperswithcode.com/paper/exploiting-diffusion-prior-for-generalizable</link>
      <description><![CDATA[Contents generated by recent advanced Text-to-Image (T2I) diffusion models are sometimes too imaginative for existing off-the-shelf property semantic predictors to estimate due to the immitigable domain gap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploiting-diffusion-prior-for-generalizable</guid>
    </item>
    <item>
      <title>AlignBench: Benchmarking Chinese Alignment of Large Language Models</title>
      <link>https://paperswithcode.com/paper/alignbench-benchmarking-chinese-alignment-of</link>
      <description><![CDATA[Alignment has become a critical step for instruction-tuned Large Language Models (LLMs) to become helpful assistants.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alignbench-benchmarking-chinese-alignment-of</guid>
    </item>
    <item>
      <title>ElasticDiffusion: Training-free Arbitrary Size Image Generation</title>
      <link>https://paperswithcode.com/paper/elasticdiffusion-training-free-arbitrary-size</link>
      <description><![CDATA[We propose ElasticDiffusion, a novel training-free decoding method that enables pretrained text-to-image diffusion models to generate images with various sizes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elasticdiffusion-training-free-arbitrary-size</guid>
    </item>
    <item>
      <title>Routing-Guided Learned Product Quantization for Graph-Based Approximate Nearest Neighbor Search</title>
      <link>https://paperswithcode.com/paper/routing-guided-learned-product-quantization</link>
      <description><![CDATA[It suffers from the large-scale $\mathcal{X}$ because a PG with full vectors is too large to fit into the memory, e. g., a billion-scale $\mathcal{X}$ in 128 dimensions would consume nearly 600 GB memory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/routing-guided-learned-product-quantization</guid>
    </item>
    <item>
      <title>Compact3D: Compressing Gaussian Splat Radiance Field Models with Vector Quantization</title>
      <link>https://paperswithcode.com/paper/compact3d-compressing-gaussian-splat-radiance</link>
      <description><![CDATA[3D Gaussian Splatting is a new method for modeling and rendering 3D radiance fields that achieves much faster learning and rendering time compared to SOTA NeRF methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compact3d-compressing-gaussian-splat-radiance</guid>
    </item>
    <item>
      <title>Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation</title>
      <link>https://paperswithcode.com/paper/towards-assessing-and-benchmarking-risk</link>
      <description><![CDATA[This efficient estimator is characterized by its capability to form the most advantageous policy portfolios, maximizing returns while minimizing risks during online deployment, a nuance that existing metrics typically overlook.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-assessing-and-benchmarking-risk</guid>
    </item>
    <item>
      <title>Language Model Agents Suffer from Compositional Generalization in Web Automation</title>
      <link>https://paperswithcode.com/paper/language-model-agents-suffer-from</link>
      <description><![CDATA[We show that while existing prompted LMAs (gpt-3. 5-turbo or gpt-4) achieve 94. 0% average success rate on base tasks, their performance degrades to 24. 9% success rate on compositional tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-model-agents-suffer-from</guid>
    </item>
    <item>
      <title>MotionEditor: Editing Video Motion via Content-Aware Diffusion</title>
      <link>https://paperswithcode.com/paper/motioneditor-editing-video-motion-via-content</link>
      <description><![CDATA[This mechanism enables the editing branch to query the key and value from the reconstruction branch in a decoupled manner, making the editing branch retain the original background and protagonist appearance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motioneditor-editing-video-motion-via-content</guid>
    </item>
    <item>
      <title>What Do Llamas Really Think? Revealing Preference Biases in Language Model Representations</title>
      <link>https://paperswithcode.com/paper/what-do-llamas-really-think-revealing</link>
      <description><![CDATA[We propose a logistic Bradley-Terry probe which predicts word pair preferences of LLMs from the words' hidden vectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-do-llamas-really-think-revealing</guid>
    </item>
    <item>
      <title>LLVMs4Protest: Harnessing the Power of Large Language and Vision Models for Deciphering Protests in the News</title>
      <link>https://paperswithcode.com/paper/llvms4protest-harnessing-the-power-of-large</link>
      <description><![CDATA[First, the longformer model was fine-tuned using the Dynamic of Collective Action (DoCA) Corpus.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llvms4protest-harnessing-the-power-of-large</guid>
    </item>
    <item>
      <title>Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking</title>
      <link>https://paperswithcode.com/paper/dichotomy-of-early-and-late-phase-implicit</link>
      <description><![CDATA[Recent work by Power et al. (2022) highlighted a surprising "grokking" phenomenon in learning arithmetic tasks: a neural net first "memorizes" the training set, resulting in perfect training accuracy but near-random test accuracy, and after training for sufficiently longer, it suddenly transitions to perfect test accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dichotomy-of-early-and-late-phase-implicit</guid>
    </item>
    <item>
      <title>On the convergence of adaptive first order methods: proximal gradient and alternating minimization algorithms</title>
      <link>https://paperswithcode.com/paper/on-the-convergence-of-adaptive-first-order</link>
      <description><![CDATA[Building upon recent works on linesearch-free adaptive proximal gradient methods, this paper proposes AdaPG$^{\pi, r}$, a framework that unifies and extends existing results by providing larger stepsize policies and improved lower bounds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-convergence-of-adaptive-first-order</guid>
    </item>
    <item>
      <title>Accurate Segmentation of Optic Disc And Cup from Multiple Pseudo-labels by Noise-Aware Learning</title>
      <link>https://paperswithcode.com/paper/accurate-segmentation-of-optic-disc-and-cup</link>
      <description><![CDATA[The training framework of the MPNN is constructed by a teacher-student architecture to learn segmentation from clean pixels and noisy pixels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accurate-segmentation-of-optic-disc-and-cup</guid>
    </item>
    <item>
      <title>CAST: Cross-Attention in Space and Time for Video Action Recognition</title>
      <link>https://paperswithcode.com/paper/cast-cross-attention-in-space-and-time-for-1</link>
      <description><![CDATA[In this work, we propose a novel two-stream architecture, called Cross-Attention in Space and Time (CAST), that achieves a balanced spatio-temporal understanding of videos using only RGB input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cast-cross-attention-in-space-and-time-for-1</guid>
    </item>
    <item>
      <title>FRC-GIF: Frame Ranking-based Personalized Artistic Media Generation Method for Resource Constrained Devices</title>
      <link>https://paperswithcode.com/paper/frc-gif-frame-ranking-based-personalized</link>
      <description><![CDATA[Generating video highlights in the form of animated graphics interchange formats (GIFs) has significantly simplified the process of video browsing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/frc-gif-frame-ranking-based-personalized</guid>
    </item>
    <item>
      <title>MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation</title>
      <link>https://paperswithcode.com/paper/maxtron-mask-transformer-with-trajectory</link>
      <description><![CDATA[To alleviate the issue, we propose to adapt the trajectory attention for both the dense pixel features and object queries, aiming to improve the short-term and long-term tracking results, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maxtron-mask-transformer-with-trajectory</guid>
    </item>
    <item>
      <title>FFT: Towards Harmlessness Evaluation and Analysis for LLMs with Factuality, Fairness, Toxicity</title>
      <link>https://paperswithcode.com/paper/fft-towards-harmlessness-evaluation-and</link>
      <description><![CDATA[The widespread of generative artificial intelligence has heightened concerns about the potential harms posed by AI-generated texts, primarily stemming from factoid, unfair, and toxic content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fft-towards-harmlessness-evaluation-and</guid>
    </item>
    <item>
      <title>TIDE: Test Time Few Shot Object Detection</title>
      <link>https://paperswithcode.com/paper/tide-test-time-few-shot-object-detection</link>
      <description><![CDATA[Few-shot object detection (FSOD) aims to extract semantic knowledge from limited object instances of novel categories within a target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tide-test-time-few-shot-object-detection</guid>
    </item>
    <item>
      <title>Solving the Team Orienteering Problem with Transformers</title>
      <link>https://paperswithcode.com/paper/solving-the-team-orienteering-problem-with-1</link>
      <description><![CDATA[This problem is usually modeled as a Combinatorial Optimization problem named as Team Orienteering Problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/solving-the-team-orienteering-problem-with-1</guid>
    </item>
    <item>
      <title>CAT-DM: Controllable Accelerated Virtual Try-on with Diffusion Model</title>
      <link>https://paperswithcode.com/paper/cat-dm-controllable-accelerated-virtual-try</link>
      <description><![CDATA[Image-based virtual try-on enables users to virtually try on different garments by altering original clothes in their photographs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cat-dm-controllable-accelerated-virtual-try</guid>
    </item>
    <item>
      <title>Distributed Global Structure-from-Motion with a Deep Front-End</title>
      <link>https://paperswithcode.com/paper/distributed-global-structure-from-motion-with</link>
      <description><![CDATA[While initial approaches to Structure-from-Motion (SfM) revolved around both global and incremental methods, most recent applications rely on incremental systems to estimate camera poses due to their superior robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distributed-global-structure-from-motion-with</guid>
    </item>
    <item>
      <title>Dataset Distillation in Large Data Era</title>
      <link>https://paperswithcode.com/paper/dataset-distillation-in-large-data-era</link>
      <description><![CDATA[Dataset distillation aims to generate a smaller but representative subset from a large dataset, which allows a model to be trained efficiently, meanwhile evaluating on the original testing data distribution to achieve decent performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dataset-distillation-in-large-data-era</guid>
    </item>
    <item>
      <title>MCI Detection using fMRI time series embeddings of Recurrence plots</title>
      <link>https://paperswithcode.com/paper/mci-detection-using-fmri-time-series</link>
      <description><![CDATA[Utilizing resting state fMRI time series imaging, we can study the underlying dynamics at ear-marked Regions of Interest (ROIs) to understand structure or lack thereof.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mci-detection-using-fmri-time-series</guid>
    </item>
    <item>
      <title>COVID-19 Vaccine Misinformation in Middle Income Countries</title>
      <link>https://paperswithcode.com/paper/covid-19-vaccine-misinformation-in-middle</link>
      <description><![CDATA[This paper introduces a multilingual dataset of COVID-19 vaccine misinformation, consisting of annotated tweets from three middle-income countries: Brazil, Indonesia, and Nigeria.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/covid-19-vaccine-misinformation-in-middle</guid>
    </item>
    <item>
      <title>Automatic Functional Differentiation in JAX</title>
      <link>https://paperswithcode.com/paper/automatic-functional-differentiation-in-jax</link>
      <description><![CDATA[We present a set of primitive operators that serve as foundational building blocks for constructing several key types of functionals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automatic-functional-differentiation-in-jax</guid>
    </item>
    <item>
      <title>Unsupervised learning architecture based on neural Darwinism and Hopfield networks recognizes symbols with high accuracy</title>
      <link>https://paperswithcode.com/paper/unsupervised-learning-architecture-based-on</link>
      <description><![CDATA[In simulations, the model achieves high accuracy in learning the letters of the Latin alphabet, presented as binary patterns on a grid.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-learning-architecture-based-on</guid>
    </item>
    <item>
      <title>TransCORALNet: A Two-Stream Transformer CORAL Networks for Supply Chain Credit Assessment Cold Start</title>
      <link>https://paperswithcode.com/paper/transcoralnet-a-two-stream-transformer-coral</link>
      <description><![CDATA[Thanks to the domain adaptation capability of the proposed model, the domain shift between the source and target domain is minimized.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transcoralnet-a-two-stream-transformer-coral</guid>
    </item>
    <item>
      <title>LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models</title>
      <link>https://paperswithcode.com/paper/lmrl-gym-benchmarks-for-multi-turn</link>
      <description><![CDATA[Developing such algorithms requires tasks that can gauge progress on algorithm design, provide accessible and reproducible evaluations for multi-turn interactions, and cover a range of task properties and challenges in improving reinforcement learning algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lmrl-gym-benchmarks-for-multi-turn</guid>
    </item>
    <item>
      <title>Semantic-Aware Frame-Event Fusion based Pattern Recognition via Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/semantic-aware-frame-event-fusion-based</link>
      <description><![CDATA[Current methods typically employ backbone networks to individually extract the features of RGB frames and event streams, and subsequently fuse these features for pattern recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-aware-frame-event-fusion-based</guid>
    </item>
    <item>
      <title>IMMA: Immunizing text-to-image Models against Malicious Adaptation</title>
      <link>https://paperswithcode.com/paper/imma-immunizing-text-to-image-models-against</link>
      <description><![CDATA[Advancements in text-to-image models and fine-tuning methods have led to the increasing risk of malicious adaptation, i. e., fine-tuning to generate harmful unauthorized content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imma-immunizing-text-to-image-models-against</guid>
    </item>
    <item>
      <title>RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance</title>
      <link>https://paperswithcode.com/paper/radialog-a-large-vision-language-model-for</link>
      <description><![CDATA[Conversational AI tools that can generate and discuss clinically correct radiology reports for a given medical image have the potential to transform radiology.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/radialog-a-large-vision-language-model-for</guid>
    </item>
    <item>
      <title>VTimeLLM: Empower LLM to Grasp Video Moments</title>
      <link>https://paperswithcode.com/paper/vtimellm-empower-llm-to-grasp-video-moments</link>
      <description><![CDATA[Large language models (LLMs) have shown remarkable text understanding capabilities, which have been extended as Video LLMs to handle video data for comprehending visual details.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vtimellm-empower-llm-to-grasp-video-moments</guid>
    </item>
    <item>
      <title>New Perspectives on the Evaluation of Link Prediction Algorithms for Dynamic Graphs</title>
      <link>https://paperswithcode.com/paper/new-perspectives-on-the-evaluation-of-link</link>
      <description><![CDATA[We leverage these visualization tools to investigate the effect of negative sampling on the predictive performance, at the node and edge level.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/new-perspectives-on-the-evaluation-of-link</guid>
    </item>
    <item>
      <title>RainAI -- Precipitation Nowcasting from Satellite Data</title>
      <link>https://paperswithcode.com/paper/rainai-precipitation-nowcasting-from</link>
      <description><![CDATA[This paper presents a solution to the Weather4Cast 2023 competition, where the goal is to forecast high-resolution precipitation with an 8-hour lead time using lower-resolution satellite radiance images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rainai-precipitation-nowcasting-from</guid>
    </item>
    <item>
      <title>Optimizing ZX-Diagrams with Deep Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/optimizing-zx-diagrams-with-deep</link>
      <description><![CDATA[ZX-diagrams are a powerful graphical language for the description of quantum processes with applications in fundamental quantum mechanics, quantum circuit optimization, tensor network simulation, and many more.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimizing-zx-diagrams-with-deep</guid>
    </item>
    <item>
      <title>mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large Language Model</title>
      <link>https://paperswithcode.com/paper/mplug-paperowl-scientific-diagram-analysis</link>
      <description><![CDATA[In this work, towards a more versatile copilot for academic paper writing, we mainly focus on strengthening the multi-modal diagram analysis ability of Multimodal LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mplug-paperowl-scientific-diagram-analysis</guid>
    </item>
    <item>
      <title>CritiqueLLM: Scaling LLM-as-Critic for Effective and Explainable Evaluation of Large Language Model Generation</title>
      <link>https://paperswithcode.com/paper/critiquellm-scaling-llm-as-critic-for</link>
      <description><![CDATA[Since the natural language processing (NLP) community started to make large language models (LLMs), such as GPT-4, act as a critic to evaluate the quality of generated texts, most of them only train a critique generation model of a specific scale on specific datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/critiquellm-scaling-llm-as-critic-for</guid>
    </item>
    <item>
      <title>Perturbation-based Analysis of Compositional Data</title>
      <link>https://paperswithcode.com/paper/perturbation-based-analysis-of-compositional</link>
      <description><![CDATA[Existing statistical methods for compositional data analysis are inadequate for many modern applications for two reasons.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perturbation-based-analysis-of-compositional</guid>
    </item>
    <item>
      <title>A Comparison Between Invariant and Equivariant Classical and Quantum Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/a-comparison-between-invariant-and</link>
      <description><![CDATA[In this paper, we perform a fair and comprehensive comparison between classical graph neural networks (GNNs) and equivariant graph neural networks (EGNNs) and their quantum counterparts: quantum graph neural networks (QGNNs) and equivariant quantum graph neural networks (EQGNN).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparison-between-invariant-and</guid>
    </item>
    <item>
      <title>Steering Deep Feature Learning with Backward Aligned Feature Updates</title>
      <link>https://paperswithcode.com/paper/steering-deep-feature-learning-with-backward</link>
      <description><![CDATA[Deep learning succeeds by doing hierarchical feature learning, yet tuning Hyper-Parameters (HP) such as initialization scales, learning rates etc., only give indirect control over this behavior.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/steering-deep-feature-learning-with-backward</guid>
    </item>
    <item>
      <title>HOLD: Category-agnostic 3D Reconstruction of Interacting Hands and Objects from Video</title>
      <link>https://paperswithcode.com/paper/hold-category-agnostic-3d-reconstruction-of</link>
      <description><![CDATA[Since humans interact with diverse objects every day, the holistic 3D capture of these interactions is important to understand and model human behaviour.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hold-category-agnostic-3d-reconstruction-of</guid>
    </item>
    <item>
      <title>InstructSeq: Unifying Vision Tasks with Instruction-conditioned Multi-modal Sequence Generation</title>
      <link>https://paperswithcode.com/paper/instructseq-unifying-vision-tasks-with</link>
      <description><![CDATA[In this work, we introduce InstructSeq, an instruction-conditioned multi-modal modeling framework that unifies diverse vision tasks through flexible natural language control and handling of both visual and textual data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructseq-unifying-vision-tasks-with</guid>
    </item>
    <item>
      <title>Is Underwater Image Enhancement All Object Detectors Need?</title>
      <link>https://paperswithcode.com/paper/is-underwater-image-enhancement-all-object</link>
      <description><![CDATA[Coupled with 7 object detection models retrained using raw underwater images, we employ these 133 models to comprehensively analyze the effect of underwater image enhancement on underwater object detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-underwater-image-enhancement-all-object</guid>
    </item>
    <item>
      <title>SCOPE-RL: A Python Library for Offline Reinforcement Learning and Off-Policy Evaluation</title>
      <link>https://paperswithcode.com/paper/scope-rl-a-python-library-for-offline</link>
      <description><![CDATA[This paper introduces SCOPE-RL, a comprehensive open-source Python software designed for offline reinforcement learning (offline RL), off-policy evaluation (OPE), and selection (OPS).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scope-rl-a-python-library-for-offline</guid>
    </item>
    <item>
      <title>LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding, Reasoning, and Planning</title>
      <link>https://paperswithcode.com/paper/ll3da-visual-interactive-instruction-tuning</link>
      <description><![CDATA[However, developing LMMs that can comprehend, reason, and plan in complex and diverse 3D environments remains a challenging topic, especially considering the demand for understanding permutation-invariant point cloud 3D representations of the 3D scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ll3da-visual-interactive-instruction-tuning</guid>
    </item>
    <item>
      <title>CoRec: An Easy Approach for Coordination Recognition</title>
      <link>https://paperswithcode.com/paper/corec-an-easy-approach-for-coordination</link>
      <description><![CDATA[In this paper, we observe and address the challenges of the coordination recognition task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/corec-an-easy-approach-for-coordination</guid>
    </item>
    <item>
      <title>TaskBench: Benchmarking Large Language Models for Task Automation</title>
      <link>https://paperswithcode.com/paper/taskbench-benchmarking-large-language-models</link>
      <description><![CDATA[To this end, we introduce TaskBench to evaluate the capability of LLMs in task automation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taskbench-benchmarking-large-language-models</guid>
    </item>
  </channel>
</rss>
