<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 15 Mar 2023 09:13:48 +0000</lastBuildDate>
    <item>
      <title>SimFLE: Simple Facial Landmark Encoding for Self-Supervised Facial Expression Recognition in the Wild</title>
      <link>https://paperswithcode.com/paper/simfle-simple-facial-landmark-encoding-for</link>
      <description><![CDATA[One of the key issues in facial expression recognition in the wild (FER-W) is that curating large-scale labeled facial images is challenging due to the inherent complexity and ambiguity of facial images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simfle-simple-facial-landmark-encoding-for</guid>
    </item>
    <item>
      <title>Co-Salient Object Detection with Co-Representation Purification</title>
      <link>https://paperswithcode.com/paper/co-salient-object-detection-with-co</link>
      <description><![CDATA[Such irrelevant information in the co-representation interferes with its locating of co-salient objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/co-salient-object-detection-with-co</guid>
    </item>
    <item>
      <title>Sr-init: An interpretable layer pruning method</title>
      <link>https://paperswithcode.com/paper/sr-init-an-interpretable-layer-pruning-method</link>
      <description><![CDATA[Our SR-init method is inspired by the discovery that the accuracy drop due to stochastic re-initialization of layer parameters differs in various layers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sr-init-an-interpretable-layer-pruning-method</guid>
    </item>
    <item>
      <title>Quaternion Orthogonal Transformer for Facial Expression Recognition in the Wild</title>
      <link>https://paperswithcode.com/paper/quaternion-orthogonal-transformer-for-facial</link>
      <description><![CDATA[Firstly, to reduce redundancy among features extracted from pre-trained ResNet-50, we use the orthogonal loss to decompose and compact these features into three sets of orthogonal sub-features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quaternion-orthogonal-transformer-for-facial</guid>
    </item>
    <item>
      <title>AdPE: Adversarial Positional Embeddings for Pretraining Vision Transformers via MAE+</title>
      <link>https://paperswithcode.com/paper/adpe-adversarial-positional-embeddings-for</link>
      <description><![CDATA[A criterion in unsupervised pretraining is the pretext task needs to be sufficiently hard to prevent the transformer encoder from learning trivial low-level features not generalizable well to downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adpe-adversarial-positional-embeddings-for</guid>
    </item>
    <item>
      <title>Eliciting Latent Predictions from Transformers with the Tuned Lens</title>
      <link>https://paperswithcode.com/paper/eliciting-latent-predictions-from</link>
      <description><![CDATA[We analyze transformers from the perspective of iterative inference, seeking to understand how model predictions are refined layer by layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eliciting-latent-predictions-from</guid>
    </item>
    <item>
      <title>A Contrastive Knowledge Transfer Framework for Model Compression and Transfer Learning</title>
      <link>https://paperswithcode.com/paper/a-contrastive-knowledge-transfer-framework</link>
      <description><![CDATA[Knowledge Transfer (KT) achieves competitive performance and is widely used for image classification tasks in model compression and transfer learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-contrastive-knowledge-transfer-framework</guid>
    </item>
    <item>
      <title>Practically Solving LPN in High Noise Regimes Faster Using Neural Networks</title>
      <link>https://paperswithcode.com/paper/practically-solving-lpn-in-high-noise-regimes</link>
      <description><![CDATA[For some settings we are also able to provide theories that explain the rationale of the design of our models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/practically-solving-lpn-in-high-noise-regimes</guid>
    </item>
    <item>
      <title>The Life Cycle of Knowledge in Big Language Models: A Survey</title>
      <link>https://paperswithcode.com/paper/the-life-cycle-of-knowledge-in-big-language</link>
      <description><![CDATA[Knowledge plays a critical role in artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-life-cycle-of-knowledge-in-big-language</guid>
    </item>
    <item>
      <title>Evaluation of ChatGPT as a Question Answering System for Answering Complex Questions</title>
      <link>https://paperswithcode.com/paper/evaluation-of-chatgpt-as-a-question-answering</link>
      <description><![CDATA[As ChatGPT covers resources such as Wikipedia and supports natural language question answering, it has garnered attention as a potential replacement for traditional knowledge based question answering (KBQA) models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluation-of-chatgpt-as-a-question-answering</guid>
    </item>
    <item>
      <title>Sequential three-way decisions with a single hidden layer feedforward neural network</title>
      <link>https://paperswithcode.com/paper/sequential-three-way-decisions-with-a-single</link>
      <description><![CDATA[The experimental results verify that STWD-SFNN has a more compact network on structured datasets than other SFNN models, and has better generalization performance than the competitive models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sequential-three-way-decisions-with-a-single</guid>
    </item>
    <item>
      <title>On the Implicit Geometry of Cross-Entropy Parameterizations for Label-Imbalanced Data</title>
      <link>https://paperswithcode.com/paper/on-the-implicit-geometry-of-cross-entropy</link>
      <description><![CDATA[Aiming to extend this theory to non-linear models, we investigate the implicit geometry of classifiers and embeddings that are learned by different CE parameterizations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-implicit-geometry-of-cross-entropy</guid>
    </item>
    <item>
      <title>Multiway clustering of 3-order tensor via affinity matrix</title>
      <link>https://paperswithcode.com/paper/multiway-clustering-of-3-order-tensor-via</link>
      <description><![CDATA[We propose a new method of multiway clustering for 3-order tensors via affinity matrix (MCAM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiway-clustering-of-3-order-tensor-via</guid>
    </item>
    <item>
      <title>Relational Multi-Task Learning: Modeling Relations between Data and Tasks</title>
      <link>https://paperswithcode.com/paper/relational-multi-task-learning-modeling-1</link>
      <description><![CDATA[Here we introduce a novel relational multi-task learning setting where we leverage data point labels from auxiliary tasks to make more accurate predictions on the new task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relational-multi-task-learning-modeling-1</guid>
    </item>
    <item>
      <title>GPT-4 Technical Report</title>
      <link>https://paperswithcode.com/paper/gpt-4-technical-report</link>
      <description><![CDATA[We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-4-technical-report</guid>
    </item>
    <item>
      <title>LayoutDM: Discrete Diffusion Model for Controllable Layout Generation</title>
      <link>https://paperswithcode.com/paper/layoutdm-discrete-diffusion-model-for</link>
      <description><![CDATA[Controllable layout generation aims at synthesizing plausible arrangement of element bounding boxes with optional constraints, such as type or position of a specific element.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/layoutdm-discrete-diffusion-model-for</guid>
    </item>
    <item>
      <title>Implant Global and Local Hierarchy Information to Sequence based Code Representation Models</title>
      <link>https://paperswithcode.com/paper/implant-global-and-local-hierarchy</link>
      <description><![CDATA[Furthermore, we propose the Hierarchy Transformer (HiT), a simple but effective sequence model to incorporate the complete hierarchical embeddings of source code into a Transformer model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implant-global-and-local-hierarchy</guid>
    </item>
    <item>
      <title>A Simple Framework for Open-Vocabulary Segmentation and Detection</title>
      <link>https://paperswithcode.com/paper/a-simple-framework-for-open-vocabulary</link>
      <description><![CDATA[We present \ourmodel{}, a simple Open-vocabulary Segmentation and Detection framework that jointly learns from different segmentation and detection datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-simple-framework-for-open-vocabulary</guid>
    </item>
    <item>
      <title>Diversity-Aware Meta Visual Prompting</title>
      <link>https://paperswithcode.com/paper/diversity-aware-meta-visual-prompting</link>
      <description><![CDATA[We present Diversity-Aware Meta Visual Prompting~(DAM-VP), an efficient and effective prompting method for transferring pre-trained models to downstream tasks with frozen backbone.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diversity-aware-meta-visual-prompting</guid>
    </item>
    <item>
      <title>Optimizing Deep Learning Model Parameters with the Bees Algorithm for Improved Medical Text Classification</title>
      <link>https://paperswithcode.com/paper/optimizing-deep-learning-model-parameters</link>
      <description><![CDATA[This paper introduces a novel mechanism to obtain the optimal parameters of a deep learning model using the Bees Algorithm, which is a recent promising swarm intelligence algorithm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimizing-deep-learning-model-parameters</guid>
    </item>
    <item>
      <title>A CNN Based Framework for Unistroke Numeral Recognition in Air-Writing</title>
      <link>https://paperswithcode.com/paper/a-cnn-based-framework-for-unistroke-numeral</link>
      <description><![CDATA[Air-writing refers to virtually writing linguistic characters through hand gestures in three-dimensional space with six degrees of freedom.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-cnn-based-framework-for-unistroke-numeral</guid>
    </item>
    <item>
      <title>Automated Ensemble Search Framework for Semantic Segmentation Using Medical Imaging Labels</title>
      <link>https://paperswithcode.com/paper/automated-ensemble-search-framework-for</link>
      <description><![CDATA[Reliable classification and detection of certain medical conditions, in images, with state-of-the-art semantic segmentation networks, require vast amounts of pixel-wise annotation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automated-ensemble-search-framework-for</guid>
    </item>
    <item>
      <title>Alias-Free Convnets: Fractional Shift Invariance via Polynomial Activations</title>
      <link>https://paperswithcode.com/paper/alias-free-convnets-fractional-shift</link>
      <description><![CDATA[Although CNNs are believed to be invariant to translations, recent works have shown this is not the case, due to aliasing effects that stem from downsampling layers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alias-free-convnets-fractional-shift</guid>
    </item>
    <item>
      <title>Window-Based Early-Exit Cascades for Uncertainty Estimation: When Deep Ensembles are More Efficient than Single Models</title>
      <link>https://paperswithcode.com/paper/window-based-early-exit-cascades-for</link>
      <description><![CDATA[Experiments on ImageNet-scale data across a number of network architectures and uncertainty tasks show that the proposed window-based early-exit approach is able to achieve a superior uncertainty-computation trade-off compared to scaling single models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/window-based-early-exit-cascades-for</guid>
    </item>
    <item>
      <title>Calibrated Teacher for Sparsely Annotated Object Detection</title>
      <link>https://paperswithcode.com/paper/calibrated-teacher-for-sparsely-annotated</link>
      <description><![CDATA[Recent works on sparsely annotated object detection alleviate this problem by generating pseudo labels for the missing annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/calibrated-teacher-for-sparsely-annotated</guid>
    </item>
    <item>
      <title>Editing Implicit Assumptions in Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/editing-implicit-assumptions-in-text-to-image</link>
      <description><![CDATA[Our Text-to-Image Model Editing method, TIME for short, receives a pair of inputs: a "source" under-specified prompt for which the model makes an implicit assumption (e. g., "a pack of roses"), and a "destination" prompt that describes the same setting, but with a specified desired attribute (e. g., "a pack of blue roses").]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/editing-implicit-assumptions-in-text-to-image</guid>
    </item>
    <item>
      <title>Image Label based Semantic Segmentation Framework using Object Perimeters</title>
      <link>https://paperswithcode.com/paper/image-label-based-semantic-segmentation</link>
      <description><![CDATA[Our new PerimeterFit module will be applied to pre-refine the CAM predictions before using the pixel-similarity-based network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/image-label-based-semantic-segmentation</guid>
    </item>
    <item>
      <title>InstMove: Instance Motion for Object-centric Video Segmentation</title>
      <link>https://paperswithcode.com/paper/instmove-instance-motion-for-object-centric</link>
      <description><![CDATA[A common solution is to use optical flow to provide motion information, but essentially it only considers pixel-level motion, which still relies on appearance similarity and hence is often inaccurate under occlusion and fast movement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instmove-instance-motion-for-object-centric</guid>
    </item>
    <item>
      <title>Blind Video Deflickering by Neural Filtering with a Flawed Atlas</title>
      <link>https://paperswithcode.com/paper/blind-video-deflickering-by-neural-filtering</link>
      <description><![CDATA[Prior work usually requires specific guidance such as the flickering frequency, manual annotations, or extra consistent videos to remove the flicker.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blind-video-deflickering-by-neural-filtering</guid>
    </item>
    <item>
      <title>DynaMask: Dynamic Mask Selection for Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/dynamask-dynamic-mask-selection-for-instance</link>
      <description><![CDATA[The representative instance segmentation methods mostly segment different object instances with a mask of the fixed resolution, e. g., 28*28 grid.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamask-dynamic-mask-selection-for-instance</guid>
    </item>
    <item>
      <title>PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/pimae-point-cloud-and-image-interactive</link>
      <description><![CDATA[Masked Autoencoders learn strong visual representations and achieve state-of-the-art results in several independent modalities, yet very few works have addressed their capabilities in multi-modality settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pimae-point-cloud-and-image-interactive</guid>
    </item>
    <item>
      <title>Automated Self-Supervised Learning for Recommendation</title>
      <link>https://paperswithcode.com/paper/automated-self-supervised-learning-for</link>
      <description><![CDATA[This does not generalize across different datasets and downstream recommendation tasks, which is difficult to be adaptive for data augmentation and robust to noise perturbation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automated-self-supervised-learning-for</guid>
    </item>
    <item>
      <title>Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis</title>
      <link>https://paperswithcode.com/paper/parameter-is-not-all-you-need-starting-from</link>
      <description><![CDATA[We present a Non-parametric Network for 3D point cloud analysis, Point-NN, which consists of purely non-learnable components: farthest point sampling (FPS), k-nearest neighbors (k-NN), and pooling operations, with trigonometric functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parameter-is-not-all-you-need-starting-from</guid>
    </item>
    <item>
      <title>AGTGAN: Unpaired Image Translation for Photographic Ancient Character Generation</title>
      <link>https://paperswithcode.com/paper/agtgan-unpaired-image-translation-for</link>
      <description><![CDATA[We evaluate our approach on the photographic ancient character datasets, e. g., OBC306 and CSDD.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agtgan-unpaired-image-translation-for</guid>
    </item>
    <item>
      <title>TriDet: Temporal Action Detection with Relative Boundary Modeling</title>
      <link>https://paperswithcode.com/paper/tridet-temporal-action-detection-with</link>
      <description><![CDATA[In this paper, we present a one-stage framework TriDet for temporal action detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tridet-temporal-action-detection-with</guid>
    </item>
    <item>
      <title>Challenges and Practices of Deep Learning Model Reengineering: A Case Study on Computer Vision</title>
      <link>https://paperswithcode.com/paper/challenges-and-practices-of-deep-learning</link>
      <description><![CDATA[We describe this process as deep learning model reengineering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/challenges-and-practices-of-deep-learning</guid>
    </item>
    <item>
      <title>CrossFormer++: A Versatile Vision Transformer Hinging on Cross-scale Attention</title>
      <link>https://paperswithcode.com/paper/crossformer-a-versatile-vision-transformer-1</link>
      <description><![CDATA[On the one hand, CEL blends each token with multiple patches of different scales, providing the self-attention module itself with cross-scale features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/crossformer-a-versatile-vision-transformer-1</guid>
    </item>
    <item>
      <title>Domain Generalization via Nuclear Norm Regularization</title>
      <link>https://paperswithcode.com/paper/domain-generalization-via-nuclear-norm</link>
      <description><![CDATA[In this paper, we propose a simple and effective regularization method based on the nuclear norm of the learned features for domain generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-generalization-via-nuclear-norm</guid>
    </item>
    <item>
      <title>OTOV2: Automatic, Generic, User-Friendly</title>
      <link>https://paperswithcode.com/paper/otov2-automatic-generic-user-friendly</link>
      <description><![CDATA[We propose the second generation of Only-Train-Once (OTOv2), which first automatically trains and compresses a general DNN only once from scratch to produce a more compact model with competitive performance without fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/otov2-automatic-generic-user-friendly</guid>
    </item>
    <item>
      <title>Contextually-rich human affect perception using multimodal scene information</title>
      <link>https://paperswithcode.com/paper/contextually-rich-human-affect-perception</link>
      <description><![CDATA[The process of human affect understanding involves the ability to infer person specific emotional states from various sources including images, speech, and language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contextually-rich-human-affect-perception</guid>
    </item>
    <item>
      <title>Unsupervised Representation Learning in Partially Observable Atari Games</title>
      <link>https://paperswithcode.com/paper/unsupervised-representation-learning-in</link>
      <description><![CDATA[Contrastive methods have performed better than generative models in previous state representation learning research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-representation-learning-in</guid>
    </item>
    <item>
      <title>High-throughput Generative Inference of Large Language Models with a Single GPU</title>
      <link>https://paperswithcode.com/paper/high-throughput-generative-inference-of-large</link>
      <description><![CDATA[As a result, when running OPT-175B on a single 16GB GPU, FlexGen achieves significantly higher throughput compared to state-of-the-art offloading systems, reaching a generation throughput of 1 token/s for the first time with an effective batch size of 144.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-throughput-generative-inference-of-large</guid>
    </item>
    <item>
      <title>One-Shot Segmentation of Novel White Matter Tracts via Extensive Data Augmentation</title>
      <link>https://paperswithcode.com/paper/one-shot-segmentation-of-novel-white-matter</link>
      <description><![CDATA[However, accurate segmentation of novel WM tracts can still be challenging in the one-shot setting, where only one scan is annotated for the novel WM tracts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-shot-segmentation-of-novel-white-matter</guid>
    </item>
    <item>
      <title>ST360IQ: No-Reference Omnidirectional Image Quality Assessment with Spherical Vision Transformers</title>
      <link>https://paperswithcode.com/paper/st360iq-no-reference-omnidirectional-image</link>
      <description><![CDATA[As their popularity has increased dramatically in recent years, evaluating the quality of 360 images has become a problem of interest since it provides insights for capturing, transmitting, and consuming this new media.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/st360iq-no-reference-omnidirectional-image</guid>
    </item>
    <item>
      <title>TranSG: Transformer-Based Skeleton Graph Prototype Contrastive Learning with Structure-Trajectory Prompted Reconstruction for Person Re-Identification</title>
      <link>https://paperswithcode.com/paper/transg-transformer-based-skeleton-graph</link>
      <description><![CDATA[Then, we propose the Graph Prototype Contrastive learning (GPC) to mine the most typical graph features (graph prototypes) of each identity, and contrast the inherent similarity between graph representations and different prototypes from both skeleton and sequence levels to learn discriminative graph representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transg-transformer-based-skeleton-graph</guid>
    </item>
    <item>
      <title>Kernel Density Bayesian Inverse Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/kernel-density-bayesian-inverse-reinforcement</link>
      <description><![CDATA[Inverse reinforcement learning~(IRL) is a powerful framework to infer an agent's reward function by observing its behavior, but IRL algorithms that learn point estimates of the reward function can be misleading because there may be several functions that describe an agent's behavior equally well.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kernel-density-bayesian-inverse-reinforcement</guid>
    </item>
    <item>
      <title>Upcycling Models under Domain and Category Shift</title>
      <link>https://paperswithcode.com/paper/upcycling-models-under-domain-and-category</link>
      <description><![CDATA[We examine the superiority of our GLC on multiple benchmarks with different category shift scenarios, including partial-set, open-set, and open-partial-set DA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/upcycling-models-under-domain-and-category</guid>
    </item>
    <item>
      <title>Learning Distortion Invariant Representation for Image Restoration from A Causality Perspective</title>
      <link>https://paperswithcode.com/paper/learning-distortion-invariant-representation</link>
      <description><![CDATA[In this paper, we are the first to propose a novel training strategy for image restoration from the causality perspective, to improve the generalization ability of DNNs for unknown degradations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-distortion-invariant-representation</guid>
    </item>
    <item>
      <title>Super-Resolution Information Enhancement For Crowd Counting</title>
      <link>https://paperswithcode.com/paper/super-resolution-information-enhancement-for</link>
      <description><![CDATA[As the proposed method requires SR labels, we further propose a Super-Resolution Crowd Counting dataset (SR-Crowd).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/super-resolution-information-enhancement-for</guid>
    </item>
    <item>
      <title>I Don't Care Anymore: Identifying the Onset of Careless Responding</title>
      <link>https://paperswithcode.com/paper/i-don-t-care-anymore-identifying-the-onset-of</link>
      <description><![CDATA[We propose a novel method to identify the onset of careless responding (or an absence thereof) for each participant.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/i-don-t-care-anymore-identifying-the-onset-of</guid>
    </item>
  </channel>
</rss>
