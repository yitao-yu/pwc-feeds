<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 14 Aug 2023 21:06:09 +0000</lastBuildDate>
    <item>
      <title>Spatial-information Guided Adaptive Context-aware Network for Efficient RGB-D Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/spatial-information-guided-adaptive-context</link>
      <description><![CDATA[Efficient RGB-D semantic segmentation has received considerable attention in mobile robots, which plays a vital role in analyzing and recognizing environmental information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatial-information-guided-adaptive-context</guid>
    </item>
    <item>
      <title>MS3D++: Ensemble of Experts for Multi-Source Unsupervised Domain Adaption in 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/ms3d-ensemble-of-experts-for-multi-source</link>
      <description><![CDATA[MS3D++ provides a straightforward approach to domain adaptation by generating high-quality pseudo-labels, enabling the adaptation of 3D detectors to a diverse range of lidar types, regardless of their density.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ms3d-ensemble-of-experts-for-multi-source</guid>
    </item>
    <item>
      <title>Enhancing Generalization of Universal Adversarial Perturbation through Gradient Aggregation</title>
      <link>https://paperswithcode.com/paper/enhancing-generalization-of-universal</link>
      <description><![CDATA[Deep neural networks are vulnerable to universal adversarial perturbation (UAP), an instance-agnostic perturbation capable of fooling the target model for most samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-generalization-of-universal</guid>
    </item>
    <item>
      <title>LTP-MMF: Towards Long-term Provider Max-min Fairness Under Recommendation Feedback Loops</title>
      <link>https://paperswithcode.com/paper/ltp-mmf-towards-long-term-provider-max-min</link>
      <description><![CDATA[RFL means that recommender system can only receive feedback on exposed items from users and update recommender models incrementally based on this feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ltp-mmf-towards-long-term-provider-max-min</guid>
    </item>
    <item>
      <title>Generalizing Event-Based Motion Deblurring in Real-World Scenarios</title>
      <link>https://paperswithcode.com/paper/generalizing-event-based-motion-deblurring-in</link>
      <description><![CDATA[Event-based motion deblurring has shown promising results by exploiting low-latency events.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizing-event-based-motion-deblurring-in</guid>
    </item>
    <item>
      <title>Augmented Negative Sampling for Collaborative Filtering</title>
      <link>https://paperswithcode.com/paper/augmented-negative-sampling-for-collaborative</link>
      <description><![CDATA[To balance efficiency and effectiveness, the vast majority of existing methods follow the two-pass approach, in which the first pass samples a fixed number of unobserved items by a simple static distribution and then the second pass selects the final negative items using a more sophisticated negative sampling strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/augmented-negative-sampling-for-collaborative</guid>
    </item>
    <item>
      <title>Head Rotation in Denoising Diffusion Models</title>
      <link>https://paperswithcode.com/paper/head-rotation-in-denoising-diffusion-models</link>
      <description><![CDATA[Denoising Diffusion Models (DDM) are emerging as the cutting-edge technology in the realm of deep generative modeling, challenging the dominance of Generative Adversarial Networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/head-rotation-in-denoising-diffusion-models</guid>
    </item>
    <item>
      <title>Nonlinear Permuted Granger Causality</title>
      <link>https://paperswithcode.com/paper/nonlinear-permuted-granger-causality</link>
      <description><![CDATA[Granger causal inference is a contentious but widespread method used in fields ranging from economics to neuroscience.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nonlinear-permuted-granger-causality</guid>
    </item>
    <item>
      <title>Change Point Detection With Conceptors</title>
      <link>https://paperswithcode.com/paper/change-point-detection-with-conceptors</link>
      <description><![CDATA[For the at most one change point problem, we propose the use of a conceptor matrix to learn the characteristic dynamics of a specified training window in a time series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/change-point-detection-with-conceptors</guid>
    </item>
    <item>
      <title>Learned Point Cloud Compression for Classification</title>
      <link>https://paperswithcode.com/paper/learned-point-cloud-compression-for</link>
      <description><![CDATA[Our codec demonstrates the potential of specialized codecs for machine analysis of point clouds, and provides a basis for extension to more complex tasks and datasets in the future.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learned-point-cloud-compression-for</guid>
    </item>
    <item>
      <title>Exploring Predicate Visual Context in Detecting of Human-Object Interactions</title>
      <link>https://paperswithcode.com/paper/exploring-predicate-visual-context-in</link>
      <description><![CDATA[Recently, the DETR framework has emerged as the dominant approach for human--object interaction (HOI) research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-predicate-visual-context-in</guid>
    </item>
    <item>
      <title>FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods</title>
      <link>https://paperswithcode.com/paper/funnybirds-a-synthetic-vision-dataset-for-a</link>
      <description><![CDATA[Using our tools, we report results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/funnybirds-a-synthetic-vision-dataset-for-a</guid>
    </item>
    <item>
      <title>Semantics2Hands: Transferring Hand Motion Semantics between Avatars</title>
      <link>https://paperswithcode.com/paper/semantics2hands-transferring-hand-motion</link>
      <description><![CDATA[Human hands, the primary means of non-verbal communication, convey intricate semantics in various scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantics2hands-transferring-hand-motion</guid>
    </item>
    <item>
      <title>Diffusion-based Visual Counterfactual Explanations -- Towards Systematic Quantitative Evaluation</title>
      <link>https://paperswithcode.com/paper/diffusion-based-visual-counterfactual</link>
      <description><![CDATA[Latest methods for visual counterfactual explanations (VCE) harness the power of deep generative models to synthesize new examples of high-dimensional images of impressive quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-based-visual-counterfactual</guid>
    </item>
    <item>
      <title>Uncertainty Quantification for Image-based Traffic Prediction across Cities</title>
      <link>https://paperswithcode.com/paper/uncertainty-quantification-for-image-based</link>
      <description><![CDATA[We compare two epistemic and two aleatoric UQ methods on both temporal and spatio-temporal transfer tasks, and find that meaningful uncertainty estimates can be recovered.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncertainty-quantification-for-image-based</guid>
    </item>
    <item>
      <title>A Game-Theoretic Framework for Joint Forecasting and Planning</title>
      <link>https://paperswithcode.com/paper/a-game-theoretic-framework-for-joint</link>
      <description><![CDATA[On the other hand, planning for worst-case motions leads to overtly conservative behavior and a ``frozen robot''.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-game-theoretic-framework-for-joint</guid>
    </item>
    <item>
      <title>Toward a Better Understanding of Loss Functions for Collaborative Filtering</title>
      <link>https://paperswithcode.com/paper/toward-a-better-understanding-of-loss</link>
      <description><![CDATA[Inspired by this analysis, we propose a novel loss function that improves the design of alignment and uniformity considering the unique patterns of datasets called Margin-aware Alignment and Weighted Uniformity (MAWU).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toward-a-better-understanding-of-loss</guid>
    </item>
    <item>
      <title>Scale-Preserving Automatic Concept Extraction (SPACE)</title>
      <link>https://paperswithcode.com/paper/scale-preserving-automatic-concept-extraction</link>
      <description><![CDATA[Convolutional Neural Networks (CNN) have become a common choice for industrial quality control, as well as other critical applications in the Industry 4. 0.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scale-preserving-automatic-concept-extraction</guid>
    </item>
    <item>
      <title>Identification of the Relevance of Comments in Codes Using Bag of Words and Transformer Based Models</title>
      <link>https://paperswithcode.com/paper/identification-of-the-relevance-of-comments</link>
      <description><![CDATA[The performance of the classical bag of words model and transformer-based models were explored to identify significant features from the given training corpus.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/identification-of-the-relevance-of-comments</guid>
    </item>
    <item>
      <title>DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models</title>
      <link>https://paperswithcode.com/paper/datasetdm-synthesizing-data-with-perception</link>
      <description><![CDATA[To showcase the power of the proposed approach, we generate datasets with rich dense pixel-wise labels for a wide range of downstream tasks, including semantic segmentation, instance segmentation, and depth estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datasetdm-synthesizing-data-with-perception</guid>
    </item>
    <item>
      <title>Taming the Power of Diffusion Models for High-Quality Virtual Try-On with Appearance Flow</title>
      <link>https://paperswithcode.com/paper/taming-the-power-of-diffusion-models-for-high</link>
      <description><![CDATA[Our approach, namely Diffusion-based Conditional Inpainting for Virtual Try-ON (DCI-VTON), effectively utilizes the power of the diffusion model, and the incorporation of the warping module helps to produce high-quality and realistic virtual try-on results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taming-the-power-of-diffusion-models-for-high</guid>
    </item>
    <item>
      <title>LittleMu: Deploying an Online Virtual Teaching Assistant via Heterogeneous Sources Integration and Chain of Teach Prompts</title>
      <link>https://paperswithcode.com/paper/littlemu-deploying-an-online-virtual-teaching</link>
      <description><![CDATA[However, few MOOC platforms are providing human or virtual teaching assistants to support learning for massive online students due to the complexity of real-world online education scenarios and the lack of training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/littlemu-deploying-an-online-virtual-teaching</guid>
    </item>
    <item>
      <title>FoodSAM: Any Food Segmentation</title>
      <link>https://paperswithcode.com/paper/foodsam-any-food-segmentation</link>
      <description><![CDATA[Remarkably, this pioneering framework stands as the first-ever work to achieve instance, panoptic, and promptable segmentation on food images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foodsam-any-food-segmentation</guid>
    </item>
    <item>
      <title>Complex Facial Expression Recognition Using Deep Knowledge Distillation of Basic Features</title>
      <link>https://paperswithcode.com/paper/complex-facial-expression-recognition-using</link>
      <description><![CDATA[Our method achieves the current state-of-the-art in continual learning for complex facial expression recognition with 74. 28% Overall Accuracy on new classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/complex-facial-expression-recognition-using</guid>
    </item>
    <item>
      <title>KETM:A Knowledge-Enhanced Text Matching method</title>
      <link>https://paperswithcode.com/paper/ketm-a-knowledge-enhanced-text-matching</link>
      <description><![CDATA[To this end, in this paper, We introduce a new model for text matching called the Knowledge Enhanced Text Matching model (KETM), to enrich contextual representations with real-world common-sense knowledge from external knowledge sources to enhance our model understanding and reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ketm-a-knowledge-enhanced-text-matching</guid>
    </item>
    <item>
      <title>Cyclic-Bootstrap Labeling for Weakly Supervised Object Detection</title>
      <link>https://paperswithcode.com/paper/cyclic-bootstrap-labeling-for-weakly</link>
      <description><![CDATA[These inaccurate high-scoring region proposals will mislead the training of subsequent refinement modules and thus hamper the detection performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cyclic-bootstrap-labeling-for-weakly</guid>
    </item>
    <item>
      <title>TrajPAC: Towards Robustness Verification of Pedestrian Trajectory Prediction Models</title>
      <link>https://paperswithcode.com/paper/trajpac-towards-robustness-verification-of</link>
      <description><![CDATA[Firstly, the previous definitions of robustness in trajectory prediction are ambiguous.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trajpac-towards-robustness-verification-of</guid>
    </item>
    <item>
      <title>Foundation Model is Efficient Multimodal Multitask Model Selector</title>
      <link>https://paperswithcode.com/paper/foundation-model-is-efficient-multimodal</link>
      <description><![CDATA[This paper investigates an under-explored but important problem: given a collection of pre-trained neural networks, predicting their performance on each multi-modal task without fine-tuning them, such as image recognition, referring, captioning, visual question answering, and text question answering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundation-model-is-efficient-multimodal</guid>
    </item>
    <item>
      <title>Unleashing the Strengths of Unlabeled Data in Pan-cancer Abdominal Organ Quantification: the FLARE22 Challenge</title>
      <link>https://paperswithcode.com/paper/unleashing-the-strengths-of-unlabeled-data-in</link>
      <description><![CDATA[The best-performing algorithms successfully generalized to holdout external validation sets, achieving a median DSC of 89. 5\%, 90. 9\%, and 88. 3\% on North American, European, and Asian cohorts, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unleashing-the-strengths-of-unlabeled-data-in</guid>
    </item>
    <item>
      <title>Recognizing Handwritten Mathematical Expressions of Vertical Addition and Subtraction</title>
      <link>https://paperswithcode.com/paper/recognizing-handwritten-mathematical-1</link>
      <description><![CDATA[We also proposed a transcription method to map the bounding boxes from the object detection stage to a mathematical expression in the LATEX markup sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recognizing-handwritten-mathematical-1</guid>
    </item>
    <item>
      <title>GPLaSDI: Gaussian Process-based Interpretable Latent Space Dynamics Identification through Deep Autoencoder</title>
      <link>https://paperswithcode.com/paper/gplasdi-gaussian-process-based-interpretable</link>
      <description><![CDATA[By interpolating and solving the ODE system in the reduced latent space, fast and accurate ROM predictions can be made by feeding the predicted latent space dynamics into the decoder.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gplasdi-gaussian-process-based-interpretable</guid>
    </item>
    <item>
      <title>Deep generative models for unsupervised delamination detection using guided waves</title>
      <link>https://paperswithcode.com/paper/deep-generative-models-for-unsupervised</link>
      <description><![CDATA[With the rising demands for robust structural health monitoring procedures for aerospace structures, the scope of intelligent algorithms and learning techniques is expanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-generative-models-for-unsupervised</guid>
    </item>
    <item>
      <title>Multi-domain Recommendation with Embedding Disentangling and Domain Alignment</title>
      <link>https://paperswithcode.com/paper/multi-domain-recommendation-with-embedding</link>
      <description><![CDATA[We propose a new MDR method named EDDA with two key components, i. e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-domain-recommendation-with-embedding</guid>
    </item>
    <item>
      <title>Information decomposition reveals hidden high-order contributions to temporal irreversibility</title>
      <link>https://paperswithcode.com/paper/information-decomposition-reveals-hidden-high</link>
      <description><![CDATA[Temporal irreversibility, often referred to as the arrow of time, is a fundamental concept in statistical mechanics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/information-decomposition-reveals-hidden-high</guid>
    </item>
    <item>
      <title>Double-chain Constraints for 3D Human Pose Estimation in Images and Videos</title>
      <link>https://paperswithcode.com/paper/double-chain-constraints-for-3d-human-pose</link>
      <description><![CDATA[Notably, our model achieves state-of-the-art performance on all action categories in the Human3. 6M dataset using detected 2D poses from CPN, and our code is available at: https://github. com/KHB1698/DC-GCT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/double-chain-constraints-for-3d-human-pose</guid>
    </item>
    <item>
      <title>Deep Fusion Transformer Network with Weighted Vector-Wise Keypoints Voting for Robust 6D Object Pose Estimation</title>
      <link>https://paperswithcode.com/paper/deep-fusion-transformer-network-with-weighted</link>
      <description><![CDATA[One critical challenge in 6D object pose estimation from a single RGBD image is efficient integration of two different modalities, i. e., color and depth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-fusion-transformer-network-with-weighted</guid>
    </item>
    <item>
      <title>Follow Anything: Open-set detection, tracking, and following in real-time</title>
      <link>https://paperswithcode.com/paper/follow-anything-open-set-detection-tracking</link>
      <description><![CDATA[We demonstrate FAn on a real-world robotic system (a micro aerial vehicle) and report its ability to seamlessly follow the objects of interest in a real-time control loop.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/follow-anything-open-set-detection-tracking</guid>
    </item>
    <item>
      <title>High-performance Data Management for Whole Slide Image Analysis in Digital Pathology</title>
      <link>https://paperswithcode.com/paper/high-performance-data-management-for-whole</link>
      <description><![CDATA[The performance evaluation encompasses two key scenarios: (1) a pure CPU-based image analysis scenario (termed the "CPU scenario"), and (2) a GPU-based deep learning framework scenario (referred to as the "GPU scenario").]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-performance-data-management-for-whole</guid>
    </item>
    <item>
      <title>Pseudo-label Alignment for Semi-supervised Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/pseudo-label-alignment-for-semi-supervised</link>
      <description><![CDATA[Through extensive experiments conducted on the COCO and Cityscapes datasets, we demonstrate that PAIS is a promising framework for semi-supervised instance segmentation, particularly in cases where labeled data is severely limited.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pseudo-label-alignment-for-semi-supervised</guid>
    </item>
    <item>
      <title>Deformable Mixer Transformer with Gating for Multi-Task Learning of Dense Prediction</title>
      <link>https://paperswithcode.com/paper/deformable-mixer-transformer-with-gating-for</link>
      <description><![CDATA[In this work, we present a novel MTL model by combining both merits of deformable CNN and query-based Transformer with shared gating for multi-task learning of dense prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deformable-mixer-transformer-with-gating-for</guid>
    </item>
    <item>
      <title>Is there progress in activity progress prediction?</title>
      <link>https://paperswithcode.com/paper/is-there-progress-in-activity-progress</link>
      <description><![CDATA[We conclude that the progress prediction task is ill-posed on the currently used real-world datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-there-progress-in-activity-progress</guid>
    </item>
    <item>
      <title>Progressive Spatio-temporal Perception for Audio-Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/progressive-spatio-temporal-perception-for</link>
      <description><![CDATA[Such naturally multi-modal videos are composed of rich and complex dynamic audio-visual components, where most of which could be unrelated to the given questions, or even play as interference in answering the content of interest.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progressive-spatio-temporal-perception-for</guid>
    </item>
    <item>
      <title>Temporally-Adaptive Models for Efficient Video Understanding</title>
      <link>https://paperswithcode.com/paper/temporally-adaptive-models-for-efficient</link>
      <description><![CDATA[Spatial convolutions are extensively used in numerous deep video models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporally-adaptive-models-for-efficient</guid>
    </item>
    <item>
      <title>Speech-Driven 3D Face Animation with Composite and Regional Facial Movements</title>
      <link>https://paperswithcode.com/paper/speech-driven-3d-face-animation-with</link>
      <description><![CDATA[This paper emphasizes the importance of considering both the composite and regional natures of facial movements in speech-driven 3D face animation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/speech-driven-3d-face-animation-with</guid>
    </item>
    <item>
      <title>Surface Masked AutoEncoder: Self-Supervision for Cortical Imaging Data</title>
      <link>https://paperswithcode.com/paper/surface-masked-autoencoder-self-supervision</link>
      <description><![CDATA[By reconstructing surface data from a masked version of the input, the proposed method effectively models cortical structure to learn strong representations that translate to improved performance in downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surface-masked-autoencoder-self-supervision</guid>
    </item>
    <item>
      <title>Enhancing Low-light Light Field Images with A Deep Compensation Unfolding Network</title>
      <link>https://paperswithcode.com/paper/enhancing-low-light-light-field-images-with-a</link>
      <description><![CDATA[This paper presents a novel and interpretable end-to-end learning framework, called the deep compensation unfolding network (DCUNet), for restoring light field (LF) images captured under low-light conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-low-light-light-field-images-with-a</guid>
    </item>
    <item>
      <title>PoseBusters: AI-based docking methods fail to generate physically valid poses or generalise to novel sequences</title>
      <link>https://paperswithcode.com/paper/posebusters-ai-based-docking-methods-fail-to</link>
      <description><![CDATA[The last few years have seen the development of numerous deep learning-based protein-ligand docking methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posebusters-ai-based-docking-methods-fail-to</guid>
    </item>
    <item>
      <title>RLSAC: Reinforcement Learning enhanced Sample Consensus for End-to-End Robust Estimation</title>
      <link>https://paperswithcode.com/paper/rlsac-reinforcement-learning-enhanced-sample</link>
      <description><![CDATA[Therefore, RLSAC can avoid differentiating to learn the features and the feedback of downstream tasks for end-to-end robust estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rlsac-reinforcement-learning-enhanced-sample</guid>
    </item>
    <item>
      <title>Interaction-aware Joint Attention Estimation Using People Attributes</title>
      <link>https://paperswithcode.com/paper/interaction-aware-joint-attention-estimation</link>
      <description><![CDATA[We introduce a specialized MLP head with positional embedding to the Transformer so that it predicts pixelwise confidence of joint attention for generating the confidence heatmap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interaction-aware-joint-attention-estimation</guid>
    </item>
    <item>
      <title>A Comparative Visual Analytics Framework for Evaluating Evolutionary Processes in Multi-objective Optimization</title>
      <link>https://paperswithcode.com/paper/a-comparative-visual-analytics-framework-for</link>
      <description><![CDATA[Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparative-visual-analytics-framework-for</guid>
    </item>
  </channel>
</rss>
