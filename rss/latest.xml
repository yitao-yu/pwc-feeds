<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 01 Feb 2024 21:06:16 +0000</lastBuildDate>
    <item>
      <title>Recurrent Partial Kernel Network for Efficient Optical Flow Estimation</title>
      <link>https://paperswithcode.com/paper/recurrent-partial-kernel-network-for</link>
      <description><![CDATA[However, this impacts the widespread adoption of optical flow methods and makes it harder to train more general models since the optical flow data is hard to obtain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recurrent-partial-kernel-network-for</guid>
    </item>
    <item>
      <title>Dendritic Learning-incorporated Vision Transformer for Image Recognition</title>
      <link>https://paperswithcode.com/paper/dendritic-learning-incorporated-vision</link>
      <description><![CDATA[DVT is a groundbreaking Biomimetic Vision Transformer that combines dendritic learning and Vision Transformer architecture, showcasing superior image recognition performance through biologically inspired structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dendritic-learning-incorporated-vision</guid>
    </item>
    <item>
      <title>SNP-S3: Shared Network Pre-training and Significant Semantic Strengthening for Various Video-Text Tasks</title>
      <link>https://paperswithcode.com/paper/snp-s3-shared-network-pre-training-and</link>
      <description><![CDATA[By employing one shared BERT-type network to refine textual and cross-modal features simultaneously, SNP is lightweight and could support various downstream applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/snp-s3-shared-network-pre-training-and</guid>
    </item>
    <item>
      <title>PF-GNN: Differentiable particle filtering based approximation of universal graph representations</title>
      <link>https://paperswithcode.com/paper/pf-gnn-differentiable-particle-filtering-1</link>
      <description><![CDATA[Message passing Graph Neural Networks (GNNs) are known to be limited in expressive power by the 1-WL color-refinement test for graph isomorphism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pf-gnn-differentiable-particle-filtering-1</guid>
    </item>
    <item>
      <title>A Policy Gradient Primal-Dual Algorithm for Constrained MDPs with Uniform PAC Guarantees</title>
      <link>https://paperswithcode.com/paper/a-policy-gradient-primal-dual-algorithm-for</link>
      <description><![CDATA[We study a primal-dual reinforcement learning (RL) algorithm for the online constrained Markov decision processes (CMDP) problem, wherein the agent explores an optimal policy that maximizes return while satisfying constraints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-policy-gradient-primal-dual-algorithm-for</guid>
    </item>
    <item>
      <title>Improved Scene Landmark Detection for Camera Localization</title>
      <link>https://paperswithcode.com/paper/improved-scene-landmark-detection-for-camera</link>
      <description><![CDATA[To mitigate the capacity issue, we propose to split the landmarks into subgroups and train a separate network for each subgroup.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-scene-landmark-detection-for-camera</guid>
    </item>
    <item>
      <title>Datacube segmentation via Deep Spectral Clustering</title>
      <link>https://paperswithcode.com/paper/datacube-segmentation-via-deep-spectral</link>
      <description><![CDATA[Extended Vision techniques are ubiquitous in physics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datacube-segmentation-via-deep-spectral</guid>
    </item>
    <item>
      <title>Data-Effective Learning: A Comprehensive Medical Benchmark</title>
      <link>https://paperswithcode.com/paper/data-effective-learning-a-comprehensive</link>
      <description><![CDATA[This benchmark includes a dataset with millions of data samples from 31 medical centers (DataDEL), a baseline method for comparison (MedDEL), and a new evaluation metric (NormDEL) to objectively measure data-effective learning performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-effective-learning-a-comprehensive</guid>
    </item>
    <item>
      <title>LaneGraph2Seq: Lane Topology Extraction with Language Model via Vertex-Edge Encoding and Connectivity Enhancement</title>
      <link>https://paperswithcode.com/paper/lanegraph2seq-lane-topology-extraction-with</link>
      <description><![CDATA[Accurate extraction of lane graphs relies on precisely estimating vertex and edge information within the DAG.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lanegraph2seq-lane-topology-extraction-with</guid>
    </item>
    <item>
      <title>Double InfoGAN for Contrastive Analysis</title>
      <link>https://paperswithcode.com/paper/double-infogan-for-contrastive-analysis</link>
      <description><![CDATA[Experimental results on four visual datasets, from simple synthetic examples to complex medical images, show that the proposed method outperforms SOTA CA-VAEs in terms of latent separation and image quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/double-infogan-for-contrastive-analysis</guid>
    </item>
    <item>
      <title>EnCLAP: Combining Neural Audio Codec and Audio-Text Joint Embedding for Automated Audio Captioning</title>
      <link>https://paperswithcode.com/paper/enclap-combining-neural-audio-codec-and-audio</link>
      <description><![CDATA[We also introduce a new training objective called masked codec modeling that improves acoustic awareness of the pretrained language model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enclap-combining-neural-audio-codec-and-audio</guid>
    </item>
    <item>
      <title>COMET: Contrastive Mean Teacher for Online Source-Free Universal Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/comet-contrastive-mean-teacher-for-online</link>
      <description><![CDATA[In real-world applications, there is often a domain shift from training to test data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comet-contrastive-mean-teacher-for-online</guid>
    </item>
    <item>
      <title>Towards Semantic Consistency: Dirichlet Energy Driven Robust Multi-Modal Entity Alignment</title>
      <link>https://paperswithcode.com/paper/towards-semantic-consistency-dirichlet-energy</link>
      <description><![CDATA[In Multi-Modal Knowledge Graphs (MMKGs), Multi-Modal Entity Alignment (MMEA) is crucial for identifying identical entities across diverse modal attributes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-semantic-consistency-dirichlet-energy</guid>
    </item>
    <item>
      <title>Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data</title>
      <link>https://paperswithcode.com/paper/good-at-captioning-bad-at-counting</link>
      <description><![CDATA[Large Vision-Language Models (VLMs) have demonstrated impressive performance on complex tasks involving visual input with natural language instructions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/good-at-captioning-bad-at-counting</guid>
    </item>
    <item>
      <title>LongAlign: A Recipe for Long Context Alignment of Large Language Models</title>
      <link>https://paperswithcode.com/paper/longalign-a-recipe-for-long-context-alignment</link>
      <description><![CDATA[Extending large language models to effectively handle long contexts requires instruction fine-tuning on input sequences of similar length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longalign-a-recipe-for-long-context-alignment</guid>
    </item>
    <item>
      <title>LOCOST: State-Space Models for Long Document Abstractive Summarization</title>
      <link>https://paperswithcode.com/paper/locost-state-space-models-for-long-document</link>
      <description><![CDATA[State-space models are a low-complexity alternative to transformers for encoding long sequences and capturing long-term dependencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/locost-state-space-models-for-long-document</guid>
    </item>
    <item>
      <title>Operator learning without the adjoint</title>
      <link>https://paperswithcode.com/paper/operator-learning-without-the-adjoint</link>
      <description><![CDATA[There is a mystery at the heart of operator learning: how can one recover a non-self-adjoint operator from data without probing the adjoint?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/operator-learning-without-the-adjoint</guid>
    </item>
    <item>
      <title>DROP: Decouple Re-Identification and Human Parsing with Task-specific Features for Occluded Person Re-identification</title>
      <link>https://paperswithcode.com/paper/drop-decouple-re-identification-and-human</link>
      <description><![CDATA[Unlike mainstream approaches using global features for simultaneous multi-task learning of ReID and human parsing, or relying on semantic information for attention guidance, DROP argues that the inferior performance of the former is due to distinct granularity requirements for ReID and human parsing features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drop-decouple-re-identification-and-human</guid>
    </item>
    <item>
      <title>Explainable Benchmarking for Iterative Optimization Heuristics</title>
      <link>https://paperswithcode.com/paper/explainable-benchmarking-for-iterative</link>
      <description><![CDATA[Introducing the IOH-Xplainer software framework, for analyzing and understanding the performance of various optimization algorithms and the impact of their different components and hyper-parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explainable-benchmarking-for-iterative</guid>
    </item>
    <item>
      <title>Controllable Dense Captioner with Multimodal Embedding Bridging</title>
      <link>https://paperswithcode.com/paper/controllable-dense-captioner-with-multimodal</link>
      <description><![CDATA[In this paper, we propose a controllable dense captioner (ControlCap), which accommodates user's intention to dense captioning by introducing linguistic guidance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controllable-dense-captioner-with-multimodal</guid>
    </item>
    <item>
      <title>Prompt-Driven LLM Safeguarding via Directed Representation Optimization</title>
      <link>https://paperswithcode.com/paper/prompt-driven-llm-safeguarding-via-directed</link>
      <description><![CDATA[Prepending model inputs with safety prompts is a common practice of safeguarding large language models (LLMs) from complying with queries that contain harmful intents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-driven-llm-safeguarding-via-directed</guid>
    </item>
    <item>
      <title>M2-RAAP: A Multi-Modal Recipe for Advancing Adaptation-based Pre-training towards Effective and Efficient Zero-shot Video-text Retrieval</title>
      <link>https://paperswithcode.com/paper/m2-raap-a-multi-modal-recipe-for-advancing</link>
      <description><![CDATA[We then summarize this empirical study into the M2-RAAP recipe, where our technical contributions lie in 1) the data filtering and text re-writing pipeline resulting in 1M high-quality bilingual video-text pairs, 2) the replacement of video inputs with key-frames to accelerate pre-training, and 3) the Auxiliary-Caption-Guided (ACG) strategy to enhance video features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/m2-raap-a-multi-modal-recipe-for-advancing</guid>
    </item>
    <item>
      <title>Entity Linking in the Job Market Domain</title>
      <link>https://paperswithcode.com/paper/entity-linking-in-the-job-market-domain</link>
      <description><![CDATA[In this work, we are the first to explore EL in this domain, specifically targeting the linkage of occupational skills to the ESCO taxonomy (le Vrang et al., 2014).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/entity-linking-in-the-job-market-domain</guid>
    </item>
    <item>
      <title>Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought Reasoning</title>
      <link>https://paperswithcode.com/paper/deductive-beam-search-decoding-deducible</link>
      <description><![CDATA[Recent advancements have significantly augmented the reasoning capabilities of Large Language Models (LLMs) through various methodologies, especially chain-of-thought (CoT) reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deductive-beam-search-decoding-deducible</guid>
    </item>
    <item>
      <title>WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts</title>
      <link>https://paperswithcode.com/paper/wsc-enhancing-the-winograd-schema-challenge</link>
      <description><![CDATA[The Winograd Schema Challenge (WSC) serves as a prominent benchmark for evaluating machine understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wsc-enhancing-the-winograd-schema-challenge</guid>
    </item>
    <item>
      <title>Hi-SAM: Marrying Segment Anything Model for Hierarchical Text Segmentation</title>
      <link>https://paperswithcode.com/paper/hi-sam-marrying-segment-anything-model-for</link>
      <description><![CDATA[In terms of the AMG mode, Hi-SAM segments text stroke foreground masks initially, then samples foreground points for hierarchical text mask generation and achieves layout analysis in passing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hi-sam-marrying-segment-anything-model-for</guid>
    </item>
    <item>
      <title>SimAda: A Simple Unified Framework for Adapting Segment Anything Model in Underperformed Scenes</title>
      <link>https://paperswithcode.com/paper/simada-a-simple-unified-framework-for</link>
      <description><![CDATA[In this paper, we aim to investigate the impact of the general vision modules on finetuning SAM and enable them to generalize across all downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simada-a-simple-unified-framework-for</guid>
    </item>
    <item>
      <title>An attempt to generate new bridge types from latent space of energy-based model</title>
      <link>https://paperswithcode.com/paper/an-attempt-to-generate-new-bridge-types-from-4</link>
      <description><![CDATA[Train energy function on symmetric structured image dataset of three span beam bridge, arch bridge, cable-stayed bridge, and suspension bridge to accurately calculate the energy values of real and fake samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-attempt-to-generate-new-bridge-types-from-4</guid>
    </item>
    <item>
      <title>Network-based Topic Structure Visualization</title>
      <link>https://paperswithcode.com/paper/network-based-topic-structure-visualization</link>
      <description><![CDATA[In the real world, many topics are inter-correlated, making it challenging to investigate their structure and relationships.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/network-based-topic-structure-visualization</guid>
    </item>
    <item>
      <title>Local and Global Contexts for Conversation</title>
      <link>https://paperswithcode.com/paper/local-and-global-contexts-for-conversation</link>
      <description><![CDATA[The context in conversation is the dialog history crucial for multi-turn dialogue.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/local-and-global-contexts-for-conversation</guid>
    </item>
    <item>
      <title>Graph Contrastive Learning with Cohesive Subgraph Awareness</title>
      <link>https://paperswithcode.com/paper/graph-contrastive-learning-with-cohesive</link>
      <description><![CDATA[However, such stochastic augmentations may severely damage the intrinsic properties of a graph and deteriorate the following representation learning process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-contrastive-learning-with-cohesive</guid>
    </item>
    <item>
      <title>Game-Theoretic Unlearnable Example Generator</title>
      <link>https://paperswithcode.com/paper/game-theoretic-unlearnable-example-generator</link>
      <description><![CDATA[Unlearnable example attacks are data poisoning attacks aiming to degrade the clean test accuracy of deep learning by adding imperceptible perturbations to the training samples, which can be formulated as a bi-level optimization problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/game-theoretic-unlearnable-example-generator</guid>
    </item>
    <item>
      <title>An Open Software Suite for Event-Based Video</title>
      <link>https://paperswithcode.com/paper/an-open-software-suite-for-event-based-video</link>
      <description><![CDATA[While traditional video representations are organized around discrete image frames, event-based video is a new paradigm that forgoes image frames altogether.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-open-software-suite-for-event-based-video</guid>
    </item>
    <item>
      <title>Using Motion Forecasting for Behavior-Based Virtual Reality (VR) Authentication</title>
      <link>https://paperswithcode.com/paper/using-motion-forecasting-for-behavior-based</link>
      <description><![CDATA[In this work, we present the first approach that predicts future user behavior using Transformer-based forecasting and using the forecasted trajectory to perform user authentication.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/using-motion-forecasting-for-behavior-based</guid>
    </item>
    <item>
      <title>CaMU: Disentangling Causal Effects in Deep Model Unlearning</title>
      <link>https://paperswithcode.com/paper/camu-disentangling-causal-effects-in-deep</link>
      <description><![CDATA[To address this shortcoming, the present study undertakes a causal analysis of the unlearning and introduces a novel framework termed Causal Machine Unlearning (CaMU).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camu-disentangling-causal-effects-in-deep</guid>
    </item>
    <item>
      <title>Checkmating One, by Using Many: Combining Mixture of Experts with MCTS to Improve in Chess</title>
      <link>https://paperswithcode.com/paper/checkmating-one-by-using-many-combining</link>
      <description><![CDATA[This paper presents a new approach that integrates deep learning with computational chess, using both the Mixture of Experts (MoE) method and Monte-Carlo Tree Search (MCTS).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/checkmating-one-by-using-many-combining</guid>
    </item>
    <item>
      <title>Zero-Shot Reinforcement Learning via Function Encoders</title>
      <link>https://paperswithcode.com/paper/zero-shot-reinforcement-learning-via-function</link>
      <description><![CDATA[Although reinforcement learning (RL) can solve many challenging sequential decision making problems, achieving zero-shot transfer across related tasks remains a challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-reinforcement-learning-via-function</guid>
    </item>
    <item>
      <title>Weak-to-Strong Jailbreaking on Large Language Models</title>
      <link>https://paperswithcode.com/paper/weak-to-strong-jailbreaking-on-large-language</link>
      <description><![CDATA[Upon examining the jailbreaking vulnerability of aligned LLMs, we observe that the decoding distributions of jailbroken and aligned models differ only in the initial generations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/weak-to-strong-jailbreaking-on-large-language</guid>
    </item>
    <item>
      <title>Non-central panorama indoor dataset</title>
      <link>https://paperswithcode.com/paper/non-central-panorama-indoor-dataset</link>
      <description><![CDATA[Omnidirectional images are one of the main sources of information for learning based scene understanding algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/non-central-panorama-indoor-dataset</guid>
    </item>
    <item>
      <title>H-SynEx: Using synthetic images and ultra-high resolution ex vivo MRI for hypothalamus subregion segmentation</title>
      <link>https://paperswithcode.com/paper/h-synex-using-synthetic-images-and-ultra-high</link>
      <description><![CDATA[Materials and Methods: We trained our deep learning method, H-synEx, with synthetic images derived from label maps built from ultra-high resolution ex vivo MRI scans, which enables finer-grained manual segmentation when compared with 1mm isometric in vivo images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h-synex-using-synthetic-images-and-ultra-high</guid>
    </item>
    <item>
      <title>MuSc: Zero-Shot Industrial Anomaly Classification and Segmentation with Mutual Scoring of the Unlabeled Images</title>
      <link>https://paperswithcode.com/paper/musc-zero-shot-industrial-anomaly</link>
      <description><![CDATA[We reveal that the abundant normal and abnormal cues implicit in unlabeled test images can be exploited for anomaly determination, which is ignored by prior methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/musc-zero-shot-industrial-anomaly</guid>
    </item>
    <item>
      <title>MT-Ranker: Reference-free machine translation evaluation by inter-system ranking</title>
      <link>https://paperswithcode.com/paper/mt-ranker-reference-free-machine-translation</link>
      <description><![CDATA[Traditionally, Machine Translation (MT) Evaluation has been treated as a regression problem -- producing an absolute translation-quality score.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mt-ranker-reference-free-machine-translation</guid>
    </item>
    <item>
      <title>Gazetteer-Enhanced Bangla Named Entity Recognition with BanglaBERT Semantic Embeddings K-Means-Infused CRF Model</title>
      <link>https://paperswithcode.com/paper/gazetteer-enhanced-bangla-named-entity</link>
      <description><![CDATA[In this research, we explored the existing state of research in Bangla Named Entity Recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gazetteer-enhanced-bangla-named-entity</guid>
    </item>
    <item>
      <title>A simple, strong baseline for building damage detection on the xBD dataset</title>
      <link>https://paperswithcode.com/paper/a-simple-strong-baseline-for-building-damage</link>
      <description><![CDATA[We construct a strong baseline method for building damage detection by starting with the highly-engineered winning solution of the xView2 competition, and gradually stripping away components.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-simple-strong-baseline-for-building-damage</guid>
    </item>
    <item>
      <title>MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models</title>
      <link>https://paperswithcode.com/paper/mt-eval-a-multi-turn-capabilities-evaluation</link>
      <description><![CDATA[Large language models (LLMs) are increasingly relied upon for complex multi-turn conversations across diverse real-world applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mt-eval-a-multi-turn-capabilities-evaluation</guid>
    </item>
    <item>
      <title>Proactive Detection of Voice Cloning with Localized Watermarking</title>
      <link>https://paperswithcode.com/paper/proactive-detection-of-voice-cloning-with</link>
      <description><![CDATA[In the rapidly evolving field of speech generative models, there is a pressing need to ensure audio authenticity against the risks of voice cloning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proactive-detection-of-voice-cloning-with</guid>
    </item>
    <item>
      <title>CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/core-towards-scalable-and-efficient-causal</link>
      <description><![CDATA[Causal discovery is the challenging task of inferring causal structure from data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/core-towards-scalable-and-efficient-causal</guid>
    </item>
    <item>
      <title>X-ray Image Generation as a Method of Performance Prediction for Real-Time Inspection: a Case Study</title>
      <link>https://paperswithcode.com/paper/x-ray-image-generation-as-a-method-of</link>
      <description><![CDATA[We show how a calibrated image generation model can be used to quantitatively evaluate the effect of the X-ray exposure time on the performance of the inspection system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-ray-image-generation-as-a-method-of</guid>
    </item>
    <item>
      <title>Personalized Differential Privacy for Ridge Regression</title>
      <link>https://paperswithcode.com/paper/personalized-differential-privacy-for-ridge</link>
      <description><![CDATA[DP requires to specify a uniform privacy level $\varepsilon$ that expresses the maximum privacy loss that each data point in the entire dataset is willing to tolerate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalized-differential-privacy-for-ridge</guid>
    </item>
    <item>
      <title>Making Parametric Anomaly Detection on Tabular Data Non-Parametric Again</title>
      <link>https://paperswithcode.com/paper/making-parametric-anomaly-detection-on</link>
      <description><![CDATA[Deep learning for tabular data has garnered increasing attention in recent years, yet employing deep models for structured data remains challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/making-parametric-anomaly-detection-on</guid>
    </item>
  </channel>
</rss>
