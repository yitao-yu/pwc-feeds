<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 05 Oct 2023 21:06:32 +0000</lastBuildDate>
    <item>
      <title>DED: Diagnostic Evidence Distillation for acne severity grading on face images</title>
      <link>https://paperswithcode.com/paper/ded-diagnostic-evidence-distillation-for-acne</link>
      <description><![CDATA[In this study, we propose an acne diagnosis method, Diagnostic Evidence Distillation (DED), that suitably adapts the characteristics of acne diagnosis and can be applied to diagnose under different acne criteria.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ded-diagnostic-evidence-distillation-for-acne</guid>
    </item>
    <item>
      <title>JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/jsontuning-towards-generalizable-robust-and</link>
      <description><![CDATA[Instruction tuning has emerged as a crucial process for harnessing the capabilities of large language models (LLMs) by providing explicit task instructions, leading to improved performance in various tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jsontuning-towards-generalizable-robust-and</guid>
    </item>
    <item>
      <title>A Recipe for Improved Certifiable Robustness: Capacity and Data</title>
      <link>https://paperswithcode.com/paper/a-recipe-for-improved-certifiable-robustness</link>
      <description><![CDATA[A key challenge, supported both theoretically and empirically, is that robustness demands greater network capacity and more data than standard training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-recipe-for-improved-certifiable-robustness</guid>
    </item>
    <item>
      <title>Fast, Expressive SE$(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space</title>
      <link>https://paperswithcode.com/paper/fast-expressive-se-n-equivariant-networks</link>
      <description><![CDATA[The theory of homogeneous spaces tells us how to do group convolutions with feature maps over the homogeneous space of positions $\mathbb{R}^3$, position and orientations $\mathbb{R}^3 {\times} S^2$, and the group SE$(3)$ itself.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-expressive-se-n-equivariant-networks</guid>
    </item>
    <item>
      <title>Local Search GFlowNets</title>
      <link>https://paperswithcode.com/paper/local-search-gflownets</link>
      <description><![CDATA[Generative Flow Networks (GFlowNets) are amortized sampling methods that learn a distribution over discrete objects proportional to their rewards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/local-search-gflownets</guid>
    </item>
    <item>
      <title>GET: Group Event Transformer for Event-Based Vision</title>
      <link>https://paperswithcode.com/paper/get-group-event-transformer-for-event-based-1</link>
      <description><![CDATA[Event cameras are a type of novel neuromorphic sen-sor that has been gaining increasing attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/get-group-event-transformer-for-event-based-1</guid>
    </item>
    <item>
      <title>Multimodal Question Answering for Unified Information Extraction</title>
      <link>https://paperswithcode.com/paper/multimodal-question-answering-for-unified</link>
      <description><![CDATA[In addition, the effectiveness of our framework can successfully transfer to the few-shot setting, enhancing LMMs on a scale of 10B parameters to be competitive or outperform much larger language models such as ChatGPT and GPT-4.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-question-answering-for-unified</guid>
    </item>
    <item>
      <title>Co-modeling the Sequential and Graphical Route for Peptide</title>
      <link>https://paperswithcode.com/paper/co-modeling-the-sequential-and-graphical</link>
      <description><![CDATA[Peptides are formed by the dehydration condensation of multiple amino acids.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/co-modeling-the-sequential-and-graphical</guid>
    </item>
    <item>
      <title>Neural Bayes Estimators for Irregular Spatial Data using Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/neural-bayes-estimators-for-irregular-spatial</link>
      <description><![CDATA[Neural Bayes estimators are neural networks that approximate Bayes estimators in a fast and likelihood-free manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-bayes-estimators-for-irregular-spatial</guid>
    </item>
    <item>
      <title>SemiReward: A General Reward Model for Semi-supervised Learning</title>
      <link>https://paperswithcode.com/paper/semireward-a-general-reward-model-for-semi</link>
      <description><![CDATA[Semi-supervised learning (SSL) has witnessed great progress with various improvements in the self-training framework with pseudo labeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semireward-a-general-reward-model-for-semi</guid>
    </item>
    <item>
      <title>CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/coda-collaborative-novel-box-discovery-and</link>
      <description><![CDATA[Open-vocabulary 3D Object Detection (OV-3DDet) aims to detect objects from an arbitrary list of categories within a 3D scene, which remains seldom explored in the literature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coda-collaborative-novel-box-discovery-and</guid>
    </item>
    <item>
      <title>Leveraging Classic Deconvolution and Feature Extraction in Zero-Shot Image Restoration</title>
      <link>https://paperswithcode.com/paper/leveraging-classic-deconvolution-and-feature</link>
      <description><![CDATA[Our approach combines a pre-trained network to extract deep features from the input image with iterative Richardson-Lucy deconvolution steps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-classic-deconvolution-and-feature</guid>
    </item>
    <item>
      <title>Learning and reusing primitive behaviours to improve Hindsight Experience Replay sample efficiency</title>
      <link>https://paperswithcode.com/paper/learning-and-reusing-primitive-behaviours-to</link>
      <description><![CDATA[Hindsight Experience Replay (HER) is a technique used in reinforcement learning (RL) that has proven to be very efficient for training off-policy RL-based agents to solve goal-based robotic manipulation tasks using sparse rewards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-and-reusing-primitive-behaviours-to</guid>
    </item>
    <item>
      <title>Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond</title>
      <link>https://paperswithcode.com/paper/towards-end-to-end-embodied-decision-making</link>
      <description><![CDATA[In this study, we explore the potential of Multimodal Large Language Models (MLLMs) in improving embodied decision-making processes for agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-end-to-end-embodied-decision-making</guid>
    </item>
    <item>
      <title>Robust deformable image registration using cycle-consistent implicit representations</title>
      <link>https://paperswithcode.com/paper/robust-deformable-image-registration-using</link>
      <description><![CDATA[To improve robustness, we propose a deformable registration method using pairs of cycle-consistent Implicit Neural Representations: each implicit representation is linked to a second implicit representation that estimates the opposite transformation, causing each network to act as a regularizer for its paired opposite.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-deformable-image-registration-using</guid>
    </item>
    <item>
      <title>VENOM: A Vectorized N:M Format for Unleashing the Power of Sparse Tensor Cores</title>
      <link>https://paperswithcode.com/paper/venom-a-vectorized-n-m-format-for-unleashing</link>
      <description><![CDATA[We present the V:N:M format, which enables the execution of arbitrary N:M ratios on SPTCs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/venom-a-vectorized-n-m-format-for-unleashing</guid>
    </item>
    <item>
      <title>Linear Recurrent Units for Sequential Recommendation</title>
      <link>https://paperswithcode.com/paper/linear-recurrent-units-for-sequential</link>
      <description><![CDATA[State-of-the-art sequential recommendation relies heavily on self-attention-based recommender models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linear-recurrent-units-for-sequential</guid>
    </item>
    <item>
      <title>Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance</title>
      <link>https://paperswithcode.com/paper/instance-needs-more-care-rewriting-prompts</link>
      <description><![CDATA[To this end, we propose PRoMPTd, an approach that rewrites the task prompt for each individual test input to be more specific, unambiguous, and complete, so as to provide better guidance to the task LLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instance-needs-more-care-rewriting-prompts</guid>
    </item>
    <item>
      <title>Video Transformers under Occlusion: How Physics and Background Attributes Impact Large Models for Robotic Manipulation</title>
      <link>https://paperswithcode.com/paper/video-transformers-under-occlusion-how</link>
      <description><![CDATA[As transformer architectures and dataset sizes continue to scale, the need to understand the specific dataset factors affecting model performance becomes increasingly urgent.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-transformers-under-occlusion-how</guid>
    </item>
    <item>
      <title>TransRadar: Adaptive-Directional Transformer for Real-Time Multi-View Radar Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/transradar-adaptive-directional-transformer</link>
      <description><![CDATA[Scene understanding plays an essential role in enabling autonomous driving and maintaining high standards of performance and safety.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transradar-adaptive-directional-transformer</guid>
    </item>
    <item>
      <title>Editing Personality for LLMs</title>
      <link>https://paperswithcode.com/paper/editing-personality-for-llms</link>
      <description><![CDATA[This task seeks to adjust the models' responses to opinion-related questions on specified topics since an individual's personality often manifests in the form of their expressed opinions, thereby showcasing different personality traits.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/editing-personality-for-llms</guid>
    </item>
    <item>
      <title>Can Large Language Models Provide Security &amp; Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions</title>
      <link>https://paperswithcode.com/paper/can-large-language-models-provide-security</link>
      <description><![CDATA[In this paper, we measure their ability to refute popular S&P misconceptions that the general public holds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-large-language-models-provide-security</guid>
    </item>
    <item>
      <title>OceanGPT: A Large Language Model for Ocean Science Tasks</title>
      <link>https://paperswithcode.com/paper/oceangpt-a-large-language-model-for-ocean</link>
      <description><![CDATA[Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oceangpt-a-large-language-model-for-ocean</guid>
    </item>
    <item>
      <title>Language Models as Knowledge Bases for Visual Word Sense Disambiguation</title>
      <link>https://paperswithcode.com/paper/language-models-as-knowledge-bases-for-visual</link>
      <description><![CDATA[Visual Word Sense Disambiguation (VWSD) is a novel challenging task that lies between linguistic sense disambiguation and fine-grained multimodal retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-as-knowledge-bases-for-visual</guid>
    </item>
    <item>
      <title>Language Models Represent Space and Time</title>
      <link>https://paperswithcode.com/paper/language-models-represent-space-and-time</link>
      <description><![CDATA[The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process -- a world model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-represent-space-and-time</guid>
    </item>
    <item>
      <title>Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization</title>
      <link>https://paperswithcode.com/paper/dynamic-llm-agent-network-an-llm-agent</link>
      <description><![CDATA[We further design an automatic agent team optimization algorithm based on an unsupervised metric termed $\textit{Agent Importance Score}$, enabling the selection of best agents based on the contribution each agent makes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-llm-agent-network-an-llm-agent</guid>
    </item>
    <item>
      <title>Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/driving-with-llms-fusing-object-level-vector</link>
      <description><![CDATA[Large Language Models (LLMs) have shown promise in the autonomous driving sector, particularly in generalization and interpretability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/driving-with-llms-fusing-object-level-vector</guid>
    </item>
    <item>
      <title>Towards Feasible Counterfactual Explanations: A Taxonomy Guided Template-based NLG Method</title>
      <link>https://paperswithcode.com/paper/towards-feasible-counterfactual-explanations</link>
      <description><![CDATA[Counterfactual Explanations (cf-XAI) describe the smallest changes in feature values necessary to change an outcome from one class to another.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-feasible-counterfactual-explanations</guid>
    </item>
    <item>
      <title>Probabilistic Reach-Avoid for Bayesian Neural Networks</title>
      <link>https://paperswithcode.com/paper/probabilistic-reach-avoid-for-bayesian-neural</link>
      <description><![CDATA[Such computed lower bounds provide safety certification for the given policy and BNN model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probabilistic-reach-avoid-for-bayesian-neural</guid>
    </item>
    <item>
      <title>FiGURe: Simple and Efficient Unsupervised Node Representations with Filter Augmentations</title>
      <link>https://paperswithcode.com/paper/figure-simple-and-efficient-unsupervised-node</link>
      <description><![CDATA[This paper presents a simple filter-based augmentation method to capture different parts of the eigen-spectrum.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/figure-simple-and-efficient-unsupervised-node</guid>
    </item>
    <item>
      <title>MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens</title>
      <link>https://paperswithcode.com/paper/minigpt-5-interleaved-vision-and-language</link>
      <description><![CDATA[Large Language Models (LLMs) have garnered significant attention for their advancements in natural language processing, demonstrating unparalleled prowess in text comprehension and generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minigpt-5-interleaved-vision-and-language</guid>
    </item>
    <item>
      <title>Jury: A Comprehensive Evaluation Toolkit</title>
      <link>https://paperswithcode.com/paper/jury-a-comprehensive-evaluation-toolkit</link>
      <description><![CDATA[However, the vast number of Natural Language Processing (NLP) tasks and the development of various metrics have led to challenges in evaluating different systems with different metrics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jury-a-comprehensive-evaluation-toolkit</guid>
    </item>
    <item>
      <title>Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns</title>
      <link>https://paperswithcode.com/paper/stack-attention-improving-the-ability-of</link>
      <description><![CDATA[Attention, specifically scaled dot-product attention, has proven effective for natural language, but it does not have a mechanism for handling hierarchical patterns of arbitrary nesting depth, which limits its ability to recognize certain syntactic structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stack-attention-improving-the-ability-of</guid>
    </item>
    <item>
      <title>CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery</title>
      <link>https://paperswithcode.com/paper/causaltime-realistically-generated-time</link>
      <description><![CDATA[This study introduces the CausalTime pipeline to generate time-series that highly resemble the real data and with ground truth causal graphs for quantitative performance evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causaltime-realistically-generated-time</guid>
    </item>
    <item>
      <title>Towards Stable Backdoor Purification through Feature Shift Tuning</title>
      <link>https://paperswithcode.com/paper/towards-stable-backdoor-purification-through</link>
      <description><![CDATA[Therefore, it is necessary to disentangle the backdoor and clean features in order to improve backdoor purification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-stable-backdoor-purification-through</guid>
    </item>
    <item>
      <title>Score-based Data Assimilation for a Two-Layer Quasi-Geostrophic Model</title>
      <link>https://paperswithcode.com/paper/score-based-data-assimilation-for-a-two-layer</link>
      <description><![CDATA[Data assimilation addresses the problem of identifying plausible state trajectories of dynamical systems given noisy or incomplete observations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/score-based-data-assimilation-for-a-two-layer</guid>
    </item>
    <item>
      <title>Generative Autoencoding of Dropout Patterns</title>
      <link>https://paperswithcode.com/paper/generative-autoencoding-of-dropout-patterns</link>
      <description><![CDATA[We propose a generative model termed Deciphering Autoencoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-autoencoding-of-dropout-patterns</guid>
    </item>
    <item>
      <title>Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes</title>
      <link>https://paperswithcode.com/paper/self-supervised-high-dynamic-range-imaging</link>
      <description><![CDATA[The color component is estimated from aligned multi-exposure images, while the structure one is generated through a structure-focused network that is supervised by the color component and an input reference (\eg, medium-exposure) image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-high-dynamic-range-imaging</guid>
    </item>
    <item>
      <title>LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment</title>
      <link>https://paperswithcode.com/paper/languagebind-extending-video-language</link>
      <description><![CDATA[While LanguageBind ensures that we can extend VL modalities to N modalities, we also need a high-quality dataset with alignment data pairs centered on language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/languagebind-extending-video-language</guid>
    </item>
    <item>
      <title>Stochastic Gradient Descent with Preconditioned Polyak Step-size</title>
      <link>https://paperswithcode.com/paper/stochastic-gradient-descent-with</link>
      <description><![CDATA[Stochastic Gradient Descent (SGD) is one of the many iterative optimization methods that are widely used in solving machine learning problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stochastic-gradient-descent-with</guid>
    </item>
    <item>
      <title>SMRD: SURE-based Robust MRI Reconstruction with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/smrd-sure-based-robust-mri-reconstruction</link>
      <description><![CDATA[However, diffusion models require careful tuning of inference hyperparameters on a validation set and are still sensitive to distribution shifts during testing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smrd-sure-based-robust-mri-reconstruction</guid>
    </item>
    <item>
      <title>Beyond the Benchmark: Detecting Diverse Anomalies in Videos</title>
      <link>https://paperswithcode.com/paper/beyond-the-benchmark-detecting-diverse</link>
      <description><![CDATA[MFAD excels in both simple and complex anomaly detection scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-the-benchmark-detecting-diverse</guid>
    </item>
    <item>
      <title>Differentially Encoded Observation Spaces for Perceptive Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/differentially-encoded-observation-spaces-for</link>
      <description><![CDATA[We evaluate our approach with three state-of-the-art DRL algorithms and find that differential image encoding reduces the memory footprint by as much as 14. 2x and 16. 7x across tasks from the Atari 2600 benchmark and the DeepMind Control Suite (DMC) respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/differentially-encoded-observation-spaces-for</guid>
    </item>
    <item>
      <title>Ensemble Distillation for Unsupervised Constituency Parsing</title>
      <link>https://paperswithcode.com/paper/ensemble-distillation-for-unsupervised</link>
      <description><![CDATA[We investigate the unsupervised constituency parsing task, which organizes words and phrases of a sentence into a hierarchical structure without using linguistically annotated data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ensemble-distillation-for-unsupervised</guid>
    </item>
    <item>
      <title>Mini-BEHAVIOR: A Procedurally Generated Benchmark for Long-horizon Decision-Making in Embodied AI</title>
      <link>https://paperswithcode.com/paper/mini-behavior-a-procedurally-generated</link>
      <description><![CDATA[We present Mini-BEHAVIOR, a novel benchmark for embodied AI that challenges agents to use reasoning and decision-making skills to solve complex activities that resemble everyday human challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mini-behavior-a-procedurally-generated</guid>
    </item>
    <item>
      <title>Splitting the Difference on Adversarial Training</title>
      <link>https://paperswithcode.com/paper/splitting-the-difference-on-adversarial</link>
      <description><![CDATA[The ability to achieve such near-optimal natural accuracy, while maintaining a significant level of robustness, makes our method applicable to real-world applications where natural accuracy is at a premium.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/splitting-the-difference-on-adversarial</guid>
    </item>
    <item>
      <title>Delta-AI: Local objectives for amortized inference in sparse graphical models</title>
      <link>https://paperswithcode.com/paper/delta-ai-local-objectives-for-amortized</link>
      <description><![CDATA[We present a new algorithm for amortized inference in sparse probabilistic graphical models (PGMs), which we call $\Delta$-amortized inference ($\Delta$-AI).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/delta-ai-local-objectives-for-amortized</guid>
    </item>
    <item>
      <title>Exploring Model Learning Heterogeneity for Boosting Ensemble Robustness</title>
      <link>https://paperswithcode.com/paper/exploring-model-learning-heterogeneity-for</link>
      <description><![CDATA[We show that this two-tier heterogeneity driven ensemble construction method can compose an ensemble team that promotes high ensemble diversity and low negative correlation among member models of the ensemble, strengthening ensemble robustness against both negative examples and adversarial attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-model-learning-heterogeneity-for</guid>
    </item>
    <item>
      <title>FedL2P: Federated Learning to Personalize</title>
      <link>https://paperswithcode.com/paper/fedl2p-federated-learning-to-personalize</link>
      <description><![CDATA[Federated learning (FL) research has made progress in developing algorithms for distributed learning of global models, as well as algorithms for local personalization of those common models to the specifics of each client's local data distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedl2p-federated-learning-to-personalize</guid>
    </item>
    <item>
      <title>DON-LSTM: Multi-Resolution Learning with DeepONets and Long Short-Term Memory Neural Networks</title>
      <link>https://paperswithcode.com/paper/don-lstm-multi-resolution-learning-with</link>
      <description><![CDATA[Deep operator networks (DeepONets, DONs) offer a distinct advantage over traditional neural networks in their ability to be trained on multi-resolution data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-lstm-multi-resolution-learning-with</guid>
    </item>
  </channel>
</rss>
