<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 12 Jun 2024 21:07:56 +0000</lastBuildDate>
    <item>
      <title>DUAL-REFLECT: Enhancing Large Language Models for Reflective Translation through Dual Learning Feedback Mechanisms</title>
      <link>https://paperswithcode.com/paper/dual-reflect-enhancing-large-language-models</link>
      <description><![CDATA[Recently, large language models (LLMs) enhanced by self-reflection have achieved promising performance on machine translation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-reflect-enhancing-large-language-models</guid>
    </item>
    <item>
      <title>Improving Multi-hop Logical Reasoning in Knowledge Graphs with Context-Aware Query Representation Learning</title>
      <link>https://paperswithcode.com/paper/improving-multi-hop-logical-reasoning-in</link>
      <description><![CDATA[To address the problem, we propose a model-agnostic methodology that enhances the effectiveness of existing multi-hop logical reasoning approaches by fully integrating the context of the FOL query graph.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-multi-hop-logical-reasoning-in</guid>
    </item>
    <item>
      <title>TextGrad: Automatic "Differentiation" via Text</title>
      <link>https://paperswithcode.com/paper/textgrad-automatic-differentiation-via-text</link>
      <description><![CDATA[Without modifying the framework, TextGrad improves the zero-shot accuracy of GPT-4o in Google-Proof Question Answering from $51\%$ to $55\%$, yields $20\%$ relative performance gain in optimizing LeetCode-Hard coding problem solutions, improves prompts for reasoning, designs new druglike small molecules with desirable in silico binding, and designs radiation oncology treatment plans with high specificity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textgrad-automatic-differentiation-via-text</guid>
    </item>
    <item>
      <title>Mining Frequent Structures in Conceptual Models</title>
      <link>https://paperswithcode.com/paper/mining-frequent-structures-in-conceptual</link>
      <description><![CDATA[In this paper, we propose a general approach to the problem of discovering frequent structures, as they occur in conceptual modeling languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mining-frequent-structures-in-conceptual</guid>
    </item>
    <item>
      <title>Logical Distillation of Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/logical-distillation-of-graph-neural-networks</link>
      <description><![CDATA[We introduce a decision-tree based model which leverages an extension of C2 to distill interpretable logical classifiers from GNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/logical-distillation-of-graph-neural-networks</guid>
    </item>
    <item>
      <title>Hearing Anything Anywhere</title>
      <link>https://paperswithcode.com/paper/hearing-anything-anywhere</link>
      <description><![CDATA[Recent years have seen immense progress in 3D computer vision and computer graphics, with emerging tools that can virtualize real-world 3D environments for numerous Mixed Reality (XR) applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hearing-anything-anywhere</guid>
    </item>
    <item>
      <title>EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark</title>
      <link>https://paperswithcode.com/paper/emobox-multilingual-multi-corpus-speech</link>
      <description><![CDATA[In this paper, we propose EmoBox, an out-of-the-box multilingual multi-corpus speech emotion recognition toolkit, along with a benchmark for both intra-corpus and cross-corpus settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emobox-multilingual-multi-corpus-speech</guid>
    </item>
    <item>
      <title>fKAN: Fractional Kolmogorov-Arnold Networks with trainable Jacobi basis functions</title>
      <link>https://paperswithcode.com/paper/fkan-fractional-kolmogorov-arnold-networks</link>
      <description><![CDATA[Recent advancements in neural network design have given rise to the development of Kolmogorov-Arnold Networks (KANs), which enhance speed, interpretability, and precision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fkan-fractional-kolmogorov-arnold-networks</guid>
    </item>
    <item>
      <title>Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis</title>
      <link>https://paperswithcode.com/paper/cognitive-insights-across-languages-enhancing</link>
      <description><![CDATA[Cognitive decline is a natural process that occurs as individuals age.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cognitive-insights-across-languages-enhancing</guid>
    </item>
    <item>
      <title>1st Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation</title>
      <link>https://paperswithcode.com/paper/1st-place-solution-for-mevis-track-in-cvpr</link>
      <description><![CDATA[Motion Expression guided Video Segmentation (MeViS), as an emerging task, poses many new challenges to the field of referring video object segmentation (RVOS).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/1st-place-solution-for-mevis-track-in-cvpr</guid>
    </item>
    <item>
      <title>Image Textualization: An Automatic Framework for Creating Accurate and Detailed Image Descriptions</title>
      <link>https://paperswithcode.com/paper/image-textualization-an-automatic-framework</link>
      <description><![CDATA[Image description datasets play a crucial role in the advancement of various applications such as image understanding, text-to-image generation, and text-image retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/image-textualization-an-automatic-framework</guid>
    </item>
    <item>
      <title>QuickLLaMA: Query-aware Inference Acceleration for Large Language Models</title>
      <link>https://paperswithcode.com/paper/quickllama-query-aware-inference-acceleration</link>
      <description><![CDATA[Q-LLM improved by 7. 17% compared to the current state-of-the-art on LLaMA3, and by 3. 26% on Mistral on the $\infty$-bench.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quickllama-query-aware-inference-acceleration</guid>
    </item>
    <item>
      <title>Understanding Visual Concepts Across Models</title>
      <link>https://paperswithcode.com/paper/understanding-visual-concepts-across-models</link>
      <description><![CDATA[Large multimodal models such as Stable Diffusion can generate, detect, and classify new visual concepts after fine-tuning just a single word embedding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-visual-concepts-across-models</guid>
    </item>
    <item>
      <title>Reconstructing the Tropical Pacific Upper Ocean using Online Data Assimilation with a Deep Learning model</title>
      <link>https://paperswithcode.com/paper/reconstructing-the-tropical-pacific-upper</link>
      <description><![CDATA[A deep learning (DL) model, based on a transformer architecture, is trained on a climate-model dataset and compared with a standard linear inverse model (LIM) in the tropical Pacific.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reconstructing-the-tropical-pacific-upper</guid>
    </item>
    <item>
      <title>Let Go of Your Labels with Unsupervised Transfer</title>
      <link>https://paperswithcode.com/paper/let-go-of-your-labels-with-unsupervised-1</link>
      <description><![CDATA[In particular, TURTLE matches the average performance of CLIP zero-shot on 26 datasets by employing the same representation space, spanning a wide range of architectures and model sizes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-go-of-your-labels-with-unsupervised-1</guid>
    </item>
    <item>
      <title>When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models</title>
      <link>https://paperswithcode.com/paper/when-linear-attention-meets-autoregressive</link>
      <description><![CDATA[Autoregressive Large Language Models (LLMs) have achieved impressive performance in language tasks but face two significant bottlenecks: (1) quadratic complexity in the attention module as the number of tokens increases, and (2) limited efficiency due to the sequential processing nature of autoregressive LLMs during generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-linear-attention-meets-autoregressive</guid>
    </item>
    <item>
      <title>Unified Modeling Enhanced Multimodal Learning for Precision Neuro-Oncology</title>
      <link>https://paperswithcode.com/paper/unified-modeling-enhanced-multimodal-learning</link>
      <description><![CDATA[Multimodal learning, integrating histology images and genomics, promises to enhance precision oncology with comprehensive views at microscopic and molecular levels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-modeling-enhanced-multimodal-learning</guid>
    </item>
    <item>
      <title>Blur-aware Spatio-temporal Sparse Transformer for Video Deblurring</title>
      <link>https://paperswithcode.com/paper/blur-aware-spatio-temporal-sparse-transformer</link>
      <description><![CDATA[Specifically, BSSTNet (1) uses a longer temporal window in the transformer, leveraging information from more distant frames to restore the blurry pixels in the current frame.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blur-aware-spatio-temporal-sparse-transformer</guid>
    </item>
    <item>
      <title>Mitigating Boundary Ambiguity and Inherent Bias for Text Classification in the Era of Large Language Models</title>
      <link>https://paperswithcode.com/paper/mitigating-boundary-ambiguity-and-inherent</link>
      <description><![CDATA[Our approach is grounded in the empirical observation that pairwise comparisons can effectively alleviate boundary ambiguity and inherent bias.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mitigating-boundary-ambiguity-and-inherent</guid>
    </item>
    <item>
      <title>MoreauPruner: Robust Pruning of Large Language Models against Weight Perturbations</title>
      <link>https://paperswithcode.com/paper/moreaupruner-robust-pruning-of-large-language</link>
      <description><![CDATA[Our numerical results suggest the robustness of MoreauPruner against weight perturbations, and indicate the MoreauPruner's successful accuracy-based scores in comparison to several existing pruning methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moreaupruner-robust-pruning-of-large-language</guid>
    </item>
    <item>
      <title>Beyond ELBOs: A Large-Scale Evaluation of Variational Methods for Sampling</title>
      <link>https://paperswithcode.com/paper/beyond-elbos-a-large-scale-evaluation-of</link>
      <description><![CDATA[Monte Carlo methods, Variational Inference, and their combinations play a pivotal role in sampling from intractable probability distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-elbos-a-large-scale-evaluation-of</guid>
    </item>
    <item>
      <title>Dual Thinking and Perceptual Analysis of Deep Learning Models using Human Adversarial Examples</title>
      <link>https://paperswithcode.com/paper/dual-thinking-and-perceptual-analysis-of-deep</link>
      <description><![CDATA[The dual thinking framework considers fast, intuitive processing and slower, logical processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-thinking-and-perceptual-analysis-of-deep</guid>
    </item>
    <item>
      <title>A Non-autoregressive Generation Framework for End-to-End Simultaneous Speech-to-Any Translation</title>
      <link>https://paperswithcode.com/paper/a-non-autoregressive-generation-framework-for</link>
      <description><![CDATA[Simultaneous translation models play a crucial role in facilitating communication.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-non-autoregressive-generation-framework-for</guid>
    </item>
    <item>
      <title>Instruct Large Language Models to Drive like Humans</title>
      <link>https://paperswithcode.com/paper/instruct-large-language-models-to-drive-like</link>
      <description><![CDATA[Conventional methods apply predefined rules or learn from driving data to plan the future trajectory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instruct-large-language-models-to-drive-like</guid>
    </item>
    <item>
      <title>Optimal Matrix-Mimetic Tensor Algebras via Variable Projection</title>
      <link>https://paperswithcode.com/paper/optimal-matrix-mimetic-tensor-algebras-via</link>
      <description><![CDATA[The choice of linear mapping is crucial to representation quality and, in practice, is made heuristically based on expected correlations in the data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimal-matrix-mimetic-tensor-algebras-via</guid>
    </item>
    <item>
      <title>Merging Improves Self-Critique Against Jailbreak Attacks</title>
      <link>https://paperswithcode.com/paper/merging-improves-self-critique-against</link>
      <description><![CDATA[The robustness of large language models (LLMs) against adversarial manipulations, such as jailbreak attacks, remains a significant challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/merging-improves-self-critique-against</guid>
    </item>
    <item>
      <title>Simple and Effective Masked Diffusion Language Models</title>
      <link>https://paperswithcode.com/paper/simple-and-effective-masked-diffusion</link>
      <description><![CDATA[While diffusion models excel at generating high-quality images, prior work reports a significant performance gap between diffusion and autoregressive (AR) methods in language modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simple-and-effective-masked-diffusion</guid>
    </item>
    <item>
      <title>EEG-ImageNet: An Electroencephalogram Dataset and Benchmarks with Image Visual Stimuli of Multi-Granularity Labels</title>
      <link>https://paperswithcode.com/paper/eeg-imagenet-an-electroencephalogram-dataset</link>
      <description><![CDATA[Experiments with several commonly used models show that the best models can achieve object classification with accuracy around 60% and image reconstruction with two-way identification around 64%.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eeg-imagenet-an-electroencephalogram-dataset</guid>
    </item>
    <item>
      <title>CTC-based Non-autoregressive Textless Speech-to-Speech Translation</title>
      <link>https://paperswithcode.com/paper/ctc-based-non-autoregressive-textless-speech</link>
      <description><![CDATA[Direct speech-to-speech translation (S2ST) has achieved impressive translation quality, but it often faces the challenge of slow decoding due to the considerable length of speech sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ctc-based-non-autoregressive-textless-speech</guid>
    </item>
    <item>
      <title>Image and Video Tokenization with Binary Spherical Quantization</title>
      <link>https://paperswithcode.com/paper/image-and-video-tokenization-with-binary</link>
      <description><![CDATA[The resulting BSQ-ViT achieves state-of-the-art visual reconstruction quality on image and video reconstruction benchmarks with 2. 4$\times$ throughput compared to the best prior methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/image-and-video-tokenization-with-binary</guid>
    </item>
    <item>
      <title>Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model</title>
      <link>https://paperswithcode.com/paper/paying-more-attention-to-source-context</link>
      <description><![CDATA[Large language models (LLMs) have showcased impressive multilingual machine translation ability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paying-more-attention-to-source-context</guid>
    </item>
    <item>
      <title>CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation</title>
      <link>https://paperswithcode.com/paper/coevol-constructing-better-responses-for</link>
      <description><![CDATA[The responses within IFT data could be further enhanced by leveraging the capabilities of LLMs themselves.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coevol-constructing-better-responses-for</guid>
    </item>
    <item>
      <title>EFFOcc: A Minimal Baseline for EFficient Fusion-based 3D Occupancy Network</title>
      <link>https://paperswithcode.com/paper/effocc-a-minimal-baseline-for-efficient</link>
      <description><![CDATA[On Occ3D-nuScenes benchmark, EFFOcc has only 18. 4M parameters, and achieves 50. 46 in terms of mean IoU (mIoU), to our knowledge, it is the occnet with minimal parameters compared with related occnets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effocc-a-minimal-baseline-for-efficient</guid>
    </item>
    <item>
      <title>Triple-domain Feature Learning with Frequency-aware Memory Enhancement for Moving Infrared Small Target Detection</title>
      <link>https://paperswithcode.com/paper/triple-domain-feature-learning-with-frequency</link>
      <description><![CDATA[To extend target feature learning, we propose a new Triple-domain Strategy (Tridos) with the frequency-aware memory enhancement on the spatial-temporal domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triple-domain-feature-learning-with-frequency</guid>
    </item>
    <item>
      <title>Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena</title>
      <link>https://paperswithcode.com/paper/open-llm-leaderboard-from-multi-choice-to</link>
      <description><![CDATA[To address them, a more thorough approach involves shifting from MCQ to open-style questions, which can fundamentally eliminate selection bias and random guessing issues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-llm-leaderboard-from-multi-choice-to</guid>
    </item>
    <item>
      <title>Semantic-Aware Spectrum Sharing in Internet of Vehicles Based on Deep Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/semantic-aware-spectrum-sharing-in-internet</link>
      <description><![CDATA[This optimization encompasses the optimal link of V2V and V2I sharing strategies, the transmission power for vehicles sending semantic information and the length of transmitted semantic symbols, aiming at maximizing HSSE of V2I and enhancing success rate of effective semantic information transmission (SRS) of V2V.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-aware-spectrum-sharing-in-internet</guid>
    </item>
    <item>
      <title>AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising</title>
      <link>https://paperswithcode.com/paper/asyncdiff-parallelizing-diffusion-models-by</link>
      <description><![CDATA[To address this, we introduce AsyncDiff, a universal and plug-and-play acceleration scheme that enables model parallelism across multiple devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asyncdiff-parallelizing-diffusion-models-by</guid>
    </item>
    <item>
      <title>BvSP: Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad Prediction</title>
      <link>https://paperswithcode.com/paper/bvsp-broad-view-soft-prompting-for-few-shot</link>
      <description><![CDATA[To tackle this issue, we further propose a Broadview Soft Prompting (BvSP) method that aggregates multiple templates with a broader view by taking into account the correlation between the different templates.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bvsp-broad-view-soft-prompting-for-few-shot</guid>
    </item>
    <item>
      <title>Scaling Large-Language-Model-based Multi-Agent Collaboration</title>
      <link>https://paperswithcode.com/paper/scaling-large-language-model-based-multi</link>
      <description><![CDATA[Pioneering advancements in large language model-powered agents have underscored the design pattern of multi-agent collaboration, demonstrating that collective intelligence can surpass the capabilities of each individual.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-large-language-model-based-multi</guid>
    </item>
    <item>
      <title>RGB-Sonar Tracking Benchmark and Spatial Cross-Attention Transformer Tracker</title>
      <link>https://paperswithcode.com/paper/rgb-sonar-tracking-benchmark-and-spatial</link>
      <description><![CDATA[The spatial cross-attention is used to overcome the problem of spatial misalignment of between RGB and sonar images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rgb-sonar-tracking-benchmark-and-spatial</guid>
    </item>
    <item>
      <title>AI Sandbagging: Language Models can Strategically Underperform on Evaluations</title>
      <link>https://paperswithcode.com/paper/ai-sandbagging-language-models-can</link>
      <description><![CDATA[In addition, we show that both frontier and smaller models can be prompted, or password-locked, to target specific scores on a capability evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ai-sandbagging-language-models-can</guid>
    </item>
    <item>
      <title>RWKV-CLIP: A Robust Vision-Language Representation Learner</title>
      <link>https://paperswithcode.com/paper/rwkv-clip-a-robust-vision-language</link>
      <description><![CDATA[Contrastive Language-Image Pre-training (CLIP) has significantly improved performance in various vision-language tasks by expanding the dataset with image-text pairs obtained from websites.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rwkv-clip-a-robust-vision-language</guid>
    </item>
    <item>
      <title>Matryoshka Representation Learning for Recommendation</title>
      <link>https://paperswithcode.com/paper/matryoshka-representation-learning-for</link>
      <description><![CDATA[In this paper, we introduce a novel matryoshka representation learning method for recommendation (MRL4Rec), by which we restructure user and item vectors into matryoshka representations with incrementally dimensional and overlapping vector spaces to explicitly represent user preferences and item features at different hierarchical levels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/matryoshka-representation-learning-for</guid>
    </item>
    <item>
      <title>VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs</title>
      <link>https://paperswithcode.com/paper/videollama-2-advancing-spatial-temporal</link>
      <description><![CDATA[In this paper, we present the VideoLLaMA 2, a set of Video Large Language Models (Video-LLMs) designed to enhance spatial-temporal modeling and audio understanding in video and audio-oriented tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videollama-2-advancing-spatial-temporal</guid>
    </item>
    <item>
      <title>MS-Diffusion: Multi-subject Zero-shot Image Personalization with Layout Guidance</title>
      <link>https://paperswithcode.com/paper/ms-diffusion-multi-subject-zero-shot-image</link>
      <description><![CDATA[Recent advancements in text-to-image generation models have dramatically enhanced the generation of photorealistic images from textual prompts, leading to an increased interest in personalized text-to-image applications, particularly in multi-subject scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ms-diffusion-multi-subject-zero-shot-image</guid>
    </item>
    <item>
      <title>Triage of 3D pathology data via 2.5D multiple-instance learning to guide pathologist assessments</title>
      <link>https://paperswithcode.com/paper/triage-of-3d-pathology-data-via-2-5d-multiple</link>
      <description><![CDATA[A potential early route towards clinical adoption for 3D pathology is to rely on pathologists for final diagnosis based on viewing familiar 2D H&E-like image sections from the 3D datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triage-of-3d-pathology-data-via-2-5d-multiple</guid>
    </item>
    <item>
      <title>BertaQA: How Much Do Language Models Know About Local Culture?</title>
      <link>https://paperswithcode.com/paper/bertaqa-how-much-do-language-models-know</link>
      <description><![CDATA[To address this gap, we introduce BertaQA, a multiple-choice trivia dataset that is parallel in English and Basque.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bertaqa-how-much-do-language-models-know</guid>
    </item>
    <item>
      <title>Unleashing the Denoising Capability of Diffusion Prior for Solving Inverse Problems</title>
      <link>https://paperswithcode.com/paper/unleashing-the-denoising-capability-of</link>
      <description><![CDATA[The proposed algorithm, termed ProjDiff, effectively harnesses the prior information and the denoising capability of a pre-trained diffusion model within the optimization framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unleashing-the-denoising-capability-of</guid>
    </item>
    <item>
      <title>MR-RawNet: Speaker verification system with multiple temporal resolutions for variable duration utterances using raw waveforms</title>
      <link>https://paperswithcode.com/paper/mr-rawnet-speaker-verification-system-with</link>
      <description><![CDATA[In speaker verification systems, the utilization of short utterances presents a persistent challenge, leading to performance degradation primarily due to insufficient phonetic information to characterize the speakers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mr-rawnet-speaker-verification-system-with</guid>
    </item>
    <item>
      <title>D-GRIL: End-to-End Topological Learning with 2-parameter Persistence</title>
      <link>https://paperswithcode.com/paper/d-gril-end-to-end-topological-learning-with-2</link>
      <description><![CDATA[End-to-end topological learning using 1-parameter persistence is well-known.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/d-gril-end-to-end-topological-learning-with-2</guid>
    </item>
  </channel>
</rss>
