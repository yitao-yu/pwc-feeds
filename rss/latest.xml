<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 20 Apr 2025 21:08:45 +0000</lastBuildDate>
    <item>
      <title>DrugGen enhances drug discovery with large language models and reinforcement learning</title>
      <link>https://paperswithcode.com/paper/druggen-enhances-drug-discovery-with-large</link>
      <description><![CDATA[One promising algorithm is DrugGPT, a transformer-based model, that generates small molecules for input protein sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/druggen-enhances-drug-discovery-with-large</guid>
    </item>
    <item>
      <title>Mask Image Watermarking</title>
      <link>https://paperswithcode.com/paper/mask-image-watermarking</link>
      <description><![CDATA[MaskMark has two variants: MaskMark-D, which supports global watermark embedding, watermark localization, and local watermark extraction for applications such as tamper detection, and MaskMark-ED, which focuses on local watermark embedding and extraction with enhanced robustness in small regions, enabling localized image protection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mask-image-watermarking</guid>
    </item>
    <item>
      <title>IMAGGarment-1: Fine-Grained Garment Generation for Controllable Fashion Design</title>
      <link>https://paperswithcode.com/paper/imaggarment-1-fine-grained-garment-generation</link>
      <description><![CDATA[This paper presents IMAGGarment-1, a fine-grained garment generation (FGG) framework that enables high-fidelity garment synthesis with precise control over silhouette, color, and logo placement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imaggarment-1-fine-grained-garment-generation</guid>
    </item>
    <item>
      <title>Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D Semantic Occupancy Prediction</title>
      <link>https://paperswithcode.com/paper/rethinking-temporal-fusion-with-a-unified</link>
      <description><![CDATA[We present GDFusion, a temporal fusion method for vision-based 3D semantic occupancy prediction (VisionOcc).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-temporal-fusion-with-a-unified</guid>
    </item>
    <item>
      <title>ZeroSumEval: Scaling LLM Evaluation with Inter-Model Competition</title>
      <link>https://paperswithcode.com/paper/zerosumeval-scaling-llm-evaluation-with-inter</link>
      <description><![CDATA[Evaluating the capabilities of Large Language Models (LLMs) has traditionally relied on static benchmark datasets, human assessments, or model-based evaluations - methods that often suffer from overfitting, high costs, and biases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zerosumeval-scaling-llm-evaluation-with-inter</guid>
    </item>
    <item>
      <title>ConExion: Concept Extraction with Large Language Models</title>
      <link>https://paperswithcode.com/paper/conexion-concept-extraction-with-large</link>
      <description><![CDATA[In this paper, an approach for concept extraction from documents using pre-trained large language models (LLMs) is presented.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conexion-concept-extraction-with-large</guid>
    </item>
    <item>
      <title>VistaDPO: Video Hierarchical Spatial-Temporal Direct Preference Optimization for Large Video Models</title>
      <link>https://paperswithcode.com/paper/vistadpo-video-hierarchical-spatial-temporal</link>
      <description><![CDATA[Large Video Models (LVMs) built upon Large Language Models (LLMs) have shown promise in video understanding but often suffer from misalignment with human intuition and video hallucination issues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vistadpo-video-hierarchical-spatial-temporal</guid>
    </item>
    <item>
      <title>Retrieval-Augmented Generation with Conflicting Evidence</title>
      <link>https://paperswithcode.com/paper/retrieval-augmented-generation-with-3</link>
      <description><![CDATA[Large language model (LLM) agents are increasingly employing retrieval-augmented generation (RAG) to improve the factuality of their responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retrieval-augmented-generation-with-3</guid>
    </item>
    <item>
      <title>Hierarchical Vector Quantized Graph Autoencoder with Annealing-Based Code Selection</title>
      <link>https://paperswithcode.com/paper/hierarchical-vector-quantized-graph</link>
      <description><![CDATA[Graph self-supervised learning has gained significant attention recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-vector-quantized-graph</guid>
    </item>
    <item>
      <title>Post-pre-training for Modality Alignment in Vision-Language Foundation Models</title>
      <link>https://paperswithcode.com/paper/post-pre-training-for-modality-alignment-in</link>
      <description><![CDATA[While CLIP demonstrates remarkable zero-shot performance on downstream tasks, the multi-modal feature spaces still suffer from a modality gap, which is a gap between image and text feature clusters and limits downstream task performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/post-pre-training-for-modality-alignment-in</guid>
    </item>
    <item>
      <title>CM3AE: A Unified RGB Frame and Event-Voxel/-Frame Pre-training Framework</title>
      <link>https://paperswithcode.com/paper/cm3ae-a-unified-rgb-frame-and-event-voxel</link>
      <description><![CDATA[Event cameras have attracted increasing attention in recent years due to their advantages in high dynamic range, high temporal resolution, low power consumption, and low latency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cm3ae-a-unified-rgb-frame-and-event-voxel</guid>
    </item>
    <item>
      <title>TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for Remote Sensing Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/ttrd3-texture-transfer-residual-denoising</link>
      <description><![CDATA[Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution (HR) remote sensing images from low-resolution inputs to support fine-grained ground object interpretation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ttrd3-texture-transfer-residual-denoising</guid>
    </item>
    <item>
      <title>Training-Free Hierarchical Scene Understanding for Gaussian Splatting with Superpoint Graphs</title>
      <link>https://paperswithcode.com/paper/training-free-hierarchical-scene</link>
      <description><![CDATA[Bridging natural language and 3D geometry is a crucial step toward flexible, language-driven scene understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-free-hierarchical-scene</guid>
    </item>
    <item>
      <title>Sleep-time Compute: Beyond Inference Scaling at Test-time</title>
      <link>https://paperswithcode.com/paper/sleep-time-compute-beyond-inference-scaling</link>
      <description><![CDATA[Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sleep-time-compute-beyond-inference-scaling</guid>
    </item>
    <item>
      <title>Stronger, Steadier &amp; Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/stronger-steadier-superior-geometric</link>
      <description><![CDATA[In each layer of the VFMs, we incorporate depth-aware learnable tokens to continuously decouple domain-invariant visual and spatial information, thereby enhancing depth awareness and attention of the VFMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stronger-steadier-superior-geometric</guid>
    </item>
    <item>
      <title>Personalized Text-to-Image Generation with Auto-Regressive Models</title>
      <link>https://paperswithcode.com/paper/personalized-text-to-image-generation-with</link>
      <description><![CDATA[Personalized image synthesis has emerged as a pivotal application in text-to-image generation, enabling the creation of images featuring specific subjects in diverse contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalized-text-to-image-generation-with</guid>
    </item>
    <item>
      <title>Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling</title>
      <link>https://paperswithcode.com/paper/generate-but-verify-reducing-hallucination-in</link>
      <description><![CDATA[Vision-Language Models (VLMs) excel at visual understanding but often suffer from visual hallucinations, where they generate descriptions of nonexistent objects, actions, or concepts, posing significant risks in safety-critical applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generate-but-verify-reducing-hallucination-in</guid>
    </item>
    <item>
      <title>NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement: Methods and Results</title>
      <link>https://paperswithcode.com/paper/ntire-2025-challenge-on-short-form-ugc-video</link>
      <description><![CDATA[This paper presents a review for the NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ntire-2025-challenge-on-short-form-ugc-video</guid>
    </item>
    <item>
      <title>Enhancing the Geometric Problem-Solving Ability of Multimodal LLMs via Symbolic-Neural Integration</title>
      <link>https://paperswithcode.com/paper/enhancing-the-geometric-problem-solving</link>
      <description><![CDATA[This improvement stems from our integration of the strengths of LLMs and symbolic systems, which enables a more reliable and interpretable approach for the GPS task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-the-geometric-problem-solving</guid>
    </item>
    <item>
      <title>CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/cdf-rag-causal-dynamic-feedback-for-adaptive</link>
      <description><![CDATA[We evaluate CDF-RAG on four diverse datasets, demonstrating its ability to improve response accuracy and causal correctness over existing RAG-based methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cdf-rag-causal-dynamic-feedback-for-adaptive</guid>
    </item>
    <item>
      <title>Packing Input Frame Context in Next-Frame Prediction Models for Video Generation</title>
      <link>https://paperswithcode.com/paper/packing-input-frame-context-in-next-frame</link>
      <description><![CDATA[We present a neural network structure, FramePack, to train next-frame (or next-frame-section) prediction models for video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/packing-input-frame-context-in-next-frame</guid>
    </item>
    <item>
      <title>Benchmarking LLM-based Relevance Judgment Methods</title>
      <link>https://paperswithcode.com/paper/benchmarking-llm-based-relevance-judgment</link>
      <description><![CDATA[In addition to a traditional comparison based on system rankings using Kendall correlations, we also examine how well LLM judgments align with human preferences, as inferred from relevance grades.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-llm-based-relevance-judgment</guid>
    </item>
    <item>
      <title>HSS-IAD: A Heterogeneous Same-Sort Industrial Anomaly Detection Dataset</title>
      <link>https://paperswithcode.com/paper/hss-iad-a-heterogeneous-same-sort-industrial</link>
      <description><![CDATA[However, the real-world effectiveness of MUAD methods is questioned due to limitations in current Industrial Anomaly Detection (IAD) datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hss-iad-a-heterogeneous-same-sort-industrial</guid>
    </item>
    <item>
      <title>Physics Informed Constrained Learning of Dynamics from Static Data</title>
      <link>https://paperswithcode.com/paper/physics-informed-constrained-learning-of</link>
      <description><![CDATA[In this study, we developed a new PINN learning paradigm, namely Constrained Learning, that enables the approximation of first-order derivatives or motions using non-time course or partially observed data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physics-informed-constrained-learning-of</guid>
    </item>
    <item>
      <title>Software Engineering Principles for Fairer Systems: Experiments with GroupCART</title>
      <link>https://paperswithcode.com/paper/software-engineering-principles-for-fairer</link>
      <description><![CDATA[Traditional decision tree learners typically optimize for information gain in the target attribute alone, which can result in models that unfairly discriminate against protected social groups (e. g., gender, ethnicity).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/software-engineering-principles-for-fairer</guid>
    </item>
    <item>
      <title>Image-Editing Specialists: An RLAIF Approach for Diffusion Models</title>
      <link>https://paperswithcode.com/paper/image-editing-specialists-an-rlaif-approach</link>
      <description><![CDATA[We present a novel approach to training specialized instruction-based image-editing diffusion models, addressing key challenges in structural preservation with input images and semantic alignment with user prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/image-editing-specialists-an-rlaif-approach</guid>
    </item>
    <item>
      <title>Hierarchical Feature Learning for Medical Point Clouds via State Space Model</title>
      <link>https://paperswithcode.com/paper/hierarchical-feature-learning-for-medical</link>
      <description><![CDATA[The dataset is available at https://flemme-docs. readthedocs. io/en/latest/medpoints. html.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-feature-learning-for-medical</guid>
    </item>
    <item>
      <title>Chinese-Vicuna: A Chinese Instruction-following Llama-based Model</title>
      <link>https://paperswithcode.com/paper/chinese-vicuna-a-chinese-instruction</link>
      <description><![CDATA[Chinese-Vicuna is an open-source, resource-efficient language model designed to bridge the gap in Chinese instruction-following capabilities by fine-tuning Meta's LLaMA architecture using Low-Rank Adaptation (LoRA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chinese-vicuna-a-chinese-instruction</guid>
    </item>
    <item>
      <title>Event-Enhanced Blurry Video Super-Resolution</title>
      <link>https://paperswithcode.com/paper/event-enhanced-blurry-video-super-resolution</link>
      <description><![CDATA[In this paper, we tackle the task of blurry video super-resolution (BVSR), aiming to generate high-resolution (HR) videos from low-resolution (LR) and blurry inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/event-enhanced-blurry-video-super-resolution</guid>
    </item>
    <item>
      <title>FashionDPO:Fine-tune Fashion Outfit Generation Model using Direct Preference Optimization</title>
      <link>https://paperswithcode.com/paper/fashiondpo-fine-tune-fashion-outfit</link>
      <description><![CDATA[Personalized outfit generation aims to construct a set of compatible and personalized fashion items as an outfit.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fashiondpo-fine-tune-fashion-outfit</guid>
    </item>
    <item>
      <title>Taccel: Scaling Up Vision-based Tactile Robotics via High-performance GPU Simulation</title>
      <link>https://paperswithcode.com/paper/taccel-scaling-up-vision-based-tactile</link>
      <description><![CDATA[Tactile sensing is crucial for achieving human-level robotic capabilities in manipulation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taccel-scaling-up-vision-based-tactile</guid>
    </item>
    <item>
      <title>A Phenomenological Approach to Analyzing User Queries in IT Systems Using Heidegger's Fundamental Ontology</title>
      <link>https://paperswithcode.com/paper/a-phenomenological-approach-to-analyzing-user</link>
      <description><![CDATA[This paper presents a novel research analytical IT system grounded in Martin Heidegger's Fundamental Ontology, distinguishing between beings (das Seiende) and Being (das Sein).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-phenomenological-approach-to-analyzing-user</guid>
    </item>
    <item>
      <title>Estimating Optimal Context Length for Hybrid Retrieval-augmented Multi-document Summarization</title>
      <link>https://paperswithcode.com/paper/estimating-optimal-context-length-for-hybrid</link>
      <description><![CDATA[Our method first estimates the optimal retrieval length as a function of the retriever, summarizer, and dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/estimating-optimal-context-length-for-hybrid</guid>
    </item>
    <item>
      <title>Data-efficient LLM Fine-tuning for Code Generation</title>
      <link>https://paperswithcode.com/paper/data-efficient-llm-fine-tuning-for-code</link>
      <description><![CDATA[In this work, we propose a data selection strategy in order to improve the effectiveness and efficiency of training for code-based LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-efficient-llm-fine-tuning-for-code</guid>
    </item>
    <item>
      <title>EchoWorld: Learning Motion-Aware World Models for Echocardiography Probe Guidance</title>
      <link>https://paperswithcode.com/paper/echoworld-learning-motion-aware-world-models</link>
      <description><![CDATA[To address this, we present EchoWorld, a motion-aware world modeling framework for probe guidance that encodes anatomical knowledge and motion-induced visual dynamics, while effectively leveraging past visual-motion sequences to enhance guidance precision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/echoworld-learning-motion-aware-world-models</guid>
    </item>
    <item>
      <title>Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual Try-Off</title>
      <link>https://paperswithcode.com/paper/enhancing-person-to-person-virtual-try-on</link>
      <description><![CDATA[VTON generates images of a person in a specified garment using a target photo and a standardized garment image, while a more challenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo of another person wearing the garment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-person-to-person-virtual-try-on</guid>
    </item>
    <item>
      <title>Saliency-Aware Diffusion Reconstruction for Effective Invisible Watermark Removal</title>
      <link>https://paperswithcode.com/paper/saliency-aware-diffusion-reconstruction-for</link>
      <description><![CDATA[This paper introduces a novel Saliency-Aware Diffusion Reconstruction (SADRE) framework for watermark elimination on the web, combining adaptive noise injection, region-specific perturbations, and advanced diffusion-based reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/saliency-aware-diffusion-reconstruction-for</guid>
    </item>
    <item>
      <title>Effective Dual-Region Augmentation for Reduced Reliance on Large Amounts of Labeled Data</title>
      <link>https://paperswithcode.com/paper/effective-dual-region-augmentation-for</link>
      <description><![CDATA[This paper introduces a novel dual-region augmentation approach designed to reduce reliance on large-scale labeled datasets while improving model robustness and adaptability across diverse computer vision tasks, including source-free domain adaptation (SFDA) and person re-identification (ReID).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effective-dual-region-augmentation-for</guid>
    </item>
    <item>
      <title>Set You Straight: Auto-Steering Denoising Trajectories to Sidestep Unwanted Concepts</title>
      <link>https://paperswithcode.com/paper/set-you-straight-auto-steering-denoising</link>
      <description><![CDATA[Anchor-free methods risk disrupting sampling trajectories, leading to visual artifacts, while anchor-based methods rely on the heuristic selection of anchor concepts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/set-you-straight-auto-steering-denoising</guid>
    </item>
    <item>
      <title>ArtistAuditor: Auditing Artist Style Pirate in Text-to-Image Generation Models</title>
      <link>https://paperswithcode.com/paper/artistauditor-auditing-artist-style-pirate-in</link>
      <description><![CDATA[However, when the artwork or the model has been published online, i. e., modification to the original artwork or model retraining is not feasible, these strategies might not be viable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/artistauditor-auditing-artist-style-pirate-in</guid>
    </item>
    <item>
      <title>Search is All You Need for Few-shot Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/search-is-all-you-need-for-few-shot-anomaly</link>
      <description><![CDATA[Few-shot anomaly detection (FSAD) has emerged as a crucial yet challenging task in industrial inspection, where normal distribution modeling must be accomplished with only a few normal images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/search-is-all-you-need-for-few-shot-anomaly</guid>
    </item>
    <item>
      <title>SkeletonX: Data-Efficient Skeleton-based Action Recognition via Cross-sample Feature Aggregation</title>
      <link>https://paperswithcode.com/paper/skeletonx-data-efficient-skeleton-based</link>
      <description><![CDATA[First, we propose a tailored sample pair construction strategy on two key attributes to form and aggregate sample pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/skeletonx-data-efficient-skeleton-based</guid>
    </item>
    <item>
      <title>Correlation Ratio for Unsupervised Learning of Multi-modal Deformable Registration</title>
      <link>https://paperswithcode.com/paper/correlation-ratio-for-unsupervised-learning</link>
      <description><![CDATA[This approach involves training a registration network using pairs of moving and fixed images, along with a loss function that combines an image similarity measure and deformation regularization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/correlation-ratio-for-unsupervised-learning</guid>
    </item>
    <item>
      <title>BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents</title>
      <link>https://paperswithcode.com/paper/browsecomp-a-simple-yet-challenging-benchmark</link>
      <description><![CDATA[BrowseComp for browsing agents can be seen as analogous to how programming competitions are an incomplete but useful benchmark for coding agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/browsecomp-a-simple-yet-challenging-benchmark</guid>
    </item>
    <item>
      <title>Dense Backpropagation Improves Training for Sparse Mixture-of-Experts</title>
      <link>https://paperswithcode.com/paper/dense-backpropagation-improves-training-for</link>
      <description><![CDATA[Mixture of Experts (MoE) pretraining is more scalable than dense Transformer pretraining, because MoEs learn to route inputs to a sparse set of their feedforward parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dense-backpropagation-improves-training-for</guid>
    </item>
    <item>
      <title>An Online Adaptation Method for Robust Depth Estimation and Visual Odometry in the Open World</title>
      <link>https://paperswithcode.com/paper/an-online-adaptation-method-for-robust-depth</link>
      <description><![CDATA[To this end, we construct a self-supervised online adaptation framework for monocular visual odometry aided by an online-updated depth estimation module.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-online-adaptation-method-for-robust-depth</guid>
    </item>
    <item>
      <title>Leave-One-Out Stable Conformal Prediction</title>
      <link>https://paperswithcode.com/paper/leave-one-out-stable-conformal-prediction</link>
      <description><![CDATA[Conformal prediction (CP) is an important tool for distribution-free predictive uncertainty quantification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leave-one-out-stable-conformal-prediction</guid>
    </item>
    <item>
      <title>SEROAISE: Advancing ROA Estimation for ReLU and PWA Dynamics through Estimating Certified Invariant Sets</title>
      <link>https://paperswithcode.com/paper/seroaise-advancing-roa-estimation-for-relu</link>
      <description><![CDATA[This method, described as Sequential Estimation of RoA based on Invariant Set Estimation (SEROAISE), computes a Lyapunov-like PWA function over a certified PWA invariant set.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seroaise-advancing-roa-estimation-for-relu</guid>
    </item>
    <item>
      <title>Exploring Video-Based Driver Activity Recognition under Noisy Labels</title>
      <link>https://paperswithcode.com/paper/exploring-video-based-driver-activity</link>
      <description><![CDATA[As an open research topic in the field of deep learning, learning with noisy labels has attracted much attention and grown rapidly over the past ten years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-video-based-driver-activity</guid>
    </item>
    <item>
      <title>GrabS: Generative Embodied Agent for 3D Object Segmentation without Scene Supervision</title>
      <link>https://paperswithcode.com/paper/grabs-generative-embodied-agent-for-3d-object</link>
      <description><![CDATA[We study the hard problem of 3D object segmentation in complex point clouds without requiring human labels of 3D scenes for supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grabs-generative-embodied-agent-for-3d-object</guid>
    </item>
  </channel>
</rss>
