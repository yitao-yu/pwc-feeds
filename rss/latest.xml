<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 19 Mar 2025 21:09:25 +0000</lastBuildDate>
    <item>
      <title>GFSNetwork: Differentiable Feature Selection via Gumbel-Sigmoid Relaxation</title>
      <link>https://paperswithcode.com/paper/gfsnetwork-differentiable-feature-selection</link>
      <description><![CDATA[Unlike traditional methods, where the user has to define the requested number of features, GFSNetwork selects it automatically during an end-to-end process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gfsnetwork-differentiable-feature-selection</guid>
    </item>
    <item>
      <title>MaTVLM: Hybrid Mamba-Transformer for Efficient Vision-Language Modeling</title>
      <link>https://paperswithcode.com/paper/matvlm-hybrid-mamba-transformer-for-efficient</link>
      <description><![CDATA[In this work, we present a hybrid model MaTVLM by substituting a portion of the transformer decoder layers in a pre-trained VLM with Mamba-2 layers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/matvlm-hybrid-mamba-transformer-for-efficient</guid>
    </item>
    <item>
      <title>UncTrack: Reliable Visual Object Tracking with Uncertainty-Aware Prototype Memory Network</title>
      <link>https://paperswithcode.com/paper/unctrack-reliable-visual-object-tracking-with</link>
      <description><![CDATA[Then the localization uncertainty is sent into a prototype memory network (PMN) to excavate valuable historical information to identify whether the target state prediction is reliable or not.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unctrack-reliable-visual-object-tracking-with</guid>
    </item>
    <item>
      <title>Lifting the Veil on Visual Information Flow in MLLMs: Unlocking Pathways to Faster Inference</title>
      <link>https://paperswithcode.com/paper/lifting-the-veil-on-visual-information-flow</link>
      <description><![CDATA[Multimodal large language models (MLLMs) improve performance on vision-language tasks by integrating visual features from pre-trained vision encoders into large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lifting-the-veil-on-visual-information-flow</guid>
    </item>
    <item>
      <title>ClearSight: Visual Signal Enhancement for Object Hallucination Mitigation in Multimodal Large language Models</title>
      <link>https://paperswithcode.com/paper/clearsight-visual-signal-enhancement-for</link>
      <description><![CDATA[However, these methods present two main limitations: (1) bluntly suppressing language priors can compromise coherence and accuracy of generated content, and (2) processing contrastive inputs adds computational load, significantly slowing inference speed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clearsight-visual-signal-enhancement-for</guid>
    </item>
    <item>
      <title>Valid Text-to-SQL Generation with Unification-based DeepStochLog</title>
      <link>https://paperswithcode.com/paper/valid-text-to-sql-generation-with-unification</link>
      <description><![CDATA[We propose a neurosymbolic framework that imposes SQL syntax and schema constraints with unification-based definite clause grammars and thus guarantees the generation of valid queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/valid-text-to-sql-generation-with-unification</guid>
    </item>
    <item>
      <title>Real-Time Cell Sorting with Scalable In Situ FPGA-Accelerated Deep Learning</title>
      <link>https://paperswithcode.com/paper/real-time-cell-sorting-with-scalable-in-situ</link>
      <description><![CDATA[This framework provides a scalable, cost-effective solution for lymphocyte classification, as well as a new SOTA real-time cell sorting implementation for rapid identification of subsets using in situ deep learning on off-the-shelf computing hardware.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-cell-sorting-with-scalable-in-situ</guid>
    </item>
    <item>
      <title>Niagara: Normal-Integrated Geometric Affine Field for Scene Reconstruction from a Single View</title>
      <link>https://paperswithcode.com/paper/niagara-normal-integrated-geometric-affine</link>
      <description><![CDATA[Recent advances in single-view 3D scene reconstruction have highlighted the challenges in capturing fine geometric details and ensuring structural consistency, particularly in high-fidelity outdoor scene modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/niagara-normal-integrated-geometric-affine</guid>
    </item>
    <item>
      <title>GCBLANE: A graph-enhanced convolutional BiLSTM attention network for improved transcription factor binding site prediction</title>
      <link>https://paperswithcode.com/paper/gcblane-a-graph-enhanced-convolutional-bilstm</link>
      <description><![CDATA[It integrates convolutional, multi-head attention, and recurrent layers with a graph neural network to detect key features for TFBS prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gcblane-a-graph-enhanced-convolutional-bilstm</guid>
    </item>
    <item>
      <title>LLM-Driven Multi-step Translation from C to Rust using Static Analysis</title>
      <link>https://paperswithcode.com/paper/llm-driven-multi-step-translation-from-c-to</link>
      <description><![CDATA[Translating software written in legacy languages to modern languages, such as C to Rust, has significant benefits in improving memory safety while maintaining high performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-driven-multi-step-translation-from-c-to</guid>
    </item>
    <item>
      <title>Shadow Art Kanji: Inverse Rendering Application</title>
      <link>https://paperswithcode.com/paper/shadow-art-kanji-inverse-rendering</link>
      <description><![CDATA[Finding a balance between artistic beauty and machine-generated imagery is always a difficult task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shadow-art-kanji-inverse-rendering</guid>
    </item>
    <item>
      <title>SEAL: Semantic Aware Image Watermarking</title>
      <link>https://paperswithcode.com/paper/seal-semantic-aware-image-watermarking-1</link>
      <description><![CDATA[In this paper, we propose a novel watermarking method that embeds semantic information about the generated image directly into the watermark, enabling a distortion-free watermark that can be verified without requiring a database of key patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seal-semantic-aware-image-watermarking-1</guid>
    </item>
    <item>
      <title>Seeing Sarcasm Through Different Eyes: Analyzing Multimodal Sarcasm Perception in Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/seeing-sarcasm-through-different-eyes-1</link>
      <description><![CDATA[With the advent of large vision-language models (LVLMs) demonstrating increasingly human-like abilities, a pivotal question emerges: do different LVLMs interpret multimodal sarcasm differently, and can a single model grasp sarcasm from multiple perspectives like humans?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seeing-sarcasm-through-different-eyes-1</guid>
    </item>
    <item>
      <title>SteerX: Creating Any Camera-Free 3D and 4D Scenes with Geometric Steering</title>
      <link>https://paperswithcode.com/paper/steerx-creating-any-camera-free-3d-and-4d</link>
      <description><![CDATA[Recent progress in 3D/4D scene generation emphasizes the importance of physical alignment throughout video generation and scene reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/steerx-creating-any-camera-free-3d-and-4d</guid>
    </item>
    <item>
      <title>Minding Fuzzy Regions: A Data-driven Alternating Learning Paradigm for Stable Lesion Segmentation</title>
      <link>https://paperswithcode.com/paper/minding-fuzzy-regions-a-data-driven</link>
      <description><![CDATA[In this paper, a data-driven alternating learning (DALE) paradigm is proposed to optimize the model's training process, achieving stable and high-precision segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minding-fuzzy-regions-a-data-driven</guid>
    </item>
    <item>
      <title>VGGT: Visual Geometry Grounded Transformer</title>
      <link>https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</link>
      <description><![CDATA[We present VGGT, a feed-forward neural network that directly infers all key 3D attributes of a scene, including camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</guid>
    </item>
    <item>
      <title>Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-outperforms-supervised</link>
      <description><![CDATA[Recently, reinforcement learning (RL) has been shown to greatly enhance the reasoning capabilities of large language models (LLMs), and RL-based approaches have been progressively applied to visual multimodal tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-outperforms-supervised</guid>
    </item>
    <item>
      <title>Integrating Dynamical Systems Modeling with Spatiotemporal scRNA-seq Data Analysis</title>
      <link>https://paperswithcode.com/paper/integrating-dynamical-systems-modeling-with</link>
      <description><![CDATA[Understanding the dynamic nature of biological systems is fundamental to deciphering cellular behavior, developmental processes, and disease progression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/integrating-dynamical-systems-modeling-with</guid>
    </item>
    <item>
      <title>TikZero: Zero-Shot Text-Guided Graphics Program Synthesis</title>
      <link>https://paperswithcode.com/paper/tikzero-zero-shot-text-guided-graphics</link>
      <description><![CDATA[Meanwhile, large amounts of unaligned graphics programs and captioned raster images are more readily available.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tikzero-zero-shot-text-guided-graphics</guid>
    </item>
    <item>
      <title>LLMPerf: GPU Performance Modeling meets Large Language Models</title>
      <link>https://paperswithcode.com/paper/llmperf-gpu-performance-modeling-meets-large</link>
      <description><![CDATA[On a set of publicly available OpenCL programs, our model achieves a mean absolute percentage error of $46. 1\%$.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llmperf-gpu-performance-modeling-meets-large</guid>
    </item>
    <item>
      <title>Distance-Based Tree-Sliced Wasserstein Distance</title>
      <link>https://paperswithcode.com/paper/distance-based-tree-sliced-wasserstein</link>
      <description><![CDATA[However, projecting measures onto low-dimensional spaces can lead to a loss of topological information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distance-based-tree-sliced-wasserstein</guid>
    </item>
    <item>
      <title>Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery</title>
      <link>https://paperswithcode.com/paper/cerebrum-aios-sdk-a-platform-for-agent</link>
      <description><![CDATA[Autonomous LLM-based agents have emerged as a powerful paradigm for complex task execution, yet the field lacks standardized tools for development, deployment, distribution and discovery of agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cerebrum-aios-sdk-a-platform-for-agent</guid>
    </item>
    <item>
      <title>TxAgent: An AI Agent for Therapeutic Reasoning Across a Universe of Tools</title>
      <link>https://paperswithcode.com/paper/txagent-an-ai-agent-for-therapeutic-reasoning</link>
      <description><![CDATA[It selects tools based on task objectives and executes structured function calls to solve therapeutic tasks that require clinical reasoning and cross-source validation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/txagent-an-ai-agent-for-therapeutic-reasoning</guid>
    </item>
    <item>
      <title>Multimodal-Aware Fusion Network for Referring Remote Sensing Image Segmentation</title>
      <link>https://paperswithcode.com/paper/multimodal-aware-fusion-network-for-referring</link>
      <description><![CDATA[Referring remote sensing image segmentation (RRSIS) is a novel visual task in remote sensing images segmentation, which aims to segment objects based on a given text description, with great significance in practical application.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-aware-fusion-network-for-referring</guid>
    </item>
    <item>
      <title>Generative Modeling for Mathematical Discovery</title>
      <link>https://paperswithcode.com/paper/generative-modelling-for-mathematical</link>
      <description><![CDATA[We present a new implementation of the LLM-driven genetic algorithm {\it funsearch}, whose aim is to generate examples of interest to mathematicians and which has already had some success in problems in extremal combinatorics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-modelling-for-mathematical</guid>
    </item>
    <item>
      <title>Implicit Bias-Like Patterns in Reasoning Models</title>
      <link>https://paperswithcode.com/paper/implicit-bias-like-patterns-in-reasoning</link>
      <description><![CDATA[Implicit bias refers to automatic or spontaneous mental processes that shape perceptions, judgments, and behaviors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implicit-bias-like-patterns-in-reasoning</guid>
    </item>
    <item>
      <title>Can Large Reasoning Models do Analogical Reasoning under Perceptual Uncertainty?</title>
      <link>https://paperswithcode.com/paper/can-large-reasoning-models-do-analogical</link>
      <description><![CDATA[To assess the influence of visual uncertainties on these nonverbal analogical reasoning tests, we extend the I-RAVEN-X dataset, which otherwise assumes an oracle perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-large-reasoning-models-do-analogical</guid>
    </item>
    <item>
      <title>MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens</title>
      <link>https://paperswithcode.com/paper/mms-llama-efficient-llm-based-audio-visual-1</link>
      <description><![CDATA[Audio-Visual Speech Recognition (AVSR) achieves robust speech recognition in noisy environments by combining auditory and visual information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mms-llama-efficient-llm-based-audio-visual-1</guid>
    </item>
    <item>
      <title>Bottom-up Iterative Anomalous Diffusion Detector (BI-ADD)</title>
      <link>https://paperswithcode.com/paper/bottom-up-iterative-anomalous-diffusion</link>
      <description><![CDATA[A trajectory in our case follows a fractional Brownian motion and we estimate the diffusive properties of the trajectories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bottom-up-iterative-anomalous-diffusion</guid>
    </item>
    <item>
      <title>An Ensemble-Based Two-Step Framework for Classification of Pap Smear Cell Images</title>
      <link>https://paperswithcode.com/paper/ps3c-an-ensemble-based-two-step-framework-for</link>
      <description><![CDATA[This project aims to promote the development of automated tools for pap smear images classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ps3c-an-ensemble-based-two-step-framework-for</guid>
    </item>
    <item>
      <title>An Real-Sim-Real (RSR) Loop Framework for Generalizable Robotic Policy Transfer with Differentiable Simulation</title>
      <link>https://paperswithcode.com/paper/an-real-sim-real-rsr-loop-framework-for</link>
      <description><![CDATA[The sim-to-real gap remains a critical challenge in robotics, hindering the deployment of algorithms trained in simulation to real-world systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-real-sim-real-rsr-loop-framework-for</guid>
    </item>
    <item>
      <title>EEdit : Rethinking the Spatial and Temporal Redundancy for Efficient Image Editing</title>
      <link>https://paperswithcode.com/paper/eedit-rethinking-the-spatial-and-temporal</link>
      <description><![CDATA[Inversion-based image editing is rapidly gaining momentum while suffering from significant computation overhead, hindering its application in real-time interactive scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eedit-rethinking-the-spatial-and-temporal</guid>
    </item>
    <item>
      <title>StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error</title>
      <link>https://paperswithcode.com/paper/stepmathagent-a-step-wise-agent-for</link>
      <description><![CDATA[Evaluating mathematical capabilities is critical for assessing the overall performance of large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stepmathagent-a-step-wise-agent-for</guid>
    </item>
    <item>
      <title>DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding</title>
      <link>https://paperswithcode.com/paper/drivelmm-o1-a-step-by-step-reasoning-dataset</link>
      <description><![CDATA[Our model achieves a +7. 49% gain in final answer accuracy, along with a 3. 62% improvement in reasoning score over the previous best open-source model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drivelmm-o1-a-step-by-step-reasoning-dataset</guid>
    </item>
    <item>
      <title>AdvPaint: Protecting Images from Inpainting Manipulation via Adversarial Attention Disruption</title>
      <link>https://paperswithcode.com/paper/advpaint-protecting-images-from-inpainting</link>
      <description><![CDATA[The outstanding capability of diffusion models in generating high-quality images poses significant threats when misused by adversaries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advpaint-protecting-images-from-inpainting</guid>
    </item>
    <item>
      <title>Hierarchical Self-Supervised Adversarial Training for Robust Vision Models in Histopathology</title>
      <link>https://paperswithcode.com/paper/hierarchical-self-supervised-adversarial</link>
      <description><![CDATA[Adversarial attacks pose significant challenges for vision models in critical fields like healthcare, where reliability is essential.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-self-supervised-adversarial</guid>
    </item>
    <item>
      <title>OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model</title>
      <link>https://paperswithcode.com/paper/or-llm-agent-automating-modeling-and-solving</link>
      <description><![CDATA[Due to the lack of dedicated benchmark datasets for evaluating the automated solving of OR problems, we construct a benchmark dataset comprising 83 real-world OR problems described in natural language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/or-llm-agent-automating-modeling-and-solving</guid>
    </item>
    <item>
      <title>High-Resolution Uplink Sensing in Millimeter-Wave ISAC Systems</title>
      <link>https://paperswithcode.com/paper/high-resolution-uplink-sensing-in-millimeter</link>
      <description><![CDATA[We then propose several methods for constructing a ``clean'' reference signal, which is subsequently used to cancel the effect caused by the clock asynchrony.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-resolution-uplink-sensing-in-millimeter</guid>
    </item>
    <item>
      <title>OODD: Test-time Out-of-Distribution Detection with Dynamic Dictionary</title>
      <link>https://paperswithcode.com/paper/oodd-test-time-out-of-distribution-detection</link>
      <description><![CDATA[Out-of-distribution (OOD) detection remains challenging for deep learning models, particularly when test-time OOD samples differ significantly from training outliers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oodd-test-time-out-of-distribution-detection</guid>
    </item>
    <item>
      <title>OCCUQ: Exploring Efficient Uncertainty Quantification for 3D Occupancy Prediction</title>
      <link>https://paperswithcode.com/paper/occuq-exploring-efficient-uncertainty</link>
      <description><![CDATA[Our approach consistently demonstrates reliable uncertainty measures, indicating its potential for enhancing the robustness of autonomous driving systems in real-world scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/occuq-exploring-efficient-uncertainty</guid>
    </item>
    <item>
      <title>A Hierarchical Semantic Distillation Framework for Open-Vocabulary Object Detection</title>
      <link>https://paperswithcode.com/paper/a-hierarchical-semantic-distillation</link>
      <description><![CDATA[In this work, we propose a hierarchical semantic distillation framework named HD-OVD to construct a comprehensive distillation process, which exploits generalizable knowledge from the CLIP model in three aspects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-hierarchical-semantic-distillation</guid>
    </item>
    <item>
      <title>GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding</title>
      <link>https://paperswithcode.com/paper/groundingsuite-measuring-complex-multi</link>
      <description><![CDATA[Pixel grounding, encompassing tasks such as Referring Expression Segmentation (RES), has garnered considerable attention due to its immense potential for bridging the gap between vision and language modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/groundingsuite-measuring-complex-multi</guid>
    </item>
    <item>
      <title>OVTR: End-to-End Open-Vocabulary Multiple Object Tracking with Transformer</title>
      <link>https://paperswithcode.com/paper/ovtr-end-to-end-open-vocabulary-multiple</link>
      <description><![CDATA[Open-vocabulary multiple object tracking aims to generalize trackers to unseen categories during training, enabling their application across a variety of real-world scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ovtr-end-to-end-open-vocabulary-multiple</guid>
    </item>
    <item>
      <title>Information Density Principle for MLLM Benchmarks</title>
      <link>https://paperswithcode.com/paper/information-density-principle-for-mllm</link>
      <description><![CDATA[Therefore, we propose a critical principle of Information Density, which examines how much insight a benchmark can provide for the development of MLLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/information-density-principle-for-mllm</guid>
    </item>
    <item>
      <title>Probing LLMs for Multilingual Discourse Generalization Through a Unified Label Set</title>
      <link>https://paperswithcode.com/paper/probing-llms-for-multilingual-discourse</link>
      <description><![CDATA[Discourse understanding is essential for many NLP tasks, yet most existing work remains constrained by framework-dependent discourse representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probing-llms-for-multilingual-discourse</guid>
    </item>
    <item>
      <title>TokenCarve: Information-Preserving Visual Token Compression in Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/tokencarve-information-preserving-visual</link>
      <description><![CDATA[This insight introduces a novel information-preserving perspective, making it possible to maintain performance even under extreme token compression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tokencarve-information-preserving-visual</guid>
    </item>
    <item>
      <title>VisTai: Benchmarking Vision-Language Models for Traditional Chinese in Taiwan</title>
      <link>https://paperswithcode.com/paper/vistai-benchmarking-vision-language-models</link>
      <description><![CDATA[In this paper, we propose a comprehensive evaluation benchmark for Visual Language Models (VLM) in Traditional Chinese.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vistai-benchmarking-vision-language-models</guid>
    </item>
    <item>
      <title>VMBench: A Benchmark for Perception-Aligned Video Motion Generation</title>
      <link>https://paperswithcode.com/paper/vmbench-a-benchmark-for-perception-aligned</link>
      <description><![CDATA[Based on these findings, we introduce VMBench--a comprehensive Video Motion Benchmark that has perception-aligned motion metrics and features the most diverse types of motion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vmbench-a-benchmark-for-perception-aligned</guid>
    </item>
    <item>
      <title>Retrieval-Augmented Generation with Hierarchical Knowledge</title>
      <link>https://paperswithcode.com/paper/retrieval-augmented-generation-with-1</link>
      <description><![CDATA[Graph-based Retrieval-Augmented Generation (RAG) methods have significantly enhanced the performance of large language models (LLMs) in domain-specific tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retrieval-augmented-generation-with-1</guid>
    </item>
    <item>
      <title>A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1</title>
      <link>https://paperswithcode.com/paper/a-frustratingly-simple-yet-highly-effective</link>
      <description><![CDATA[Despite promising performance on open-source large vision-language models (LVLMs), transfer-based targeted attacks often fail against black-box commercial LVLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-frustratingly-simple-yet-highly-effective</guid>
    </item>
  </channel>
</rss>
