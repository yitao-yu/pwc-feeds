<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 22 Mar 2025 09:16:15 +0000</lastBuildDate>
    <item>
      <title>ELTEX: A Framework for Domain-Driven Synthetic Data Generation</title>
      <link>https://paperswithcode.com/paper/eltex-a-framework-for-domain-driven-synthetic</link>
      <description><![CDATA[We release a curated synthetic dataset of social media texts for cyberattack detection in blockchain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eltex-a-framework-for-domain-driven-synthetic</guid>
    </item>
    <item>
      <title>Dynamic Bi-Elman Attention Networks (DBEAN): Dual-Directional Context-Aware Representation Learning for Enhanced Text Classification</title>
      <link>https://paperswithcode.com/paper/dynamic-bi-elman-attention-networks-dbean</link>
      <description><![CDATA[Text classification, a fundamental task in natural language processing (NLP), aims to categorize textual data into predefined labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-bi-elman-attention-networks-dbean</guid>
    </item>
    <item>
      <title>PiEEG kit - bioscience Lab in home for your Brain and Body</title>
      <link>https://paperswithcode.com/paper/pieeg-kit-bioscience-lab-in-home-for-your</link>
      <description><![CDATA[PiEEG kit is a multifunctional, compact, and mobile device that allows measure EEG, EMG, EOG, and EKG signals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pieeg-kit-bioscience-lab-in-home-for-your</guid>
    </item>
    <item>
      <title>Model Hubs and Beyond: Analyzing Model Popularity, Performance, and Documentation</title>
      <link>https://paperswithcode.com/paper/model-hubs-and-beyond-analyzing-model</link>
      <description><![CDATA[Additionally, we identify critical inconsistencies in model card reporting: approximately 80\% of the models analyzed lack detailed information about the model, training, and evaluation processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/model-hubs-and-beyond-analyzing-model</guid>
    </item>
    <item>
      <title>Text-Derived Relational Graph-Enhanced Network for Skeleton-Based Action Segmentation</title>
      <link>https://paperswithcode.com/paper/text-derived-relational-graph-enhanced</link>
      <description><![CDATA[Additionally, we propose a Spatial-Aware Enhancement Processing (SAEP) method, which incorporates random joint occlusion and axial rotation to enhance spatial generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-derived-relational-graph-enhanced</guid>
    </item>
    <item>
      <title>Reliable uncertainty quantification for 2D/3D anatomical landmark localization using multi-output conformal prediction</title>
      <link>https://paperswithcode.com/paper/reliable-uncertainty-quantification-for-2d-3d</link>
      <description><![CDATA[Through extensive empirical evaluation across multiple 2D and 3D datasets, we demonstrate that our methods consistently outperform existing multi-output conformal prediction approaches in both validity and efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reliable-uncertainty-quantification-for-2d-3d</guid>
    </item>
    <item>
      <title>Room Impulse Response Estimation through Optimal Mass Transport Barycenters</title>
      <link>https://paperswithcode.com/paper/room-impulse-response-estimation-through</link>
      <description><![CDATA[In this work, we consider the problem of jointly estimating a set of room impulse responses (RIRs) corresponding to closely spaced microphones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/room-impulse-response-estimation-through</guid>
    </item>
    <item>
      <title>MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling</title>
      <link>https://paperswithcode.com/paper/meshfleet-filtered-and-annotated-3d-vehicle</link>
      <description><![CDATA[Fine-tuning large generative models is a promising perspective for making these models available in these fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meshfleet-filtered-and-annotated-3d-vehicle</guid>
    </item>
    <item>
      <title>RoGSplat: Learning Robust Generalizable Human Gaussian Splatting from Sparse Multi-View Images</title>
      <link>https://paperswithcode.com/paper/rogsplat-learning-robust-generalizable-human</link>
      <description><![CDATA[To account for possible misalignment between SMPL model and images, we propose to predict image-aligned 3D prior points by leveraging both pixel-level features and voxel-level features, from which we regress the coarse Gaussians.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rogsplat-learning-robust-generalizable-human</guid>
    </item>
    <item>
      <title>Make Your Training Flexible: Towards Deployment-Efficient Video Models</title>
      <link>https://paperswithcode.com/paper/make-your-training-flexible-towards</link>
      <description><![CDATA[By making the sampling grid flexible and leveraging token selection, it is easily adopted in most popular video training frameworks, boosting model robustness with nearly no additional cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/make-your-training-flexible-towards</guid>
    </item>
    <item>
      <title>Inducing Causal Structure for Interpretable Neural Networks Applied to Glucose Prediction for T1DM Patients</title>
      <link>https://paperswithcode.com/paper/inducing-causal-structure-for-interpretable-1</link>
      <description><![CDATA[Causal abstraction techniques such as Interchange Intervention Training (IIT) have been proposed to infuse neural network with expert knowledge encoded in causal models, but their application to real-world problems remains limited.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inducing-causal-structure-for-interpretable-1</guid>
    </item>
    <item>
      <title>State Space Model Meets Transformer: A New Paradigm for 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/state-space-model-meets-transformer-a-new-1</link>
      <description><![CDATA[To the best of our knowledge, this is the first method to model queries as system states and scene points as system inputs, which can simultaneously update scene point features and query features with linear complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/state-space-model-meets-transformer-a-new-1</guid>
    </item>
    <item>
      <title>Second language Korean Universal Dependency treebank v1.2: Focus on data augmentation and annotation scheme refinement</title>
      <link>https://paperswithcode.com/paper/second-language-korean-universal-dependency</link>
      <description><![CDATA[We expand the second language (L2) Korean Universal Dependencies (UD) treebank with 5, 454 manually annotated sentences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/second-language-korean-universal-dependency</guid>
    </item>
    <item>
      <title>NERCat: Fine-Tuning for Enhanced Named Entity Recognition in Catalan</title>
      <link>https://paperswithcode.com/paper/nercat-fine-tuning-for-enhanced-named-entity</link>
      <description><![CDATA[Named Entity Recognition (NER) is a critical component of Natural Language Processing (NLP) for extracting structured information from unstructured text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nercat-fine-tuning-for-enhanced-named-entity</guid>
    </item>
    <item>
      <title>DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal</title>
      <link>https://paperswithcode.com/paper/dars-dynamic-action-re-sampling-to-enhance</link>
      <description><![CDATA[To improve coding agent performance, we present Dynamic Action Re-Sampling (DARS), a novel inference time compute scaling approach for coding agents, that is faster and more effective at recovering from sub-optimal decisions compared to baselines.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dars-dynamic-action-re-sampling-to-enhance</guid>
    </item>
    <item>
      <title>Rethinking End-to-End 2D to 3D Scene Segmentation in Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/rethinking-end-to-end-2d-to-3d-scene</link>
      <description><![CDATA[Therefore, we formulate the association learning module and the noisy label filtering module for effective and robust codebook learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-end-to-end-2d-to-3d-scene</guid>
    </item>
    <item>
      <title>Exploiting Inherent Class Label: Towards Robust Scribble Supervised Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/exploiting-inherent-class-label-towards</link>
      <description><![CDATA[Scribble-based weakly supervised semantic segmentation leverages only a few annotated pixels as labels to train a segmentation model, presenting significant potential for reducing the human labor involved in the annotation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploiting-inherent-class-label-towards</guid>
    </item>
    <item>
      <title>SimWorld: A Unified Benchmark for Simulator-Conditioned Scene Generation via World Model</title>
      <link>https://paperswithcode.com/paper/simworld-a-unified-benchmark-for-simulator</link>
      <description><![CDATA[It is a novel data generation pipeline by combining the powerful scene simulation capabilities of the simulation engine with the robust data generation capabilities of the world model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simworld-a-unified-benchmark-for-simulator</guid>
    </item>
    <item>
      <title>Empowering Smaller Models: Tuning LLaMA and Gemma with Chain-of-Thought for Ukrainian Exam Tasks</title>
      <link>https://paperswithcode.com/paper/empowering-smaller-models-tuning-llama-and</link>
      <description><![CDATA[In addition, the proposed tuning method with joint task topic and step-by-step solution generation outperforms standard chain-of-thought tuning in matching tasks and provides a 5. 4% gain over the best LLaMA 3. 2 model due to guiding the model to recall and apply domain-relevant information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/empowering-smaller-models-tuning-llama-and</guid>
    </item>
    <item>
      <title>LEGNet: Lightweight Edge-Gaussian Driven Network for Low-Quality Remote Sensing Image Object Detection</title>
      <link>https://paperswithcode.com/paper/legnet-lightweight-edge-gaussian-driven</link>
      <description><![CDATA[Remote sensing object detection (RSOD) faces formidable challenges in complex visual environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/legnet-lightweight-edge-gaussian-driven</guid>
    </item>
    <item>
      <title>Where do Large Vision-Language Models Look at when Answering Questions?</title>
      <link>https://paperswithcode.com/paper/where-do-large-vision-language-models-look-at</link>
      <description><![CDATA[Large Vision-Language Models (LVLMs) have shown promising performance in vision-language understanding and reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/where-do-large-vision-language-models-look-at</guid>
    </item>
    <item>
      <title>A-SCoRe: Attention-based Scene Coordinate Regression for wide-ranging scenarios</title>
      <link>https://paperswithcode.com/paper/a-score-attention-based-scene-coordinate</link>
      <description><![CDATA[While state-of-the art methods that relies on feature matching have proven to be accurate for visual localization, its requirements for storage and compute are burdens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-score-attention-based-scene-coordinate</guid>
    </item>
    <item>
      <title>Intra and Inter Parser-Prompted Transformers for Effective Image Restoration</title>
      <link>https://paperswithcode.com/paper/intra-and-inter-parser-prompted-transformers</link>
      <description><![CDATA[To enhance the integration of the parser within IRNet, we propose Intra Parser-Prompted Attention (IntraPPA) and Inter Parser-Prompted Attention (InterPPA) to implicitly and explicitly learn useful parser features to facilitate restoration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intra-and-inter-parser-prompted-transformers</guid>
    </item>
    <item>
      <title>Is Discretization Fusion All You Need for Collaborative Perception?</title>
      <link>https://paperswithcode.com/paper/is-discretization-fusion-all-you-need-for</link>
      <description><![CDATA[ACCO is composed by three main components: (1) Anchor featuring block (AFB) that targets to generate anchor proposals and projects prepared anchor queries to image features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-discretization-fusion-all-you-need-for</guid>
    </item>
    <item>
      <title>Inferring Event Descriptions from Time Series with Language Models</title>
      <link>https://paperswithcode.com/paper/inferring-event-descriptions-from-time-series</link>
      <description><![CDATA[Events are often described with natural language, so we conduct the first study of whether Large Language Models (LLMs) can infer natural language events from time series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inferring-event-descriptions-from-time-series</guid>
    </item>
    <item>
      <title>CoSpace: Benchmarking Continuous Space Perception Ability for Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/cospace-benchmarking-continuous-space</link>
      <description><![CDATA[In this paper, we present CoSpace, a multi-image visual understanding benchmark designed to assess the Continuous Space perception ability for VLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cospace-benchmarking-continuous-space</guid>
    </item>
    <item>
      <title>Splintering Nonconcatenative Languages for Better Tokenization</title>
      <link>https://paperswithcode.com/paper/splintering-nonconcatenative-languages-for</link>
      <description><![CDATA[Common subword tokenization algorithms like BPE and UnigramLM assume that text can be split into meaningful units by concatenative measures alone.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/splintering-nonconcatenative-languages-for</guid>
    </item>
    <item>
      <title>DIFFVSGG: Diffusion-Driven Online Video Scene Graph Generation</title>
      <link>https://paperswithcode.com/paper/diffvsgg-diffusion-driven-online-video-scene</link>
      <description><![CDATA[This embedding then serves as the input to task-specific heads for object classification, scene graph generation, etc.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffvsgg-diffusion-driven-online-video-scene</guid>
    </item>
    <item>
      <title>Scale-Aware Contrastive Reverse Distillation for Unsupervised Medical Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/scale-aware-contrastive-reverse-distillation</link>
      <description><![CDATA[Following this paradigm, we propose a novel scale-aware contrastive reverse distillation model that addresses two key limitations of existing reverse distillation methods: insufficient feature discriminability and inability to handle anomaly scale variations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scale-aware-contrastive-reverse-distillation</guid>
    </item>
    <item>
      <title>MMR: A Large-scale Benchmark Dataset for Multi-target and Multi-granularity Reasoning Segmentation</title>
      <link>https://paperswithcode.com/paper/mmr-a-large-scale-benchmark-dataset-for-multi</link>
      <description><![CDATA[To address this gap, we construct a large-scale dataset called Multi-target and Multi-granularity Reasoning (MMR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmr-a-large-scale-benchmark-dataset-for-multi</guid>
    </item>
    <item>
      <title>Limb-Aware Virtual Try-On Network with Progressive Clothing Warping</title>
      <link>https://paperswithcode.com/paper/limb-aware-virtual-try-on-network-with</link>
      <description><![CDATA[Finally, we introduce Limb-aware Texture Fusion (LTF) that focuses on generating realistic details in limb regions, where a coarse try-on result is first generated by fusing the warped clothing image with the person image, then limb textures are further fused with the coarse result under limb-aware guidance to refine limb details.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/limb-aware-virtual-try-on-network-with</guid>
    </item>
    <item>
      <title>DualToken: Towards Unifying Visual Understanding and Generation with Dual Visual Vocabularies</title>
      <link>https://paperswithcode.com/paper/dualtoken-towards-unifying-visual</link>
      <description><![CDATA[The differing representation spaces required for visual understanding and generation pose a challenge in unifying them within the autoregressive paradigm of large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dualtoken-towards-unifying-visual</guid>
    </item>
    <item>
      <title>EnvBench: A Benchmark for Automated Environment Setup</title>
      <link>https://paperswithcode.com/paper/envbench-a-benchmark-for-automated</link>
      <description><![CDATA[Recent advances in Large Language Models (LLMs) have enabled researchers to focus on practical repository-level tasks in software engineering domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/envbench-a-benchmark-for-automated</guid>
    </item>
    <item>
      <title>HSOD-BIT-V2: A New Challenging Benchmarkfor Hyperspectral Salient Object Detection</title>
      <link>https://paperswithcode.com/paper/hsod-bit-v2-a-new-challenging-benchmarkfor</link>
      <description><![CDATA[Salient Object Detection (SOD) is crucial in computer vision, yet RGB-based methods face limitations in challenging scenes, such as small objects and similar color features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hsod-bit-v2-a-new-challenging-benchmarkfor</guid>
    </item>
    <item>
      <title>Counterfactual experience augmented off-policy reinforcement learning</title>
      <link>https://paperswithcode.com/paper/counterfactual-experience-augmented-off</link>
      <description><![CDATA[By providing reward signals for counterfactual state transitions based on real information, CEA constructs a complete counterfactual experience to alleviate the out-of-distribution problem of the learning data, and outperforms general SOTA algorithms in environments with difference properties.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-experience-augmented-off</guid>
    </item>
    <item>
      <title>JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System</title>
      <link>https://paperswithcode.com/paper/judge-benchmarking-judgment-document</link>
      <description><![CDATA[We define the task as generating a complete legal judgment document from the given factual description of the case.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/judge-benchmarking-judgment-document</guid>
    </item>
    <item>
      <title>LLM-FE: Automated Feature Engineering for Tabular Data with LLMs as Evolutionary Optimizers</title>
      <link>https://paperswithcode.com/paper/llm-fe-automated-feature-engineering-for</link>
      <description><![CDATA[Automated feature engineering plays a critical role in improving predictive model performance for tabular learning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-fe-automated-feature-engineering-for</guid>
    </item>
    <item>
      <title>RWKV-7 "Goose" with Expressive Dynamic State Evolution</title>
      <link>https://paperswithcode.com/paper/rwkv-7-goose-with-expressive-dynamic-state</link>
      <description><![CDATA[We present RWKV-7 "Goose", a new sequence modeling architecture, along with pre-trained language models that establish a new state-of-the-art in downstream performance at the 3 billion parameter scale on multilingual tasks, and match current SoTA English language performance despite being trained on dramatically fewer tokens than other top 3B models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rwkv-7-goose-with-expressive-dynamic-state</guid>
    </item>
    <item>
      <title>Temporal Consistency for LLM Reasoning Process Error Identification</title>
      <link>https://paperswithcode.com/paper/temporal-consistency-for-llm-reasoning</link>
      <description><![CDATA[Verification is crucial for effective mathematical reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-consistency-for-llm-reasoning</guid>
    </item>
    <item>
      <title>Persistent Homology-induced Graph Ensembles for Time Series Regressions</title>
      <link>https://paperswithcode.com/paper/persistent-homology-induced-graph-ensembles</link>
      <description><![CDATA[The effectiveness of Spatio-temporal Graph Neural Networks (STGNNs) in time-series applications is often limited by their dependence on fixed, hand-crafted input graph structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/persistent-homology-induced-graph-ensembles</guid>
    </item>
    <item>
      <title>MDocAgent: A Multi-Modal Multi-Agent Framework for Document Understanding</title>
      <link>https://paperswithcode.com/paper/mdocagent-a-multi-modal-multi-agent-framework</link>
      <description><![CDATA[These agents engage in multi-modal context retrieval, combining their individual insights to achieve a more comprehensive understanding of the document's content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mdocagent-a-multi-modal-multi-agent-framework</guid>
    </item>
    <item>
      <title>Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels</title>
      <link>https://paperswithcode.com/paper/tiled-flash-linear-attention-more-efficient</link>
      <description><![CDATA[Leveraging the chunkwise-parallel formulation of linear RNNs, Flash Linear Attention (FLA) shows that linear RNN kernels are faster than Flash Attention, by parallelizing over chunks of the input sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tiled-flash-linear-attention-more-efficient</guid>
    </item>
    <item>
      <title>Out-of-Distribution Generalization in Time Series: A Survey</title>
      <link>https://paperswithcode.com/paper/out-of-distribution-generalization-in-time</link>
      <description><![CDATA[Time series frequently manifest distribution shifts, diverse latent features, and non-stationary learning dynamics, particularly in open and evolving environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/out-of-distribution-generalization-in-time</guid>
    </item>
    <item>
      <title>Advances in 4D Generation: A Survey</title>
      <link>https://paperswithcode.com/paper/advances-in-4d-generation-a-survey</link>
      <description><![CDATA[Generative artificial intelligence has witnessed remarkable advancements across multiple domains in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advances-in-4d-generation-a-survey</guid>
    </item>
    <item>
      <title>Capturing Smile Dynamics with the Quintic Volatility Model: SPX, Skew-Stickiness Ratio and VIX</title>
      <link>https://paperswithcode.com/paper/capturing-smile-dynamics-with-the-quintic</link>
      <description><![CDATA[We introduce the two-factor Quintic Ornstein-Uhlenbeck model, where volatility is modeled as a polynomial of degree five based on the sum of two Ornstein-Uhlenbeck processes driven by the same Brownian Motion, each mean-reverting at a different speed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/capturing-smile-dynamics-with-the-quintic</guid>
    </item>
    <item>
      <title>Mapping Urban Villages in China: Progress and Challenges</title>
      <link>https://paperswithcode.com/paper/mapping-urban-villages-in-china-progress-and</link>
      <description><![CDATA[We also address the challenges and future directions for further research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mapping-urban-villages-in-china-progress-and</guid>
    </item>
    <item>
      <title>GeoFlow-SLAM: A Robust Tightly-Coupled RGBD-Inertial Fusion SLAM for Dynamic Legged Robotics</title>
      <link>https://paperswithcode.com/paper/geoflow-slam-a-robust-tightly-coupled-rgbd</link>
      <description><![CDATA[This paper presents GeoFlow-SLAM, a robust and effective Tightly-Coupled RGBD-inertial SLAM for legged robots operating in highly dynamic environments. By integrating geometric consistency, legged odometry constraints, and dual-stream optical flow (GeoFlow), our method addresses three critical challenges:feature matching and pose initialization failures during fast locomotion and visual feature scarcity in texture-less scenes. Specifically, in rapid motion scenarios, feature matching is notably enhanced by leveraging dual-stream optical flow, which combines prior map points and poses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geoflow-slam-a-robust-tightly-coupled-rgbd</guid>
    </item>
    <item>
      <title>Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control</title>
      <link>https://paperswithcode.com/paper/cosmos-transfer1-conditional-world-generation</link>
      <description><![CDATA[We introduce Cosmos-Transfer, a conditional world generation model that can generate world simulations based on multiple spatial control inputs of various modalities such as segmentation, depth, and edge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cosmos-transfer1-conditional-world-generation</guid>
    </item>
    <item>
      <title>Multi-Prototype Embedding Refinement for Semi-Supervised Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/multi-prototype-embedding-refinement-for-semi</link>
      <description><![CDATA[Medical image segmentation aims to identify anatomical structures at the voxel-level.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-prototype-embedding-refinement-for-semi</guid>
    </item>
    <item>
      <title>Carbonic anhydrase II simulated with a universal neural network potential</title>
      <link>https://paperswithcode.com/paper/carbonic-anhydrase-ii-simulated-with-a</link>
      <description><![CDATA[Additionally, we observe a new reaction pathway where CO$_2$ reacts with a water molecule in the active site, which donates a proton to the zinc-bound hydroxide.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/carbonic-anhydrase-ii-simulated-with-a</guid>
    </item>
  </channel>
</rss>
