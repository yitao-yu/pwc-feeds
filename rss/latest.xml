<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 07 Dec 2024 09:15:31 +0000</lastBuildDate>
    <item>
      <title>Stereo Anywhere: Robust Zero-Shot Deep Stereo Matching Even Where Either Stereo or Mono Fail</title>
      <link>https://paperswithcode.com/paper/stereo-anywhere-robust-zero-shot-deep-stereo</link>
      <description><![CDATA[We introduce Stereo Anywhere, a novel stereo-matching framework that combines geometric constraints with robust priors from monocular depth Vision Foundation Models (VFMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stereo-anywhere-robust-zero-shot-deep-stereo</guid>
    </item>
    <item>
      <title>BEFL: Balancing Energy Consumption in Federated Learning for Mobile Edge IoT</title>
      <link>https://paperswithcode.com/paper/befl-balancing-energy-consumption-in</link>
      <description><![CDATA[Existing research primarily focuses on reducing overall energy consumption, but this may inadvertently create energy consumption imbalances, leading to the premature dropout of energy-sensitive devices. To address these challenges, we propose BEFL, a joint optimization framework aimed at balancing three objectives: enhancing global model accuracy, minimizing total energy consumption, and reducing energy usage disparities among devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/befl-balancing-energy-consumption-in</guid>
    </item>
    <item>
      <title>FlashSloth: Lightning Multimodal Large Language Models via Embedded Visual Compression</title>
      <link>https://paperswithcode.com/paper/flashsloth-lightning-multimodal-large</link>
      <description><![CDATA[Despite a big leap forward in capability, multimodal large language models (MLLMs) tend to behave like a sloth in practical use, i. e., slow response and large latency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flashsloth-lightning-multimodal-large</guid>
    </item>
    <item>
      <title>Can Targeted Clean-Label Poisoning Attacks Generalize?</title>
      <link>https://paperswithcode.com/paper/can-targeted-clean-label-poisoning-attacks</link>
      <description><![CDATA[In a common clean-label setting, they are achieved by slightly perturbing a subset of training samples given access to those specific targets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-targeted-clean-label-poisoning-attacks</guid>
    </item>
    <item>
      <title>TransAdapter: Vision Transformer for Feature-Centric Unsupervised Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/transadapter-vision-transformer-for-feature</link>
      <description><![CDATA[Unsupervised Domain Adaptation (UDA) aims to utilize labeled data from a source domain to solve tasks in an unlabeled target domain, often hindered by significant domain gaps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transadapter-vision-transformer-for-feature</guid>
    </item>
    <item>
      <title>Unified Framework for Open-World Compositional Zero-shot Learning</title>
      <link>https://paperswithcode.com/paper/unified-framework-for-open-world</link>
      <description><![CDATA[Open-World Compositional Zero-Shot Learning (OW-CZSL) addresses the challenge of recognizing novel compositions of known primitives and entities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-framework-for-open-world</guid>
    </item>
    <item>
      <title>VisionZip: Longer is Better but Not Necessary in Vision Language Models</title>
      <link>https://paperswithcode.com/paper/visionzip-longer-is-better-but-not-necessary</link>
      <description><![CDATA[To address this, we introduce VisionZip, a simple yet effective method that selects a set of informative tokens for input to the language model, reducing visual token redundancy and improving efficiency while maintaining model performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visionzip-longer-is-better-but-not-necessary</guid>
    </item>
    <item>
      <title>p-MoD: Building Mixture-of-Depths MLLMs via Progressive Ratio Decay</title>
      <link>https://paperswithcode.com/paper/p-mod-building-mixture-of-depths-mllms-via</link>
      <description><![CDATA[In this paper, we propose to build efficient MLLMs by leveraging the Mixture-of-Depths (MoD) mechanism, where each transformer decoder layer selects essential vision tokens to process while skipping redundant ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/p-mod-building-mixture-of-depths-mllms-via</guid>
    </item>
    <item>
      <title>Mask of truth: model sensitivity to unexpected regions of medical images</title>
      <link>https://paperswithcode.com/paper/mask-of-truth-model-sensitivity-to-unexpected</link>
      <description><![CDATA[We show that all models trained on the PadChest dataset, irrespective of the masking strategy, are able to obtain an Area Under the Curve (AUC) above random.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mask-of-truth-model-sensitivity-to-unexpected</guid>
    </item>
    <item>
      <title>HumanEdit: A High-Quality Human-Rewarded Dataset for Instruction-based Image Editing</title>
      <link>https://paperswithcode.com/paper/humanedit-a-high-quality-human-rewarded</link>
      <description><![CDATA[HumanEdit bridges this gap by employing human annotators to construct data pairs and administrators to provide feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/humanedit-a-high-quality-human-rewarded</guid>
    </item>
    <item>
      <title>Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</link>
      <description><![CDATA[We present Infinity, a Bitwise Visual AutoRegressive Modeling capable of generating high-resolution, photorealistic images following language instruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</guid>
    </item>
    <item>
      <title>Training MLPs on Graphs without Supervision</title>
      <link>https://paperswithcode.com/paper/training-mlps-on-graphs-without-supervision</link>
      <description><![CDATA[We provide a comprehensive theoretical analysis, demonstrating the equivalence between SimMLP and GNNs based on mutual information and inductive bias, highlighting SimMLP's advanced structural learning capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-mlps-on-graphs-without-supervision</guid>
    </item>
    <item>
      <title>Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion</title>
      <link>https://paperswithcode.com/paper/florence-vl-enhancing-vision-language-models</link>
      <description><![CDATA[We present Florence-VL, a new family of multimodal large language models (MLLMs) with enriched visual representations produced by Florence-2, a generative vision foundation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/florence-vl-enhancing-vision-language-models</guid>
    </item>
    <item>
      <title>EmbodiedOcc: Embodied 3D Occupancy Prediction for Vision-based Online Scene Understanding</title>
      <link>https://paperswithcode.com/paper/embodiedocc-embodied-3d-occupancy-prediction</link>
      <description><![CDATA[3D occupancy prediction provides a comprehensive description of the surrounding scenes and has become an essential task for 3D perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embodiedocc-embodied-3d-occupancy-prediction</guid>
    </item>
    <item>
      <title>DiffSign: AI-Assisted Generation of Customizable Sign Language Videos With Enhanced Realism</title>
      <link>https://paperswithcode.com/paper/diffsign-ai-assisted-generation-of</link>
      <description><![CDATA[Our goal is to make media content more accessible to the DHH community by generating sign language videos with synthetic signers that are realistic and expressive.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffsign-ai-assisted-generation-of</guid>
    </item>
    <item>
      <title>Learning to Hash for Recommendation: A Survey</title>
      <link>https://paperswithcode.com/paper/learning-to-hash-for-recommendation-a-survey</link>
      <description><![CDATA[In this survey, we present a comprehensive review of current HashRec algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-hash-for-recommendation-a-survey</guid>
    </item>
    <item>
      <title>Graph-Sequential Alignment and Uniformity: Toward Enhanced Recommendation Systems</title>
      <link>https://paperswithcode.com/paper/graph-sequential-alignment-and-uniformity</link>
      <description><![CDATA[Graph-based and sequential methods are two popular recommendation paradigms, each excelling in its domain but lacking the ability to leverage signals from the other.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-sequential-alignment-and-uniformity</guid>
    </item>
    <item>
      <title>Quantifying the Limits of Segment Anything Model: Analyzing Challenges in Segmenting Tree-Like and Low-Contrast Structures</title>
      <link>https://paperswithcode.com/paper/quantifying-the-limits-of-segment-anything</link>
      <description><![CDATA[Segment Anything Model (SAM) has shown impressive performance in interactive and zero-shot segmentation across diverse domains, suggesting that they have learned a general concept of "objects" from their large-scale training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quantifying-the-limits-of-segment-anything</guid>
    </item>
    <item>
      <title>Monet: Mixture of Monosemantic Experts for Transformers</title>
      <link>https://paperswithcode.com/paper/monet-mixture-of-monosemantic-experts-for</link>
      <description><![CDATA[Understanding the internal computations of large language models (LLMs) is crucial for aligning them with human values and preventing undesirable behaviors like toxic content generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monet-mixture-of-monosemantic-experts-for</guid>
    </item>
    <item>
      <title>4D SlingBAG: spatial-temporal coupled Gaussian ball for large-scale dynamic 3D photoacoustic iterative reconstruction</title>
      <link>https://paperswithcode.com/paper/4d-slingbag-spatial-temporal-coupled-gaussian</link>
      <description><![CDATA[However, for existing IR algorithms, multi-frame 3D reconstruction leads to extremely high memory consumption and prolonged computation time, with limited consideration of the spatial-temporal continuity between data frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/4d-slingbag-spatial-temporal-coupled-gaussian</guid>
    </item>
    <item>
      <title>Integrating Various Software Artifacts for Better LLM-based Bug Localization and Program Repair</title>
      <link>https://paperswithcode.com/paper/integrating-various-software-artifacts-for</link>
      <description><![CDATA[The results show that while issue content is particularly effective in assisting LLMs with fault localization and program repair, different types of software artifacts complement each other.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/integrating-various-software-artifacts-for</guid>
    </item>
    <item>
      <title>Grounding Descriptions in Images informs Zero-Shot Visual Recognition</title>
      <link>https://paperswithcode.com/paper/grounding-descriptions-in-images-informs-zero</link>
      <description><![CDATA[In this paper, we propose GRAIN, a new pretraining strategy aimed at aligning representations at both fine and coarse levels simultaneously.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grounding-descriptions-in-images-informs-zero</guid>
    </item>
    <item>
      <title>JANUS: A Difference-Oriented Analyzer For Financial Centralization Risks in Smart Contracts</title>
      <link>https://paperswithcode.com/paper/janus-a-difference-oriented-analyzer-for</link>
      <description><![CDATA[Focusing on the impact of risks rather than behaviors, JANUS achieves improved accuracy compared to existing tools and can uncover centralization risks with unknown patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/janus-a-difference-oriented-analyzer-for</guid>
    </item>
    <item>
      <title>PDG2Seq: Periodic Dynamic Graph to Sequence Model for Traffic Flow Prediction</title>
      <link>https://paperswithcode.com/paper/pdg2seq-periodic-dynamic-graph-to-sequence</link>
      <description><![CDATA[To address these findings, this paper proposes a Periodic Dynamic Graph to Sequence Model (PDG2Seq) for traffic flow prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pdg2seq-periodic-dynamic-graph-to-sequence</guid>
    </item>
    <item>
      <title>PANGAEA: A Global and Inclusive Benchmark for Geospatial Foundation Models</title>
      <link>https://paperswithcode.com/paper/pangaea-a-global-and-inclusive-benchmark-for</link>
      <description><![CDATA[To overcome these challenges, we introduce PANGAEA, a standardized evaluation protocol that covers a diverse set of datasets, tasks, resolutions, sensor modalities, and temporalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pangaea-a-global-and-inclusive-benchmark-for</guid>
    </item>
    <item>
      <title>GRAM: Generalization in Deep RL with a Robust Adaptation Module</title>
      <link>https://paperswithcode.com/paper/gram-generalization-in-deep-rl-with-a-robust</link>
      <description><![CDATA[The reliable deployment of deep reinforcement learning in real-world settings requires the ability to generalize across a variety of conditions, including both in-distribution scenarios seen during training as well as novel out-of-distribution scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gram-generalization-in-deep-rl-with-a-robust</guid>
    </item>
    <item>
      <title>SynFinTabs: A Dataset of Synthetic Financial Tables for Information and Table Extraction</title>
      <link>https://paperswithcode.com/paper/synfintabs-a-dataset-of-synthetic-financial</link>
      <description><![CDATA[To demonstrate the effectiveness of our dataset in training models to extract information from table images, we create FinTabQA, a layout large language model trained on an extractive question-answering task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synfintabs-a-dataset-of-synthetic-financial</guid>
    </item>
    <item>
      <title>Divot: Diffusion Powers Video Tokenizer for Comprehension and Generation</title>
      <link>https://paperswithcode.com/paper/divot-diffusion-powers-video-tokenizer-for</link>
      <description><![CDATA[We posit that if a video diffusion model can effectively de-noise video clips by taking the features of a video tokenizer as the condition, then the tokenizer has successfully captured robust spatial and temporal information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/divot-diffusion-powers-video-tokenizer-for</guid>
    </item>
    <item>
      <title>LossVal: Efficient Data Valuation for Neural Networks</title>
      <link>https://paperswithcode.com/paper/lossval-efficient-data-valuation-for-neural</link>
      <description><![CDATA[Assessing the importance of individual training samples is a key challenge in machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lossval-efficient-data-valuation-for-neural</guid>
    </item>
    <item>
      <title>MISR: Measuring Instrumental Self-Reasoning in Frontier Models</title>
      <link>https://paperswithcode.com/paper/misr-measuring-instrumental-self-reasoning-in</link>
      <description><![CDATA[We propose a suite of tasks to evaluate the instrumental self-reasoning ability of large language model (LLM) agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/misr-measuring-instrumental-self-reasoning-in</guid>
    </item>
    <item>
      <title>Dual-Branch Subpixel-Guided Network for Hyperspectral Image Classification</title>
      <link>https://paperswithcode.com/paper/dual-branch-subpixel-guided-network-for</link>
      <description><![CDATA[Deep learning (DL) has been widely applied into hyperspectral image (HSI) classification owing to its promising feature learning and representation capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-branch-subpixel-guided-network-for</guid>
    </item>
    <item>
      <title>YOLO-CCA: A Context-Based Approach for Traffic Sign Detection</title>
      <link>https://paperswithcode.com/paper/yolo-cca-a-context-based-approach-for-traffic</link>
      <description><![CDATA[Due to the complexity of driving environments, traffic sign detection frequently encounters a range of challenges, including low resolution, limited feature information, and small object sizes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-cca-a-context-based-approach-for-traffic</guid>
    </item>
    <item>
      <title>Bench-CoE: a Framework for Collaboration of Experts from Benchmark</title>
      <link>https://paperswithcode.com/paper/bench-coe-a-framework-for-collaboration-of</link>
      <description><![CDATA[Large Language Models (LLMs) are key technologies driving intelligent systems to handle multiple tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bench-coe-a-framework-for-collaboration-of</guid>
    </item>
    <item>
      <title>Probabilistic Gaussian Superposition for Efficient 3D Occupancy Prediction</title>
      <link>https://paperswithcode.com/paper/probabilistic-gaussian-superposition-for</link>
      <description><![CDATA[To address this, we propose a probabilistic Gaussian superposition model which interprets each Gaussian as a probability distribution of its neighborhood being occupied and conforms to probabilistic multiplication to derive the overall geometry.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probabilistic-gaussian-superposition-for</guid>
    </item>
    <item>
      <title>Exact: Exploring Space-Time Perceptive Clues for Weakly Supervised Satellite Image Time Series Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/exact-exploring-space-time-perceptive-clues</link>
      <description><![CDATA[Remarkably, the segmentation network trained on Exact-generated masks achieves 95% of its fully supervised performance, showing the bright promise of weakly supervised paradigm in crop mapping scenario.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exact-exploring-space-time-perceptive-clues</guid>
    </item>
    <item>
      <title>DEIM: DETR with Improved Matching for Fast Convergence</title>
      <link>https://paperswithcode.com/paper/deim-detr-with-improved-matching-for-fast</link>
      <description><![CDATA[We introduce DEIM, an innovative and efficient training framework designed to accelerate convergence in real-time object detection with Transformer-based architectures (DETR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deim-detr-with-improved-matching-for-fast</guid>
    </item>
    <item>
      <title>ZipAR: Accelerating Autoregressive Image Generation through Spatial Locality</title>
      <link>https://paperswithcode.com/paper/zipar-accelerating-autoregressive-image</link>
      <description><![CDATA[In this paper, we propose ZipAR, a training-free, plug-and-play parallel decoding framework for accelerating auto-regressive (AR) visual generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zipar-accelerating-autoregressive-image</guid>
    </item>
    <item>
      <title>Learnable Similarity and Dissimilarity Guided Symmetric Non-Negative Matrix Factorization</title>
      <link>https://paperswithcode.com/paper/learnable-similarity-and-dissimilarity-guided</link>
      <description><![CDATA[In this paper, we construct the similarity matrix as a weighted $k$-NN graph with learnable weight that reflects the reliability of each $k$-th NN.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learnable-similarity-and-dissimilarity-guided</guid>
    </item>
    <item>
      <title>Does your model understand genes? A benchmark of gene properties for biological and text models</title>
      <link>https://paperswithcode.com/paper/does-your-model-understand-genes-a-benchmark</link>
      <description><![CDATA[Our findings suggest that text-based models and protein language models generally outperform expression-based models in genomic properties and regulatory functions tasks, whereas expression-based models demonstrate superior performance in localization tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/does-your-model-understand-genes-a-benchmark</guid>
    </item>
    <item>
      <title>Parametric Enhancement of PerceptNet: A Human-Inspired Approach for Image Quality Assessment</title>
      <link>https://paperswithcode.com/paper/parametric-enhancement-of-perceptnet-a-human</link>
      <description><![CDATA[We present two parametric model versions: one with hand-chosen biologically plausible parameters, and another fitted to human perception experimental data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parametric-enhancement-of-perceptnet-a-human</guid>
    </item>
    <item>
      <title>Learning-based Sketches for Frequency Estimation in Data Streams without Ground Truth</title>
      <link>https://paperswithcode.com/paper/learning-based-sketches-for-frequency</link>
      <description><![CDATA[Estimating the frequency of items on the high-volume, fast data stream has been extensively studied in many areas, such as database and network measurement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-based-sketches-for-frequency</guid>
    </item>
    <item>
      <title>Improving Linguistic Diversity of Large Language Models with Possibility Exploration Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/improving-linguistic-diversity-of-large</link>
      <description><![CDATA[Although several fine-tuning and prompting techniques have been suggested to tackle the issue, they are often tailored to specific tasks or come with a substantial increase in computational cost and latency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-linguistic-diversity-of-large</guid>
    </item>
    <item>
      <title>Learning Semantic Association Rules from Internet of Things Data</title>
      <link>https://paperswithcode.com/paper/learning-semantic-association-rules-from</link>
      <description><![CDATA[In this paper, we propose a novel ARM pipeline for IoT data that utilizes both dynamic sensor data and static IoT system metadata.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-semantic-association-rules-from</guid>
    </item>
    <item>
      <title>Robust Multi-bit Text Watermark with LLM-based Paraphrasers</title>
      <link>https://paperswithcode.com/paper/robust-multi-bit-text-watermark-with-llm</link>
      <description><![CDATA[To embed our multi-bit watermark, we use two paraphrasers alternatively to encode the pre-defined binary code at the sentence level.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-multi-bit-text-watermark-with-llm</guid>
    </item>
    <item>
      <title>A surprisal oracle for when every layer counts</title>
      <link>https://paperswithcode.com/paper/a-surprisal-oracle-for-when-every-layer</link>
      <description><![CDATA[Active Curriculum Language Modeling (ACLM; Hong et al., 2023) is a learner directed approach to training a language model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-surprisal-oracle-for-when-every-layer</guid>
    </item>
    <item>
      <title>PrefixKV: Adaptive Prefix KV Cache is What Vision Instruction-Following Models Need for Efficient Generation</title>
      <link>https://paperswithcode.com/paper/prefixkv-adaptive-prefix-kv-cache-is-what</link>
      <description><![CDATA[With an adaptive layer-wise KV retention recipe based on binary search, the maximum contextual information can thus be preserved in each layer, facilitating the generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prefixkv-adaptive-prefix-kv-cache-is-what</guid>
    </item>
    <item>
      <title>Timestamp calibration for time-series single cell RNA-seq expression data</title>
      <link>https://paperswithcode.com/paper/timestamp-calibration-for-time-series-single</link>
      <description><![CDATA[To tackle this challenge, we have developed a novel timestamp calibration model called ScPace for handling noisy labeled time-series ScRNA-seq data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/timestamp-calibration-for-time-series-single</guid>
    </item>
    <item>
      <title>A Stitch in Time Saves Nine: Small VLM is a Precise Guidance for Accelerating Large VLMs</title>
      <link>https://paperswithcode.com/paper/a-stitch-in-time-saves-nine-small-vlm-is-a</link>
      <description><![CDATA[Vision-language models (VLMs) have shown remarkable success across various multi-modal tasks, yet large VLMs encounter significant efficiency challenges due to processing numerous visual tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-stitch-in-time-saves-nine-small-vlm-is-a</guid>
    </item>
    <item>
      <title>CleanDIFT: Diffusion Features without Noise</title>
      <link>https://paperswithcode.com/paper/cleandift-diffusion-features-without-noise</link>
      <description><![CDATA[Internal features from large-scale pre-trained diffusion models have recently been established as powerful semantic descriptors for a wide range of downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cleandift-diffusion-features-without-noise</guid>
    </item>
    <item>
      <title>Nonparametric Filtering, Estimation and Classification using Neural Jump ODEs</title>
      <link>https://paperswithcode.com/paper/nonparametric-filtering-estimation-and</link>
      <description><![CDATA[Neural Jump ODEs model the conditional expectation between observations by neural ODEs and jump at arrival of new observations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nonparametric-filtering-estimation-and</guid>
    </item>
  </channel>
</rss>
