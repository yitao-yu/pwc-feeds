<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 30 Dec 2024 09:16:30 +0000</lastBuildDate>
    <item>
      <title>EEG-Reptile: An Automatized Reptile-Based Meta-Learning Library for BCIs</title>
      <link>https://paperswithcode.com/paper/eeg-reptile-an-automatized-reptile-based-meta</link>
      <description><![CDATA[It utilizes the Reptile meta-learning algorithm to adapt neural network classifiers of EEG data to the inter-subject domain, allowing for more efficient fine-tuning for a new subject on a small amount of data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eeg-reptile-an-automatized-reptile-based-meta</guid>
    </item>
    <item>
      <title>TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data</title>
      <link>https://paperswithcode.com/paper/targa-targeted-synthetic-data-generation-for</link>
      <description><![CDATA[Then we generate corresponding natural language questions for these constructed queries to jointly serve as the synthetic demonstrations for in-context learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/targa-targeted-synthetic-data-generation-for</guid>
    </item>
    <item>
      <title>Interacted Object Grounding in Spatio-Temporal Human-Object Interactions</title>
      <link>https://paperswithcode.com/paper/interacted-object-grounding-in-spatio</link>
      <description><![CDATA[Accordingly, an object grounding task is proposed expecting vision systems to discover interacted objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interacted-object-grounding-in-spatio</guid>
    </item>
    <item>
      <title>MBQ: Modality-Balanced Quantization for Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/mbq-modality-balanced-quantization-for-large</link>
      <description><![CDATA[Therefore, treating tokens from different modalities equally, as in existing PTQ methods, may over-emphasize the insensitive modalities, leading to significant accuracy loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mbq-modality-balanced-quantization-for-large</guid>
    </item>
    <item>
      <title>Gx2Mol: De Novo Generation of Hit-like Molecules from Gene Expression Profiles via Deep Learning</title>
      <link>https://paperswithcode.com/paper/gx2mol-de-novo-generation-of-hit-like</link>
      <description><![CDATA[De novo generation of hit-like molecules is a challenging task in the drug discovery process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gx2mol-de-novo-generation-of-hit-like</guid>
    </item>
    <item>
      <title>Fortran2CPP: Automating Fortran-to-C++ Migration using LLMs via Multi-Turn Dialogue and Dual-Agent Integration</title>
      <link>https://paperswithcode.com/paper/fortran2cpp-automating-fortran-to-c-migration</link>
      <description><![CDATA[Migrating Fortran code to C++ is a common task for many scientific computing teams, driven by the need to leverage modern programming paradigms, enhance cross-platform compatibility, and improve maintainability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fortran2cpp-automating-fortran-to-c-migration</guid>
    </item>
    <item>
      <title>RecConv: Efficient Recursive Convolutions for Multi-Frequency Representations</title>
      <link>https://paperswithcode.com/paper/recconv-efficient-recursive-convolutions-for</link>
      <description><![CDATA[RecConv establishes a linear relationship between parameter growth and decomposing levels which determines the effective kernel size $k\times 2^\ell$ for a base kernel $k$ and $\ell$ levels of decomposition, while maintaining constant FLOPs regardless of the ERF expansion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recconv-efficient-recursive-convolutions-for</guid>
    </item>
    <item>
      <title>Toward Adaptive Reasoning in Large Language Models with Thought Rollback</title>
      <link>https://paperswithcode.com/paper/toward-adaptive-reasoning-in-large-language-1</link>
      <description><![CDATA[For instance, the solving rate of GPT-4 with TR outperforms the current best by $9\%$ on the MATH dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toward-adaptive-reasoning-in-large-language-1</guid>
    </item>
    <item>
      <title>An In-Depth Analysis of Adversarial Discriminative Domain Adaptation for Digit Classification</title>
      <link>https://paperswithcode.com/paper/an-in-depth-analysis-of-adversarial</link>
      <description><![CDATA[Domain adaptation is an active area of research driven by the growing demand for robust machine learning models that perform well on real-world data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-in-depth-analysis-of-adversarial</guid>
    </item>
    <item>
      <title>MINIMA: Modality Invariant Image Matching</title>
      <link>https://paperswithcode.com/paper/minima-modality-invariant-image-matching</link>
      <description><![CDATA[Under this setting, the matching labels and rich diversity of the RGB dataset are well inherited by the generated multimodal data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minima-modality-invariant-image-matching</guid>
    </item>
    <item>
      <title>Generalized Uncertainty-Based Evidential Fusion with Hybrid Multi-Head Attention for Weak-Supervised Temporal Action Localization</title>
      <link>https://paperswithcode.com/paper/generalized-uncertainty-based-evidential</link>
      <description><![CDATA[Additionally, the proposed GUEF adaptively eliminates the interference of background noise by fusing snippet-level evidences to refine uncertainty measurement and select superior foreground feature information, which enables the model to concentrate on integral action instances to achieve better action localization and classification performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-uncertainty-based-evidential</guid>
    </item>
    <item>
      <title>Optimizing Local-Global Dependencies for Accurate 3D Human Pose Estimation</title>
      <link>https://paperswithcode.com/paper/optimizing-local-global-dependencies-for</link>
      <description><![CDATA[To address this, we propose SSR-STF, a dual-stream model that effectively integrates local features with global dependencies to enhance 3D human pose estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimizing-local-global-dependencies-for</guid>
    </item>
    <item>
      <title>UniBrain: A Unified Model for Cross-Subject Brain Decoding</title>
      <link>https://paperswithcode.com/paper/unibrain-a-unified-model-for-cross-subject</link>
      <description><![CDATA[We validate our UniBrain on the brain decoding benchmark, achieving comparable performance to current state-of-the-art subject-specific models with extremely fewer parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unibrain-a-unified-model-for-cross-subject</guid>
    </item>
    <item>
      <title>DeepSeek-V3 Technical Report</title>
      <link>https://paperswithcode.com/paper/deepseek-v3-technical-report</link>
      <description><![CDATA[We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-v3-technical-report</guid>
    </item>
    <item>
      <title>DrivingWorld: ConstructingWorld Model for Autonomous Driving via Video GPT</title>
      <link>https://paperswithcode.com/paper/drivingworld-constructingworld-model-for</link>
      <description><![CDATA[However, prior works tend to produce unsatisfactory results, as the classic GPT framework is designed to handle 1D contextual information, such as text, and lacks the inherent ability to model the spatial and temporal dynamics essential for video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drivingworld-constructingworld-model-for</guid>
    </item>
    <item>
      <title>Generating Editable Head Avatars with 3D Gaussian GANs</title>
      <link>https://paperswithcode.com/paper/generating-editable-head-avatars-with-3d</link>
      <description><![CDATA[We propose a novel approach that enhances the editability and animation control of 3D head avatars by incorporating 3D Gaussian Splatting (3DGS) as an explicit 3D representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-editable-head-avatars-with-3d</guid>
    </item>
    <item>
      <title>DAPoinTr: Domain Adaptive Point Transformer for Point Cloud Completion</title>
      <link>https://paperswithcode.com/paper/dapointr-domain-adaptive-point-transformer</link>
      <description><![CDATA[To this end, we propose a pioneering Domain Adaptive Point Transformer (DAPoinTr) framework for point cloud completion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dapointr-domain-adaptive-point-transformer</guid>
    </item>
    <item>
      <title>When SAM2 Meets Video Shadow and Mirror Detection</title>
      <link>https://paperswithcode.com/paper/when-sam2-meets-video-shadow-and-mirror</link>
      <description><![CDATA[As the successor to the Segment Anything Model (SAM), the Segment Anything Model 2 (SAM2) not only improves performance in image segmentation but also extends its capabilities to video segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-sam2-meets-video-shadow-and-mirror</guid>
    </item>
    <item>
      <title>Exploring GLU Expansion Ratios: A Study of Structured Pruning in LLaMA-3.2 Models</title>
      <link>https://paperswithcode.com/paper/exploring-glu-expansion-ratios-a-study-of</link>
      <description><![CDATA[Large language models with GLU architectures are typically designed with significant expansion ratios in their MLP layers, where output dimensions are several times larger than input dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-glu-expansion-ratios-a-study-of</guid>
    </item>
    <item>
      <title>MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes</title>
      <link>https://paperswithcode.com/paper/medec-a-benchmark-for-medical-error-detection</link>
      <description><![CDATA[We also found that although recent LLMs have a good performance in error detection and correction, they are still outperformed by medical doctors in these tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medec-a-benchmark-for-medical-error-detection</guid>
    </item>
    <item>
      <title>PlanLLM: Video Procedure Planning with Refinable Large Language Models</title>
      <link>https://paperswithcode.com/paper/planllm-video-procedure-planning-with</link>
      <description><![CDATA[We also propose Mutual Information Maximization module to connect world-level commonsense of step descriptions and sample-specific information of visual states, enabling LLMs to employ the reasoning ability to generate step sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/planllm-video-procedure-planning-with</guid>
    </item>
    <item>
      <title>Tint Your Models Task-wise for Improved Multi-task Model Merging</title>
      <link>https://paperswithcode.com/paper/tint-your-models-task-wise-for-improved-multi</link>
      <description><![CDATA[Motivated by this finding, we propose Model Tinting, a new test-time approach that introduces a single task-specific layer for each task as trainable adjustments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tint-your-models-task-wise-for-improved-multi</guid>
    </item>
    <item>
      <title>Modality-Projection Universal Model for Comprehensive Full-Body Medical Imaging Segmentation</title>
      <link>https://paperswithcode.com/paper/modality-projection-universal-model-for</link>
      <description><![CDATA[The integration of deep learning in medical imaging has shown great promise for enhancing diagnostic, therapeutic, and research outcomes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/modality-projection-universal-model-for</guid>
    </item>
    <item>
      <title>Personalized Dynamic Music Emotion Recognition with Dual-Scale Attention-Based Meta-Learning</title>
      <link>https://paperswithcode.com/paper/personalized-dynamic-music-emotion</link>
      <description><![CDATA[Motivated by these issues, we explore more effective sequence processing methods and introduce the Personalized DMER (PDMER) problem, which requires models to predict emotions that align with personalized perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalized-dynamic-music-emotion</guid>
    </item>
    <item>
      <title>Learning Cross-Domain Representations for Transferable Drug Perturbations on Single-Cell Transcriptional Responses</title>
      <link>https://paperswithcode.com/paper/learning-cross-domain-representations-for</link>
      <description><![CDATA[Given a pair of perturbed expression profiles, our approach decouples the perturbation representations from basal states through domain separation encoders and then cross-transfers them in the latent space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-cross-domain-representations-for</guid>
    </item>
    <item>
      <title>SUTrack: Towards Simple and Unified Single Object Tracking</title>
      <link>https://paperswithcode.com/paper/sutrack-towards-simple-and-unified-single</link>
      <description><![CDATA[It consolidates five SOT tasks (RGB-based, RGB-Depth, RGB-Thermal, RGB-Event, RGB-Language Tracking) into a unified model trained in a single session.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sutrack-towards-simple-and-unified-single</guid>
    </item>
    <item>
      <title>Context-Aware Deep Learning for Multi Modal Depression Detection</title>
      <link>https://paperswithcode.com/paper/context-aware-deep-learning-for-multi-modal</link>
      <description><![CDATA[In this study, we focus on automated approaches to detect depression from clinical interviews using multi-modal machine learning (ML).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-aware-deep-learning-for-multi-modal</guid>
    </item>
    <item>
      <title>ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning</title>
      <link>https://paperswithcode.com/paper/vipcap-retrieval-text-based-visual-prompts</link>
      <description><![CDATA[Experimental results demonstrate that ViPCap significantly outperforms prior lightweight captioning models in efficiency and effectiveness, demonstrating the potential for a plug-and-play solution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vipcap-retrieval-text-based-visual-prompts</guid>
    </item>
    <item>
      <title>Advanced Knowledge Transfer: Refined Feature Distillation for Zero-Shot Quantization in Edge Computing</title>
      <link>https://paperswithcode.com/paper/advanced-knowledge-transfer-refined-feature</link>
      <description><![CDATA[Particularly, we analyzed that refining feature maps in the feature distillation process is an effective way to transfer knowledge to the Q model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advanced-knowledge-transfer-refined-feature</guid>
    </item>
    <item>
      <title>Spectral Enhancement and Pseudo-Anchor Guidance for Infrared-Visible Person Re-Identification</title>
      <link>https://paperswithcode.com/paper/spectral-enhancement-and-pseudo-anchor</link>
      <description><![CDATA[The development of deep learning has facilitated the application of person re-identification (ReID) technology in intelligent security.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spectral-enhancement-and-pseudo-anchor</guid>
    </item>
    <item>
      <title>Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment</title>
      <link>https://paperswithcode.com/paper/task-preference-optimization-improving</link>
      <description><![CDATA[Current multimodal large language models (MLLMs) struggle with fine-grained or precise understanding of visuals though they give comprehensive perception and reasoning in a spectrum of vision applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/task-preference-optimization-improving</guid>
    </item>
    <item>
      <title>Time Series Foundational Models: Their Role in Anomaly Detection and Prediction</title>
      <link>https://paperswithcode.com/paper/time-series-foundational-models-their-role-in</link>
      <description><![CDATA[Time series foundational models (TSFM) have gained prominence in time series forecasting, promising state-of-the-art performance across various applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/time-series-foundational-models-their-role-in</guid>
    </item>
    <item>
      <title>Transformer-Based Wireless Capsule Endoscopy Bleeding Tissue Detection and Classification</title>
      <link>https://paperswithcode.com/paper/transformer-based-wireless-capsule-endoscopy</link>
      <description><![CDATA[Trained in an end-to-end approach on the Auto-WCEBleedGen Version 1 challenge training set, our model performs both detection and classification tasks as a single unit.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-based-wireless-capsule-endoscopy</guid>
    </item>
    <item>
      <title>Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal Video-Text Retrieval</title>
      <link>https://paperswithcode.com/paper/reversed-in-time-a-novel-temporal-emphasized</link>
      <description><![CDATA[We further enhance the use of harder-negatives in model training, and benchmark a variety of video-text models on RTime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reversed-in-time-a-novel-temporal-emphasized</guid>
    </item>
    <item>
      <title>AskChart: Universal Chart Understanding through Textual Enhancement</title>
      <link>https://paperswithcode.com/paper/askchart-universal-chart-understanding</link>
      <description><![CDATA[To effectively train AskChart, we design a three-stage training strategy to align visual and textual modalities for learning robust visual-textual representations and optimizing the learning of the MoE layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/askchart-universal-chart-understanding</guid>
    </item>
    <item>
      <title>On the Expressiveness and Length Generalization of Selective State-Space Models on Regular Languages</title>
      <link>https://paperswithcode.com/paper/on-the-expressiveness-and-length</link>
      <description><![CDATA[In this work, we provide insight into the workings of selective SSMs by analyzing their expressiveness and length generalization performance on regular language tasks, i. e., finite-state automaton (FSA) emulation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-expressiveness-and-length</guid>
    </item>
    <item>
      <title>TPCH: Tensor-interacted Projection and Cooperative Hashing for Multi-view Clustering</title>
      <link>https://paperswithcode.com/paper/tpch-tensor-interacted-projection-and</link>
      <description><![CDATA[In recent years, anchor and hash-based multi-view clustering methods have gained attention for their efficiency and simplicity in handling large-scale data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tpch-tensor-interacted-projection-and</guid>
    </item>
    <item>
      <title>On the Robustness of Generative Information Retrieval Models</title>
      <link>https://paperswithcode.com/paper/on-the-robustness-of-generative-information</link>
      <description><![CDATA[Based on this taxonomy, we conduct empirical studies to analyze the OOD robustness of representative generative IR models against dense retrieval models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-robustness-of-generative-information</guid>
    </item>
    <item>
      <title>Embodied Image Quality Assessment for Robotic Intelligence</title>
      <link>https://paperswithcode.com/paper/embodied-image-quality-assessment-for-robotic</link>
      <description><![CDATA[Image quality assessment (IQA) of user-generated content (UGC) is a critical technique for human quality of experience (QoE).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embodied-image-quality-assessment-for-robotic</guid>
    </item>
    <item>
      <title>HELPNet: Hierarchical Perturbations Consistency and Entropy-guided Ensemble for Scribble Supervised Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/helpnet-hierarchical-perturbations</link>
      <description><![CDATA[Experimental results on three public datasets ACDC, MSCMRseg, and CHAOS show that HELPNet significantly outperforms state-of-the-art methods for scribble-based weakly supervised segmentation and achieves performance comparable to fully supervised methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/helpnet-hierarchical-perturbations</guid>
    </item>
    <item>
      <title>Open-Vocabulary Panoptic Segmentation Using BERT Pre-Training of Vision-Language Multiway Transformer Model</title>
      <link>https://paperswithcode.com/paper/open-vocabulary-panoptic-segmentation-using</link>
      <description><![CDATA[Open-vocabulary panoptic segmentation remains a challenging problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-vocabulary-panoptic-segmentation-using</guid>
    </item>
    <item>
      <title>Constraint-Adaptive Policy Switching for Offline Safe Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/constraint-adaptive-policy-switching-for</link>
      <description><![CDATA[Offline safe reinforcement learning (OSRL) involves learning a decision-making policy to maximize rewards from a fixed batch of training data to satisfy pre-defined safety constraints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/constraint-adaptive-policy-switching-for</guid>
    </item>
    <item>
      <title>Distortion-Aware Adversarial Attacks on Bounding Boxes of Object Detectors</title>
      <link>https://paperswithcode.com/paper/distortion-aware-adversarial-attacks-on</link>
      <description><![CDATA[We also evaluate our technique on MS COCO 2017 and PASCAL VOC 2012 datasets and analyze the trade-off between success attack rate and image distortion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distortion-aware-adversarial-attacks-on</guid>
    </item>
    <item>
      <title>Accelerating Diffusion Transformers with Dual Feature Caching</title>
      <link>https://paperswithcode.com/paper/accelerating-diffusion-transformers-with-dual</link>
      <description><![CDATA[However, on the one hand, aggressively reusing all the features cached in previous timesteps leads to a severe drop in generation quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-diffusion-transformers-with-dual</guid>
    </item>
    <item>
      <title>Simultaneously Recovering Multi-Person Meshes and Multi-View Cameras with Human Semantics</title>
      <link>https://paperswithcode.com/paper/simultaneously-recovering-multi-person-meshes</link>
      <description><![CDATA[Finally, a latent motion prior is proposed to refine the camera parameters and human motions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simultaneously-recovering-multi-person-meshes</guid>
    </item>
    <item>
      <title>HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs</title>
      <link>https://paperswithcode.com/paper/huatuogpt-o1-towards-medical-complex</link>
      <description><![CDATA[To address this, we propose verifiable medical problems with a medical verifier to check the correctness of model outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huatuogpt-o1-towards-medical-complex</guid>
    </item>
    <item>
      <title>CoEvo: Continual Evolution of Symbolic Solutions Using Large Language Models</title>
      <link>https://paperswithcode.com/paper/coevo-continual-evolution-of-symbolic</link>
      <description><![CDATA[We propose a novel framework that utilizes LLMs in an evolutionary search methodology, augmented by a dynamic knowledge library that integrates and refines insights in an \textit{open-ended manner}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coevo-continual-evolution-of-symbolic</guid>
    </item>
    <item>
      <title>Accelerating AIGC Services with Latent Action Diffusion Scheduling in Edge Networks</title>
      <link>https://paperswithcode.com/paper/accelerating-aigc-services-with-latent-action</link>
      <description><![CDATA[The LAD-TS generates a near-optimal offloading decision by leveraging the diffusion model's conditional generation capability and the reinforcement learning's environment interaction ability, thereby minimizing the service delays under multiple resource constraints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-aigc-services-with-latent-action</guid>
    </item>
    <item>
      <title>Beyond the Known: Enhancing Open Set Domain Adaptation with Unknown Exploration</title>
      <link>https://paperswithcode.com/paper/beyond-the-known-enhancing-open-set-domain</link>
      <description><![CDATA[In this work, we introduce a new approach to improve OSDA techniques by extracting a set of high-confidence unknown instances and using it as a hard constraint to tighten the classification boundaries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-the-known-enhancing-open-set-domain</guid>
    </item>
    <item>
      <title>Graph Structure Learning for Spatial-Temporal Imputation: Adapting to Node and Feature Scales</title>
      <link>https://paperswithcode.com/paper/graph-structure-learning-for-spatial-temporal</link>
      <description><![CDATA[Spatial-temporal data collected across different geographic locations often suffer from missing values, posing challenges to data analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-structure-learning-for-spatial-temporal</guid>
    </item>
  </channel>
</rss>
