<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 21 May 2025 09:19:19 +0000</lastBuildDate>
    <item>
      <title>Enhancing Abstractive Summarization of Scientific Papers Using Structure Information</title>
      <link>https://paperswithcode.com/paper/enhancing-abstractive-summarization-of</link>
      <description><![CDATA[Abstractive summarization of scientific papers has always been a research focus, yet existing methods face two main challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-abstractive-summarization-of</guid>
    </item>
    <item>
      <title>Safety Subspaces are Not Distinct: A Fine-Tuning Case Study</title>
      <link>https://paperswithcode.com/paper/safety-subspaces-are-not-distinct-a-fine</link>
      <description><![CDATA[A growing body of work suggests that alignment may correspond to identifiable geometric directions in weight space, forming subspaces that could, in principle, be isolated or preserved to defend against misalignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safety-subspaces-are-not-distinct-a-fine</guid>
    </item>
    <item>
      <title>MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem</title>
      <link>https://paperswithcode.com/paper/mm-agent-llm-as-agents-for-real-world</link>
      <description><![CDATA[We introduce MM-Bench, a curated benchmark of 111 problems from the Mathematical Contest in Modeling (MCM/ICM), spanning the years 2000 to 2025 and across ten diverse domains such as physics, biology, and economics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mm-agent-llm-as-agents-for-real-world</guid>
    </item>
    <item>
      <title>Reasoning Models Better Express Their Confidence</title>
      <link>https://paperswithcode.com/paper/reasoning-models-better-express-their</link>
      <description><![CDATA[Despite their strengths, large language models (LLMs) often fail to communicate their confidence accurately, making it difficult to assess when they might be wrong and limiting their reliability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reasoning-models-better-express-their</guid>
    </item>
    <item>
      <title>Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models</title>
      <link>https://paperswithcode.com/paper/toward-reliable-biomedical-hypothesis</link>
      <description><![CDATA[Large language models (LLMs) have shown significant potential in scientific disciplines such as biomedicine, particularly in hypothesis generation, where they can analyze vast literature, identify patterns, and suggest research directions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toward-reliable-biomedical-hypothesis</guid>
    </item>
    <item>
      <title>KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models</title>
      <link>https://paperswithcode.com/paper/kerl-knowledge-enhanced-personalized-recipe</link>
      <description><![CDATA[We introduce KERL, a unified system that leverages food KGs and LLMs to provide personalized food recommendations and generates recipes with associated micro-nutritional information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kerl-knowledge-enhanced-personalized-recipe</guid>
    </item>
    <item>
      <title>s3: You Don't Need That Much Data to Train a Search Agent via RL</title>
      <link>https://paperswithcode.com/paper/s3-you-don-t-need-that-much-data-to-train-a</link>
      <description><![CDATA[Retrieval-augmented generation (RAG) systems empower large language models (LLMs) to access external knowledge during inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s3-you-don-t-need-that-much-data-to-train-a</guid>
    </item>
    <item>
      <title>Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds</title>
      <link>https://paperswithcode.com/paper/causal-cartographer-from-mapping-to-reasoning</link>
      <description><![CDATA[Causal world models are systems that can answer counterfactual questions about an environment of interest, i. e. predict how it would have evolved if an arbitrary subset of events had been realized differently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causal-cartographer-from-mapping-to-reasoning</guid>
    </item>
    <item>
      <title>RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection</title>
      <link>https://paperswithcode.com/paper/radar-enhancing-radiology-report-generation</link>
      <description><![CDATA[Previous approaches have attempted to utilize multimodal LLMs for this task, enhancing their performance through the integration of domain-specific knowledge retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/radar-enhancing-radiology-report-generation</guid>
    </item>
    <item>
      <title>Intra-class Patch Swap for Self-Distillation</title>
      <link>https://paperswithcode.com/paper/intra-class-patch-swap-for-self-distillation</link>
      <description><![CDATA[Although a teacher-free distillation (self-distillation) has emerged as a promising alternative, many existing approaches still rely on architectural modifications or complex training procedures, which limit their generality and efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intra-class-patch-swap-for-self-distillation</guid>
    </item>
    <item>
      <title>Taming Recommendation Bias with Causal Intervention on Evolving Personal Popularity</title>
      <link>https://paperswithcode.com/paper/taming-recommendation-bias-with-causal</link>
      <description><![CDATA[To address these issues, we propose a novel method called CausalEPP (Causal Intervention on Evolving Personal Popularity) for taming recommendation bias, which accounts for the evolving personal popularity of users.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taming-recommendation-bias-with-causal</guid>
    </item>
    <item>
      <title>LoVR: A Benchmark for Long Video Retrieval in Multimodal Contexts</title>
      <link>https://paperswithcode.com/paper/lovr-a-benchmark-for-long-video-retrieval-in</link>
      <description><![CDATA[To address these limitations, we introduce LoVR, a benchmark specifically designed for long video-text retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lovr-a-benchmark-for-long-video-retrieval-in</guid>
    </item>
    <item>
      <title>Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting</title>
      <link>https://paperswithcode.com/paper/dolphin-document-image-parsing-via</link>
      <description><![CDATA[Document image parsing is challenging due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dolphin-document-image-parsing-via</guid>
    </item>
    <item>
      <title>CSTS: A Benchmark for the Discovery of Correlation Structures in Time Series Clustering</title>
      <link>https://paperswithcode.com/paper/csts-a-benchmark-for-the-discovery-of</link>
      <description><![CDATA[To address these challenges, we introduce CSTS (Correlation Structures in Time Series), a synthetic benchmark for evaluating the discovery of correlation structures in multivariate time series data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/csts-a-benchmark-for-the-discovery-of</guid>
    </item>
    <item>
      <title>EEG-to-Text Translation: A Model for Deciphering Human Brain Activity</title>
      <link>https://paperswithcode.com/paper/eeg-to-text-translation-a-model-for</link>
      <description><![CDATA[To overcome these shortcomings, we propose a new model, R1 Translator, which aims to improve the performance of EEG-to-text decoding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eeg-to-text-translation-a-model-for</guid>
    </item>
    <item>
      <title>Personalized Student Knowledge Modeling for Future Learning Resource Prediction</title>
      <link>https://paperswithcode.com/paper/personalized-student-knowledge-modeling-for</link>
      <description><![CDATA[Despite advances in deep learning for education, student knowledge tracing and behavior modeling face persistent challenges: limited personalization, inadequate modeling of diverse learning activities (especially non-assessed materials), and overlooking the interplay between knowledge acquisition and behavioral patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalized-student-knowledge-modeling-for</guid>
    </item>
    <item>
      <title>MGStream: Motion-aware 3D Gaussian for Streamable Dynamic Scene Reconstruction</title>
      <link>https://paperswithcode.com/paper/mgstream-motion-aware-3d-gaussian-for</link>
      <description><![CDATA[The rigid deformation is applied to the motion-related 3DGs for modeling the dynamic, and the attention-based optimization on the motion-related 3DGs enables the reconstruction of the emerging objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mgstream-motion-aware-3d-gaussian-for</guid>
    </item>
    <item>
      <title>Instructing Text-to-Image Diffusion Models via Classifier-Guided Semantic Optimization</title>
      <link>https://paperswithcode.com/paper/instructing-text-to-image-diffusion-models</link>
      <description><![CDATA[In this work, we propose optimizing semantic embeddings guided by attribute classifiers to steer text-to-image models toward desired edits, without relying on text prompts or requiring any training or fine-tuning of the diffusion model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructing-text-to-image-diffusion-models</guid>
    </item>
    <item>
      <title>Do Language Models Use Their Depth Efficiently?</title>
      <link>https://paperswithcode.com/paper/do-language-models-use-their-depth</link>
      <description><![CDATA[All this evidence suggests that deeper models are not using their depth to learn new kinds of computation, but only using the greater depth to perform more fine-grained adjustments to the residual.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-language-models-use-their-depth</guid>
    </item>
    <item>
      <title>DiagnosisArena: Benchmarking Diagnostic Reasoning for Large Language Models</title>
      <link>https://paperswithcode.com/paper/diagnosisarena-benchmarking-diagnostic</link>
      <description><![CDATA[Through DiagnosisArena, we aim to drive further advancements in AIs diagnostic reasoning capabilities, enabling more effective solutions for real-world clinical diagnostic challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diagnosisarena-benchmarking-diagnostic</guid>
    </item>
    <item>
      <title>ABBA: Highly Expressive Hadamard Product Adaptation for Large Language Models</title>
      <link>https://paperswithcode.com/paper/abba-highly-expressive-hadamard-product</link>
      <description><![CDATA[Recent methods like HiRA aim to increase expressivity by incorporating a Hadamard product with the frozen weights, but still rely on the structure of the pre-trained model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/abba-highly-expressive-hadamard-product</guid>
    </item>
    <item>
      <title>Transfer Learning from Visual Speech Recognition to Mouthing Recognition in German Sign Language</title>
      <link>https://paperswithcode.com/paper/transfer-learning-from-visual-speech</link>
      <description><![CDATA[Sign Language Recognition (SLR) systems primarily focus on manual gestures, but non-manual features such as mouth movements, specifically mouthing, provide valuable linguistic information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transfer-learning-from-visual-speech</guid>
    </item>
    <item>
      <title>X-KAN: Optimizing Local Kolmogorov-Arnold Networks via Evolutionary Rule-Based Machine Learning</title>
      <link>https://paperswithcode.com/paper/x-kan-optimizing-local-kolmogorov-arnold</link>
      <description><![CDATA[These results validate the effectiveness of using KAN as a local model in XCSF, which evaluates the rule fitness based on both accuracy and generality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-kan-optimizing-local-kolmogorov-arnold</guid>
    </item>
    <item>
      <title>RAVENEA: A Benchmark for Multimodal Retrieval-Augmented Visual Culture Understanding</title>
      <link>https://paperswithcode.com/paper/ravenea-a-benchmark-for-multimodal-retrieval</link>
      <description><![CDATA[To bridge this gap, we introduce RAVENEA (Retrieval-Augmented Visual culturE uNdErstAnding), a new benchmark designed to advance visual culture understanding through retrieval, focusing on two tasks: culture-focused visual question answering (cVQA) and culture-informed image captioning (cIC).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ravenea-a-benchmark-for-multimodal-retrieval</guid>
    </item>
    <item>
      <title>Latent Flow Transformer</title>
      <link>https://paperswithcode.com/paper/latent-flow-transformer</link>
      <description><![CDATA[Transformers, the standard implementation for large language models (LLMs), typically consist of tens to hundreds of discrete layers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-flow-transformer</guid>
    </item>
    <item>
      <title>Video Compression Commander: Plug-and-Play Inference Acceleration for Video Large Language Models</title>
      <link>https://paperswithcode.com/paper/video-compression-commander-plug-and-play</link>
      <description><![CDATA[Video large language models (VideoLLM) excel at video understanding, but face efficiency challenges due to the quadratic complexity of abundant visual tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-compression-commander-plug-and-play</guid>
    </item>
    <item>
      <title>Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models</title>
      <link>https://paperswithcode.com/paper/neural-incompatibility-the-unbridgeable-gap</link>
      <description><![CDATA[In this paper, we first demonstrate $\textbf{Alignment}$ in parametric space is the fundamental prerequisite to achieve successful cross-scale PKT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-incompatibility-the-unbridgeable-gap</guid>
    </item>
    <item>
      <title>MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language</title>
      <link>https://paperswithcode.com/paper/mug-eval-a-proxy-evaluation-framework-for</link>
      <description><![CDATA[We propose MUG-Eval, a novel framework that evaluates LLMs' multilingual generation capabilities by transforming existing benchmarks into conversational tasks and measuring the LLMs' accuracies on those tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mug-eval-a-proxy-evaluation-framework-for</guid>
    </item>
    <item>
      <title>Think-J: Learning to Think for Generative LLM-as-a-Judge</title>
      <link>https://paperswithcode.com/paper/think-j-learning-to-think-for-generative-llm</link>
      <description><![CDATA[We propose two methods for judgment thinking optimization, based on offline and online RL, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/think-j-learning-to-think-for-generative-llm</guid>
    </item>
    <item>
      <title>RLVR-World: Training World Models with Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/rlvr-world-training-world-models-with</link>
      <description><![CDATA[World models predict state transitions in response to actions and are increasingly developed across diverse modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rlvr-world-training-world-models-with</guid>
    </item>
    <item>
      <title>Place Recognition: A Comprehensive Review, Current Challenges and Future Directions</title>
      <link>https://paperswithcode.com/paper/place-recognition-a-comprehensive-review</link>
      <description><![CDATA[The unified framework of leading-edge place recognition methods, i. e., code library, and the results of their experimental evaluations are available at https://github. com/CV4RA/SOTA-Place-Recognitioner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/place-recognition-a-comprehensive-review</guid>
    </item>
    <item>
      <title>Unlocking the Power of SAM 2 for Few-Shot Segmentation</title>
      <link>https://paperswithcode.com/paper/unlocking-the-power-of-sam-2-for-few-shot</link>
      <description><![CDATA[A simple idea is to encode support foreground (FG) features as memory, with which query FG features are matched and fused.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlocking-the-power-of-sam-2-for-few-shot</guid>
    </item>
    <item>
      <title>Visual Agentic Reinforcement Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/visual-agentic-reinforcement-fine-tuning</link>
      <description><![CDATA[A key trend in Large Reasoning Models (e. g., OpenAI's o3) is the native agentic ability to use external tools such as web browsers for searching and writing/executing code for image manipulation to think with images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-agentic-reinforcement-fine-tuning</guid>
    </item>
    <item>
      <title>Domain Adaptation for Multi-label Image Classification: a Discriminator-free Approach</title>
      <link>https://paperswithcode.com/paper/domain-adaptation-for-multi-label-image</link>
      <description><![CDATA[Subsequently, the source and target GMM parameters are leveraged to formulate an adversarial loss using the Fr\'echet distance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-adaptation-for-multi-label-image</guid>
    </item>
    <item>
      <title>Egocentric Action-aware Inertial Localization in Point Clouds</title>
      <link>https://paperswithcode.com/paper/egocentric-action-aware-inertial-localization</link>
      <description><![CDATA[These encoders are then used in reasoning the IMU data and the point cloud over time and space to perform inertial localization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/egocentric-action-aware-inertial-localization</guid>
    </item>
    <item>
      <title>DeepEyes: Incentivizing "Thinking with Images" via Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/deepeyes-incentivizing-thinking-with-images</link>
      <description><![CDATA[Large Vision-Language Models (VLMs) have shown strong capabilities in multimodal understanding and reasoning, yet they are primarily constrained by text-based reasoning processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepeyes-incentivizing-thinking-with-images</guid>
    </item>
    <item>
      <title>XDementNET: An Explainable Attention Based Deep Convolutional Network to Detect Alzheimer Progression from MRI data</title>
      <link>https://paperswithcode.com/paper/xdementnet-an-explainable-attention-based</link>
      <description><![CDATA[Many recent studies shows that the combination of brain Magnetic Resonance Imaging (MRI) and deep neural networks have achieved promising results for diagnosing AD.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xdementnet-an-explainable-attention-based</guid>
    </item>
    <item>
      <title>Diving into the Fusion of Monocular Priors for Generalized Stereo Matching</title>
      <link>https://paperswithcode.com/paper/diving-into-the-fusion-of-monocular-priors</link>
      <description><![CDATA[A direct fusion of a monocular depth map could alleviate the local optima problem, but noisy disparity results computed at the first several iterations will misguide the fusion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diving-into-the-fusion-of-monocular-priors</guid>
    </item>
    <item>
      <title>R2MED: A Benchmark for Reasoning-Driven Medical Retrieval</title>
      <link>https://paperswithcode.com/paper/r2med-a-benchmark-for-reasoning-driven</link>
      <description><![CDATA[These findings underscore a substantial gap between current retrieval techniques and the reasoning demands of real clinical tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r2med-a-benchmark-for-reasoning-driven</guid>
    </item>
    <item>
      <title>Nonparametric Teaching for Graph Property Learners</title>
      <link>https://paperswithcode.com/paper/nonparametric-teaching-for-graph-property</link>
      <description><![CDATA[Inferring properties of graph-structured data, e. g., the solubility of molecules, essentially involves learning the implicit mapping from graphs to their properties.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nonparametric-teaching-for-graph-property</guid>
    </item>
    <item>
      <title>Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/decoupling-classifier-for-boosting-few-shot-1</link>
      <description><![CDATA[This paper focus on few-shot object detection~(FSOD) and instance segmentation~(FSIS), which requires a model to quickly adapt to novel classes with a few labeled instances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decoupling-classifier-for-boosting-few-shot-1</guid>
    </item>
    <item>
      <title>Grouping First, Attending Smartly: Training-Free Acceleration for Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/grouping-first-attending-smartly-training</link>
      <description><![CDATA[We validate GRAT on pretrained Flux and HunyuanVideo for image and video generation, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grouping-first-attending-smartly-training</guid>
    </item>
    <item>
      <title>Dynadiff: Single-stage Decoding of Images from Continuously Evolving fMRI</title>
      <link>https://paperswithcode.com/paper/dynadiff-single-stage-decoding-of-images-from</link>
      <description><![CDATA[However, current approaches depend on complicated multi-stage pipelines and preprocessing steps that typically collapse the temporal dimension of brain recordings, thereby limiting time-resolved brain decoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynadiff-single-stage-decoding-of-images-from</guid>
    </item>
    <item>
      <title>I'll believe it when I see it: Images increase misinformation sharing in Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/i-ll-believe-it-when-i-see-it-images-increase</link>
      <description><![CDATA[In humans, visual content is known to boost credibility and shareability of information, yet its effect on vision-language models (VLMs) remains unclear.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/i-ll-believe-it-when-i-see-it-images-increase</guid>
    </item>
    <item>
      <title>FRAbench and GenEval: Scaling Fine-Grained Aspect Evaluation across Tasks, Modalities</title>
      <link>https://paperswithcode.com/paper/frabench-and-geneval-scaling-fine-grained</link>
      <description><![CDATA[Evaluating the open-ended outputs of large language models (LLMs) has become a bottleneck as model capabilities, task diversity, and modality coverage rapidly expand.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/frabench-and-geneval-scaling-fine-grained</guid>
    </item>
    <item>
      <title>Unlearning for Federated Online Learning to Rank: A Reproducibility Study</title>
      <link>https://paperswithcode.com/paper/unlearning-for-federated-online-learning-to</link>
      <description><![CDATA[This paper reports on findings from a comparative study on the effectiveness and efficiency of federated unlearning strategies within Federated Online Learning to Rank (FOLTR), with specific attention to systematically analysing the unlearning capabilities of methods in a verifiable manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlearning-for-federated-online-learning-to</guid>
    </item>
    <item>
      <title>Decentralized Arena: Towards Democratic and Scalable Automatic Evaluation of Language Models</title>
      <link>https://paperswithcode.com/paper/decentralized-arena-towards-democratic-and</link>
      <description><![CDATA[The recent explosion of large language models (LLMs), each with its own general or specialized strengths, makes scalable, reliable benchmarking more urgent than ever.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decentralized-arena-towards-democratic-and</guid>
    </item>
    <item>
      <title>From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery</title>
      <link>https://paperswithcode.com/paper/from-automation-to-autonomy-a-survey-on-large</link>
      <description><![CDATA[Large Language Models (LLMs) are catalyzing a paradigm shift in scientific discovery, evolving from task-specific automation tools into increasingly autonomous agents and fundamentally redefining research processes and human-AI collaboration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-automation-to-autonomy-a-survey-on-large</guid>
    </item>
    <item>
      <title>Temporal Query Network for Efficient Multivariate Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/temporal-query-network-for-efficient</link>
      <description><![CDATA[In this paper, we propose a novel technique called Temporal Query (TQ) to more effectively capture multivariate correlations, thereby improving model performance in MTSF tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-query-network-for-efficient</guid>
    </item>
    <item>
      <title>Neural Functional: Learning Function to Scalar Maps for Neural PDE Surrogates</title>
      <link>https://paperswithcode.com/paper/neural-functional-learning-function-to-scalar</link>
      <description><![CDATA[Many architectures for neural PDE surrogates have been proposed in recent years, largely based on neural networks or operator learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-functional-learning-function-to-scalar</guid>
    </item>
  </channel>
</rss>
