<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 06 Aug 2024 21:08:04 +0000</lastBuildDate>
    <item>
      <title>UniProcessor: A Text-induced Unified Low-level Image Processor</title>
      <link>https://paperswithcode.com/paper/uniprocessor-a-text-induced-unified-low-level</link>
      <description><![CDATA[In this paper, we propose a text-induced unified image processor for low-level vision tasks, termed UniProcessor, which can effectively process various degradation types and levels, and support multimodal control.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uniprocessor-a-text-induced-unified-low-level</guid>
    </item>
    <item>
      <title>Comparison of Large Language Models for Generating Contextually Relevant Questions</title>
      <link>https://paperswithcode.com/paper/comparison-of-large-language-models-for</link>
      <description><![CDATA[This study explores the effectiveness of Large Language Models (LLMs) for Automatic Question Generation in educational settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comparison-of-large-language-models-for</guid>
    </item>
    <item>
      <title>OmniBal: Towards Fast Instruct-tuning for Vision-Language Models via Omniverse Computation Balance</title>
      <link>https://paperswithcode.com/paper/omnibal-towards-fast-instruct-tuning-for</link>
      <description><![CDATA[We rebalanced the computational loads from data, model, and memory perspectives to address this issue, achieving more balanced computation across devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnibal-towards-fast-instruct-tuning-for</guid>
    </item>
    <item>
      <title>High-Resolution Spatial Transcriptomics from Histology Images using HisToSGE</title>
      <link>https://paperswithcode.com/paper/high-resolution-spatial-transcriptomics-from</link>
      <description><![CDATA[Spatial transcriptomics (ST) is a groundbreaking genomic technology that enables spatial localization analysis of gene expression within tissue sections.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-resolution-spatial-transcriptomics-from</guid>
    </item>
    <item>
      <title>PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning</title>
      <link>https://paperswithcode.com/paper/pip-prototypes-injected-prompt-for-federated</link>
      <description><![CDATA[Federated Class Incremental Learning (FCIL) is a new direction in continual learning (CL) for addressing catastrophic forgetting and non-IID data distribution simultaneously.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pip-prototypes-injected-prompt-for-federated</guid>
    </item>
    <item>
      <title>HandDAGT: A Denoising Adaptive Graph Transformer for 3D Hand Pose Estimation</title>
      <link>https://paperswithcode.com/paper/handdagt-a-denoising-adaptive-graph</link>
      <description><![CDATA[To address this challenge, this paper proposes the Denoising Adaptive Graph Transformer, HandDAGT, for hand pose estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/handdagt-a-denoising-adaptive-graph</guid>
    </item>
    <item>
      <title>Automated Review Generation Method Based on Large Language Models</title>
      <link>https://paperswithcode.com/paper/automated-review-generation-method-based-on</link>
      <description><![CDATA[Literature research, vital for scientific advancement, is overwhelmed by the vast ocean of available information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automated-review-generation-method-based-on</guid>
    </item>
    <item>
      <title>Boosting Efficiency in Task-Agnostic Exploration through Causal Knowledge</title>
      <link>https://paperswithcode.com/paper/boosting-efficiency-in-task-agnostic</link>
      <description><![CDATA[We demonstrate that causal exploration aids in learning accurate world models using fewer data and provide theoretical guarantees for its convergence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-efficiency-in-task-agnostic</guid>
    </item>
    <item>
      <title>PIXELMOD: Improving Soft Moderation of Visual Misleading Information on Twitter</title>
      <link>https://paperswithcode.com/paper/pixelmod-improving-soft-moderation-of-visual</link>
      <description><![CDATA[Images are a powerful and immediate vehicle to carry misleading or outright false messages, yet identifying image-based misinformation at scale poses unique challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pixelmod-improving-soft-moderation-of-visual</guid>
    </item>
    <item>
      <title>SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision Language Models</title>
      <link>https://paperswithcode.com/paper/synthvlm-high-efficiency-and-high-quality</link>
      <description><![CDATA[Crucially, our method's reliance on purely generated data ensures the preservation of privacy, achieving SoTA performance with just 100k data points (only 18% of the official dataset size).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synthvlm-high-efficiency-and-high-quality</guid>
    </item>
    <item>
      <title>Add-SD: Rational Generation without Manual Reference</title>
      <link>https://paperswithcode.com/paper/add-sd-rational-generation-without-manual</link>
      <description><![CDATA[Our work contributes in three aspects: proposing a dataset containing numerous instructed image pairs; fine-tuning a diffusion model for rational generation; and generating synthetic data to boost downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/add-sd-rational-generation-without-manual</guid>
    </item>
    <item>
      <title>Edge Learning Based Collaborative Automatic Modulation Classification for Hierarchical Cognitive Radio Networks</title>
      <link>https://paperswithcode.com/paper/edge-learning-based-collaborative-automatic</link>
      <description><![CDATA[In hierarchical cognitive radio networks, edge or cloud servers utilize the data collected by edge devices for modulation classification, which, however, is faced with problems of the computation load, transmission overhead, and data privacy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edge-learning-based-collaborative-automatic</guid>
    </item>
    <item>
      <title>Interpreting and Mitigating Hallucination in MLLMs through Multi-agent Debate</title>
      <link>https://paperswithcode.com/paper/interpreting-and-mitigating-hallucination-in</link>
      <description><![CDATA[MLLMs often generate outputs that are inconsistent with the visual content, a challenge known as hallucination.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpreting-and-mitigating-hallucination-in</guid>
    </item>
    <item>
      <title>Restoring Real-World Degraded Events Improves Deblurring Quality</title>
      <link>https://paperswithcode.com/paper/restoring-real-world-degraded-events-improves</link>
      <description><![CDATA[To better assess the deblurring performance of different methods on real-world degraded events, we present a new real-world dataset named DavisMCR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/restoring-real-world-degraded-events-improves</guid>
    </item>
    <item>
      <title>XHand: Real-time Expressive Hand Avatar</title>
      <link>https://paperswithcode.com/paper/xhand-real-time-expressive-hand-avatar</link>
      <description><![CDATA[Hand avatars play a pivotal role in a wide array of digital interfaces, enhancing user immersion and facilitating natural interaction within virtual environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xhand-real-time-expressive-hand-avatar</guid>
    </item>
    <item>
      <title>ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/arcle-the-abstraction-and-reasoning-corpus</link>
      <description><![CDATA[This paper introduces ARCLE, an environment designed to facilitate reinforcement learning research on the Abstraction and Reasoning Corpus (ARC).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/arcle-the-abstraction-and-reasoning-corpus</guid>
    </item>
    <item>
      <title>Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection</title>
      <link>https://paperswithcode.com/paper/integer-valued-training-and-spike-driven</link>
      <description><![CDATA[The proposed method is validated on both static and neuromorphic object detection datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/integer-valued-training-and-spike-driven</guid>
    </item>
    <item>
      <title>Rethinking the Function of Neurons in KANs</title>
      <link>https://paperswithcode.com/paper/rethinking-the-function-of-neurons-in-kans</link>
      <description><![CDATA[The neurons of Kolmogorov-Arnold Networks (KANs) perform a simple summation motivated by the Kolmogorov-Arnold representation theorem, which asserts that sum is the only fundamental multivariate function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-the-function-of-neurons-in-kans</guid>
    </item>
    <item>
      <title>StackFLOW: Monocular Human-Object Reconstruction by Stacked Normalizing Flow with Offset</title>
      <link>https://paperswithcode.com/paper/stackflow-monocular-human-object</link>
      <description><![CDATA[Modeling and capturing the 3D spatial arrangement of the human and the object is the key to perceiving 3D human-object interaction from monocular images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stackflow-monocular-human-object</guid>
    </item>
    <item>
      <title>Dynamic Scene Understanding through Object-Centric Voxelization and Neural Rendering</title>
      <link>https://paperswithcode.com/paper/dynamic-scene-understanding-through-object</link>
      <description><![CDATA[The key idea is to perform object-centric voxelization to capture the 3D nature of the scene, which infers per-object occupancy probabilities at individual spatial locations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-scene-understanding-through-object</guid>
    </item>
    <item>
      <title>DyGKT: Dynamic Graph Learning for Knowledge Tracing</title>
      <link>https://paperswithcode.com/paper/dygkt-dynamic-graph-learning-for-knowledge</link>
      <description><![CDATA[Different from the existing research which utilizes fixed-length learning sequence to obtain the student states and regards KT as a static problem, this work is motivated by three dynamical characteristics: 1) The scales of students answering records are constantly growing; 2) The semantics of time intervals between the records vary; 3) The relationships between students, questions and concepts are evolving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dygkt-dynamic-graph-learning-for-knowledge</guid>
    </item>
    <item>
      <title>Monocular Human-Object Reconstruction in the Wild</title>
      <link>https://paperswithcode.com/paper/monocular-human-object-reconstruction-in-the</link>
      <description><![CDATA[Learning the prior knowledge of the 3D human-object spatial relation is crucial for reconstructing human-object interaction from images and understanding how humans interact with objects in 3D space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monocular-human-object-reconstruction-in-the</guid>
    </item>
    <item>
      <title>What Are Good Positional Encodings for Directed Graphs?</title>
      <link>https://paperswithcode.com/paper/what-are-good-positional-encodings-for</link>
      <description><![CDATA[Our numerical experiments demonstrate the effectiveness of Multi-q Magnetic Laplacian PE with a stable neural architecture, outperforming previous PE methods (with stable networks) on predicting directed distances/walk profiles, sorting network satisfiability, and on general circuit benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-are-good-positional-encodings-for</guid>
    </item>
    <item>
      <title>MMTrail: A Multimodal Trailer Video Dataset with Language and Music Descriptions</title>
      <link>https://paperswithcode.com/paper/mmtrail-a-multimodal-trailer-video-dataset</link>
      <description><![CDATA[To fulfill this gap, we present MMTrail, a large-scale multi-modality video-language dataset incorporating more than 20M trailer clips with visual captions, and 2M high-quality clips with multimodal captions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmtrail-a-multimodal-trailer-video-dataset</guid>
    </item>
    <item>
      <title>Autogenic Language Embedding for Coherent Point Tracking</title>
      <link>https://paperswithcode.com/paper/autogenic-language-embedding-for-coherent</link>
      <description><![CDATA[Point tracking is a challenging task in computer vision, aiming to establish point-wise correspondence across long video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autogenic-language-embedding-for-coherent</guid>
    </item>
    <item>
      <title>Emotion-driven Piano Music Generation via Two-stage Disentanglement and Functional Representation</title>
      <link>https://paperswithcode.com/paper/emotion-driven-piano-music-generation-via-two</link>
      <description><![CDATA[We further leverage our framework in a novel application of emotional controls, showing a broad potential in emotion-driven music generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emotion-driven-piano-music-generation-via-two</guid>
    </item>
    <item>
      <title>DocXPand-25k: a large and diverse benchmark dataset for identity documents analysis</title>
      <link>https://paperswithcode.com/paper/docxpand-25k-a-large-and-diverse-benchmark</link>
      <description><![CDATA[Identity document (ID) image analysis has become essential for many online services, like bank account opening or insurance subscription.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/docxpand-25k-a-large-and-diverse-benchmark</guid>
    </item>
    <item>
      <title>No learning rates needed: Introducing SALSA -- Stable Armijo Line Search Adaptation</title>
      <link>https://paperswithcode.com/paper/no-learning-rates-needed-introducing-salsa</link>
      <description><![CDATA[In recent studies, line search methods have been demonstrated to significantly enhance the performance of conventional stochastic gradient descent techniques across various datasets and architectures, while making an otherwise critical choice of learning rate schedule superfluous.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/no-learning-rates-needed-introducing-salsa</guid>
    </item>
    <item>
      <title>Improving PINNs By Algebraic Inclusion of Boundary and Initial Conditions</title>
      <link>https://paperswithcode.com/paper/improving-pinns-by-algebraic-inclusion-of</link>
      <description><![CDATA[Physics-Informed Neural Networks (PINNs) is the general method that has evolved for this task but its training is well-known to be very unstable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-pinns-by-algebraic-inclusion-of</guid>
    </item>
    <item>
      <title>Investigating Sparsity in Recurrent Neural Networks</title>
      <link>https://paperswithcode.com/paper/investigating-sparsity-in-recurrent-neural</link>
      <description><![CDATA[Many researchers in past years have focused on pruning mainly CNNs, while hardly any research is done for the same in RNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/investigating-sparsity-in-recurrent-neural</guid>
    </item>
    <item>
      <title>Boosting Audio Visual Question Answering via Key Semantic-Aware Cues</title>
      <link>https://paperswithcode.com/paper/boosting-audio-visual-question-answering-via</link>
      <description><![CDATA[The Audio Visual Question Answering (AVQA) task aims to answer questions related to various visual objects, sounds, and their interactions in videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-audio-visual-question-answering-via</guid>
    </item>
    <item>
      <title>Machine Unlearning in Generative AI: A Survey</title>
      <link>https://paperswithcode.com/paper/machine-unlearning-in-generative-ai-a-survey</link>
      <description><![CDATA[We offer a comprehensive survey on many things about MU in Generative AI, such as a new problem formulation, evaluation methods, and a structured discussion on the advantages and limitations of different kinds of MU techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/machine-unlearning-in-generative-ai-a-survey</guid>
    </item>
    <item>
      <title>Image Re-Identification: Where Self-supervision Meets Vision-Language Learning</title>
      <link>https://paperswithcode.com/paper/image-re-identification-where-self</link>
      <description><![CDATA[Recently, large-scale vision-language pre-trained models like CLIP have shown impressive performance in image re-identification (ReID).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/image-re-identification-where-self</guid>
    </item>
    <item>
      <title>CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/cleft-language-image-contrastive-learning</link>
      <description><![CDATA[Recent advancements in Contrastive Language-Image Pre-training (CLIP) have demonstrated notable success in self-supervised representation learning across various tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cleft-language-image-contrastive-learning</guid>
    </item>
    <item>
      <title>ImagiNet: A Multi-Content Dataset for Generalizable Synthetic Image Detection via Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/imaginet-a-multi-content-dataset-for</link>
      <description><![CDATA[Generative models, such as diffusion models (DMs), variational autoencoders (VAEs), and generative adversarial networks (GANs), produce images with a level of authenticity that makes them nearly indistinguishable from real photos and artwork.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imaginet-a-multi-content-dataset-for</guid>
    </item>
    <item>
      <title>Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation</title>
      <link>https://paperswithcode.com/paper/emotion-driven-melody-harmonization-via</link>
      <description><![CDATA[Previous research found it hard to alter the perceived emotional valence of lead sheets only by harmonizing the same melody with different chords, which may be attributed to the constraints imposed by the melody itself and the limitation of existing music representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emotion-driven-melody-harmonization-via</guid>
    </item>
    <item>
      <title>Garment Animation NeRF with Color Editing</title>
      <link>https://paperswithcode.com/paper/garment-animation-nerf-with-color-editing</link>
      <description><![CDATA[Our approach infers garment dynamic features from body motion, providing a preliminary overview of garment structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/garment-animation-nerf-with-color-editing</guid>
    </item>
    <item>
      <title>Theia: Distilling Diverse Vision Foundation Models for Robot Learning</title>
      <link>https://paperswithcode.com/paper/theia-distilling-diverse-vision-foundation</link>
      <description><![CDATA[Vision-based robot policy learning, which maps visual inputs to actions, necessitates a holistic understanding of diverse visual tasks beyond single-task needs like classification or segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/theia-distilling-diverse-vision-foundation</guid>
    </item>
    <item>
      <title>Can I trust my anomaly detection system? A case study based on explainable AI</title>
      <link>https://paperswithcode.com/paper/can-i-trust-my-anomaly-detection-system-a</link>
      <description><![CDATA[Generative models based on variational autoencoders are a popular technique for detecting anomalies in images in a semi-supervised context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-i-trust-my-anomaly-detection-system-a</guid>
    </item>
    <item>
      <title>Through the Looking Glass, and what Horn Clause Programs Found There</title>
      <link>https://paperswithcode.com/paper/through-the-looking-glass-and-what-horn</link>
      <description><![CDATA[Dual Horn clauses mirror key properties of Horn clauses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/through-the-looking-glass-and-what-horn</guid>
    </item>
    <item>
      <title>Importance Corrected Neural JKO Sampling</title>
      <link>https://paperswithcode.com/paper/importance-corrected-neural-jko-sampling</link>
      <description><![CDATA[In order to sample from an unnormalized probability density function, we propose to combine continuous normalizing flows (CNFs) with rejection-resampling steps based on importance weights.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/importance-corrected-neural-jko-sampling</guid>
    </item>
    <item>
      <title>Efficient Face Super-Resolution via Wavelet-based Feature Enhancement Network</title>
      <link>https://paperswithcode.com/paper/efficient-face-super-resolution-via-wavelet</link>
      <description><![CDATA[Previous methods typically employ an encoder-decoder structure to extract facial structural features, where the direct downsampling inevitably introduces distortions, especially to high-frequency features such as edges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-face-super-resolution-via-wavelet</guid>
    </item>
    <item>
      <title>Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/advancing-multimodal-large-language-models-in</link>
      <description><![CDATA[To fill the gap, we propose a visualization-referenced instruction tuning approach to guide the training dataset enhancement and model development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-multimodal-large-language-models-in</guid>
    </item>
    <item>
      <title>F-KANs: Federated Kolmogorov-Arnold Networks</title>
      <link>https://paperswithcode.com/paper/f-kans-federated-kolmogorov-arnold-networks</link>
      <description><![CDATA[In this paper, we present an innovative federated learning (FL) approach that utilizes Kolmogorov-Arnold Networks (KANs) for classification tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/f-kans-federated-kolmogorov-arnold-networks</guid>
    </item>
    <item>
      <title>Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity</title>
      <link>https://paperswithcode.com/paper/urban-traffic-accident-risk-prediction</link>
      <description><![CDATA[In particular, it should adequately consider the regional background, accurately capture both spatial proximity and semantic similarity, and effectively address the sparsity of traffic accidents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/urban-traffic-accident-risk-prediction</guid>
    </item>
    <item>
      <title>RelBench: A Benchmark for Deep Learning on Relational Databases</title>
      <link>https://paperswithcode.com/paper/relbench-a-benchmark-for-deep-learning-on</link>
      <description><![CDATA[We use RelBench to conduct the first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024), which combines graph neural network predictive models with (deep) tabular models that extract initial entity-level representations from raw tables.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relbench-a-benchmark-for-deep-learning-on</guid>
    </item>
    <item>
      <title>Reverse Map Projections as Equivariant Quantum Embeddings</title>
      <link>https://paperswithcode.com/paper/reverse-map-projections-as-equivariant</link>
      <description><![CDATA[We introduce the novel class $(E_\alpha)_{\alpha \in [-\infty, 1)}$ of reverse map projection embeddings, each one defining a unique new method of encoding classical data into quantum states.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reverse-map-projections-as-equivariant</guid>
    </item>
    <item>
      <title>GradCraft: Elevating Multi-task Recommendations through Holistic Gradient Crafting</title>
      <link>https://paperswithcode.com/paper/gradcraft-elevating-multi-task</link>
      <description><![CDATA[GradCraft ensures the concurrent achievement of appropriate magnitude balance and global direction balance, aligning with the inherent characteristics of recommendation scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gradcraft-elevating-multi-task</guid>
    </item>
    <item>
      <title>Global Structure-from-Motion Revisited</title>
      <link>https://paperswithcode.com/paper/global-structure-from-motion-revisited</link>
      <description><![CDATA[Recovering 3D structure and camera motion from images has been a long-standing focus of computer vision research and is known as Structure-from-Motion (SfM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/global-structure-from-motion-revisited</guid>
    </item>
    <item>
      <title>ALEN: A Dual-Approach for Uniform and Non-Uniform Low-Light Image Enhancement</title>
      <link>https://paperswithcode.com/paper/alen-a-dual-approach-for-uniform-and-non</link>
      <description><![CDATA[To address this challenge, the Adaptive Light Enhancement Network (ALEN) is introduced, whose main approach is the use of a classification mechanism to determine whether local or global illumination enhancement is required.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alen-a-dual-approach-for-uniform-and-non</guid>
    </item>
  </channel>
</rss>
