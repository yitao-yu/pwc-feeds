<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 26 Feb 2025 21:09:10 +0000</lastBuildDate>
    <item>
      <title>AKDT: Adaptive Kernel Dilation Transformer for Effective Image Denoising</title>
      <link>https://paperswithcode.com/paper/akdt-adaptive-kernel-dilation-transformer-for</link>
      <description><![CDATA[At the core of AKDT, the NE is seamlessly integrated within standard Transformer components to form the Noise-Guided Feed-Forward Network (NG-FFN) and Noise-Guided Multi-Headed Self-Attention (NG-MSA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/akdt-adaptive-kernel-dilation-transformer-for</guid>
    </item>
    <item>
      <title>Detecting Offensive Memes with Social Biases in Singapore Context Using Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/detecting-offensive-memes-with-social-biases</link>
      <description><![CDATA[Traditional online content moderation systems struggle to classify modern multimodal means of communication, such as memes, a highly nuanced and information-dense medium.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detecting-offensive-memes-with-social-biases</guid>
    </item>
    <item>
      <title>Learning Structure-Supporting Dependencies via Keypoint Interactive Transformer for General Mammal Pose Estimation</title>
      <link>https://paperswithcode.com/paper/learning-structure-supporting-dependencies</link>
      <description><![CDATA[To this end, we propose a Keypoint Interactive Transformer (KIT) to learn instance-level structure-supporting dependencies for general mammal pose estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-structure-supporting-dependencies</guid>
    </item>
    <item>
      <title>AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement</title>
      <link>https://paperswithcode.com/paper/aisafetylab-a-comprehensive-framework-for-ai</link>
      <description><![CDATA[As AI models are increasingly deployed across diverse real-world scenarios, ensuring their safety remains a critical yet underexplored challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aisafetylab-a-comprehensive-framework-for-ai</guid>
    </item>
    <item>
      <title>From System 1 to System 2: A Survey of Reasoning Large Language Models</title>
      <link>https://paperswithcode.com/paper/from-system-1-to-system-2-a-survey-of</link>
      <description><![CDATA[Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-system-1-to-system-2-a-survey-of</guid>
    </item>
    <item>
      <title>MaxGlaViT: A novel lightweight vision transformer-based approach for early diagnosis of glaucoma stages from fundus images</title>
      <link>https://paperswithcode.com/paper/maxglavit-a-novel-lightweight-vision</link>
      <description><![CDATA[This study introduces MaxGlaViT, a lightweight model based on the restructured Multi-Axis Vision Transformer (MaxViT) for early glaucoma detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maxglavit-a-novel-lightweight-vision</guid>
    </item>
    <item>
      <title>CoT-UQ: Improving Response-wise Uncertainty Quantification in LLMs with Chain-of-Thought</title>
      <link>https://paperswithcode.com/paper/cot-uq-improving-response-wise-uncertainty</link>
      <description><![CDATA[Experimental results demonstrate that CoT-UQ significantly outperforms existing UQ methods, achieving an average improvement of 5. 9% AUROC compared to current UQ methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cot-uq-improving-response-wise-uncertainty</guid>
    </item>
    <item>
      <title>Language Model Fine-Tuning on Scaled Survey Data for Predicting Distributions of Public Opinions</title>
      <link>https://paperswithcode.com/paper/language-model-fine-tuning-on-scaled-survey</link>
      <description><![CDATA[Large language models (LLMs) present novel opportunities in public opinion research by predicting survey responses in advance during the early stages of survey design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-model-fine-tuning-on-scaled-survey</guid>
    </item>
    <item>
      <title>R1-OnevisionAn Open-Source Multimodal Large Language Model Capable of Deep Reasoning</title>
      <link>https://paperswithcode.com/paper/r1-onevision-an-open-source-multimodal-large</link>
      <description><![CDATA[R1-OneVision is a versatile multimodal reasoning large model, designed to tackle complex visual reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r1-onevision-an-open-source-multimodal-large</guid>
    </item>
    <item>
      <title>Exact Learning of Permutations for Nonzero Binary Inputs with Logarithmic Training Size and Quadratic Ensemble Complexity</title>
      <link>https://paperswithcode.com/paper/exact-learning-of-permutations-for-nonzero</link>
      <description><![CDATA[The ability of an architecture to realize permutations is quite fundamental.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exact-learning-of-permutations-for-nonzero</guid>
    </item>
    <item>
      <title>Unraveling the geometry of visual relational reasoning</title>
      <link>https://paperswithcode.com/paper/unraveling-the-geometry-of-visual-relational</link>
      <description><![CDATA[To investigate how neural networks generalize abstract relations, we introduce SimplifiedRPM, a novel benchmark for systematic evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unraveling-the-geometry-of-visual-relational</guid>
    </item>
    <item>
      <title>CLIMB-3D: Continual Learning for Imbalanced 3D Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/climb-3d-continual-learning-for-imbalanced-3d</link>
      <description><![CDATA[Unlike prior methods, our framework minimizes ER usage, with KD preventing forgetting and supporting the IC module in compiling past class statistics to balance learning of rare classes during incremental updates.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/climb-3d-continual-learning-for-imbalanced-3d</guid>
    </item>
    <item>
      <title>MegaLoc: One Retrieval to Place Them All</title>
      <link>https://paperswithcode.com/paper/megaloc-one-retrieval-to-place-them-all</link>
      <description><![CDATA[We find that MegaLoc (1) achieves state of the art on a large number of Visual Place Recognition datasets, (2) impressive results on common Landmark Retrieval datasets, and (3) sets a new state of the art for Visual Localization on the LaMAR datasets, where we only changed the retrieval method to the existing localization pipeline.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/megaloc-one-retrieval-to-place-them-all</guid>
    </item>
    <item>
      <title>Semantic Neural Radiance Fields for Multi-Date Satellite Data</title>
      <link>https://paperswithcode.com/paper/semantic-neural-radiance-fields-for-multi</link>
      <description><![CDATA[In this work we propose a satellite specific Neural Radiance Fields (NeRF) model capable to obtain a three-dimensional semantic representation (neural semantic field) of the scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-neural-radiance-fields-for-multi</guid>
    </item>
    <item>
      <title>FedBM: Stealing Knowledge from Pre-trained Language Models for Heterogeneous Federated Learning</title>
      <link>https://paperswithcode.com/paper/fedbm-stealing-knowledge-from-pre-trained</link>
      <description><![CDATA[However, current studies have shown that data heterogeneity incurs local learning bias in classifiers and feature extractors of client models during local training, leading to the performance degradation of a federation system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedbm-stealing-knowledge-from-pre-trained</guid>
    </item>
    <item>
      <title>SwimVG: Step-wise Multimodal Fusion and Adaption for Visual Grounding</title>
      <link>https://paperswithcode.com/paper/swimvg-step-wise-multimodal-fusion-and</link>
      <description><![CDATA[Most existing methods transfer visual/linguistic knowledge separately by fully fine-tuning uni-modal pre-trained models, followed by a simple stack of visual-language transformers for multimodal fusion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/swimvg-step-wise-multimodal-fusion-and</guid>
    </item>
    <item>
      <title>Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning</title>
      <link>https://paperswithcode.com/paper/linguistic-generalizability-of-test-time</link>
      <description><![CDATA[Scaling pre-training compute has proven effective for achieving mulitlinguality, but does the same hold for test-time scaling?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linguistic-generalizability-of-test-time</guid>
    </item>
    <item>
      <title>On Relation-Specific Neurons in Large Language Models</title>
      <link>https://paperswithcode.com/paper/on-relation-specific-neurons-in-large</link>
      <description><![CDATA[To investigate this, we study the Llama-2 family on a chosen set of relations with a statistics-based method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-relation-specific-neurons-in-large</guid>
    </item>
    <item>
      <title>HIPPO: Enhancing the Table Understanding Capability of Large Language Models through Hybrid-Modal Preference Optimization</title>
      <link>https://paperswithcode.com/paper/hippo-enhancing-the-table-understanding</link>
      <description><![CDATA[Tabular data contains rich structural semantics and plays a crucial role in organizing and manipulating information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hippo-enhancing-the-table-understanding</guid>
    </item>
    <item>
      <title>Measuring Data Diversity for Instruction Tuning: A Systematic Analysis and A Reliable Metric</title>
      <link>https://paperswithcode.com/paper/measuring-data-diversity-for-instruction</link>
      <description><![CDATA[To address this, we systematically analyze 11 existing diversity measurement methods by assessing their correlation with model performance through extensive fine-tuning experiments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/measuring-data-diversity-for-instruction</guid>
    </item>
    <item>
      <title>Baichuan-Audio: A Unified Framework for End-to-End Speech Interaction</title>
      <link>https://paperswithcode.com/paper/baichuan-audio-a-unified-framework-for-end-to</link>
      <description><![CDATA[To mitigate the loss of intelligence during pre-training and preserve the original capabilities of the LLM, we propose a two-stage pre-training strategy that maintains language understanding while enhancing audio modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/baichuan-audio-a-unified-framework-for-end-to</guid>
    </item>
    <item>
      <title>Posterior Inference with Diffusion Models for High-dimensional Black-box Optimization</title>
      <link>https://paperswithcode.com/paper/posterior-inference-with-diffusion-models-for</link>
      <description><![CDATA[First, we train a diffusion model to capture the data distribution and an ensemble of proxies to predict function values with uncertainty quantification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posterior-inference-with-diffusion-models-for</guid>
    </item>
    <item>
      <title>Deep Minimax Classifiers for Imbalanced Datasets with a Small Number of Minority Samples</title>
      <link>https://paperswithcode.com/paper/deep-minimax-classifiers-for-imbalanced</link>
      <description><![CDATA[Our algorithm iterates through two steps: a minimization step that trains the model based on a selected target prior, and a maximization step that updates the target prior towards the adversarial prior for the trained model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-minimax-classifiers-for-imbalanced</guid>
    </item>
    <item>
      <title>A Hybrid Approach to Information Retrieval and Answer Generation for Regulatory Texts</title>
      <link>https://paperswithcode.com/paper/a-hybrid-approach-to-information-retrieval</link>
      <description><![CDATA[Regulatory texts are inherently long and complex, presenting significant challenges for information retrieval systems in supporting regulatory officers with compliance tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-hybrid-approach-to-information-retrieval</guid>
    </item>
    <item>
      <title>MultiOCR-QA: Dataset for Evaluating Robustness of LLMs in Question Answering on Multilingual OCR Texts</title>
      <link>https://paperswithcode.com/paper/multiocr-qa-dataset-for-evaluating-robustness</link>
      <description><![CDATA[Optical Character Recognition (OCR) plays a crucial role in digitizing historical and multilingual documents, yet OCR errors -- imperfect extraction of the text, including character insertion, deletion and permutation -- can significantly impact downstream tasks like question-answering (QA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiocr-qa-dataset-for-evaluating-robustness</guid>
    </item>
    <item>
      <title>Advancing Eurasia Fire Understanding Through Machine Learning Techniques</title>
      <link>https://paperswithcode.com/paper/advancing-eurasia-fire-understanding-through</link>
      <description><![CDATA[Modern fire management systems increasingly rely on satellite data and weather forecasting; however, access to comprehensive datasets remains limited due to proprietary restrictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-eurasia-fire-understanding-through</guid>
    </item>
    <item>
      <title>A comparative analysis of rank aggregation methods for the partial label ranking problem</title>
      <link>https://paperswithcode.com/paper/a-comparative-analysis-of-rank-aggregation</link>
      <description><![CDATA[Recently, research has increasingly focused on the \textit{partial label ranking} problem, a generalization of the label ranking problem that allows \textit{ties} in the predicted orders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparative-analysis-of-rank-aggregation</guid>
    </item>
    <item>
      <title>Order Matters: Investigate the Position Bias in Multi-constraint Instruction Following</title>
      <link>https://paperswithcode.com/paper/order-matters-investigate-the-position-bias</link>
      <description><![CDATA[Real-world instructions with multiple constraints pose a significant challenge to existing large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/order-matters-investigate-the-position-bias</guid>
    </item>
    <item>
      <title>Towards Hierarchical Rectified Flow</title>
      <link>https://paperswithcode.com/paper/towards-hierarchical-rectified-flow</link>
      <description><![CDATA[Unlike the classic rectified flow formulation, which formulates a single ODE in the location domain and only captures the expected velocity field (sufficient to capture a multi-modal data distribution), the hierarchical rectified flow formulation models the multi-modal random velocity field, acceleration field, etc., in their entirety.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-hierarchical-rectified-flow</guid>
    </item>
    <item>
      <title>Tidiness Score-Guided Monte Carlo Tree Search for Visual Tabletop Rearrangement</title>
      <link>https://paperswithcode.com/paper/tidiness-score-guided-monte-carlo-tree-search</link>
      <description><![CDATA[In this paper, we present the tidiness score-guided Monte Carlo tree search (TSMCTS), a novel framework designed to address the tabletop tidying up problem using only an RGB-D camera.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tidiness-score-guided-monte-carlo-tree-search</guid>
    </item>
    <item>
      <title>Improved Diffusion-based Generative Model with Better Adversarial Robustness</title>
      <link>https://paperswithcode.com/paper/improved-diffusion-based-generative-model</link>
      <description><![CDATA[To obviate this, we analyze the training objective of DPMs and theoretically demonstrate that this mismatch can be alleviated through Distributionally Robust Optimization (DRO), which is equivalent to performing robustness-driven Adversarial Training (AT) on DPMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-diffusion-based-generative-model</guid>
    </item>
    <item>
      <title>LongSafety: Evaluating Long-Context Safety of Large Language Models</title>
      <link>https://paperswithcode.com/paper/longsafety-evaluating-long-context-safety-of</link>
      <description><![CDATA[However, the safety of LLMs in long-context tasks remains under-explored, leaving a significant gap in both evaluation and improvement of their safety.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longsafety-evaluating-long-context-safety-of</guid>
    </item>
    <item>
      <title>Instance-Dependent Regret Bounds for Learning Two-Player Zero-Sum Games with Bandit Feedback</title>
      <link>https://paperswithcode.com/paper/instance-dependent-regret-bounds-for-learning</link>
      <description><![CDATA[We additionally prove that in this case, our algorithm also enjoys last-iterate convergence and can identify the pure strategy Nash equilibrium with near-optimal sample complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instance-dependent-regret-bounds-for-learning</guid>
    </item>
    <item>
      <title>Capability Instruction Tuning: A New Paradigm for Dynamic LLM Routing</title>
      <link>https://paperswithcode.com/paper/capability-instruction-tuning-a-new-paradigm</link>
      <description><![CDATA[We develop a new paradigm, constructing capability instructions with model capability representation, user instruction, and performance inquiry prompts to assess the performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/capability-instruction-tuning-a-new-paradigm</guid>
    </item>
    <item>
      <title>DIS-CO: Discovering Copyrighted Content in VLMs Training Data</title>
      <link>https://paperswithcode.com/paper/dis-co-discovering-copyrighted-content-in</link>
      <description><![CDATA[Motivated by the hypothesis that a VLM is able to recognize images from its training corpus, we propose DIS-CO, a novel approach to infer the inclusion of copyrighted content during the model's development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dis-co-discovering-copyrighted-content-in</guid>
    </item>
    <item>
      <title>Forgetting Any Data at Any Time: A Theoretically Certified Unlearning Framework for Vertical Federated Learning</title>
      <link>https://paperswithcode.com/paper/forgetting-any-data-at-any-time-a</link>
      <description><![CDATA[Privacy concerns in machine learning are heightened by regulations such as the GDPR, which enforces the "right to be forgotten" (RTBF), driving the emergence of machine unlearning as a critical research field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/forgetting-any-data-at-any-time-a</guid>
    </item>
    <item>
      <title>LongSpec: Long-Context Speculative Decoding with Efficient Drafting and Verification</title>
      <link>https://paperswithcode.com/paper/longspec-long-context-speculative-decoding</link>
      <description><![CDATA[Despite its promise, the effective application of speculative decoding in LLMs still confronts three key challenges: the increasing memory demands of the draft model, the distribution shift between the short-training corpora and long-context inference, and inefficiencies in attention implementation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longspec-long-context-speculative-decoding</guid>
    </item>
    <item>
      <title>JUREX-4E: Juridical Expert-Annotated Four-Element Knowledge Base for Legal Reasoning</title>
      <link>https://paperswithcode.com/paper/jurex-4e-juridical-expert-annotated-four</link>
      <description><![CDATA[The Four-Element Theory is a fundamental framework in criminal law, defining the constitution of crime through four dimensions: Subject, Object, Subjective aspect, and Objective aspect.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jurex-4e-juridical-expert-annotated-four</guid>
    </item>
    <item>
      <title>DICEPTION: A Generalist Diffusion Model for Visual Perceptual Tasks</title>
      <link>https://paperswithcode.com/paper/diception-a-generalist-diffusion-model-for</link>
      <description><![CDATA[We achieve results on par with SAM-vit-h using only 0. 06% of their data (e. g., 600K vs. 1B pixel-level annotated images).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diception-a-generalist-diffusion-model-for</guid>
    </item>
    <item>
      <title>Big-Math: A Large-Scale, High-Quality Math Dataset for Reinforcement Learning in Language Models</title>
      <link>https://paperswithcode.com/paper/big-math-a-large-scale-high-quality-math</link>
      <description><![CDATA[However, existing open math datasets either contain a small collection of high-quality, human-written problems or a large corpus of machine-generated problems of uncertain quality, forcing researchers to choose between quality and quantity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/big-math-a-large-scale-high-quality-math</guid>
    </item>
    <item>
      <title>Diffusion Models for Tabular Data: Challenges, Current Progress, and Future Directions</title>
      <link>https://paperswithcode.com/paper/diffusion-models-for-tabular-data-challenges</link>
      <description><![CDATA[This survey addresses this gap by providing a comprehensive review of diffusion models for tabular data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-for-tabular-data-challenges</guid>
    </item>
    <item>
      <title>MLLMs Know Where to Look: Training-free Perception of Small Visual Details with Multimodal LLMs</title>
      <link>https://paperswithcode.com/paper/mllms-know-where-to-look-training-free</link>
      <description><![CDATA[Multimodal Large Language Models (MLLMs) have experienced rapid progress in visual recognition tasks in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mllms-know-where-to-look-training-free</guid>
    </item>
    <item>
      <title>Adversarial Training for Defense Against Label Poisoning Attacks</title>
      <link>https://paperswithcode.com/paper/adversarial-training-for-defense-against</link>
      <description><![CDATA[These results underscore the potential of FLORAL to enhance the resilience of machine learning models against label poisoning threats, thereby ensuring robust classification in adversarial settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-training-for-defense-against</guid>
    </item>
    <item>
      <title>Stable-SPAM: How to Train in 4-Bit More Stably than 16-Bit Adam</title>
      <link>https://paperswithcode.com/paper/stable-spam-how-to-train-in-4-bit-more-stably</link>
      <description><![CDATA[This paper comprehensively evaluates several recently proposed optimizers for 4-bit training, revealing that low-bit precision amplifies sensitivity to learning rates and often causes unstable gradient norms, leading to divergence at higher learning rates.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stable-spam-how-to-train-in-4-bit-more-stably</guid>
    </item>
    <item>
      <title>Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs</title>
      <link>https://paperswithcode.com/paper/emergent-misalignment-narrow-finetuning-can</link>
      <description><![CDATA[In our experiment, a model is finetuned to output insecure code without disclosing this to the user.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emergent-misalignment-narrow-finetuning-can</guid>
    </item>
    <item>
      <title>MambaFlow: A Novel and Flow-guided State Space Model for Scene Flow Estimation</title>
      <link>https://paperswithcode.com/paper/mambaflow-a-novel-and-flow-guided-state-space</link>
      <description><![CDATA[In this paper, we propose MambaFlow, a novel scene flow estimation network with a mamba-based decoder.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mambaflow-a-novel-and-flow-guided-state-space</guid>
    </item>
    <item>
      <title>MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/mad-ad-masked-diffusion-for-unsupervised</link>
      <description><![CDATA[During training, our model processes only normal brain MRI scans and performs a forward diffusion process in the latent space that adds noise to the features of randomly-selected patches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mad-ad-masked-diffusion-for-unsupervised</guid>
    </item>
    <item>
      <title>Introducing Visual Perception Token into Multimodal Large Language Model</title>
      <link>https://paperswithcode.com/paper/introducing-visual-perception-token-into</link>
      <description><![CDATA[The Region Selection Token explicitly identifies specific regions in an image that require further perception, while the Vision Re-Encoding Token uses its hidden states as control signals to guide additional visual perception processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/introducing-visual-perception-token-into</guid>
    </item>
    <item>
      <title>Predicting the Energy Landscape of Stochastic Dynamical System via Physics-informed Self-supervised Learning</title>
      <link>https://paperswithcode.com/paper/predicting-the-energy-landscape-of-stochastic</link>
      <description><![CDATA[Energy landscapes play a crucial role in shaping dynamics of many real-world complex systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/predicting-the-energy-landscape-of-stochastic</guid>
    </item>
    <item>
      <title>CipherPrune: Efficient and Scalable Private Transformer Inference</title>
      <link>https://paperswithcode.com/paper/cipherprune-efficient-and-scalable-private</link>
      <description><![CDATA[Our experiments demonstrate that CipherPrune reduces the execution overhead of private Transformer inference by approximately $6. 1\times$ for 128-token inputs and $10. 6\times$ for 512-token inputs, compared to previous methods, with only a marginal drop in accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cipherprune-efficient-and-scalable-private</guid>
    </item>
  </channel>
</rss>
