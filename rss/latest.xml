<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 17 Oct 2024 21:08:59 +0000</lastBuildDate>
    <item>
      <title>Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective</title>
      <link>https://paperswithcode.com/paper/stabilize-the-latent-space-for-image</link>
      <description><![CDATA[Furthermore, we propose a simple but effective discrete image tokenizer to stabilize the latent space for image generative modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stabilize-the-latent-space-for-image</guid>
    </item>
    <item>
      <title>PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking</title>
      <link>https://paperswithcode.com/paper/preflexor-preference-based-recursive-language</link>
      <description><![CDATA[We propose a recursive learning approach that engages the model in multi-step reasoning, revisiting, and refining intermediate steps before producing a final output in training and inference phases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/preflexor-preference-based-recursive-language</guid>
    </item>
    <item>
      <title>Conditional Outcome Equivalence: A Quantile Alternative to CATE</title>
      <link>https://paperswithcode.com/paper/conditional-outcome-equivalence-a-quantile</link>
      <description><![CDATA[This is in stark contrast to CATE where it is possible to obtain high-quality estimates which have less dependency upon the smoothness of the nuisance parameters when the CATE itself is smooth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conditional-outcome-equivalence-a-quantile</guid>
    </item>
    <item>
      <title>HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts</title>
      <link>https://paperswithcode.com/paper/henry-a-multi-agent-system-framework-for</link>
      <description><![CDATA[This project, named HEnRY, aims to introduce a Multi-Agent System (MAS) into Intesa Sanpaolo.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/henry-a-multi-agent-system-framework-for</guid>
    </item>
    <item>
      <title>Characterizing Behavioral Differences and Adaptations of Automated Vehicles and Human Drivers at Unsignalized Intersections: Insights from Waymo and Lyft Open Datasets</title>
      <link>https://paperswithcode.com/paper/characterizing-behavioral-differences-and</link>
      <description><![CDATA[This study aims to bridge this gap by examining behavioral differences and adaptations of AVs and HVs at unsignalized intersections by utilizing two comprehensive AV datasets from Waymo and Lyft.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/characterizing-behavioral-differences-and</guid>
    </item>
    <item>
      <title>Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization</title>
      <link>https://paperswithcode.com/paper/embedding-an-ethical-mind-aligning-text-to</link>
      <description><![CDATA[To optimize the value encoder, we also develop a framework to automatically construct a text-image preference dataset of 86k (prompt, aligned image, violating image, value principle) samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embedding-an-ethical-mind-aligning-text-to</guid>
    </item>
    <item>
      <title>MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation</title>
      <link>https://paperswithcode.com/paper/mllm-can-see-dynamic-correction-decoding-for</link>
      <description><![CDATA[Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mllm-can-see-dynamic-correction-decoding-for</guid>
    </item>
    <item>
      <title>DARNet: Dual Attention Refinement Network with Spatiotemporal Construction for Auditory Attention Detection</title>
      <link>https://paperswithcode.com/paper/darnet-dual-attention-refinement-network-with</link>
      <description><![CDATA[To address these issues, this paper proposes a dual attention refinement network with spatiotemporal construction for AAD, named DARNet, which consists of the spatiotemporal construction module, dual attention refinement module, and feature fusion \& classifier module.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/darnet-dual-attention-refinement-network-with</guid>
    </item>
    <item>
      <title>AIC CTU system at AVeriTeC: Re-framing automated fact-checking as a simple RAG task</title>
      <link>https://paperswithcode.com/paper/aic-ctu-system-at-averitec-re-framing</link>
      <description><![CDATA[This paper describes our $3^{rd}$ place submission in the AVeriTeC shared task in which we attempted to address the challenge of fact-checking with evidence retrieved in the wild using a simple scheme of Retrieval-Augmented Generation (RAG) designed for the task, leveraging the predictive power of Large Language Models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aic-ctu-system-at-averitec-re-framing</guid>
    </item>
    <item>
      <title>Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models</title>
      <link>https://paperswithcode.com/paper/layer-wise-importance-matters-less-memory-for</link>
      <description><![CDATA[Extensive experiments on a range of LLMs, PEFTs, and downstream tasks substantiate the effectiveness of our proposed method, showcasing IST's capacity to enhance existing layer-based PEFT methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/layer-wise-importance-matters-less-memory-for</guid>
    </item>
    <item>
      <title>CVCP-Fusion: On Implicit Depth Estimation for 3D Bounding Box Prediction</title>
      <link>https://paperswithcode.com/paper/cvcp-fusion-on-implicit-depth-estimation-for</link>
      <description><![CDATA[In this paper we propose Cross-View Center Point-Fusion, a state-of-the-art model to perform 3D object detection by combining camera and LiDAR-derived features in the BEV space to preserve semantic density from the camera stream while incorporating spacial data from the LiDAR stream.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cvcp-fusion-on-implicit-depth-estimation-for</guid>
    </item>
    <item>
      <title>Do LLMs Have the Generalization Ability in Conducting Causal Inference?</title>
      <link>https://paperswithcode.com/paper/do-llms-have-the-generalization-ability-in</link>
      <description><![CDATA[In this paper, we selected four tasks: Causal Path Discovery (CP), Backdoor Adjustment (BA), Factual Inference (FI), and Counterfactual Inference (CI) as representatives of causal inference tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-llms-have-the-generalization-ability-in</guid>
    </item>
    <item>
      <title>Contrastive learning of cell state dynamics in response to perturbations</title>
      <link>https://paperswithcode.com/paper/contrastive-learning-of-cell-state-dynamics</link>
      <description><![CDATA[We illustrate the features and applications of DynaCLR with the following experiments: analyzing the kinetics of viral infection in human cells, detecting transient changes in cell morphology due to cell division, and mapping the dynamics of organelles due to viral infection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-learning-of-cell-state-dynamics</guid>
    </item>
    <item>
      <title>It Takes Two to Tango: Directly Optimizing for Constrained Synthesizability in Generative Molecular Design</title>
      <link>https://paperswithcode.com/paper/it-takes-two-to-tango-directly-optimizing-for</link>
      <description><![CDATA[Our framework is the first generative approach to tackle constrained synthesizability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/it-takes-two-to-tango-directly-optimizing-for</guid>
    </item>
    <item>
      <title>On-the-fly Modulation for Balanced Multimodal Learning</title>
      <link>https://paperswithcode.com/paper/on-the-fly-modulation-for-balanced-multimodal</link>
      <description><![CDATA[Then, On-the-fly Prediction Modulation (OPM) and On-the-fly Gradient Modulation (OGM) strategies are proposed to modulate the optimization of each modality, by monitoring the discriminative discrepancy between modalities during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-fly-modulation-for-balanced-multimodal</guid>
    </item>
    <item>
      <title>LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/llm-mixer-multiscale-mixing-in-llms-for-time</link>
      <description><![CDATA[Time series forecasting remains a challenging task, particularly in the context of complex multiscale temporal patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-mixer-multiscale-mixing-in-llms-for-time</guid>
    </item>
    <item>
      <title>Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs</title>
      <link>https://paperswithcode.com/paper/difficult-task-yes-but-simple-task-no</link>
      <description><![CDATA[Multimodal Large Language Models (MLLMs) demonstrate a strong understanding of the real world and can even handle complex tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/difficult-task-yes-but-simple-task-no</guid>
    </item>
    <item>
      <title>Process Reward Model with Q-Value Rankings</title>
      <link>https://paperswithcode.com/paper/process-reward-model-with-q-value-rankings</link>
      <description><![CDATA[PQM optimizes Q-value rankings based on a novel comparative loss function, enhancing the model's ability to capture the intricate dynamics among sequential decisions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/process-reward-model-with-q-value-rankings</guid>
    </item>
    <item>
      <title>Safety Filtering While Training: Improving the Performance and Sample Efficiency of Reinforcement Learning Agents</title>
      <link>https://paperswithcode.com/paper/safety-filtering-while-training-improving-the</link>
      <description><![CDATA[In experiments, we show that the proposed training approaches require significantly fewer environment interactions and improve performance by up to 20% compared to standard RL training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safety-filtering-while-training-improving-the</guid>
    </item>
    <item>
      <title>A Cross-Lingual Statutory Article Retrieval Dataset for Taiwan Legal Studies</title>
      <link>https://paperswithcode.com/paper/a-cross-lingual-statutory-article-retrieval</link>
      <description><![CDATA[This paper introduces a cross-lingual statutory article retrieval (SAR) dataset designed to enhance legal information retrieval in multilingual settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-cross-lingual-statutory-article-retrieval</guid>
    </item>
    <item>
      <title>Adversarially Guided Stateful Defense Against Backdoor Attacks in Federated Deep Learning</title>
      <link>https://paperswithcode.com/paper/adversarially-guided-stateful-defense-against</link>
      <description><![CDATA[We show that in realistic FL settings, state-of-the-art (SOTA) defenses struggle to perform well against backdoor attacks in FL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarially-guided-stateful-defense-against</guid>
    </item>
    <item>
      <title>Differentiable Programming for Computational Plasma Physics</title>
      <link>https://paperswithcode.com/paper/differentiable-programming-for-computational</link>
      <description><![CDATA[First, we consider how differentiable programming can be used to simplify and improve stellarator optimization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/differentiable-programming-for-computational</guid>
    </item>
    <item>
      <title>MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models</title>
      <link>https://paperswithcode.com/paper/mtu-bench-a-multi-granularity-tool-use</link>
      <description><![CDATA[Besides, all evaluation metrics of our MTU-Bench are based on the prediction results and the ground truth without using any GPT or human evaluation metrics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mtu-bench-a-multi-granularity-tool-use</guid>
    </item>
    <item>
      <title>TraM : Enhancing User Sleep Prediction with Transformer-based Multivariate Time Series Modeling and Machine Learning Ensembles</title>
      <link>https://paperswithcode.com/paper/tram-enhancing-user-sleep-prediction-with</link>
      <description><![CDATA[Time Series Transformer was used for labels where time series characteristics are crucial, while Machine Learning Ensembles were employed for labels requiring comprehensive daily activity statistics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tram-enhancing-user-sleep-prediction-with</guid>
    </item>
    <item>
      <title>Meta-DT: Offline Meta-RL as Conditional Sequence Modeling with World Model Disentanglement</title>
      <link>https://paperswithcode.com/paper/meta-dt-offline-meta-rl-as-conditional</link>
      <description><![CDATA[We pretrain a context-aware world model to learn a compact task representation, and inject it as a contextual condition to the causal transformer to guide task-oriented sequence generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-dt-offline-meta-rl-as-conditional</guid>
    </item>
    <item>
      <title>Language Models Encode Numbers Using Digit Representations in Base 10</title>
      <link>https://paperswithcode.com/paper/language-models-encode-numbers-using-digit</link>
      <description><![CDATA[Large language models (LLMs) frequently make errors when handling even simple numerical problems, such as comparing two small numbers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-encode-numbers-using-digit</guid>
    </item>
    <item>
      <title>Leaving the barn door open for Clever Hans: Simple features predict LLM benchmark answers</title>
      <link>https://paperswithcode.com/paper/leaving-the-barn-door-open-for-clever-hans</link>
      <description><![CDATA[In this work, we investigate the extent to which simple $n$-grams extracted from benchmark instances can be combined to predict labels in modern multiple-choice benchmarks designed for LLMs, and whether LLMs might be using such $n$-gram patterns to solve these benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leaving-the-barn-door-open-for-clever-hans</guid>
    </item>
    <item>
      <title>Zero-shot Model-based Reinforcement Learning using Large Language Models</title>
      <link>https://paperswithcode.com/paper/zero-shot-model-based-reinforcement-learning</link>
      <description><![CDATA[The emerging zero-shot capabilities of Large Language Models (LLMs) have led to their applications in areas extending well beyond natural language processing tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-model-based-reinforcement-learning</guid>
    </item>
    <item>
      <title>Benchmarking Data Efficiency in $Δ$-ML and Multifidelity Models for Quantum Chemistry</title>
      <link>https://paperswithcode.com/paper/benchmarking-data-efficiency-in-d-ml-and</link>
      <description><![CDATA[Increased work in reducing the cost of generating training data resulted in the development of $\Delta$-ML and multifidelity machine learning methods which use data at more than one QC level of accuracy, or fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-data-efficiency-in-d-ml-and</guid>
    </item>
    <item>
      <title>Conditional Density Estimation with Histogram Trees</title>
      <link>https://paperswithcode.com/paper/conditional-density-estimation-with-histogram</link>
      <description><![CDATA[Our experiments demonstrate that, in comparison to existing interpretable CDE methods, CDTrees are both more accurate (as measured by the log-loss) and more robust against irrelevant features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conditional-density-estimation-with-histogram</guid>
    </item>
    <item>
      <title>Improving Long-Text Alignment for Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/improving-long-text-alignment-for-text-to</link>
      <description><![CDATA[To tackle these issues, we propose LongAlign, which includes a segment-level encoding method for processing long texts and a decomposed preference optimization method for effective alignment training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-long-text-alignment-for-text-to</guid>
    </item>
    <item>
      <title>On the potential of Optimal Transport in Geospatial Data Science</title>
      <link>https://paperswithcode.com/paper/on-the-potential-of-optimal-transport-in</link>
      <description><![CDATA[We put forward Optimal Transport (OT) as a spatial evaluation metric and loss function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-potential-of-optimal-transport-in</guid>
    </item>
    <item>
      <title>MCTBench: Multimodal Cognition towards Text-Rich Visual Scenes Benchmark</title>
      <link>https://paperswithcode.com/paper/mctbench-multimodal-cognition-towards-text</link>
      <description><![CDATA[The comprehension of text-rich visual scenes has become a focal point for evaluating Multi-modal Large Language Models (MLLMs) due to their widespread applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mctbench-multimodal-cognition-towards-text</guid>
    </item>
    <item>
      <title>Eliciting Textual Descriptions from Representations of Continuous Prompts</title>
      <link>https://paperswithcode.com/paper/eliciting-textual-descriptions-from</link>
      <description><![CDATA[Continuous prompts, or "soft prompts", are a widely-adopted parameter-efficient tuning strategy for large language models, but are often less favorable due to their opaque nature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eliciting-textual-descriptions-from</guid>
    </item>
    <item>
      <title>Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/automatically-generating-visual-hallucination</link>
      <description><![CDATA[Our theoretical analysis shows that symmetric accuracy is an unbiased evaluation metric that remains unaffected by the imbalance of VH testing cases with varying answers when an MLLM is randomly guessing the answers, whereas traditional accuracy is prone to such imbalance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automatically-generating-visual-hallucination</guid>
    </item>
    <item>
      <title>Bayesian Experimental Design via Contrastive Diffusions</title>
      <link>https://paperswithcode.com/paper/bayesian-experimental-design-via-contrastive</link>
      <description><![CDATA[In this work, we introduce an {\it expected posterior} distribution with cost-effective sampling properties and provide a tractable access to the EIG contrast maximization via a new EIG gradient expression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bayesian-experimental-design-via-contrastive</guid>
    </item>
    <item>
      <title>RATE: Score Reward Models with Imperfect Rewrites of Rewrites</title>
      <link>https://paperswithcode.com/paper/rate-score-reward-models-with-imperfect</link>
      <description><![CDATA[In this paper, we develop an evaluation method, RATE (Rewrite-based Attribute Treatment Estimators), that allows us to measure the causal effect of a given attribute of a response (e. g., length) on the reward assigned to that response.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rate-score-reward-models-with-imperfect</guid>
    </item>
    <item>
      <title>Spatio-Temporal Distortion Aware Omnidirectional Video Super-Resolution</title>
      <link>https://paperswithcode.com/paper/spatio-temporal-distortion-aware</link>
      <description><![CDATA[Omnidirectional video (ODV) can provide an immersive experience and is widely utilized in the field of virtual reality and augmented reality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatio-temporal-distortion-aware</guid>
    </item>
    <item>
      <title>Enhancing Assamese NLP Capabilities: Introducing a Centralized Dataset Repository</title>
      <link>https://paperswithcode.com/paper/enhancing-assamese-nlp-capabilities</link>
      <description><![CDATA[This paper introduces a centralized, open-source dataset repository designed to advance NLP and NMT for Assamese, a low-resource language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-assamese-nlp-capabilities</guid>
    </item>
    <item>
      <title>A Bilevel Optimization Framework for Imbalanced Data Classification</title>
      <link>https://paperswithcode.com/paper/a-bilevel-optimization-framework-for</link>
      <description><![CDATA[To tackle unresolved problems related to both oversampling and undersampling, we propose a new undersampling approach that: (i) avoids the pitfalls of noise and overlap caused by synthetic data and (ii) avoids the pitfall of under-fitting caused by random undersampling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-bilevel-optimization-framework-for</guid>
    </item>
    <item>
      <title>Dual-Teacher Ensemble Models with Double-Copy-Paste for 3D Semi-Supervised Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/dual-teacher-ensemble-models-with-double-copy</link>
      <description><![CDATA[Dual-teacher models were introduced to address this problem but often neglected the importance of maintaining teacher model diversity, leading to coupling issues among teachers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-teacher-ensemble-models-with-double-copy</guid>
    </item>
    <item>
      <title>TEOcc: Radar-camera Multi-modal Occupancy Prediction via Temporal Enhancement</title>
      <link>https://paperswithcode.com/paper/teocc-radar-camera-multi-modal-occupancy</link>
      <description><![CDATA[In addition, the proposed temporal enhancement branch is a plug-and-play module that can be easily integrated into existing occupancy prediction methods to improve the performance of occupancy prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teocc-radar-camera-multi-modal-occupancy</guid>
    </item>
    <item>
      <title>FedCCRL: Federated Domain Generalization with Cross-Client Representation Learning</title>
      <link>https://paperswithcode.com/paper/fedccrl-federated-domain-generalization-with</link>
      <description><![CDATA[Domain Generalization (DG) aims to train models that can effectively generalize to unseen domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedccrl-federated-domain-generalization-with</guid>
    </item>
    <item>
      <title>Why Go Full? Elevating Federated Learning Through Partial Network Updates</title>
      <link>https://paperswithcode.com/paper/why-go-full-elevating-federated-learning</link>
      <description><![CDATA[In traditional federated learning, the entire parameter set of local models is updated and averaged in each training round.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/why-go-full-elevating-federated-learning</guid>
    </item>
    <item>
      <title>LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios</title>
      <link>https://paperswithcode.com/paper/lr-sql-a-supervised-fine-tuning-method-for</link>
      <description><![CDATA[Large language models revolutionize Text2SQL through supervised fine-tuning, yet a crucial limitation is overlooked: the complexity of databases leads to an increased context length, consequently resulting in higher GPU memory demands for model fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lr-sql-a-supervised-fine-tuning-method-for</guid>
    </item>
    <item>
      <title>A Hitchhiker's Guide to Scaling Law Estimation</title>
      <link>https://paperswithcode.com/paper/a-hitchhiker-s-guide-to-scaling-law</link>
      <description><![CDATA[Moreover, while different model families differ scaling behavior, they are often similar enough that a target model's behavior can be predicted from a single model with the same architecture, along with scaling parameter estimates derived from other model families.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-hitchhiker-s-guide-to-scaling-law</guid>
    </item>
    <item>
      <title>Archilles' Heel in Semi-open LLMs: Hiding Bottom against Recovery Attacks</title>
      <link>https://paperswithcode.com/paper/archilles-heel-in-semi-open-llms-hiding</link>
      <description><![CDATA[We analyze the contribution of closed-source layer to the overall resilience and theoretically prove that in a deep transformer-based model, there exists a transition layer such that even small recovery errors in layers before this layer can lead to recovery failure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/archilles-heel-in-semi-open-llms-hiding</guid>
    </item>
    <item>
      <title>Leveraging LLM Embeddings for Cross Dataset Label Alignment and Zero Shot Music Emotion Prediction</title>
      <link>https://paperswithcode.com/paper/leveraging-llm-embeddings-for-cross-dataset</link>
      <description><![CDATA[In this work, we present a novel method for music emotion recognition that leverages Large Language Model (LLM) embeddings for label alignment across multiple datasets and zero-shot prediction on novel categories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-llm-embeddings-for-cross-dataset</guid>
    </item>
    <item>
      <title>RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation</title>
      <link>https://paperswithcode.com/paper/rclicks-realistic-click-simulation-for</link>
      <description><![CDATA[According to our benchmark, in real-world usage interactive segmentation models may perform worse than it has been reported in the baseline benchmark, and most of the methods are not robust.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rclicks-realistic-click-simulation-for</guid>
    </item>
    <item>
      <title>Overcoming Domain Limitations in Open-vocabulary Segmentation</title>
      <link>https://paperswithcode.com/paper/overcoming-domain-limitations-in-open</link>
      <description><![CDATA[Extensive experiments demonstrate that this approach allows OVS models to adapt to new domains while maintaining performance on the previous training dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/overcoming-domain-limitations-in-open</guid>
    </item>
  </channel>
</rss>
