<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 30 May 2023 21:05:38 +0000</lastBuildDate>
    <item>
      <title>TaleCrafter: Interactive Story Visualization with Multiple Characters</title>
      <link>https://paperswithcode.com/paper/talecrafter-interactive-story-visualization</link>
      <description><![CDATA[Accurate Story visualization requires several necessary elements, such as identity consistency across frames, the alignment between plain text and visual content, and a reasonable layout of objects in images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/talecrafter-interactive-story-visualization</guid>
    </item>
    <item>
      <title>CamoDiffusion: Camouflaged Object Detection via Conditional Diffusion Models</title>
      <link>https://paperswithcode.com/paper/camodiffusion-camouflaged-object-detection</link>
      <description><![CDATA[Due to the stochastic sampling process of diffusion, our model is capable of sampling multiple possible predictions from the mask distribution, avoiding the problem of overconfident point estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camodiffusion-camouflaged-object-detection</guid>
    </item>
    <item>
      <title>Reason to explain: Interactive contrastive explanations (REASONX)</title>
      <link>https://paperswithcode.com/paper/reason-to-explain-interactive-contrastive</link>
      <description><![CDATA[REASONX provides interactive contrastive explanations that can be augmented by background knowledge, and allows to operate under a setting of under-specified information, leading to increased flexibility in the provided explanations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reason-to-explain-interactive-contrastive</guid>
    </item>
    <item>
      <title>Beyond Confidence: Reliable Models Should Also Consider Atypicality</title>
      <link>https://paperswithcode.com/paper/beyond-confidence-reliable-models-should-also</link>
      <description><![CDATA[In this work, we investigate the relationship between how atypical(rare) a sample or a class is and the reliability of a model's predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-confidence-reliable-models-should-also</guid>
    </item>
    <item>
      <title>Data Augmentation for Low-Resource Keyphrase Generation</title>
      <link>https://paperswithcode.com/paper/data-augmentation-for-low-resource-keyphrase</link>
      <description><![CDATA[Very few works address the problem of keyphrase generation in low-resource settings, but they still rely on a lot of additional unlabeled data for pretraining and on automatic methods for pseudo-annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-augmentation-for-low-resource-keyphrase</guid>
    </item>
    <item>
      <title>Towards Efficient Deep Hashing Retrieval: Condensing Your Data via Feature-Embedding Matching</title>
      <link>https://paperswithcode.com/paper/towards-efficient-deep-hashing-retrieval</link>
      <description><![CDATA[The expenses involved in training state-of-the-art deep hashing retrieval models have witnessed an increase due to the adoption of more sophisticated models and large-scale datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-efficient-deep-hashing-retrieval</guid>
    </item>
    <item>
      <title>Synfeal: A Data-Driven Simulator for End-to-End Camera Localization</title>
      <link>https://paperswithcode.com/paper/synfeal-a-data-driven-simulator-for-end-to</link>
      <description><![CDATA[Our results also suggest that when a large localization dataset with high quality is available, training from scratch leads to better performances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synfeal-a-data-driven-simulator-for-end-to</guid>
    </item>
    <item>
      <title>Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models</title>
      <link>https://paperswithcode.com/paper/marked-personas-using-natural-language</link>
      <description><![CDATA[To recognize and mitigate harms from large language models (LLMs), we need to understand the prevalence and nuances of stereotypes in LLM outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/marked-personas-using-natural-language</guid>
    </item>
    <item>
      <title>Large Language Models are not Fair Evaluators</title>
      <link>https://paperswithcode.com/paper/large-language-models-are-not-fair-evaluators</link>
      <description><![CDATA[We uncover a systematic bias in the evaluation paradigm of adopting large language models~(LLMs), e. g., GPT-4, as a referee to score the quality of responses generated by candidate models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-are-not-fair-evaluators</guid>
    </item>
    <item>
      <title>Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/test-time-adaptation-with-clip-reward-for</link>
      <description><![CDATA[Specifically, we adopt CLIP as reward model to provide feedback for VL models during test time in various tasks, including image classification, image-text retrieval, and image captioning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/test-time-adaptation-with-clip-reward-for</guid>
    </item>
    <item>
      <title>HyperConformer: Multi-head HyperMixer for Efficient Speech Recognition</title>
      <link>https://paperswithcode.com/paper/hyperconformer-multi-head-hypermixer-for</link>
      <description><![CDATA[In particular, multi-head HyperConformer achieves comparable or higher recognition performance while being more efficient than Conformer in terms of inference speed, memory, parameter count, and available training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyperconformer-multi-head-hypermixer-for</guid>
    </item>
    <item>
      <title>BigTrans: Augmenting Large Language Models with Multilingual Translation Capability over 100 Languages</title>
      <link>https://paperswithcode.com/paper/bigtrans-augmenting-large-language-models</link>
      <description><![CDATA[Second, we continue training the model with a large-scale parallel dataset that covers 102 natural languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bigtrans-augmenting-large-language-models</guid>
    </item>
    <item>
      <title>DiffRate : Differentiable Compression Rate for Efficient Vision Transformers</title>
      <link>https://paperswithcode.com/paper/diffrate-differentiable-compression-rate-for</link>
      <description><![CDATA[Token compression aims to speed up large-scale vision transformers (e. g. ViTs) by pruning (dropping) or merging tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffrate-differentiable-compression-rate-for</guid>
    </item>
    <item>
      <title>Contextual Object Detection with Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/contextual-object-detection-with-multimodal</link>
      <description><![CDATA[Moreover, we present ContextDET, a unified multimodal model that is capable of end-to-end differentiable modeling of visual-language contexts, so as to locate, identify, and associate visual objects with language inputs for human-AI interaction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contextual-object-detection-with-multimodal</guid>
    </item>
    <item>
      <title>ReSup: Reliable Label Noise Suppression for Facial Expression Recognition</title>
      <link>https://paperswithcode.com/paper/resup-reliable-label-noise-suppression-for</link>
      <description><![CDATA[To further enhance the reliability of our noise decision results, ReSup uses two networks to jointly achieve noise suppression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/resup-reliable-label-noise-suppression-for</guid>
    </item>
    <item>
      <title>MT-SLVR: Multi-Task Self-Supervised Learning for Transformation In(Variant) Representations</title>
      <link>https://paperswithcode.com/paper/mt-slvr-multi-task-self-supervised-learning</link>
      <description><![CDATA[Contrastive self-supervised learning has gained attention for its ability to create high-quality representations from large unlabelled data sets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mt-slvr-multi-task-self-supervised-learning</guid>
    </item>
    <item>
      <title>InstructEdit: Improving Automatic Masks for Diffusion-based Image Editing With User Instructions</title>
      <link>https://paperswithcode.com/paper/instructedit-improving-automatic-masks-for</link>
      <description><![CDATA[In this work, we propose a framework termed InstructEdit that can do fine-grained editing based on user instructions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructedit-improving-automatic-masks-for</guid>
    </item>
    <item>
      <title>Improved Probabilistic Image-Text Representations</title>
      <link>https://paperswithcode.com/paper/improved-probabilistic-image-text</link>
      <description><![CDATA[In addition, two optimization techniques are proposed to enhance PCME++ further; first, the incorporation of pseudo-positives to prevent the loss saturation problem under massive false negatives; second, mixed sample data augmentation for probabilistic matching.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-probabilistic-image-text</guid>
    </item>
    <item>
      <title>Faithfulness Tests for Natural Language Explanations</title>
      <link>https://paperswithcode.com/paper/faithfulness-tests-for-natural-language</link>
      <description><![CDATA[Explanations of neural models aim to reveal a model's decision-making process for its predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/faithfulness-tests-for-natural-language</guid>
    </item>
    <item>
      <title>Out-of-Distributed Semantic Pruning for Robust Semi-Supervised Learning</title>
      <link>https://paperswithcode.com/paper/out-of-distributed-semantic-pruning-for-1</link>
      <description><![CDATA[We argue that an overlooked problem of robust SSL is its corrupted information on semantic level, practically limiting the development of the field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/out-of-distributed-semantic-pruning-for-1</guid>
    </item>
    <item>
      <title>Gen-L-Video: Multi-Text to Long Video Generation via Temporal Co-Denoising</title>
      <link>https://paperswithcode.com/paper/gen-l-video-multi-text-to-long-video</link>
      <description><![CDATA[To address this challenge, we introduce a novel paradigm dubbed as Gen-L-Video, capable of extending off-the-shelf short video diffusion models for generating and editing videos comprising hundreds of frames with diverse semantic segments without introducing additional training, all while preserving content consistency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gen-l-video-multi-text-to-long-video</guid>
    </item>
    <item>
      <title>Multi-Scale Attention for Audio Question Answering</title>
      <link>https://paperswithcode.com/paper/multi-scale-attention-for-audio-question</link>
      <description><![CDATA[Audio question answering (AQA), acting as a widely used proxy task to explore scene understanding, has got more attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-attention-for-audio-question</guid>
    </item>
    <item>
      <title>ChatGPT-powered Conversational Drug Editing Using Retrieval and Domain Feedback</title>
      <link>https://paperswithcode.com/paper/chatgpt-powered-conversational-drug-editing</link>
      <description><![CDATA[This research sheds light on the potential of ChatGPT and conversational LLMs for drug editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatgpt-powered-conversational-drug-editing</guid>
    </item>
    <item>
      <title>3DTeethSeg'22: 3D Teeth Scan Segmentation and Labeling Challenge</title>
      <link>https://paperswithcode.com/paper/3dteethseg-22-3d-teeth-scan-segmentation-and</link>
      <description><![CDATA[To address these challenges, the 3DTeethSeg'22 challenge was organized in conjunction with the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) in 2022, with a call for algorithms tackling teeth localization, segmentation, and labeling from intraoral 3D scans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dteethseg-22-3d-teeth-scan-segmentation-and</guid>
    </item>
    <item>
      <title>Learning Conditional Attributes for Compositional Zero-Shot Learning</title>
      <link>https://paperswithcode.com/paper/learning-conditional-attributes-for-1</link>
      <description><![CDATA[Compositional Zero-Shot Learning (CZSL) aims to train models to recognize novel compositional concepts based on learned concepts such as attribute-object combinations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-conditional-attributes-for-1</guid>
    </item>
    <item>
      <title>CommonAccent: Exploring Large Acoustic Pretrained Models for Accent Classification Based on Common Voice</title>
      <link>https://paperswithcode.com/paper/commonaccent-exploring-large-acoustic</link>
      <description><![CDATA[We introduce a simple-to-follow recipe aligned to the SpeechBrain toolkit for accent classification based on Common Voice 7. 0 (English) and Common Voice 11. 0 (Italian, German, and Spanish).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/commonaccent-exploring-large-acoustic</guid>
    </item>
    <item>
      <title>TD-GEM: Text-Driven Garment Editing Mapper</title>
      <link>https://paperswithcode.com/paper/td-gem-text-driven-garment-editing-mapper</link>
      <description><![CDATA[An optimization-based Contrasive Language-Image Pre-training (CLIP) is then utilized to guide the latent representation of a fashion image in the direction of a target attribute expressed in terms of a text prompt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/td-gem-text-driven-garment-editing-mapper</guid>
    </item>
    <item>
      <title>Counterpart Fairness -- Addressing Systematic between-group Differences in Fairness Evaluation</title>
      <link>https://paperswithcode.com/paper/counterpart-fairness-addressing-systematic</link>
      <description><![CDATA[The confounding factors, which are non-sensitive variables but manifest systematic differences, can significantly affect fairness evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterpart-fairness-addressing-systematic</guid>
    </item>
    <item>
      <title>Multiscale Positive-Unlabeled Detection of AI-Generated Texts</title>
      <link>https://paperswithcode.com/paper/multiscale-positive-unlabeled-detection-of-ai</link>
      <description><![CDATA[In this PU context, we propose the length-sensitive Multiscale PU Loss, where we use a recurrent model in abstraction to estimate positive priors of scale-variant corpuses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiscale-positive-unlabeled-detection-of-ai</guid>
    </item>
    <item>
      <title>A Critical Evaluation of Evaluations for Long-form Question Answering</title>
      <link>https://paperswithcode.com/paper/a-critical-evaluation-of-evaluations-for-long</link>
      <description><![CDATA[We present a careful analysis of experts' evaluation, which focuses on new aspects such as the comprehensiveness of the answer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-critical-evaluation-of-evaluations-for-long</guid>
    </item>
    <item>
      <title>Ask an Expert: Leveraging Language Models to Improve Strategic Reasoning in Goal-Oriented Dialogue Models</title>
      <link>https://paperswithcode.com/paper/ask-an-expert-leveraging-language-models-to</link>
      <description><![CDATA[We propose the "Ask an Expert" framework in which the model is trained with access to an "expert" which it can consult at each turn.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ask-an-expert-leveraging-language-models-to</guid>
    </item>
    <item>
      <title>Check-COVID: Fact-Checking COVID-19 News Claims with Scientific Evidence</title>
      <link>https://paperswithcode.com/paper/check-covid-fact-checking-covid-19-news</link>
      <description><![CDATA[We present a new fact-checking benchmark, Check-COVID, that requires systems to verify claims about COVID-19 from news using evidence from scientific articles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/check-covid-fact-checking-covid-19-news</guid>
    </item>
    <item>
      <title>E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition</title>
      <link>https://paperswithcode.com/paper/e-ner-evidential-deep-learning-for</link>
      <description><![CDATA[Most named entity recognition (NER) systems focus on improving model performance, ignoring the need to quantify model uncertainty, which is critical to the reliability of NER systems in open environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/e-ner-evidential-deep-learning-for</guid>
    </item>
    <item>
      <title>TotalDefMeme: A Multi-Attribute Meme dataset on Total Defence in Singapore</title>
      <link>https://paperswithcode.com/paper/totaldefmeme-a-multi-attribute-meme-dataset</link>
      <description><![CDATA[While several countries have adopted total defence as their defence policy, very few studies have investigated its effectiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/totaldefmeme-a-multi-attribute-meme-dataset</guid>
    </item>
    <item>
      <title>Learning Two-Layer Neural Networks, One (Giant) Step at a Time</title>
      <link>https://paperswithcode.com/paper/learning-two-layer-neural-networks-one-giant</link>
      <description><![CDATA[In contrast, $n = O(d^2)$ is essential for learning multiple directions and specialization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-two-layer-neural-networks-one-giant</guid>
    </item>
    <item>
      <title>Stochastic Bridges as Effective Regularizers for Parameter-Efficient Tuning</title>
      <link>https://paperswithcode.com/paper/stochastic-bridges-as-effective-regularizers</link>
      <description><![CDATA[Since it is non-trivial to directly model the intermediate states and design a running cost function, we propose to use latent stochastic bridges to regularize the intermediate states and use the regularization as the running cost of PETs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stochastic-bridges-as-effective-regularizers</guid>
    </item>
    <item>
      <title>Plug-and-Play Knowledge Injection for Pre-trained Language Models</title>
      <link>https://paperswithcode.com/paper/plug-and-play-knowledge-injection-for-pre</link>
      <description><![CDATA[Experimental results on three knowledge-driven NLP tasks show that existing injection methods are not suitable for the new paradigm, while map-tuning effectively improves the performance of downstream models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plug-and-play-knowledge-injection-for-pre</guid>
    </item>
    <item>
      <title>Rethinking Masked Language Modeling for Chinese Spelling Correction</title>
      <link>https://paperswithcode.com/paper/rethinking-masked-language-modeling-for</link>
      <description><![CDATA[In this paper, we study Chinese Spelling Correction (CSC) as a joint decision made by two separate models: a language model and an error model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-masked-language-modeling-for</guid>
    </item>
    <item>
      <title>Generating EDU Extracts for Plan-Guided Summary Re-Ranking</title>
      <link>https://paperswithcode.com/paper/generating-edu-extracts-for-plan-guided</link>
      <description><![CDATA[Similarly, on 1k samples from CNN / DM, we show that prompting GPT-3 to follow EDU plans outperforms sampling-based methods by 1. 05 ROUGE-2 F1 points.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-edu-extracts-for-plan-guided</guid>
    </item>
    <item>
      <title>OccCasNet: Occlusion-aware Cascade Cost Volume for Light Field Depth Estimation</title>
      <link>https://paperswithcode.com/paper/occcasnet-occlusion-aware-cascade-cost-volume</link>
      <description><![CDATA[To address this issue and achieve a better trade-off between accuracy and efficiency, we propose an occlusion-aware cascade cost volume for LF depth (disparity) estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/occcasnet-occlusion-aware-cascade-cost-volume</guid>
    </item>
    <item>
      <title>Plug-and-Play Document Modules for Pre-trained Models</title>
      <link>https://paperswithcode.com/paper/plug-and-play-document-modules-for-pre</link>
      <description><![CDATA[By inserting document plugins into the backbone PTM for downstream tasks, we can encode a document one time to handle multiple tasks, which is more efficient than conventional encoding-task coupling methods that simultaneously encode documents and input queries using task-specific encoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plug-and-play-document-modules-for-pre</guid>
    </item>
    <item>
      <title>SimpSON: Simplifying Photo Cleanup with Single-Click Distracting Object Segmentation Network</title>
      <link>https://paperswithcode.com/paper/simpson-simplifying-photo-cleanup-with-single-1</link>
      <description><![CDATA[In photo editing, it is common practice to remove visual distractions to improve the overall image quality and highlight the primary subject.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simpson-simplifying-photo-cleanup-with-single-1</guid>
    </item>
    <item>
      <title>Decoupling Pseudo Label Disambiguation and Representation Learning for Generalized Intent Discovery</title>
      <link>https://paperswithcode.com/paper/decoupling-pseudo-label-disambiguation-and</link>
      <description><![CDATA[Previous methods suffer from a coupling of pseudo label disambiguation and representation learning, that is, the reliability of pseudo labels relies on representation learning, and representation learning is restricted by pseudo labels in turn.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decoupling-pseudo-label-disambiguation-and</guid>
    </item>
    <item>
      <title>Using Caterpillar to Nibble Small-Scale Images</title>
      <link>https://paperswithcode.com/paper/using-caterpillar-to-nibble-small-scale</link>
      <description><![CDATA[Recently, MLP-based models have become popular and attained significant performance on medium-scale datasets (e. g., ImageNet-1k).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/using-caterpillar-to-nibble-small-scale</guid>
    </item>
    <item>
      <title>Reward Collapse in Aligning Large Language Models</title>
      <link>https://paperswithcode.com/paper/reward-collapse-in-aligning-large-language</link>
      <description><![CDATA[This insight allows us to derive closed-form expressions for the reward distribution associated with a set of utility functions in an asymptotic regime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reward-collapse-in-aligning-large-language</guid>
    </item>
    <item>
      <title>Incentivizing honest performative predictions with proper scoring rules</title>
      <link>https://paperswithcode.com/paper/incentivizing-honest-performative-predictions</link>
      <description><![CDATA[We show that, for binary predictions, if the influence of the expert's prediction on outcomes is bounded, it is possible to define scoring rules under which optimal reports are arbitrarily close to fixed points.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/incentivizing-honest-performative-predictions</guid>
    </item>
    <item>
      <title>MixDehazeNet : Mix Structure Block For Image Dehazing Network</title>
      <link>https://paperswithcode.com/paper/mixdehazenet-mix-structure-block-for-image</link>
      <description><![CDATA[For example, compared with the previous state-of-the-art methods, MixDehazeNet achieves a significant improvement (42. 62dB PSNR) on the SOTS indoor dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixdehazenet-mix-structure-block-for-image</guid>
    </item>
    <item>
      <title>Bayesian Decision Making to Localize Visual Queries in 2D</title>
      <link>https://paperswithcode.com/paper/bayesian-decision-making-to-localize-visual</link>
      <description><![CDATA[The results are then combined together with the similarity in lower dimensions from the Siamese Head, acting as our measurement, to generate a posterior which is then used to determine the final similarity of the visual crop with the proposed bounding box.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bayesian-decision-making-to-localize-visual</guid>
    </item>
    <item>
      <title>Tab-CoT: Zero-shot Tabular Chain of Thought</title>
      <link>https://paperswithcode.com/paper/tab-cot-zero-shot-tabular-chain-of-thought</link>
      <description><![CDATA[The chain-of-though (CoT) prompting methods were successful in various natural language processing (NLP) tasks thanks to their ability to unveil the underlying complex reasoning processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tab-cot-zero-shot-tabular-chain-of-thought</guid>
    </item>
    <item>
      <title>Decoding the Underlying Meaning of Multimodal Hateful Memes</title>
      <link>https://paperswithcode.com/paper/decoding-the-underlying-meaning-of-multimodal</link>
      <description><![CDATA[Recent studies have proposed models that yielded promising performance for the hateful meme classification task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decoding-the-underlying-meaning-of-multimodal</guid>
    </item>
  </channel>
</rss>
