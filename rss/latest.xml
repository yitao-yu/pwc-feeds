<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 22 Dec 2023 09:12:13 +0000</lastBuildDate>
    <item>
      <title>Anchoring Path for Inductive Relation Prediction in Knowledge Graphs</title>
      <link>https://paperswithcode.com/paper/anchoring-path-for-inductive-relation</link>
      <description><![CDATA[To address this challenge, we propose Anchoring Path Sentence Transformer (APST) by introducing Anchoring Paths (APs) to alleviate the reliance of CPs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anchoring-path-for-inductive-relation</guid>
    </item>
    <item>
      <title>Controllable 3D Face Generation with Conditional Style Code Diffusion</title>
      <link>https://paperswithcode.com/paper/controllable-3d-face-generation-with</link>
      <description><![CDATA[For 3D GAN inversion, we introduce two methods which aim to enhance the representation of style codes and alleviate 3D inconsistencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controllable-3d-face-generation-with</guid>
    </item>
    <item>
      <title>Universal Noise Annotation: Unveiling the Impact of Noisy annotation on Object Detection</title>
      <link>https://paperswithcode.com/paper/universal-noise-annotation-unveiling-the</link>
      <description><![CDATA[For object detection task with noisy labels, it is important to consider not only categorization noise, as in image classification, but also localization noise, missing annotations, and bogus bounding boxes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-noise-annotation-unveiling-the</guid>
    </item>
    <item>
      <title>Argue with Me Tersely: Towards Sentence-Level Counter-Argument Generation</title>
      <link>https://paperswithcode.com/paper/argue-with-me-tersely-towards-sentence-level</link>
      <description><![CDATA[The results show the competitiveness of our proposed framework and evaluator in counter-argument generation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/argue-with-me-tersely-towards-sentence-level</guid>
    </item>
    <item>
      <title>T-Eval: Evaluating the Tool Utilization Capability Step by Step</title>
      <link>https://paperswithcode.com/paper/t-eval-evaluating-the-tool-utilization</link>
      <description><![CDATA[In contrast to previous works that evaluate models holistically, we comprehensively decompose the tool utilization into multiple sub-processes, including instruction following, planning, reasoning, retrieval, understanding, and review.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t-eval-evaluating-the-tool-utilization</guid>
    </item>
    <item>
      <title>Bootstrap Masked Visual Modeling via Hard Patches Mining</title>
      <link>https://paperswithcode.com/paper/bootstrap-masked-visual-modeling-via-hard</link>
      <description><![CDATA[To empower the model as a teacher, we propose Hard Patches Mining (HPM), predicting patch-wise losses and subsequently determining where to mask.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bootstrap-masked-visual-modeling-via-hard</guid>
    </item>
    <item>
      <title>TinySAM: Pushing the Envelope for Efficient Segment Anything Model</title>
      <link>https://paperswithcode.com/paper/tinysam-pushing-the-envelope-for-efficient</link>
      <description><![CDATA[We first propose a full-stage knowledge distillation method with online hard prompt sampling strategy to distill a lightweight student model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tinysam-pushing-the-envelope-for-efficient</guid>
    </item>
    <item>
      <title>Fine-tuning Graph Neural Networks by Preserving Graph Generative Patterns</title>
      <link>https://paperswithcode.com/paper/fine-tuning-graph-neural-networks-by</link>
      <description><![CDATA[In this paper, we identify the fundamental cause of structural divergence as the discrepancy of generative patterns between the pre-training and downstream graphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-graph-neural-networks-by</guid>
    </item>
    <item>
      <title>ChatGPT as a commenter to the news: can LLMs generate human-like opinions?</title>
      <link>https://paperswithcode.com/paper/chatgpt-as-a-commenter-to-the-news-can-llms</link>
      <description><![CDATA[ChatGPT, GPT-3. 5, and other large language models (LLMs) have drawn significant attention since their release, and the abilities of these models have been investigated for a wide variety of tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatgpt-as-a-commenter-to-the-news-can-llms</guid>
    </item>
    <item>
      <title>SPGroup3D: Superpoint Grouping Network for Indoor 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/spgroup3d-superpoint-grouping-network-for</link>
      <description><![CDATA[To this end, we propose a novel superpoint grouping network for indoor anchor-free one-stage 3D object detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spgroup3d-superpoint-grouping-network-for</guid>
    </item>
    <item>
      <title>Revisiting Foreground and Background Separation in Weakly-supervised Temporal Action Localization: A Clustering-based Approach</title>
      <link>https://paperswithcode.com/paper/revisiting-foreground-and-background-1</link>
      <description><![CDATA[It comprises two core components: a snippet clustering component that groups the snippets into multiple latent clusters and a cluster classification component that further classifies the cluster as foreground or background.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-foreground-and-background-1</guid>
    </item>
    <item>
      <title>Weakly Supervised Semantic Segmentation for Driving Scenes</title>
      <link>https://paperswithcode.com/paper/weakly-supervised-semantic-segmentation-for-1</link>
      <description><![CDATA[Notably, the proposed method achieves 51. 8\% mIoU on the Cityscapes test dataset, showcasing its potential as a strong WSSS baseline on driving scene datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/weakly-supervised-semantic-segmentation-for-1</guid>
    </item>
    <item>
      <title>Paint3D: Paint Anything 3D with Lighting-Less Texture Diffusion Models</title>
      <link>https://paperswithcode.com/paper/paint3d-paint-anything-3d-with-lighting-less</link>
      <description><![CDATA[This paper presents Paint3D, a novel coarse-to-fine generative framework that is capable of producing high-resolution, lighting-less, and diverse 2K UV texture maps for untextured 3D meshes conditioned on text or image inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paint3d-paint-anything-3d-with-lighting-less</guid>
    </item>
    <item>
      <title>LingoQA: Video Question Answering for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/lingoqa-video-question-answering-for</link>
      <description><![CDATA[To fill this gap, we introduce LingoQA, a benchmark specifically for autonomous driving Video QA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lingoqa-video-question-answering-for</guid>
    </item>
    <item>
      <title>Entropic Open-set Active Learning</title>
      <link>https://paperswithcode.com/paper/entropic-open-set-active-learning</link>
      <description><![CDATA[Active Learning (AL) aims to enhance the performance of deep models by selecting the most informative samples for annotation from a pool of unlabeled data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/entropic-open-set-active-learning</guid>
    </item>
    <item>
      <title>SE(3)-Equivariant and Noise-Invariant 3D Motion Tracking in Medical Images</title>
      <link>https://paperswithcode.com/paper/se-3-equivariant-and-noise-invariant-3d</link>
      <description><![CDATA[Here we propose EquiTrack, the first method that uses recent steerable SE(3)-equivariant CNNs (E-CNN) for motion tracking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/se-3-equivariant-and-noise-invariant-3d</guid>
    </item>
    <item>
      <title>3D Pose Estimation of Two Interacting Hands from a Monocular Event Camera</title>
      <link>https://paperswithcode.com/paper/3d-pose-estimation-of-two-interacting-hands</link>
      <description><![CDATA[3D hand tracking from a monocular video is a very challenging problem due to hand interactions, occlusions, left-right hand ambiguity, and fast motion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-pose-estimation-of-two-interacting-hands</guid>
    </item>
    <item>
      <title>DriveLM: Driving with Graph Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/drivelm-driving-with-graph-visual-question</link>
      <description><![CDATA[The experiments demonstrate that Graph VQA provides a simple, principled framework for reasoning about a driving scene, and DriveLM-Data provides a challenging benchmark for this task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drivelm-driving-with-graph-visual-question</guid>
    </item>
    <item>
      <title>Towards More Faithful Natural Language Explanation Using Multi-Level Contrastive Learning in VQA</title>
      <link>https://paperswithcode.com/paper/towards-more-faithful-natural-language</link>
      <description><![CDATA[To address the above issues, we propose a novel self-supervised \textbf{M}ulti-level \textbf{C}ontrastive \textbf{L}earning based natural language \textbf{E}xplanation model (MCLE) for VQA with semantic-level, image-level, and instance-level factual and counterfactual samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-more-faithful-natural-language</guid>
    </item>
    <item>
      <title>Leveraging Visual Supervision for Array-based Active Speaker Detection and Localization</title>
      <link>https://paperswithcode.com/paper/leveraging-visual-supervision-for-array-based</link>
      <description><![CDATA[The multichannel audio ``student'' network is trained to generate the same results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-visual-supervision-for-array-based</guid>
    </item>
    <item>
      <title>HD-Painter: High-Resolution and Prompt-Faithful Text-Guided Image Inpainting with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/hd-painter-high-resolution-and-prompt</link>
      <description><![CDATA[Recent progress in text-guided image inpainting, based on the unprecedented success of text-to-image diffusion models, has led to exceptionally realistic and visually plausible results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hd-painter-high-resolution-and-prompt</guid>
    </item>
    <item>
      <title>Risk-Sensitive Stochastic Optimal Control as Rao-Blackwellized Markovian Score Climbing</title>
      <link>https://paperswithcode.com/paper/risk-sensitive-stochastic-optimal-control-as</link>
      <description><![CDATA[Stochastic optimal control of dynamical systems is a crucial challenge in sequential decision-making.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/risk-sensitive-stochastic-optimal-control-as</guid>
    </item>
    <item>
      <title>MFABA: A More Faithful and Accelerated Boundary-based Attribution Method for Deep Neural Networks</title>
      <link>https://paperswithcode.com/paper/mfaba-a-more-faithful-and-accelerated</link>
      <description><![CDATA[To better understand the output of deep neural networks (DNN), attribution based methods have been an important approach for model interpretability, which assign a score for each input dimension to indicate its importance towards the model outcome.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mfaba-a-more-faithful-and-accelerated</guid>
    </item>
    <item>
      <title>DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis</title>
      <link>https://paperswithcode.com/paper/diffportrait3d-controllable-diffusion-for</link>
      <description><![CDATA[The rendering view is then manipulated with a novel conditional control module that interprets the camera pose by watching a condition image of a crossed subject from the same view.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffportrait3d-controllable-diffusion-for</guid>
    </item>
    <item>
      <title>Spectral Prompt Tuning:Unveiling Unseen Classes for Zero-Shot Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/spectral-prompt-tuning-unveiling-unseen</link>
      <description><![CDATA[Recently, CLIP has found practical utility in the domain of pixel-level zero-shot segmentation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spectral-prompt-tuning-unveiling-unseen</guid>
    </item>
    <item>
      <title>DVIS++: Improved Decoupled Framework for Universal Video Segmentation</title>
      <link>https://paperswithcode.com/paper/dvis-improved-decoupled-framework-for</link>
      <description><![CDATA[We present the \textbf{D}ecoupled \textbf{VI}deo \textbf{S}egmentation (DVIS) framework, a novel approach for the challenging task of universal video segmentation, including video instance segmentation (VIS), video semantic segmentation (VSS), and video panoptic segmentation (VPS).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dvis-improved-decoupled-framework-for</guid>
    </item>
    <item>
      <title>TagCLIP: A Local-to-Global Framework to Enhance Open-Vocabulary Multi-Label Classification of CLIP Without Training</title>
      <link>https://paperswithcode.com/paper/tagclip-a-local-to-global-framework-to</link>
      <description><![CDATA[As a result, we dissect the preservation of patch-wise spatial information in CLIP and proposed a local-to-global framework to obtain image tags.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tagclip-a-local-to-global-framework-to</guid>
    </item>
    <item>
      <title>Fed-QSSL: A Framework for Personalized Federated Learning under Bitwidth and Data Heterogeneity</title>
      <link>https://paperswithcode.com/paper/fed-qssl-a-framework-for-personalized</link>
      <description><![CDATA[Motivated by high resource costs of centralized machine learning schemes as well as data privacy concerns, federated learning (FL) emerged as an efficient alternative that relies on aggregating locally trained models rather than collecting clients' potentially private data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fed-qssl-a-framework-for-personalized</guid>
    </item>
    <item>
      <title>Reducing Shape-Radiance Ambiguity in Radiance Fields with a Closed-Form Color Estimation Method</title>
      <link>https://paperswithcode.com/paper/reducing-shape-radiance-ambiguity-in-radiance-1</link>
      <description><![CDATA[The key is a rendering method that is only based on the density field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reducing-shape-radiance-ambiguity-in-radiance-1</guid>
    </item>
    <item>
      <title>Machine Mindset: An MBTI Exploration of Large Language Models</title>
      <link>https://paperswithcode.com/paper/machine-mindset-an-mbti-exploration-of-large</link>
      <description><![CDATA[We present a novel approach for integrating Myers-Briggs Type Indicator (MBTI) personality traits into large language models (LLMs), addressing the challenges of personality consistency in personalized AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/machine-mindset-an-mbti-exploration-of-large</guid>
    </item>
    <item>
      <title>AdvST: Revisiting Data Augmentations for Single Domain Generalization</title>
      <link>https://paperswithcode.com/paper/advst-revisiting-data-augmentations-for</link>
      <description><![CDATA[Then, we propose Adversarial learning with Semantics Transformations (AdvST) that augments the source domain data with semantics transformations and learns a robust model with the augmented data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advst-revisiting-data-augmentations-for</guid>
    </item>
    <item>
      <title>Unlocking Deep Learning: A BP-Free Approach for Parallel Block-Wise Training of Neural Networks</title>
      <link>https://paperswithcode.com/paper/unlocking-deep-learning-a-bp-free-approach</link>
      <description><![CDATA[This includes decisions on how to decouple network blocks and which auxiliary networks to use for each block.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlocking-deep-learning-a-bp-free-approach</guid>
    </item>
    <item>
      <title>MinePlanner: A Benchmark for Long-Horizon Planning in Large Minecraft Worlds</title>
      <link>https://paperswithcode.com/paper/mineplanner-a-benchmark-for-long-horizon</link>
      <description><![CDATA[We propose a new benchmark for planning tasks based on the Minecraft game.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mineplanner-a-benchmark-for-long-horizon</guid>
    </item>
    <item>
      <title>Language Resources for Dutch Large Language Modelling</title>
      <link>https://paperswithcode.com/paper/language-resources-for-dutch-large-language</link>
      <description><![CDATA[Despite the rapid expansion of types of large language models, there remains a notable gap in models specifically designed for the Dutch language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-resources-for-dutch-large-language</guid>
    </item>
    <item>
      <title>ALMANACS: A Simulatability Benchmark for Language Model Explainability</title>
      <link>https://paperswithcode.com/paper/almanacs-a-simulatability-benchmark-for</link>
      <description><![CDATA[The ALMANACS scenarios span twelve safety-relevant topics such as ethical reasoning and advanced AI behaviors; they have idiosyncratic premises to invoke model-specific behavior; and they have a train-test distributional shift to encourage faithful explanations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/almanacs-a-simulatability-benchmark-for</guid>
    </item>
    <item>
      <title>SEER-ZSL: Semantic Encoder-Enhanced Representations for Generalized Zero-Shot Learning</title>
      <link>https://paperswithcode.com/paper/seer-zsl-semantic-encoder-enhanced</link>
      <description><![CDATA[This approach generates discriminative classes, effectively classifying both seen and unseen classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seer-zsl-semantic-encoder-enhanced</guid>
    </item>
    <item>
      <title>Near-Optimal Resilient Aggregation Rules for Distributed Learning Using 1-Center and 1-Mean Clustering with Outliers</title>
      <link>https://paperswithcode.com/paper/near-optimal-resilient-aggregation-rules-for</link>
      <description><![CDATA[Our analysis show that constant approximations to the 1-center and 1-mean clustering problems with outliers provide near-optimal resilient aggregators for metric-based criteria, which have been proven to be crucial in the homogeneous and heterogeneous cases respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/near-optimal-resilient-aggregation-rules-for</guid>
    </item>
    <item>
      <title>LRS: Enhancing Adversarial Transferability through Lipschitz Regularized Surrogate</title>
      <link>https://paperswithcode.com/paper/lrs-enhancing-adversarial-transferability</link>
      <description><![CDATA[The transferability of adversarial examples is of central importance to transfer-based black-box adversarial attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lrs-enhancing-adversarial-transferability</guid>
    </item>
    <item>
      <title>Energy-efficient Spiking Neural Network Equalization for IM/DD Systems with Optimized Neural Encoding</title>
      <link>https://paperswithcode.com/paper/energy-efficient-spiking-neural-network</link>
      <description><![CDATA[We propose an energy-efficient equalizer for IM/DD systems based on spiking neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/energy-efficient-spiking-neural-network</guid>
    </item>
    <item>
      <title>DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines</title>
      <link>https://paperswithcode.com/paper/dspy-assertions-computational-constraints-for</link>
      <description><![CDATA[Our reference implementation of LM Assertions is integrated into DSPy at https://github. com/stanfordnlp/dspy]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dspy-assertions-computational-constraints-for</guid>
    </item>
    <item>
      <title>A Closer Look at the Few-Shot Adaptation of Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/a-closer-look-at-the-few-shot-adaptation-of</link>
      <description><![CDATA[Efficient transfer learning (ETL) is receiving increasing attention to adapt large pre-trained language-vision models on downstream tasks with a few labeled samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-closer-look-at-the-few-shot-adaptation-of</guid>
    </item>
    <item>
      <title>Comparing Machine Learning Algorithms by Union-Free Generic Depth</title>
      <link>https://paperswithcode.com/paper/comparing-machine-learning-algorithms-by</link>
      <description><![CDATA[We propose a framework for descriptively analyzing sets of partial orders based on the concept of depth functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comparing-machine-learning-algorithms-by</guid>
    </item>
    <item>
      <title>Diffusion Models With Learned Adaptive Noise</title>
      <link>https://paperswithcode.com/paper/diffusion-models-with-learned-adaptive-noise</link>
      <description><![CDATA[Diffusion models have gained traction as powerful algorithms for synthesizing high-quality images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-with-learned-adaptive-noise</guid>
    </item>
    <item>
      <title>CodeLL: A Lifelong Learning Dataset to Support the Co-Evolution of Data and Language Models of Code</title>
      <link>https://paperswithcode.com/paper/codell-a-lifelong-learning-dataset-to-support</link>
      <description><![CDATA[Motivated by recent work on lifelong learning applications for language models (LMs) of code, we introduce CodeLL, a lifelong learning dataset focused on code changes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codell-a-lifelong-learning-dataset-to-support</guid>
    </item>
    <item>
      <title>Partially factorized variational inference for high-dimensional mixed models</title>
      <link>https://paperswithcode.com/paper/partially-factorized-variational-inference</link>
      <description><![CDATA[We also provide generic results, which are of independent interest, relating the accuracy of variational inference to the convergence rate of the corresponding coordinate ascent variational inference (CAVI) algorithm for Gaussian targets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/partially-factorized-variational-inference</guid>
    </item>
    <item>
      <title>Retrieval-augmented Multilingual Knowledge Editing</title>
      <link>https://paperswithcode.com/paper/retrieval-augmented-multilingual-knowledge</link>
      <description><![CDATA[Knowledge represented in Large Language Models (LLMs) is quite often incorrect and can also become obsolete over time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retrieval-augmented-multilingual-knowledge</guid>
    </item>
    <item>
      <title>Revisiting Deep Generalized Canonical Correlation Analysis</title>
      <link>https://paperswithcode.com/paper/revisiting-deep-generalized-canonical</link>
      <description><![CDATA[Others overload the problem by also seeking to reveal what is not common among the views -- i. e., the private components that are needed to fully reconstruct each view.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-deep-generalized-canonical</guid>
    </item>
    <item>
      <title>FiFAR: A Fraud Detection Dataset for Learning to Defer</title>
      <link>https://paperswithcode.com/paper/fifar-a-fraud-detection-dataset-for-learning</link>
      <description><![CDATA[Financial fraud detection is a high-stakes setting where algorithms and human experts often work in tandem; however, there are no publicly available datasets for L2D concerning this important application of human-AI teaming.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fifar-a-fraud-detection-dataset-for-learning</guid>
    </item>
    <item>
      <title>Splatter Image: Ultra-Fast Single-View 3D Reconstruction</title>
      <link>https://paperswithcode.com/paper/splatter-image-ultra-fast-single-view-3d</link>
      <description><![CDATA[We introduce the Splatter Image, an ultra-fast approach for monocular 3D object reconstruction which operates at 38 FPS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/splatter-image-ultra-fast-single-view-3d</guid>
    </item>
    <item>
      <title>Federated Learning with Extremely Noisy Clients via Negative Distillation</title>
      <link>https://paperswithcode.com/paper/federated-learning-with-extremely-noisy</link>
      <description><![CDATA[The model trained on noisy labels serves as a `bad teacher' in knowledge distillation, aiming to decrease the risk of providing incorrect information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/federated-learning-with-extremely-noisy</guid>
    </item>
  </channel>
</rss>
