<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 13 Dec 2024 09:17:34 +0000</lastBuildDate>
    <item>
      <title>RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios</title>
      <link>https://paperswithcode.com/paper/rulearena-a-benchmark-for-rule-guided</link>
      <description><![CDATA[This paper introduces RuleArena, a novel and challenging benchmark designed to evaluate the ability of large language models (LLMs) to follow complex, real-world rules in reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rulearena-a-benchmark-for-rule-guided</guid>
    </item>
    <item>
      <title>OLA-VLM: Elevating Visual Perception in Multimodal LLMs with Auxiliary Embedding Distillation</title>
      <link>https://paperswithcode.com/paper/ola-vlm-elevating-visual-perception-in</link>
      <description><![CDATA[The standard practice for developing contemporary MLLMs is to feed features from vision encoder(s) into the LLM and train with natural language supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ola-vlm-elevating-visual-perception-in</guid>
    </item>
    <item>
      <title>Exemplar Masking for Multimodal Incremental Learning</title>
      <link>https://paperswithcode.com/paper/exemplar-masking-for-multimodal-incremental</link>
      <description><![CDATA[Specifically, the non-important tokens are masked based on the attention weights and the correlation across different modalities, significantly reducing the storage size of an exemplar and consequently saving more exemplars under the same memory buffer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exemplar-masking-for-multimodal-incremental</guid>
    </item>
    <item>
      <title>Multimodal Industrial Anomaly Detection by Crossmodal Reverse Distillation</title>
      <link>https://paperswithcode.com/paper/multimodal-industrial-anomaly-detection-by-1</link>
      <description><![CDATA[Anomalies in one modality may not be effectively captured in the fused teacher features, leading to detection failures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-industrial-anomaly-detection-by-1</guid>
    </item>
    <item>
      <title>A physics-informed transformer neural operator for learning generalized solutions of initial boundary value problems</title>
      <link>https://paperswithcode.com/paper/a-physics-informed-transformer-neural</link>
      <description><![CDATA[A major drawback of existing neural approaches is the requirement to retrain with new initial/boundary conditions, and the necessity for a large amount of simulation data for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-physics-informed-transformer-neural</guid>
    </item>
    <item>
      <title>Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders</title>
      <link>https://paperswithcode.com/paper/gaze-lle-gaze-target-estimation-via-large</link>
      <description><![CDATA[We address the problem of gaze target estimation, which aims to predict where a person is looking in a scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaze-lle-gaze-target-estimation-via-large</guid>
    </item>
    <item>
      <title>Auto-Regressive Moving Diffusion Models for Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/auto-regressive-moving-diffusion-models-for</link>
      <description><![CDATA[This design aligns the diffusion model's sampling procedure with the forecasting objective, resulting in an unconditional, continuous sequential diffusion TSF model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/auto-regressive-moving-diffusion-models-for</guid>
    </item>
    <item>
      <title>Reversing the Damage: A QP-Aware Transformer-Diffusion Approach for 8K Video Restoration under Codec Compression</title>
      <link>https://paperswithcode.com/paper/reversing-the-damage-a-qp-aware-transformer</link>
      <description><![CDATA[In this paper, we introduce DiQP; a novel Transformer-Diffusion model for restoring 8K video quality degraded by codec compression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reversing-the-damage-a-qp-aware-transformer</guid>
    </item>
    <item>
      <title>Multimodal Music Generation with Explicit Bridges and Retrieval Augmentation</title>
      <link>https://paperswithcode.com/paper/multimodal-music-generation-with-explicit</link>
      <description><![CDATA[Multimodal music generation aims to produce music from diverse input modalities, including text, videos, and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-music-generation-with-explicit</guid>
    </item>
    <item>
      <title>Single-View Graph Contrastive Learning with Soft Neighborhood Awareness</title>
      <link>https://paperswithcode.com/paper/single-view-graph-contrastive-learning-with</link>
      <description><![CDATA[Most graph contrastive learning (GCL) methods heavily rely on cross-view contrast, thus facing several concomitant challenges, such as the complexity of designing effective augmentations, the potential for information loss between views, and increased computational costs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/single-view-graph-contrastive-learning-with</guid>
    </item>
    <item>
      <title>DrivingRecon: Large 4D Gaussian Reconstruction Model For Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/drivingrecon-large-4d-gaussian-reconstruction</link>
      <description><![CDATA[To this end, we introduce the Large 4D Gaussian Reconstruction Model (DrivingRecon), a generalizable driving scene reconstruction model, which directly predicts 4D Gaussian from surround view videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drivingrecon-large-4d-gaussian-reconstruction</guid>
    </item>
    <item>
      <title>Doe-1: Closed-Loop Autonomous Driving with Large World Model</title>
      <link>https://paperswithcode.com/paper/doe-1-closed-loop-autonomous-driving-with</link>
      <description><![CDATA[In this paper, we explore a closed-loop framework for autonomous driving and propose a large Driving wOrld modEl (Doe-1) for unified perception, prediction, and planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/doe-1-closed-loop-autonomous-driving-with</guid>
    </item>
    <item>
      <title>Neptune: The Long Orbit to Benchmarking Long Video Understanding</title>
      <link>https://paperswithcode.com/paper/neptune-the-long-orbit-to-benchmarking-long</link>
      <description><![CDATA[This paper describes a semi-automatic pipeline to generate challenging question-answer-decoy sets for understanding long videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neptune-the-long-orbit-to-benchmarking-long</guid>
    </item>
    <item>
      <title>Temporal Action Localization with Cross Layer Task Decoupling and Refinement</title>
      <link>https://paperswithcode.com/paper/temporal-action-localization-with-cross-layer</link>
      <description><![CDATA[Temporal action localization (TAL) involves dual tasks to classify and localize actions within untrimmed videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-action-localization-with-cross-layer</guid>
    </item>
    <item>
      <title>Owl-1: Omni World Model for Consistent Long Video Generation</title>
      <link>https://paperswithcode.com/paper/owl-1-omni-world-model-for-consistent-long</link>
      <description><![CDATA[As videos are observations of the underlying evolving world, we propose to model the long-term developments in a latent space and use VGMs to film them into videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/owl-1-omni-world-model-for-consistent-long</guid>
    </item>
    <item>
      <title>Motif Guided Graph Transformer with Combinatorial Skeleton Prototype Learning for Skeleton-Based Person Re-Identification</title>
      <link>https://paperswithcode.com/paper/motif-guided-graph-transformer-with</link>
      <description><![CDATA[This paper presents a generic Motif guided graph transformer with Combinatorial skeleton prototype learning (MoCos) that exploits structure-specific and gait-related body relations as well as combinatorial features of skeleton graphs to learn effective skeleton representations for person re-ID.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motif-guided-graph-transformer-with</guid>
    </item>
    <item>
      <title>Diffusion Predictive Control with Constraints</title>
      <link>https://paperswithcode.com/paper/diffusion-predictive-control-with-constraints</link>
      <description><![CDATA[Diffusion models have recently gained popularity for policy learning in robotics due to their ability to capture high-dimensional and multimodal distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-predictive-control-with-constraints</guid>
    </item>
    <item>
      <title>Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion</title>
      <link>https://paperswithcode.com/paper/filter-then-generate-large-language-models</link>
      <description><![CDATA[Fundamentally, applying LLMs on KGC introduces several critical challenges, including a vast set of entity candidates, hallucination issue of LLMs, and under-exploitation of the graph structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/filter-then-generate-large-language-models</guid>
    </item>
    <item>
      <title>USDRL: Unified Skeleton-Based Dense Representation Learning with Multi-Grained Feature Decorrelation</title>
      <link>https://paperswithcode.com/paper/usdrl-unified-skeleton-based-dense</link>
      <description><![CDATA[Additionally, we design a Dense Spatio-Temporal Encoder (DSTE) to capture fine-grained action representations effectively, thereby enhancing the performance of dense prediction tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/usdrl-unified-skeleton-based-dense</guid>
    </item>
    <item>
      <title>A Geometry-Aware Message Passing Neural Network for Modeling Aerodynamics over Airfoils</title>
      <link>https://paperswithcode.com/paper/a-geometry-aware-message-passing-neural</link>
      <description><![CDATA[We subsequently propagate this representation to all collocation points through message passing on a directed, bipartite graph.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-geometry-aware-message-passing-neural</guid>
    </item>
    <item>
      <title>UFO: Enhancing Diffusion-Based Video Generation with a Uniform Frame Organizer</title>
      <link>https://paperswithcode.com/paper/ufo-enhancing-diffusion-based-video</link>
      <description><![CDATA[Recently, diffusion-based video generation models have achieved significant success.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ufo-enhancing-diffusion-based-video</guid>
    </item>
    <item>
      <title>DisPose: Disentangling Pose Guidance for Controllable Human Image Animation</title>
      <link>https://paperswithcode.com/paper/dispose-disentangling-pose-guidance-for</link>
      <description><![CDATA[Specifically, we generate a dense motion field from a sparse motion field and the reference image, which provides region-level dense guidance while maintaining the generalization of the sparse pose control.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dispose-disentangling-pose-guidance-for</guid>
    </item>
    <item>
      <title>Video Seal: Open and Efficient Video Watermarking</title>
      <link>https://paperswithcode.com/paper/video-seal-open-and-efficient-video</link>
      <description><![CDATA[To reduce these gaps, this paper introduces Video Seal, a comprehensive framework for neural video watermarking and a competitive open-sourced model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-seal-open-and-efficient-video</guid>
    </item>
    <item>
      <title>Video Repurposing from User Generated Content: A Large-scale Dataset and Benchmark</title>
      <link>https://paperswithcode.com/paper/video-repurposing-from-user-generated-content</link>
      <description><![CDATA[The demand for producing short-form videos for sharing on social media platforms has experienced significant growth in recent times.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-repurposing-from-user-generated-content</guid>
    </item>
    <item>
      <title>V2PE: Improving Multimodal Long-Context Capability of Vision-Language Models with Variable Visual Position Encoding</title>
      <link>https://paperswithcode.com/paper/v2pe-improving-multimodal-long-context</link>
      <description><![CDATA[In our work, we first conduct an empirical analysis of the long-context capabilities of VLMs using our augmented long-context multimodal datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/v2pe-improving-multimodal-long-context</guid>
    </item>
    <item>
      <title>A Flexible Plug-and-Play Module for Generating Variable-Length</title>
      <link>https://paperswithcode.com/paper/a-flexible-plug-and-play-module-for</link>
      <description><![CDATA[The NHL framework introduces a novel mechanism to simultaneously generate hash codes of varying lengths in a nested manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-flexible-plug-and-play-module-for</guid>
    </item>
    <item>
      <title>Arbitrary-steps Image Super-resolution via Diffusion Inversion</title>
      <link>https://paperswithcode.com/paper/arbitrary-steps-image-super-resolution-via</link>
      <description><![CDATA[This study presents a new image super-resolution (SR) technique based on diffusion inversion, aiming at harnessing the rich image priors encapsulated in large pre-trained diffusion models to improve SR performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/arbitrary-steps-image-super-resolution-via</guid>
    </item>
    <item>
      <title>MultiEYE: Dataset and Benchmark for OCT-Enhanced Retinal Disease Recognition from Fundus Images</title>
      <link>https://paperswithcode.com/paper/multieye-dataset-and-benchmark-for-oct</link>
      <description><![CDATA[Existing multi-modal learning methods on fundus and OCT images mostly require both modalities to be available and strictly paired for training and testing, which appears less practical in clinical scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multieye-dataset-and-benchmark-for-oct</guid>
    </item>
    <item>
      <title>Dynamic-VLM: Simple Dynamic Visual Token Compression for VideoLLM</title>
      <link>https://paperswithcode.com/paper/dynamic-vlm-simple-dynamic-visual-token</link>
      <description><![CDATA[The application of Large Vision-Language Models (LVLMs) for analyzing images and videos is an exciting and rapidly evolving field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-vlm-simple-dynamic-visual-token</guid>
    </item>
    <item>
      <title>InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions</title>
      <link>https://paperswithcode.com/paper/internlm-xcomposer2-5-omnilive-a</link>
      <description><![CDATA[Recent advancements in multimodal large language models (MLLMs) have made significant strides in open-world understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internlm-xcomposer2-5-omnilive-a</guid>
    </item>
    <item>
      <title>Advancing Attribution-Based Neural Network Explainability through Relative Absolute Magnitude Layer-Wise Relevance Propagation and Multi-Component Evaluation</title>
      <link>https://paperswithcode.com/paper/advancing-attribution-based-neural-network</link>
      <description><![CDATA[We utilize this new metric to evaluate the performance of various attribution-based methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-attribution-based-neural-network</guid>
    </item>
    <item>
      <title>Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine</title>
      <link>https://paperswithcode.com/paper/towards-a-multimodal-large-language-model</link>
      <description><![CDATA[In this paper, we introduce a novel end-to-end multimodal large language model for the biomedical domain, named MedPLIB, which possesses pixel-level understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-a-multimodal-large-language-model</guid>
    </item>
    <item>
      <title>Dynamic Prompt Allocation and Tuning for Continual Test-Time Adaptation</title>
      <link>https://paperswithcode.com/paper/dynamic-prompt-allocation-and-tuning-for</link>
      <description><![CDATA[For known domains, the corresponding domain-specific prompt is directly selected, while for previously unseen domains, a new prompt is allocated.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-prompt-allocation-and-tuning-for</guid>
    </item>
    <item>
      <title>Uplift modeling with continuous treatments: A predict-then-optimize approach</title>
      <link>https://paperswithcode.com/paper/uplift-modeling-with-continuous-treatments-a</link>
      <description><![CDATA[One common approach involves two steps: first, an inference step that estimates conditional average treatment effects (CATEs), and second, an optimization step that ranks entities based on their CATE values and assigns treatment to the top k within a given budget.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uplift-modeling-with-continuous-treatments-a</guid>
    </item>
    <item>
      <title>Hidden Biases of End-to-End Driving Datasets</title>
      <link>https://paperswithcode.com/paper/hidden-biases-of-end-to-end-driving-datasets</link>
      <description><![CDATA[End-to-end driving systems have made rapid progress, but have so far not been applied to the challenging new CARLA Leaderboard 2. 0.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hidden-biases-of-end-to-end-driving-datasets</guid>
    </item>
    <item>
      <title>MOS: Model Surgery for Pre-Trained Model-Based Class-Incremental Learning</title>
      <link>https://paperswithcode.com/paper/mos-model-surgery-for-pre-trained-model-based</link>
      <description><![CDATA[Class-Incremental Learning (CIL) requires models to continually acquire knowledge of new classes without forgetting old ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mos-model-surgery-for-pre-trained-model-based</guid>
    </item>
    <item>
      <title>Elevating Flow-Guided Video Inpainting with Reference Generation</title>
      <link>https://paperswithcode.com/paper/elevating-flow-guided-video-inpainting-with</link>
      <description><![CDATA[Powered by a strong generative model, our method not only significantly enhances frame-level quality for object removal but also synthesizes new content in the missing areas based on user-provided text prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elevating-flow-guided-video-inpainting-with</guid>
    </item>
    <item>
      <title>OFTSR: One-Step Flow for Image Super-Resolution with Tunable Fidelity-Realism Trade-offs</title>
      <link>https://paperswithcode.com/paper/oftsr-one-step-flow-for-image-super</link>
      <description><![CDATA[Specifically, we force the predictions from our one-step student model for same input to lie on the same sampling ODE trajectory of the teacher model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oftsr-one-step-flow-for-image-super</guid>
    </item>
    <item>
      <title>What Makes Cryptic Crosswords Challenging for LLMs?</title>
      <link>https://paperswithcode.com/paper/what-makes-cryptic-crosswords-challenging-for</link>
      <description><![CDATA[Cryptic crosswords are puzzles that rely on general knowledge and the solver's ability to manipulate language on different levels, dealing with various types of wordplay.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-makes-cryptic-crosswords-challenging-for</guid>
    </item>
    <item>
      <title>FuzzDistill: Intelligent Fuzzing Target Selection using Compile-Time Analysis and Machine Learning</title>
      <link>https://paperswithcode.com/paper/fuzzdistill-intelligent-fuzzing-target</link>
      <description><![CDATA[Fuzz testing is a fundamental technique employed to identify vulnerabilities within software systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fuzzdistill-intelligent-fuzzing-target</guid>
    </item>
    <item>
      <title>Emotional Vietnamese Speech-Based Depression Diagnosis Using Dynamic Attention Mechanism</title>
      <link>https://paperswithcode.com/paper/emotional-vietnamese-speech-based-depression</link>
      <description><![CDATA[Major depressive disorder is a prevalent and serious mental health condition that negatively impacts your emotions, thoughts, actions, and overall perception of the world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emotional-vietnamese-speech-based-depression</guid>
    </item>
    <item>
      <title>Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel</title>
      <link>https://paperswithcode.com/paper/bootstrapping-language-guided-navigation</link>
      <description><![CDATA[In this paper, we introduce a Self-Refining Data Flywheel (SRDF) that generates high-quality and large-scale navigational instruction-trajectory pairs by iteratively refining the data pool through the collaboration between two models, the instruction generator and the navigator, without any human-in-the-loop annotation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bootstrapping-language-guided-navigation</guid>
    </item>
    <item>
      <title>SAFIRE: Segment Any Forged Image Region</title>
      <link>https://paperswithcode.com/paper/safire-segment-any-forged-image-region</link>
      <description><![CDATA[Each point on an image is used to segment the source region containing itself.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safire-segment-any-forged-image-region</guid>
    </item>
    <item>
      <title>Magneto: Combining Small and Large Language Models for Schema Matching</title>
      <link>https://paperswithcode.com/paper/magneto-combining-small-and-large-language</link>
      <description><![CDATA[Recent advances in language models opened new opportunities to address complex schema matching tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magneto-combining-small-and-large-language</guid>
    </item>
    <item>
      <title>LAION-SG: An Enhanced Large-Scale Dataset for Training Complex Image-Text Models with Structural Annotations</title>
      <link>https://paperswithcode.com/paper/laion-sg-an-enhanced-large-scale-dataset-for</link>
      <description><![CDATA[However, existing T2I models show decayed performance in compositional image generation involving multiple objects and intricate relationships.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/laion-sg-an-enhanced-large-scale-dataset-for</guid>
    </item>
    <item>
      <title>Learning Flow Fields in Attention for Controllable Person Image Generation</title>
      <link>https://paperswithcode.com/paper/learning-flow-fields-in-attention-for</link>
      <description><![CDATA[Additionally, we show that our loss is model-agnostic and can be used to improve the performance of other diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-flow-fields-in-attention-for</guid>
    </item>
    <item>
      <title>Learn How to Query from Unlabeled Data Streams in Federated Learning</title>
      <link>https://paperswithcode.com/paper/learn-how-to-query-from-unlabeled-data</link>
      <description><![CDATA[Federated learning (FL) enables collaborative learning among decentralized clients while safeguarding the privacy of their local data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learn-how-to-query-from-unlabeled-data</guid>
    </item>
    <item>
      <title>REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability</title>
      <link>https://paperswithcode.com/paper/repeat-improving-uncertainty-estimation-in</link>
      <description><![CDATA[REPEAT leverages the stochasticity of current R-XAI methods to produce multiple estimates of importance, thus considering each pixel in an image as a Bernoulli random variable that is either important or unimportant.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repeat-improving-uncertainty-estimation-in</guid>
    </item>
    <item>
      <title>Benchmarking Large Vision-Language Models via Directed Scene Graph for Comprehensive Image Captioning</title>
      <link>https://paperswithcode.com/paper/benchmarking-large-vision-language-models-via</link>
      <description><![CDATA[Generating detailed captions comprehending text-rich visual content in images has received growing attention for Large Vision-Language Models (LVLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-large-vision-language-models-via</guid>
    </item>
    <item>
      <title>Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures</title>
      <link>https://paperswithcode.com/paper/hierarchical-classification-for-automated</link>
      <description><![CDATA[Automated benthic image annotation is crucial to efficiently monitor and protect coral reefs against climate change.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-classification-for-automated</guid>
    </item>
  </channel>
</rss>
