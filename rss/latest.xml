<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 31 Mar 2025 09:18:56 +0000</lastBuildDate>
    <item>
      <title>ZS-VCOS: Zero-Shot Outperforms Supervised Video Camouflaged Object Segmentation with Zero-Shot Method</title>
      <link>https://paperswithcode.com/paper/zs-vcos-zero-shot-outperforms-supervised</link>
      <description><![CDATA[Our method integrates optical flow, a vision-language model, and SAM 2 into a sequential pipeline, where the output of one component provides cues for the next.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zs-vcos-zero-shot-outperforms-supervised</guid>
    </item>
    <item>
      <title>Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers</title>
      <link>https://paperswithcode.com/paper/exploring-the-effectiveness-of-multi-stage</link>
      <description><![CDATA[State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-effectiveness-of-multi-stage</guid>
    </item>
    <item>
      <title>EgoToM: Benchmarking Theory of Mind Reasoning from Egocentric Videos</title>
      <link>https://paperswithcode.com/paper/egotom-benchmarking-theory-of-mind-reasoning</link>
      <description><![CDATA[We introduce EgoToM, a new video question-answering benchmark that extends Theory-of-Mind (ToM) evaluation to egocentric domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/egotom-benchmarking-theory-of-mind-reasoning</guid>
    </item>
    <item>
      <title>Landscape of Thoughts: Visualizing the Reasoning Process of Large Language Models</title>
      <link>https://paperswithcode.com/paper/landscape-of-thoughts-visualizing-the</link>
      <description><![CDATA[We showcase this advantage by adapting our tool to a lightweight verifier that evaluates the correctness of reasoning paths.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/landscape-of-thoughts-visualizing-the</guid>
    </item>
    <item>
      <title>Why Stop at One Error? Benchmarking LLMs as Data Science Code Debuggers for Multi-Hop and Multi-Bug Errors</title>
      <link>https://paperswithcode.com/paper/why-stop-at-one-error-benchmarking-llms-as</link>
      <description><![CDATA[LLMs are transforming software development, yet current code generation and code repair benchmarks mainly assess syntactic and functional correctness in simple, single-error cases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/why-stop-at-one-error-benchmarking-llms-as</guid>
    </item>
    <item>
      <title>Fuzzy Cluster-Aware Contrastive Clustering for Time Series</title>
      <link>https://paperswithcode.com/paper/fuzzy-cluster-aware-contrastive-clustering</link>
      <description><![CDATA[To address these issues, we propose a fuzzy cluster-aware contrastive clustering framework (FCACC) that jointly optimizes representation learning and clustering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fuzzy-cluster-aware-contrastive-clustering</guid>
    </item>
    <item>
      <title>Machine Learning Models for Soil Parameter Prediction Based on Satellite, Weather, Clay and Yield Data</title>
      <link>https://paperswithcode.com/paper/machine-learning-models-for-soil-parameter</link>
      <description><![CDATA[Efficient nutrient management and precise fertilization are essential for advancing modern agriculture, particularly in regions striving to optimize crop yields sustainably.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/machine-learning-models-for-soil-parameter</guid>
    </item>
    <item>
      <title>ActionStudio: A Lightweight Framework for Data and Training of Action Models</title>
      <link>https://paperswithcode.com/paper/actionstudio-a-lightweight-framework-for-data</link>
      <description><![CDATA[Action models are essential for enabling autonomous agents to perform complex tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/actionstudio-a-lightweight-framework-for-data</guid>
    </item>
    <item>
      <title>Unicorn: Text-Only Data Synthesis for Vision Language Model Training</title>
      <link>https://paperswithcode.com/paper/unicorn-text-only-data-synthesis-for-vision</link>
      <description><![CDATA[By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unicorn-text-only-data-synthesis-for-vision</guid>
    </item>
    <item>
      <title>FLIP: Towards Comprehensive and Reliable Evaluation of Federated Prompt Learning</title>
      <link>https://paperswithcode.com/paper/flip-towards-comprehensive-and-reliable</link>
      <description><![CDATA[The increasing emphasis on privacy and data security has driven the adoption of federated learning, a decentralized approach to train machine learning models without sharing raw data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flip-towards-comprehensive-and-reliable</guid>
    </item>
    <item>
      <title>A Refined Analysis of Massive Activations in LLMs</title>
      <link>https://paperswithcode.com/paper/a-refined-analysis-of-massive-activations-in</link>
      <description><![CDATA[Motivated in part by their relevance for low-precision training and quantization, massive activations in large language models (LLMs) have recently emerged as a topic of interest.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-refined-analysis-of-massive-activations-in</guid>
    </item>
    <item>
      <title>A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination</title>
      <link>https://paperswithcode.com/paper/a-causal-framework-to-measure-and-mitigate</link>
      <description><![CDATA[Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-causal-framework-to-measure-and-mitigate</guid>
    </item>
    <item>
      <title>CoSIL: Software Issue Localization via LLM-Driven Code Repository Graph Searching</title>
      <link>https://paperswithcode.com/paper/cosil-software-issue-localization-via-llm</link>
      <description><![CDATA[CoSIL reduces the search space through module call graphs, iteratively searches the function call graph to obtain relevant contexts, and uses context pruning to control the search direction and manage contexts effectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cosil-software-issue-localization-via-llm</guid>
    </item>
    <item>
      <title>VITAL: More Understandable Feature Visualization through Distribution Alignment and Relevant Information Flow</title>
      <link>https://paperswithcode.com/paper/vital-more-understandable-feature</link>
      <description><![CDATA[Feature visualization (FV) is a powerful tool to decode what information neurons are responding to and hence to better understand the reasoning behind such networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vital-more-understandable-feature</guid>
    </item>
    <item>
      <title>Q-Insight: Understanding Image Quality via Visual Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/q-insight-understanding-image-quality-via</link>
      <description><![CDATA[Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/q-insight-understanding-image-quality-via</guid>
    </item>
    <item>
      <title>MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets</title>
      <link>https://paperswithcode.com/paper/mo-ctrans-a-unified-multi-organ-segmentation</link>
      <description><![CDATA[Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i. e. axial and coronal) and annotated for different organs (i. e. liver, kidney, spleen).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mo-ctrans-a-unified-multi-organ-segmentation</guid>
    </item>
    <item>
      <title>CPPO: Accelerating the Training of Group Relative Policy Optimization-Based Reasoning Models</title>
      <link>https://paperswithcode.com/paper/cppo-accelerating-the-training-of-group</link>
      <description><![CDATA[This paper introduces Completion Pruning Policy Optimization (CPPO) to accelerate the training of reasoning models based on Group Relative Policy Optimization (GRPO).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cppo-accelerating-the-training-of-group</guid>
    </item>
    <item>
      <title>Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish</title>
      <link>https://paperswithcode.com/paper/historical-ink-exploring-large-language</link>
      <description><![CDATA[This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/historical-ink-exploring-large-language</guid>
    </item>
    <item>
      <title>AdaRank: Adaptive Rank Pruning for Enhanced Model Merging</title>
      <link>https://paperswithcode.com/paper/adarank-adaptive-rank-pruning-for-enhanced</link>
      <description><![CDATA[Model merging has emerged as a promising approach for unifying independently fine-tuned models into an integrated framework, significantly enhancing computational efficiency in multi-task learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adarank-adaptive-rank-pruning-for-enhanced</guid>
    </item>
    <item>
      <title>STADE: Standard Deviation as a Pruning Metric</title>
      <link>https://paperswithcode.com/paper/stade-standard-deviation-as-a-pruning-metric</link>
      <description><![CDATA[Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stade-standard-deviation-as-a-pruning-metric</guid>
    </item>
    <item>
      <title>Data-Agnostic Robotic Long-Horizon Manipulation with Vision-Language-Guided Closed-Loop Feedback</title>
      <link>https://paperswithcode.com/paper/data-agnostic-robotic-long-horizon</link>
      <description><![CDATA[Recent advances in language-conditioned robotic manipulation have leveraged imitation and reinforcement learning to enable robots to execute tasks from human commands.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-agnostic-robotic-long-horizon</guid>
    </item>
    <item>
      <title>VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic Faithfulness</title>
      <link>https://paperswithcode.com/paper/vbench-2-0-advancing-video-generation</link>
      <description><![CDATA[To bridge this gap, we introduce VBench-2. 0, a next-generation benchmark designed to automatically evaluate video generative models for their intrinsic faithfulness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vbench-2-0-advancing-video-generation</guid>
    </item>
    <item>
      <title>Pretrained Bayesian Non-parametric Knowledge Prior in Robotic Long-Horizon Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/pretrained-bayesian-non-parametric-knowledge</link>
      <description><![CDATA[Reinforcement learning (RL) methods typically learn new tasks from scratch, often disregarding prior knowledge that could accelerate the learning process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pretrained-bayesian-non-parametric-knowledge</guid>
    </item>
    <item>
      <title>Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for Embodied Interactive Tasks</title>
      <link>https://paperswithcode.com/paper/embodied-reasoner-synergizing-visual-search</link>
      <description><![CDATA[Recent advances in deep thinking models have demonstrated remarkable reasoning capabilities on mathematical and coding tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embodied-reasoner-synergizing-visual-search</guid>
    </item>
    <item>
      <title>Prompting Vision-Language Model for Nuclei Instance Segmentation and Classification</title>
      <link>https://paperswithcode.com/paper/prompting-vision-language-model-for-nuclei</link>
      <description><![CDATA[Nuclei instance segmentation and classification are a fundamental and challenging task in whole slide Imaging (WSI) analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompting-vision-language-model-for-nuclei</guid>
    </item>
    <item>
      <title>OntoAligner: A Comprehensive Modular and Robust Python Toolkit for Ontology Alignment</title>
      <link>https://paperswithcode.com/paper/ontoaligner-a-comprehensive-modular-and</link>
      <description><![CDATA[Ontology Alignment (OA) is fundamental for achieving semantic interoperability across diverse knowledge systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ontoaligner-a-comprehensive-modular-and</guid>
    </item>
    <item>
      <title>R-PRM: Reasoning-Driven Process Reward Modeling</title>
      <link>https://paperswithcode.com/paper/r-prm-reasoning-driven-process-reward</link>
      <description><![CDATA[Large language models (LLMs) inevitably make mistakes when performing step-by-step mathematical reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r-prm-reasoning-driven-process-reward</guid>
    </item>
    <item>
      <title>Lumina-Image 2.0: A Unified and Efficient Image Generative Framework</title>
      <link>https://paperswithcode.com/paper/lumina-image-2-0-a-unified-and-efficient</link>
      <description><![CDATA[We introduce Lumina-Image 2. 0, an advanced text-to-image generation framework that achieves significant progress compared to previous work, Lumina-Next.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lumina-image-2-0-a-unified-and-efficient</guid>
    </item>
    <item>
      <title>Multi-Scale Invertible Neural Network for Wide-Range Variable-Rate Learned Image Compression</title>
      <link>https://paperswithcode.com/paper/multi-scale-invertible-neural-network-for</link>
      <description><![CDATA[Autoencoder-based structures have dominated recent learned image compression methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-invertible-neural-network-for</guid>
    </item>
    <item>
      <title>Reinforced Model Merging</title>
      <link>https://paperswithcode.com/paper/reinforced-model-merging</link>
      <description><![CDATA[The success of large language models has garnered widespread attention for model merging techniques, especially training-free methods which combine model capabilities within the parameter space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforced-model-merging</guid>
    </item>
    <item>
      <title>On Large Multimodal Models as Open-World Image Classifiers</title>
      <link>https://paperswithcode.com/paper/on-large-multimodal-models-as-open-world</link>
      <description><![CDATA[Despite this remarkable capability, most existing studies on LMM classification performance are surprisingly limited in scope, often assuming a closed-world setting with a predefined set of categories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-large-multimodal-models-as-open-world</guid>
    </item>
    <item>
      <title>Tune It Up: Music Genre Transfer and Prediction</title>
      <link>https://paperswithcode.com/paper/tune-it-up-music-genre-transfer-and</link>
      <description><![CDATA[In this study, we adapt and improve CycleGAN model to perform music style transfer on Jazz and Classic genres.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tune-it-up-music-genre-transfer-and</guid>
    </item>
    <item>
      <title>Challenging the Boundaries of Reasoning: An Olympiad-Level Math Benchmark for Large Language Models</title>
      <link>https://paperswithcode.com/paper/challenging-the-boundaries-of-reasoning-an</link>
      <description><![CDATA[In recent years, the rapid development of large reasoning models has resulted in the saturation of existing benchmarks for evaluating mathematical reasoning, highlighting the urgent need for more challenging and rigorous evaluation frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/challenging-the-boundaries-of-reasoning-an</guid>
    </item>
    <item>
      <title>Vision-to-Music Generation: A Survey</title>
      <link>https://paperswithcode.com/paper/vision-to-music-generation-a-survey</link>
      <description><![CDATA[Vision-to-music Generation, including video-to-music and image-to-music tasks, is a significant branch of multimodal artificial intelligence demonstrating vast application prospects in fields such as film scoring, short video creation, and dance music synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-to-music-generation-a-survey</guid>
    </item>
    <item>
      <title>Optimal Stepsize for Diffusion Sampling</title>
      <link>https://paperswithcode.com/paper/optimal-stepsize-for-diffusion-sampling</link>
      <description><![CDATA[Diffusion models achieve remarkable generation quality but suffer from computational intensive sampling due to suboptimal step discretization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimal-stepsize-for-diffusion-sampling</guid>
    </item>
    <item>
      <title>PyUAT: Open-source Python framework for efficient and scalable cell tracking</title>
      <link>https://paperswithcode.com/paper/pyuat-open-source-python-framework-for</link>
      <description><![CDATA[Tracking individual cells in live-cell imaging provides fundamental insights, inevitable for studying causes and consequences of phenotypic heterogeneity, responses to changing environmental conditions or stressors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pyuat-open-source-python-framework-for</guid>
    </item>
    <item>
      <title>Reward Design for Reinforcement Learning Agents</title>
      <link>https://paperswithcode.com/paper/reward-design-for-reinforcement-learning</link>
      <description><![CDATA[Second, we build on this teacher-driven approach by introducing a novel method for adaptive interpretable reward design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reward-design-for-reinforcement-learning</guid>
    </item>
    <item>
      <title>Mobile-VideoGPT: Fast and Accurate Video Understanding Language Model</title>
      <link>https://paperswithcode.com/paper/mobile-videogpt-fast-and-accurate-video</link>
      <description><![CDATA[To tackle these challenges, we propose Mobile-VideoGPT, an efficient multimodal framework designed to operate with fewer than a billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobile-videogpt-fast-and-accurate-video</guid>
    </item>
    <item>
      <title>DGSUnet: An Improved Unet Model with DINO-Guided SAM2 for Multi-Scale Feature Collaboration</title>
      <link>https://paperswithcode.com/paper/dgsunet-an-improved-unet-model-with-dino</link>
      <description><![CDATA[Despite the significant advancements in general image segmentation achieved by large-scale pre-trained foundation models (such as Meta's Segment Any-thing Model (SAM) series and DINOv2), their performance in specialized fields remains limited by two critical issues: the excessive training costs due to large model parameters, and the insufficient ability to represent specific domain characteristics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dgsunet-an-improved-unet-model-with-dino</guid>
    </item>
    <item>
      <title>A Comprehensive Benchmark for RNA 3D Structure-Function Modeling</title>
      <link>https://paperswithcode.com/paper/a-comprehensive-benchmark-for-rna-3d</link>
      <description><![CDATA[The RNA structure-function relationship has recently garnered significant attention within the deep learning community, promising to grow in importance as nucleic acid structure models advance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comprehensive-benchmark-for-rna-3d</guid>
    </item>
    <item>
      <title>Semantic Library Adaptation: LoRA Retrieval and Fusion for Open-Vocabulary Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/semantic-library-adaptation-lora-retrieval</link>
      <description><![CDATA[Open-vocabulary semantic segmentation models associate vision and text to label pixels from an undefined set of classes using textual queries, providing versatile performance on novel datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-library-adaptation-lora-retrieval</guid>
    </item>
    <item>
      <title>ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging</title>
      <link>https://paperswithcode.com/paper/zjuklab-at-semeval-2025-task-4-unlearning-via</link>
      <description><![CDATA[This paper presents the ZJUKLAB team's submission for SemEval-2025 Task 4: Unlearning Sensitive Content from Large Language Models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zjuklab-at-semeval-2025-task-4-unlearning-via</guid>
    </item>
    <item>
      <title>Video-R1: Reinforcing Video Reasoning in MLLMs</title>
      <link>https://paperswithcode.com/paper/video-r1-reinforcing-video-reasoning-in-mllms</link>
      <description><![CDATA[However, directly applying RL training with the GRPO algorithm to video reasoning presents two primary challenges: (i) a lack of temporal modeling for video reasoning, and (ii) the scarcity of high-quality video-reasoning data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-r1-reinforcing-video-reasoning-in-mllms</guid>
    </item>
    <item>
      <title>Test-Time Visual In-Context Tuning</title>
      <link>https://paperswithcode.com/paper/test-time-visual-in-context-tuning</link>
      <description><![CDATA[Visual in-context learning (VICL), as a new paradigm in computer vision, allows the model to rapidly adapt to various tasks with only a handful of prompts and examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/test-time-visual-in-context-tuning</guid>
    </item>
    <item>
      <title>A Unified Image-Dense Annotation Generation Model for Underwater Scenes</title>
      <link>https://paperswithcode.com/paper/a-unified-image-dense-annotation-generation</link>
      <description><![CDATA[This paper proposes a unified Text-to-Image and DEnse annotation generation method (TIDE) for underwater scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-unified-image-dense-annotation-generation</guid>
    </item>
    <item>
      <title>Nearest Neighbour Equilibrium Clustering</title>
      <link>https://paperswithcode.com/paper/nearest-neighbour-equilibrium-clustering</link>
      <description><![CDATA[A novel and intuitive nearest neighbours based clustering algorithm is introduced, in which a cluster is defined in terms of an equilibrium condition which balances its size and cohesiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nearest-neighbour-equilibrium-clustering</guid>
    </item>
    <item>
      <title>Rerouting Connection: Hybrid Computer Vision Analysis Reveals Visual Similarity Between Indus and Tibetan-Yi Corridor Writing Systems</title>
      <link>https://paperswithcode.com/paper/rerouting-connection-hybrid-computer-vision</link>
      <description><![CDATA[This thesis employs a hybrid CNN-Transformer architecture, in conjunction with a detailed anthropological framework, to investigate potential historical connections between the visual morphology of the Indus Valley script and pictographic systems of the Tibetan-Yi Corridor.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rerouting-connection-hybrid-computer-vision</guid>
    </item>
    <item>
      <title>Recurrent Feature Mining and Keypoint Mixup Padding for Category-Agnostic Pose Estimation</title>
      <link>https://paperswithcode.com/paper/recurrent-feature-mining-and-keypoint-mixup</link>
      <description><![CDATA[Hence, these works neglect to mine fine-grained and structure-aware (FGSA) features from both support and query images, which are crucial for pixel-level keypoint localization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recurrent-feature-mining-and-keypoint-mixup</guid>
    </item>
    <item>
      <title>Effective Skill Unlearning through Intervention and Abstention</title>
      <link>https://paperswithcode.com/paper/effective-skill-unlearning-through</link>
      <description><![CDATA[Based on these observations, we propose two lightweight, training-free skill unlearning methods via \textit{intervention} and \textit{abstention} respectively: \texttt{Neuron Adjust} and \texttt{Key Space Detection}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effective-skill-unlearning-through</guid>
    </item>
    <item>
      <title>Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/learning-class-prototypes-for-unified-sparse</link>
      <description><![CDATA[To this end, we propose a unified sparse supervised 3D object detection method for both indoor and outdoor scenes through learning class prototypes to effectively utilize unlabeled objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-class-prototypes-for-unified-sparse</guid>
    </item>
  </channel>
</rss>
