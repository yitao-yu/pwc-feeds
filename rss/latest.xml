<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 27 Jul 2022 09:14:43 +0000</lastBuildDate>
    <item>
      <title>Few-shot Learning with Class-Covariance Metric for Hyperspectral Image Classification</title>
      <link>https://paperswithcode.com/paper/few-shot-learning-with-class-covariance</link>
      <description><![CDATA[Recently, embedding and metric-based few-shot learning (FSL) has been introduced into hyperspectral image classification (HSIC) and achieved impressive progress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/few-shot-learning-with-class-covariance</guid>
    </item>
    <item>
      <title>Towards Smart City Security: Violence and Weaponized Violence Detection using DCNN</title>
      <link>https://paperswithcode.com/paper/towards-smart-city-security-violence-and</link>
      <description><![CDATA[In this ever connected society, CCTVs have had a pivotal role in enforcing safety and security of the citizens by recording unlawful activities for the authorities to take actions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-smart-city-security-violence-and</guid>
    </item>
    <item>
      <title>A Reliable Online Method for Joint Estimation of Focal Length and Camera Rotation</title>
      <link>https://paperswithcode.com/paper/a-reliable-online-method-for-joint-estimation</link>
      <description><![CDATA[Linear perspectivecues deriving from regularities of the built environment can be used to recalibrate both intrinsic and extrinsic camera parameters online, but these estimates can be unreliable due to irregularities in the scene, uncertainties in line segment estimation and background clutter.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-reliable-online-method-for-joint-estimation</guid>
    </item>
    <item>
      <title>Criteria Comparative Learning for Real-scene Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/criteria-comparative-learning-for-real-scene</link>
      <description><![CDATA[Inspired by the observation that the contrastive relationship could also exist between the criteria, in this work, we propose a novel training paradigm for RealSR, named Criteria Comparative Learning (Cria-CL), by developing contrastive losses defined on criteria instead of image patches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/criteria-comparative-learning-for-real-scene</guid>
    </item>
    <item>
      <title>Large-displacement 3D Object Tracking with Hybrid Non-local Optimization</title>
      <link>https://paperswithcode.com/paper/large-displacement-3d-object-tracking-with</link>
      <description><![CDATA[Optimization-based 3D object tracking is known to be precise and fast, but sensitive to large inter-frame displacements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-displacement-3d-object-tracking-with</guid>
    </item>
    <item>
      <title>Cross-Modality Image Registration using a Training-Time Privileged Third Modality</title>
      <link>https://paperswithcode.com/paper/cross-modality-image-registration-using-a</link>
      <description><![CDATA[In this work, we consider the task of pairwise cross-modality image registration, which may benefit from exploiting additional images available only at training time from an additional modality that is different to those being registered.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-modality-image-registration-using-a</guid>
    </item>
    <item>
      <title>Repeated Environment Inference for Invariant Learning</title>
      <link>https://paperswithcode.com/paper/repeated-environment-inference-for-invariant</link>
      <description><![CDATA[The EI step uses a reference model which focuses on spurious correlations to efficiently reach a good environment partition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repeated-environment-inference-for-invariant</guid>
    </item>
    <item>
      <title>Visually explaining 3D-CNN predictions for video classification with an adaptive occlusion sensitivity analysis</title>
      <link>https://paperswithcode.com/paper/visually-explaining-3d-cnn-predictions-for</link>
      <description><![CDATA[The key idea here is to occlude a specific volume of data by a 3D mask in an input 3D temporal-spatial data space and then measure the change degree in the output score.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visually-explaining-3d-cnn-predictions-for</guid>
    </item>
    <item>
      <title>Generalized Probabilistic U-Net for medical image segementation</title>
      <link>https://paperswithcode.com/paper/generalized-probabilistic-u-net-for-medical</link>
      <description><![CDATA[We propose the Generalized Probabilistic U-Net, which extends the Probabilistic U-Net by allowing more general forms of the Gaussian distribution as the latent space distribution that can better approximate the uncertainty in the reference segmentations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-probabilistic-u-net-for-medical</guid>
    </item>
    <item>
      <title>Domain Adaptation under Open Set Label Shift</title>
      <link>https://paperswithcode.com/paper/domain-adaptation-under-open-set-label-shift</link>
      <description><![CDATA[We introduce the problem of domain adaptation under Open Set Label Shift (OSLS) where the label distribution can change arbitrarily and a new class may arrive during deployment, but the class-conditional distributions p(x|y) are domain-invariant.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-adaptation-under-open-set-label-shift</guid>
    </item>
    <item>
      <title>Learning Protein Representations via Complete 3D Graph Networks</title>
      <link>https://paperswithcode.com/paper/learning-protein-representations-via-complete</link>
      <description><![CDATA[Our ProNet is very flexible and can be used to compute protein representations at different levels of granularity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-protein-representations-via-complete</guid>
    </item>
    <item>
      <title>Representing Random Utility Choice Models with Neural Networks</title>
      <link>https://paperswithcode.com/paper/representing-random-utility-choice-models</link>
      <description><![CDATA[Motivated by the successes of deep learning, we propose a class of neural network-based discrete choice models, called RUMnets, which is inspired by the random utility maximization (RUM) framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representing-random-utility-choice-models</guid>
    </item>
    <item>
      <title>Learning Hierarchy Aware Features for Reducing Mistake Severity</title>
      <link>https://paperswithcode.com/paper/learning-hierarchy-aware-features-for</link>
      <description><![CDATA[In this paper, we propose a novel approach for learning Hierarchy Aware Features (HAF) that leverages classifiers at each level of the hierarchy that are constrained to generate predictions consistent with the label hierarchy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-hierarchy-aware-features-for</guid>
    </item>
    <item>
      <title>ProposalContrast: Unsupervised Pre-training for LiDAR-based 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/proposalcontrast-unsupervised-pre-training</link>
      <description><![CDATA[Existing approaches for unsupervised point cloud pre-training are constrained to either scene-level or point/voxel-level instance discrimination.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proposalcontrast-unsupervised-pre-training</guid>
    </item>
    <item>
      <title>Hansel: A Chinese Few-Shot and Zero-Shot Entity Linking Benchmark</title>
      <link>https://paperswithcode.com/paper/hansel-a-chinese-few-shot-and-zero-shot-1</link>
      <description><![CDATA[We then establish a strong baseline that scores a R@1 of 46. 2% on Few-Shot and 76. 6% on Zero-Shot on our dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hansel-a-chinese-few-shot-and-zero-shot-1</guid>
    </item>
    <item>
      <title>Semi-supervised 3D Object Detection with Proficient Teachers</title>
      <link>https://paperswithcode.com/paper/semi-supervised-3d-object-detection-with</link>
      <description><![CDATA[To reduce the dependence on large supervision, semi-supervised learning (SSL) based approaches have been proposed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semi-supervised-3d-object-detection-with</guid>
    </item>
    <item>
      <title>Compositional Human-Scene Interaction Synthesis with Semantic Control</title>
      <link>https://paperswithcode.com/paper/compositional-human-scene-interaction</link>
      <description><![CDATA[Furthermore, inspired by the compositional nature of interactions that humans can simultaneously interact with multiple objects, we define interaction semantics as the composition of varying numbers of atomic action-object pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compositional-human-scene-interaction</guid>
    </item>
    <item>
      <title>Controllable User Dialogue Act Augmentation for Dialogue State Tracking</title>
      <link>https://paperswithcode.com/paper/controllable-user-dialogue-act-augmentation</link>
      <description><![CDATA[Prior work has demonstrated that data augmentation is useful for improving dialogue state tracking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controllable-user-dialogue-act-augmentation</guid>
    </item>
    <item>
      <title>Lifelong DP: Consistently Bounded Differential Privacy in Lifelong Machine Learning</title>
      <link>https://paperswithcode.com/paper/lifelong-dp-consistently-bounded-differential</link>
      <description><![CDATA[In this paper, we show that the process of continually learning new tasks and memorizing previous tasks introduces unknown privacy risks and challenges to bound the privacy loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lifelong-dp-consistently-bounded-differential</guid>
    </item>
    <item>
      <title>Bundle MCR: Towards Conversational Bundle Recommendation</title>
      <link>https://paperswithcode.com/paper/bundle-mcr-towards-conversational-bundle</link>
      <description><![CDATA[MCR, which uses a conversational paradigm to elicit user interests by asking user preferences on tags (e. g., categories or attributes) and handling user feedback across multiple rounds, is an emerging recommendation setting to acquire user feedback and narrow down the output space, but has not been explored in the context of bundle recommendation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bundle-mcr-towards-conversational-bundle</guid>
    </item>
    <item>
      <title>NewsStories: Illustrating articles with visual summaries</title>
      <link>https://paperswithcode.com/paper/newsstories-illustrating-articles-with-visual</link>
      <description><![CDATA[Thus, we explore a novel setting where the goal is to learn a self-supervised visual-language representation that is robust to varying text length and the number of images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/newsstories-illustrating-articles-with-visual</guid>
    </item>
    <item>
      <title>Learning Visual Representation from Modality-Shared Contrastive Language-Image Pre-training</title>
      <link>https://paperswithcode.com/paper/learning-visual-representation-from-modality</link>
      <description><![CDATA[Large-scale multi-modal contrastive pre-training has demonstrated great utility to learn transferable features for a range of downstream tasks by mapping multiple modalities into a shared embedding space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-visual-representation-from-modality</guid>
    </item>
    <item>
      <title>CENet: Toward Concise and Efficient LiDAR Semantic Segmentation for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/cenet-toward-concise-and-efficient-lidar</link>
      <description><![CDATA[Accurate and fast scene understanding is one of the challenging task for autonomous driving, which requires to take full advantage of LiDAR point clouds for semantic segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cenet-toward-concise-and-efficient-lidar</guid>
    </item>
    <item>
      <title>MV-FCOS3D++: Multi-View Camera-Only 4D Object Detection with Pretrained Monocular Backbones</title>
      <link>https://paperswithcode.com/paper/mv-fcos3d-multi-view-camera-only-4d-object</link>
      <description><![CDATA[In this technical report, we present our solution, dubbed MV-FCOS3D++, for the Camera-Only 3D Detection track in Waymo Open Dataset Challenge 2022.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mv-fcos3d-multi-view-camera-only-4d-object</guid>
    </item>
    <item>
      <title>Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models</title>
      <link>https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</link>
      <description><![CDATA[In RDMs, a set of nearest neighbors is retrieved from an external database during training for each training instance, and the diffusion model is conditioned on these informative samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</guid>
    </item>
    <item>
      <title>LaKo: Knowledge-driven Visual Question Answering via Late Knowledge-to-Text Injection</title>
      <link>https://paperswithcode.com/paper/lako-knowledge-driven-visual-question</link>
      <description><![CDATA[Visual question answering (VQA) often requires an understanding of visual concepts and language semantics, which relies on external knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lako-knowledge-driven-visual-question</guid>
    </item>
    <item>
      <title>Learning Bipedal Walking On Planned Footsteps For Humanoid Robots</title>
      <link>https://paperswithcode.com/paper/learning-bipedal-walking-on-planned-footsteps</link>
      <description><![CDATA[To enable the application of RL policies for humanoid robots in real-world settings, it is crucial to build a system that can achieve robust walking in any direction, on 2D and 3D terrains, and be controllable by a user-command.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-bipedal-walking-on-planned-footsteps</guid>
    </item>
    <item>
      <title>Efficient One Pass Self-distillation with Zipf's Label Smoothing</title>
      <link>https://paperswithcode.com/paper/efficient-one-pass-self-distillation-with</link>
      <description><![CDATA[This paper proposes an efficient self-distillation method named Zipf's Label Smoothing (Zipf's LS), which uses the on-the-fly prediction of a network to generate soft supervision that conforms to Zipf distribution without using any contrastive samples or auxiliary parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-one-pass-self-distillation-with</guid>
    </item>
    <item>
      <title>Monocular 3D Object Detection with Depth from Motion</title>
      <link>https://paperswithcode.com/paper/monocular-3d-object-detection-with-depth-from</link>
      <description><![CDATA[Perceiving 3D objects from monocular inputs is crucial for robotic systems, given its economy compared to multi-sensor settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monocular-3d-object-detection-with-depth-from</guid>
    </item>
    <item>
      <title>Behind Every Domain There is a Shift: Adapting Distortion-aware Vision Transformers for Panoramic Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/behind-every-domain-there-is-a-shift-adapting</link>
      <description><![CDATA[Panoramic segmentation is under-explored due to two critical challenges: (1) image distortions and object deformations on panoramas; (2) lack of annotations for training panoramic segmenters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/behind-every-domain-there-is-a-shift-adapting</guid>
    </item>
    <item>
      <title>Domain Decorrelation with Potential Energy Ranking</title>
      <link>https://paperswithcode.com/paper/domain-decorrelation-with-potential-energy</link>
      <description><![CDATA[PoER helps the neural networks to capture label-related features which contain the domain information first in shallow layers and then distills the label-discriminative representations out progressively, enforcing the neural networks to be aware of the characteristic of objects and background which is vital to the generation of domain-invariant features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-decorrelation-with-potential-energy</guid>
    </item>
    <item>
      <title>Deep Laparoscopic Stereo Matching with Transformers</title>
      <link>https://paperswithcode.com/paper/deep-laparoscopic-stereo-matching-with</link>
      <description><![CDATA[The self-attention mechanism, successfully employed with the transformer structure is shown promise in many computer vision tasks including image recognition, and object detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-laparoscopic-stereo-matching-with</guid>
    </item>
    <item>
      <title>Reference-based Image Super-Resolution with Deformable Attention Transformer</title>
      <link>https://paperswithcode.com/paper/reference-based-image-super-resolution-with</link>
      <description><![CDATA[Reference-based image super-resolution (RefSR) aims to exploit auxiliary reference (Ref) images to super-resolve low-resolution (LR) images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reference-based-image-super-resolution-with</guid>
    </item>
    <item>
      <title>Cost Volume Pyramid Network with Multi-strategies Range Searching for Multi-view Stereo</title>
      <link>https://paperswithcode.com/paper/cost-volume-pyramid-network-with-multi</link>
      <description><![CDATA[Multi-view stereo is an important research task in computer vision while still keeping challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cost-volume-pyramid-network-with-multi</guid>
    </item>
    <item>
      <title>Domain-invariant Feature Exploration for Domain Generalization</title>
      <link>https://paperswithcode.com/paper/domain-invariant-feature-exploration-for</link>
      <description><![CDATA[Internal invariance means that the features can be learned with a single domain and the features capture intrinsic semantics of data, i. e., the property within a domain, which is agnostic to other domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-invariant-feature-exploration-for</guid>
    </item>
    <item>
      <title>Dynamic Channel Selection in Self-Supervised Learning</title>
      <link>https://paperswithcode.com/paper/dynamic-channel-selection-in-self-supervised</link>
      <description><![CDATA[Currently, convnets pre-trained with self-supervision have obtained comparable performance on downstream tasks in comparison to their supervised counterparts in computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-channel-selection-in-self-supervised</guid>
    </item>
    <item>
      <title>Generative Subgraph Contrast for Self-Supervised Graph Representation Learning</title>
      <link>https://paperswithcode.com/paper/generative-subgraph-contrast-for-self</link>
      <description><![CDATA[To this end, in this paper, we propose a novel adaptive subgraph generation based contrastive learning framework for efficient and robust self-supervised graph representation learning, and the optimal transport distance is utilized as the similarity metric between the subgraphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-subgraph-contrast-for-self</guid>
    </item>
    <item>
      <title>Active Learning Strategies for Weakly-supervised Object Detection</title>
      <link>https://paperswithcode.com/paper/active-learning-strategies-for-weakly</link>
      <description><![CDATA[On COCO, using on average 10 fully-annotated images per class, or equivalently 1% of the training set, BiB also reduces the performance gap (in AP) between the weakly-supervised detector and the fully-supervised Fast RCNN by over 70%, showing a good trade-off between performance and data efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/active-learning-strategies-for-weakly</guid>
    </item>
    <item>
      <title>C3-SL: Circular Convolution-Based Batch-Wise Compression for Communication-Efficient Split Learning</title>
      <link>https://paperswithcode.com/paper/c3-sl-circular-convolution-based-batch-wise</link>
      <description><![CDATA[Based on the simulation results on CIFAR-10 and CIFAR-100, our method achieves a 16x compression ratio with negligible accuracy drops compared with the vanilla SL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/c3-sl-circular-convolution-based-batch-wise</guid>
    </item>
    <item>
      <title>Self-Distilled Vision Transformer for Domain Generalization</title>
      <link>https://paperswithcode.com/paper/self-distilled-vision-transformer-for-domain</link>
      <description><![CDATA[In recent past, several domain generalization (DG) methods have been proposed, showing encouraging performance, however, almost all of them build on convolutional neural networks (CNNs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-distilled-vision-transformer-for-domain</guid>
    </item>
    <item>
      <title>WinoGAViL: Gamified Association Benchmark to Challenge Vision-and-Language Models</title>
      <link>https://paperswithcode.com/paper/winogavil-gamified-association-benchmark-to</link>
      <description><![CDATA[While vision-and-language models perform well on tasks such as visual question answering, they struggle when it comes to basic human commonsense reasoning skills.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/winogavil-gamified-association-benchmark-to</guid>
    </item>
    <item>
      <title>Advancing Semi-Supervised Task Oriented Dialog Systems by JSA Learning of Discrete Latent Variable Models</title>
      <link>https://paperswithcode.com/paper/advancing-semi-supervised-task-oriented</link>
      <description><![CDATA[In this paper, we propose to apply JSA to semi-supervised learning of the latent state TOD models, which is referred to as JSA-TOD.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-semi-supervised-task-oriented</guid>
    </item>
    <item>
      <title>Trainability Preserving Neural Structured Pruning</title>
      <link>https://paperswithcode.com/paper/trainability-preserving-neural-structured</link>
      <description><![CDATA[In this paper, we present trainability preserving pruning (TPP), a regularization-based structured pruning method that can effectively maintain trainability during sparsification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trainability-preserving-neural-structured</guid>
    </item>
    <item>
      <title>W2N:Switching From Weak Supervision to Noisy Supervision for Object Detection</title>
      <link>https://paperswithcode.com/paper/w2n-switching-from-weak-supervision-to-noisy</link>
      <description><![CDATA[Generally, with given pseudo ground-truths generated from the well-trained WSOD network, we propose a two-module iterative training algorithm to refine pseudo labels and supervise better object detector progressively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/w2n-switching-from-weak-supervision-to-noisy</guid>
    </item>
    <item>
      <title>Patchwork++: Fast and Robust Ground Segmentation Solving Partial Under-Segmentation Using 3D Point Cloud</title>
      <link>https://paperswithcode.com/paper/patchwork-fast-and-robust-ground-segmentation</link>
      <description><![CDATA[Moreover, even if the parameters are well adjusted, a partial under-segmentation problem can still emerge, which implies ground segmentation failures in some regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/patchwork-fast-and-robust-ground-segmentation</guid>
    </item>
    <item>
      <title>Intention-Conditioned Long-Term Human Egocentric Action Forecasting @ EGO4D Challenge 2022</title>
      <link>https://paperswithcode.com/paper/intention-conditioned-long-term-human</link>
      <description><![CDATA[Our framework first extracts two level of human information over the N observed videos human actions through a Hierarchical Multi-task MLP Mixer (H3M).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intention-conditioned-long-term-human</guid>
    </item>
    <item>
      <title>ArtFID: Quantitative Evaluation of Neural Style Transfer</title>
      <link>https://paperswithcode.com/paper/artfid-quantitative-evaluation-of-neural</link>
      <description><![CDATA[The field of neural style transfer has experienced a surge of research exploring different avenues ranging from optimization-based approaches and feed-forward models to meta-learning methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/artfid-quantitative-evaluation-of-neural</guid>
    </item>
    <item>
      <title>Domain Adaptive Person Search</title>
      <link>https://paperswithcode.com/paper/domain-adaptive-person-search</link>
      <description><![CDATA[In this paper, we take a further step and present Domain Adaptive Person Search (DAPS), which aims to generalize the model from a labeled source domain to the unlabeled target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-adaptive-person-search</guid>
    </item>
    <item>
      <title>Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection</title>
      <link>https://paperswithcode.com/paper/revisiting-ap-loss-for-dense-object-detection-1</link>
      <description><![CDATA[However, a deep understanding of how AP loss affects the detector from a pairwise ranking perspective has not yet been developed. In this work, we revisit the average precision (AP)loss and reveal that the crucial element is that of selecting the ranking pairs between positive and negative samples. Based on this observation, we propose two strategies to improve the AP loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-ap-loss-for-dense-object-detection-1</guid>
    </item>
    <item>
      <title>On Mitigating Hard Clusters for Face Clustering</title>
      <link>https://paperswithcode.com/paper/on-mitigating-hard-clusters-for-face</link>
      <description><![CDATA[Face clustering is a promising way to scale up face recognition systems using large-scale unlabeled face images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-mitigating-hard-clusters-for-face</guid>
    </item>
  </channel>
</rss>
