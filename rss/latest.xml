<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 13 May 2024 09:13:58 +0000</lastBuildDate>
    <item>
      <title>Semantic and Spatial Adaptive Pixel-level Classifier for Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/semantic-and-spatial-adaptive-pixel-level</link>
      <description><![CDATA[Specifically, we employ the coarse masks obtained from the fixed prototypes as a guide to adjust the fixed prototype towards the center of the semantic and spatial domains in the test image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-and-spatial-adaptive-pixel-level</guid>
    </item>
    <item>
      <title>Heterogeneous Graph Neural Networks with Loss-decrease-aware Curriculum Learning</title>
      <link>https://paperswithcode.com/paper/heterogeneous-graph-neural-networks-with-loss</link>
      <description><![CDATA[Additionally, we propose a sampling strategy to alleviate training imbalance issues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/heterogeneous-graph-neural-networks-with-loss</guid>
    </item>
    <item>
      <title>Multi-Object Tracking in the Dark</title>
      <link>https://paperswithcode.com/paper/multi-object-tracking-in-the-dark</link>
      <description><![CDATA[We conducted a comprehensive analysis of our LMOT dataset and proposed LTrack.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-object-tracking-in-the-dark</guid>
    </item>
    <item>
      <title>Learning Latent Dynamic Robust Representations for World Models</title>
      <link>https://paperswithcode.com/paper/learning-latent-dynamic-robust</link>
      <description><![CDATA[Visual Model-Based Reinforcement Learning (MBRL) promises to encapsulate agent's knowledge about the underlying dynamics of the environment, enabling learning a world model as a useful planner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-latent-dynamic-robust</guid>
    </item>
    <item>
      <title>State-Free Inference of State-Space Models: The Transfer Function Approach</title>
      <link>https://paperswithcode.com/paper/state-free-inference-of-state-space-models</link>
      <description><![CDATA[We approach designing a state-space model for deep learning applications through its dual representation, the transfer function, and uncover a highly efficient sequence parallel inference algorithm that is state-free: unlike other proposed algorithms, state-free inference does not incur any significant memory or computational cost with an increase in state size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/state-free-inference-of-state-space-models</guid>
    </item>
    <item>
      <title>Contrastive Representation for Data Filtering in Cross-Domain Offline Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/contrastive-representation-for-data-filtering</link>
      <description><![CDATA[In this paper, we propose a novel representation-based approach to measure the domain gap, where the representation is learned through a contrastive objective by sampling transitions from different domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-representation-for-data-filtering</guid>
    </item>
    <item>
      <title>Pruning as a Domain-specific LLM Extractor</title>
      <link>https://paperswithcode.com/paper/pruning-as-a-domain-specific-llm-extractor</link>
      <description><![CDATA[Moreover, by efficiently approximating weight importance with the refined training loss on a domain-specific calibration dataset, we obtain a pruned model emphasizing generality and specificity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pruning-as-a-domain-specific-llm-extractor</guid>
    </item>
    <item>
      <title>Disttack: Graph Adversarial Attacks Toward Distributed GNN Training</title>
      <link>https://paperswithcode.com/paper/disttack-graph-adversarial-attacks-toward</link>
      <description><![CDATA[In this study, we introduce Disttack, the first framework of adversarial attacks for distributed GNN training that leverages the characteristics of frequent gradient updates in a distributed system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disttack-graph-adversarial-attacks-toward</guid>
    </item>
    <item>
      <title>MRSegmentator: Robust Multi-Modality Segmentation of 40 Classes in MRI and CT Sequences</title>
      <link>https://paperswithcode.com/paper/mrsegmentator-robust-multi-modality</link>
      <description><![CDATA[Results: The model showcased high accuracy in segmenting well-defined organs, achieving Dice Similarity Coefficient (DSC) scores of 0. 97 for the right and left lungs, and 0. 95 for the heart.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mrsegmentator-robust-multi-modality</guid>
    </item>
    <item>
      <title>OneTo3D: One Image to Re-editable Dynamic 3D Model and Video Generation</title>
      <link>https://paperswithcode.com/paper/oneto3d-one-image-to-re-editable-dynamic-3d</link>
      <description><![CDATA[To address this issue, we propose the OneTo3D, a method and theory to used one single image to generate the editable 3D model and generate the targeted semantic continuous time-unlimited 3D video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oneto3d-one-image-to-re-editable-dynamic-3d</guid>
    </item>
    <item>
      <title>Single-seed generation of Brownian paths and integrals for adaptive and high order SDE solvers</title>
      <link>https://paperswithcode.com/paper/single-seed-generation-of-brownian-paths-and</link>
      <description><![CDATA[With the aim of using high order SDE solvers adaptively, we extend the VBT to generate these integrals of BM in addition to the Brownian increments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/single-seed-generation-of-brownian-paths-and</guid>
    </item>
    <item>
      <title>Conformal Validity Guarantees Exist for Any Data Distribution</title>
      <link>https://paperswithcode.com/paper/conformal-validity-guarantees-exist-for-any</link>
      <description><![CDATA[As machine learning (ML) gains widespread adoption, practitioners are increasingly seeking means to quantify and control the risk these systems incur.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conformal-validity-guarantees-exist-for-any</guid>
    </item>
    <item>
      <title>PCLMix: Weakly Supervised Medical Image Segmentation via Pixel-Level Contrastive Learning and Dynamic Mix Augmentation</title>
      <link>https://paperswithcode.com/paper/pclmix-weakly-supervised-medical-image</link>
      <description><![CDATA[In weakly supervised medical image segmentation, the absence of structural priors and the discreteness of class feature distribution present a challenge, i. e., how to accurately propagate supervision signals from local to global regions without excessively spreading them to other irrelevant regions?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pclmix-weakly-supervised-medical-image</guid>
    </item>
    <item>
      <title>Unsupervised multimodal modeling of cognitive and brain health trajectories for early dementia prediction</title>
      <link>https://paperswithcode.com/paper/unsupervised-multimodal-modeling-of-cognitive</link>
      <description><![CDATA[In contrast to supervised classification approaches that require labeled data, we propose an unsupervised multimodal trajectory modeling (MTM) approach based on a mixture of state space models that captures changes in longitudinal data (i. e., trajectories) and stratifies individuals without using clinical diagnosis for model training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-multimodal-modeling-of-cognitive</guid>
    </item>
    <item>
      <title>Context-Guided Spatial Feature Reconstruction for Efficient Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/context-guided-spatial-feature-reconstruction</link>
      <description><![CDATA[Specifically, it achieves $43. 6\%$ mIoU on ADE20K with only $4. 0$ GFLOPs, which is $0. 9\%$ and $2. 5\%$ mIoU better than SeaFormer and SegNeXt but with about $38. 0\%$ fewer GFLOPs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-guided-spatial-feature-reconstruction</guid>
    </item>
    <item>
      <title>MAPL: Memory Augmentation and Pseudo-Labeling for Semi-Supervised Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/mapl-memory-augmentation-and-pseudo-labeling</link>
      <description><![CDATA[Meanwhile, a memory-enhanced learning mechanism is introduced to effectively predict abnormal regions by analyzing the difference be-tween the input samples and the normal samples in the memory pool.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mapl-memory-augmentation-and-pseudo-labeling</guid>
    </item>
    <item>
      <title>DARA: Domain- and Relation-aware Adapters Make Parameter-efficient Tuning for Visual Grounding</title>
      <link>https://paperswithcode.com/paper/dara-domain-and-relation-aware-adapters-make</link>
      <description><![CDATA[Specifically, we propose \textbf{DARA}, a novel PETL method comprising \underline{\textbf{D}}omain-aware \underline{\textbf{A}}dapters (DA Adapters) and \underline{\textbf{R}}elation-aware \underline{\textbf{A}}dapters (RA Adapters) for VG.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dara-domain-and-relation-aware-adapters-make</guid>
    </item>
    <item>
      <title>Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation</title>
      <link>https://paperswithcode.com/paper/improving-instruction-following-in-language</link>
      <description><![CDATA[Assessing response quality to instructions in language models is vital but challenging due to the complexity of human language across different contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-instruction-following-in-language</guid>
    </item>
    <item>
      <title>Look Once to Hear: Target Speech Hearing with Noisy Examples</title>
      <link>https://paperswithcode.com/paper/look-once-to-hear-target-speech-hearing-with</link>
      <description><![CDATA[We present the first enrollment interface where the wearer looks at the target speaker for a few seconds to capture a single, short, highly noisy, binaural example of the target speaker.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/look-once-to-hear-target-speech-hearing-with</guid>
    </item>
    <item>
      <title>Novel Class Discovery for Ultra-Fine-Grained Visual Categorization</title>
      <link>https://paperswithcode.com/paper/novel-class-discovery-for-ultra-fine-grained</link>
      <description><![CDATA[To tackle this problem, we devise a Region-Aligned Proxy Learning (RAPL) framework, which comprises a Channel-wise Region Alignment (CRA) module and a Semi-Supervised Proxy Learning (SemiPL) strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/novel-class-discovery-for-ultra-fine-grained</guid>
    </item>
    <item>
      <title>An Investigation of Incorporating Mamba for Speech Enhancement</title>
      <link>https://paperswithcode.com/paper/an-investigation-of-incorporating-mamba-for</link>
      <description><![CDATA[This work aims to study a scalable state-space model (SSM), Mamba, for the speech enhancement (SE) task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-investigation-of-incorporating-mamba-for</guid>
    </item>
    <item>
      <title>Time Evidence Fusion Network: Multi-source View in Long-Term Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/time-evidence-fusion-network-multi-source</link>
      <description><![CDATA[TEFN is not a model that achieves the ultimate in single aspect, but a model that balances performance, accuracy, stability, and interpretability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/time-evidence-fusion-network-multi-source</guid>
    </item>
    <item>
      <title>Linearizing Large Language Models</title>
      <link>https://paperswithcode.com/paper/linearizing-large-language-models</link>
      <description><![CDATA[Linear transformers have emerged as a subquadratic-time alternative to softmax attention and have garnered significant interest due to their fixed-size recurrent state that lowers inference cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linearizing-large-language-models</guid>
    </item>
    <item>
      <title>Learning A Spiking Neural Network for Efficient Image Deraining</title>
      <link>https://paperswithcode.com/paper/learning-a-spiking-neural-network-for</link>
      <description><![CDATA[Our work is motivated by the observation that rain pixel values will lead to a more pronounced intensity of spike signals in SNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-a-spiking-neural-network-for</guid>
    </item>
    <item>
      <title>Detecting Statements in Text: A Domain-Agnostic Few-Shot Solution</title>
      <link>https://paperswithcode.com/paper/detecting-statements-in-text-a-domain</link>
      <description><![CDATA[In light of this, we propose and release a qualitative and versatile few-shot learning methodology as a common paradigm for any claim-based textual classification task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detecting-statements-in-text-a-domain</guid>
    </item>
    <item>
      <title>Deep Hierarchical Graph Alignment Kernels</title>
      <link>https://paperswithcode.com/paper/deep-hierarchical-graph-alignment-kernels</link>
      <description><![CDATA[Typical R-convolution graph kernels invoke the kernel functions that decompose graphs into non-isomorphic substructures and compare them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-hierarchical-graph-alignment-kernels</guid>
    </item>
    <item>
      <title>Rectified Gaussian kernel multi-view k-means clustering</title>
      <link>https://paperswithcode.com/paper/rectified-gaussian-kernel-multi-view-k-means</link>
      <description><![CDATA[In this paper, we show two new variants of multi-view k-means (MVKM) algorithms to address multi-view data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rectified-gaussian-kernel-multi-view-k-means</guid>
    </item>
    <item>
      <title>Perceptual Crack Detection for Rendered 3D Textured Meshes</title>
      <link>https://paperswithcode.com/paper/perceptual-crack-detection-for-rendered-3d</link>
      <description><![CDATA[Extensive experiments on large-scale public datasets of 3D textured meshes demonstrate effectiveness and efficiency of the proposed PCD method in correct localization and detection of crack artifacts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perceptual-crack-detection-for-rendered-3d</guid>
    </item>
    <item>
      <title>MasterWeaver: Taming Editability and Identity for Personalized Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/masterweaver-taming-editability-and-identity</link>
      <description><![CDATA[In this work, we present MasterWeaver, a test-time tuning-free method designed to generate personalized images with both faithful identity fidelity and flexible editability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masterweaver-taming-editability-and-identity</guid>
    </item>
    <item>
      <title>HMT: Hierarchical Memory Transformer for Long Context Language Processing</title>
      <link>https://paperswithcode.com/paper/hmt-hierarchical-memory-transformer-for-long</link>
      <description><![CDATA[With an additional 0. 5% - 2% of parameters, HMT can easily plug in and augment future LLMs to handle long context effectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hmt-hierarchical-memory-transformer-for-long</guid>
    </item>
    <item>
      <title>Probing Multimodal LLMs as World Models for Driving</title>
      <link>https://paperswithcode.com/paper/probing-multimodal-llms-as-world-models-for</link>
      <description><![CDATA[We provide a sober look at the application of Multimodal Large Language Models (MLLMs) within the domain of autonomous driving and challenge/verify some common assumptions, focusing on their ability to reason and interpret dynamic driving scenarios through sequences of images/frames in a closed-loop control environment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probing-multimodal-llms-as-world-models-for</guid>
    </item>
    <item>
      <title>A Mixture of Experts Approach to 3D Human Motion Prediction</title>
      <link>https://paperswithcode.com/paper/a-mixture-of-experts-approach-to-3d-human</link>
      <description><![CDATA[This project addresses the challenge of human motion prediction, a critical area for applications such as au- tonomous vehicle movement detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-mixture-of-experts-approach-to-3d-human</guid>
    </item>
    <item>
      <title>Audio-Visual Speech Recognition based on Regulated Transformer and Spatio-Temporal Fusion Strategy for Driver Assistive Systems</title>
      <link>https://paperswithcode.com/paper/audio-visual-speech-recognition-based-on</link>
      <description><![CDATA[The article introduces a novel audio-visual speech command recognition transformer (AVCRFormer) specifically designed for robust AVSR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audio-visual-speech-recognition-based-on</guid>
    </item>
    <item>
      <title>Evaluating Real-World Robot Manipulation Policies in Simulation</title>
      <link>https://paperswithcode.com/paper/evaluating-real-world-robot-manipulation</link>
      <description><![CDATA[We then employ these approaches to create SIMPLER, a collection of simulated environments for manipulation policy evaluation on common real robot setups.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-real-world-robot-manipulation</guid>
    </item>
    <item>
      <title>OpenBA-V2: Reaching 77.3% High Compression Ratio with Fast Multi-Stage Pruning</title>
      <link>https://paperswithcode.com/paper/openba-v2-reaching-77-3-high-compression</link>
      <description><![CDATA[Large Language Models (LLMs) have played an important role in many fields due to their powerful capabilities. However, their massive number of parameters leads to high deployment requirements and incurs significant inference costs, which impedes their practical applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openba-v2-reaching-77-3-high-compression</guid>
    </item>
    <item>
      <title>Multi-Stream Keypoint Attention Network for Sign Language Recognition and Translation</title>
      <link>https://paperswithcode.com/paper/multi-stream-keypoint-attention-network-for</link>
      <description><![CDATA[The resulting framework is denoted as MSKA-SLR, which is expanded into a sign language translation (SLT) model through the straightforward addition of an extra translation network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-stream-keypoint-attention-network-for</guid>
    </item>
    <item>
      <title>Cross-Care: Assessing the Healthcare Implications of Pre-training Data on Language Model Bias</title>
      <link>https://paperswithcode.com/paper/cross-care-assessing-the-healthcare</link>
      <description><![CDATA[Large language models (LLMs) are increasingly essential in processing natural languages, yet their application is frequently compromised by biases and inaccuracies originating in their training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-care-assessing-the-healthcare</guid>
    </item>
    <item>
      <title>LayerPlexRank: Exploring Node Centrality and Layer Influence through Algebraic Connectivity in Multiplex Networks</title>
      <link>https://paperswithcode.com/paper/layerplexrank-exploring-node-centrality-and</link>
      <description><![CDATA[As the calculation of centrality in complex networks becomes increasingly vital across technological, biological, and social systems, precise and scalable ranking methods are essential for understanding these networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/layerplexrank-exploring-node-centrality-and</guid>
    </item>
    <item>
      <title>Continuous max-flow augmentation of self-supervised few-shot learning on SPECT left ventricles</title>
      <link>https://paperswithcode.com/paper/continuous-max-flow-augmentation-of-self</link>
      <description><![CDATA[Single-Photon Emission Computed Tomography (SPECT) left ventricular assessment protocols are important for detecting ischemia in high-risk patients.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/continuous-max-flow-augmentation-of-self</guid>
    </item>
    <item>
      <title>Characteristic Learning for Provable One Step Generation</title>
      <link>https://paperswithcode.com/paper/characteristic-learning-for-provable-one-step</link>
      <description><![CDATA[We propose the characteristic generator, a novel one-step generative model that combines the efficiency of sampling in Generative Adversarial Networks (GANs) with the stable performance of flow-based models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/characteristic-learning-for-provable-one-step</guid>
    </item>
    <item>
      <title>Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/lumina-t2x-transforming-text-into-any</link>
      <description><![CDATA[Sora unveils the potential of scaling Diffusion Transformer for generating photorealistic images and videos at arbitrary resolutions, aspect ratios, and durations, yet it still lacks sufficient implementation details.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lumina-t2x-transforming-text-into-any</guid>
    </item>
    <item>
      <title>Boosting Multimodal Large Language Models with Visual Tokens Withdrawal for Rapid Inference</title>
      <link>https://paperswithcode.com/paper/boosting-multimodal-large-language-models</link>
      <description><![CDATA[Our approach is inspired by two intriguing phenomena we have observed: (1) the attention sink phenomenon that is prevalent in LLMs also persists in MLLMs, suggesting that initial tokens and nearest tokens receive the majority of attention, while middle vision tokens garner minimal attention in deep layers; (2) the presence of information migration, which implies that visual information is transferred to subsequent text tokens within the first few layers of MLLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-multimodal-large-language-models</guid>
    </item>
    <item>
      <title>OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs</title>
      <link>https://paperswithcode.com/paper/openfactcheck-a-unified-framework-for</link>
      <description><![CDATA[The increased use of large language models (LLMs) across a variety of real-world applications calls for mechanisms to verify the factual accuracy of their outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openfactcheck-a-unified-framework-for</guid>
    </item>
    <item>
      <title>UnSegGNet: Unsupervised Image Segmentation using Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/unseggnet-unsupervised-image-segmentation</link>
      <description><![CDATA[Image segmentation, the process of partitioning an image into meaningful regions, plays a pivotal role in computer vision and medical imaging applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unseggnet-unsupervised-image-segmentation</guid>
    </item>
    <item>
      <title>Pre-trained Text-to-Image Diffusion Models Are Versatile Representation Learners for Control</title>
      <link>https://paperswithcode.com/paper/pre-trained-text-to-image-diffusion-models</link>
      <description><![CDATA[This has led to the emergence of pre-trained vision-language models as a tool for transferring representations learned from internet-scale data to downstream tasks and new domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pre-trained-text-to-image-diffusion-models</guid>
    </item>
    <item>
      <title>Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/memory-space-visual-prompting-for-efficient</link>
      <description><![CDATA[Current solutions for efficiently constructing large vision-language (VL) models follow a two-step paradigm: projecting the output of pre-trained vision encoders to the input space of pre-trained language models as visual prompts; and then transferring the models to downstream VL tasks via end-to-end parameter-efficient fine-tuning (PEFT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memory-space-visual-prompting-for-efficient</guid>
    </item>
    <item>
      <title>A Multi-Level Superoptimizer for Tensor Programs</title>
      <link>https://paperswithcode.com/paper/a-multi-level-superoptimizer-for-tensor</link>
      <description><![CDATA[We introduce Mirage, the first multi-level superoptimizer for tensor programs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-multi-level-superoptimizer-for-tensor</guid>
    </item>
    <item>
      <title>Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM</title>
      <link>https://paperswithcode.com/paper/chain-of-attack-a-semantic-driven-contextual</link>
      <description><![CDATA[CoA is a semantic-driven contextual multi-turn attack method that adaptively adjusts the attack policy through contextual feedback and semantic relevance during multi-turn of dialogue with a large model, resulting in the model producing unreasonable or harmful content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chain-of-attack-a-semantic-driven-contextual</guid>
    </item>
    <item>
      <title>Evaluating Dialect Robustness of Language Models via Conversation Understanding</title>
      <link>https://paperswithcode.com/paper/evaluating-dialect-robustness-of-language</link>
      <description><![CDATA[With an evergrowing number of LLMs reporting superlative performance for English, their ability to perform equitably for different dialects of English (i. e., dialect robustness) needs to be ascertained.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-dialect-robustness-of-language</guid>
    </item>
    <item>
      <title>CuMo: Scaling Multimodal LLM with Co-Upcycled Mixture-of-Experts</title>
      <link>https://paperswithcode.com/paper/cumo-scaling-multimodal-llm-with-co-upcycled</link>
      <description><![CDATA[Recent advancements in Multimodal Large Language Models (LLMs) have focused primarily on scaling by increasing text-image pair data and enhancing LLMs to improve performance on multimodal tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cumo-scaling-multimodal-llm-with-co-upcycled</guid>
    </item>
  </channel>
</rss>
