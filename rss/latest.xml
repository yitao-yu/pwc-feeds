<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 15 Oct 2024 21:09:03 +0000</lastBuildDate>
    <item>
      <title>AFlow: Automating Agentic Workflow Generation</title>
      <link>https://paperswithcode.com/paper/aflow-automating-agentic-workflow-generation</link>
      <description><![CDATA[Large language models (LLMs) have demonstrated remarkable potential in solving complex tasks across diverse domains, typically by employing agentic workflows that follow detailed instructions and operational sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aflow-automating-agentic-workflow-generation</guid>
    </item>
    <item>
      <title>StegaINR4MIH: steganography by implicit neural representation for multi-image hiding</title>
      <link>https://paperswithcode.com/paper/stegainr4mih-steganography-by-implicit-neural</link>
      <description><![CDATA[Multi-image hiding, which embeds multiple secret images into a cover image and is able to recover these images with high quality, has gradually become a research hotspot in the field of image steganography.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stegainr4mih-steganography-by-implicit-neural</guid>
    </item>
    <item>
      <title>LVD-2M: A Long-take Video Dataset with Temporally Dense Captions</title>
      <link>https://paperswithcode.com/paper/lvd-2m-a-long-take-video-dataset-with</link>
      <description><![CDATA[The efficacy of video generation models heavily depends on the quality of their training datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lvd-2m-a-long-take-video-dataset-with</guid>
    </item>
    <item>
      <title>Enhancing Attributed Graph Networks with Alignment and Uniformity Constraints for Session-based Recommendation</title>
      <link>https://paperswithcode.com/paper/enhancing-attributed-graph-networks-with</link>
      <description><![CDATA[In this paper, we propose a model-agnostic framework, named AttrGAU (Attributed Graph Networks with Alignment and Uniformity Constraints), to bring the MIA's superiority into existing attribute-agnostic models, to improve their accuracy and robustness for recommendation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-attributed-graph-networks-with</guid>
    </item>
    <item>
      <title>Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts</title>
      <link>https://paperswithcode.com/paper/efficiently-democratizing-medical-llms-for-50</link>
      <description><![CDATA[In order to leverage the generalization capability of multilingual LLMs to efficiently scale to more resource-constrained languages, we explore the internal information flow of LLMs from a multilingual perspective using Mixture of Experts (MoE) modularity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiently-democratizing-medical-llms-for-50</guid>
    </item>
    <item>
      <title>Get Rid of Task Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework</title>
      <link>https://paperswithcode.com/paper/get-rid-of-task-isolation-a-continuous-multi</link>
      <description><![CDATA[To this end, we argue that there is an essential to propose a Continuous Multi-task Spatio-Temporal learning framework (CMuST) to empower collective urban intelligence, which reforms the urban spatiotemporal learning from single-domain to cooperatively multi-dimensional and multi-task learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/get-rid-of-task-isolation-a-continuous-multi</guid>
    </item>
    <item>
      <title>Out-of-Bounding-Box Triggers: A Stealthy Approach to Cheat Object Detectors</title>
      <link>https://paperswithcode.com/paper/out-of-bounding-box-triggers-a-stealthy</link>
      <description><![CDATA[In recent years, the study of adversarial robustness in object detection systems, particularly those based on deep neural networks (DNNs), has become a pivotal area of research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/out-of-bounding-box-triggers-a-stealthy</guid>
    </item>
    <item>
      <title>GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs</title>
      <link>https://paperswithcode.com/paper/graphclip-enhancing-transferability-in-graph</link>
      <description><![CDATA[In this work, we propose the GraphCLIP framework to address these challenges by learning graph foundation models with strong cross-domain zero/few-shot transferability through a self-supervised contrastive graph-summary pretraining method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphclip-enhancing-transferability-in-graph</guid>
    </item>
    <item>
      <title>MagicEraser: Erasing Any Objects via Semantics-Aware Control</title>
      <link>https://paperswithcode.com/paper/magiceraser-erasing-any-objects-via-semantics</link>
      <description><![CDATA[However, the object erasure task, which is in increasing demand, aims to erase objects and generate harmonious background.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magiceraser-erasing-any-objects-via-semantics</guid>
    </item>
    <item>
      <title>How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective</title>
      <link>https://paperswithcode.com/paper/how-to-leverage-demonstration-data-in</link>
      <description><![CDATA[This paper introduces a novel generalized self-imitation learning ($\textbf{GSIL}$) framework, which effectively and efficiently aligns large language models with offline demonstration data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-to-leverage-demonstration-data-in</guid>
    </item>
    <item>
      <title>Queueing Matching Bandits with Preference Feedback</title>
      <link>https://paperswithcode.com/paper/queueing-matching-bandits-with-preference</link>
      <description><![CDATA[In this study, we consider multi-class multi-server asymmetric queueing systems consisting of $N$ queues on one side and $K$ servers on the other side, where jobs randomly arrive in queues at each time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/queueing-matching-bandits-with-preference</guid>
    </item>
    <item>
      <title>Effi-Code: Unleashing Code Efficiency in Language Models</title>
      <link>https://paperswithcode.com/paper/effi-code-unleashing-code-efficiency-in</link>
      <description><![CDATA[In this work, we present Effi-Code, an approach to enhancing code generation in LLMs that can improve both efficiency and correctness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effi-code-unleashing-code-efficiency-in</guid>
    </item>
    <item>
      <title>StatioCL: Contrastive Learning for Time Series via Non-Stationary and Temporal Contrast</title>
      <link>https://paperswithcode.com/paper/statiocl-contrastive-learning-for-time-series</link>
      <description><![CDATA[However, existing CL methods often introduce false negative pairs (FNPs) by neglecting inherent characteristics and then randomly selecting distinct segments as dissimilar pairs, leading to erroneous representation learning, reduced model performance, and overall inefficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/statiocl-contrastive-learning-for-time-series</guid>
    </item>
    <item>
      <title>FormalAlign: Automated Alignment Evaluation for Autoformalization</title>
      <link>https://paperswithcode.com/paper/formalalign-automated-alignment-evaluation</link>
      <description><![CDATA[To address this, we introduce \textsc{FormalAlign}, the first automated framework designed for evaluating the alignment between natural and formal languages in autoformalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/formalalign-automated-alignment-evaluation</guid>
    </item>
    <item>
      <title>Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance</title>
      <link>https://paperswithcode.com/paper/context-parametric-inversion-why-instruction</link>
      <description><![CDATA[However, even state-of-the-art models often struggle to follow the instruction, especially when the input context is not aligned with the model's parametric knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-parametric-inversion-why-instruction</guid>
    </item>
    <item>
      <title>MMCFND: Multimodal Multilingual Caption-aware Fake News Detection for Low-resource Indic Languages</title>
      <link>https://paperswithcode.com/paper/mmcfnd-multimodal-multilingual-caption-aware</link>
      <description><![CDATA[While there has been research on detecting fake news in high resource languages using multimodal approaches, methods for low resource Indic languages primarily rely on textual analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmcfnd-multimodal-multilingual-caption-aware</guid>
    </item>
    <item>
      <title>Predicting from Strings: Language Model Embeddings for Bayesian Optimization</title>
      <link>https://paperswithcode.com/paper/predicting-from-strings-language-model</link>
      <description><![CDATA[Bayesian Optimization is ubiquitous in the field of experimental design and blackbox optimization for improving search efficiency, but has been traditionally restricted to regression models which are only applicable to fixed search spaces and tabular input features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/predicting-from-strings-language-model</guid>
    </item>
    <item>
      <title>Coupled autoregressive active inference agents for control of multi-joint dynamical systems</title>
      <link>https://paperswithcode.com/paper/coupled-autoregressive-active-inference</link>
      <description><![CDATA[We propose an active inference agent to identify and control a mechanical system with multiple bodies connected by joints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coupled-autoregressive-active-inference</guid>
    </item>
    <item>
      <title>LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory</title>
      <link>https://paperswithcode.com/paper/longmemeval-benchmarking-chat-assistants-on</link>
      <description><![CDATA[Recent large language model (LLM)-driven chat assistant systems have integrated memory components to track user-assistant chat histories, enabling more accurate and personalized responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longmemeval-benchmarking-chat-assistants-on</guid>
    </item>
    <item>
      <title>Improved Depth Estimation of Bayesian Neural Networks</title>
      <link>https://paperswithcode.com/paper/improved-depth-estimation-of-bayesian-neural</link>
      <description><![CDATA[This paper proposes improvements over earlier work by Nazareth and Blei (2022) for estimating the depth of Bayesian neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-depth-estimation-of-bayesian-neural</guid>
    </item>
    <item>
      <title>TRESTLE: A Model of Concept Formation in Structured Domains</title>
      <link>https://paperswithcode.com/paper/trestle-a-model-of-concept-formation-in</link>
      <description><![CDATA[The literature on concept formation has demonstrated that humans are capable of learning concepts incrementally, with a variety of attribute types, and in both supervised and unsupervised settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trestle-a-model-of-concept-formation-in</guid>
    </item>
    <item>
      <title>Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?</title>
      <link>https://paperswithcode.com/paper/will-llms-replace-the-encoder-only-models-in</link>
      <description><![CDATA[Large Language Models (LLM) have recently shown promising performance in temporal reasoning tasks such as temporal question answering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/will-llms-replace-the-encoder-only-models-in</guid>
    </item>
    <item>
      <title>UniMatch V2: Pushing the Limit of Semi-Supervised Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/unimatch-v2-pushing-the-limit-of-semi</link>
      <description><![CDATA[Despite the achieved progress, strangely, even in this flourishing era of numerous powerful vision models, almost all SSS works are still sticking to 1) using outdated ResNet encoders with small-scale ImageNet-1K pre-training, and 2) evaluation on simple Pascal and Cityscapes datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unimatch-v2-pushing-the-limit-of-semi</guid>
    </item>
    <item>
      <title>Balanced Neural ODEs: nonlinear model order reduction and Koopman operator approxmations</title>
      <link>https://paperswithcode.com/paper/balanced-neural-odes-nonlinear-model-order</link>
      <description><![CDATA[Variational Autoencoders (VAEs) are a powerful framework for learning compact latent representations, while NeuralODEs excel in learning transient system dynamics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/balanced-neural-odes-nonlinear-model-order</guid>
    </item>
    <item>
      <title>Generalizable Humanoid Manipulation with Improved 3D Diffusion Policies</title>
      <link>https://paperswithcode.com/paper/generalizable-humanoid-manipulation-with</link>
      <description><![CDATA[Humanoid robots capable of autonomous operation in diverse environments have long been a goal for roboticists.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizable-humanoid-manipulation-with</guid>
    </item>
    <item>
      <title>Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature</title>
      <link>https://paperswithcode.com/paper/reproducible-machine-learning-based-voice</link>
      <description><![CDATA[We combine this feature set, containing data from the publicly available Saarbr\"ucken Voice Database (SVD), with preprocessing using the K-Means Synthetic Minority Over-Sampling Technique algorithm to address class imbalance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reproducible-machine-learning-based-voice</guid>
    </item>
    <item>
      <title>SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition</title>
      <link>https://paperswithcode.com/paper/sensorllm-aligning-large-language-models-with</link>
      <description><![CDATA[In this work, we bridge the gap between wearable sensor technology and personalized AI assistants by enabling Large Language Models (LLMs) to understand time-series tasks like human activity recognition (HAR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sensorllm-aligning-large-language-models-with</guid>
    </item>
    <item>
      <title>Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs</title>
      <link>https://paperswithcode.com/paper/free-video-llm-prompt-guided-visual</link>
      <description><![CDATA[Conversely, training-free approaches offer a more efficient alternative by adapting pre-trained image-LLMs models for video tasks without additional training, but they face inference efficiency bottlenecks due to the large number of visual tokens generated from video frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/free-video-llm-prompt-guided-visual</guid>
    </item>
    <item>
      <title>Local and Global Decoding in Text Generation</title>
      <link>https://paperswithcode.com/paper/local-and-global-decoding-in-text-generation</link>
      <description><![CDATA[Traditional methods, such as top-$k$ and top-$\pi$, apply local normalisation to the model's output distribution, which can distort it.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/local-and-global-decoding-in-text-generation</guid>
    </item>
    <item>
      <title>DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads</title>
      <link>https://paperswithcode.com/paper/duoattention-efficient-long-context-llm</link>
      <description><![CDATA[Based on this insight, we introduce DuoAttention, a framework that only applies a full KV cache to retrieval heads while using a light-weight, constant-length KV cache for streaming heads, which reduces both LLM's decoding and pre-filling memory and latency without compromising its long-context abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/duoattention-efficient-long-context-llm</guid>
    </item>
    <item>
      <title>Dynamical loss functions shape landscape topography and improve learning in artificial neural networks</title>
      <link>https://paperswithcode.com/paper/dynamical-loss-functions-shape-landscape</link>
      <description><![CDATA[Dynamical loss functions are derived from standard loss functions used in supervised classification tasks, but they are modified such that the contribution from each class periodically increases and decreases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamical-loss-functions-shape-landscape</guid>
    </item>
    <item>
      <title>LiveXiv -- A Multi-Modal Live Benchmark Based on Arxiv Papers Content</title>
      <link>https://paperswithcode.com/paper/livexiv-a-multi-modal-live-benchmark-based-on</link>
      <description><![CDATA[Moreover, we introduce an efficient evaluation approach that estimates the performance of all models on the evolving benchmark using evaluations of only a subset of models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/livexiv-a-multi-modal-live-benchmark-based-on</guid>
    </item>
    <item>
      <title>QueST: Querying Functional and Structural Niches on Spatial Transcriptomics Data via Contrastive Subgraph Embedding</title>
      <link>https://paperswithcode.com/paper/quest-querying-functional-and-structural</link>
      <description><![CDATA[To address this gap, we introduce QueST, a novel niche representation learning model designed for querying spatial niches across multiple samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quest-querying-functional-and-structural</guid>
    </item>
    <item>
      <title>Revisiting and Benchmarking Graph Autoencoders: A Contrastive Learning Perspective</title>
      <link>https://paperswithcode.com/paper/revisiting-and-benchmarking-graph</link>
      <description><![CDATA[Graph autoencoders (GAEs) are self-supervised learning models that can learn meaningful representations of graph-structured data by reconstructing the input graph from a low-dimensional latent space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-and-benchmarking-graph</guid>
    </item>
    <item>
      <title>ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection</title>
      <link>https://paperswithcode.com/paper/rosar-an-adversarial-re-training-framework</link>
      <description><![CDATA[This paper introduces ROSAR, a novel framework enhancing the robustness of deep learning object detection models tailored for side-scan sonar (SSS) images, generated by autonomous underwater vehicles using sonar sensors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rosar-an-adversarial-re-training-framework</guid>
    </item>
    <item>
      <title>HART: Efficient Visual Generation with Hybrid Autoregressive Transformer</title>
      <link>https://paperswithcode.com/paper/hart-efficient-visual-generation-with-hybrid</link>
      <description><![CDATA[To address these challenges, we present the hybrid tokenizer, which decomposes the continuous latents from the autoencoder into two components: discrete tokens representing the big picture and continuous tokens representing the residual components that cannot be represented by the discrete tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hart-efficient-visual-generation-with-hybrid</guid>
    </item>
    <item>
      <title>A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration</title>
      <link>https://paperswithcode.com/paper/a-consistency-aware-spot-guided-transformer</link>
      <description><![CDATA[Deep learning-based feature matching has shown great superiority for point cloud registration in the absence of pose priors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-consistency-aware-spot-guided-transformer</guid>
    </item>
    <item>
      <title>Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings</title>
      <link>https://paperswithcode.com/paper/adversarially-robust-out-of-distribution</link>
      <description><![CDATA[By incorporating a tailored loss function, we apply Lyapunov stability theory to ensure that both in-distribution (ID) and OOD data converge to stable equilibrium points within the dynamical system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarially-robust-out-of-distribution</guid>
    </item>
    <item>
      <title>Is Structure Dependence Shaped for Efficient Communication?: A Case Study on Coordination</title>
      <link>https://paperswithcode.com/paper/is-structure-dependence-shaped-for-efficient</link>
      <description><![CDATA[The results demonstrate that the language with the structure-dependent reduction operation is significantly more communicatively efficient than the counterfactual languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-structure-dependence-shaped-for-efficient</guid>
    </item>
    <item>
      <title>Domain-Conditioned Transformer for Fully Test-time Adaptation</title>
      <link>https://paperswithcode.com/paper/domain-conditioned-transformer-for-fully-test</link>
      <description><![CDATA[We observe that, when applying a transformer network model into a new domain, the self-attention profiles of image samples in the target domain deviate significantly from those in the source domain, which results in large performance degradation during domain changes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-conditioned-transformer-for-fully-test</guid>
    </item>
    <item>
      <title>SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing</title>
      <link>https://paperswithcode.com/paper/sensorbench-benchmarking-llms-in-coding-based</link>
      <description><![CDATA[Effective processing, interpretation, and management of sensor data have emerged as a critical component of cyber-physical systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sensorbench-benchmarking-llms-in-coding-based</guid>
    </item>
    <item>
      <title>TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control</title>
      <link>https://paperswithcode.com/paper/textctrl-diffusion-based-scene-text-editing</link>
      <description><![CDATA[Centred on content modification and style preservation, Scene Text Editing (STE) remains a challenging task despite considerable progress in text-to-image synthesis and text-driven image manipulation recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textctrl-diffusion-based-scene-text-editing</guid>
    </item>
    <item>
      <title>V2M: Visual 2-Dimensional Mamba for Image Representation Learning</title>
      <link>https://paperswithcode.com/paper/v2m-visual-2-dimensional-mamba-for-image</link>
      <description><![CDATA[Mamba has garnered widespread attention due to its flexible design and efficient hardware performance to process 1D sequences based on the state space model (SSM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/v2m-visual-2-dimensional-mamba-for-image</guid>
    </item>
    <item>
      <title>Denial-of-Service Poisoning Attacks against Large Language Models</title>
      <link>https://paperswithcode.com/paper/denial-of-service-poisoning-attacks-against</link>
      <description><![CDATA[To overcome this limitation, we propose poisoning-based DoS (P-DoS) attacks for LLMs, demonstrating that injecting a single poisoned sample designed for DoS purposes can break the output length limit.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/denial-of-service-poisoning-attacks-against</guid>
    </item>
    <item>
      <title>SAMPa: Sharpness-aware Minimization Parallelized</title>
      <link>https://paperswithcode.com/paper/sampa-sharpness-aware-minimization</link>
      <description><![CDATA[Sharpness-aware minimization (SAM) has been shown to improve the generalization of neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sampa-sharpness-aware-minimization</guid>
    </item>
    <item>
      <title>Self-Assessed Generation: Trustworthy Label Generation for Optical Flow and Stereo Matching in Real-world</title>
      <link>https://paperswithcode.com/paper/self-assessed-generation-trustworthy-label</link>
      <description><![CDATA[A significant challenge facing current optical flow and stereo methods is the difficulty in generalizing them well to the real world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-assessed-generation-trustworthy-label</guid>
    </item>
    <item>
      <title>The Epochal Sawtooth Effect: Unveiling Training Loss Oscillations in Adam and Other Optimizers</title>
      <link>https://paperswithcode.com/paper/the-epochal-sawtooth-effect-unveiling</link>
      <description><![CDATA[In this paper, we identify and analyze a recurring training loss pattern, which we term the \textit{Epochal Sawtooth Effect (ESE)}, commonly observed during training with adaptive gradient-based optimizers, particularly Adam optimizer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-epochal-sawtooth-effect-unveiling</guid>
    </item>
    <item>
      <title>TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE</title>
      <link>https://paperswithcode.com/paper/tabcf-counterfactual-explanations-for-tabular</link>
      <description><![CDATA[In the field of Explainable AI (XAI), counterfactual (CF) explanations are one prominent method to interpret a black-box model by suggesting changes to the input that would alter a prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tabcf-counterfactual-explanations-for-tabular</guid>
    </item>
    <item>
      <title>XAI-based Feature Selection for Improved Network Intrusion Detection Systems</title>
      <link>https://paperswithcode.com/paper/xai-based-feature-selection-for-improved</link>
      <description><![CDATA[Explainability and evaluation of AI models are crucial parts of the security of modern intrusion detection systems (IDS) in the network security field, yet they are lacking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xai-based-feature-selection-for-improved</guid>
    </item>
    <item>
      <title>The Implicit Bias of Structured State Space Models Can Be Poisoned With Clean Labels</title>
      <link>https://paperswithcode.com/paper/the-implicit-bias-of-structured-state-space</link>
      <description><![CDATA[Prior work argued that the implicit bias of SSMs leads to generalization in a setting where data is generated by a low dimensional teacher.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-implicit-bias-of-structured-state-space</guid>
    </item>
  </channel>
</rss>
