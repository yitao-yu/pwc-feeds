<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 09 Sep 2024 21:08:09 +0000</lastBuildDate>
    <item>
      <title>One-Shot Diffusion Mimicker for Handwritten Text Generation</title>
      <link>https://paperswithcode.com/paper/one-shot-diffusion-mimicker-for-handwritten</link>
      <description><![CDATA[Extensive experiments demonstrate that our method can successfully generate handwriting scripts with just one sample reference in multiple languages, even outperforming previous methods using over ten samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-shot-diffusion-mimicker-for-handwritten</guid>
    </item>
    <item>
      <title>Qihoo-T2X: An Efficiency-Focused Diffusion Transformer via Proxy Tokens for Text-to-Any-Task</title>
      <link>https://paperswithcode.com/paper/qihoo-t2x-an-efficiency-focused-diffusion</link>
      <description><![CDATA[The global self-attention mechanism in diffusion transformers involves redundant computation due to the sparse and redundant nature of visual information, and the attention map of tokens within a spatial window shows significant similarity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qihoo-t2x-an-efficiency-focused-diffusion</guid>
    </item>
    <item>
      <title>MixNet: Joining Force of Classical and Modern Approaches Toward the Comprehensive Pipeline in Motor Imagery EEG Classification</title>
      <link>https://paperswithcode.com/paper/mixnet-joining-force-of-classical-and-modern</link>
      <description><![CDATA[Recent advances in deep learning (DL) have significantly impacted motor imagery (MI)-based brain-computer interface (BCI) systems, enhancing the decoding of electroencephalography (EEG) signals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixnet-joining-force-of-classical-and-modern</guid>
    </item>
    <item>
      <title>UniDet3D: Multi-dataset Indoor 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/unidet3d-multi-dataset-indoor-3d-object</link>
      <description><![CDATA[Growing customer demand for smart solutions in robotics and augmented reality has attracted considerable attention to 3D object detection from point clouds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unidet3d-multi-dataset-indoor-3d-object</guid>
    </item>
    <item>
      <title>Enhancing Sequential Music Recommendation with Personalized Popularity Awareness</title>
      <link>https://paperswithcode.com/paper/enhancing-sequential-music-recommendation</link>
      <description><![CDATA[In the realm of music recommendation, sequential recommender systems have shown promise in capturing the dynamic nature of music consumption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-sequential-music-recommendation</guid>
    </item>
    <item>
      <title>SDformerFlow: Spatiotemporal swin spikeformer for event-based optical flow estimation</title>
      <link>https://paperswithcode.com/paper/sdformerflow-spatiotemporal-swin-spikeformer</link>
      <description><![CDATA[Our work is the first to make use of spikeformers for dense optical flow estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdformerflow-spatiotemporal-swin-spikeformer</guid>
    </item>
    <item>
      <title>DreamForge: Motion-Aware Autoregressive Video Generation for Multi-View Driving Scenes</title>
      <link>https://paperswithcode.com/paper/dreamforge-motion-aware-autoregressive-video</link>
      <description><![CDATA[Recent advances in diffusion models have significantly enhanced the cotrollable generation of streetscapes for and facilitated downstream perception and planning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamforge-motion-aware-autoregressive-video</guid>
    </item>
    <item>
      <title>Accelerating Training with Neuron Interaction and Nowcasting Networks</title>
      <link>https://paperswithcode.com/paper/accelerating-training-with-neuron-interaction</link>
      <description><![CDATA[By accurately modeling neuron connectivity, we allow NiNo to accelerate Adam training by up to 50\% in vision and language tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-training-with-neuron-interaction</guid>
    </item>
    <item>
      <title>Structure and dynamics of growing networks of Reddit threads</title>
      <link>https://paperswithcode.com/paper/structure-and-dynamics-of-growing-networks-of</link>
      <description><![CDATA[We model threads of this community as complex networks of user interactions growing in time, and we analyze the evolution of their structural properties.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structure-and-dynamics-of-growing-networks-of</guid>
    </item>
    <item>
      <title>LITE: A Paradigm Shift in Multi-Object Tracking with Efficient ReID Feature Integration</title>
      <link>https://paperswithcode.com/paper/lite-a-paradigm-shift-in-multi-object</link>
      <description><![CDATA[The Lightweight Integrated Tracking-Feature Extraction (LITE) paradigm is introduced as a novel multi-object tracking (MOT) approach.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lite-a-paradigm-shift-in-multi-object</guid>
    </item>
    <item>
      <title>Residual Stream Analysis with Multi-Layer SAEs</title>
      <link>https://paperswithcode.com/paper/residual-stream-analysis-with-multi-layer</link>
      <description><![CDATA[Interestingly, while a single SAE feature is active at different layers for different prompts, for a single prompt, we find that a single feature is far more likely to be active at a single layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/residual-stream-analysis-with-multi-layer</guid>
    </item>
    <item>
      <title>Introducing a Class-Aware Metric for Monocular Depth Estimation: An Automotive Perspective</title>
      <link>https://paperswithcode.com/paper/introducing-a-class-aware-metric-for</link>
      <description><![CDATA[Within this paper, we present a novel approach for the evaluation of depth estimation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/introducing-a-class-aware-metric-for</guid>
    </item>
    <item>
      <title>Train Till You Drop: Towards Stable and Robust Source-free Unsupervised 3D Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/train-till-you-drop-towards-stable-and-robust</link>
      <description><![CDATA[We tackle the challenging problem of source-free unsupervised domain adaptation (SFUDA) for 3D semantic segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/train-till-you-drop-towards-stable-and-robust</guid>
    </item>
    <item>
      <title>Hybrid Cost Volume for Memory-Efficient Optical Flow</title>
      <link>https://paperswithcode.com/paper/hybrid-cost-volume-for-memory-efficient</link>
      <description><![CDATA[Compared to the recurrent flow methods based the all-pairs cost volumes, our HCVFlow significantly reduces memory consumption while ensuring high accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hybrid-cost-volume-for-memory-efficient</guid>
    </item>
    <item>
      <title>RCNet: Deep Recurrent Collaborative Network for Multi-View Low-Light Image Enhancement</title>
      <link>https://paperswithcode.com/paper/rcnet-deep-recurrent-collaborative-network</link>
      <description><![CDATA[Recent single image-based enhancement methods may not be able to provide consistently desirable restoration performance for all views due to the ignorance of potential feature correspondence among different views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rcnet-deep-recurrent-collaborative-network</guid>
    </item>
    <item>
      <title>CoxKAN: Kolmogorov-Arnold Networks for Interpretable, High-Performance Survival Analysis</title>
      <link>https://paperswithcode.com/paper/coxkan-kolmogorov-arnold-networks-for</link>
      <description><![CDATA[Evaluation on the 9 real datasets show that CoxKAN consistently outperforms the Cox proportional hazards model and achieves performance that is superior or comparable to that of tuned MLPs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coxkan-kolmogorov-arnold-networks-for</guid>
    </item>
    <item>
      <title>Multi-Programming Language Ensemble for Code Generation in Large Language Model</title>
      <link>https://paperswithcode.com/paper/multi-programming-language-ensemble-for-code</link>
      <description><![CDATA[This multi-language ensemble strategy leverages the complementary strengths of different programming languages, enabling the model to produce more accurate and robust code.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-programming-language-ensemble-for-code</guid>
    </item>
    <item>
      <title>Goal-Reaching Policy Learning from Non-Expert Observations via Effective Subgoal Guidance</title>
      <link>https://paperswithcode.com/paper/goal-reaching-policy-learning-from-non-expert</link>
      <description><![CDATA[To achieve our goal, we propose a novel subgoal guidance learning strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/goal-reaching-policy-learning-from-non-expert</guid>
    </item>
    <item>
      <title>MpoxMamba: A Grouped Mamba-based Lightweight Hybrid Network for Mpox Detection</title>
      <link>https://paperswithcode.com/paper/mpoxmamba-a-grouped-mamba-based-lightweight</link>
      <description><![CDATA[Due to the lack of effective mpox detection tools, the mpox virus continues to spread worldwide and has once again been declared a public health emergency of international concern by the World Health Organization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mpoxmamba-a-grouped-mamba-based-lightweight</guid>
    </item>
    <item>
      <title>A Unified Approach to Inferring Chemical Compounds with the Desired Aqueous Solubility</title>
      <link>https://paperswithcode.com/paper/a-unified-approach-to-inferring-chemical</link>
      <description><![CDATA[Aqueous solubility (AS) is a key physiochemical property that plays a crucial role in drug discovery and material design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-unified-approach-to-inferring-chemical</guid>
    </item>
    <item>
      <title>Smooth-edged Perturbations Improve Perturbation-based Image Explanations</title>
      <link>https://paperswithcode.com/paper/smooth-edged-perturbations-improve</link>
      <description><![CDATA[Due to the intractability of perturbing each pixel individually, images are typically attributed to larger segments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smooth-edged-perturbations-improve</guid>
    </item>
    <item>
      <title>FS-MedSAM2: Exploring the Potential of SAM2 for Few-Shot Medical Image Segmentation without Fine-tuning</title>
      <link>https://paperswithcode.com/paper/fs-medsam2-exploring-the-potential-of-sam2</link>
      <description><![CDATA[The Segment Anything Model 2 (SAM2) has recently demonstrated exceptional performance in zero-shot prompt segmentation for natural images and videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fs-medsam2-exploring-the-potential-of-sam2</guid>
    </item>
    <item>
      <title>Standing on the shoulders of giants</title>
      <link>https://paperswithcode.com/paper/standing-on-the-shoulders-of-giants-1</link>
      <description><![CDATA[Although fundamental to the advancement of Machine Learning, the classic evaluation metrics extracted from the confusion matrix, such as precision and F1, are limited.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/standing-on-the-shoulders-of-giants-1</guid>
    </item>
    <item>
      <title>Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/improving-uncertainty-error-correspondence-in</link>
      <description><![CDATA[Previous work has investigated the correspondence between uncertainty and error, however, no work has been done on improving the "utility" of Bayesian uncertainty maps such that it is only present in inaccurate regions and not in the accurate ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-uncertainty-error-correspondence-in</guid>
    </item>
    <item>
      <title>Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding</title>
      <link>https://paperswithcode.com/paper/lexicon3d-probing-visual-foundation-models</link>
      <description><![CDATA[To address this issue, we present a comprehensive study that probes various visual encoding models for 3D scene understanding, identifying the strengths and limitations of each model across different scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lexicon3d-probing-visual-foundation-models</guid>
    </item>
    <item>
      <title>KAN See In the Dark</title>
      <link>https://paperswithcode.com/paper/kan-see-in-the-dark</link>
      <description><![CDATA[Existing low-light image enhancement methods are difficult to fit the complex nonlinear relationship between normal and low-light images due to uneven illumination and noise effects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kan-see-in-the-dark</guid>
    </item>
    <item>
      <title>Sirius: Contextual Sparsity with Correction for Efficient LLMs</title>
      <link>https://paperswithcode.com/paper/sirius-contextual-sparsity-with-correction</link>
      <description><![CDATA[However, after a comprehensive evaluation of contextual sparsity methods on various complex generation tasks, we find that although CS succeeds in prompt-understanding tasks, CS significantly degrades the model performance for reasoning, deduction, and knowledge-based tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sirius-contextual-sparsity-with-correction</guid>
    </item>
    <item>
      <title>TCDiff: Triple Condition Diffusion Model with 3D Constraints for Stylizing Synthetic Faces</title>
      <link>https://paperswithcode.com/paper/tcdiff-triple-condition-diffusion-model-with</link>
      <description><![CDATA[In this paper, we propose a Triple Condition Diffusion Model (TCDiff) to improve face style transfer from real to synthetic faces through 2D and 3D facial constraints, enhancing face identity consistency while keeping the necessary high intra-class variance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tcdiff-triple-condition-diffusion-model-with</guid>
    </item>
    <item>
      <title>A method to benchmark high-dimensional process drift detection</title>
      <link>https://paperswithcode.com/paper/a-method-to-benchmark-high-dimensional</link>
      <description><![CDATA[Process curves are multi-variate finite time series data coming from manufacturing processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-method-to-benchmark-high-dimensional</guid>
    </item>
    <item>
      <title>The representation landscape of few-shot learning and fine-tuning in large language models</title>
      <link>https://paperswithcode.com/paper/the-representation-landscape-of-few-shot</link>
      <description><![CDATA[More specifically, we compare how LLMs solve the same question-answering task, finding that ICL and SFT create very different internal structures, in both cases undergoing a sharp transition in the middle of the network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-representation-landscape-of-few-shot</guid>
    </item>
    <item>
      <title>Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities</title>
      <link>https://paperswithcode.com/paper/fine-tuning-large-language-models-for-domain-1</link>
      <description><![CDATA[The advancement of Large Language Models (LLMs) for domain applications in fields such as materials science and engineering depends on the development of fine-tuning strategies that adapt models for specialized, technical capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-large-language-models-for-domain-1</guid>
    </item>
    <item>
      <title>ELO-Rated Sequence Rewards: Advancing Reinforcement Learning Models</title>
      <link>https://paperswithcode.com/paper/elo-rated-sequence-rewards-advancing</link>
      <description><![CDATA[Reinforcement Learning (RL) is highly dependent on the meticulous design of the reward function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elo-rated-sequence-rewards-advancing</guid>
    </item>
    <item>
      <title>Few-shot Adaptation of Medical Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/few-shot-adaptation-of-medical-vision</link>
      <description><![CDATA[Integrating image and text data through multi-modal learning has emerged as a new approach in medical imaging research, following its successful deployment in computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/few-shot-adaptation-of-medical-vision</guid>
    </item>
    <item>
      <title>Tissue Concepts: supervised foundation models in computational pathology</title>
      <link>https://paperswithcode.com/paper/tissue-concepts-supervised-foundation-models</link>
      <description><![CDATA[The proposed method is based on multi-task learning to train a joint encoder, by combining 16 different classification, segmentation, and detection tasks on a total of 912, 000 patches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tissue-concepts-supervised-foundation-models</guid>
    </item>
    <item>
      <title>Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models</title>
      <link>https://paperswithcode.com/paper/debate-on-graph-a-flexible-and-reliable</link>
      <description><![CDATA[Furthermore, the integration experiments with various LLMs on the mentioned datasets highlight the flexibility of DoG.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/debate-on-graph-a-flexible-and-reliable</guid>
    </item>
    <item>
      <title>MVTN: A Multiscale Video Transformer Network for Hand Gesture Recognition</title>
      <link>https://paperswithcode.com/paper/mvtn-a-multiscale-video-transformer-network</link>
      <description><![CDATA[In this paper, we introduce a novel Multiscale Video Transformer Network (MVTN) for dynamic hand gesture recognition, since multiscale features can extract features with variable size, pose, and shape of hand which is a challenge in hand gesture recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mvtn-a-multiscale-video-transformer-network</guid>
    </item>
    <item>
      <title>CDM: A Reliable Metric for Fair and Accurate Formula Recognition Evaluation</title>
      <link>https://paperswithcode.com/paper/cdm-a-reliable-metric-for-fair-and-accurate</link>
      <description><![CDATA[Such a spatially-aware and character-matching method offers a more accurate and equitable evaluation compared with previous BLEU and Edit Distance metrics that rely solely on text-based character matching.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cdm-a-reliable-metric-for-fair-and-accurate</guid>
    </item>
    <item>
      <title>iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models</title>
      <link>https://paperswithcode.com/paper/itext2kg-incremental-knowledge-graphs</link>
      <description><![CDATA[Our method demonstrates superior performance compared to baseline methods across three scenarios: converting scientific papers to graphs, websites to graphs, and CVs to graphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/itext2kg-incremental-knowledge-graphs</guid>
    </item>
    <item>
      <title>Practical Forecasting of Cryptocoins Timeseries using Correlation Patterns</title>
      <link>https://paperswithcode.com/paper/practical-forecasting-of-cryptocoins</link>
      <description><![CDATA[We study the causality between the trends, and exploit the derived correlations to understand the accuracy of state-of-the-art forecasting techniques for time series modeling (e. g., GBMs, LSTM and GRU) of correlated cryptocoins.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/practical-forecasting-of-cryptocoins</guid>
    </item>
    <item>
      <title>Labeled-to-Unlabeled Distribution Alignment for Partially-Supervised Multi-Organ Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/labeled-to-unlabeled-distribution-alignment</link>
      <description><![CDATA[However, the limited availability of labeled foreground organs and the absence of supervision to distinguish unlabeled foreground organs from the background pose a significant challenge, which leads to a distribution mismatch between labeled and unlabeled pixels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/labeled-to-unlabeled-distribution-alignment</guid>
    </item>
    <item>
      <title>HGAMN: Heterogeneous Graph Attention Matching Network for Multilingual POI Retrieval at Baidu Maps</title>
      <link>https://paperswithcode.com/paper/hgamn-heterogeneous-graph-attention-matching</link>
      <description><![CDATA[To mitigate challenge \#2, we construct edges between POI and query nodes based on the co-occurrences between queries and POIs, where queries in different languages and formulations can be aggregated for individual POIs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hgamn-heterogeneous-graph-attention-matching</guid>
    </item>
    <item>
      <title>A practical approach to evaluating the adversarial distance for machine learning classifiers</title>
      <link>https://paperswithcode.com/paper/a-practical-approach-to-evaluating-the</link>
      <description><![CDATA[Robustness is critical for machine learning (ML) classifiers to ensure consistent performance in real-world applications where models may encounter corrupted or adversarial inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-practical-approach-to-evaluating-the</guid>
    </item>
    <item>
      <title>LMLT: Low-to-high Multi-Level Vision Transformer for Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/lmlt-low-to-high-multi-level-vision</link>
      <description><![CDATA[LMLT divides image features along the channel dimension, gradually reduces spatial size for lower heads, and applies self-attention to each head.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lmlt-low-to-high-multi-level-vision</guid>
    </item>
    <item>
      <title>Text-Guided Mixup Towards Long-Tailed Image Categorization</title>
      <link>https://paperswithcode.com/paper/text-guided-mixup-towards-long-tailed-image</link>
      <description><![CDATA[In many real-world applications, the frequency distribution of class labels for training data can exhibit a long-tailed distribution, which challenges traditional approaches of training deep neural networks that require heavy amounts of balanced data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-guided-mixup-towards-long-tailed-image</guid>
    </item>
    <item>
      <title>iSeg: An Iterative Refinement-based Framework for Training-free Segmentation</title>
      <link>https://paperswithcode.com/paper/iseg-an-iterative-refinement-based-framework</link>
      <description><![CDATA[To address this, we propose an iterative refinement framework for training-free segmentation, named iSeg, having an entropy-reduced self-attention module which utilizes a gradient descent scheme to reduce the entropy of self-attention map, thereby suppressing the weak responses corresponding to irrelevant global information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/iseg-an-iterative-refinement-based-framework</guid>
    </item>
    <item>
      <title>Unveiling Context-Related Anomalies: Knowledge Graph Empowered Decoupling of Scene and Action for Human-Related Video Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/unveiling-context-related-anomalies-knowledge</link>
      <description><![CDATA[In short, current methods struggle to integrate low-level visual and high-level action features, leading to poor anomaly detection in varied and complex scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unveiling-context-related-anomalies-knowledge</guid>
    </item>
    <item>
      <title>Non-Uniform Illumination Attack for Fooling Convolutional Neural Networks</title>
      <link>https://paperswithcode.com/paper/non-uniform-illumination-attack-for-fooling</link>
      <description><![CDATA[This strategy seeks to bolster CNN models' resilience against NUI attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/non-uniform-illumination-attack-for-fooling</guid>
    </item>
    <item>
      <title>Bi-capacity Choquet Integral for Sensor Fusion with Label Uncertainty</title>
      <link>https://paperswithcode.com/paper/bi-capacity-choquet-integral-for-sensor</link>
      <description><![CDATA[This allows for extended non-linear interactions between the sensor sources and can lead to interesting fusion results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bi-capacity-choquet-integral-for-sensor</guid>
    </item>
    <item>
      <title>LowFormer: Hardware Efficient Design for Convolutional Transformer Backbones</title>
      <link>https://paperswithcode.com/paper/lowformer-hardware-efficient-design-for</link>
      <description><![CDATA[We analyzed common modules and architectural design choices for backbones not in terms of MACs, but rather in actual throughput and latency, as the combination of the latter two is a better representation of the efficiency of models in real applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lowformer-hardware-efficient-design-for</guid>
    </item>
    <item>
      <title>Surface-Centric Modeling for High-Fidelity Generalizable Neural Surface Reconstruction</title>
      <link>https://paperswithcode.com/paper/surface-centric-modeling-for-high-fidelity</link>
      <description><![CDATA[To this end, we propose SuRF, a new Surface-centric framework that incorporates a new Region sparsification based on a matching Field, achieving good trade-offs between performance, efficiency and scalability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surface-centric-modeling-for-high-fidelity</guid>
    </item>
  </channel>
</rss>
