<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 25 Feb 2025 21:09:18 +0000</lastBuildDate>
    <item>
      <title>R1-OnevisionAn Open-Source Multimodal Large Language Model Capable of Deep Reasoning</title>
      <link>https://paperswithcode.com/paper/r1-onevision-an-open-source-multimodal-large</link>
      <description><![CDATA[R1-OneVision is a versatile multimodal reasoning large model, designed to tackle complex visual reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r1-onevision-an-open-source-multimodal-large</guid>
    </item>
    <item>
      <title>Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/fed-sb-a-silver-bullet-for-extreme</link>
      <description><![CDATA[However, federated fine-tuning using LoRA is challenging due to suboptimal updates arising from traditional federated averaging of individual adapters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fed-sb-a-silver-bullet-for-extreme</guid>
    </item>
    <item>
      <title>VaViM and VaVAM: Autonomous Driving through Video Generative Modeling</title>
      <link>https://paperswithcode.com/paper/vavim-and-vavam-autonomous-driving-through</link>
      <description><![CDATA[We explore the potential of large-scale generative video models for autonomous driving, introducing an open-source auto-regressive video model (VaViM) and its companion video-action model (VaVAM) to investigate how video pre-training transfers to real-world driving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vavim-and-vavam-autonomous-driving-through</guid>
    </item>
    <item>
      <title>KnowZRel: Common Sense Knowledge-based Zero-Shot Relationship Retrieval for Generalised Scene Graph Generation</title>
      <link>https://paperswithcode.com/paper/knowzrel-common-sense-knowledge-based-zero</link>
      <description><![CDATA[The generalisability of Scene Graph Generation (SGG) methods is crucial for reliable reasoning and real-world applicability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/knowzrel-common-sense-knowledge-based-zero</guid>
    </item>
    <item>
      <title>Plan-over-Graph: Towards Parallelable LLM Agent Schedule</title>
      <link>https://paperswithcode.com/paper/plan-over-graph-towards-parallelable-llm</link>
      <description><![CDATA[The model then understands this task graph as input and generates a plan for parallel execution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plan-over-graph-towards-parallelable-llm</guid>
    </item>
    <item>
      <title>InstructAgent: Building User Controllable Recommender via LLM Agent</title>
      <link>https://paperswithcode.com/paper/instructagent-building-user-controllable</link>
      <description><![CDATA[Traditional recommender systems usually take the user-platform paradigm, where users are directly exposed under the control of the platform's recommendation algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructagent-building-user-controllable</guid>
    </item>
    <item>
      <title>How Much Knowledge Can You Pack into a LoRA Adapter without Harming LLM?</title>
      <link>https://paperswithcode.com/paper/how-much-knowledge-can-you-pack-into-a-lora-1</link>
      <description><![CDATA[The performance of Large Language Models (LLMs) on many tasks is greatly limited by the knowledge learned during pre-training and stored in the model's parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-much-knowledge-can-you-pack-into-a-lora-1</guid>
    </item>
    <item>
      <title>seqKAN: Sequence processing with Kolmogorov-Arnold Networks</title>
      <link>https://paperswithcode.com/paper/seqkan-sequence-processing-with-kolmogorov</link>
      <description><![CDATA[Kolmogorov-Arnold Networks (KANs) have been recently proposed as a machine learning framework that is more interpretable and controllable than the multi-layer perceptron.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seqkan-sequence-processing-with-kolmogorov</guid>
    </item>
    <item>
      <title>Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis</title>
      <link>https://paperswithcode.com/paper/tree-of-debate-multi-persona-debate-trees</link>
      <description><![CDATA[With the exponential growth of research facilitated by modern technology and improved accessibility, scientific discoveries have become increasingly fragmented within and across fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tree-of-debate-multi-persona-debate-trees</guid>
    </item>
    <item>
      <title>MedFuncta: Modality-Agnostic Representations Based on Efficient Neural Fields</title>
      <link>https://paperswithcode.com/paper/medfuncta-modality-agnostic-representations</link>
      <description><![CDATA[Recent research in medical image analysis with deep learning almost exclusively focuses on grid- or voxel-based data representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medfuncta-modality-agnostic-representations</guid>
    </item>
    <item>
      <title>CLIPPER: Compression enables long-context synthetic data generation</title>
      <link>https://paperswithcode.com/paper/clipper-compression-enables-long-context</link>
      <description><![CDATA[We introduce CLIPPER, a compression-based approach for generating synthetic data tailored to narrative claim verification - a task that requires reasoning over a book to verify a given claim.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clipper-compression-enables-long-context</guid>
    </item>
    <item>
      <title>Self-Improvement Towards Pareto Optimality: Mitigating Preference Conflicts in Multi-Objective Alignment</title>
      <link>https://paperswithcode.com/paper/self-improvement-towards-pareto-optimality</link>
      <description><![CDATA[To efficiently obtain and utilize such responses, we propose a self-improving DPO framework that enables LLMs to self-generate and select Pareto-optimal responses for self-supervised preference alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-improvement-towards-pareto-optimality</guid>
    </item>
    <item>
      <title>Exploring RWKV for Sentence Embeddings: Layer-wise Analysis and Baseline Comparison for Semantic Similarity</title>
      <link>https://paperswithcode.com/paper/exploring-rwkv-for-sentence-embeddings-layer</link>
      <description><![CDATA[This paper investigates the efficacy of RWKV, a novel language model architecture known for its linear attention mechanism, for generating sentence embeddings in a zero-shot setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-rwkv-for-sentence-embeddings-layer</guid>
    </item>
    <item>
      <title>PredictaBoard: Benchmarking LLM Score Predictability</title>
      <link>https://paperswithcode.com/paper/predictaboard-benchmarking-llm-score</link>
      <description><![CDATA[Despite possessing impressive skills, Large Language Models (LLMs) often fail unpredictably, demonstrating inconsistent success in even basic common sense reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/predictaboard-benchmarking-llm-score</guid>
    </item>
    <item>
      <title>LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/longwriter-v-enabling-ultra-long-and-high</link>
      <description><![CDATA[Moreover, to achieve long outputs that maintain high-fidelity to the input images, we employ Direct Preference Optimization (DPO) to the SFT model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longwriter-v-enabling-ultra-long-and-high</guid>
    </item>
    <item>
      <title>Prompt-to-Leaderboard</title>
      <link>https://paperswithcode.com/paper/prompt-to-leaderboard</link>
      <description><![CDATA[To address this, we propose Prompt-to-Leaderboard (P2L), a method that produces leaderboards specific to a prompt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-to-leaderboard</guid>
    </item>
    <item>
      <title>CER: Confidence Enhanced Reasoning in LLMs</title>
      <link>https://paperswithcode.com/paper/cer-confidence-enhanced-reasoning-in-llms</link>
      <description><![CDATA[We propose an approach that encourages multi-step reasoning in LLMs and quantify the confidence of intermediate answers such as numerical results in mathematical reasoning and proper nouns in open-domain generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cer-confidence-enhanced-reasoning-in-llms</guid>
    </item>
    <item>
      <title>Generating $Ï€$-Functional Molecules Using STGG+ with Active Learning</title>
      <link>https://paperswithcode.com/paper/generating-p-functional-molecules-using-stgg</link>
      <description><![CDATA[Our results demonstrate that our method is highly effective in generating novel molecules with high oscillator strength, contrary to existing methods such as reinforcement learning (RL) methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-p-functional-molecules-using-stgg</guid>
    </item>
    <item>
      <title>Time Travel: A Comprehensive Benchmark to Evaluate LMMs on Historical and Cultural Artifacts</title>
      <link>https://paperswithcode.com/paper/time-travel-a-comprehensive-benchmark-to</link>
      <description><![CDATA[Our goal is to establish AI as a reliable partner in preserving cultural heritage, ensuring that technological advancements contribute meaningfully to historical discovery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/time-travel-a-comprehensive-benchmark-to</guid>
    </item>
    <item>
      <title>Multimodal RewardBench: Holistic Evaluation of Reward Models for Vision Language Models</title>
      <link>https://paperswithcode.com/paper/multimodal-rewardbench-holistic-evaluation-of</link>
      <description><![CDATA[Reward models play an essential role in training vision-language models (VLMs) by assessing output quality to enable aligning with human preferences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-rewardbench-holistic-evaluation-of</guid>
    </item>
    <item>
      <title>BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction</title>
      <link>https://paperswithcode.com/paper/bp-sgcn-behavioral-pseudo-label-informed</link>
      <description><![CDATA[In this work, we introduce the behavioral pseudo-labels that effectively capture the behavior distributions of pedestrians and heterogeneous agents solely based on their motion features, significantly improving the accuracy of trajectory prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bp-sgcn-behavioral-pseudo-label-informed</guid>
    </item>
    <item>
      <title>Integrating Extra Modality Helps Segmentor Find Camouflaged Objects Well</title>
      <link>https://paperswithcode.com/paper/integrating-extra-modality-helps-segmentor</link>
      <description><![CDATA[UniLearner exploits multimodal data unrelated to the COS task to improve the segmentation ability of the COS models by generating pseudo-modal content and cross-modal semantic associations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/integrating-extra-modality-helps-segmentor</guid>
    </item>
    <item>
      <title>Revealing and Mitigating Over-Attention in Knowledge Editing</title>
      <link>https://paperswithcode.com/paper/revealing-and-mitigating-over-attention-in</link>
      <description><![CDATA[Large Language Models have demonstrated superior performance across a wide range of tasks, but they still exhibit undesirable errors due to incorrect knowledge learned from the training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revealing-and-mitigating-over-attention-in</guid>
    </item>
    <item>
      <title>Preordering: A hybrid of correlation clustering and partial ordering</title>
      <link>https://paperswithcode.com/paper/preordering-a-hybrid-of-correlation</link>
      <description><![CDATA[We discuss the preordering problem, a joint relaxation of the correlation clustering problem and the partial ordering problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/preordering-a-hybrid-of-correlation</guid>
    </item>
    <item>
      <title>Enhancing Language Multi-Agent Learning with Multi-Agent Credit Re-Assignment for Interactive Environment Generalization</title>
      <link>https://paperswithcode.com/paper/enhancing-language-multi-agent-learning-with</link>
      <description><![CDATA[To address these issues, we propose CollabUIAgents, a multi-agent reinforcement learning framework with a novel multi-agent credit re-assignment (CR) strategy, assigning process rewards with LLMs rather than environment-specific rewards and learning with synthesized preference data, in order to foster generalizable, collaborative behaviors among the role-free agents' policies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-language-multi-agent-learning-with</guid>
    </item>
    <item>
      <title>S*: Test Time Scaling for Code Generation</title>
      <link>https://paperswithcode.com/paper/s-test-time-scaling-for-code-generation</link>
      <description><![CDATA[Increasing test-time compute for LLMs shows promise across domains but remains underexplored in code generation, despite extensive study in math.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s-test-time-scaling-for-code-generation</guid>
    </item>
    <item>
      <title>Port-Hamiltonian Neural Networks with Output Error Noise Models</title>
      <link>https://paperswithcode.com/paper/port-hamiltonian-neural-networks-with-output</link>
      <description><![CDATA[However, their direct application to engineering systems is often challenged by practical issues, including the presence of external inputs, dissipation, and noisy measurements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/port-hamiltonian-neural-networks-with-output</guid>
    </item>
    <item>
      <title>Information Types in Product Reviews</title>
      <link>https://paperswithcode.com/paper/information-types-in-product-reviews</link>
      <description><![CDATA[Information in text is communicated in a way that supports a goal for its reader.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/information-types-in-product-reviews</guid>
    </item>
    <item>
      <title>EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations</title>
      <link>https://paperswithcode.com/paper/equivamap-leveraging-llms-for-automatic</link>
      <description><![CDATA[A fundamental problem in combinatorial optimization is identifying equivalent formulations, which can lead to more efficient solution strategies and deeper insights into a problem's computational complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/equivamap-leveraging-llms-for-automatic</guid>
    </item>
    <item>
      <title>FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis</title>
      <link>https://paperswithcode.com/paper/fetalclip-a-visual-language-foundation-model</link>
      <description><![CDATA[Foundation models are becoming increasingly effective in the medical domain, offering pre-trained models on large datasets that can be readily adapted for downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fetalclip-a-visual-language-foundation-model</guid>
    </item>
    <item>
      <title>Evaluating Precise Geolocation Inference Capabilities of Vision Language Models</title>
      <link>https://paperswithcode.com/paper/evaluating-precise-geolocation-inference</link>
      <description><![CDATA[Our findings establish that modern foundation VLMs can act as powerful image geolocation tools, without being specifically trained for this task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-precise-geolocation-inference</guid>
    </item>
    <item>
      <title>H3DE-Net: Efficient and Accurate 3D Landmark Detection in Medical Imaging</title>
      <link>https://paperswithcode.com/paper/h3de-net-efficient-and-accurate-3d-landmark</link>
      <description><![CDATA[To our knowledge, H3DE-Net is the first 3D landmark detection model that integrates such a lightweight attention mechanism with CNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h3de-net-efficient-and-accurate-3d-landmark</guid>
    </item>
    <item>
      <title>PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</title>
      <link>https://paperswithcode.com/paper/pc-agent-a-hierarchical-multi-agent</link>
      <description><![CDATA[From the decision-making perspective, to handle complex user instructions and interdependent subtasks more effectively, we propose a hierarchical multi-agent collaboration architecture that decomposes decision-making processes into Instruction-Subtask-Action levels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pc-agent-a-hierarchical-multi-agent</guid>
    </item>
    <item>
      <title>MedVAE: Efficient Automated Interpretation of Medical Images with Large-Scale Generalizable Autoencoders</title>
      <link>https://paperswithcode.com/paper/medvae-efficient-automated-interpretation-of</link>
      <description><![CDATA[In this work, we address the challenge of downsizing medical images in order to improve downstream computational efficiency while preserving clinically-relevant features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medvae-efficient-automated-interpretation-of</guid>
    </item>
    <item>
      <title>LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention</title>
      <link>https://paperswithcode.com/paper/lserve-efficient-long-sequence-llm-serving</link>
      <description><![CDATA[On average, LServe accelerates LLM prefilling by up to 2. 9x and decoding by 1. 3-2. 1x over vLLM, maintaining long-context accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lserve-efficient-long-sequence-llm-serving</guid>
    </item>
    <item>
      <title>Spatial and Frequency Domain Adaptive Fusion Network for Image Deblurring</title>
      <link>https://paperswithcode.com/paper/spatial-and-frequency-domain-adaptive-fusion</link>
      <description><![CDATA[Specifically, we design a gated spatial-frequency domain feature fusion block (GSFFBlock), which consists of three key components: a spatial domain information module, a frequency domain information dynamic generation module (FDGM), and a gated fusion module (GFM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatial-and-frequency-domain-adaptive-fusion</guid>
    </item>
    <item>
      <title>From RAG to Memory: Non-Parametric Continual Learning for Large Language Models</title>
      <link>https://paperswithcode.com/paper/from-rag-to-memory-non-parametric-continual</link>
      <description><![CDATA[We address this unintended deterioration and propose HippoRAG 2, a framework that outperforms standard RAG comprehensively on factual, sense-making, and associative memory tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-rag-to-memory-non-parametric-continual</guid>
    </item>
    <item>
      <title>Accurate Forgetting for Heterogeneous Federated Continual Learning</title>
      <link>https://paperswithcode.com/paper/accurate-forgetting-for-heterogeneous</link>
      <description><![CDATA[Bridging FL and continual learning (CL) gives rise to a challenging practical problem: federated continual learning (FCL).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accurate-forgetting-for-heterogeneous</guid>
    </item>
    <item>
      <title>Aligning LLMs to Ask Good Questions A Case Study in Clinical Reasoning</title>
      <link>https://paperswithcode.com/paper/aligning-llms-to-ask-good-questions-a-case</link>
      <description><![CDATA[Large language models (LLMs) often fail to ask effective questions under uncertainty, making them unreliable in domains where proactive information-gathering is essential for decisionmaking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-llms-to-ask-good-questions-a-case</guid>
    </item>
    <item>
      <title>TritonBench: Benchmarking Large Language Model Capabilities for Generating Triton Operators</title>
      <link>https://paperswithcode.com/paper/tritonbench-benchmarking-large-language-model</link>
      <description><![CDATA[Despite advances in large language models (LLMs) for conventional code generation, these models struggle to generate accurate, performance-optimized Triton code, as they lack awareness of its specifications and the complexities of GPU programming.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tritonbench-benchmarking-large-language-model</guid>
    </item>
    <item>
      <title>How to Get Your LLM to Generate Challenging Problems for Evaluation</title>
      <link>https://paperswithcode.com/paper/how-to-get-your-llm-to-generate-challenging</link>
      <description><![CDATA[The performance of state-of-the-art LLMs on these synthetic benchmarks lies in the range of 40-60% accuracy, thereby demonstrating the effectiveness of our framework at generating challenging problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-to-get-your-llm-to-generate-challenging</guid>
    </item>
    <item>
      <title>Asymmetric Co-Training for Source-Free Few-Shot Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/asymmetric-co-training-for-source-free-few</link>
      <description><![CDATA[Our findings suggest that adapting a source pre-trained model using only a small amount of labeled target data offers a practical and dependable solution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asymmetric-co-training-for-source-free-few</guid>
    </item>
    <item>
      <title>MAGO-SP: Detection and Correction of Water-Fat Swaps in Magnitude-Only VIBE MRI</title>
      <link>https://paperswithcode.com/paper/mago-sp-detection-and-correction-of-water-fat</link>
      <description><![CDATA[While the two-point VIBE provides water-fat-separated images, the six-point VIBE allows estimation of the effective transversal relaxation rate R2* and the proton density fat fraction (PDFF), which are imaging markers for health and disease.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mago-sp-detection-and-correction-of-water-fat</guid>
    </item>
    <item>
      <title>On the logical skills of large language models: evaluations using arbitrarily complex first-order logic problems</title>
      <link>https://paperswithcode.com/paper/on-the-logical-skills-of-large-language</link>
      <description><![CDATA[We present a method of generating first-order logic statements whose complexity can be controlled along multiple dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-logical-skills-of-large-language</guid>
    </item>
    <item>
      <title>Capturing Nuanced Preferences: Preference-Aligned Distillation for Small Language Models</title>
      <link>https://paperswithcode.com/paper/capturing-nuanced-preferences-preference</link>
      <description><![CDATA[Based on this, PAD comprises three key steps: (1) sampling diverse responses using high-temperature; (2) computing rewards for both teacher and student to construct their intrinsic preference; and (3) training the student's intrinsic preference distribution to align with the teacher's.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/capturing-nuanced-preferences-preference</guid>
    </item>
    <item>
      <title>A Theory for Conditional Generative Modeling on Multiple Data Sources</title>
      <link>https://paperswithcode.com/paper/a-theory-for-conditional-generative-modeling</link>
      <description><![CDATA[The results highlight that the number of sources and similarity among source distributions improve the advantage of multi-source training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-theory-for-conditional-generative-modeling</guid>
    </item>
    <item>
      <title>Length-Controlled Margin-Based Preference Optimization without Reference Model</title>
      <link>https://paperswithcode.com/paper/length-controlled-margin-based-preference</link>
      <description><![CDATA[A key innovation of LMPO lies in its Length-Controlled Margin-Based loss function, integrated within the Bradley-Terry framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/length-controlled-margin-based-preference</guid>
    </item>
    <item>
      <title>Sparse Activations as Conformal Predictors</title>
      <link>https://paperswithcode.com/paper/sparse-activations-as-conformal-predictors</link>
      <description><![CDATA[Conformal prediction is a distribution-free framework for uncertainty quantification that replaces point predictions with sets, offering marginal coverage guarantees (i. e., ensuring that the prediction sets contain the true label with a specified probability, in expectation).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparse-activations-as-conformal-predictors</guid>
    </item>
    <item>
      <title>Narrative-Driven Travel Planning: Geoculturally-Grounded Script Generation with Evolutionary Itinerary Optimization</title>
      <link>https://paperswithcode.com/paper/narrative-driven-travel-planning</link>
      <description><![CDATA[To enhance tourists' experiences and immersion, this paper proposes a narrative-driven travel planning framework called NarrativeGuide, which generates a geoculturally-grounded narrative script for travelers, offering a novel, role-playing experience for their journey.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/narrative-driven-travel-planning</guid>
    </item>
    <item>
      <title>Optimizing Model Selection for Compound AI Systems</title>
      <link>https://paperswithcode.com/paper/optimizing-model-selection-for-compound-ai</link>
      <description><![CDATA[We propose LLMSelector, an efficient framework for model selection in compound systems, which leverages two key empirical insights: (i) end-to-end performance is often monotonic in how well each module performs, with all other modules held fixed, and (ii) per-module performance can be estimated accurately by an LLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimizing-model-selection-for-compound-ai</guid>
    </item>
  </channel>
</rss>
