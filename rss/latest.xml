<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 09 Sep 2022 21:08:12 +0000</lastBuildDate>
    <item>
      <title>AARGH! End-to-end Retrieval-Generation for Task-Oriented Dialog</title>
      <link>https://paperswithcode.com/paper/aargh-end-to-end-retrieval-generation-for</link>
      <description><![CDATA[We introduce AARGH, an end-to-end task-oriented dialog system combining retrieval and generative approaches in a single model, aiming at improving dialog management and lexical diversity of outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aargh-end-to-end-retrieval-generation-for</guid>
    </item>
    <item>
      <title>Text-Free Learning of a Natural Language Interface for Pretrained Face Generators</title>
      <link>https://paperswithcode.com/paper/text-free-learning-of-a-natural-language</link>
      <description><![CDATA[We propose Fast text2StyleGAN, a natural language interface that adapts pre-trained GANs for text-guided human face synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-free-learning-of-a-natural-language</guid>
    </item>
    <item>
      <title>R$^3$LIVE++: A Robust, Real-time, Radiance reconstruction package with a tightly-coupled LiDAR-Inertial-Visual state Estimator</title>
      <link>https://paperswithcode.com/paper/r-3-live-a-robust-real-time-radiance</link>
      <description><![CDATA[The LIO subsystem utilizes the measurements from a LiDAR for reconstructing the geometric structure (i. e., the positions of 3D points), while the VIO subsystem simultaneously recovers the radiance information of the geometric structure from the input images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r-3-live-a-robust-real-time-radiance</guid>
    </item>
    <item>
      <title>Generalized One-shot Domain Adaption of Generative Adversarial Networks</title>
      <link>https://paperswithcode.com/paper/generalized-one-shot-domain-adaption-of</link>
      <description><![CDATA[While previous works mainly focus on the style transfer, we propose a novel and concise framework\footnote{\url{https://github. com/thevoidname/Generalized-One-shot-GAN-Adaption}} to address the \textit{generalized one-shot adaption} task for both style and entity transfer, in which a reference image and its binary entity mask are provided.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-one-shot-domain-adaption-of</guid>
    </item>
    <item>
      <title>Simpler is better: Multilevel Abstraction with Graph Convolutional Recurrent Neural Network Cells for Traffic Prediction</title>
      <link>https://paperswithcode.com/paper/simpler-is-better-multilevel-abstraction-with</link>
      <description><![CDATA[In recent years, graph neural networks (GNNs) combined with variants of recurrent neural networks (RNNs) have reached state-of-the-art performance in spatiotemporal forecasting tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simpler-is-better-multilevel-abstraction-with</guid>
    </item>
    <item>
      <title>Stochastic gradient descent with gradient estimator for categorical features</title>
      <link>https://paperswithcode.com/paper/stochastic-gradient-descent-with-gradient</link>
      <description><![CDATA[Categorical data are present in key areas such as health or supply chain, and this data require specific treatment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stochastic-gradient-descent-with-gradient</guid>
    </item>
    <item>
      <title>Accented Speech Recognition under the Indian context</title>
      <link>https://paperswithcode.com/paper/accented-speech-recognition-under-the-indian</link>
      <description><![CDATA[The accent itself can be a conveyor of status, pride, and other emotional information which can be captured through Speech itself.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accented-speech-recognition-under-the-indian</guid>
    </item>
    <item>
      <title>Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization</title>
      <link>https://paperswithcode.com/paper/extractive-is-not-faithful-an-investigation</link>
      <description><![CDATA[Though extractive summarization is less prone to the common unfaithfulness issues of abstractive summaries, does that mean extractive is equal to faithful?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extractive-is-not-faithful-an-investigation</guid>
    </item>
    <item>
      <title>Aerial View Goal Localization with Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/aerial-view-goal-localization-with</link>
      <description><![CDATA[In many cases the rough location may be known and a UAV can be deployed to explore a given, confined area to precisely localize the missing people.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aerial-view-goal-localization-with</guid>
    </item>
    <item>
      <title>Pre-Training a Graph Recurrent Network for Language Representation</title>
      <link>https://paperswithcode.com/paper/pre-training-a-graph-recurrent-network-for</link>
      <description><![CDATA[Transformer-based pre-trained models have gained much advance in recent years, becoming one of the most important backbones in natural language processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pre-training-a-graph-recurrent-network-for</guid>
    </item>
    <item>
      <title>Data Feedback Loops: Model-driven Amplification of Dataset Biases</title>
      <link>https://paperswithcode.com/paper/data-feedback-loops-model-driven</link>
      <description><![CDATA[Datasets scraped from the internet have been critical to the successes of large-scale machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-feedback-loops-model-driven</guid>
    </item>
    <item>
      <title>Effects of Archive Size on Computation Time and Solution Quality for Multi-Objective Optimization</title>
      <link>https://paperswithcode.com/paper/effects-of-archive-size-on-computation-time</link>
      <description><![CDATA[In this study, we examine the effects of the archive size on three aspects: (i) the quality of the selected final solution set, (ii) the total computation time for the archive maintenance and the final solution set selection, and (iii) the required memory size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effects-of-archive-size-on-computation-time</guid>
    </item>
    <item>
      <title>YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications</title>
      <link>https://paperswithcode.com/paper/yolov6-a-single-stage-object-detection</link>
      <description><![CDATA[The YOLO community has prospered overwhelmingly to enrich its use in a multitude of hardware platforms and abundant scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov6-a-single-stage-object-detection</guid>
    </item>
    <item>
      <title>Improving the Cross-Lingual Generalisation in Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/improving-the-cross-lingual-generalisation-in</link>
      <description><![CDATA[While several benefits were realized for multilingual vision-language pretrained models, recent benchmarks across various tasks and languages showed poor cross-lingual generalisation when multilingually pre-trained vision-language models are applied to non-English data, with a large gap between (supervised) English performance and (zero-shot) cross-lingual transfer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-the-cross-lingual-generalisation-in</guid>
    </item>
    <item>
      <title>Semantic Interactive Learning for Text Classification: A Constructive Approach for Contextual Interactions</title>
      <link>https://paperswithcode.com/paper/semantic-interactive-learning-for-text</link>
      <description><![CDATA[Interactive Machine Learning (IML) shall enable intelligent systems to interactively learn from their end-users, and is quickly becoming more and more important.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-interactive-learning-for-text</guid>
    </item>
    <item>
      <title>Improving Self-supervised Learning for Out-of-distribution Task via Auxiliary Classifier</title>
      <link>https://paperswithcode.com/paper/improving-self-supervised-learning-for-out-of</link>
      <description><![CDATA[Observing a strong relationship between rotation prediction (self-supervised) accuracy and semantic classification accuracy on OOD tasks, we introduce an additional auxiliary classification head in our multi-task network along with semantic classification and rotation prediction head.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-self-supervised-learning-for-out-of</guid>
    </item>
    <item>
      <title>VGStore: A Multimodal Extension to SPARQL for Querying RDF Scene Graph</title>
      <link>https://paperswithcode.com/paper/vgstore-a-multimodal-extension-to-sparql-for</link>
      <description><![CDATA[Semantic Web technology has successfully facilitated many RDF models with rich data representation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vgstore-a-multimodal-extension-to-sparql-for</guid>
    </item>
    <item>
      <title>On the Complementarity between Pre-Training and Random-Initialization for Resource-Rich Machine Translation</title>
      <link>https://paperswithcode.com/paper/on-the-complementarity-between-pre-training-1</link>
      <description><![CDATA[Pre-Training (PT) of text representations has been successfully applied to low-resource Neural Machine Translation (NMT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-complementarity-between-pre-training-1</guid>
    </item>
    <item>
      <title>Interpretations Steered Network Pruning via Amortized Inferred Saliency Maps</title>
      <link>https://paperswithcode.com/paper/interpretations-steered-network-pruning-via</link>
      <description><![CDATA[To fill in this gap, we propose to address the channel pruning problem from a novel perspective by leveraging the interpretations of a model to steer the pruning process, thereby utilizing information from both inputs and outputs of the model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpretations-steered-network-pruning-via</guid>
    </item>
    <item>
      <title>KT-BT: A Framework for Knowledge Transfer Through Behavior Trees in Multi-Robot Systems</title>
      <link>https://paperswithcode.com/paper/kt-bt-a-framework-for-knowledge-transfer</link>
      <description><![CDATA[We theoretically investigate the properties of the KT-BT framework in achieving homogeneity of high knowledge across the entire group compared to a heterogeneous system without the capability of sharing their knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kt-bt-a-framework-for-knowledge-transfer</guid>
    </item>
    <item>
      <title>Multi-Scale Attention-based Multiple Instance Learning for Classification of Multi-Gigapixel Histology Images</title>
      <link>https://paperswithcode.com/paper/multi-scale-attention-based-multiple-instance</link>
      <description><![CDATA[To the best of our knowledge, this is the first attempt to predict LMP1 status on NPC using deep learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-attention-based-multiple-instance</guid>
    </item>
    <item>
      <title>Entity-based SpanCopy for Abstractive Summarization to Improve the Factual Consistency</title>
      <link>https://paperswithcode.com/paper/entity-based-spancopy-for-abstractive</link>
      <description><![CDATA[Despite the success of recent abstractive summarizers on automatic evaluation metrics, the generated summaries still present factual inconsistencies with the source document.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/entity-based-spancopy-for-abstractive</guid>
    </item>
    <item>
      <title>SynSciPass: detecting appropriate uses of scientific text generation</title>
      <link>https://paperswithcode.com/paper/synscipass-detecting-appropriate-uses-of</link>
      <description><![CDATA[By training the same model that performed well on DAGPap22 on SynSciPass, we show that not only is the model more robust to domain shifts but also is able to uncover the type of technology used for machine generated text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synscipass-detecting-appropriate-uses-of</guid>
    </item>
    <item>
      <title>Difficulty-Net: Learning to Predict Difficulty for Long-Tailed Recognition</title>
      <link>https://paperswithcode.com/paper/difficulty-net-learning-to-predict-difficulty</link>
      <description><![CDATA[Long-tailed datasets, where head classes comprise much more training samples than tail classes, cause recognition models to get biased towards the head classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/difficulty-net-learning-to-predict-difficulty</guid>
    </item>
    <item>
      <title>On the Effectiveness of Compact Biomedical Transformers</title>
      <link>https://paperswithcode.com/paper/on-the-effectiveness-of-compact-biomedical</link>
      <description><![CDATA[Language models pre-trained on biomedical corpora, such as BioBERT, have recently shown promising results on downstream biomedical tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-effectiveness-of-compact-biomedical</guid>
    </item>
    <item>
      <title>Joint Learning of Deep Texture and High-Frequency Features for Computer-Generated Image Detection</title>
      <link>https://paperswithcode.com/paper/joint-learning-of-deep-texture-and-high</link>
      <description><![CDATA[Based on the finding that multiple different modules in image acquisition will lead to different sensitivity inconsistencies to the convolutional neural network (CNN)-based rendering in images, we propose a deep texture rendering module for texture difference enhancement and discriminative texture representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/joint-learning-of-deep-texture-and-high</guid>
    </item>
    <item>
      <title>BiFuse++: Self-supervised and Efficient Bi-projection Fusion for 360 Depth Estimation</title>
      <link>https://paperswithcode.com/paper/bifuse-self-supervised-and-efficient-bi</link>
      <description><![CDATA[Thus, state-of-the-art frameworks for monocular 360 depth estimation such as bi-projection fusion in BiFuse are proposed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bifuse-self-supervised-and-efficient-bi</guid>
    </item>
    <item>
      <title>Shifting Perspective to See Difference: A Novel Multi-View Method for Skeleton based Action Recognition</title>
      <link>https://paperswithcode.com/paper/shifting-perspective-to-see-difference-a</link>
      <description><![CDATA[Our module can work seamlessly with the existing action classification model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shifting-perspective-to-see-difference-a</guid>
    </item>
    <item>
      <title>What does a platypus look like? Generating customized prompts for zero-shot image classification</title>
      <link>https://paperswithcode.com/paper/what-does-a-platypus-look-like-generating</link>
      <description><![CDATA[Unlike traditional classification models, open vocabulary models classify among any arbitrary set of categories specified with natural language during inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-does-a-platypus-look-like-generating</guid>
    </item>
    <item>
      <title>Morphology-preserving Autoregressive 3D Generative Modelling of the Brain</title>
      <link>https://paperswithcode.com/paper/morphology-preserving-autoregressive-3d</link>
      <description><![CDATA[Still, the ability to produce high-resolution 3D volumetric imaging data with correct anatomical morphology has been hampered by data scarcity and algorithmic and computational limitations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/morphology-preserving-autoregressive-3d</guid>
    </item>
    <item>
      <title>AutoPruner: Transformer-Based Call Graph Pruning</title>
      <link>https://paperswithcode.com/paper/autopruner-transformer-based-call-graph</link>
      <description><![CDATA[Given a call graph constructed by traditional static analysis tools, AutoPruner takes a Transformer-based approach to capture the semantic relationships between the caller and callee functions associated with each edge in the call graph.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autopruner-transformer-based-call-graph</guid>
    </item>
    <item>
      <title>Risk of Bias in Chest X-ray Foundation Models</title>
      <link>https://paperswithcode.com/paper/risk-of-bias-in-chest-x-ray-foundation-models</link>
      <description><![CDATA[Foundation models are considered a breakthrough in all applications of AI, promising robust and reusable mechanisms for feature extraction, alleviating the need for large amounts of high quality training data for task-specific prediction models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/risk-of-bias-in-chest-x-ray-foundation-models</guid>
    </item>
    <item>
      <title>A Survey of Neural Trees</title>
      <link>https://paperswithcode.com/paper/a-survey-of-neural-trees</link>
      <description><![CDATA[This survey aims to present a comprehensive review of NTs and attempts to identify how they enhance the model interpretability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-neural-trees</guid>
    </item>
    <item>
      <title>Quantitative probing: Validating causal models using quantitative domain knowledge</title>
      <link>https://paperswithcode.com/paper/quantitative-probing-validating-causal-models</link>
      <description><![CDATA[We present quantitative probing as a model-agnostic framework for validating causal models in the presence of quantitative domain knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quantitative-probing-validating-causal-models</guid>
    </item>
    <item>
      <title>Social Media Engagement and Cryptocurrency Performance</title>
      <link>https://paperswithcode.com/paper/social-media-engagement-and-cryptocurrency</link>
      <description><![CDATA[We use this model to estimate engagement coefficients for 48 cryptocurrencies created between 2019 and 2021 using data from Twitter from the first month of the cryptocurrencies' existence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/social-media-engagement-and-cryptocurrency</guid>
    </item>
    <item>
      <title>VulCurator: A Vulnerability-Fixing Commit Detector</title>
      <link>https://paperswithcode.com/paper/vulcurator-a-vulnerability-fixing-commit</link>
      <description><![CDATA[Open-source software (OSS) vulnerability management process is important nowadays, as the number of discovered OSS vulnerabilities is increasing over time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vulcurator-a-vulnerability-fixing-commit</guid>
    </item>
    <item>
      <title>Deep Learning for Medical Imaging From Diagnosis Prediction to its Counterfactual Explanation</title>
      <link>https://paperswithcode.com/paper/deep-learning-for-medical-imaging-from</link>
      <description><![CDATA[Deep neural networks (DNN) have achieved unprecedented performance in computer-vision tasks almost ubiquitously in business, technology, and science.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-learning-for-medical-imaging-from</guid>
    </item>
    <item>
      <title>Benchmarking Multimodal Variational Autoencoders: GeBiD Dataset and Toolkit</title>
      <link>https://paperswithcode.com/paper/benchmarking-multimodal-variational</link>
      <description><![CDATA[Second, we present a synthetic bimodal dataset designed for a comprehensive evaluation of the joint generation and cross-generation capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-multimodal-variational</guid>
    </item>
    <item>
      <title>Multimodal Speech Enhancement Using Burst Propagation</title>
      <link>https://paperswithcode.com/paper/multimodal-speech-enhancement-using-burst</link>
      <description><![CDATA[This paper proposes the MBURST, a novel multimodal solution for audio-visual speech enhancements that consider the most recent neurological discoveries regarding pyramidal cells of the prefrontal cortex and other brain regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-speech-enhancement-using-burst</guid>
    </item>
    <item>
      <title>AI Illustrator: Translating Raw Descriptions into Images by Prompt-based Cross-Modal Generation</title>
      <link>https://paperswithcode.com/paper/ai-illustrator-translating-raw-descriptions</link>
      <description><![CDATA[To address this issue, we propose a Prompt-based Cross-Modal Generation Framework (PCM-Frame) to leverage two powerful pre-trained models, including CLIP and StyleGAN.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ai-illustrator-translating-raw-descriptions</guid>
    </item>
    <item>
      <title>A Data-dependent Approach for High Dimensional (Robust) Wasserstein Alignment</title>
      <link>https://paperswithcode.com/paper/a-data-dependent-approach-for-high</link>
      <description><![CDATA[Our framework is a "data-dependent" approach that has the complexity depending on the intrinsic dimension of the input data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-data-dependent-approach-for-high</guid>
    </item>
    <item>
      <title>Decoding Demographic un-fairness from Indian Names</title>
      <link>https://paperswithcode.com/paper/decoding-demographic-un-fairness-from-indian</link>
      <description><![CDATA[Demographic classification is essential in fairness assessment in recommender systems or in measuring unintended bias in online networks and voting systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decoding-demographic-un-fairness-from-indian</guid>
    </item>
    <item>
      <title>3D Textured Shape Recovery with Learned Geometric Priors</title>
      <link>https://paperswithcode.com/paper/3d-textured-shape-recovery-with-learned</link>
      <description><![CDATA[3D textured shape recovery from partial scans is crucial for many real-world applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-textured-shape-recovery-with-learned</guid>
    </item>
    <item>
      <title>MSMDFusion: Fusing LiDAR and Camera at Multiple Scales with Multi-Depth Seeds for 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/msmdfusion-fusing-lidar-and-camera-at</link>
      <description><![CDATA[Fusing LiDAR and camera information is essential for achieving accurate and reliable 3D object detection in autonomous driving systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/msmdfusion-fusing-lidar-and-camera-at</guid>
    </item>
    <item>
      <title>INFACT: An Online Human Evaluation Framework for Conversational Recommendation</title>
      <link>https://paperswithcode.com/paper/infact-an-online-human-evaluation-framework</link>
      <description><![CDATA[Conversational recommender systems (CRS) are interactive agents that support their users in recommendation-related goals through multi-turn conversations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infact-an-online-human-evaluation-framework</guid>
    </item>
    <item>
      <title>Semi-supervised Crowd Counting via Density Agency</title>
      <link>https://paperswithcode.com/paper/semi-supervised-crowd-counting-via-density</link>
      <description><![CDATA[In this paper, we propose a new agency-guided semi-supervised counting approach.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semi-supervised-crowd-counting-via-density</guid>
    </item>
    <item>
      <title>Efficient search of active inference policy spaces using k-means</title>
      <link>https://paperswithcode.com/paper/efficient-search-of-active-inference-policy</link>
      <description><![CDATA[We develop an approach to policy selection in active inference that allows us to efficiently search large policy spaces by mapping each policy to its embedding in a vector space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-search-of-active-inference-policy</guid>
    </item>
    <item>
      <title>ViTKD: Practical Guidelines for ViT feature knowledge distillation</title>
      <link>https://paperswithcode.com/paper/vitkd-practical-guidelines-for-vit-feature</link>
      <description><![CDATA[In this paper, we explore the way of feature-based distillation for ViT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vitkd-practical-guidelines-for-vit-feature</guid>
    </item>
    <item>
      <title>Profiling Television Watching Behaviour Using Bayesian Hierarchical Joint Models for Time-to-Event and Count Data</title>
      <link>https://paperswithcode.com/paper/profiling-television-watching-behaviour-using</link>
      <description><![CDATA[The model drastically reduces the dimensionality of the data from thousands of observations per customer to 11 customer-level parameter estimates and random effects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/profiling-television-watching-behaviour-using</guid>
    </item>
    <item>
      <title>PTSEFormer: Progressive Temporal-Spatial Enhanced TransFormer Towards Video Object Detection</title>
      <link>https://paperswithcode.com/paper/ptseformer-progressive-temporal-spatial</link>
      <description><![CDATA[The temporal information is introduced by the temporal feature aggregation model (TFAM), by conducting an attention mechanism between the context frames and the target frame (i. e., the frame to be detected).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ptseformer-progressive-temporal-spatial</guid>
    </item>
  </channel>
</rss>
