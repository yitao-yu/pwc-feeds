<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 12 Oct 2024 09:15:53 +0000</lastBuildDate>
    <item>
      <title>Efficient Dictionary Learning with Switch Sparse Autoencoders</title>
      <link>https://paperswithcode.com/paper/efficient-dictionary-learning-with-switch</link>
      <description><![CDATA[We present experiments comparing Switch SAEs with other SAE architectures, and find that Switch SAEs deliver a substantial Pareto improvement in the reconstruction vs. sparsity frontier for a given fixed training compute budget.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-dictionary-learning-with-switch</guid>
    </item>
    <item>
      <title>Thought2Text: Text Generation from EEG Signal using Large Language Models (LLMs)</title>
      <link>https://paperswithcode.com/paper/thought2text-text-generation-from-eeg-signal</link>
      <description><![CDATA[Decoding and expressing brain activity in a comprehensible form is a challenging frontier in AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/thought2text-text-generation-from-eeg-signal</guid>
    </item>
    <item>
      <title>Neural Reasoning Networks: Efficient Interpretable Neural Networks With Automatic Textual Explanations</title>
      <link>https://paperswithcode.com/paper/neural-reasoning-networks-efficient</link>
      <description><![CDATA[Recent advances in machine learning have led to a surge in adoption of neural networks for various tasks, but lack of interpretability remains an issue for many others in which an understanding of the features influencing the prediction is necessary to ensure fairness, safety, and legal compliance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-reasoning-networks-efficient</guid>
    </item>
    <item>
      <title>Poison-splat: Computation Cost Attack on 3D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/poison-splat-computation-cost-attack-on-3d</link>
      <description><![CDATA[However, in this work, we reveal a significant security vulnerability that has been largely overlooked in 3DGS: the computation cost of training 3DGS could be maliciously tampered by poisoning the input data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poison-splat-computation-cost-attack-on-3d</guid>
    </item>
    <item>
      <title>OneRef: Unified One-tower Expression Grounding and Segmentation with Mask Referring Modeling</title>
      <link>https://paperswithcode.com/paper/oneref-unified-one-tower-expression-grounding</link>
      <description><![CDATA[Simultaneously, the current mask visual language modeling (MVLM) fails to capture the nuanced referential relationship between image-text in referring tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oneref-unified-one-tower-expression-grounding</guid>
    </item>
    <item>
      <title>A Closer Look at Machine Unlearning for Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-closer-look-at-machine-unlearning-for-large</link>
      <description><![CDATA[Specifically, the behavior that untargeted unlearning attempts to approximate is unpredictable and may involve hallucinations, and existing regularization is insufficient for targeted unlearning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-closer-look-at-machine-unlearning-for-large</guid>
    </item>
    <item>
      <title>Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning</title>
      <link>https://paperswithcode.com/paper/packing-analysis-packing-is-more-appropriate</link>
      <description><![CDATA[Although it has demonstrated effectiveness during pre-training, there remains a lack of comprehensive analysis for the supervised fine-tuning (SFT) stage on the following points: (1) whether packing can effectively enhance training efficiency while maintaining performance, (2) the suitable size of the model and dataset for fine-tuning with the packing method, and (3) whether packing unrelated or related training samples might cause the model to either excessively disregard or over-rely on the context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/packing-analysis-packing-is-more-appropriate</guid>
    </item>
    <item>
      <title>Reward-Augmented Data Enhances Direct Preference Alignment of LLMs</title>
      <link>https://paperswithcode.com/paper/reward-augmented-data-enhances-direct</link>
      <description><![CDATA[This dataset is easily integrated with existing direct alignment algorithms and is applicable to any preference dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reward-augmented-data-enhances-direct</guid>
    </item>
    <item>
      <title>CoPESD: A Multi-Level Surgical Motion Dataset for Training Large Vision-Language Models to Co-Pilot Endoscopic Submucosal Dissection</title>
      <link>https://paperswithcode.com/paper/copesd-a-multi-level-surgical-motion-dataset</link>
      <description><![CDATA[In this paper, we design a hierarchical decomposition of ESD motion granularity and introduce a multi-level surgical motion dataset (CoPESD) for training LVLMs as the robotic \textbf{Co}-\textbf{P}ilot of \textbf{E}ndoscopic \textbf{S}ubmucosal \textbf{D}issection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/copesd-a-multi-level-surgical-motion-dataset</guid>
    </item>
    <item>
      <title>QCircuitNet: A Large-Scale Hierarchical Dataset for Quantum Algorithm Design</title>
      <link>https://paperswithcode.com/paper/qcircuitnet-a-large-scale-hierarchical</link>
      <description><![CDATA[In this work, we introduce QCircuitNet, the first benchmark and test dataset designed to evaluate AI's capability in designing and implementing quantum algorithms in the form of quantum circuit codes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qcircuitnet-a-large-scale-hierarchical</guid>
    </item>
    <item>
      <title>Window Function-less DFT with Reduced Noise and Latency for Real-Time Music Analysis</title>
      <link>https://paperswithcode.com/paper/window-function-less-dft-with-reduced-noise</link>
      <description><![CDATA[Music analysis applications demand algorithms that can provide both high time and frequency resolution while minimizing noise in an already-noisy signal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/window-function-less-dft-with-reduced-noise</guid>
    </item>
    <item>
      <title>CrackSegDiff: Diffusion Probability Model-based Multi-modal Crack Segmentation</title>
      <link>https://paperswithcode.com/paper/cracksegdiff-diffusion-probability-model</link>
      <description><![CDATA[Our experimental evaluation on the three-class crack image segmentation tasks within the FIND dataset demonstrates that CrackSegDiff outperforms state-of-the-art methods, particularly excelling in the detection of shallow cracks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cracksegdiff-diffusion-probability-model</guid>
    </item>
    <item>
      <title>Relational Diffusion Distillation for Efficient Image Generation</title>
      <link>https://paperswithcode.com/paper/relational-diffusion-distillation-for</link>
      <description><![CDATA[Therefore, many training-free sampling methods have been proposed to reduce the number of sampling steps required for diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relational-diffusion-distillation-for</guid>
    </item>
    <item>
      <title>Scaling Up Your Kernels: Large Kernel Design in ConvNets towards Universal Representations</title>
      <link>https://paperswithcode.com/paper/scaling-up-your-kernels-large-kernel-design</link>
      <description><![CDATA[This paper proposes the paradigm of large convolutional kernels in designing modern Convolutional Neural Networks (ConvNets).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-up-your-kernels-large-kernel-design</guid>
    </item>
    <item>
      <title>Generalizable and Animatable Gaussian Head Avatar</title>
      <link>https://paperswithcode.com/paper/generalizable-and-animatable-gaussian-head</link>
      <description><![CDATA[In this paper, we propose Generalizable and Animatable Gaussian head Avatar (GAGAvatar) for one-shot animatable head avatar reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizable-and-animatable-gaussian-head</guid>
    </item>
    <item>
      <title>RayEmb: Arbitrary Landmark Detection in X-Ray Images Using Ray Embedding Subspace</title>
      <link>https://paperswithcode.com/paper/rayemb-arbitrary-landmark-detection-in-x-ray</link>
      <description><![CDATA[Anatomical landmarks pre-annotated in the CT volume can be detected in X-ray images to establish 2D-3D correspondences, which are then utilized for registration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rayemb-arbitrary-landmark-detection-in-x-ray</guid>
    </item>
    <item>
      <title>Parameter-Efficient Fine-Tuning in Spectral Domain for Point Cloud Learning</title>
      <link>https://paperswithcode.com/paper/parameter-efficient-fine-tuning-in-spectral</link>
      <description><![CDATA[PointGST freezes the pre-trained model and introduces a lightweight, trainable Point Cloud Spectral Adapter (PCSA) to fine-tune parameters in the spectral domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parameter-efficient-fine-tuning-in-spectral</guid>
    </item>
    <item>
      <title>SNN-PAR: Energy Efficient Pedestrian Attribute Recognition via Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/snn-par-energy-efficient-pedestrian-attribute</link>
      <description><![CDATA[To address this issue, in this paper, we propose a Spiking Neural Network (SNN) based framework for energy-efficient attribute recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/snn-par-energy-efficient-pedestrian-attribute</guid>
    </item>
    <item>
      <title>Firzen: Firing Strict Cold-Start Items with Frozen Heterogeneous and Homogeneous Graphs for Recommendation</title>
      <link>https://paperswithcode.com/paper/firzen-firing-strict-cold-start-items-with</link>
      <description><![CDATA[Recommendation models utilizing unique identities (IDs) to represent distinct users and items have dominated the recommender systems literature for over a decade.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/firzen-firing-strict-cold-start-items-with</guid>
    </item>
    <item>
      <title>MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code</title>
      <link>https://paperswithcode.com/paper/mathcoder2-better-math-reasoning-from</link>
      <description><![CDATA[Training several popular base models with this corpus significantly improves their mathematical abilities, leading to the creation of the MathCoder2 family of models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mathcoder2-better-math-reasoning-from</guid>
    </item>
    <item>
      <title>GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps</title>
      <link>https://paperswithcode.com/paper/gametraversalbenchmark-evaluating-planning</link>
      <description><![CDATA[Large language models (LLMs) have recently demonstrated great success in generating and understanding natural language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gametraversalbenchmark-evaluating-planning</guid>
    </item>
    <item>
      <title>Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models</title>
      <link>https://paperswithcode.com/paper/teaching-inspired-integrated-prompting</link>
      <description><![CDATA[Experiments are conducted on nine benchmarks which demonstrates that our approach improves the reasoning accuracy of LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teaching-inspired-integrated-prompting</guid>
    </item>
    <item>
      <title>DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory</title>
      <link>https://paperswithcode.com/paper/delta-an-online-document-level-translation</link>
      <description><![CDATA[Large language models (LLMs) have achieved reasonable quality improvements in machine translation (MT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/delta-an-online-document-level-translation</guid>
    </item>
    <item>
      <title>Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs</title>
      <link>https://paperswithcode.com/paper/efficiently-learning-at-test-time-active-fine</link>
      <description><![CDATA[To address this, we introduce SIFT, a data selection algorithm designed to reduce uncertainty about the model's response given a prompt, which unifies ideas from retrieval and active learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiently-learning-at-test-time-active-fine</guid>
    </item>
    <item>
      <title>IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera</title>
      <link>https://paperswithcode.com/paper/inceventgs-pose-free-gaussian-splatting-from</link>
      <description><![CDATA[To recover the 3D scene representation incrementally, we exploit the tracking and mapping paradigm of conventional SLAM pipelines for IncEventGS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inceventgs-pose-free-gaussian-splatting-from</guid>
    </item>
    <item>
      <title>Meta-Learning Integration in Hierarchical Reinforcement Learning for Advanced Task Complexity</title>
      <link>https://paperswithcode.com/paper/meta-learning-integration-in-hierarchical</link>
      <description><![CDATA[To address this, we integrate meta-learning into HRL to enhance the agent's ability to learn and adapt hierarchical policies swiftly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-learning-integration-in-hierarchical</guid>
    </item>
    <item>
      <title>Deconstructing equivariant representations in molecular systems</title>
      <link>https://paperswithcode.com/paper/deconstructing-equivariant-representations-in</link>
      <description><![CDATA[In this work, we report on a set of experiments using a simple equivariant graph convolution model on the QM9 dataset, focusing on correlating quantitative performance with the resulting molecular graph embeddings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deconstructing-equivariant-representations-in</guid>
    </item>
    <item>
      <title>Reversible Decoupling Network for Single Image Reflection Removal</title>
      <link>https://paperswithcode.com/paper/reversible-decoupling-network-for-single</link>
      <description><![CDATA[Recent deep-learning-based approaches to single-image reflection removal have shown promising advances, primarily for two reasons: 1) the utilization of recognition-pretrained features as inputs, and 2) the design of dual-stream interaction networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reversible-decoupling-network-for-single</guid>
    </item>
    <item>
      <title>LADIMO: Face Morph Generation through Biometric Template Inversion with Latent Diffusion</title>
      <link>https://paperswithcode.com/paper/ladimo-face-morph-generation-through</link>
      <description><![CDATA[Face morphing attacks pose a severe security threat to face recognition systems, enabling the morphed face image to be verified against multiple identities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ladimo-face-morph-generation-through</guid>
    </item>
    <item>
      <title>Optimal-State Dynamics Estimation for Physics-based Human Motion Capture from Videos</title>
      <link>https://paperswithcode.com/paper/optimal-state-dynamics-estimation-for-physics</link>
      <description><![CDATA[We develop a control loop as a meta-PD controller to predict internal joint torques and external reaction forces, followed by a physics-based motion simulation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimal-state-dynamics-estimation-for-physics</guid>
    </item>
    <item>
      <title>Linguistically-Informed Multilingual Instruction Tuning: Is There an Optimal Set of Languages to Tune?</title>
      <link>https://paperswithcode.com/paper/linguistically-informed-multilingual</link>
      <description><![CDATA[All resources, including the code for language selection and multilingual instruction tuning, are made available in our official repository at https://github. com/GGLAB-KU/ling-informed-mit enabling reproducibility and further research in this area.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linguistically-informed-multilingual</guid>
    </item>
    <item>
      <title>Q-VLM: Post-training Quantization for Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/q-vlm-post-training-quantization-for-large</link>
      <description><![CDATA[On the contrary, we mine the cross-layer dependency that significantly influences discretization errors of the entire vision-language model, and embed this dependency into optimal quantization strategy searching with low search cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/q-vlm-post-training-quantization-for-large</guid>
    </item>
    <item>
      <title>StepTool: A Step-grained Reinforcement Learning Framework for Tool Learning in LLMs</title>
      <link>https://paperswithcode.com/paper/steptool-a-step-grained-reinforcement</link>
      <description><![CDATA[Despite having powerful reasoning and inference capabilities, Large Language Models (LLMs) still need external tools to acquire real-time information retrieval or domain-specific expertise to solve complex tasks, which is referred to as tool learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/steptool-a-step-grained-reinforcement</guid>
    </item>
    <item>
      <title>Agent S: An Open Agentic Framework that Uses Computers Like a Human</title>
      <link>https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</link>
      <description><![CDATA[We present Agent S, an open agentic framework that enables autonomous interaction with computers through a Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</guid>
    </item>
    <item>
      <title>MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/motiongs-exploring-explicit-motion-guidance</link>
      <description><![CDATA[Specifically, we first introduce an optical flow decoupling module that decouples optical flow into camera flow and motion flow, corresponding to camera movement and object motion respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motiongs-exploring-explicit-motion-guidance</guid>
    </item>
    <item>
      <title>TopoTune : A Framework for Generalized Combinatorial Complex Neural Networks</title>
      <link>https://paperswithcode.com/paper/topotune-a-framework-for-generalized</link>
      <description><![CDATA[Combinatorial Complex Neural Networks (CCNNs), fairly general TDL models, have been shown to be more expressive and better performing than GNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/topotune-a-framework-for-generalized</guid>
    </item>
    <item>
      <title>A Gentle Introduction and Tutorial on Deep Generative Models in Transportation Research</title>
      <link>https://paperswithcode.com/paper/a-gentle-introduction-and-tutorial-on-deep</link>
      <description><![CDATA[Deep Generative Models (DGMs) have rapidly advanced in recent years, becoming essential tools in various fields due to their ability to learn complex data distributions and generate synthetic data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-gentle-introduction-and-tutorial-on-deep</guid>
    </item>
    <item>
      <title>Dynamic metastability in the self-attention model</title>
      <link>https://paperswithcode.com/paper/dynamic-metastability-in-the-self-attention</link>
      <description><![CDATA[We finally probe the dynamics beyond the exponentially long period of metastability, and illustrate that, under an appropriate time-rescaling, the energy reaches its global maximum in finite time and has a staircase profile, with trajectories manifesting saddle-to-saddle-like behavior, reminiscent of recent works in the analysis of training dynamics via gradient descent for two-layer neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-metastability-in-the-self-attention</guid>
    </item>
    <item>
      <title>Rethinking the Evaluation of Visible and Infrared Image Fusion</title>
      <link>https://paperswithcode.com/paper/rethinking-the-evaluation-of-visible-and</link>
      <description><![CDATA[Visible and Infrared Image Fusion (VIF) has garnered significant interest across a wide range of high-level vision tasks, such as object detection and semantic segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-the-evaluation-of-visible-and</guid>
    </item>
    <item>
      <title>Deciphering Cross-Modal Alignment in Large Vision-Language Models with Modality Integration Rate</title>
      <link>https://paperswithcode.com/paper/deciphering-cross-modal-alignment-in-large</link>
      <description><![CDATA[We present the Modality Integration Rate (MIR), an effective, robust, and generalized metric to indicate the multi-modal pre-training quality of Large Vision Language Models (LVLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deciphering-cross-modal-alignment-in-large</guid>
    </item>
    <item>
      <title>Personalized Visual Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/personalized-visual-instruction-tuning</link>
      <description><![CDATA[In this paper, we introduce Personalized Visual Instruction Tuning (PVIT), a novel data curation and training framework designed to enable MLLMs to identify target individuals within an image and engage in personalized and coherent dialogues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalized-visual-instruction-tuning</guid>
    </item>
    <item>
      <title>Deep Correlated Prompting for Visual Recognition with Missing Modalities</title>
      <link>https://paperswithcode.com/paper/deep-correlated-prompting-for-visual</link>
      <description><![CDATA[Plentiful ablations are further given to show the generalizability and reliability of our method upon different modality-missing ratios and types.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-correlated-prompting-for-visual</guid>
    </item>
    <item>
      <title>MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders</title>
      <link>https://paperswithcode.com/paper/mentalarena-self-play-training-of-language</link>
      <description><![CDATA[In this paper, we introduce MentalArena, a self-play framework to train language models by generating domain-specific personalized data, where we obtain a better model capable of making a personalized diagnosis and treatment (as a therapist) and providing information (as a patient).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mentalarena-self-play-training-of-language</guid>
    </item>
    <item>
      <title>On the Similarity of Circuits across Languages: a Case Study on the Subject-verb Agreement Task</title>
      <link>https://paperswithcode.com/paper/on-the-similarity-of-circuits-across</link>
      <description><![CDATA[Notably, this subject number signal is represented as a direction in the residual stream space, and is language-independent.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-similarity-of-circuits-across</guid>
    </item>
    <item>
      <title>NeRF-Accelerated Ecological Monitoring in Mixed-Evergreen Redwood Forest</title>
      <link>https://paperswithcode.com/paper/nerf-accelerated-ecological-monitoring-in</link>
      <description><![CDATA[In this paper, we present a comparison of MLS and NeRF forest reconstructions for the purpose of trunk diameter estimation in a mixed-evergreen Redwood forest.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nerf-accelerated-ecological-monitoring-in</guid>
    </item>
    <item>
      <title>HFH-Font: Few-shot Chinese Font Synthesis with Higher Quality, Faster Speed, and Higher Resolution</title>
      <link>https://paperswithcode.com/paper/hfh-font-few-shot-chinese-font-synthesis-with</link>
      <description><![CDATA[Using our method, for the first time, large-scale Chinese vector fonts of a quality comparable to those manually created by professional font designers can be automatically generated.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hfh-font-few-shot-chinese-font-synthesis-with</guid>
    </item>
    <item>
      <title>TinyEmo: Scaling down Emotional Reasoning via Metric Projection</title>
      <link>https://paperswithcode.com/paper/tinyemo-scaling-down-emotional-reasoning-via</link>
      <description><![CDATA[Our approach features: (1) a synthetic emotional instruct dataset for both pre-training and fine-tuning stages, (2) a Metric Projector that delegates classification from the language model allowing for more efficient training and inference, (3) a multi-modal large language model (MM-LLM) for emotional reasoning, and (4) a semi-automated framework for bias detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tinyemo-scaling-down-emotional-reasoning-via</guid>
    </item>
    <item>
      <title>Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning</title>
      <link>https://paperswithcode.com/paper/is-c4-dataset-optimal-for-pruning-an</link>
      <description><![CDATA[In this study, we evaluate the choice of calibration data on LLM pruning, across a wide range of datasets that are most commonly used in LLM training and evaluation, including four pertaining datasets as well as three categories of downstream tasks encompassing nine datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-c4-dataset-optimal-for-pruning-an</guid>
    </item>
    <item>
      <title>Pixtral 12B</title>
      <link>https://paperswithcode.com/paper/pixtral-12b</link>
      <description><![CDATA[Unlike many open-source models, Pixtral is also a cutting-edge text model for its size, and does not compromise on natural language performance to excel in multimodal tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pixtral-12b</guid>
    </item>
    <item>
      <title>Shap-Select: Lightweight Feature Selection Using SHAP Values and Regression</title>
      <link>https://paperswithcode.com/paper/shap-select-lightweight-feature-selection</link>
      <description><![CDATA[Feature selection is an essential process in machine learning, especially when dealing with high-dimensional datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shap-select-lightweight-feature-selection</guid>
    </item>
  </channel>
</rss>
