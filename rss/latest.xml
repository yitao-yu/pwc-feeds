<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 30 Mar 2025 09:15:20 +0000</lastBuildDate>
    <item>
      <title>Exploring the Evolution of Physics Cognition in Video Generation: A Survey</title>
      <link>https://paperswithcode.com/paper/exploring-the-evolution-of-physics-cognition</link>
      <description><![CDATA[Recent advancements in video generation have witnessed significant progress, especially with the rapid advancement of diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-evolution-of-physics-cognition</guid>
    </item>
    <item>
      <title>VADMamba: Exploring State Space Models for Fast Video Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/vadmamba-exploring-state-space-models-for</link>
      <description><![CDATA[Video anomaly detection (VAD) methods are mostly CNN-based or Transformer-based, achieving impressive results, but the focus on detection accuracy often comes at the expense of inference speed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vadmamba-exploring-state-space-models-for</guid>
    </item>
    <item>
      <title>FineCIR: Explicit Parsing of Fine-Grained Modification Semantics for Composed Image Retrieval</title>
      <link>https://paperswithcode.com/paper/finecir-explicit-parsing-of-fine-grained</link>
      <description><![CDATA[Using this pipeline, we refine the FashionIQ and CIRR datasets to create two fine-grained CIR datasets: Fine-FashionIQ and Fine-CIRR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finecir-explicit-parsing-of-fine-grained</guid>
    </item>
    <item>
      <title>Harnessing Chain-of-Thought Metadata for Task Routing and Adversarial Prompt Detection</title>
      <link>https://paperswithcode.com/paper/harnessing-chain-of-thought-metadata-for-task</link>
      <description><![CDATA[In this work, we propose a metric called Number of Thoughts (NofT) to determine the difficulty of tasks pre-prompting and support Large Language Models (LLMs) in production contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/harnessing-chain-of-thought-metadata-for-task</guid>
    </item>
    <item>
      <title>R-PRM: Reasoning-Driven Process Reward Modeling</title>
      <link>https://paperswithcode.com/paper/r-prm-reasoning-driven-process-reward</link>
      <description><![CDATA[Large language models (LLMs) inevitably make mistakes when performing step-by-step mathematical reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r-prm-reasoning-driven-process-reward</guid>
    </item>
    <item>
      <title>As easy as PIE: understanding when pruning causes language models to disagree</title>
      <link>https://paperswithcode.com/paper/as-easy-as-pie-understanding-when-pruning</link>
      <description><![CDATA[However, when looking at how individual data points are affected by pruning, it turns out that a particular subset of data points always bears most of the brunt (in terms of reduced accuracy) when pruning, but this effect goes unnoticed when reporting the mean accuracy of all data points.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/as-easy-as-pie-understanding-when-pruning</guid>
    </item>
    <item>
      <title>OpenHuEval: Evaluating Large Language Model on Hungarian Specifics</title>
      <link>https://paperswithcode.com/paper/openhueval-evaluating-large-language-model-on</link>
      <description><![CDATA[We introduce OpenHuEval, the first benchmark for LLMs focusing on the Hungarian language and specifics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openhueval-evaluating-large-language-model-on</guid>
    </item>
    <item>
      <title>Large Language Model Agent: A Survey on Methodology, Applications and Challenges</title>
      <link>https://paperswithcode.com/paper/large-language-model-agent-a-survey-on</link>
      <description><![CDATA[The era of intelligent agents is upon us, driven by revolutionary advancements in large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-model-agent-a-survey-on</guid>
    </item>
    <item>
      <title>AugWard: Augmentation-Aware Representation Learning for Accurate Graph Classification</title>
      <link>https://paperswithcode.com/paper/augward-augmentation-aware-representation</link>
      <description><![CDATA[In this paper, we propose AugWard (Augmentation-Aware Training with Graph Distance and Consistency Regularization), a novel graph representation learning framework that carefully considers the diversity introduced by graph augmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/augward-augmentation-aware-representation</guid>
    </item>
    <item>
      <title>VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic Faithfulness</title>
      <link>https://paperswithcode.com/paper/vbench-2-0-advancing-video-generation</link>
      <description><![CDATA[To bridge this gap, we introduce VBench-2. 0, a next-generation benchmark designed to automatically evaluate video generative models for their intrinsic faithfulness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vbench-2-0-advancing-video-generation</guid>
    </item>
    <item>
      <title>Challenging the Boundaries of Reasoning: An Olympiad-Level Math Benchmark for Large Language Models</title>
      <link>https://paperswithcode.com/paper/challenging-the-boundaries-of-reasoning-an</link>
      <description><![CDATA[In recent years, the rapid development of large reasoning models has resulted in the saturation of existing benchmarks for evaluating mathematical reasoning, highlighting the urgent need for more challenging and rigorous evaluation frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/challenging-the-boundaries-of-reasoning-an</guid>
    </item>
    <item>
      <title>vGamba: Attentive State Space Bottleneck for efficient Long-range Dependencies in Visual Recognition</title>
      <link>https://paperswithcode.com/paper/vgamba-attentive-state-space-bottleneck-for</link>
      <description><![CDATA[The interplay of these components ensures that vGamba leverages the low computational demands of SSMs while maintaining the accuracy of attention mechanisms for modeling long-range dependencies in vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vgamba-attentive-state-space-bottleneck-for</guid>
    </item>
    <item>
      <title>HyperGraphRAG: Retrieval-Augmented Generation with Hypergraph-Structured Knowledge Representation</title>
      <link>https://paperswithcode.com/paper/hypergraphrag-retrieval-augmented-generation</link>
      <description><![CDATA[To retrieve and generate over hypergraphs, we introduce a complete pipeline with a hypergraph construction method, a hypergraph retrieval strategy, and a hypergraph-guided generation mechanism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hypergraphrag-retrieval-augmented-generation</guid>
    </item>
    <item>
      <title>Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for Embodied Interactive Tasks</title>
      <link>https://paperswithcode.com/paper/embodied-reasoner-synergizing-visual-search</link>
      <description><![CDATA[Recent advances in deep thinking models have demonstrated remarkable reasoning capabilities on mathematical and coding tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embodied-reasoner-synergizing-visual-search</guid>
    </item>
    <item>
      <title>SWI: Speaking with Intent in Large Language Models</title>
      <link>https://paperswithcode.com/paper/swi-speaking-with-intent-in-large-language</link>
      <description><![CDATA[Intent, typically clearly formulated and planned, functions as a cognitive framework for reasoning and problem-solving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/swi-speaking-with-intent-in-large-language</guid>
    </item>
    <item>
      <title>Lumina-Image 2.0: A Unified and Efficient Image Generative Framework</title>
      <link>https://paperswithcode.com/paper/lumina-image-2-0-a-unified-and-efficient</link>
      <description><![CDATA[We introduce Lumina-Image 2. 0, an advanced text-to-image generation framework that achieves significant progress compared to previous work, Lumina-Next.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lumina-image-2-0-a-unified-and-efficient</guid>
    </item>
    <item>
      <title>Vision-to-Music Generation: A Survey</title>
      <link>https://paperswithcode.com/paper/vision-to-music-generation-a-survey</link>
      <description><![CDATA[Vision-to-music Generation, including video-to-music and image-to-music tasks, is a significant branch of multimodal artificial intelligence demonstrating vast application prospects in fields such as film scoring, short video creation, and dance music synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-to-music-generation-a-survey</guid>
    </item>
    <item>
      <title>Improvement Graph Convolution Collaborative Filtering with Weighted addition input</title>
      <link>https://paperswithcode.com/paper/improvement-graph-convolution-collaborative</link>
      <description><![CDATA[The ratings of users on considered items can be represented by graphs which are input for many efficient models to find out the characteristics of the users and the items.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improvement-graph-convolution-collaborative</guid>
    </item>
    <item>
      <title>ProHOC: Probabilistic Hierarchical Out-of-Distribution Classification via Multi-Depth Networks</title>
      <link>https://paperswithcode.com/paper/prohoc-probabilistic-hierarchical-out-of</link>
      <description><![CDATA[Out-of-distribution (OOD) detection in deep learning has traditionally been framed as a binary task, where samples are either classified as belonging to the known classes or marked as OOD, with little attention given to the semantic relationships between OOD samples and the in-distribution (ID) classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prohoc-probabilistic-hierarchical-out-of</guid>
    </item>
    <item>
      <title>PLAIN: Scalable Estimation Architecture for Integrated Sensing and Communication</title>
      <link>https://paperswithcode.com/paper/plain-scalable-estimation-architecture-for</link>
      <description><![CDATA[In this work, we propose PLAIN, a tensor-based estimation architecture that flexibly scales with multiple sensing dimensions and can handle high dimensionality, limited measurement time, and super-resolution requirements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plain-scalable-estimation-architecture-for</guid>
    </item>
    <item>
      <title>Towards Generating Realistic 3D Semantic Training Data for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/towards-generating-realistic-3d-semantic</link>
      <description><![CDATA[In our experiments, we show that using the synthetic annotated data generated by our method as training data together with the real semantic segmentation labels, leads to an improvement in the semantic segmentation model performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-generating-realistic-3d-semantic</guid>
    </item>
    <item>
      <title>Prompting Vision-Language Model for Nuclei Instance Segmentation and Classification</title>
      <link>https://paperswithcode.com/paper/prompting-vision-language-model-for-nuclei</link>
      <description><![CDATA[Nuclei instance segmentation and classification are a fundamental and challenging task in whole slide Imaging (WSI) analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompting-vision-language-model-for-nuclei</guid>
    </item>
    <item>
      <title>FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs</title>
      <link>https://paperswithcode.com/paper/facebench-a-multi-view-multi-level-facial</link>
      <description><![CDATA[Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in various tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/facebench-a-multi-view-multi-level-facial</guid>
    </item>
    <item>
      <title>BOLT: Boost Large Vision-Language Model Without Training for Long-form Video Understanding</title>
      <link>https://paperswithcode.com/paper/bolt-boost-large-vision-language-model</link>
      <description><![CDATA[In this paper, we introduce BOLT, a method to BOost Large VLMs without additional Training through a comprehensive study of frame selection strategies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bolt-boost-large-vision-language-model</guid>
    </item>
    <item>
      <title>Optimal Stepsize for Diffusion Sampling</title>
      <link>https://paperswithcode.com/paper/optimal-stepsize-for-diffusion-sampling</link>
      <description><![CDATA[Diffusion models achieve remarkable generation quality but suffer from computational intensive sampling due to suboptimal step discretization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimal-stepsize-for-diffusion-sampling</guid>
    </item>
    <item>
      <title>Effective Skill Unlearning through Intervention and Abstention</title>
      <link>https://paperswithcode.com/paper/effective-skill-unlearning-through</link>
      <description><![CDATA[Based on these observations, we propose two lightweight, training-free skill unlearning methods via \textit{intervention} and \textit{abstention} respectively: \texttt{Neuron Adjust} and \texttt{Key Space Detection}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effective-skill-unlearning-through</guid>
    </item>
    <item>
      <title>Semantic Library Adaptation: LoRA Retrieval and Fusion for Open-Vocabulary Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/semantic-library-adaptation-lora-retrieval</link>
      <description><![CDATA[Open-vocabulary semantic segmentation models associate vision and text to label pixels from an undefined set of classes using textual queries, providing versatile performance on novel datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-library-adaptation-lora-retrieval</guid>
    </item>
    <item>
      <title>Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data</title>
      <link>https://paperswithcode.com/paper/progressive-rendering-distillation-adapting</link>
      <description><![CDATA[Aiming at overcoming the data shortage, we propose a novel training scheme, termed as Progressive Rendering Distillation (PRD), eliminating the need for 3D ground-truths by distilling multi-view diffusion models and adapting SD into a native 3D generator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progressive-rendering-distillation-adapting</guid>
    </item>
    <item>
      <title>Intelligent IoT Attack Detection Design via ODLLM with Feature Ranking-based Knowledge Base</title>
      <link>https://paperswithcode.com/paper/intelligent-iot-attack-detection-design-via</link>
      <description><![CDATA[The widespread adoption of Internet of Things (IoT) devices has introduced significant cybersecurity challenges, particularly with the increasing frequency and sophistication of Distributed Denial of Service (DDoS) attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intelligent-iot-attack-detection-design-via</guid>
    </item>
    <item>
      <title>Mobile-VideoGPT: Fast and Accurate Video Understanding Language Model</title>
      <link>https://paperswithcode.com/paper/mobile-videogpt-fast-and-accurate-video</link>
      <description><![CDATA[To tackle these challenges, we propose Mobile-VideoGPT, an efficient multimodal framework designed to operate with fewer than a billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobile-videogpt-fast-and-accurate-video</guid>
    </item>
    <item>
      <title>Elementwise Layer Normalization</title>
      <link>https://paperswithcode.com/paper/elementwise-layer-normalization</link>
      <description><![CDATA[A recent paper proposed Dynamic Tanh (DyT) as a drop-in replacement for Layer Normalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elementwise-layer-normalization</guid>
    </item>
    <item>
      <title>LOCATEdit: Graph Laplacian Optimized Cross Attention for Localized Text-Guided Image Editing</title>
      <link>https://paperswithcode.com/paper/locatedit-graph-laplacian-optimized-cross</link>
      <description><![CDATA[Text-guided image editing aims to modify specific regions of an image according to natural language instructions while maintaining the general structure and the background fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/locatedit-graph-laplacian-optimized-cross</guid>
    </item>
    <item>
      <title>Test-Time Visual In-Context Tuning</title>
      <link>https://paperswithcode.com/paper/test-time-visual-in-context-tuning</link>
      <description><![CDATA[Visual in-context learning (VICL), as a new paradigm in computer vision, allows the model to rapidly adapt to various tasks with only a handful of prompts and examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/test-time-visual-in-context-tuning</guid>
    </item>
    <item>
      <title>When Astronomy Meets AI: Manazel For Crescent Visibility Prediction in Morocco</title>
      <link>https://paperswithcode.com/paper/when-astronomy-meets-ai-manazel-for-crescent</link>
      <description><![CDATA[The accurate determination of the beginning of each Hijri month is essential for religious, cultural, and administrative purposes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-astronomy-meets-ai-manazel-for-crescent</guid>
    </item>
    <item>
      <title>A Unified Image-Dense Annotation Generation Model for Underwater Scenes</title>
      <link>https://paperswithcode.com/paper/a-unified-image-dense-annotation-generation</link>
      <description><![CDATA[This paper proposes a unified Text-to-Image and DEnse annotation generation method (TIDE) for underwater scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-unified-image-dense-annotation-generation</guid>
    </item>
    <item>
      <title>Video-R1: Reinforcing Video Reasoning in MLLMs</title>
      <link>https://paperswithcode.com/paper/video-r1-reinforcing-video-reasoning-in-mllms</link>
      <description><![CDATA[However, directly applying RL training with the GRPO algorithm to video reasoning presents two primary challenges: (i) a lack of temporal modeling for video reasoning, and (ii) the scarcity of high-quality video-reasoning data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-r1-reinforcing-video-reasoning-in-mllms</guid>
    </item>
    <item>
      <title>Multi-Scale Invertible Neural Network for Wide-Range Variable-Rate Learned Image Compression</title>
      <link>https://paperswithcode.com/paper/multi-scale-invertible-neural-network-for</link>
      <description><![CDATA[Autoencoder-based structures have dominated recent learned image compression methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-invertible-neural-network-for</guid>
    </item>
    <item>
      <title>Nearest Neighbour Equilibrium Clustering</title>
      <link>https://paperswithcode.com/paper/nearest-neighbour-equilibrium-clustering</link>
      <description><![CDATA[A novel and intuitive nearest neighbours based clustering algorithm is introduced, in which a cluster is defined in terms of an equilibrium condition which balances its size and cohesiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nearest-neighbour-equilibrium-clustering</guid>
    </item>
    <item>
      <title>Rerouting Connection: Hybrid Computer Vision Analysis Reveals Visual Similarity Between Indus and Tibetan-Yi Corridor Writing Systems</title>
      <link>https://paperswithcode.com/paper/rerouting-connection-hybrid-computer-vision</link>
      <description><![CDATA[This thesis employs a hybrid CNN-Transformer architecture, in conjunction with a detailed anthropological framework, to investigate potential historical connections between the visual morphology of the Indus Valley script and pictographic systems of the Tibetan-Yi Corridor.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rerouting-connection-hybrid-computer-vision</guid>
    </item>
    <item>
      <title>HSLiNets: Evaluating Band Ordering Strategies in Hyperspectral and LiDAR Fusion</title>
      <link>https://paperswithcode.com/paper/hslinets-evaluating-band-ordering-strategies</link>
      <description><![CDATA[The integration of hyperspectral imaging (HSI) and Light Detection and Ranging (LiDAR) data provides complementary spectral and spatial information for remote sensing applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hslinets-evaluating-band-ordering-strategies</guid>
    </item>
    <item>
      <title>Keyword-Oriented Multimodal Modeling for Euphemism Identification</title>
      <link>https://paperswithcode.com/paper/keyword-oriented-multimodal-modeling-for</link>
      <description><![CDATA[Euphemism identification deciphers the true meaning of euphemisms, such as linking "weed" (euphemism) to "marijuana" (target keyword) in illicit texts, aiding content moderation and combating underground markets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/keyword-oriented-multimodal-modeling-for</guid>
    </item>
    <item>
      <title>Recurrent Feature Mining and Keypoint Mixup Padding for Category-Agnostic Pose Estimation</title>
      <link>https://paperswithcode.com/paper/recurrent-feature-mining-and-keypoint-mixup</link>
      <description><![CDATA[Hence, these works neglect to mine fine-grained and structure-aware (FGSA) features from both support and query images, which are crucial for pixel-level keypoint localization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recurrent-feature-mining-and-keypoint-mixup</guid>
    </item>
    <item>
      <title>DGSUnet: An Improved Unet Model with DINO-Guided SAM2 for Multi-Scale Feature Collaboration</title>
      <link>https://paperswithcode.com/paper/dgsunet-an-improved-unet-model-with-dino</link>
      <description><![CDATA[Despite the significant advancements in general image segmentation achieved by large-scale pre-trained foundation models (such as Meta's Segment Any-thing Model (SAM) series and DINOv2), their performance in specialized fields remains limited by two critical issues: the excessive training costs due to large model parameters, and the insufficient ability to represent specific domain characteristics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dgsunet-an-improved-unet-model-with-dino</guid>
    </item>
    <item>
      <title>Reinforced Model Merging</title>
      <link>https://paperswithcode.com/paper/reinforced-model-merging</link>
      <description><![CDATA[The success of large language models has garnered widespread attention for model merging techniques, especially training-free methods which combine model capabilities within the parameter space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforced-model-merging</guid>
    </item>
    <item>
      <title>ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging</title>
      <link>https://paperswithcode.com/paper/zjuklab-at-semeval-2025-task-4-unlearning-via</link>
      <description><![CDATA[This paper presents the ZJUKLAB team's submission for SemEval-2025 Task 4: Unlearning Sensitive Content from Large Language Models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zjuklab-at-semeval-2025-task-4-unlearning-via</guid>
    </item>
    <item>
      <title>Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/learning-class-prototypes-for-unified-sparse</link>
      <description><![CDATA[To this end, we propose a unified sparse supervised 3D object detection method for both indoor and outdoor scenes through learning class prototypes to effectively utilize unlabeled objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-class-prototypes-for-unified-sparse</guid>
    </item>
    <item>
      <title>A Comprehensive Benchmark for RNA 3D Structure-Function Modeling</title>
      <link>https://paperswithcode.com/paper/a-comprehensive-benchmark-for-rna-3d</link>
      <description><![CDATA[The RNA structure-function relationship has recently garnered significant attention within the deep learning community, promising to grow in importance as nucleic acid structure models advance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comprehensive-benchmark-for-rna-3d</guid>
    </item>
    <item>
      <title>BioX-CPath: Biologically-driven Explainable Diagnostics for Multistain IHC Computational Pathology</title>
      <link>https://paperswithcode.com/paper/biox-cpath-biologically-driven-explainable</link>
      <description><![CDATA[The development of biologically interpretable and explainable models remains a key challenge in computational pathology, particularly for multistain immunohistochemistry (IHC) analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biox-cpath-biologically-driven-explainable</guid>
    </item>
    <item>
      <title>TS-Inverse: A Gradient Inversion Attack Tailored for Federated Time Series Forecasting Models</title>
      <link>https://paperswithcode.com/paper/ts-inverse-a-gradient-inversion-attack</link>
      <description><![CDATA[We then propose TS-Inverse, a novel GIA that improves the inversion of TS data by (i) learning a gradient inversion model that outputs quantile predictions, (ii) a unique loss function that incorporates periodicity and trend regularization, and (iii) regularization according to the quantile predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ts-inverse-a-gradient-inversion-attack</guid>
    </item>
    <item>
      <title>Representation Improvement in Latent Space for Search-Based Testing of Autonomous Robotic Systems</title>
      <link>https://paperswithcode.com/paper/representation-improvement-in-latent-space</link>
      <description><![CDATA[Testing autonomous robotic systems, such as self-driving cars and unmanned aerial vehicles, is challenging due to their interaction with highly unpredictable environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representation-improvement-in-latent-space</guid>
    </item>
  </channel>
</rss>
