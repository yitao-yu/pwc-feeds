<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 07 Jul 2023 21:06:58 +0000</lastBuildDate>
    <item>
      <title>RecallM: An Architecture for Temporal Context Understanding and Question Answering</title>
      <link>https://paperswithcode.com/paper/recallm-an-architecture-for-temporal-context</link>
      <description><![CDATA[The ideal long-term memory mechanism for Large Language Model (LLM) based chatbots, would lay the foundation for continual learning, complex reasoning and allow sequential and temporal dependencies to be learnt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recallm-an-architecture-for-temporal-context</guid>
    </item>
    <item>
      <title>Learning Disentangled Representations in Signed Directed Graphs without Social Assumptions</title>
      <link>https://paperswithcode.com/paper/learning-disentangled-representations-in-1</link>
      <description><![CDATA[In this paper, we propose DINES, a novel method for learning disentangled node representations in signed directed graphs without social assumptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-disentangled-representations-in-1</guid>
    </item>
    <item>
      <title>Learning Curves for Heterogeneous Feature-Subsampled Ridge Ensembles</title>
      <link>https://paperswithcode.com/paper/learning-curves-for-heterogeneous-feature</link>
      <description><![CDATA[We study an ensemble of linear predictors, each fit using ridge regression on a subset of the available features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-curves-for-heterogeneous-feature</guid>
    </item>
    <item>
      <title>Improving Retrieval-Augmented Large Language Models via Data Importance Learning</title>
      <link>https://paperswithcode.com/paper/improving-retrieval-augmented-large-language</link>
      <description><![CDATA[There are exponentially many terms in the multilinear extension, and one key contribution of this paper is a polynomial time algorithm that computes exactly, given a retrieval-augmented model with an additive utility function and a validation set, the data importance of data points in the retrieval corpus using the multilinear extension of the model's utility function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-retrieval-augmented-large-language</guid>
    </item>
    <item>
      <title>BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training</title>
      <link>https://paperswithcode.com/paper/bleurt-has-universal-translations-an-analysis</link>
      <description><![CDATA[In this study, we systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of their guidance for training machine translation systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bleurt-has-universal-translations-an-analysis</guid>
    </item>
    <item>
      <title>Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback</title>
      <link>https://paperswithcode.com/paper/censored-sampling-of-diffusion-models-using-3</link>
      <description><![CDATA[Sometimes, however, a pre-trained diffusion model exhibits partial misalignment in the sense that the model can generate good images, but it sometimes outputs undesirable images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/censored-sampling-of-diffusion-models-using-3</guid>
    </item>
    <item>
      <title>Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning</title>
      <link>https://paperswithcode.com/paper/proto-clip-vision-language-prototypical</link>
      <description><![CDATA[The two encoders are used to compute prototypes of image classes for classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proto-clip-vision-language-prototypical</guid>
    </item>
    <item>
      <title>ContainerGym: A Real-World Reinforcement Learning Benchmark for Resource Allocation</title>
      <link>https://paperswithcode.com/paper/containergym-a-real-world-reinforcement</link>
      <description><![CDATA[It is sufficiently versatile to evaluate reinforcement learning algorithms on any real-world problem that fits our resource allocation framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/containergym-a-real-world-reinforcement</guid>
    </item>
    <item>
      <title>Distilling Large Vision-Language Model with Out-of-Distribution Generalizability</title>
      <link>https://paperswithcode.com/paper/distilling-large-vision-language-model-with</link>
      <description><![CDATA[Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distilling-large-vision-language-model-with</guid>
    </item>
    <item>
      <title>Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification</title>
      <link>https://paperswithcode.com/paper/benchmarking-test-time-adaptation-against</link>
      <description><![CDATA[To implement this benchmark, we have developed a unified framework in PyTorch, which allows for consistent evaluation and comparison of the TTA methods across the different datasets and network architectures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-test-time-adaptation-against</guid>
    </item>
    <item>
      <title>Through the Fairness Lens: Experimental Analysis and Evaluation of Entity Matching</title>
      <link>https://paperswithcode.com/paper/through-the-fairness-lens-experimental</link>
      <description><![CDATA[Entity matching (EM) is a challenging problem studied by different communities for over half a century.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/through-the-fairness-lens-experimental</guid>
    </item>
    <item>
      <title>Towards accurate instance segmentation in large-scale LiDAR point clouds</title>
      <link>https://paperswithcode.com/paper/towards-accurate-instance-segmentation-in</link>
      <description><![CDATA[Panoptic segmentation is the combination of semantic and instance segmentation: assign the points in a 3D point cloud to semantic categories and partition them into distinct object instances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-accurate-instance-segmentation-in</guid>
    </item>
    <item>
      <title>Advancing Zero-Shot Digital Human Quality Assessment through Text-Prompted Evaluation</title>
      <link>https://paperswithcode.com/paper/advancing-zero-shot-digital-human-quality</link>
      <description><![CDATA[To address this gap, we propose SJTU-H3D, a subjective quality assessment database specifically designed for full-body digital humans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-zero-shot-digital-human-quality</guid>
    </item>
    <item>
      <title>Fourier-Net+: Leveraging Band-Limited Representation for Efficient 3D Medical Image Registration</title>
      <link>https://paperswithcode.com/paper/fourier-net-leveraging-band-limited</link>
      <description><![CDATA[Instead of directly predicting a full-resolution displacement field, our Fourier-Net learns a low-dimensional representation of the displacement field in the band-limited Fourier domain which our model-driven decoder converts to a full-resolution displacement field in the spatial domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fourier-net-leveraging-band-limited</guid>
    </item>
    <item>
      <title>Focused Transformer: Contrastive Training for Context Scaling</title>
      <link>https://paperswithcode.com/paper/focused-transformer-contrastive-training-for</link>
      <description><![CDATA[This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/focused-transformer-contrastive-training-for</guid>
    </item>
    <item>
      <title>Efficient Domain Adaptation of Sentence Embeddings using Adapters</title>
      <link>https://paperswithcode.com/paper/efficient-domain-adaptation-of-sentence</link>
      <description><![CDATA[Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-domain-adaptation-of-sentence</guid>
    </item>
    <item>
      <title>Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/semi-supervised-domain-adaptive-medical-image</link>
      <description><![CDATA[In this work, we investigate relatively less explored semi-supervised domain adaptation (SSDA) for medical image segmentation, where access to a few labeled target samples can improve the adaptation performance substantially.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semi-supervised-domain-adaptive-medical-image</guid>
    </item>
    <item>
      <title>The Role of Subgroup Separability in Group-Fair Medical Image Classification</title>
      <link>https://paperswithcode.com/paper/the-role-of-subgroup-separability-in-group</link>
      <description><![CDATA[We investigate performance disparities in deep classifiers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-role-of-subgroup-separability-in-group</guid>
    </item>
    <item>
      <title>A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications</title>
      <link>https://paperswithcode.com/paper/a-privacy-preserving-walk-in-the-latent-space</link>
      <description><![CDATA[Generative Adversarial Networks (GANs) have demonstrated their ability to generate synthetic samples that match a target distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-privacy-preserving-walk-in-the-latent-space</guid>
    </item>
    <item>
      <title>DeepOnto: A Python Package for Ontology Engineering with Deep Learning</title>
      <link>https://paperswithcode.com/paper/deeponto-a-python-package-for-ontology</link>
      <description><![CDATA[Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deeponto-a-python-package-for-ontology</guid>
    </item>
    <item>
      <title>Generalizing Backpropagation for Gradient-Based Interpretability</title>
      <link>https://paperswithcode.com/paper/generalizing-backpropagation-for-gradient</link>
      <description><![CDATA[Many popular feature-attribution methods for interpreting deep neural networks rely on computing the gradients of a model's output with respect to its inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizing-backpropagation-for-gradient</guid>
    </item>
    <item>
      <title>BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables</title>
      <link>https://paperswithcode.com/paper/babe-enhancing-fairness-via-estimation-of</link>
      <description><![CDATA[We consider the problem of unfair discrimination between two groups and propose a pre-processing method to achieve fairness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/babe-enhancing-fairness-via-estimation-of</guid>
    </item>
    <item>
      <title>KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text Understanding</title>
      <link>https://paperswithcode.com/paper/korc-knowledge-oriented-reading-comprehension</link>
      <description><![CDATA[However, these benchmarks have encountered two major limitations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/korc-knowledge-oriented-reading-comprehension</guid>
    </item>
    <item>
      <title>Efficient Semiring-Weighted Earley Parsing</title>
      <link>https://paperswithcode.com/paper/efficient-semiring-weighted-earley-parsing</link>
      <description><![CDATA[This paper provides a reference description, in the form of a deduction system, of Earley's (1970) context-free parsing algorithm with various speed-ups.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-semiring-weighted-earley-parsing</guid>
    </item>
    <item>
      <title>Knowledge Graph Self-Supervised Rationalization for Recommendation</title>
      <link>https://paperswithcode.com/paper/knowledge-graph-self-supervised</link>
      <description><![CDATA[By masking important knowledge with high rational scores, KGRec is trained to rebuild and highlight useful knowledge connections that serve as rationales.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/knowledge-graph-self-supervised</guid>
    </item>
    <item>
      <title>ALPCAH: Sample-wise Heteroscedastic PCA with Tail Singular Value Regularization</title>
      <link>https://paperswithcode.com/paper/alpcah-sample-wise-heteroscedastic-pca-with</link>
      <description><![CDATA[Other methods such as Weighted PCA (WPCA) assume the noise variances are known, which may be difficult to know in practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alpcah-sample-wise-heteroscedastic-pca-with</guid>
    </item>
    <item>
      <title>Your spouse needs professional help: Determining the Contextual Appropriateness of Messages through Modeling Social Relationships</title>
      <link>https://paperswithcode.com/paper/your-spouse-needs-professional-help</link>
      <description><![CDATA[We introduce a new dataset of contextually-situated judgments of appropriateness and show that large language models can readily incorporate relationship information to accurately identify appropriateness in a given context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/your-spouse-needs-professional-help</guid>
    </item>
    <item>
      <title>T-MARS: Improving Visual Representations by Circumventing Text Feature Learning</title>
      <link>https://paperswithcode.com/paper/t-mars-improving-visual-representations-by</link>
      <description><![CDATA[However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t-mars-improving-visual-representations-by</guid>
    </item>
    <item>
      <title>CFSum: A Coarse-to-Fine Contribution Network for Multimodal Summarization</title>
      <link>https://paperswithcode.com/paper/cfsum-a-coarse-to-fine-contribution-network</link>
      <description><![CDATA[Therefore, we propose a novel Coarse-to-Fine contribution network for multimodal Summarization (CFSum) to consider different contributions of images for summarization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cfsum-a-coarse-to-fine-contribution-network</guid>
    </item>
    <item>
      <title>A Survey on Evaluation of Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-on-evaluation-of-large-language</link>
      <description><![CDATA[Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-evaluation-of-large-language</guid>
    </item>
    <item>
      <title>Learning to Solve Tasks with Exploring Prior Behaviours</title>
      <link>https://paperswithcode.com/paper/learning-to-solve-tasks-with-exploring-prior</link>
      <description><![CDATA[Our method can endow agents with the ability to explore and acquire the required prior behaviours and then connect to the task-specific behaviours in the demonstration to solve sparse-reward tasks without requiring additional demonstration of the prior behaviours.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-solve-tasks-with-exploring-prior</guid>
    </item>
    <item>
      <title>Transfer Learning for the Efficient Detection of COVID-19 from Smartphone Audio Data</title>
      <link>https://paperswithcode.com/paper/transfer-learning-for-the-efficient-detection</link>
      <description><![CDATA[The efficacy of this solution mainly depends on the performances of AI algorithms applied to the collected data and their possible implementation directly on the users' mobile devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transfer-learning-for-the-efficient-detection</guid>
    </item>
    <item>
      <title>LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams</title>
      <link>https://paperswithcode.com/paper/leo-learning-efficient-orderings-for</link>
      <description><![CDATA[We show how the configuration space can be efficiently explored using black-box optimization, circumventing the curse of dimensionality (in the number of variables and objectives), and finding good orderings that reduce the PF enumeration time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leo-learning-efficient-orderings-for</guid>
    </item>
    <item>
      <title>GAFAR: Graph-Attention Feature-Augmentation for Registration A Fast and Light-weight Point Set Registration Algorithm</title>
      <link>https://paperswithcode.com/paper/gafar-graph-attention-feature-augmentation</link>
      <description><![CDATA[Rigid registration of point clouds is a fundamental problem in computer vision with many applications from 3D scene reconstruction to geometry capture and robotics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gafar-graph-attention-feature-augmentation</guid>
    </item>
    <item>
      <title>Zero-Shot Neural Architecture Search: Challenges, Solutions, and Opportunities</title>
      <link>https://paperswithcode.com/paper/zero-shot-neural-architecture-search</link>
      <description><![CDATA[Recently, zero-shot (or training-free) Neural Architecture Search (NAS) approaches have been proposed to liberate the NAS from training requirements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-neural-architecture-search</guid>
    </item>
    <item>
      <title>Unbalanced Optimal Transport: A Unified Framework for Object Detection</title>
      <link>https://paperswithcode.com/paper/unbalanced-optimal-transport-a-unified-1</link>
      <description><![CDATA[The approach is well suited for GPU implementation, which proves to be an advantage for large-scale models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unbalanced-optimal-transport-a-unified-1</guid>
    </item>
    <item>
      <title>LongNet: Scaling Transformers to 1,000,000,000 Tokens</title>
      <link>https://paperswithcode.com/paper/longnet-scaling-transformers-to-1000000000</link>
      <description><![CDATA[Scaling sequence length has become a critical demand in the era of large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longnet-scaling-transformers-to-1000000000</guid>
    </item>
    <item>
      <title>First-Explore, then Exploit: Meta-Learning Intelligent Exploration</title>
      <link>https://paperswithcode.com/paper/first-explore-then-exploit-meta-learning</link>
      <description><![CDATA[We argue a core barrier prohibiting many RL approaches from learning intelligent exploration is that the methods attempt to explore and exploit simultaneously, which harms both exploration and exploitation as the goals often conflict.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/first-explore-then-exploit-meta-learning</guid>
    </item>
    <item>
      <title>A Comparison of Machine Learning Methods for Data with High-Cardinality Categorical Variables</title>
      <link>https://paperswithcode.com/paper/a-comparison-of-machine-learning-methods-for</link>
      <description><![CDATA[High-cardinality categorical variables are variables for which the number of different levels is large relative to the sample size of a data set, or in other words, there are few data points per level.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparison-of-machine-learning-methods-for</guid>
    </item>
    <item>
      <title>Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/learning-symbolic-rules-over-abstract-meaning</link>
      <description><![CDATA[Text-based reinforcement learning agents have predominantly been neural network-based models with embeddings-based representation, learning uninterpretable policies that often do not generalize well to unseen games.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-symbolic-rules-over-abstract-meaning</guid>
    </item>
    <item>
      <title>EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models</title>
      <link>https://paperswithcode.com/paper/ehrshot-an-ehr-benchmark-for-few-shot</link>
      <description><![CDATA[The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ehrshot-an-ehr-benchmark-for-few-shot</guid>
    </item>
    <item>
      <title>MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets</title>
      <link>https://paperswithcode.com/paper/mdvit-multi-domain-vision-transformer-for</link>
      <description><![CDATA[Naivly combining datasets from different domains can result in negative knowledge transfer (NKT), i. e., a decrease in model performance on some domains with non-negligible inter-domain heterogeneity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mdvit-multi-domain-vision-transformer-for</guid>
    </item>
    <item>
      <title>Remote Sensing Image Change Detection with Graph Interaction</title>
      <link>https://paperswithcode.com/paper/remote-sensing-image-change-detection-with</link>
      <description><![CDATA[More specifically, by leveraging the concept of non-local operations and mapping the features obtained from the backbone network to the graph structure space, we propose a unified self-focus mechanism for bitemporal images. This approach enhances the information coupling between the two temporal images while effectively suppressing task-irrelevant interference, Based on a streamlined backbone architecture, namely ResNet18, our model demonstrates superior performance compared to other state-of-the-art methods (SOTA) on the GZ CD dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/remote-sensing-image-change-detection-with</guid>
    </item>
    <item>
      <title>Detecting Images Generated by Deep Diffusion Models using their Local Intrinsic Dimensionality</title>
      <link>https://paperswithcode.com/paper/detecting-images-generated-by-deep-diffusion</link>
      <description><![CDATA[In this paper, we propose using the lightweight multi Local Intrinsic Dimensionality (multiLID), which has been originally developed in context of the detection of adversarial examples, for the automatic detection of synthetic images and the identification of the according generator networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detecting-images-generated-by-deep-diffusion</guid>
    </item>
    <item>
      <title>How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model</title>
      <link>https://paperswithcode.com/paper/how-deep-neural-networks-learn-compositional</link>
      <description><![CDATA[We find that the number of training data $P^*$ required by deep CNNs to learn this task (i) grows asymptotically as $n_c m^L$, which is only polynomial in the input dimensionality; (ii) coincides with the training set size such that the representation of a trained network becomes invariant to exchanges of synonyms; (iii) corresponds to the number of data at which the correlations between low-level features and classes become detectable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-deep-neural-networks-learn-compositional</guid>
    </item>
    <item>
      <title>S3C: Self-Supervised Stochastic Classifiers for Few-Shot Class-Incremental Learning</title>
      <link>https://paperswithcode.com/paper/s3c-self-supervised-stochastic-classifiers</link>
      <description><![CDATA[Few-shot class-incremental learning (FSCIL) aims to learn progressively about new classes with very few labeled samples, without forgetting the knowledge of already learnt classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s3c-self-supervised-stochastic-classifiers</guid>
    </item>
    <item>
      <title>NMS Threshold matters for Ego4D Moment Queries -- 2nd place solution to the Ego4D Moment Queries Challenge 2023</title>
      <link>https://paperswithcode.com/paper/nms-threshold-matters-for-ego4d-moment</link>
      <description><![CDATA[This report describes our submission to the Ego4D Moment Queries Challenge 2023.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nms-threshold-matters-for-ego4d-moment</guid>
    </item>
    <item>
      <title>Set Learning for Accurate and Calibrated Models</title>
      <link>https://paperswithcode.com/paper/set-learning-for-accurate-and-calibrated</link>
      <description><![CDATA[Model overconfidence and poor calibration are common in machine learning and difficult to account for when applying standard empirical risk minimization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/set-learning-for-accurate-and-calibrated</guid>
    </item>
    <item>
      <title>LLCaps: Learning to Illuminate Low-Light Capsule Endoscopy with Curved Wavelet Attention and Reverse Diffusion</title>
      <link>https://paperswithcode.com/paper/llcaps-learning-to-illuminate-low-light</link>
      <description><![CDATA[Given the exuberant development of the denoising diffusion probabilistic model (DDPM) in computer vision, we introduce a WCE LLIE framework based on the multi-scale convolutional neural network (CNN) and reverse diffusion process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llcaps-learning-to-illuminate-low-light</guid>
    </item>
    <item>
      <title>DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models</title>
      <link>https://paperswithcode.com/paper/dragondiffusion-enabling-drag-style</link>
      <description><![CDATA[Specifically, we construct classifier guidance based on the strong correspondence of intermediate features in the diffusion model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dragondiffusion-enabling-drag-style</guid>
    </item>
  </channel>
</rss>
