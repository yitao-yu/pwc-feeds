<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 29 Nov 2023 09:12:39 +0000</lastBuildDate>
    <item>
      <title>Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching</title>
      <link>https://paperswithcode.com/paper/is-this-the-subspace-you-are-looking-for-an</link>
      <description><![CDATA[We demonstrate this phenomenon in a distilled mathematical example, in two real-world domains (the indirect object identification task and factual recall), and present evidence for its prevalence in practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-this-the-subspace-you-are-looking-for-an</guid>
    </item>
    <item>
      <title>PyTorch Geometric High Order: A Unified Library for High Order Graph Neural Network</title>
      <link>https://paperswithcode.com/paper/pytorch-geometric-high-order-a-unified</link>
      <description><![CDATA[We introduce PyTorch Geometric High Order (PyGHO), a library for High Order Graph Neural Networks (HOGNNs) that extends PyTorch Geometric (PyG).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pytorch-geometric-high-order-a-unified</guid>
    </item>
    <item>
      <title>Computational Hypergraph Discovery, a Gaussian Process framework for connecting the dots</title>
      <link>https://paperswithcode.com/paper/computational-hypergraph-discovery-a-gaussian</link>
      <description><![CDATA[Type 1: Approximate an unknown function given input/output data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/computational-hypergraph-discovery-a-gaussian</guid>
    </item>
    <item>
      <title>Adversarial Diffusion Distillation</title>
      <link>https://paperswithcode.com/paper/adversarial-diffusion-distillation</link>
      <description><![CDATA[We introduce Adversarial Diffusion Distillation (ADD), a novel training approach that efficiently samples large-scale foundational image diffusion models in just 1-4 steps while maintaining high image quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-diffusion-distillation</guid>
    </item>
    <item>
      <title>Visual Semantic Navigation with Real Robots</title>
      <link>https://paperswithcode.com/paper/visual-semantic-navigation-with-real-robots</link>
      <description><![CDATA[Visual Semantic Navigation (VSN) is the ability of a robot to learn visual semantic information for navigating in unseen environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-semantic-navigation-with-real-robots</guid>
    </item>
    <item>
      <title>Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld</title>
      <link>https://paperswithcode.com/paper/embodied-multi-modal-agent-trained-by-an-llm</link>
      <description><![CDATA[While large language models (LLMs) excel in a simulated world of texts, they struggle to interact with the more realistic world without perceptions of other modalities such as visual or audio signals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embodied-multi-modal-agent-trained-by-an-llm</guid>
    </item>
    <item>
      <title>LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models</title>
      <link>https://paperswithcode.com/paper/llama-vid-an-image-is-worth-2-tokens-in-large</link>
      <description><![CDATA[Current VLMs, while proficient in tasks like image captioning and visual question answering, face computational burdens when processing long videos due to the excessive visual tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-vid-an-image-is-worth-2-tokens-in-large</guid>
    </item>
    <item>
      <title>SARDINE: A Simulator for Automated Recommendation in Dynamic and Interactive Environments</title>
      <link>https://paperswithcode.com/paper/sardine-a-simulator-for-automated</link>
      <description><![CDATA[Simulators can provide valuable insights for researchers and practitioners who wish to improve recommender systems, because they allow one to easily tweak the experimental setup in which recommender systems operate, and as a result lower the cost of identifying general trends and uncovering novel findings about the candidate methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sardine-a-simulator-for-automated</guid>
    </item>
    <item>
      <title>Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding</title>
      <link>https://paperswithcode.com/paper/mitigating-object-hallucinations-in-large</link>
      <description><![CDATA[Large Vision-Language Models (LVLMs) have advanced considerably, intertwining visual recognition and language understanding to generate content that is not only coherent but also contextually attuned.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mitigating-object-hallucinations-in-large</guid>
    </item>
    <item>
      <title>Self-training solutions for the ICCV 2023 GeoNet Challenge</title>
      <link>https://paperswithcode.com/paper/self-training-solutions-for-the-iccv-2023</link>
      <description><![CDATA[Our solution adopts a two-stage source-free domain adaptation framework with a Swin Transformer backbone to achieve knowledge transfer from the USA (source) domain to Asia (target) domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-training-solutions-for-the-iccv-2023</guid>
    </item>
    <item>
      <title>LLaFS: When Large-Language Models Meet Few-Shot Segmentation</title>
      <link>https://paperswithcode.com/paper/llafs-when-large-language-models-meet-few</link>
      <description><![CDATA[This paper proposes LLaFS, the first attempt to leverage large language models (LLMs) in few-shot segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llafs-when-large-language-models-meet-few</guid>
    </item>
    <item>
      <title>MVBench: A Comprehensive Multi-modal Video Understanding Benchmark</title>
      <link>https://paperswithcode.com/paper/mvbench-a-comprehensive-multi-modal-video</link>
      <description><![CDATA[With the rapid development of Multi-modal Large Language Models (MLLMs), a number of diagnostic benchmarks have recently emerged to evaluate the comprehension capabilities of these models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mvbench-a-comprehensive-multi-modal-video</guid>
    </item>
    <item>
      <title>Filter-Pruning of Lightweight Face Detectors Using a Geometric Median Criterion</title>
      <link>https://paperswithcode.com/paper/filter-pruning-of-lightweight-face-detectors</link>
      <description><![CDATA[Face detectors are becoming a crucial component of many applications, including surveillance, that often have to run on edge devices with limited processing power and memory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/filter-pruning-of-lightweight-face-detectors</guid>
    </item>
    <item>
      <title>CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models</title>
      <link>https://paperswithcode.com/paper/cdeval-a-benchmark-for-measuring-the-cultural</link>
      <description><![CDATA[This benchmark serves as a valuable resource for cultural studies in LLMs, paving the way for more culturally aware and sensitive models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cdeval-a-benchmark-for-measuring-the-cultural</guid>
    </item>
    <item>
      <title>Enhancing Item-level Bundle Representation for Bundle Recommendation</title>
      <link>https://paperswithcode.com/paper/enhancing-item-level-bundle-representation</link>
      <description><![CDATA[In this paper, we propose a novel approach EBRec, short of Enhanced Bundle Recommendation, which incorporates two enhanced modules to explore inherent item-level bundle representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-item-level-bundle-representation</guid>
    </item>
    <item>
      <title>Scalable Label Distribution Learning for Multi-Label Classification</title>
      <link>https://paperswithcode.com/paper/scalable-label-distribution-learning-for</link>
      <description><![CDATA[Most existing MLC methods are based on the assumption that the correlation of two labels in each label pair is symmetric, which is violated in many real-world scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-label-distribution-learning-for</guid>
    </item>
    <item>
      <title>Graph Prompt Learning: A Comprehensive Survey and Beyond</title>
      <link>https://paperswithcode.com/paper/graph-prompt-learning-a-comprehensive-survey</link>
      <description><![CDATA[This paper presents a pioneering survey on the emerging domain of graph prompts in AGI, addressing key challenges and opportunities in harnessing graph data for AGI applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-prompt-learning-a-comprehensive-survey</guid>
    </item>
    <item>
      <title>Typhoon Intensity Prediction with Vision Transformer</title>
      <link>https://paperswithcode.com/paper/typhoon-intensity-prediction-with-vision</link>
      <description><![CDATA[Predicting typhoon intensity accurately across space and time is crucial for issuing timely disaster warnings and facilitating emergency response.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/typhoon-intensity-prediction-with-vision</guid>
    </item>
    <item>
      <title>Brain-ID: Learning Robust Feature Representations for Brain Imaging</title>
      <link>https://paperswithcode.com/paper/brain-id-learning-robust-feature</link>
      <description><![CDATA[Recent learning-based approaches have made astonishing advances in calibrated medical imaging like computerized tomography, yet they struggle to generalize in uncalibrated modalities -- notoriously magnetic resonance imaging (MRI), where performance is highly sensitive to the differences in MR contrast, resolution, and orientation between the training and testing data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/brain-id-learning-robust-feature</guid>
    </item>
    <item>
      <title>Centre Stage: Centricity-based Audio-Visual Temporal Action Detection</title>
      <link>https://paperswithcode.com/paper/centre-stage-centricity-based-audio-visual</link>
      <description><![CDATA[Previous one-stage action detection approaches have modelled temporal dependencies using only the visual modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/centre-stage-centricity-based-audio-visual</guid>
    </item>
    <item>
      <title>1-Lipschitz Layers Compared: Memory, Speed, and Certifiable Robustness</title>
      <link>https://paperswithcode.com/paper/1-lipschitz-layers-compared-memory-speed-and</link>
      <description><![CDATA[The robustness of neural networks against input perturbations with bounded magnitude represents a serious concern in the deployment of deep learning models in safety-critical systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/1-lipschitz-layers-compared-memory-speed-and</guid>
    </item>
    <item>
      <title>D4AM: A General Denoising Framework for Downstream Acoustic Models</title>
      <link>https://paperswithcode.com/paper/d4am-a-general-denoising-framework-for</link>
      <description><![CDATA[To our knowledge, this is the first work that deploys an effective combination scheme of regression (denoising) and classification (ASR) objectives to derive a general pre-processor applicable to various unseen ASR systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/d4am-a-general-denoising-framework-for</guid>
    </item>
    <item>
      <title>Full-resolution MLPs Empower Medical Dense Prediction</title>
      <link>https://paperswithcode.com/paper/full-resolution-mlps-empower-medical-dense</link>
      <description><![CDATA[This textural information is crucial for medical dense prediction as it can differentiate the subtle human anatomy in medical images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/full-resolution-mlps-empower-medical-dense</guid>
    </item>
    <item>
      <title>LLMs for Science: Usage for Code Generation and Data Analysis</title>
      <link>https://paperswithcode.com/paper/llms-for-science-usage-for-code-generation</link>
      <description><![CDATA[We have investigated a set of use cases for LLM-based tools in scientific research, and conducted a first study to assess to which degree current tools are helpful.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llms-for-science-usage-for-code-generation</guid>
    </item>
    <item>
      <title>Text-Driven Image Editing via Learnable Regions</title>
      <link>https://paperswithcode.com/paper/text-driven-image-editing-via-learnable</link>
      <description><![CDATA[Language has emerged as a natural interface for image editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-driven-image-editing-via-learnable</guid>
    </item>
    <item>
      <title>Bridging the Gap: A Unified Video Comprehension Framework for Moment Retrieval and Highlight Detection</title>
      <link>https://paperswithcode.com/paper/bridging-the-gap-a-unified-video</link>
      <description><![CDATA[Video Moment Retrieval (MR) and Highlight Detection (HD) have attracted significant attention due to the growing demand for video analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridging-the-gap-a-unified-video</guid>
    </item>
    <item>
      <title>The Sky's the Limit: Re-lightable Outdoor Scenes via a Sky-pixel Constrained Illumination Prior and Outside-In Visibility</title>
      <link>https://paperswithcode.com/paper/the-sky-s-the-limit-re-lightable-outdoor</link>
      <description><![CDATA[We also introduce a novel `outside-in' method for computing differentiable sky visibility based on a neural directional distance function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-sky-s-the-limit-re-lightable-outdoor</guid>
    </item>
    <item>
      <title>Debiasing Multimodal Models via Causal Information Minimization</title>
      <link>https://paperswithcode.com/paper/debiasing-multimodal-models-via-causal</link>
      <description><![CDATA[In this paper, we study bias arising from confounders in a causal graph for multimodal data and examine a novel approach that leverages causally-motivated information minimization to learn the confounder representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/debiasing-multimodal-models-via-causal</guid>
    </item>
    <item>
      <title>Sluggish and Chemically-Biased Interstitial Diffusion in Concentrated Solid Solution Alloys: Mechanisms and Methods</title>
      <link>https://paperswithcode.com/paper/sluggish-and-chemically-biased-interstitial</link>
      <description><![CDATA[Interstitial diffusion is a pivotal process that governs the phase stability and irradiation response of materials in non-equilibrium conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sluggish-and-chemically-biased-interstitial</guid>
    </item>
    <item>
      <title>Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for Imbalanced Medical Classification</title>
      <link>https://paperswithcode.com/paper/text2tree-aligning-text-representation-to-the</link>
      <description><![CDATA[Deep learning approaches exhibit promising performances on various text tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2tree-aligning-text-representation-to-the</guid>
    </item>
    <item>
      <title>Panoptic Video Scene Graph Generation</title>
      <link>https://paperswithcode.com/paper/panoptic-video-scene-graph-generation-1</link>
      <description><![CDATA[PVSG relates to the existing video scene graph generation (VidSGG) problem, which focuses on temporal interactions between humans and objects grounded with bounding boxes in videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/panoptic-video-scene-graph-generation-1</guid>
    </item>
    <item>
      <title>Clean Label Disentangling for Medical Image Segmentation with Noisy Labels</title>
      <link>https://paperswithcode.com/paper/clean-label-disentangling-for-medical-image</link>
      <description><![CDATA[Current methods focusing on medical image segmentation suffer from incorrect annotations, which is known as the noisy label issue.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clean-label-disentangling-for-medical-image</guid>
    </item>
    <item>
      <title>MedGen: A Python Natural Language Processing Toolkit for Medical Text Processing</title>
      <link>https://paperswithcode.com/paper/medgen-a-python-natural-language-processing</link>
      <description><![CDATA[This study introduces MedGen, a comprehensive natural language processing (NLP) toolkit designed for medical text processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medgen-a-python-natural-language-processing</guid>
    </item>
    <item>
      <title>MultiCBR: Multi-view Contrastive Learning for Bundle Recommendation</title>
      <link>https://paperswithcode.com/paper/multicbr-multi-view-contrastive-learning-for</link>
      <description><![CDATA[It does, however, have two limitations: 1) the two-view formulation does not fully exploit all the heterogeneous relations among users, bundles and items; and 2) the "early contrast and late fusion" framework is less effective in capturing user preference and difficult to generalize to multiple views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multicbr-multi-view-contrastive-learning-for</guid>
    </item>
    <item>
      <title>Evaluating Optimal Reference Translations</title>
      <link>https://paperswithcode.com/paper/evaluating-optimal-reference-translations</link>
      <description><![CDATA[The overall translation quality reached by current machine translation (MT) systems for high-resourced language pairs is remarkably good.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-optimal-reference-translations</guid>
    </item>
    <item>
      <title>ViT-Lens-2: Gateway to Omni-modal Intelligence</title>
      <link>https://paperswithcode.com/paper/vit-lens-2-gateway-to-omni-modal-intelligence</link>
      <description><![CDATA[In this paper, we present ViT-Lens-2 that facilitates efficient omni-modal representation learning by perceiving novel modalities with a pretrained ViT and aligning them to a pre-defined space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vit-lens-2-gateway-to-omni-modal-intelligence</guid>
    </item>
    <item>
      <title>Learning Multi-Frequency Partial Correlation Graphs</title>
      <link>https://paperswithcode.com/paper/learning-multi-frequency-partial-correlation</link>
      <description><![CDATA[Despite the large research effort devoted to learning dependencies between time series, the state of the art still faces a major limitation: existing methods learn partial correlations but fail to discriminate across distinct frequency bands.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-multi-frequency-partial-correlation</guid>
    </item>
    <item>
      <title>GLIME: General, Stable and Local LIME Explanation</title>
      <link>https://paperswithcode.com/paper/glime-general-stable-and-local-lime</link>
      <description><![CDATA[Additionally, LIME's sampling neighborhood is non-local and biased towards the reference, resulting in poor local fidelity and sensitivity to reference choice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glime-general-stable-and-local-lime</guid>
    </item>
    <item>
      <title>Efficient Dataset Distillation via Minimax Diffusion</title>
      <link>https://paperswithcode.com/paper/efficient-dataset-distillation-via-minimax</link>
      <description><![CDATA[Observing that key factors for constructing an effective surrogate dataset are representativeness and diversity, we design additional minimax criteria in the generative training to enhance these facets for the generated images of diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-dataset-distillation-via-minimax</guid>
    </item>
    <item>
      <title>SpotServe: Serving Generative Large Language Models on Preemptible Instances</title>
      <link>https://paperswithcode.com/paper/spotserve-serving-generative-large-language</link>
      <description><![CDATA[This paper aims to reduce the monetary cost for serving LLMs by leveraging preemptible GPU instances on modern clouds, which offer accesses to spare GPUs at a much cheaper price than regular instances but may be preempted by the cloud at any time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spotserve-serving-generative-large-language</guid>
    </item>
    <item>
      <title>Progressive Target-Styled Feature Augmentation for Unsupervised Domain Adaptation on Point Clouds</title>
      <link>https://paperswithcode.com/paper/progressive-target-styled-feature</link>
      <description><![CDATA[Unlike previous works that focus on feature extractor adaptation, our PTSFA approach focuses on classifier adaptation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progressive-target-styled-feature</guid>
    </item>
    <item>
      <title>A Quantitative Approach to Understand Self-Supervised Models as Cross-lingual Feature Extractors</title>
      <link>https://paperswithcode.com/paper/a-quantitative-approach-to-understand-self</link>
      <description><![CDATA[There is a positive correlation between PSR scores and ASR performance, suggesting that phonetic information extracted by monolingual SSL models can be used for downstream tasks in cross-lingual settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-quantitative-approach-to-understand-self</guid>
    </item>
    <item>
      <title>Class-Adaptive Sampling Policy for Efficient Continual Learning</title>
      <link>https://paperswithcode.com/paper/class-adaptive-sampling-policy-for-efficient</link>
      <description><![CDATA[Continual learning (CL) aims to acquire new knowledge while preserving information from previous experiences without forgetting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/class-adaptive-sampling-policy-for-efficient</guid>
    </item>
    <item>
      <title>The Battleship Approach to the Low Resource Entity Matching Problem</title>
      <link>https://paperswithcode.com/paper/the-battleship-approach-to-the-low-resource</link>
      <description><![CDATA[Entity matching, a core data integration problem, is the task of deciding whether two data tuples refer to the same real-world entity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-battleship-approach-to-the-low-resource</guid>
    </item>
    <item>
      <title>SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/seesr-towards-semantics-aware-real-world</link>
      <description><![CDATA[First, we train a degradation-aware prompt extractor, which can generate accurate soft and hard semantic prompts even under strong degradation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seesr-towards-semantics-aware-real-world</guid>
    </item>
    <item>
      <title>Sensitivity-Based Layer Insertion for Residual and Feedforward Neural Networks</title>
      <link>https://paperswithcode.com/paper/sensitivity-based-layer-insertion-for</link>
      <description><![CDATA[The training of neural networks requires tedious and often manual tuning of the network architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sensitivity-based-layer-insertion-for</guid>
    </item>
    <item>
      <title>SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/sed-a-simple-encoder-decoder-for-open</link>
      <description><![CDATA[In this paper, we propose a simple encoder-decoder, named SED, for open-vocabulary semantic segmentation, which comprises a hierarchical encoder-based cost map generation and a gradual fusion decoder with category early rejection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sed-a-simple-encoder-decoder-for-open</guid>
    </item>
    <item>
      <title>MAST: Model-Agnostic Sparsified Training</title>
      <link>https://paperswithcode.com/paper/mast-model-agnostic-sparsified-training</link>
      <description><![CDATA[We introduce a novel optimization problem formulation that departs from the conventional way of minimizing machine learning model loss as a black-box function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mast-model-agnostic-sparsified-training</guid>
    </item>
    <item>
      <title>Experimental Analysis of Large-scale Learnable Vector Storage Compression</title>
      <link>https://paperswithcode.com/paper/experimental-analysis-of-large-scale</link>
      <description><![CDATA[Learnable embedding vector is one of the most important applications in machine learning, and is widely used in various database-related domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/experimental-analysis-of-large-scale</guid>
    </item>
    <item>
      <title>Enhancing Perceptual Quality in Video Super-Resolution through Temporally-Consistent Detail Synthesis using Diffusion Models</title>
      <link>https://paperswithcode.com/paper/enhancing-perceptual-quality-in-video-super</link>
      <description><![CDATA[We demonstrate the effectiveness of StableVSR in enhancing the perceptual quality of upscaled videos compared to existing state-of-the-art methods for VSR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-perceptual-quality-in-video-super</guid>
    </item>
  </channel>
</rss>
