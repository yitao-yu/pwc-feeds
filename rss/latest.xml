<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 20 Feb 2025 21:08:25 +0000</lastBuildDate>
    <item>
      <title>Label Drop for Multi-Aspect Relation Modeling in Universal Information Extraction</title>
      <link>https://paperswithcode.com/paper/label-drop-for-multi-aspect-relation-modeling</link>
      <description><![CDATA[Single-target instruction UIE enables the extraction of only one type of relation at a time, limiting its ability to model correlations between relations and thus restricting its capability to extract complex relations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/label-drop-for-multi-aspect-relation-modeling</guid>
    </item>
    <item>
      <title>MotifBench: A standardized protein design benchmark for motif-scaffolding problems</title>
      <link>https://paperswithcode.com/paper/motifbench-a-standardized-protein-design</link>
      <description><![CDATA[The motif-scaffolding problem is a central task in computational protein design: Given the coordinates of atoms in a geometry chosen to confer a desired biochemical function (a motif), the task is to identify diverse protein structures (scaffolds) that include the motif and maintain its geometry.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motifbench-a-standardized-protein-design</guid>
    </item>
    <item>
      <title>Probabilistic neural operators for functional uncertainty quantification</title>
      <link>https://paperswithcode.com/paper/probabilistic-neural-operators-for-functional</link>
      <description><![CDATA[Neural operators aim to approximate the solution operator of a system of differential equations purely from data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probabilistic-neural-operators-for-functional</guid>
    </item>
    <item>
      <title>Dimension reduction methods, persistent homology and machine learning for EEG signal analysis of Interictal Epileptic Discharges</title>
      <link>https://paperswithcode.com/paper/dimension-reduction-methods-persistent</link>
      <description><![CDATA[The reduced data are examined using topological data analysis (TDA), specifically using a persistent homology algorithm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dimension-reduction-methods-persistent</guid>
    </item>
    <item>
      <title>MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction</title>
      <link>https://paperswithcode.com/paper/maskgwm-a-generalizable-driving-world-model</link>
      <description><![CDATA[The prevailing driving world model mainly build on video prediction model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maskgwm-a-generalizable-driving-world-model</guid>
    </item>
    <item>
      <title>Atom of Thoughts for Markov LLM Test-Time Scaling</title>
      <link>https://paperswithcode.com/paper/atom-of-thoughts-for-markov-llm-test-time</link>
      <description><![CDATA[Based on this observation, we propose Atom of Thoughts (AoT), where each state transition in the reasoning process consists of decomposing the current question into a dependency-based directed acyclic graph and contracting its subquestions, forming a new atomic question state.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/atom-of-thoughts-for-markov-llm-test-time</guid>
    </item>
    <item>
      <title>Data-Efficient Limited-Angle CT Using Deep Priors and Regularization</title>
      <link>https://paperswithcode.com/paper/data-efficient-limited-angle-ct-using-deep</link>
      <description><![CDATA[We only use a total of 12 data points--eight for learning a prior and four for hyperparameter selection--and achieve results comparable to the best synthetic data-driven approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-efficient-limited-angle-ct-using-deep</guid>
    </item>
    <item>
      <title>Joint Evaluation of Fairness and Relevance in Recommender Systems with Pareto Frontier</title>
      <link>https://paperswithcode.com/paper/joint-evaluation-of-fairness-and-relevance-in</link>
      <description><![CDATA[Motivated by this, we present a new approach for jointly evaluating fairness and relevance in RSs: Distance to Pareto Frontier (DPFR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/joint-evaluation-of-fairness-and-relevance-in</guid>
    </item>
    <item>
      <title>JotlasNet: Joint Tensor Low-Rank and Attention-based Sparse Unrolling Network for Accelerating Dynamic MRI</title>
      <link>https://paperswithcode.com/paper/jotlasnet-joint-tensor-low-rank-and-attention</link>
      <description><![CDATA[In this paper, we propose a novel deep unrolling network, JotlasNet, for dynamic MRI reconstruction by jointly utilizing tensor low-rank and attention-based sparse priors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jotlasnet-joint-tensor-low-rank-and-attention</guid>
    </item>
    <item>
      <title>Diffusion Models without Classifier-free Guidance</title>
      <link>https://paperswithcode.com/paper/diffusion-models-without-classifier-free-1</link>
      <description><![CDATA[This paper presents Model-guidance (MG), a novel objective for training diffusion model that addresses and removes of the commonly used Classifier-free guidance (CFG).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-without-classifier-free-1</guid>
    </item>
    <item>
      <title>Bitnet.cpp: Efficient Edge Inference for Ternary LLMs</title>
      <link>https://paperswithcode.com/paper/bitnet-cpp-efficient-edge-inference-for</link>
      <description><![CDATA[The advent of 1-bit large language models (LLMs), led by BitNet b1. 58, has spurred interest in ternary LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bitnet-cpp-efficient-edge-inference-for</guid>
    </item>
    <item>
      <title>Sharp-PINNs: staggered hard-constrained physics-informed neural networks for phase field modelling of corrosion</title>
      <link>https://paperswithcode.com/paper/sharp-pinns-staggered-hard-constrained</link>
      <description><![CDATA[This framework is benchmarked through simulations of corrosion problems with multiple pits, where the staggered training scheme and network architecture significantly improve both the efficiency and accuracy of PINNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sharp-pinns-staggered-hard-constrained</guid>
    </item>
    <item>
      <title>Positional Encoding in Transformer-Based Time Series Models: A Survey</title>
      <link>https://paperswithcode.com/paper/positional-encoding-in-transformer-based-time</link>
      <description><![CDATA[Recent advancements in transformer-based models have greatly improved time series analysis, providing robust solutions for tasks such as forecasting, anomaly detection, and classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/positional-encoding-in-transformer-based-time</guid>
    </item>
    <item>
      <title>How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training</title>
      <link>https://paperswithcode.com/paper/how-do-llms-acquire-new-knowledge-a-knowledge</link>
      <description><![CDATA[Despite exceptional capabilities in knowledge-intensive tasks, Large Language Models (LLMs) face a critical gap in understanding how they internalize new knowledge, particularly how to structurally embed acquired knowledge in their neural computations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-do-llms-acquire-new-knowledge-a-knowledge</guid>
    </item>
    <item>
      <title>ReLearn: Unlearning via Learning for Large Language Models</title>
      <link>https://paperswithcode.com/paper/relearn-unlearning-via-learning-for-large</link>
      <description><![CDATA[Current unlearning methods for large language models usually rely on reverse optimization to reduce target token probabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relearn-unlearning-via-learning-for-large</guid>
    </item>
    <item>
      <title>Provable and Practical Online Learning Rate Adaptation with Hypergradient Descent</title>
      <link>https://paperswithcode.com/paper/provable-and-practical-online-learning-rate</link>
      <description><![CDATA[We provide the first rigorous convergence analysis of HDM using the online learning framework of [Gao24] and apply this analysis to develop new state-of-the-art adaptive gradient methods with empirical and theoretical support.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/provable-and-practical-online-learning-rate</guid>
    </item>
    <item>
      <title>FinMTEB: Finance Massive Text Embedding Benchmark</title>
      <link>https://paperswithcode.com/paper/finmteb-finance-massive-text-embedding</link>
      <description><![CDATA[Embedding models play a crucial role in representing and retrieving information across various NLP applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finmteb-finance-massive-text-embedding</guid>
    </item>
    <item>
      <title>Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages</title>
      <link>https://paperswithcode.com/paper/multilingual-encoder-knows-more-than-you</link>
      <description><![CDATA[While multilingual language models like XLM-R have advanced multilingualism in NLP, they still perform poorly in extremely low-resource languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multilingual-encoder-knows-more-than-you</guid>
    </item>
    <item>
      <title>Spatio-temporal collaborative multiple-stream transformer network for liver lesion classification on multiple-sequence magnetic resonance imaging</title>
      <link>https://paperswithcode.com/paper/spatio-temporal-collaborative-multiple-stream</link>
      <description><![CDATA[Accurate identification of focal liver lesions is essential for determining the appropriate therapeutic approach in clinical practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatio-temporal-collaborative-multiple-stream</guid>
    </item>
    <item>
      <title>Reduced Order Modeling with Shallow Recurrent Decoder Networks</title>
      <link>https://paperswithcode.com/paper/reduced-order-modeling-with-shallow-recurrent</link>
      <description><![CDATA[In this work, we propose sensor-driven SHallow REcurrent Decoder networks for Reduced Order Modeling (SHRED-ROM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reduced-order-modeling-with-shallow-recurrent</guid>
    </item>
    <item>
      <title>FuncGenFoil: Airfoil Generation and Editing Model in Function Space</title>
      <link>https://paperswithcode.com/paper/funcgenfoil-airfoil-generation-and-editing</link>
      <description><![CDATA[Aircraft manufacturing is the jewel in the crown of industry, among which generating high-fidelity airfoil geometries with controllable and editable representations remains a fundamental challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/funcgenfoil-airfoil-generation-and-editing</guid>
    </item>
    <item>
      <title>Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model</title>
      <link>https://paperswithcode.com/paper/reading-your-heart-learning-ecg-words-and</link>
      <description><![CDATA[Although previous ECG self-supervised learning (eSSL) methods have made significant progress in representation learning from unannotated ECG data, they typically treat ECG signals as ordinary time-series data, segmenting the signals using fixed-size and fixed-step time windows, which often ignore the form and rhythm characteristics and latent semantic relationships in ECG signals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reading-your-heart-learning-ecg-words-and</guid>
    </item>
    <item>
      <title>Man Made Language Models? Evaluating LLMs' Perpetuation of Masculine Generics Bias</title>
      <link>https://paperswithcode.com/paper/man-made-language-models-evaluating-llms</link>
      <description><![CDATA[We filter existing French instruction datasets to retrieve generic instructions and analyze the responses of 6 different LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/man-made-language-models-evaluating-llms</guid>
    </item>
    <item>
      <title>QMaxViT-Unet+: A Query-Based MaxViT-Unet with Edge Enhancement for Scribble-Supervised Segmentation of Medical Images</title>
      <link>https://paperswithcode.com/paper/qmaxvit-unet-a-query-based-maxvit-unet-with</link>
      <description><![CDATA[Building on this approach, we propose QMaxViT-Unet+, a novel framework for scribble-supervised medical image segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qmaxvit-unet-a-query-based-maxvit-unet-with</guid>
    </item>
    <item>
      <title>Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</title>
      <link>https://paperswithcode.com/paper/step-video-t2v-technical-report-the-practice</link>
      <description><![CDATA[We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained model with 30B parameters and the ability to generate videos up to 204 frames in length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/step-video-t2v-technical-report-the-practice</guid>
    </item>
    <item>
      <title>Robust Anomaly Detection via Tensor Chidori Pseudoskeleton Decomposition</title>
      <link>https://paperswithcode.com/paper/robust-anomaly-detection-via-tensor-chidori</link>
      <description><![CDATA[The results underscore the potential of Tensor Chidori pseudoskeleton decomposition to enhance anomaly detection for large-scale, high-dimensional data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-anomaly-detection-via-tensor-chidori</guid>
    </item>
    <item>
      <title>CISSIR: Beam Codebooks with Self-Interference Reduction Guarantees for Integrated Sensing and Communication Beyond 5G</title>
      <link>https://paperswithcode.com/paper/cissir-beam-codebooks-with-self-interference</link>
      <description><![CDATA[We propose a beam codebook design to reduce self-interference (SI) in integrated sensing and communication (ISAC) systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cissir-beam-codebooks-with-self-interference</guid>
    </item>
    <item>
      <title>HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation</title>
      <link>https://paperswithcode.com/paper/healthgpt-a-medical-large-vision-language</link>
      <description><![CDATA[To effectively learn the HealthGPT, we devise a comprehensive medical domain-specific comprehension and generation dataset called VL-Health.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/healthgpt-a-medical-large-vision-language</guid>
    </item>
    <item>
      <title>HADL Framework for Noise Resilient Long-Term Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/hadl-framework-for-noise-resilient-long-term</link>
      <description><![CDATA[Long-term time series forecasting is critical in domains such as finance, economics, and energy, where accurate and reliable predictions over extended horizons drive strategic decision-making.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hadl-framework-for-noise-resilient-long-term</guid>
    </item>
    <item>
      <title>Strassen Multisystolic Array Hardware Architectures</title>
      <link>https://paperswithcode.com/paper/strassen-multisystolic-array-hardware</link>
      <description><![CDATA[While Strassen's matrix multiplication algorithm reduces the complexity of naive matrix multiplication, general-purpose hardware is not suitable for achieving the algorithm's promised theoretical speedups.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/strassen-multisystolic-array-hardware</guid>
    </item>
    <item>
      <title>Data Valuation using Neural Networks for Efficient Instruction Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/data-valuation-using-neural-networks-for</link>
      <description><![CDATA[Particularly, recent works have proposed various metrics and algorithms to calculate the influence of data using language models, which do not scale well with large models and datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-valuation-using-neural-networks-for</guid>
    </item>
    <item>
      <title>Leveraging large language models for structured information extraction from pathology reports</title>
      <link>https://paperswithcode.com/paper/leveraging-large-language-models-for-25</link>
      <description><![CDATA[We evaluate LLMs' accuracy in extracting structured information from breast cancer histopathology reports, compared to manual extraction by a trained human annotator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-large-language-models-for-25</guid>
    </item>
    <item>
      <title>MonoForce: Learnable Image-conditioned Physics Engine</title>
      <link>https://paperswithcode.com/paper/monoforce-learnable-image-conditioned-physics</link>
      <description><![CDATA[This layer includes a differentiable physics engine that computes the robot's trajectory by querying these forces at the points of contact with the terrain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monoforce-learnable-image-conditioned-physics</guid>
    </item>
    <item>
      <title>Compress image to patches for Vision Transformer</title>
      <link>https://paperswithcode.com/paper/compress-image-to-patches-for-vision</link>
      <description><![CDATA[However, as the depth of the model and the resolution of the input images increase, the computational cost associated with training and running ViT models has surged dramatically. This paper proposes a hybrid model based on CNN and Vision Transformer, named CI2P-ViT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compress-image-to-patches-for-vision</guid>
    </item>
    <item>
      <title>Comparative Study of Machine Unlearning Techniques for Computer Vision and NLP Models</title>
      <link>https://paperswithcode.com/paper/comparative-study-of-machine-unlearning</link>
      <description><![CDATA[Machine unlearning is an emerging field in machine learning that focuses on efficiently removing the influence of specific data from a trained model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comparative-study-of-machine-unlearning</guid>
    </item>
    <item>
      <title>EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition</title>
      <link>https://paperswithcode.com/paper/eventstr-a-benchmark-dataset-and-baselines</link>
      <description><![CDATA[Mainstream Scene Text Recognition (STR) algorithms are developed based on RGB cameras which are sensitive to challenging factors such as low illumination, motion blur, and cluttered backgrounds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eventstr-a-benchmark-dataset-and-baselines</guid>
    </item>
    <item>
      <title>A Systematic Evaluation of Generative Models on Tabular Transportation Data</title>
      <link>https://paperswithcode.com/paper/a-systematic-evaluation-of-generative-models</link>
      <description><![CDATA[This work underscores the potential need to develop generative models specifically tailored to take advantage of the unique characteristics of emerging domains, such as transportation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-systematic-evaluation-of-generative-models</guid>
    </item>
    <item>
      <title>A Deep Inverse-Mapping Model for a Flapping Robotic Wing</title>
      <link>https://paperswithcode.com/paper/a-deep-inverse-mapping-model-for-a-flapping</link>
      <description><![CDATA[To train our model, we developed a flapping wing system that simultaneously measures the wing's aerodynamic force and its 3D motion using high-speed cameras.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-deep-inverse-mapping-model-for-a-flapping</guid>
    </item>
    <item>
      <title>Eidetic Learning: an Efficient and Provable Solution to Catastrophic Forgetting</title>
      <link>https://paperswithcode.com/paper/eidetic-learning-an-efficient-and-provable</link>
      <description><![CDATA[We show with a variety of network architectures and sets of tasks that EideticNets are immune to forgetting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eidetic-learning-an-efficient-and-provable</guid>
    </item>
    <item>
      <title>Large Images are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/large-images-are-gaussians-high-quality-large</link>
      <description><![CDATA[While Implicit Neural Representations (INRs) have demonstrated significant success in image representation, they are often hindered by large training memory and slow decoding speed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-images-are-gaussians-high-quality-large</guid>
    </item>
    <item>
      <title>A Judge-free LLM Open-ended Generation Benchmark Based on the Distributional Hypothesis</title>
      <link>https://paperswithcode.com/paper/a-judge-free-llm-open-ended-generation</link>
      <description><![CDATA[Evaluating the open-ended text generation of large language models (LLMs) is challenging because of the lack of a clear ground truth and the high cost of human or LLM-based assessments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-judge-free-llm-open-ended-generation</guid>
    </item>
    <item>
      <title>A Contextual-Aware Position Encoding for Sequential Recommendation</title>
      <link>https://paperswithcode.com/paper/a-contextual-aware-position-encoding-for</link>
      <description><![CDATA[To bridge this gap, we propose a novel Contextual-Aware Position Encoding method for sequential recommendation, abbreviated as CAPE.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-contextual-aware-position-encoding-for</guid>
    </item>
    <item>
      <title>TokenSynth: A Token-based Neural Synthesizer for Instrument Cloning and Text-to-Instrument</title>
      <link>https://paperswithcode.com/paper/tokensynth-a-token-based-neural-synthesizer</link>
      <description><![CDATA[Recent advancements in neural audio codecs have enabled the use of tokenized audio representations in various audio generation tasks, such as text-to-speech, text-to-audio, and text-to-music generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tokensynth-a-token-based-neural-synthesizer</guid>
    </item>
    <item>
      <title>Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection</title>
      <link>https://paperswithcode.com/paper/wholly-wood-wholly-leveraging-diversified</link>
      <description><![CDATA[Accurately estimating the orientation of visual objects with compact rotated bounding boxes (RBoxes) has become a prominent demand, which challenges existing object detection paradigms that only use horizontal bounding boxes (HBoxes).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wholly-wood-wholly-leveraging-diversified</guid>
    </item>
    <item>
      <title>On the Importance of Embedding Norms in Self-Supervised Learning</title>
      <link>https://paperswithcode.com/paper/on-the-importance-of-embedding-norms-in-self</link>
      <description><![CDATA[While this seemingly implies that embedding norms cannot play any role in SSL, a few recent works have suggested that embedding norms have properties related to network convergence and confidence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-importance-of-embedding-norms-in-self</guid>
    </item>
    <item>
      <title>Exploring the Potential of Encoder-free Architectures in 3D LMMs</title>
      <link>https://paperswithcode.com/paper/exploring-the-potential-of-encoder-free</link>
      <description><![CDATA[In this paper, we present the first comprehensive investigation into the potential of encoder-free architectures to overcome the challenges of encoder-based 3D Large Multimodal Models (LMMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-potential-of-encoder-free</guid>
    </item>
    <item>
      <title>Harnessing Vision Models for Time Series Analysis: A Survey</title>
      <link>https://paperswithcode.com/paper/harnessing-vision-models-for-time-series</link>
      <description><![CDATA[Time series analysis has witnessed the inspiring development from traditional autoregressive models, deep learning models, to recent Transformers and Large Language Models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/harnessing-vision-models-for-time-series</guid>
    </item>
    <item>
      <title>LP-LM: No Hallucinations in Question Answering with Logic Programming</title>
      <link>https://paperswithcode.com/paper/lp-lm-no-hallucinations-in-question-answering</link>
      <description><![CDATA[Large language models (LLMs) are able to generate human-like responses to user queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lp-lm-no-hallucinations-in-question-answering</guid>
    </item>
    <item>
      <title>Off-Switching Not Guaranteed</title>
      <link>https://paperswithcode.com/paper/off-switching-not-guaranteed</link>
      <description><![CDATA[Hadfield-Menell et al. (2017) propose the Off-Switch Game, a model of Human-AI cooperation in which AI agents always defer to humans because they are uncertain about our preferences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/off-switching-not-guaranteed</guid>
    </item>
    <item>
      <title>You Do Not Fully Utilize Transformer's Representation Capacity</title>
      <link>https://paperswithcode.com/paper/you-do-not-fully-utilize-transformer-s</link>
      <description><![CDATA[In contrast to RNNs, which compress previous tokens into a single hidden state, Transformers can attend to all previous tokens directly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/you-do-not-fully-utilize-transformer-s</guid>
    </item>
  </channel>
</rss>
