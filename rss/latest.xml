<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 22 Dec 2022 09:12:29 +0000</lastBuildDate>
    <item>
      <title>Control of Continuous Quantum Systems with Many Degrees of Freedom based on Convergent Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/control-of-continuous-quantum-systems-with</link>
      <description><![CDATA[Although there have been a few successful applications of deep RL to quantum control problems, most of the existing RL algorithms suffer from instabilities and unsatisfactory reproducibility, and require a large amount of fine-tuning and a large computational budget, both of which limit their applicability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/control-of-continuous-quantum-systems-with</guid>
    </item>
    <item>
      <title>Is it worth it? An experimental comparison of six deep- and classical machine learning methods for unsupervised anomaly detection in time series</title>
      <link>https://paperswithcode.com/paper/is-it-worth-it-an-experimental-comparison-of</link>
      <description><![CDATA[The detection of anomalies in time series data is crucial in a wide range of applications, such as system monitoring, health care or cyber security.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-it-worth-it-an-experimental-comparison-of</guid>
    </item>
    <item>
      <title>Crowd Score: A Method for the Evaluation of Jokes using Large Language Model AI Voters as Judges</title>
      <link>https://paperswithcode.com/paper/crowd-score-a-method-for-the-evaluation-of</link>
      <description><![CDATA[We tested our methodology on 52 jokes in a crowd of four AI voters with different humour types: affiliative, self-enhancing, aggressive and self-defeating.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/crowd-score-a-method-for-the-evaluation-of</guid>
    </item>
    <item>
      <title>AgAsk: An Agent to Help Answer Farmer's Questions From Scientific Documents</title>
      <link>https://paperswithcode.com/paper/agask-an-agent-to-help-answer-farmer-s</link>
      <description><![CDATA[On the basis of these needs we release an information retrieval test collection comprising real questions, a large collection of scientific documents split in passages, and ground truth relevance assessments indicating which passages are relevant to each question.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agask-an-agent-to-help-answer-farmer-s</guid>
    </item>
    <item>
      <title>Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns Predict Reading Times Over and Above GPT-2 Surprisal</title>
      <link>https://paperswithcode.com/paper/entropy-and-distance-based-predictors-from</link>
      <description><![CDATA[Transformer-based large language models are trained to make predictions about the next word by aggregating representations of previous tokens through their self-attention mechanism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/entropy-and-distance-based-predictors-from</guid>
    </item>
    <item>
      <title>3D Highlighter: Localizing Regions on 3D Shapes via Text Descriptions</title>
      <link>https://paperswithcode.com/paper/3d-highlighter-localizing-regions-on-3d</link>
      <description><![CDATA[A key feature of our system is the ability to interpret "out-of-domain" localizations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-highlighter-localizing-regions-on-3d</guid>
    </item>
    <item>
      <title>Training language models for deeper understanding improves brain alignment</title>
      <link>https://paperswithcode.com/paper/training-language-models-for-deeper</link>
      <description><![CDATA[We show that training language models for deeper narrative understanding results in richer representations that have improved alignment to human brain activity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-language-models-for-deeper</guid>
    </item>
    <item>
      <title>Cross-Linguistic Syntactic Difference in Multilingual BERT: How Good is It and How Does It Affect Transfer?</title>
      <link>https://paperswithcode.com/paper/cross-linguistic-syntactic-difference-in</link>
      <description><![CDATA[We demonstrate that the distance between the distributions of different languages is highly consistent with the syntactic difference in terms of linguistic formalisms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-linguistic-syntactic-difference-in</guid>
    </item>
    <item>
      <title>Mining User-aware Multi-Relations for Fake News Detection in Large Scale Online Social Networks</title>
      <link>https://paperswithcode.com/paper/mining-user-aware-multi-relations-for-fake</link>
      <description><![CDATA[In this paper, we construct a dual-layer graph (i. e., the news layer and the user layer) to extract multiple relations of news and users in social networks to derive rich information for detecting fake news.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mining-user-aware-multi-relations-for-fake</guid>
    </item>
    <item>
      <title>An Audio-Visual Speech Separation Model Inspired by Cortico-Thalamo-Cortical Circuits</title>
      <link>https://paperswithcode.com/paper/an-audio-visual-speech-separation-model</link>
      <description><![CDATA[Then, inspired by the large number of connections between cortical regions and the thalamus, the model fuses the auditory and visual information in a thalamic subnetwork through top-down connections.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-audio-visual-speech-separation-model</guid>
    </item>
    <item>
      <title>Towards dynamic stability analysis of sustainable power grids using graph neural networks</title>
      <link>https://paperswithcode.com/paper/towards-dynamic-stability-analysis-of</link>
      <description><![CDATA[To mitigate climate change, the share of renewable needs to be increased.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-dynamic-stability-analysis-of</guid>
    </item>
    <item>
      <title>SLGTformer: An Attention-Based Approach to Sign Language Recognition</title>
      <link>https://paperswithcode.com/paper/slgtformer-an-attention-based-approach-to</link>
      <description><![CDATA[However, this frontal appearance can be quantified as a temporal sequence of human body pose, leading to Sign Language Recognition through the learning of spatiotemporal dynamics of skeleton keypoints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/slgtformer-an-attention-based-approach-to</guid>
    </item>
    <item>
      <title>Generalized Decoding for Pixel, Image, and Language</title>
      <link>https://paperswithcode.com/paper/generalized-decoding-for-pixel-image-and</link>
      <description><![CDATA[We present X-Decoder, a generalized decoding model that can predict pixel-level segmentation and language tokens seamlessly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-decoding-for-pixel-image-and</guid>
    </item>
    <item>
      <title>Semi-Supervised Learning of Monocular Depth Estimation via Consistency Regularization with K-way Disjoint Masking</title>
      <link>https://paperswithcode.com/paper/semi-supervised-learning-of-monocular-depth</link>
      <description><![CDATA[Semi-Supervised Learning (SSL) has recently accomplished successful achievements in various fields such as image classification, object detection, and semantic segmentation, which typically require a lot of labour to construct ground-truth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semi-supervised-learning-of-monocular-depth</guid>
    </item>
    <item>
      <title>Revisiting Residual Networks for Adversarial Robustness: An Architectural Perspective</title>
      <link>https://paperswithcode.com/paper/revisiting-residual-networks-for-adversarial</link>
      <description><![CDATA[In contrast, little attention was devoted to analyzing the role of architectural elements (such as topology, depth, and width) on adversarial robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-residual-networks-for-adversarial</guid>
    </item>
    <item>
      <title>Exploring Content Relationships for Distilling Efficient GANs</title>
      <link>https://paperswithcode.com/paper/exploring-content-relationships-for</link>
      <description><![CDATA[This paper proposes a content relationship distillation (CRD) to tackle the over-parameterized generative adversarial networks (GANs) for the serviceability in cutting-edge devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-content-relationships-for</guid>
    </item>
    <item>
      <title>Hyperparameters in Contextual RL are Highly Situational</title>
      <link>https://paperswithcode.com/paper/hyperparameters-in-contextual-rl-are-highly</link>
      <description><![CDATA[Although Reinforcement Learning (RL) has shown impressive results in games and simulation, real-world application of RL suffers from its instability under changing environment conditions and hyperparameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyperparameters-in-contextual-rl-are-highly</guid>
    </item>
    <item>
      <title>Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks</title>
      <link>https://paperswithcode.com/paper/hidden-poison-machine-unlearning-enables</link>
      <description><![CDATA[We introduce camouflaged data poisoning attacks, a new attack vector that arises in the context of machine unlearning and other settings when model retraining may be induced.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hidden-poison-machine-unlearning-enables</guid>
    </item>
    <item>
      <title>Benchmarking person re-identification datasets and approaches for practical real-world implementations</title>
      <link>https://paperswithcode.com/paper/benchmarking-person-re-identification-1</link>
      <description><![CDATA[Recently, Person Re-Identification (Re-ID) has received a lot of attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-person-re-identification-1</guid>
    </item>
    <item>
      <title>Using Machine Learning to Determine Morphologies of $z&lt;1$ AGN Host Galaxies in the Hyper Suprime-Cam Wide Survey</title>
      <link>https://paperswithcode.com/paper/using-machine-learning-to-determine</link>
      <description><![CDATA[The classification precision of our models has a noticeable dependency on host galaxy radius and magnitude.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/using-machine-learning-to-determine</guid>
    </item>
    <item>
      <title>Causal Inference for Knowledge Graph based Recommendation</title>
      <link>https://paperswithcode.com/paper/causal-inference-for-knowledge-graph-based</link>
      <description><![CDATA[Knowledge Graph (KG), as a side-information, tends to be utilized to supplement the collaborative filtering (CF) based recommendation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causal-inference-for-knowledge-graph-based</guid>
    </item>
    <item>
      <title>Towards Reasoning in Large Language Models: A Survey</title>
      <link>https://paperswithcode.com/paper/towards-reasoning-in-large-language-models-a</link>
      <description><![CDATA[Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-reasoning-in-large-language-models-a</guid>
    </item>
    <item>
      <title>When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories</title>
      <link>https://paperswithcode.com/paper/when-not-to-trust-language-models</link>
      <description><![CDATA[Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the limitations of relying solely on their parameters to encode a wealth of world knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-not-to-trust-language-models</guid>
    </item>
    <item>
      <title>True Detective: A Challenging Benchmark for Deep Abductive Reasoning \\in Foundation Models</title>
      <link>https://paperswithcode.com/paper/true-detective-a-challenging-benchmark-for</link>
      <description><![CDATA[Our work provides a challenging benchmark for future studies on reasoning in language models and contributes to a better understanding of the limits of LLMs' abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/true-detective-a-challenging-benchmark-for</guid>
    </item>
    <item>
      <title>Precise Zero-Shot Dense Retrieval without Relevance Labels</title>
      <link>https://paperswithcode.com/paper/precise-zero-shot-dense-retrieval-without</link>
      <description><![CDATA[Given a query, HyDE first zero-shot instructs an instruction-following language model (e. g. InstructGPT) to generate a hypothetical document.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/precise-zero-shot-dense-retrieval-without</guid>
    </item>
    <item>
      <title>Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation</title>
      <link>https://paperswithcode.com/paper/towards-robustness-of-text-to-sql-models-3</link>
      <description><![CDATA[The robustness of Text-to-SQL parsers against adversarial perturbations plays a crucial role in delivering highly reliable applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robustness-of-text-to-sql-models-3</guid>
    </item>
    <item>
      <title>Which Pixel to Annotate: a Label-Efficient Nuclei Segmentation Framework</title>
      <link>https://paperswithcode.com/paper/which-pixel-to-annotate-a-label-efficient</link>
      <description><![CDATA[Recently deep neural networks, which require a large amount of annotated samples, have been widely applied in nuclei instance segmentation of H\&E stained pathology images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/which-pixel-to-annotate-a-label-efficient</guid>
    </item>
    <item>
      <title>Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions</title>
      <link>https://paperswithcode.com/paper/interleaving-retrieval-with-chain-of-thought</link>
      <description><![CDATA[This is insufficient, however, when the necessary knowledge is not available or up-to-date within a model's parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interleaving-retrieval-with-chain-of-thought</guid>
    </item>
    <item>
      <title>DOC: Improving Long Story Coherence With Detailed Outline Control</title>
      <link>https://paperswithcode.com/paper/doc-improving-long-story-coherence-with</link>
      <description><![CDATA[In human evaluations of automatically generated stories, DOC substantially outperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22. 5% absolute gain), outline relevance (28. 2%), and interestingness (20. 7%).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/doc-improving-long-story-coherence-with</guid>
    </item>
    <item>
      <title>Graph Neural Networks in Computer Vision -- Architectures, Datasets and Common Approaches</title>
      <link>https://paperswithcode.com/paper/graph-neural-networks-in-computer-vision</link>
      <description><![CDATA[Firstly, we investigate the architectures of Graph Neural Networks and their derivatives used in this area to provide accurate and explainable recommendations for the ensuing investigations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-neural-networks-in-computer-vision</guid>
    </item>
    <item>
      <title>Self-Pair: Synthesizing Changes from Single Source for Object Change Detection in Remote Sensing Imagery</title>
      <link>https://paperswithcode.com/paper/self-pair-synthesizing-changes-from-single</link>
      <description><![CDATA[For change detection in remote sensing, constructing a training dataset for deep learning models is difficult due to the requirements of bi-temporal supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-pair-synthesizing-changes-from-single</guid>
    </item>
    <item>
      <title>Unleashing the Power of Visual Prompting At the Pixel Level</title>
      <link>https://paperswithcode.com/paper/unleashing-the-power-of-visual-prompting-at</link>
      <description><![CDATA[This paper presents a simple and effective visual prompting method for adapting pre-trained models to downstream recognition tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unleashing-the-power-of-visual-prompting-at</guid>
    </item>
    <item>
      <title>Goal-oriented Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/goal-oriented-autonomous-driving</link>
      <description><![CDATA[Modern autonomous driving system is characterized as modular tasks in sequential order, i. e., perception, prediction and planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/goal-oriented-autonomous-driving</guid>
    </item>
    <item>
      <title>BMX: Boosting Machine Translation Metrics with Explainability</title>
      <link>https://paperswithcode.com/paper/bmx-boosting-machine-translation-metrics-with</link>
      <description><![CDATA[Hence, recent works consider their explainability with the goals of better understandability for humans and better metric analysis, including failure cases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bmx-boosting-machine-translation-metrics-with</guid>
    </item>
    <item>
      <title>Self-adaptive In-context Learning</title>
      <link>https://paperswithcode.com/paper/self-adaptive-in-context-learning</link>
      <description><![CDATA[Despite the surprising few-shot performance of in-context learning (ICL), it is still a common practice to randomly sample examples to serve as context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-adaptive-in-context-learning</guid>
    </item>
    <item>
      <title>Variational Factorization Machines for Preference Elicitation in Large-Scale Recommender Systems</title>
      <link>https://paperswithcode.com/paper/variational-factorization-machines-for</link>
      <description><![CDATA[Factorization machines (FMs) are a powerful tool for regression and classification in the context of sparse observations, that has been successfully applied to collaborative filtering, especially when side information over users or items is available.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/variational-factorization-machines-for</guid>
    </item>
    <item>
      <title>Modeling Human Eye Movements with Neural Networks in a Maze-Solving Task</title>
      <link>https://paperswithcode.com/paper/modeling-human-eye-movements-with-neural</link>
      <description><![CDATA[This not only provides a generative model of eye movements in this task but also suggests a computational theory for how humans solve the task, namely that humans use mental simulation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/modeling-human-eye-movements-with-neural</guid>
    </item>
    <item>
      <title>ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/adas-a-simple-active-and-adaptive-baseline</link>
      <description><![CDATA[State-of-the-art 3D semantic segmentation models are trained on the off-the-shelf public benchmarks, but they often face the major challenge when these well-trained models are deployed to a new domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adas-a-simple-active-and-adaptive-baseline</guid>
    </item>
    <item>
      <title>Large Language Models Are Reasoning Teachers</title>
      <link>https://paperswithcode.com/paper/large-language-models-are-reasoning-teachers</link>
      <description><![CDATA[We propose Fine-tune-CoT, a method that leverages the capabilities of very large LMs to generate reasoning samples and teach smaller models via fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-are-reasoning-teachers</guid>
    </item>
    <item>
      <title>A Comparison Between Tsetlin Machines and Deep Neural Networks in the Context of Recommendation Systems</title>
      <link>https://paperswithcode.com/paper/a-comparison-between-tsetlin-machines-and</link>
      <description><![CDATA[These comparisons are based on model performance, interpretability/explainability, and scalability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparison-between-tsetlin-machines-and</guid>
    </item>
    <item>
      <title>Toward a Unified Framework for Unsupervised Complex Tabular Reasoning</title>
      <link>https://paperswithcode.com/paper/toward-a-unified-framework-for-unsupervised</link>
      <description><![CDATA[To bridge the gap between the programs and natural language sentences, we design a powerful "NL-Generator" module to generate natural language sentences with complex logic from these programs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toward-a-unified-framework-for-unsupervised</guid>
    </item>
    <item>
      <title>Exploring the Challenges of Open Domain Multi-Document Summarization</title>
      <link>https://paperswithcode.com/paper/exploring-the-challenges-of-open-domain-multi</link>
      <description><![CDATA[Multi-document summarization (MDS) has traditionally been studied assuming a set of ground-truth topic-related input documents is provided.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-challenges-of-open-domain-multi</guid>
    </item>
    <item>
      <title>On Improving Summarization Factual Consistency from Natural Language Feedback</title>
      <link>https://paperswithcode.com/paper/on-improving-summarization-factual</link>
      <description><![CDATA[In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-improving-summarization-factual</guid>
    </item>
    <item>
      <title>HyperBO+: Pre-training a universal prior for Bayesian optimization with hierarchical Gaussian processes</title>
      <link>https://paperswithcode.com/paper/hyperbo-pre-training-a-universal-prior-for</link>
      <description><![CDATA[However, those prior learning methods typically assume that the input domains are the same for all tasks, weakening their ability to use observations on functions with different domains or generalize the learned priors to BO on different search spaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyperbo-pre-training-a-universal-prior-for</guid>
    </item>
    <item>
      <title>ReCode: Robustness Evaluation of Code Generation Models</title>
      <link>https://paperswithcode.com/paper/recode-robustness-evaluation-of-code</link>
      <description><![CDATA[Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted area and to date there is no comprehensive benchmark for robustness in code generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recode-robustness-evaluation-of-code</guid>
    </item>
    <item>
      <title>Self-Instruct: Aligning Language Model with Self Generated Instructions</title>
      <link>https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</link>
      <description><![CDATA[Applying our method to vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT_001, which is trained with private user data and human annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</guid>
    </item>
    <item>
      <title>Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers</title>
      <link>https://paperswithcode.com/paper/why-can-gpt-learn-in-context-language-models</link>
      <description><![CDATA[In order to better understand how ICL works, this paper explains language models as meta-optimizers and understands ICL as a kind of implicit finetuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/why-can-gpt-learn-in-context-language-models</guid>
    </item>
    <item>
      <title>Pre-trained Language Models for Keyphrase Generation: A Thorough Empirical Study</title>
      <link>https://paperswithcode.com/paper/pre-trained-language-models-for-keyphrase</link>
      <description><![CDATA[However, there lacks a systematic study of how the two types of approaches compare and how different design choices can affect the performance of PLM-based models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pre-trained-language-models-for-keyphrase</guid>
    </item>
    <item>
      <title>DimonGen: Diversified Generative Commonsense Reasoning for Explaining Concept Relationships</title>
      <link>https://paperswithcode.com/paper/dimongen-diversified-generative-commonsense</link>
      <description><![CDATA[In this paper, we propose DimonGen, which aims to generate diverse sentences describing concept relationships in various everyday scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dimongen-diversified-generative-commonsense</guid>
    </item>
    <item>
      <title>When Federated Learning Meets Pre-trained Language Models' Parameter-Efficient Tuning Methods</title>
      <link>https://paperswithcode.com/paper/when-federated-learning-meets-pre-trained</link>
      <description><![CDATA[To facilitate the research of PETuning in FL, we also develop a federated tuning framework FedPETuning, which allows practitioners to exploit different PETuning methods under the FL training paradigm conveniently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-federated-learning-meets-pre-trained</guid>
    </item>
  </channel>
</rss>
