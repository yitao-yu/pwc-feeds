<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 04 Dec 2024 09:18:03 +0000</lastBuildDate>
    <item>
      <title>LoCo: Low-Contrast-Enhanced Contrastive Learning for Semi-Supervised Endoscopic Image Segmentation</title>
      <link>https://paperswithcode.com/paper/loco-low-contrast-enhanced-contrastive</link>
      <description><![CDATA[The segmentation of endoscopic images plays a vital role in computer-aided diagnosis and treatment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/loco-low-contrast-enhanced-contrastive</guid>
    </item>
    <item>
      <title>ASANet: Asymmetric Semantic Aligning Network for RGB and SAR image land cover classification</title>
      <link>https://paperswithcode.com/paper/asanet-asymmetric-semantic-aligning-network</link>
      <description><![CDATA[Most existing studies on cross-modal fusion assume that consistent feature information is necessary between the two modalities, and as a result, they construct networks without adequately addressing the unique characteristics of each modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asanet-asymmetric-semantic-aligning-network</guid>
    </item>
    <item>
      <title>Generalizing Weisfeiler-Lehman Kernels to Subgraphs</title>
      <link>https://paperswithcode.com/paper/generalizing-weisfeiler-lehman-kernels-to</link>
      <description><![CDATA[Subgraph representation learning has been effective in solving various real-world problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizing-weisfeiler-lehman-kernels-to</guid>
    </item>
    <item>
      <title>Trajectory-based Road Autolabeling with Lidar-Camera Fusion in Winter Conditions</title>
      <link>https://paperswithcode.com/paper/trajectory-based-road-autolabeling-with-lidar</link>
      <description><![CDATA[Robust road segmentation in all road conditions is required for safe autonomous driving and advanced driver assistance systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trajectory-based-road-autolabeling-with-lidar</guid>
    </item>
    <item>
      <title>Active Negative Loss: A Robust Framework for Learning with Noisy Labels</title>
      <link>https://paperswithcode.com/paper/active-negative-loss-a-robust-framework-for</link>
      <description><![CDATA[By replacing MAE in APL with our proposed NNLFs, we enhance APL and present a new framework called Active Negative Loss (ANL).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/active-negative-loss-a-robust-framework-for</guid>
    </item>
    <item>
      <title>How to Use Diffusion Priors under Sparse Views?</title>
      <link>https://paperswithcode.com/paper/how-to-use-diffusion-priors-under-sparse</link>
      <description><![CDATA[However, the diffusion model, as an external prior that can directly provide visual supervision, has always underperformed in sparse-view 3D reconstruction using Score Distillation Sampling (SDS) due to the low information entropy of sparse views compared to text, leading to optimization challenges caused by mode deviation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-to-use-diffusion-priors-under-sparse</guid>
    </item>
    <item>
      <title>BANER: Boundary-Aware LLMs for Few-Shot Named Entity Recognition</title>
      <link>https://paperswithcode.com/paper/baner-boundary-aware-llms-for-few-shot-named</link>
      <description><![CDATA[In this paper, we propose an approach called Boundary-Aware LLMs for Few-Shot Named Entity Recognition to address these issues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/baner-boundary-aware-llms-for-few-shot-named</guid>
    </item>
    <item>
      <title>Noisy Ostracods: A Fine-Grained, Imbalanced Real-World Dataset for Benchmarking Robust Machine Learning and Label Correction Methods</title>
      <link>https://paperswithcode.com/paper/noisy-ostracods-a-fine-grained-imbalanced</link>
      <description><![CDATA[We present the Noisy Ostracods, a noisy dataset for genus and species classification of crustacean ostracods with specialists' annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/noisy-ostracods-a-fine-grained-imbalanced</guid>
    </item>
    <item>
      <title>Remote Sensing Temporal Vision-Language Models: A Comprehensive Survey</title>
      <link>https://paperswithcode.com/paper/remote-sensing-temporal-vision-language</link>
      <description><![CDATA[This survey fills a critical gap in the literature by providing an integrated overview of RSTVLM, offering a foundation for further advancements in remote sensing temporal image understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/remote-sensing-temporal-vision-language</guid>
    </item>
    <item>
      <title>AccDiffusion v2: Towards More Accurate Higher-Resolution Diffusion Extrapolation</title>
      <link>https://paperswithcode.com/paper/accdiffusion-v2-towards-more-accurate-higher</link>
      <description><![CDATA[Finally, our analysis indicates that global semantic information is conducive to suppressing both repetitive generation and local distortion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accdiffusion-v2-towards-more-accurate-higher</guid>
    </item>
    <item>
      <title>RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation</title>
      <link>https://paperswithcode.com/paper/rg-san-rule-guided-spatial-awareness-network</link>
      <description><![CDATA[The RG-SAN consists of the Text-driven Localization Module (TLM) and the Rule-guided Weak Supervision (RWS) strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rg-san-rule-guided-spatial-awareness-network</guid>
    </item>
    <item>
      <title>HERO: Hint-Based Efficient and Reliable Query Optimizer</title>
      <link>https://paperswithcode.com/paper/hero-hint-based-efficient-and-reliable-query</link>
      <description><![CDATA[The model addresses the three key challenges in learned hint-based query optimization: reliable hint recommendation (ensuring non-degradation of query latency), efficient hint exploration, and fast inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hero-hint-based-efficient-and-reliable-query</guid>
    </item>
    <item>
      <title>Wasserstein Markets for Differentially-Private Data</title>
      <link>https://paperswithcode.com/paper/wasserstein-markets-for-differentially</link>
      <description><![CDATA[Data is an increasingly vital component of decision making processes across industries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wasserstein-markets-for-differentially</guid>
    </item>
    <item>
      <title>Class-wise Autoencoders Measure Classification Difficulty And Detect Label Mistakes</title>
      <link>https://paperswithcode.com/paper/class-wise-autoencoders-measure</link>
      <description><![CDATA[We introduce a new framework for analyzing classification datasets based on the ratios of reconstruction errors between autoencoders trained on individual classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/class-wise-autoencoders-measure</guid>
    </item>
    <item>
      <title>Generating Critical Scenarios for Testing Automated Driving Systems</title>
      <link>https://paperswithcode.com/paper/generating-critical-scenarios-for-testing</link>
      <description><![CDATA[In this paper, we propose AVASTRA, a Reinforcement Learning (RL)-based approach to generate realistic critical scenarios for testing ADSs in simulation environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-critical-scenarios-for-testing</guid>
    </item>
    <item>
      <title>Diffusion-based Visual Anagram as Multi-task Learning</title>
      <link>https://paperswithcode.com/paper/diffusion-based-visual-anagram-as-multi-task</link>
      <description><![CDATA[Visual anagrams are images that change appearance upon transformation, like flipping or rotation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-based-visual-anagram-as-multi-task</guid>
    </item>
    <item>
      <title>OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/ocr-hinders-rag-evaluating-the-cascading</link>
      <description><![CDATA[In this paper, we introduce OHRBench, the first benchmark for understanding the cascading impact of OCR on RAG systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ocr-hinders-rag-evaluating-the-cascading</guid>
    </item>
    <item>
      <title>HumanRig: Learning Automatic Rigging for Humanoid Character in a Large Scale Dataset</title>
      <link>https://paperswithcode.com/paper/humanrig-learning-automatic-rigging-for</link>
      <description><![CDATA[With the rapid evolution of 3D generation algorithms, the cost of producing 3D humanoid character models has plummeted, yet the field is impeded by the lack of a comprehensive dataset for automatic rigging, which is a pivotal step in character animation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/humanrig-learning-automatic-rigging-for</guid>
    </item>
    <item>
      <title>Agri-LLaVA: Knowledge-Infused Large Multimodal Assistant on Agricultural Pests and Diseases</title>
      <link>https://paperswithcode.com/paper/agri-llava-knowledge-infused-large-multimodal</link>
      <description><![CDATA[By open-sourcing our dataset and model, we aim to promote research and development in LMMs within the agricultural domain and make significant contributions to tackle the challenges of agricultural pests and diseases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agri-llava-knowledge-infused-large-multimodal</guid>
    </item>
    <item>
      <title>SimuScope: Realistic Endoscopic Synthetic Dataset Generation through Surgical Simulation and Diffusion Models</title>
      <link>https://paperswithcode.com/paper/simuscope-realistic-endoscopic-synthetic</link>
      <description><![CDATA[This simulator generates a wide set of annotations that surpass those available in public synthetic datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simuscope-realistic-endoscopic-synthetic</guid>
    </item>
    <item>
      <title>ShadowHack: Hacking Shadows via Luminance-Color Divide and Conquer</title>
      <link>https://paperswithcode.com/paper/shadowhack-hacking-shadows-via-luminance</link>
      <description><![CDATA[Shadows introduce challenges such as reduced brightness, texture deterioration, and color distortion in images, complicating a holistic solution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shadowhack-hacking-shadows-via-luminance</guid>
    </item>
    <item>
      <title>ROVER: A Multi-Season Dataset for Visual SLAM</title>
      <link>https://paperswithcode.com/paper/rover-a-multi-season-dataset-for-visual-slam</link>
      <description><![CDATA[To address this gap, we present ROVER, a comprehensive benchmark dataset tailored for evaluating visual SLAM algorithms under diverse environmental conditions and spatial configurations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rover-a-multi-season-dataset-for-visual-slam</guid>
    </item>
    <item>
      <title>GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot</title>
      <link>https://paperswithcode.com/paper/glm-4-voice-towards-intelligent-and-human</link>
      <description><![CDATA[We continue pre-training from the pre-trained text language model GLM-4-9B with a combination of unsupervised speech data, interleaved speech-text data, and supervised speech-text data, scaling up to 1 trillion tokens, achieving state-of-the-art performance in both speech language modeling and spoken question answering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glm-4-voice-towards-intelligent-and-human</guid>
    </item>
    <item>
      <title>Gracefully Filtering Backdoor Samples for Generative Large Language Models without Retraining</title>
      <link>https://paperswithcode.com/paper/gracefully-filtering-backdoor-samples-for</link>
      <description><![CDATA[Backdoor attacks remain significant security threats to generative large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gracefully-filtering-backdoor-samples-for</guid>
    </item>
    <item>
      <title>VideoICL: Confidence-based Iterative In-context Learning for Out-of-Distribution Video Understanding</title>
      <link>https://paperswithcode.com/paper/videoicl-confidence-based-iterative-in</link>
      <description><![CDATA[To address these issues, we propose VideoICL, a novel video in-context learning framework for OOD tasks that introduces a similarity-based relevant example selection strategy and a confidence-based iterative inference approach.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videoicl-confidence-based-iterative-in</guid>
    </item>
    <item>
      <title>Towards Rich Emotions in 3D Avatars: A Text-to-3D Avatar Generation Benchmark</title>
      <link>https://paperswithcode.com/paper/towards-rich-emotions-in-3d-avatars-a-text-to</link>
      <description><![CDATA[T3DEM is the most crucial step in determining the quality of Emo3D generation and encompasses three key challenges: Expression Diversity, Emotion-Content Consistency, and Expression Fluidity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-rich-emotions-in-3d-avatars-a-text-to</guid>
    </item>
    <item>
      <title>Active Learning via Classifier Impact and Greedy Selection for Interactive Image Retrieval</title>
      <link>https://paperswithcode.com/paper/active-learning-via-classifier-impact-and</link>
      <description><![CDATA[Finally, we assess our performance for the interactive content-based image retrieval task on several benchmarks and demonstrate its superiority over existing approaches and common baselines.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/active-learning-via-classifier-impact-and</guid>
    </item>
    <item>
      <title>Copy-Move Forgery Detection and Question Answering for Remote Sensing Image</title>
      <link>https://paperswithcode.com/paper/copy-move-forgery-detection-and-question</link>
      <description><![CDATA[This paper introduces the task of Remote Sensing Copy-Move Question Answering (RSCMQA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/copy-move-forgery-detection-and-question</guid>
    </item>
    <item>
      <title>Fast LiDAR Data Generation with Rectified Flows</title>
      <link>https://paperswithcode.com/paper/fast-lidar-data-generation-with-rectified</link>
      <description><![CDATA[Building LiDAR generative models holds promise as powerful data priors for restoration, scene manipulation, and scalable simulation in autonomous mobile robots.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-lidar-data-generation-with-rectified</guid>
    </item>
    <item>
      <title>Saliency Maps Give a False Sense of Explanability to Image Classifiers: An Empirical Evaluation across Methods and Metrics</title>
      <link>https://paperswithcode.com/paper/saliency-maps-give-a-false-sense-of</link>
      <description><![CDATA[The interpretability of deep neural networks (DNNs) has emerged as a crucial area of research, particularly in image classification tasks where decisions often lack transparency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/saliency-maps-give-a-false-sense-of</guid>
    </item>
    <item>
      <title>Scaling Image Tokenizers with Grouped Spherical Quantization</title>
      <link>https://paperswithcode.com/paper/scaling-image-tokenizers-with-grouped</link>
      <description><![CDATA[Vision tokenizers have gained a lot of attraction due to their scalability and compactness; previous works depend on old-school GAN-based hyperparameters, biased comparisons, and a lack of comprehensive analysis of the scaling behaviours.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-image-tokenizers-with-grouped</guid>
    </item>
    <item>
      <title>GSOT3D: Towards Generic 3D Single Object Tracking in the Wild</title>
      <link>https://paperswithcode.com/paper/gsot3d-towards-generic-3d-single-object</link>
      <description><![CDATA[In this paper, we present a novel benchmark, GSOT3D, that aims at facilitating development of generic 3D single object tracking (SOT) in the wild.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gsot3d-towards-generic-3d-single-object</guid>
    </item>
    <item>
      <title>From ChebNet to ChebGibbsNet</title>
      <link>https://paperswithcode.com/paper/from-chebnet-to-chebgibbsnet-1</link>
      <description><![CDATA[Different polynomial bases, such as Bernstein, Chebyshev, and monomial basis, have various convergence rates that will affect the error in polynomial interpolation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-chebnet-to-chebgibbsnet-1</guid>
    </item>
    <item>
      <title>FedAH: Aggregated Head for Personalized Federated Learning</title>
      <link>https://paperswithcode.com/paper/fedah-aggregated-head-for-personalized</link>
      <description><![CDATA[Personalized Federated Learning (PFL), building upon FL, aims to address the issue of statistical heterogeneity and achieve personalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedah-aggregated-head-for-personalized</guid>
    </item>
    <item>
      <title>Adaptive High-Pass Kernel Prediction for Efficient Video Deblurring</title>
      <link>https://paperswithcode.com/paper/adaptive-high-pass-kernel-prediction-for</link>
      <description><![CDATA[State-of-the-art video deblurring methods use deep network architectures to recover sharpened video frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-high-pass-kernel-prediction-for</guid>
    </item>
    <item>
      <title>Dual-Branch Graph Transformer Network for 3D Human Mesh Reconstruction from Video</title>
      <link>https://paperswithcode.com/paper/dual-branch-graph-transformer-network-for-3d</link>
      <description><![CDATA[DGTR employs a dual-branch network including a Global Motion Attention (GMA) branch and a Local Details Refine (LDR) branch to parallelly extract long-term dependencies and local crucial information, helping model global human motion and local human details (e. g., local motion, tiny movement).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-branch-graph-transformer-network-for-3d</guid>
    </item>
    <item>
      <title>IQA-Adapter: Exploring Knowledge Transfer from Image Quality Assessment to Diffusion-based Generative Models</title>
      <link>https://paperswithcode.com/paper/iqa-adapter-exploring-knowledge-transfer-from</link>
      <description><![CDATA[In this work, we propose methods to integrate image quality assessment (IQA) models into diffusion-based generators, enabling quality-aware image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/iqa-adapter-exploring-knowledge-transfer-from</guid>
    </item>
    <item>
      <title>Multimodal Fusion Learning with Dual Attention for Medical Imaging</title>
      <link>https://paperswithcode.com/paper/multimodal-fusion-learning-with-dual</link>
      <description><![CDATA[We show that the multi-branch fusion attention of DRIFA learns enhanced representations for each modality, such as dermoscopy, pap smear, MRI, and CT-scan, whereas multimodal information fusion attention module learns more refined multimodal shared representations, improving the network's generalization across multiple tasks and enhancing overall performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-fusion-learning-with-dual</guid>
    </item>
    <item>
      <title>MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation</title>
      <link>https://paperswithcode.com/paper/mambau-lite-a-lightweight-model-based-on</link>
      <description><![CDATA[Early detection of skin abnormalities plays a crucial role in diagnosing and treating skin cancer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mambau-lite-a-lightweight-model-based-on</guid>
    </item>
    <item>
      <title>The "LLM World of Words" English free association norms generated by large language models</title>
      <link>https://paperswithcode.com/paper/the-llm-world-of-words-english-free</link>
      <description><![CDATA[We demonstrate how these datasets can be used for investigating implicit biases in humans and LLMs, such as the harmful gender stereotypes that are prevalent both in society and LLM outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-llm-world-of-words-english-free</guid>
    </item>
    <item>
      <title>XQ-GAN: An Open-source Image Tokenization Framework for Autoregressive Generation</title>
      <link>https://paperswithcode.com/paper/xq-gan-an-open-source-image-tokenization</link>
      <description><![CDATA[Improvements in architecture, quantization techniques, and training recipes have significantly enhanced both image reconstruction and the downstream generation quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xq-gan-an-open-source-image-tokenization</guid>
    </item>
    <item>
      <title>SailCompass: Towards Reproducible and Robust Evaluation for Southeast Asian Languages</title>
      <link>https://paperswithcode.com/paper/sailcompass-towards-reproducible-and-robust</link>
      <description><![CDATA[In this paper, we introduce SailCompass, a reproducible and robust evaluation benchmark for assessing Large Language Models (LLMs) on Southeast Asian Languages (SEA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sailcompass-towards-reproducible-and-robust</guid>
    </item>
    <item>
      <title>Phaseformer: Phase-based Attention Mechanism for Underwater Image Restoration and Beyond</title>
      <link>https://paperswithcode.com/paper/phaseformer-phase-based-attention-mechanism</link>
      <description><![CDATA[Quality degradation is observed in underwater images due to the effects of light refraction and absorption by water, leading to issues like color cast, haziness, and limited visibility.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phaseformer-phase-based-attention-mechanism</guid>
    </item>
    <item>
      <title>Towards Universal Soccer Video Understanding</title>
      <link>https://paperswithcode.com/paper/towards-universal-soccer-video-understanding</link>
      <description><![CDATA[As a globally celebrated sport, soccer has attracted widespread interest from fans over the world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-universal-soccer-video-understanding</guid>
    </item>
    <item>
      <title>PhysGame: Uncovering Physical Commonsense Violations in Gameplay Videos</title>
      <link>https://paperswithcode.com/paper/physgame-uncovering-physical-commonsense-1</link>
      <description><![CDATA[In this paper, we propose PhysGame as a pioneering benchmark to evaluate physical commonsense violations in gameplay videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physgame-uncovering-physical-commonsense-1</guid>
    </item>
    <item>
      <title>NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision</title>
      <link>https://paperswithcode.com/paper/ncdd-nearest-centroid-distance-deficit-for</link>
      <description><![CDATA[Evaluations across multiple deep learning architectures and two publicly available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness of our approach compared to several state-of-the-art methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ncdd-nearest-centroid-distance-deficit-for</guid>
    </item>
    <item>
      <title>R-Bot: An LLM-based Query Rewrite System</title>
      <link>https://paperswithcode.com/paper/r-bot-an-llm-based-query-rewrite-system</link>
      <description><![CDATA[Query rewrite is essential for optimizing SQL queries to improve their execution efficiency without changing their results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r-bot-an-llm-based-query-rewrite-system</guid>
    </item>
    <item>
      <title>HackSynth: LLM Agent and Evaluation Framework for Autonomous Penetration Testing</title>
      <link>https://paperswithcode.com/paper/hacksynth-llm-agent-and-evaluation-framework</link>
      <description><![CDATA[We introduce HackSynth, a novel Large Language Model (LLM)-based agent capable of autonomous penetration testing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hacksynth-llm-agent-and-evaluation-framework</guid>
    </item>
    <item>
      <title>Align-KD: Distilling Cross-Modal Alignment Knowledge for Mobile Vision-Language Model</title>
      <link>https://paperswithcode.com/paper/align-kd-distilling-cross-modal-alignment</link>
      <description><![CDATA[The teacher also helps student learn the projection of vision token into text embedding space based on the focus of text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/align-kd-distilling-cross-modal-alignment</guid>
    </item>
    <item>
      <title>TinyFusion: Diffusion Transformers Learned Shallow</title>
      <link>https://paperswithcode.com/paper/tinyfusion-diffusion-transformers-learned</link>
      <description><![CDATA[In this work, we present TinyFusion, a depth pruning method designed to remove redundant layers from diffusion transformers via end-to-end learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tinyfusion-diffusion-transformers-learned</guid>
    </item>
  </channel>
</rss>
