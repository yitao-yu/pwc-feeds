<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 09 Jun 2024 09:13:59 +0000</lastBuildDate>
    <item>
      <title>Do Language Models Understand Morality? Towards a Robust Detection of Moral Content</title>
      <link>https://paperswithcode.com/paper/do-language-models-understand-morality</link>
      <description><![CDATA[We introduce the Davinci model as a state-of-the-art zero-shot unsupervised moral values classifier, pushing the boundaries of moral value detection without the need for explicit training on labeled data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-language-models-understand-morality</guid>
    </item>
    <item>
      <title>BitsFusion: 1.99 bits Weight Quantization of Diffusion Model</title>
      <link>https://paperswithcode.com/paper/bitsfusion-1-99-bits-weight-quantization-of</link>
      <description><![CDATA[Diffusion-based image generation models have achieved great success in recent years by showing the capability of synthesizing high-quality content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bitsfusion-1-99-bits-weight-quantization-of</guid>
    </item>
    <item>
      <title>Batch-in-Batch: a new adversarial training framework for initial perturbation and sample selection</title>
      <link>https://paperswithcode.com/paper/batch-in-batch-a-new-adversarial-training</link>
      <description><![CDATA[Adversarial training methods commonly generate independent initial perturbation for adversarial samples from a simple uniform distribution, and obtain the training batch for the classifier without selection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/batch-in-batch-a-new-adversarial-training</guid>
    </item>
    <item>
      <title>DSNet: A Novel Way to Use Atrous Convolutions in Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/dsnet-a-novel-way-to-use-atrous-convolutions</link>
      <description><![CDATA[Following these guidelines, we propose DSNet, a Dual-Branch CNN architecture, which incorporates atrous convolutions in the shallow layers of the model architecture, as well as pretraining the nearly entire encoder on ImageNet to achieve better performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dsnet-a-novel-way-to-use-atrous-convolutions</guid>
    </item>
    <item>
      <title>LLMEmbed: Rethinking Lightweight LLM's Genuine Function in Text Classification</title>
      <link>https://paperswithcode.com/paper/llmembed-rethinking-lightweight-llm-s-genuine</link>
      <description><![CDATA[With the booming of Large Language Models (LLMs), prompt-learning has become a promising method mainly researched in various research areas.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llmembed-rethinking-lightweight-llm-s-genuine</guid>
    </item>
    <item>
      <title>Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt</title>
      <link>https://paperswithcode.com/paper/jailbreak-vision-language-models-via-bi-modal</link>
      <description><![CDATA[To address this limitation, this paper introduces the Bi-Modal Adversarial Prompt Attack (BAP), which executes jailbreaks by optimizing textual and visual prompts cohesively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jailbreak-vision-language-models-via-bi-modal</guid>
    </item>
    <item>
      <title>VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval</title>
      <link>https://paperswithcode.com/paper/vista-visualized-text-embedding-for-universal</link>
      <description><![CDATA[Thirdly, we introduce a multi-stage training algorithm, which first aligns the visual token embedding with the text encoder using massive weakly labeled data, and then develops multi-modal representation capability using the generated composed image-text data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vista-visualized-text-embedding-for-universal</guid>
    </item>
    <item>
      <title>Slicing Mutual Information Generalization Bounds for Neural Networks</title>
      <link>https://paperswithcode.com/paper/slicing-mutual-information-generalization</link>
      <description><![CDATA[The ability of machine learning (ML) algorithms to generalize well to unseen data has been studied through the lens of information theory, by bounding the generalization error with the input-output mutual information (MI), i. e., the MI between the training data and the learned hypothesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/slicing-mutual-information-generalization</guid>
    </item>
    <item>
      <title>Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language Model</title>
      <link>https://paperswithcode.com/paper/legal-documents-drafting-with-fine-tuned-pre</link>
      <description><![CDATA[However, in the legal field application, it is difficult to obtain a large number of manually annotated data sets, which restricts the typical method applied to the task of drafting legal documents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/legal-documents-drafting-with-fine-tuned-pre</guid>
    </item>
    <item>
      <title>Uncovering Limitations of Large Language Models in Information Seeking from Tables</title>
      <link>https://paperswithcode.com/paper/uncovering-limitations-of-large-language</link>
      <description><![CDATA[Seeking information from tables (TIS) is a crucial capability for Large Language Models (LLMs), serving as the foundation of knowledge-based Q&A systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncovering-limitations-of-large-language</guid>
    </item>
    <item>
      <title>What is Dataset Distillation Learning?</title>
      <link>https://paperswithcode.com/paper/what-is-dataset-distillation-learning</link>
      <description><![CDATA[We reveal distilled data cannot serve as a substitute for real data during training outside the standard evaluation setting for dataset distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-is-dataset-distillation-learning</guid>
    </item>
    <item>
      <title>Spatio-temporal Early Prediction based on Multi-objective Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/spatio-temporal-early-prediction-based-on</link>
      <description><![CDATA[Accuracy and timeliness are indeed often conflicting goals in prediction tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatio-temporal-early-prediction-based-on</guid>
    </item>
    <item>
      <title>Bayesian Power Steering: An Effective Approach for Domain Adaptation of Diffusion Models</title>
      <link>https://paperswithcode.com/paper/bayesian-power-steering-an-effective-approach</link>
      <description><![CDATA[We propose a Bayesian framework for fine-tuning large diffusion models with a novel network structure called Bayesian Power Steering (BPS).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bayesian-power-steering-an-effective-approach</guid>
    </item>
    <item>
      <title>VideoTetris: Towards Compositional Text-to-Video Generation</title>
      <link>https://paperswithcode.com/paper/videotetris-towards-compositional-text-to</link>
      <description><![CDATA[Diffusion models have demonstrated great success in text-to-video (T2V) generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videotetris-towards-compositional-text-to</guid>
    </item>
    <item>
      <title>Pointer-Guided Pre-Training: Infusing Large Language Models with Paragraph-Level Contextual Awareness</title>
      <link>https://paperswithcode.com/paper/pointer-guided-pre-training-infusing-large</link>
      <description><![CDATA[We introduce "pointer-guided segment ordering" (SO), a novel pre-training technique aimed at enhancing the contextual understanding of paragraph-level text representations in large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pointer-guided-pre-training-infusing-large</guid>
    </item>
    <item>
      <title>Leveraging automatic strategy discovery to teach people how to select better projects</title>
      <link>https://paperswithcode.com/paper/leveraging-automatic-strategy-discovery-to</link>
      <description><![CDATA[We develop a computational method (MGPS) that automatically discovers project selection strategies that are optimized for real people and develop an intelligent tutor that teaches the discovered strategies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-automatic-strategy-discovery-to</guid>
    </item>
    <item>
      <title>From Tissue Plane to Organ World: A Benchmark Dataset for Multimodal Biomedical Image Registration using Deep Co-Attention Networks</title>
      <link>https://paperswithcode.com/paper/from-tissue-plane-to-organ-world-a-benchmark</link>
      <description><![CDATA[To gain the most information from this multimodal, multiscale approach, it is desirable to identify precisely where a histologic tissue section was taken from within the organ in order to correlate with the tissue features in exactly the same organ region.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-tissue-plane-to-organ-world-a-benchmark</guid>
    </item>
    <item>
      <title>The 3D-PC: a benchmark for visual perspective taking in humans and machines</title>
      <link>https://paperswithcode.com/paper/the-3d-pc-a-benchmark-for-visual-perspective</link>
      <description><![CDATA[It is an essential feature of human intelligence, which develops over the first decade of life and requires an ability to process the 3D structure of visual scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-3d-pc-a-benchmark-for-visual-perspective</guid>
    </item>
    <item>
      <title>On the Expressive Power of Spectral Invariant Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/on-the-expressive-power-of-spectral-invariant</link>
      <description><![CDATA[On the other hand, we prove that EPNN itself is bounded by a recently proposed class of Subgraph GNNs, implying that all these spectral invariant architectures are strictly less expressive than 3-WL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-expressive-power-of-spectral-invariant</guid>
    </item>
    <item>
      <title>Frequency-based Matcher for Long-tailed Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/frequency-based-matcher-for-long-tailed</link>
      <description><![CDATA[The successful application of semantic segmentation technology in the real world has been among the most exciting achievements in the computer vision community over the past decade.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/frequency-based-matcher-for-long-tailed</guid>
    </item>
    <item>
      <title>Coarse-To-Fine Tensor Trains for Compact Visual Representations</title>
      <link>https://paperswithcode.com/paper/coarse-to-fine-tensor-trains-for-compact</link>
      <description><![CDATA[This has prevented practitioners from deploying the full potential of tensor networks for visual data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coarse-to-fine-tensor-trains-for-compact</guid>
    </item>
    <item>
      <title>MLVU: A Comprehensive Benchmark for Multi-Task Long Video Understanding</title>
      <link>https://paperswithcode.com/paper/mlvu-a-comprehensive-benchmark-for-multi-task</link>
      <description><![CDATA[To address the above problems, we propose a new benchmark, called MLVU (Multi-task Long Video Understanding Benchmark), for the comprehensive and in-depth evaluation of LVU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mlvu-a-comprehensive-benchmark-for-multi-task</guid>
    </item>
    <item>
      <title>ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions</title>
      <link>https://paperswithcode.com/paper/abex-data-augmentation-for-low-resource-nlu</link>
      <description><![CDATA[We present ABEX, a novel and effective generative data augmentation methodology for low-resource Natural Language Understanding (NLU) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/abex-data-augmentation-for-low-resource-nlu</guid>
    </item>
    <item>
      <title>Amortized Equation Discovery in Hybrid Dynamical Systems</title>
      <link>https://paperswithcode.com/paper/amortized-equation-discovery-in-hybrid</link>
      <description><![CDATA[Hybrid dynamical systems are prevalent in science and engineering to express complex systems with continuous and discrete states.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/amortized-equation-discovery-in-hybrid</guid>
    </item>
    <item>
      <title>Repurposing Language Models into Embedding Models: Finding the Compute-Optimal Recipe</title>
      <link>https://paperswithcode.com/paper/repurposing-language-models-into-embedding</link>
      <description><![CDATA[Text embeddings are essential for many tasks, such as document retrieval, clustering, and semantic similarity assessment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repurposing-language-models-into-embedding</guid>
    </item>
    <item>
      <title>Contrastive Sparse Autoencoders for Interpreting Planning of Chess-Playing Agents</title>
      <link>https://paperswithcode.com/paper/contrastive-sparse-autoencoders-for</link>
      <description><![CDATA[This is unsustainable in ensuring transparency to the end-user, particularly when these systems are responsible for sensitive decision-making.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-sparse-autoencoders-for</guid>
    </item>
    <item>
      <title>The CLRS-Text Algorithmic Reasoning Language Benchmark</title>
      <link>https://paperswithcode.com/paper/the-clrs-text-algorithmic-reasoning-language</link>
      <description><![CDATA[Three years ago, a similar issue was identified and rectified in the field of neural algorithmic reasoning, with the advent of the CLRS benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-clrs-text-algorithmic-reasoning-language</guid>
    </item>
    <item>
      <title>Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/generalization-enhanced-code-vulnerability</link>
      <description><![CDATA[First, we utilize the vulnerability patches to construct a vulnerability localization task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalization-enhanced-code-vulnerability</guid>
    </item>
    <item>
      <title>A Large-Scale Neutral Comparison Study of Survival Models on Low-Dimensional Data</title>
      <link>https://paperswithcode.com/paper/a-large-scale-neutral-comparison-study-of</link>
      <description><![CDATA[Evaluating on 8 survival metrics, we assess discrimination, calibration, and overall predictive performance of the tested models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-large-scale-neutral-comparison-study-of</guid>
    </item>
    <item>
      <title>FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages</title>
      <link>https://paperswithcode.com/paper/fairytaleqa-translated-enabling-educational</link>
      <description><![CDATA[By employing fine-tuned, modest-scale models, we establish benchmarks for both Question Generation (QG) and QA tasks within the translated datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fairytaleqa-translated-enabling-educational</guid>
    </item>
    <item>
      <title>How Far Can We Compress Instant-NGP-Based NeRF?</title>
      <link>https://paperswithcode.com/paper/how-far-can-we-compress-instant-ngp-based</link>
      <description><![CDATA[In this paper, we introduce the Context-based NeRF Compression (CNC) framework, which leverages highly efficient context models to provide a storage-friendly NeRF representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-far-can-we-compress-instant-ngp-based</guid>
    </item>
    <item>
      <title>Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster</title>
      <link>https://paperswithcode.com/paper/explainability-and-hate-speech-structured</link>
      <description><![CDATA[Content moderators play a key role in keeping the conversation on social media healthy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explainability-and-hate-speech-structured</guid>
    </item>
    <item>
      <title>NoisyGL: A Comprehensive Benchmark for Graph Neural Networks under Label Noise</title>
      <link>https://paperswithcode.com/paper/noisygl-a-comprehensive-benchmark-for-graph</link>
      <description><![CDATA[However, due to variations in dataset selection, data splitting, and preprocessing techniques, the community currently lacks a comprehensive benchmark, which impedes deeper understanding and further development of GLN.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/noisygl-a-comprehensive-benchmark-for-graph</guid>
    </item>
    <item>
      <title>Bench2Drive: Towards Multi-Ability Benchmarking of Closed-Loop End-To-End Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/bench2drive-towards-multi-ability</link>
      <description><![CDATA[In an era marked by the rapid scaling of foundation models, autonomous driving technologies are approaching a transformative threshold where end-to-end autonomous driving (E2E-AD) emerges due to its potential of scaling up in the data-driven manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bench2drive-towards-multi-ability</guid>
    </item>
    <item>
      <title>Intention and Face in Dialog</title>
      <link>https://paperswithcode.com/paper/intention-and-face-in-dialog</link>
      <description><![CDATA[The notion of face described by Brown and Levinson (1987) has been studied in great detail, but a critical aspect of the framework, that which focuses on how intentions mediate the planning of turns which impose upon face, has received far less attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intention-and-face-in-dialog</guid>
    </item>
    <item>
      <title>Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models</title>
      <link>https://paperswithcode.com/paper/buffer-of-thoughts-thought-augmented</link>
      <description><![CDATA[We introduce Buffer of Thoughts (BoT), a novel and versatile thought-augmented reasoning approach for enhancing accuracy, efficiency and robustness of large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/buffer-of-thoughts-thought-augmented</guid>
    </item>
    <item>
      <title>Linguistically Conditioned Semantic Textual Similarity</title>
      <link>https://paperswithcode.com/paper/linguistically-conditioned-semantic-textual</link>
      <description><![CDATA[We also propose a new method that largely improves the performance over baselines on the C-STS data by training the models with the answers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linguistically-conditioned-semantic-textual</guid>
    </item>
    <item>
      <title>Untrained Neural Nets for Snapshot Compressive Imaging: Theory and Algorithms</title>
      <link>https://paperswithcode.com/paper/untrained-neural-nets-for-snapshot</link>
      <description><![CDATA[We also employ the recently proposed bagged-deep-image-prior (bagged-DIP) idea to develop SCI Bagged Deep Video Prior (SCI-BDVP) algorithms that address the common challenges faced by standard UNN solutions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/untrained-neural-nets-for-snapshot</guid>
    </item>
    <item>
      <title>DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data</title>
      <link>https://paperswithcode.com/paper/direct-3d-learning-direct-text-to-3d</link>
      <description><![CDATA[Unlike recent 3D generative models that rely on clean and well-aligned 3D data, limiting them to single or few-class generation, our model is directly trained on extensive noisy and unaligned `in-the-wild' 3D assets, mitigating the key challenge (i. e., data scarcity) in large-scale 3D generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct-3d-learning-direct-text-to-3d</guid>
    </item>
    <item>
      <title>Everything to the Synthetic: Diffusion-driven Test-time Adaptation via Synthetic-Domain Alignment</title>
      <link>https://paperswithcode.com/paper/everything-to-the-synthetic-diffusion-driven</link>
      <description><![CDATA[To adapt the source model to the synthetic domain of the unconditional diffusion model, we introduce a Synthetic-Domain Alignment (SDA) framework to fine-tune the source model with synthetic data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/everything-to-the-synthetic-diffusion-driven</guid>
    </item>
    <item>
      <title>Privacy Preserving Semi-Decentralized Mean Estimation over Intermittently-Connected Networks</title>
      <link>https://paperswithcode.com/paper/privacy-preserving-semi-decentralized-mean</link>
      <description><![CDATA[We consider the problem of privately estimating the mean of vectors distributed across different nodes of an unreliable wireless network, where communications between nodes can fail intermittently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/privacy-preserving-semi-decentralized-mean</guid>
    </item>
    <item>
      <title>ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization</title>
      <link>https://paperswithcode.com/paper/reno-enhancing-one-step-text-to-image-models</link>
      <description><![CDATA[Moreover, given the same computational resources, a ReNO-optimized one-step model outperforms widely-used open-source models such as SDXL and PixArt-$\alpha$, highlighting the efficiency and effectiveness of ReNO in enhancing T2I model performance at inference time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reno-enhancing-one-step-text-to-image-models</guid>
    </item>
    <item>
      <title>On The Persona-based Summarization of Domain-Specific Documents</title>
      <link>https://paperswithcode.com/paper/on-the-persona-based-summarization-of-domain</link>
      <description><![CDATA[However, every persona of a domain has different requirements of information and hence their summarization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-persona-based-summarization-of-domain</guid>
    </item>
    <item>
      <title>Lean Workbook: A large-scale Lean problem set formalized from natural language math problems</title>
      <link>https://paperswithcode.com/paper/lean-workbook-a-large-scale-lean-problem-set</link>
      <description><![CDATA[Our results indicate that the synthetic data pipeline can provide useful training data and improve the performance of LLMs in translating and understanding complex mathematical problems and proofs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lean-workbook-a-large-scale-lean-problem-set</guid>
    </item>
    <item>
      <title>Scaling and evaluating sparse autoencoders</title>
      <link>https://paperswithcode.com/paper/scaling-and-evaluating-sparse-autoencoders</link>
      <description><![CDATA[Using these techniques, we find clean scaling laws with respect to autoencoder size and sparsity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-and-evaluating-sparse-autoencoders</guid>
    </item>
    <item>
      <title>Stereo-Depth Fusion through Virtual Pattern Projection</title>
      <link>https://paperswithcode.com/paper/stereo-depth-fusion-through-virtual-pattern</link>
      <description><![CDATA[This paper presents a novel general-purpose stereo and depth data fusion paradigm that mimics the active stereo principle by replacing the unreliable physical pattern projector with a depth sensor.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stereo-depth-fusion-through-virtual-pattern</guid>
    </item>
    <item>
      <title>LNQ Challenge 2023: Learning Mediastinal Lymph Node Segmentation with a Probabilistic Lymph Node Atlas</title>
      <link>https://paperswithcode.com/paper/lnq-challenge-2023-learning-mediastinal-lymph</link>
      <description><![CDATA[The evaluation of lymph node metastases plays a crucial role in achieving precise cancer staging, influencing subsequent decisions regarding treatment options.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lnq-challenge-2023-learning-mediastinal-lymph</guid>
    </item>
    <item>
      <title>VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling</title>
      <link>https://paperswithcode.com/paper/vidmuse-a-simple-video-to-music-generation</link>
      <description><![CDATA[In this work, we systematically study music generation conditioned solely on the video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vidmuse-a-simple-video-to-music-generation</guid>
    </item>
    <item>
      <title>UltraMedical: Building Specialized Generalists in Biomedicine</title>
      <link>https://paperswithcode.com/paper/ultramedical-building-specialized-generalists</link>
      <description><![CDATA[Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains and are moving towards more specialized areas.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ultramedical-building-specialized-generalists</guid>
    </item>
    <item>
      <title>Matching Anything by Segmenting Anything</title>
      <link>https://paperswithcode.com/paper/matching-anything-by-segmenting-anything</link>
      <description><![CDATA[The robust association of the same objects across video frames in complex scenes is crucial for many applications, especially Multiple Object Tracking (MOT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/matching-anything-by-segmenting-anything</guid>
    </item>
  </channel>
</rss>
