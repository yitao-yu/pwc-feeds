<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 16 Jul 2024 09:15:37 +0000</lastBuildDate>
    <item>
      <title>PolyRoom: Room-aware Transformer for Floorplan Reconstruction</title>
      <link>https://paperswithcode.com/paper/polyroom-room-aware-transformer-for-floorplan</link>
      <description><![CDATA[To tackle these challenges, we present PolyRoom, a room-aware Transformer that leverages uniform sampling representation, room-aware query initialization, and room-aware self-attention for floorplan reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/polyroom-room-aware-transformer-for-floorplan</guid>
    </item>
    <item>
      <title>SEED: A Simple and Effective 3D DETR in Point Clouds</title>
      <link>https://paperswithcode.com/paper/seed-a-simple-and-effective-3d-detr-in-point</link>
      <description><![CDATA[We argue that the main challenges are twofold: 1) How to obtain the appropriate object queries is challenging due to the high sparsity and uneven distribution of point clouds; 2) How to implement an effective query interaction by exploiting the rich geometric structure of point clouds is not fully explored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seed-a-simple-and-effective-3d-detr-in-point</guid>
    </item>
    <item>
      <title>Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education</title>
      <link>https://paperswithcode.com/paper/graphusion-leveraging-large-language-models</link>
      <description><![CDATA[Specifically, we introduce TutorQA, a new expert-verified benchmark for graph reasoning and QA, comprising six tasks and a total of 1, 200 QA pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphusion-leveraging-large-language-models</guid>
    </item>
    <item>
      <title>IDOL: Unified Dual-Modal Latent Diffusion for Human-Centric Joint Video-Depth Generation</title>
      <link>https://paperswithcode.com/paper/idol-unified-dual-modal-latent-diffusion-for</link>
      <description><![CDATA[First, to enable dual-modal generation and maximize the information exchange between video and depth generation, we propose a unified dual-modal U-Net, a parameter-sharing framework for joint video and depth denoising, wherein a modality label guides the denoising target, and cross-modal attention enables the mutual information flow.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/idol-unified-dual-modal-latent-diffusion-for</guid>
    </item>
    <item>
      <title>Aligning Neuronal Coding of Dynamic Visual Scenes with Foundation Vision Models</title>
      <link>https://paperswithcode.com/paper/aligning-neuronal-coding-of-dynamic-visual</link>
      <description><![CDATA[In conclusion, our proposed Vi-ST demonstrates a novel modeling framework for neuronal coding of dynamic visual scenes in the brain, effectively aligning our brain representation of video with neuronal activity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-neuronal-coding-of-dynamic-visual</guid>
    </item>
    <item>
      <title>VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation</title>
      <link>https://paperswithcode.com/paper/vgbench-evaluating-large-language-models-on</link>
      <description><![CDATA[In the realm of vision models, the primary mode of representation is using pixels to rasterize the visual world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vgbench-evaluating-large-language-models-on</guid>
    </item>
    <item>
      <title>Accessing Vision Foundation Models at ImageNet-level Costs</title>
      <link>https://paperswithcode.com/paper/accessing-vision-foundation-models-at</link>
      <description><![CDATA[Vision foundation models are renowned for their generalization ability due to massive training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accessing-vision-foundation-models-at</guid>
    </item>
    <item>
      <title>An evaluation of CNN models and data augmentation techniques in hierarchical localization of mobile robots</title>
      <link>https://paperswithcode.com/paper/an-evaluation-of-cnn-models-and-data</link>
      <description><![CDATA[In this sense, an ablation study of different state-of-the-art CNN models used as backbone is presented and a variety of data augmentation visual effects are proposed for addressing the visual localization of the robot.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-evaluation-of-cnn-models-and-data</guid>
    </item>
    <item>
      <title>Deep Diffusion Image Prior for Efficient OOD Adaptation in 3D Inverse Problems</title>
      <link>https://paperswithcode.com/paper/deep-diffusion-image-prior-for-efficient-ood</link>
      <description><![CDATA[However, adaptation of the prior is necessary when there exists a discrepancy between the training and testing distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-diffusion-image-prior-for-efficient-ood</guid>
    </item>
    <item>
      <title>Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?</title>
      <link>https://paperswithcode.com/paper/spider2-v-how-far-are-multimodal-agents-from</link>
      <description><![CDATA[These tasks, derived from real-world use cases, evaluate the ability of a multimodal agent to perform data-related tasks by writing code and managing the GUI in enterprise data software systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spider2-v-how-far-are-multimodal-agents-from</guid>
    </item>
    <item>
      <title>DiffStega: Towards Universal Training-Free Coverless Image Steganography with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/diffstega-towards-universal-training-free</link>
      <description><![CDATA[Traditional image steganography focuses on concealing one image within another, aiming to avoid steganalysis by unauthorized entities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffstega-towards-universal-training-free</guid>
    </item>
    <item>
      <title>Enhanced Self-supervised Learning for Multi-modality MRI Segmentation and Classification: A Novel Approach Avoiding Model Collapse</title>
      <link>https://paperswithcode.com/paper/enhanced-self-supervised-learning-for-multi</link>
      <description><![CDATA[The PBT module exploits the pyramidal hierarchy of the network to construct barlow twin loss between masked and original views, aligning the semantic representations of image patches at different vision scales in latent space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhanced-self-supervised-learning-for-multi</guid>
    </item>
    <item>
      <title>Sibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning</title>
      <link>https://paperswithcode.com/paper/sibyl-simple-yet-effective-agent-framework</link>
      <description><![CDATA[To address these limitations, we introduce Sibyl, a simple yet powerful LLM-based agent framework designed to tackle complex reasoning tasks by efficiently leveraging a minimal set of tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sibyl-simple-yet-effective-agent-framework</guid>
    </item>
    <item>
      <title>Understanding the Dependence of Perception Model Competency on Regions in an Image</title>
      <link>https://paperswithcode.com/paper/understanding-the-dependence-of-perception</link>
      <description><![CDATA[We find that the competency gradients and reconstruction loss methods show great promise in identifying regions associated with low model competency, particularly when aspects of the image that are unfamiliar to the perception model are causing this reduction in competency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-the-dependence-of-perception</guid>
    </item>
    <item>
      <title>GRUtopia: Dream General Robots in a City at Scale</title>
      <link>https://paperswithcode.com/paper/grutopia-dream-general-robots-in-a-city-at</link>
      <description><![CDATA[Recent works have been exploring the scaling laws in the field of Embodied AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grutopia-dream-general-robots-in-a-city-at</guid>
    </item>
    <item>
      <title>Pathformer3D: A 3D Scanpath Transformer for 360Â° Images</title>
      <link>https://paperswithcode.com/paper/pathformer3d-a-3d-scanpath-transformer-for</link>
      <description><![CDATA[Then, the contextual feature representation and historical fixation information are input into a Transformer decoder to output current time step's fixation embedding, where the self-attention module is used to imitate the visual working memory mechanism of human visual system and directly model the time dependencies among the fixations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pathformer3d-a-3d-scanpath-transformer-for</guid>
    </item>
    <item>
      <title>AccDiffusion: An Accurate Method for Higher-Resolution Image Generation</title>
      <link>https://paperswithcode.com/paper/accdiffusion-an-accurate-method-for-higher</link>
      <description><![CDATA[This paper attempts to address the object repetition issue in patch-wise higher-resolution image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accdiffusion-an-accurate-method-for-higher</guid>
    </item>
    <item>
      <title>DataDream: Few-shot Guided Dataset Generation</title>
      <link>https://paperswithcode.com/paper/datadream-few-shot-guided-dataset-generation</link>
      <description><![CDATA[While text-to-image diffusion models have been shown to achieve state-of-the-art results in image synthesis, they have yet to prove their effectiveness in downstream applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datadream-few-shot-guided-dataset-generation</guid>
    </item>
    <item>
      <title>GeoMix: Towards Geometry-Aware Data Augmentation</title>
      <link>https://paperswithcode.com/paper/geomix-towards-geometry-aware-data</link>
      <description><![CDATA[It effectively utilizes geometry information to interpolate features and labels with those from the nearby neighborhood, generating synthetic nodes and establishing connections for them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geomix-towards-geometry-aware-data</guid>
    </item>
    <item>
      <title>Learning Dynamics of LLM Finetuning</title>
      <link>https://paperswithcode.com/paper/learning-dynamics-of-llm-finetuning</link>
      <description><![CDATA[Learning dynamics, which describes how the learning of specific training examples influences the model's prediction of other examples, give us a powerful tool for understanding the behavior of deep learning systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-dynamics-of-llm-finetuning</guid>
    </item>
    <item>
      <title>Quantized Prompt for Efficient Generalization of Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/quantized-prompt-for-efficient-generalization</link>
      <description><![CDATA[During downstream adaptation, the most challenging problems are overfitting and catastrophic forgetting, which can cause the model to overly focus on the current data and lose more crucial domain-general knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quantized-prompt-for-efficient-generalization</guid>
    </item>
    <item>
      <title>Spatio-temporal neural distance fields for conditional generative modeling of the heart</title>
      <link>https://paperswithcode.com/paper/spatio-temporal-neural-distance-fields-for</link>
      <description><![CDATA[The rhythmic pumping motion of the heart stands as a cornerstone in life, as it circulates blood to the entire human body through a series of carefully timed contractions of the individual chambers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatio-temporal-neural-distance-fields-for</guid>
    </item>
    <item>
      <title>Towards Robust Event-based Networks for Nighttime via Unpaired Day-to-Night Event Translation</title>
      <link>https://paperswithcode.com/paper/towards-robust-event-based-networks-for</link>
      <description><![CDATA[To overcome the limitation, we aim to alleviate data imbalance by translating annotated day data into night events.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-event-based-networks-for</guid>
    </item>
    <item>
      <title>Qwen2-Audio Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-audio-technical-report</link>
      <description><![CDATA[We introduce the latest progress of Qwen-Audio, a large-scale audio-language model called Qwen2-Audio, which is capable of accepting various audio signal inputs and performing audio analysis or direct textual responses with regard to speech instructions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-audio-technical-report</guid>
    </item>
    <item>
      <title>Learning Social Cost Functions for Human-Aware Path Planning</title>
      <link>https://paperswithcode.com/paper/learning-social-cost-functions-for-human</link>
      <description><![CDATA[Achieving social acceptance is one of the main goals of Social Robotic Navigation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-social-cost-functions-for-human</guid>
    </item>
    <item>
      <title>Expanding the Scope: Inductive Knowledge Graph Reasoning with Multi-Starting Progressive Propagation</title>
      <link>https://paperswithcode.com/paper/expanding-the-scope-inductive-knowledge-graph</link>
      <description><![CDATA[Among existing models, graph neural networks (GNNs) based ones have shown promising performance for this task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/expanding-the-scope-inductive-knowledge-graph</guid>
    </item>
    <item>
      <title>Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems</title>
      <link>https://paperswithcode.com/paper/enhancing-retrieval-and-managing-retrieval-a</link>
      <description><![CDATA[These four RAG modules synergistically improve the response quality and efficiency of the RAG system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-retrieval-and-managing-retrieval-a</guid>
    </item>
    <item>
      <title>When Heterophily Meets Heterogeneity: New Graph Benchmarks and Effective Methods</title>
      <link>https://paperswithcode.com/paper/when-heterophily-meets-heterogeneity-new</link>
      <description><![CDATA[However, existing benchmarks for graph learning often focus on heterogeneous graphs with homophily or homogeneous graphs with heterophily, leaving a gap in understanding how methods perform on graphs that are both heterogeneous and heterophilic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-heterophily-meets-heterogeneity-new</guid>
    </item>
    <item>
      <title>Risk-aware Trajectory Prediction by Incorporating Spatio-temporal Traffic Interaction Analysis</title>
      <link>https://paperswithcode.com/paper/risk-aware-trajectory-prediction-by</link>
      <description><![CDATA[To operate in open-ended environments where humans interact in complex, diverse ways, autonomous robots must learn to predict their behaviour, especially when that behavior is potentially dangerous to other agents or to the robot.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/risk-aware-trajectory-prediction-by</guid>
    </item>
    <item>
      <title>Representing Rule-based Chatbots with Transformers</title>
      <link>https://paperswithcode.com/paper/representing-rule-based-chatbots-with</link>
      <description><![CDATA[Next, we train Transformers on a dataset of synthetically generated ELIZA conversations and investigate the mechanisms the models learn.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representing-rule-based-chatbots-with</guid>
    </item>
    <item>
      <title>Boosting Zero-Shot Crosslingual Performance using LLM-Based Augmentations with Effective Data Selection</title>
      <link>https://paperswithcode.com/paper/boosting-zero-shot-crosslingual-performance</link>
      <description><![CDATA[Large language models (LLMs) are very proficient text generators.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-zero-shot-crosslingual-performance</guid>
    </item>
    <item>
      <title>The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism</title>
      <link>https://paperswithcode.com/paper/the-good-the-bad-and-the-greedy-evaluation-of</link>
      <description><![CDATA[Current evaluations of large language models (LLMs) often overlook non-determinism, typically focusing on a single output per example.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-good-the-bad-and-the-greedy-evaluation-of</guid>
    </item>
    <item>
      <title>Motion-prior Contrast Maximization for Dense Continuous-Time Motion Estimation</title>
      <link>https://paperswithcode.com/paper/motion-prior-contrast-maximization-for-dense</link>
      <description><![CDATA[In optical flow estimation, our method elevates a simple UNet to achieve state-of-the-art performance among self-supervised methods on the DSEC optical flow benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motion-prior-contrast-maximization-for-dense</guid>
    </item>
    <item>
      <title>An Empirical Study of Mamba-based Pedestrian Attribute Recognition</title>
      <link>https://paperswithcode.com/paper/an-empirical-study-of-mamba-based-pedestrian</link>
      <description><![CDATA[To further tap into the potential of the novel Mamba architecture for PAR tasks, this paper designs and adapts Mamba into two typical PAR frameworks, i. e., the text-image fusion approach and pure vision Mamba multi-label recognition framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-empirical-study-of-mamba-based-pedestrian</guid>
    </item>
    <item>
      <title>RepVF: A Unified Vector Fields Representation for Multi-task 3D Perception</title>
      <link>https://paperswithcode.com/paper/repvf-a-unified-vector-fields-representation</link>
      <description><![CDATA[Concurrent processing of multiple autonomous driving 3D perception tasks within the same spatiotemporal scene poses a significant challenge, in particular due to the computational inefficiencies and feature competition between tasks when using traditional multi-task learning approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repvf-a-unified-vector-fields-representation</guid>
    </item>
    <item>
      <title>OVLW-DETR: Open-Vocabulary Light-Weighted Detection Transformer</title>
      <link>https://paperswithcode.com/paper/ovlw-detr-open-vocabulary-light-weighted</link>
      <description><![CDATA[Open-vocabulary object detection focusing on detecting novel categories guided by natural language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ovlw-detr-open-vocabulary-light-weighted</guid>
    </item>
    <item>
      <title>Can Textual Semantics Mitigate Sounding Object Segmentation Preference?</title>
      <link>https://paperswithcode.com/paper/can-textual-semantics-mitigate-sounding</link>
      <description><![CDATA[The Audio-Visual Segmentation (AVS) task aims to segment sounding objects in the visual space using audio cues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-textual-semantics-mitigate-sounding</guid>
    </item>
    <item>
      <title>No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen Representations</title>
      <link>https://paperswithcode.com/paper/no-train-all-gain-self-supervised-gradients</link>
      <description><![CDATA[Our method is simple: given any pretrained model, we first compute gradients from various self-supervised objectives for each input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/no-train-all-gain-self-supervised-gradients</guid>
    </item>
    <item>
      <title>Plain-Det: A Plain Multi-Dataset Object Detector</title>
      <link>https://paperswithcode.com/paper/plain-det-a-plain-multi-dataset-object</link>
      <description><![CDATA[Recent advancements in large-scale foundational models have sparked widespread interest in training highly proficient large vision models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plain-det-a-plain-multi-dataset-object</guid>
    </item>
    <item>
      <title>A3S: A General Active Clustering Method with Pairwise Constraints</title>
      <link>https://paperswithcode.com/paper/a3s-a-general-active-clustering-method-with</link>
      <description><![CDATA[Active clustering aims to boost the clustering performance by integrating human-annotated pairwise constraints through strategic querying.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a3s-a-general-active-clustering-method-with</guid>
    </item>
    <item>
      <title>Shape2Scene: 3D Scene Representation Learning Through Pre-training on Shape Data</title>
      <link>https://paperswithcode.com/paper/shape2scene-3d-scene-representation-learning</link>
      <description><![CDATA[In PPC, the inherent correspondence (i. e., point pairs) is naturally obtained in S2SS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shape2scene-3d-scene-representation-learning</guid>
    </item>
    <item>
      <title>Thyroidiomics: An Automated Pipeline for Segmentation and Classification of Thyroid Pathologies from Scintigraphy Images</title>
      <link>https://paperswithcode.com/paper/thyroidiomics-an-automated-pipeline-for</link>
      <description><![CDATA[The objective of this study was to develop an automated pipeline that enhances thyroid disease classification using thyroid scintigraphy images, aiming to decrease assessment time and increase diagnostic accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/thyroidiomics-an-automated-pipeline-for</guid>
    </item>
    <item>
      <title>LabelDistill: Label-guided Cross-modal Knowledge Distillation for Camera-based 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/labeldistill-label-guided-cross-modal</link>
      <description><![CDATA[Recent advancements in camera-based 3D object detection have introduced cross-modal knowledge distillation to bridge the performance gap with LiDAR 3D detectors, leveraging the precise geometric information in LiDAR point clouds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/labeldistill-label-guided-cross-modal</guid>
    </item>
    <item>
      <title>Textless Dependency Parsing by Labeled Sequence Prediction</title>
      <link>https://paperswithcode.com/paper/textless-dependency-parsing-by-labeled</link>
      <description><![CDATA[This paper proposes a textless method for dependency parsing, examining its effectiveness and limitations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textless-dependency-parsing-by-labeled</guid>
    </item>
    <item>
      <title>Noise Calibration: Plug-and-play Content-Preserving Video Enhancement using Pre-trained Video Diffusion Models</title>
      <link>https://paperswithcode.com/paper/noise-calibration-plug-and-play-content</link>
      <description><![CDATA[In order to improve the quality of synthesized videos, currently, one predominant method involves retraining an expert diffusion model and then implementing a noising-denoising process for refinement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/noise-calibration-plug-and-play-content</guid>
    </item>
    <item>
      <title>When Pedestrian Detection Meets Multi-Modal Learning: Generalist Model and Benchmark Dataset</title>
      <link>https://paperswithcode.com/paper/when-pedestrian-detection-meets-multi-modal</link>
      <description><![CDATA[With multi-modal joint training, our model achieves state-of-the-art performance on a wide range of pedestrian detection benchmarks, surpassing leading models tailored for specific sensor modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-pedestrian-detection-meets-multi-modal</guid>
    </item>
    <item>
      <title>ChatLogic: Integrating Logic Programming with Large Language Models for Multi-Step Reasoning</title>
      <link>https://paperswithcode.com/paper/chatlogic-integrating-logic-programming-with</link>
      <description><![CDATA[This paper introduces ChatLogic, an innovative framework specifically targeted at LLM reasoning tasks that can enhance the performance of LLMs in multi-step deductive reasoning tasks by integrating logic programming.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatlogic-integrating-logic-programming-with</guid>
    </item>
    <item>
      <title>xLSTMTime : Long-term Time Series Forecasting With xLSTM</title>
      <link>https://paperswithcode.com/paper/xlstmtime-long-term-time-series-forecasting</link>
      <description><![CDATA[In recent years, transformer-based models have gained prominence in multivariate long-term time series forecasting (LTSF), demonstrating significant advancements despite facing challenges such as high computational demands, difficulty in capturing temporal dynamics, and managing long-term dependencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xlstmtime-long-term-time-series-forecasting</guid>
    </item>
    <item>
      <title>Learning to Steer Markovian Agents under Model Uncertainty</title>
      <link>https://paperswithcode.com/paper/learning-to-steer-markovian-agents-under</link>
      <description><![CDATA[We introduce a model-based non-episodic Reinforcement Learning (RL) formulation for our steering problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-steer-markovian-agents-under</guid>
    </item>
    <item>
      <title>RS-NeRF: Neural Radiance Fields from Rolling Shutter Images</title>
      <link>https://paperswithcode.com/paper/rs-nerf-neural-radiance-fields-from-rolling</link>
      <description><![CDATA[Neural Radiance Fields (NeRFs) have become increasingly popular because of their impressive ability for novel view synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rs-nerf-neural-radiance-fields-from-rolling</guid>
    </item>
  </channel>
</rss>
