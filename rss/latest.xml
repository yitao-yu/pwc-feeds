<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 24 Apr 2024 21:06:55 +0000</lastBuildDate>
    <item>
      <title>Deep neural networks for choice analysis: Enhancing behavioral regularity with gradient regularization</title>
      <link>https://paperswithcode.com/paper/deep-neural-networks-for-choice-analysis-1</link>
      <description><![CDATA[Moreover, the proposed framework is applicable to other NN-based choice models such as TasteNets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-neural-networks-for-choice-analysis-1</guid>
    </item>
    <item>
      <title>Manipulating Recommender Systems: A Survey of Poisoning Attacks and Countermeasures</title>
      <link>https://paperswithcode.com/paper/manipulating-recommender-systems-a-survey-of</link>
      <description><![CDATA[This survey aims to fill this gap by primarily focusing on poisoning attacks and their countermeasures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/manipulating-recommender-systems-a-survey-of</guid>
    </item>
    <item>
      <title>Cross-Domain Causal Preference Learning for Out-of-Distribution Recommendation</title>
      <link>https://paperswithcode.com/paper/cross-domain-causal-preference-learning-for</link>
      <description><![CDATA[Recommender systems use users' historical interactions to learn their preferences and deliver personalized recommendations from a vast array of candidate items.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-domain-causal-preference-learning-for</guid>
    </item>
    <item>
      <title>PRISM: A Promptable and Robust Interactive Segmentation Model with Visual Prompts</title>
      <link>https://paperswithcode.com/paper/prism-a-promptable-and-robust-interactive</link>
      <description><![CDATA[(3) Corrective learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prism-a-promptable-and-robust-interactive</guid>
    </item>
    <item>
      <title>CoProNN: Concept-based Prototypical Nearest Neighbors for Explaining Vision Models</title>
      <link>https://paperswithcode.com/paper/copronn-concept-based-prototypical-nearest</link>
      <description><![CDATA[A promising approach towards designing useful task specific explanations with domain experts is based on compositionality of semantic concepts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/copronn-concept-based-prototypical-nearest</guid>
    </item>
    <item>
      <title>Integrating Heterogeneous Gene Expression Data through Knowledge Graphs for Improving Diabetes Prediction</title>
      <link>https://paperswithcode.com/paper/integrating-heterogeneous-gene-expression</link>
      <description><![CDATA[Diabetes is a worldwide health issue affecting millions of people.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/integrating-heterogeneous-gene-expression</guid>
    </item>
    <item>
      <title>Regularized Gauss-Newton for Optimizing Overparameterized Neural Networks</title>
      <link>https://paperswithcode.com/paper/regularized-gauss-newton-for-optimizing</link>
      <description><![CDATA[This work studies a GGN method for optimizing a two-layer neural network with explicit regularization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/regularized-gauss-newton-for-optimizing</guid>
    </item>
    <item>
      <title>Unsupervised Domain Adaptation Architecture Search with Self-Training for Land Cover Mapping</title>
      <link>https://paperswithcode.com/paper/unsupervised-domain-adaptation-architecture</link>
      <description><![CDATA[Thus, we proposed a simple yet effective framework to search for lightweight neural networks automatically for land cover mapping tasks under domain shifts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-domain-adaptation-architecture</guid>
    </item>
    <item>
      <title>Unified Unsupervised Salient Object Detection via Knowledge Transfer</title>
      <link>https://paperswithcode.com/paper/unified-unsupervised-salient-object-detection</link>
      <description><![CDATA[Firstly, we propose a Progressive Curriculum Learning-based Saliency Distilling (PCL-SD) mechanism to extract saliency cues from a pre-trained deep network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-unsupervised-salient-object-detection</guid>
    </item>
    <item>
      <title>The Power of the Noisy Channel: Unsupervised End-to-End Task-Oriented Dialogue with LLMs</title>
      <link>https://paperswithcode.com/paper/the-power-of-the-noisy-channel-unsupervised</link>
      <description><![CDATA[Training task-oriented dialogue systems typically requires turn-level annotations for interacting with their APIs: e. g. a dialogue state and the system actions taken at each step.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-power-of-the-noisy-channel-unsupervised</guid>
    </item>
    <item>
      <title>CAGE: Circumplex Affect Guided Expression Inference</title>
      <link>https://paperswithcode.com/paper/cage-circumplex-affect-guided-expression</link>
      <description><![CDATA[Using a small-scaled MaxViT-based model architecture, we evaluate the impact of discrete expression category labels in training with the continuous valence and arousal labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cage-circumplex-affect-guided-expression</guid>
    </item>
    <item>
      <title>Exploring and Unleashing the Power of Large Language Models in Automated Code Translation</title>
      <link>https://paperswithcode.com/paper/exploring-and-unleashing-the-power-of-large</link>
      <description><![CDATA[Specifically, UniTrans first craft a series of test cases for target programs with the assistance of source programs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-and-unleashing-the-power-of-large</guid>
    </item>
    <item>
      <title>Simple, Efficient and Scalable Structure-aware Adapter Boosts Protein Language Models</title>
      <link>https://paperswithcode.com/paper/simple-efficient-and-scalable-structure-aware</link>
      <description><![CDATA[Fine-tuning Pre-trained protein language models (PLMs) has emerged as a prominent strategy for enhancing downstream prediction tasks, often outperforming traditional supervised learning approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simple-efficient-and-scalable-structure-aware</guid>
    </item>
    <item>
      <title>XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts</title>
      <link>https://paperswithcode.com/paper/xft-unlocking-the-power-of-code-instruction</link>
      <description><![CDATA[We introduce XFT, a simple yet powerful training scheme, by simply merging upcycled Mixture-of-Experts (MoE) to unleash the performance limit of instruction-tuned code Large Language Models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xft-unlocking-the-power-of-code-instruction</guid>
    </item>
    <item>
      <title>CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies</title>
      <link>https://paperswithcode.com/paper/culturebank-an-online-community-driven</link>
      <description><![CDATA[To enhance language models' cultural awareness, we design a generalizable pipeline to construct cultural knowledge bases from different online communities on a massive scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/culturebank-an-online-community-driven</guid>
    </item>
    <item>
      <title>Simulating Task-Oriented Dialogues with State Transition Graphs and Large Language Models</title>
      <link>https://paperswithcode.com/paper/simulating-task-oriented-dialogues-with-state</link>
      <description><![CDATA[In our experiments, using graph-guided response simulations leads to significant improvements in intent classification, slot filling and response relevance compared to naive single-prompt simulated conversations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simulating-task-oriented-dialogues-with-state</guid>
    </item>
    <item>
      <title>SMPLer: Taming Transformers for Monocular 3D Human Shape and Pose Estimation</title>
      <link>https://paperswithcode.com/paper/smpler-taming-transformers-for-monocular-3d</link>
      <description><![CDATA[Existing Transformers for monocular 3D human shape and pose estimation typically have a quadratic computation and memory complexity with respect to the feature length, which hinders the exploitation of fine-grained information in high-resolution features that is beneficial for accurate reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smpler-taming-transformers-for-monocular-3d</guid>
    </item>
    <item>
      <title>ID-Animator: Zero-Shot Identity-Preserving Human Video Generation</title>
      <link>https://paperswithcode.com/paper/id-animator-zero-shot-identity-preserving</link>
      <description><![CDATA[Based on this pipeline, a random face reference training method is further devised to precisely capture the ID-relevant embeddings from reference images, thus improving the fidelity and generalization capacity of our model for ID-specific video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/id-animator-zero-shot-identity-preserving</guid>
    </item>
    <item>
      <title>Pillars of Grammatical Error Correction: Comprehensive Inspection Of Contemporary Approaches In The Era of Large Language Models</title>
      <link>https://paperswithcode.com/paper/pillars-of-grammatical-error-correction</link>
      <description><![CDATA[In this paper, we carry out experimental research on Grammatical Error Correction, delving into the nuances of single-model systems, comparing the efficiency of ensembling and ranking methods, and exploring the application of large language models to GEC as single-model systems, as parts of ensembles, and as ranking methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pillars-of-grammatical-error-correction</guid>
    </item>
    <item>
      <title>Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete Knowledge Graph Question Answering</title>
      <link>https://paperswithcode.com/paper/generate-on-graph-treat-llm-as-both-agent-and</link>
      <description><![CDATA[To simulate real-world scenarios and evaluate the ability of LLMs to integrate internal and external knowledge, in this paper, we propose leveraging LLMs for QA under Incomplete Knowledge Graph (IKGQA), where the given KG doesn't include all the factual triples involved in each question.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generate-on-graph-treat-llm-as-both-agent-and</guid>
    </item>
    <item>
      <title>From Matching to Generation: A Survey on Generative Information Retrieval</title>
      <link>https://paperswithcode.com/paper/from-matching-to-generation-a-survey-on</link>
      <description><![CDATA[We will summarize the advancements in GR regarding model training, document identifier, incremental learning, downstream tasks adaptation, multi-modal GR and generative recommendation, as well as progress in reliable response generation in aspects of internal knowledge memorization, external knowledge augmentation, generating response with citations and personal information assistant.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-matching-to-generation-a-survey-on</guid>
    </item>
    <item>
      <title>X-3D: Explicit 3D Structure Modeling for Point Cloud Recognition</title>
      <link>https://paperswithcode.com/paper/x-3d-explicit-3d-structure-modeling-for-point</link>
      <description><![CDATA[However, we contend that such implicit high-dimensional structure modeling approch inadequately represents the local geometric structure of point clouds due to the absence of explicit structural information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-3d-explicit-3d-structure-modeling-for-point</guid>
    </item>
    <item>
      <title>UniMERNet: A Universal Network for Real-World Mathematical Expression Recognition</title>
      <link>https://paperswithcode.com/paper/unimernet-a-universal-network-for-real-world</link>
      <description><![CDATA[This paper presents the UniMER dataset to provide the first study on Mathematical Expression Recognition (MER) towards complex real-world scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unimernet-a-universal-network-for-real-world</guid>
    </item>
    <item>
      <title>Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization</title>
      <link>https://paperswithcode.com/paper/multi-session-slam-with-differentiable-wide</link>
      <description><![CDATA[The backbone is trained end-to-end using a novel differentiable solver for wide-baseline two-view pose.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-session-slam-with-differentiable-wide</guid>
    </item>
    <item>
      <title>Metric-guided Image Reconstruction Bounds via Conformal Prediction</title>
      <link>https://paperswithcode.com/paper/metric-guided-image-reconstruction-bounds-via</link>
      <description><![CDATA[We apply our method to sparse-view CT for downstream radiotherapy planning and show 1) that metric-guided bounds have valid coverage for downstream metrics while conventional pixel-wise bounds do not and 2) anatomical differences of upper/lower bounds between metric-guided and pixel-wise methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metric-guided-image-reconstruction-bounds-via</guid>
    </item>
    <item>
      <title>CutDiffusion: A Simple, Fast, Cheap, and Strong Diffusion Extrapolation Method</title>
      <link>https://paperswithcode.com/paper/cutdiffusion-a-simple-fast-cheap-and-strong</link>
      <description><![CDATA[Transforming large pre-trained low-resolution diffusion models to cater to higher-resolution demands, i. e., diffusion extrapolation, significantly improves diffusion adaptability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cutdiffusion-a-simple-fast-cheap-and-strong</guid>
    </item>
    <item>
      <title>Taming Diffusion Probabilistic Models for Character Control</title>
      <link>https://paperswithcode.com/paper/taming-diffusion-probabilistic-models-for</link>
      <description><![CDATA[We present a novel character control framework that effectively utilizes motion diffusion probabilistic models to generate high-quality and diverse character animations, responding in real-time to a variety of dynamic user-supplied control signals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taming-diffusion-probabilistic-models-for</guid>
    </item>
    <item>
      <title>Revisiting Neural Networks for Continual Learning: An Architectural Perspective</title>
      <link>https://paperswithcode.com/paper/revisiting-neural-networks-for-continual</link>
      <description><![CDATA[This paper seeks to bridge this gap between network architecture design and CL, and to present a holistic study on the impact of network architectures on CL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-neural-networks-for-continual</guid>
    </item>
    <item>
      <title>Preserving linear invariants in ensemble filtering methods</title>
      <link>https://paperswithcode.com/paper/preserving-linear-invariants-in-ensemble</link>
      <description><![CDATA[Finally, we assess the benefits of preserving linear invariants for the ensemble Kalman filter and nonlinear ensemble filters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/preserving-linear-invariants-in-ensemble</guid>
    </item>
    <item>
      <title>Research on Robot Path Planning Based on Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/research-on-robot-path-planning-based-on</link>
      <description><![CDATA[This project has conducted experimental verification of the Visual SLAM system in a simulation environment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/research-on-robot-path-planning-based-on</guid>
    </item>
    <item>
      <title>Multi-view Disentanglement for Reinforcement Learning with Multiple Cameras</title>
      <link>https://paperswithcode.com/paper/multi-view-disentanglement-for-reinforcement</link>
      <description><![CDATA[To overcome these hardware constraints, we propose Multi-View Disentanglement (MVD), which uses multiple cameras to learn a policy that achieves zero-shot generalisation to any single camera from the training set.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-view-disentanglement-for-reinforcement</guid>
    </item>
    <item>
      <title>Integrated Gradient Correlation: a Dataset-wise Attribution Method</title>
      <link>https://paperswithcode.com/paper/integrated-gradient-correlation-a-dataset</link>
      <description><![CDATA[Attribution methods are primarily designed to study the distribution of input component contributions to individual model predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/integrated-gradient-correlation-a-dataset</guid>
    </item>
    <item>
      <title>Calc-CMU at SemEval-2024 Task 7: Pre-Calc -- Learning to Use the Calculator Improves Numeracy in Language Models</title>
      <link>https://paperswithcode.com/paper/calc-cmu-at-semeval-2024-task-7-pre-calc</link>
      <description><![CDATA[Quantitative and numerical comprehension in language is an important task in many fields like education and finance, but still remains a challenging task for language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/calc-cmu-at-semeval-2024-task-7-pre-calc</guid>
    </item>
    <item>
      <title>Mélange: Cost Efficient Large Language Model Serving by Exploiting GPU Heterogeneity</title>
      <link>https://paperswithcode.com/paper/melange-cost-efficient-large-language-model</link>
      <description><![CDATA[Within this space, we show that there is not a linear relationship between GPU cost and performance, and identify three key LLM service characteristics that significantly affect which GPU type is the most cost effective: model request size, request rate, and latency service-level objective (SLO).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/melange-cost-efficient-large-language-model</guid>
    </item>
    <item>
      <title>Graphic Design with Large Multimodal Model</title>
      <link>https://paperswithcode.com/paper/graphic-design-with-large-multimodal-model</link>
      <description><![CDATA[One existing practice is Graphic Layout Generation (GLG), which aims to layout sequential design elements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphic-design-with-large-multimodal-model</guid>
    </item>
    <item>
      <title>OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework</title>
      <link>https://paperswithcode.com/paper/openelm-an-efficient-language-model-family</link>
      <description><![CDATA[To this end, we release OpenELM, a state-of-the-art open language model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openelm-an-efficient-language-model-family</guid>
    </item>
    <item>
      <title>VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/valor-eval-holistic-coverage-and-faithfulness</link>
      <description><![CDATA[To address these issues, we introduce a multi-dimensional benchmark covering objects, attributes, and relations, with challenging images selected based on associative biases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/valor-eval-holistic-coverage-and-faithfulness</guid>
    </item>
    <item>
      <title>Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data</title>
      <link>https://paperswithcode.com/paper/preference-fine-tuning-of-llms-should</link>
      <description><![CDATA[Our main finding is that, in general, approaches that use on-policy sampling or attempt to push down the likelihood on certain responses (i. e., employ a "negative gradient") outperform offline and maximum likelihood objectives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/preference-fine-tuning-of-llms-should</guid>
    </item>
    <item>
      <title>A User-Centric Benchmark for Evaluating Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-user-centric-benchmark-for-evaluating-large</link>
      <description><![CDATA[To address this oversight, we propose benchmarking LLMs from a user perspective in both dataset construction and evaluation designs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-user-centric-benchmark-for-evaluating-large</guid>
    </item>
    <item>
      <title>CoFInAl: Enhancing Action Quality Assessment with Coarse-to-Fine Instruction Alignment</title>
      <link>https://paperswithcode.com/paper/cofinal-enhancing-action-quality-assessment</link>
      <description><![CDATA[However, this common strategy yields suboptimal results due to the inherent struggle of these backbones to capture the subtle cues essential for AQA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cofinal-enhancing-action-quality-assessment</guid>
    </item>
    <item>
      <title>Towards smallers, faster decoder-only transformers: Architectural variants and their implications</title>
      <link>https://paperswithcode.com/paper/towards-smallers-faster-decoder-only</link>
      <description><![CDATA[Research on Large Language Models (LLMs) has recently seen exponential growth, largely focused on transformer-based architectures, as introduced by [1] and further advanced by the decoder-only variations in [2].]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-smallers-faster-decoder-only</guid>
    </item>
    <item>
      <title>LVNS-RAVE: Diversified audio generation with RAVE and Latent Vector Novelty Search</title>
      <link>https://paperswithcode.com/paper/lvns-rave-diversified-audio-generation-with</link>
      <description><![CDATA[Evolutionary Algorithms and Generative Deep Learning have been two of the most powerful tools for sound generation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lvns-rave-diversified-audio-generation-with</guid>
    </item>
    <item>
      <title>MambaUIE&amp;SR: Unraveling the Ocean's Secrets with Only 2.8 FLOPs</title>
      <link>https://paperswithcode.com/paper/mambauie-sr-unraveling-the-ocean-s-secrets</link>
      <description><![CDATA[In addition, combining CNN and Transformer can effectively combine global and local information for enhancement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mambauie-sr-unraveling-the-ocean-s-secrets</guid>
    </item>
    <item>
      <title>Structure-preserving neural networks for the regularzied entropy-based closure of the Boltzmann moment system</title>
      <link>https://paperswithcode.com/paper/structure-preserving-neural-networks-for-the</link>
      <description><![CDATA[In this work, we derive and investigate a neural network-based approximation to the entropy closure method to accurately compute the solution of the multi-dimensional moment system with a low memory footprint and competitive computational time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structure-preserving-neural-networks-for-the</guid>
    </item>
    <item>
      <title>MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA based Mixture of Experts</title>
      <link>https://paperswithcode.com/paper/mixlora-enhancing-large-language-models-fine</link>
      <description><![CDATA[Unlike other LoRA based MoE methods, MixLoRA enhances model performance by utilizing independently configurable attention-layer LoRA adapters, supporting the use of LoRA and its variants for the construction of experts, and applying auxiliary load balance loss to address the imbalance problem of the router.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixlora-enhancing-large-language-models-fine</guid>
    </item>
    <item>
      <title>Self-Supervised Alignment with Mutual Information: Learning to Follow Principles without Preference Labels</title>
      <link>https://paperswithcode.com/paper/self-supervised-alignment-with-mutual</link>
      <description><![CDATA[On single-turn dialogue and summarization, a SAMI-trained mistral-7b outperforms the initial pretrained model, with win rates between 66% and 77%.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-alignment-with-mutual</guid>
    </item>
    <item>
      <title>How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study</title>
      <link>https://paperswithcode.com/paper/how-good-are-low-bit-quantized-llama3-models</link>
      <description><![CDATA[This exploration holds the potential to unveil new insights and challenges for low-bit quantization of LLaMA3 and other forthcoming LLMs, especially in addressing performance degradation problems that suffer in LLM compression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-good-are-low-bit-quantized-llama3-models</guid>
    </item>
    <item>
      <title>RingID: Rethinking Tree-Ring Watermarking for Enhanced Multi-Key Identification</title>
      <link>https://paperswithcode.com/paper/ringid-rethinking-tree-ring-watermarking-for</link>
      <description><![CDATA[We revisit Tree-Ring Watermarking, a recent diffusion model watermarking method that demonstrates great robustness to various attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ringid-rethinking-tree-ring-watermarking-for</guid>
    </item>
    <item>
      <title>SwinFuSR: an image fusion-inspired model for RGB-guided thermal image super-resolution</title>
      <link>https://paperswithcode.com/paper/swinfusr-an-image-fusion-inspired-model-for</link>
      <description><![CDATA[Thermal imaging plays a crucial role in various applications, but the inherent low resolution of commonly available infrared (IR) cameras limits its effectiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/swinfusr-an-image-fusion-inspired-model-for</guid>
    </item>
    <item>
      <title>SEED-X: Multimodal Models with Unified Multi-granularity Comprehension and Generation</title>
      <link>https://paperswithcode.com/paper/seed-x-multimodal-models-with-unified-multi</link>
      <description><![CDATA[We hope that our work will inspire future research into what can be achieved by versatile multimodal foundation models in real-world applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seed-x-multimodal-models-with-unified-multi</guid>
    </item>
  </channel>
</rss>
