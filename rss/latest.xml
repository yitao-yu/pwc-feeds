<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 15 Jul 2022 21:07:23 +0000</lastBuildDate>
    <item>
      <title>Low-Precision Arithmetic for Fast Gaussian Processes</title>
      <link>https://paperswithcode.com/paper/low-precision-arithmetic-for-fast-gaussian</link>
      <description><![CDATA[Low-precision arithmetic has had a transformative effect on the training of neural networks, reducing computation, memory and energy requirements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/low-precision-arithmetic-for-fast-gaussian</guid>
    </item>
    <item>
      <title>Recurrent Memory Transformer</title>
      <link>https://paperswithcode.com/paper/recurrent-memory-transformer</link>
      <description><![CDATA[We implement a memory mechanism with no changes to Transformer model by adding special memory tokens to the input or output sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recurrent-memory-transformer</guid>
    </item>
    <item>
      <title>Tree Structure-Aware Few-Shot Image Classification via Hierarchical Aggregation</title>
      <link>https://paperswithcode.com/paper/tree-structure-aware-few-shot-image</link>
      <description><![CDATA[To solve this problem, we present a plug-in Hierarchical Tree Structure-aware (HTS) method, which not only learns the relationship of FSL and pretext tasks, but more importantly, can adaptively select and aggregate feature representations generated by pretext tasks to maximize the performance of FSL tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tree-structure-aware-few-shot-image</guid>
    </item>
    <item>
      <title>A Personalized Zero-Shot ECG Arrhythmia Monitoring System: From Sparse Representation Based Domain Adaption to Energy Efficient Abnormal Beat Detection for Practical ECG Surveillance</title>
      <link>https://paperswithcode.com/paper/a-personalized-zero-shot-ecg-arrhythmia</link>
      <description><![CDATA[An extensive set of experiments performed on the benchmark MIT-BIH ECG dataset shows that when this domain adaptation-based training data generator is used with a simple 1-D CNN classifier, the method outperforms the prior work by a significant margin.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-personalized-zero-shot-ecg-arrhythmia</guid>
    </item>
    <item>
      <title>Multi-Level Branched Regularization for Federated Learning</title>
      <link>https://paperswithcode.com/paper/multi-level-branched-regularization-for</link>
      <description><![CDATA[A critical challenge of federated learning is data heterogeneity and imbalance across clients, which leads to inconsistency between local networks and unstable convergence of global models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-level-branched-regularization-for</guid>
    </item>
    <item>
      <title>PIAT: Physics Informed Adversarial Training for Solving Partial Differential Equations</title>
      <link>https://paperswithcode.com/paper/piat-physics-informed-adversarial-training</link>
      <description><![CDATA[In this paper, we propose the physics informed adversarial training (PIAT) of neural networks for solving nonlinear differential equations (NDE).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/piat-physics-informed-adversarial-training</guid>
    </item>
    <item>
      <title>Real-time Streaming Video Denoising with Bidirectional Buffers</title>
      <link>https://paperswithcode.com/paper/real-time-streaming-video-denoising-with</link>
      <description><![CDATA[Recent multi-output inference works propagate the bidirectional temporal feature with a parallel or recurrent framework, which either suffers from performance drops on the temporal edges of clips or can not achieve online inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-streaming-video-denoising-with</guid>
    </item>
    <item>
      <title>Adversarial Sign-Corrupted Isotonic Regression</title>
      <link>https://paperswithcode.com/paper/adversarial-sign-corrupted-isotonic</link>
      <description><![CDATA[We develop \texttt{ASCIFIT}, a three-step estimation procedure under the \texttt{ASCI} setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-sign-corrupted-isotonic</guid>
    </item>
    <item>
      <title>PASHA: Efficient HPO with Progressive Resource Allocation</title>
      <link>https://paperswithcode.com/paper/pasha-efficient-hpo-with-progressive-resource</link>
      <description><![CDATA[Hyperparameter optimization (HPO) and neural architecture search (NAS) are methods of choice to obtain the best-in-class machine learning models, but in practice they can be costly to run.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pasha-efficient-hpo-with-progressive-resource</guid>
    </item>
    <item>
      <title>Tackling Background Distraction in Video Object Segmentation</title>
      <link>https://paperswithcode.com/paper/tackling-background-distraction-in-video</link>
      <description><![CDATA[Semi-supervised video object segmentation (VOS) aims to densely track certain designated objects in videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tackling-background-distraction-in-video</guid>
    </item>
    <item>
      <title>ConCL: Concept Contrastive Learning for Dense Prediction Pre-training in Pathology Images</title>
      <link>https://paperswithcode.com/paper/concl-concept-contrastive-learning-for-dense</link>
      <description><![CDATA[We first benchmark representative SSL methods for dense prediction tasks in pathology images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/concl-concept-contrastive-learning-for-dense</guid>
    </item>
    <item>
      <title>DavarOCR: A Toolbox for OCR and Multi-Modal Document Understanding</title>
      <link>https://paperswithcode.com/paper/davarocr-a-toolbox-for-ocr-and-multi-modal</link>
      <description><![CDATA[Compared with the previous opensource OCR toolbox, DavarOCR has relatively more complete support for the sub-tasks of the cutting-edge technology of document understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/davarocr-a-toolbox-for-ocr-and-multi-modal</guid>
    </item>
    <item>
      <title>GeoSegNet: Point Cloud Semantic Segmentation via Geometric Encoder-Decoder Modeling</title>
      <link>https://paperswithcode.com/paper/geosegnet-point-cloud-semantic-segmentation</link>
      <description><![CDATA[Semantic segmentation of point clouds, aiming to assign each point a semantic category, is critical to 3D scene understanding. Despite of significant advances in recent years, most of existing methods still suffer from either the object-level misclassification or the boundary-level ambiguity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geosegnet-point-cloud-semantic-segmentation</guid>
    </item>
    <item>
      <title>Prototypical Contrast Adaptation for Domain Adaptive Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/prototypical-contrast-adaptation-for-domain</link>
      <description><![CDATA[Unsupervised Domain Adaptation (UDA) aims to adapt the model trained on the labeled source domain to an unlabeled target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prototypical-contrast-adaptation-for-domain</guid>
    </item>
    <item>
      <title>Learning Implicit Templates for Point-Based Clothed Human Modeling</title>
      <link>https://paperswithcode.com/paper/learning-implicit-templates-for-point-based</link>
      <description><![CDATA[We present FITE, a First-Implicit-Then-Explicit framework for modeling human avatars in clothing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-implicit-templates-for-point-based</guid>
    </item>
    <item>
      <title>ObjectBox: From Centers to Boxes for Anchor-Free Object Detection</title>
      <link>https://paperswithcode.com/paper/objectbox-from-centers-to-boxes-for-anchor</link>
      <description><![CDATA[We present ObjectBox, a novel single-stage anchor-free and highly generalizable object detection approach.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/objectbox-from-centers-to-boxes-for-anchor</guid>
    </item>
    <item>
      <title>Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers</title>
      <link>https://paperswithcode.com/paper/parameter-efficient-prompt-tuning-makes</link>
      <description><![CDATA[By updating only 0. 1% of the model parameters, the prompt tuning strategy can help retrieval models achieve better generalization performance than traditional methods in which all parameters are updated.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parameter-efficient-prompt-tuning-makes</guid>
    </item>
    <item>
      <title>Octuplet Loss: Make Face Recognition Robust to Image Resolution</title>
      <link>https://paperswithcode.com/paper/octuplet-loss-make-face-recognition-robust-to</link>
      <description><![CDATA[To address this problem, we propose a novel combination of the popular triplet loss to improve robustness against image resolution via fine-tuning of existing face recognition models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/octuplet-loss-make-face-recognition-robust-to</guid>
    </item>
    <item>
      <title>A Multi-Modality Ovarian Tumor Ultrasound Image Dataset for Unsupervised Cross-Domain Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/a-multi-modality-ovarian-tumor-ultrasound</link>
      <description><![CDATA[To solve this problem, we propose a Multi-Modality Ovarian Tumor Ultrasound (MMOTU) image dataset containing 1469 2d ultrasound images and 170 contrast enhanced ultrasonography (CEUS) images with pixel-wise and global-wise annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-multi-modality-ovarian-tumor-ultrasound</guid>
    </item>
    <item>
      <title>From Shapley back to Pearson: Hypothesis Testing via the Shapley Value</title>
      <link>https://paperswithcode.com/paper/from-shapley-back-to-pearson-hypothesis</link>
      <description><![CDATA[In this work, we show that Shapley-based explanation methods and conditional independence testing for feature importance are closely related.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-shapley-back-to-pearson-hypothesis</guid>
    </item>
    <item>
      <title>Refign: Align and Refine for Adaptation of Semantic Segmentation to Adverse Conditions</title>
      <link>https://paperswithcode.com/paper/refign-align-and-refine-for-adaptation-of</link>
      <description><![CDATA[Due to the scarcity of dense pixel-level semantic annotations for images recorded in adverse visual conditions, there has been a keen interest in unsupervised domain adaptation (UDA) for the semantic segmentation of such images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/refign-align-and-refine-for-adaptation-of</guid>
    </item>
    <item>
      <title>problexity -- an open-source Python library for binary classification problem complexity assessment</title>
      <link>https://paperswithcode.com/paper/problexity-an-open-source-python-library-for</link>
      <description><![CDATA[This paper describes the software module that allows for the estimation of 22 complexity measures for the Python language -- compatible with the scikit-learn programming interface -- allowing for the implementation of research using them in the most popular programming environment of the machine learning community.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/problexity-an-open-source-python-library-for</guid>
    </item>
    <item>
      <title>Egocentric Scene Understanding via Multimodal Spatial Rectifier</title>
      <link>https://paperswithcode.com/paper/egocentric-scene-understanding-via-multimodal-1</link>
      <description><![CDATA[We present a multimodal spatial rectifier that stabilizes the egocentric images to a set of reference directions, which allows learning a coherent visual representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/egocentric-scene-understanding-via-multimodal-1</guid>
    </item>
    <item>
      <title>Spatiotemporal Propagation Learning for Network-Wide Flight Delay Prediction</title>
      <link>https://paperswithcode.com/paper/spatiotemporal-propagation-learning-for</link>
      <description><![CDATA[By this means, STPN allows cross-talk of spatial and temporal factors for modeling delay propagation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatiotemporal-propagation-learning-for</guid>
    </item>
    <item>
      <title>Towards Grand Unification of Object Tracking</title>
      <link>https://paperswithcode.com/paper/towards-grand-unification-of-object-tracking</link>
      <description><![CDATA[We present a unified method, termed Unicorn, that can simultaneously solve four tracking problems (SOT, MOT, VOS, MOTS) with a single network using the same model parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-grand-unification-of-object-tracking</guid>
    </item>
    <item>
      <title>Distance Learner: Incorporating Manifold Prior to Model Training</title>
      <link>https://paperswithcode.com/paper/distance-learner-incorporating-manifold-prior</link>
      <description><![CDATA[The manifold hypothesis (real world data concentrates near low-dimensional manifolds) is suggested as the principle behind the effectiveness of machine learning algorithms in very high dimensional problems that are common in domains such as vision and speech.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distance-learner-incorporating-manifold-prior</guid>
    </item>
    <item>
      <title>Scene Text Recognition with Permuted Autoregressive Sequence Models</title>
      <link>https://paperswithcode.com/paper/scene-text-recognition-with-permuted</link>
      <description><![CDATA[Context-aware STR methods typically use internal autoregressive (AR) language models (LM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scene-text-recognition-with-permuted</guid>
    </item>
    <item>
      <title>XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model</title>
      <link>https://paperswithcode.com/paper/xmem-long-term-video-object-segmentation-with</link>
      <description><![CDATA[We present XMem, a video object segmentation architecture for long videos with unified feature memory stores inspired by the Atkinson-Shiffrin memory model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xmem-long-term-video-object-segmentation-with</guid>
    </item>
    <item>
      <title>Equivariant Hypergraph Diffusion Neural Operators</title>
      <link>https://paperswithcode.com/paper/equivariant-hypergraph-diffusion-neural</link>
      <description><![CDATA[Hypergraph neural networks (HNNs) using neural networks to encode hypergraphs provide a promising way to model higher-order relations in data and further solve relevant prediction tasks built upon such higher-order relations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/equivariant-hypergraph-diffusion-neural</guid>
    </item>
    <item>
      <title>Language Modelling with Pixels</title>
      <link>https://paperswithcode.com/paper/language-modelling-with-pixels</link>
      <description><![CDATA[Language models are defined over a finite set of inputs, which creates a vocabulary bottleneck when we attempt to scale the number of supported languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-modelling-with-pixels</guid>
    </item>
    <item>
      <title>Reinforced Path Reasoning for Counterfactual Explainable Recommendation</title>
      <link>https://paperswithcode.com/paper/reinforced-path-reasoning-for-counterfactual</link>
      <description><![CDATA[We also deploy the explanation policy to a recommendation model to enhance the recommendation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforced-path-reasoning-for-counterfactual</guid>
    </item>
    <item>
      <title>Adversarial Attacks on Monocular Pose Estimation</title>
      <link>https://paperswithcode.com/paper/adversarial-attacks-on-monocular-pose</link>
      <description><![CDATA[While studies evaluating the impact of adversarial attacks on monocular depth estimation exist, a systematic demonstration and analysis of adversarial perturbations against pose estimation are lacking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-attacks-on-monocular-pose</guid>
    </item>
    <item>
      <title>Learning to translate by learning to communicate</title>
      <link>https://paperswithcode.com/paper/learning-to-translate-by-learning-to</link>
      <description><![CDATA[We formulate and test a technique to use Emergent Communication (EC) with a pretrained multilingual model to improve on modern Unsupervised NMT systems, especially for low-resource languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-translate-by-learning-to</guid>
    </item>
    <item>
      <title>Few-Shot Specific Emitter Identification via Deep Metric Ensemble Learning</title>
      <link>https://paperswithcode.com/paper/few-shot-specific-emitter-identification-via</link>
      <description><![CDATA[Thus, we focus on few-shot SEI (FS-SEI) for aircraft identification via automatic dependent surveillance-broadcast (ADS-B) signals, and a novel FS-SEI method is proposed, based on deep metric ensemble learning (DMEL).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/few-shot-specific-emitter-identification-via</guid>
    </item>
    <item>
      <title>Dynamic Low-Resolution Distillation for Cost-Efficient End-to-End Text Spotting</title>
      <link>https://paperswithcode.com/paper/dynamic-low-resolution-distillation-for-cost</link>
      <description><![CDATA[In this paper, to address this problem, we propose a novel cost-efficient Dynamic Low-resolution Distillation (DLD) text spotting framework, which aims to infer images in different small but recognizable resolutions and achieve a better balance between accuracy and efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-low-resolution-distillation-for-cost</guid>
    </item>
    <item>
      <title>Benchmarking Omni-Vision Representation through the Lens of Visual Realms</title>
      <link>https://paperswithcode.com/paper/benchmarking-omni-vision-representation</link>
      <description><![CDATA[We benchmark ReCo and other advances in omni-vision representation studies that are different in architectures (from CNNs to transformers) and in learning paradigms (from supervised learning to self-supervised learning) on OmniBenchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-omni-vision-representation</guid>
    </item>
    <item>
      <title>Temporal Action Detection with Global Segmentation Mask Learning</title>
      <link>https://paperswithcode.com/paper/temporal-action-detection-with-global</link>
      <description><![CDATA[Existing temporal action detection (TAD) methods rely on generating an overwhelmingly large number of proposals per video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-action-detection-with-global</guid>
    </item>
    <item>
      <title>Instance Selection Mechanisms for Human-in-the-Loop Systems in Few-Shot Learning</title>
      <link>https://paperswithcode.com/paper/instance-selection-mechanisms-for-human-in</link>
      <description><![CDATA[Few-shot learning addresses this challenge and reduces data gathering and labeling costs by learning novel classes with very few labeled data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instance-selection-mechanisms-for-human-in</guid>
    </item>
    <item>
      <title>Immunofluorescence Capillary Imaging Segmentation: Cases Study</title>
      <link>https://paperswithcode.com/paper/immunofluorescence-capillary-imaging</link>
      <description><![CDATA[Our work offers a benchmark dataset for training deep learning models for capillary image segmentation and provides a potential tool for future capillary research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/immunofluorescence-capillary-imaging</guid>
    </item>
    <item>
      <title>Bootstrapped Masked Autoencoders for Vision BERT Pretraining</title>
      <link>https://paperswithcode.com/paper/bootstrapped-masked-autoencoders-for-vision</link>
      <description><![CDATA[The first design is motivated by the observation that using a pretrained MAE to extract the features as the BERT prediction target for masked tokens can achieve better pretraining performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bootstrapped-masked-autoencoders-for-vision</guid>
    </item>
    <item>
      <title>DropNet: Reducing Neural Network Complexity via Iterative Pruning</title>
      <link>https://paperswithcode.com/paper/dropnet-reducing-neural-network-complexity-1</link>
      <description><![CDATA[Modern deep neural networks require a significant amount of computing time and power to train and deploy, which limits their usage on edge devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dropnet-reducing-neural-network-complexity-1</guid>
    </item>
    <item>
      <title>BayesCap: Bayesian Identity Cap for Calibrated Uncertainty in Frozen Neural Networks</title>
      <link>https://paperswithcode.com/paper/bayescap-bayesian-identity-cap-for-calibrated</link>
      <description><![CDATA[Moreover, many of the high-performing deep learning models that are already trained and deployed are non-Bayesian in nature and do not provide uncertainty estimates.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bayescap-bayesian-identity-cap-for-calibrated</guid>
    </item>
    <item>
      <title>ReAct: Temporal Action Detection with Relational Queries</title>
      <link>https://paperswithcode.com/paper/react-temporal-action-detection-with</link>
      <description><![CDATA[Moreover, we propose two losses to facilitate and stabilize the training of action classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/react-temporal-action-detection-with</guid>
    </item>
    <item>
      <title>Structure PLP-SLAM: Efficient Sparse Mapping and Localization using Point, Line and Plane for Monocular, RGB-D and Stereo Cameras</title>
      <link>https://paperswithcode.com/paper/structure-plp-slam-efficient-sparse-mapping</link>
      <description><![CDATA[This paper demonstrates a visual SLAM system that utilizes point and line cloud for robust camera localization, simultaneously, with an embedded piece-wise planar reconstruction (PPR) module which in all provides a structural map.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structure-plp-slam-efficient-sparse-mapping</guid>
    </item>
    <item>
      <title>MultiStream: A Simple and Fast Multiple Cameras Visual Monitor and Directly Streaming</title>
      <link>https://paperswithcode.com/paper/multistream-a-simple-and-fast-multiple</link>
      <description><![CDATA[Multiple cameras can be streamed with different communication protocols or the same protocol.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multistream-a-simple-and-fast-multiple</guid>
    </item>
    <item>
      <title>CoSCL: Cooperation of Small Continual Learners is Stronger than a Big One</title>
      <link>https://paperswithcode.com/paper/coscl-cooperation-of-small-continual-learners</link>
      <description><![CDATA[Continual learning requires incremental compatibility with a sequence of tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coscl-cooperation-of-small-continual-learners</guid>
    </item>
    <item>
      <title>MRF-UNets: Searching UNet with Markov Random Fields</title>
      <link>https://paperswithcode.com/paper/mrf-unets-searching-unet-with-markov-random</link>
      <description><![CDATA[UNet [27] is widely used in semantic segmentation due to its simplicity and effectiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mrf-unets-searching-unet-with-markov-random</guid>
    </item>
    <item>
      <title>DocCoder: Generating Code by Retrieving and Reading Docs</title>
      <link>https://paperswithcode.com/paper/doccoder-generating-code-by-retrieving-and</link>
      <description><![CDATA[Inspired by this observation, we introduce DocCoder: an approach that explicitly leverages code manuals and documentation by (1) retrieving the relevant documentation given the NL intent, and (2) generating the code based on the NL intent and the retrieved documentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/doccoder-generating-code-by-retrieving-and</guid>
    </item>
    <item>
      <title>Re2G: Retrieve, Rerank, Generate</title>
      <link>https://paperswithcode.com/paper/re2g-retrieve-rerank-generate-2</link>
      <description><![CDATA[As demonstrated by GPT-3 and T5, transformers grow in capability as parameter spaces become larger and larger.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/re2g-retrieve-rerank-generate-2</guid>
    </item>
    <item>
      <title>Brick Tic-Tac-Toe: Exploring the Generalizability of AlphaZero to Novel Test Environments</title>
      <link>https://paperswithcode.com/paper/brick-tic-tac-toe-exploring-the</link>
      <description><![CDATA[Hence, current RL methods are largely not generalizable to a test environment which is conceptually similar but different from what the method has been trained on, which we term the novel test environment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/brick-tic-tac-toe-exploring-the</guid>
    </item>
  </channel>
</rss>
