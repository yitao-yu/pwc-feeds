<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 23 Jul 2024 09:14:58 +0000</lastBuildDate>
    <item>
      <title>Sparse Prior Is Not All You Need: When Differential Directionality Meets Saliency Coherence for Infrared Small Target Detection</title>
      <link>https://paperswithcode.com/paper/sparse-prior-is-not-all-you-need-when</link>
      <description><![CDATA[Infrared small target detection is crucial for the efficacy of infrared search and tracking systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparse-prior-is-not-all-you-need-when</guid>
    </item>
    <item>
      <title>MAVEN-Fact: A Large-scale Event Factuality Detection Dataset</title>
      <link>https://paperswithcode.com/paper/maven-fact-a-large-scale-event-factuality</link>
      <description><![CDATA[Thanks to the comprehensive annotations of event arguments and relations in MAVEN, MAVEN-Fact also supports some further analyses and we find that adopting event arguments and relations helps in event factuality detection for fine-tuned models but does not benefit LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maven-fact-a-large-scale-event-factuality</guid>
    </item>
    <item>
      <title>The Power of Pixels: Exploring the Potential of CNNs for Expected Goals (xG) in Football</title>
      <link>https://paperswithcode.com/paper/the-power-of-pixels-exploring-the-potential</link>
      <description><![CDATA[Expected Goals (xG) is a popular metric in football that estimates the likelihood of a shot resulting in a goal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-power-of-pixels-exploring-the-potential</guid>
    </item>
    <item>
      <title>Attention Beats Linear for Fast Implicit Neural Representation Generation</title>
      <link>https://paperswithcode.com/paper/attention-beats-linear-for-fast-implicit</link>
      <description><![CDATA[Unlike gradient-based methods, which exhibit lower efficiency in inference, the adoption of hyper-network for generating parameters in Multi-Layer Perceptrons (MLP), responsible for executing INR functions, has surfaced as a promising and efficient alternative.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-beats-linear-for-fast-implicit</guid>
    </item>
    <item>
      <title>Inverted Activations</title>
      <link>https://paperswithcode.com/paper/inverted-activations</link>
      <description><![CDATA[The scaling of neural networks with increasing data and model sizes necessitates more efficient deep learning algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inverted-activations</guid>
    </item>
    <item>
      <title>AdaCLIP: Adapting CLIP with Hybrid Learnable Prompts for Zero-Shot Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/adaclip-adapting-clip-with-hybrid-learnable</link>
      <description><![CDATA[Two types of learnable prompts are proposed: static and dynamic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaclip-adapting-clip-with-hybrid-learnable</guid>
    </item>
    <item>
      <title>Tackling Selfish Clients in Federated Learning</title>
      <link>https://paperswithcode.com/paper/tackling-selfish-clients-in-federated</link>
      <description><![CDATA[In this paper, we propose a Robust aggregation strategy for FL server to mitigate the effect of Selfishness (in short RFL-Self).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tackling-selfish-clients-in-federated</guid>
    </item>
    <item>
      <title>STAMP: Outlier-Aware Test-Time Adaptation with Stable Memory Replay</title>
      <link>https://paperswithcode.com/paper/stamp-outlier-aware-test-time-adaptation-with</link>
      <description><![CDATA[In particular, the memory bank is dynamically updated by selecting low-entropy and label-consistent samples in a class-balanced manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stamp-outlier-aware-test-time-adaptation-with</guid>
    </item>
    <item>
      <title>In-Context Learning Improves Compositional Understanding of Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/in-context-learning-improves-compositional</link>
      <description><![CDATA[Vision-Language Models (VLMs) have shown remarkable capabilities in a large number of downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/in-context-learning-improves-compositional</guid>
    </item>
    <item>
      <title>Local All-Pair Correspondence for Point Tracking</title>
      <link>https://paperswithcode.com/paper/local-all-pair-correspondence-for-point</link>
      <description><![CDATA[We introduce LocoTrack, a highly accurate and efficient model designed for the task of tracking any point (TAP) across video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/local-all-pair-correspondence-for-point</guid>
    </item>
    <item>
      <title>Open-CD: A Comprehensive Toolbox for Change Detection</title>
      <link>https://paperswithcode.com/paper/open-cd-a-comprehensive-toolbox-for-change</link>
      <description><![CDATA[We present Open-CD, a change detection toolbox that contains a rich set of change detection methods as well as related components and modules.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-cd-a-comprehensive-toolbox-for-change</guid>
    </item>
    <item>
      <title>DiffX: Guide Your Layout to Cross-Modal Generative Modeling</title>
      <link>https://paperswithcode.com/paper/diffx-guide-your-layout-to-cross-modal</link>
      <description><![CDATA[However, most diffusion models are limited to visible RGB image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffx-guide-your-layout-to-cross-modal</guid>
    </item>
    <item>
      <title>DStruct2Design: Data and Benchmarks for Data Structure Driven Generative Floor Plan Design</title>
      <link>https://paperswithcode.com/paper/dstruct2design-data-and-benchmarks-for-data</link>
      <description><![CDATA[Text conditioned generative models for images have yielded impressive results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dstruct2design-data-and-benchmarks-for-data</guid>
    </item>
    <item>
      <title>Planning behavior in a recurrent neural network that plays Sokoban</title>
      <link>https://paperswithcode.com/paper/planning-behavior-in-a-recurrent-neural</link>
      <description><![CDATA[They found that adding extra computation steps to the start of episodes at test time improves the RNN's success rate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/planning-behavior-in-a-recurrent-neural</guid>
    </item>
    <item>
      <title>Decomposition of Neural Discrete Representations for Large-Scale 3D Mapping</title>
      <link>https://paperswithcode.com/paper/decomposition-of-neural-discrete</link>
      <description><![CDATA[Learning efficient representations of local features is a key challenge in feature volume-based 3D neural mapping, especially in large-scale environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decomposition-of-neural-discrete</guid>
    </item>
    <item>
      <title>GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI</title>
      <link>https://paperswithcode.com/paper/gfe-mamba-mamba-based-ad-multi-modal</link>
      <description><![CDATA[Alzheimer's Disease (AD) is an irreversible neurodegenerative disorder that often progresses from Mild Cognitive Impairment (MCI), leading to memory loss and significantly impacting patients' lives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gfe-mamba-mamba-based-ad-multi-modal</guid>
    </item>
    <item>
      <title>AutoAD-Zero: A Training-Free Framework for Zero-Shot Audio Description</title>
      <link>https://paperswithcode.com/paper/autoad-zero-a-training-free-framework-for</link>
      <description><![CDATA[Our objective is to generate Audio Descriptions (ADs) for both movies and TV series in a training-free manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoad-zero-a-training-free-framework-for</guid>
    </item>
    <item>
      <title>Odyssey: Empowering Agents with Open-World Skills</title>
      <link>https://paperswithcode.com/paper/odyssey-empowering-agents-with-open-world</link>
      <description><![CDATA[In this work, we introduce ODYSSEY, a new framework that empowers Large Language Model (LLM)-based agents with open-world skills to explore the vast Minecraft world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/odyssey-empowering-agents-with-open-world</guid>
    </item>
    <item>
      <title>LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding</title>
      <link>https://paperswithcode.com/paper/longvideobench-a-benchmark-for-long-context</link>
      <description><![CDATA[In addition, our results indicate that model performance on the benchmark improves only when they are capable of processing more frames, positioning LongVideoBench as a valuable benchmark for evaluating future-generation long-context LMMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longvideobench-a-benchmark-for-long-context</guid>
    </item>
    <item>
      <title>Multi-Modality Co-Learning for Efficient Skeleton-based Action Recognition</title>
      <link>https://paperswithcode.com/paper/multi-modality-co-learning-for-efficient-1</link>
      <description><![CDATA[Skeleton-based action recognition has garnered significant attention due to the utilization of concise and resilient skeletons.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-modality-co-learning-for-efficient-1</guid>
    </item>
    <item>
      <title>CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning</title>
      <link>https://paperswithcode.com/paper/clip-with-generative-latent-replay-a-strong</link>
      <description><![CDATA[Through extensive experiments on different domains, we demonstrate the effectiveness of our framework in adapting to new tasks while improving zero-shot capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clip-with-generative-latent-replay-a-strong</guid>
    </item>
    <item>
      <title>Learning at a Glance: Towards Interpretable Data-limited Continual Semantic Segmentation via Semantic-Invariance Modelling</title>
      <link>https://paperswithcode.com/paper/learning-at-a-glance-towards-interpretable</link>
      <description><![CDATA[Concretely, the proposed decoupling manner includes two ways, i. e., channel-wise decoupling and spatial-level neuron-relevant semantic consistency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-at-a-glance-towards-interpretable</guid>
    </item>
    <item>
      <title>LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models</title>
      <link>https://paperswithcode.com/paper/llast-improved-end-to-end-speech-translation</link>
      <description><![CDATA[We introduces LLaST, a framework for building high-performance Large Language model based Speech-to-text Translation systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llast-improved-end-to-end-speech-translation</guid>
    </item>
    <item>
      <title>Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability</title>
      <link>https://paperswithcode.com/paper/do-large-language-models-have-compositional</link>
      <description><![CDATA[In this study, we delve into the ICL capabilities of LLMs on composite tasks, with only simple tasks as in-context examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-large-language-models-have-compositional</guid>
    </item>
    <item>
      <title>Perceptions of Linguistic Uncertainty by Language Models and Humans</title>
      <link>https://paperswithcode.com/paper/perceptions-of-linguistic-uncertainty-by</link>
      <description><![CDATA[In this paper, we investigate how language models map linguistic expressions of uncertainty to numerical responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perceptions-of-linguistic-uncertainty-by</guid>
    </item>
    <item>
      <title>Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning</title>
      <link>https://paperswithcode.com/paper/towards-latent-masked-image-modeling-for-self</link>
      <description><![CDATA[A promising yet unrealized framework is learning representations through masked reconstruction in latent space, combining the locality of MIM with the high-level targets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-latent-masked-image-modeling-for-self</guid>
    </item>
    <item>
      <title>MSSPlace: Multi-Sensor Place Recognition with Visual and Text Semantics</title>
      <link>https://paperswithcode.com/paper/mssplace-multi-sensor-place-recognition-with</link>
      <description><![CDATA[Our proposed method named MSSPlace utilizes images from multiple cameras, LiDAR point clouds, semantic segmentation masks, and text annotations to generate comprehensive place descriptors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mssplace-multi-sensor-place-recognition-with</guid>
    </item>
    <item>
      <title>Two Stacks Are Better Than One: A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives</title>
      <link>https://paperswithcode.com/paper/two-stacks-are-better-than-one-a-comparison</link>
      <description><![CDATA[We ensure that training data and model architectures are comparable, and discuss the downstream performances across 6 languages that we observe in probing and fine-tuning scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/two-stacks-are-better-than-one-a-comparison</guid>
    </item>
    <item>
      <title>Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts</title>
      <link>https://paperswithcode.com/paper/unsupervised-robust-cross-lingual-entity</link>
      <description><![CDATA[Cross-lingual entity alignment (EA) enables the integration of multiple knowledge graphs (KGs) across different languages, providing users with seamless access to diverse and comprehensive knowledge. Existing methods, mostly supervised, face challenges in obtaining labeled entity pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-robust-cross-lingual-entity</guid>
    </item>
    <item>
      <title>X-Recon: Learning-based Patient-specific High-Resolution CT Reconstruction from Orthogonal X-Ray Images</title>
      <link>https://paperswithcode.com/paper/x-recon-learning-based-patient-specific-high</link>
      <description><![CDATA[Rapid and accurate diagnosis of pneumothorax, utilizing chest X-ray and computed tomography (CT), is crucial for assisted diagnosis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-recon-learning-based-patient-specific-high</guid>
    </item>
    <item>
      <title>Visual-Semantic Decomposition and Partial Alignment for Document-based Zero-Shot Learning</title>
      <link>https://paperswithcode.com/paper/visual-semantic-decomposition-and-partial</link>
      <description><![CDATA[In this work, we propose a novel network to extract multi-view semantic concepts from documents and images and align the matching rather than entire concepts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-semantic-decomposition-and-partial</guid>
    </item>
    <item>
      <title>DriveDiTFit: Fine-tuning Diffusion Transformers for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/driveditfit-fine-tuning-diffusion</link>
      <description><![CDATA[Such datasets are expected to cover various driving scenarios with adverse weather, lighting conditions and diverse moving objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/driveditfit-fine-tuning-diffusion</guid>
    </item>
    <item>
      <title>Distance-based mutual congestion feature selection with genetic algorithm for high-dimensional medical datasets</title>
      <link>https://paperswithcode.com/paper/distance-based-mutual-congestion-feature</link>
      <description><![CDATA[One recent approach in feature selection is termed frequency-based feature selection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distance-based-mutual-congestion-feature</guid>
    </item>
    <item>
      <title>WebRPG: Automatic Web Rendering Parameters Generation for Visual Presentation</title>
      <link>https://paperswithcode.com/paper/webrpg-automatic-web-rendering-parameters</link>
      <description><![CDATA[In the era of content creation revolution propelled by advancements in generative models, the field of web design remains unexplored despite its critical role in modern digital communication.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/webrpg-automatic-web-rendering-parameters</guid>
    </item>
    <item>
      <title>Cinemo: Consistent and Controllable Image Animation with Motion Diffusion Models</title>
      <link>https://paperswithcode.com/paper/cinemo-consistent-and-controllable-image</link>
      <description><![CDATA[Diffusion models have achieved great progress in image animation due to powerful generative capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cinemo-consistent-and-controllable-image</guid>
    </item>
    <item>
      <title>Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond</title>
      <link>https://paperswithcode.com/paper/diffusion-for-out-of-distribution-detection</link>
      <description><![CDATA[To this end, we introduce: 1. the ADE-OoD benchmark, which is based on the ADE20k dataset and includes images from diverse domains with a high semantic diversity, and 2. a novel approach that uses Diffusion score matching for OoD detection (DOoD) and is robust to the increased semantic diversity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-for-out-of-distribution-detection</guid>
    </item>
    <item>
      <title>Mamba meets crack segmentation</title>
      <link>https://paperswithcode.com/paper/mamba-meets-crack-segmentation</link>
      <description><![CDATA[Second, the proposed innovative Mamba design concept, integrating Mamba with the attention mechanism, holds significant reference value for all Mamba-based computer vision models, not limited to crack segmentation networks, as investigated in this study.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mamba-meets-crack-segmentation</guid>
    </item>
    <item>
      <title>Harmonizing Flows: Leveraging normalizing flows for unsupervised and source-free MRI harmonization</title>
      <link>https://paperswithcode.com/paper/harmonizing-flows-leveraging-normalizing</link>
      <description><![CDATA[Initially, a normalizing flow network is trained to capture the distribution characteristics of the source domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/harmonizing-flows-leveraging-normalizing</guid>
    </item>
    <item>
      <title>Psychometric Alignment: Capturing Human Knowledge Distributions via Language Models</title>
      <link>https://paperswithcode.com/paper/psychometric-alignment-capturing-human</link>
      <description><![CDATA[We demonstrate that our metric can capture important variations in populations that traditional metrics, like differences in accuracy, fail to capture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/psychometric-alignment-capturing-human</guid>
    </item>
    <item>
      <title>YOLOv10 for Automated Fracture Detection in Pediatric Wrist Trauma X-rays</title>
      <link>https://paperswithcode.com/paper/yolov10-for-automated-fracture-detection-in</link>
      <description><![CDATA[Wrist fractures are highly prevalent among children and can significantly impact their daily activities, such as attending school, participating in sports, and performing basic self-care tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov10-for-automated-fracture-detection-in</guid>
    </item>
    <item>
      <title>HyperbolicLR: Epoch insensitive learning rate scheduler</title>
      <link>https://paperswithcode.com/paper/hyperboliclr-epoch-insensitive-learning-rate</link>
      <description><![CDATA[This study proposes two novel learning rate schedulers: the Hyperbolic Learning Rate Scheduler (HyperbolicLR) and the Exponential Hyperbolic Learning Rate Scheduler (ExpHyperbolicLR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyperboliclr-epoch-insensitive-learning-rate</guid>
    </item>
    <item>
      <title>SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking</title>
      <link>https://paperswithcode.com/paper/syncpkl-harnessing-llms-to-generate-synthetic</link>
      <description><![CDATA[This paper presents our approach to the Commonsense Persona Knowledge Linking (CPKL) challenge, addressing the critical need for integrating persona and commonsense knowledge in open-domain dialogue systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/syncpkl-harnessing-llms-to-generate-synthetic</guid>
    </item>
    <item>
      <title>AsyCo: An Asymmetric Dual-task Co-training Model for Partial-label Learning</title>
      <link>https://paperswithcode.com/paper/asyco-an-asymmetric-dual-task-co-training</link>
      <description><![CDATA[Specifically, the disambiguation network is trained with self-training PLL task to learn label confidence, while the auxiliary network is trained in a supervised learning paradigm to learn from the noisy pairwise similarity labels that are constructed according to the learned label confidence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asyco-an-asymmetric-dual-task-co-training</guid>
    </item>
    <item>
      <title>Prior Knowledge Integration via LLM Encoding and Pseudo Event Regulation for Video Moment Retrieval</title>
      <link>https://paperswithcode.com/paper/prior-knowledge-integration-via-llm-encoding</link>
      <description><![CDATA[Through a feasibility study, we demonstrate that LLM encoders effectively refine inter-concept relations in multimodal embeddings, even without being trained on textual embeddings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prior-knowledge-integration-via-llm-encoding</guid>
    </item>
    <item>
      <title>Proximal Policy Distillation</title>
      <link>https://paperswithcode.com/paper/proximal-policy-distillation</link>
      <description><![CDATA[We introduce Proximal Policy Distillation (PPD), a novel policy distillation method that integrates student-driven distillation and Proximal Policy Optimization (PPO) to increase sample efficiency and to leverage the additional rewards that the student policy collects during distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proximal-policy-distillation</guid>
    </item>
    <item>
      <title>TAGCOS: Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data</title>
      <link>https://paperswithcode.com/paper/tagcos-task-agnostic-gradient-clustered</link>
      <description><![CDATA[Achieving this goal poses non-trivial challenges: 1) data selection requires accurate data representations that reflect the training samples' quality, 2) considering the diverse nature of instruction datasets, and 3) ensuring the efficiency of the coreset selection algorithm for large models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tagcos-task-agnostic-gradient-clustered</guid>
    </item>
    <item>
      <title>Two eyes, Two views, and finally, One summary! Towards Multi-modal Multi-tasking Knowledge-Infused Medical Dialogue Summarization</title>
      <link>https://paperswithcode.com/paper/two-eyes-two-views-and-finally-one-summary</link>
      <description><![CDATA[We often summarize a multi-party conversation in two stages: chunking with homogeneous units and summarizing the chunks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/two-eyes-two-views-and-finally-one-summary</guid>
    </item>
    <item>
      <title>Navigation Instruction Generation with BEV Perception and Large Language Models</title>
      <link>https://paperswithcode.com/paper/navigation-instruction-generation-with-bev</link>
      <description><![CDATA[To address these challenges, we propose BEVInstructor, which incorporates Bird's Eye View (BEV) features into Multi-Modal Large Language Models (MLLMs) for instruction generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/navigation-instruction-generation-with-bev</guid>
    </item>
    <item>
      <title>Efficient Visual Transformer by Learnable Token Merging</title>
      <link>https://paperswithcode.com/paper/efficient-visual-transformer-by-learnable</link>
      <description><![CDATA[In this paper, we propose a novel and compact transformer block, Transformer with Learnable Token Merging (LTM), or LTM-Transformer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-visual-transformer-by-learnable</guid>
    </item>
    <item>
      <title>Toward Efficient Convolutional Neural Networks With Structured Ternary Patterns</title>
      <link>https://paperswithcode.com/paper/toward-efficient-convolutional-neural</link>
      <description><![CDATA[High-efficiency deep learning (DL) models are necessary not only to facilitate their use in devices with limited resources but also to improve resources required for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toward-efficient-convolutional-neural</guid>
    </item>
  </channel>
</rss>
