<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 21 Nov 2024 21:09:27 +0000</lastBuildDate>
    <item>
      <title>Intensity-Spatial Dual Masked Autoencoder for Multi-Scale Feature Learning in Chest CT Segmentation</title>
      <link>https://paperswithcode.com/paper/intensity-spatial-dual-masked-autoencoder-for</link>
      <description><![CDATA[Based on the tissue-contrast semi-masked autoencoder, a Masked AutoEncoder (MAE) branch is introduced to perform intensity masking and spatial masking operations on chest CT images for multi-scale feature learning and segmentation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intensity-spatial-dual-masked-autoencoder-for</guid>
    </item>
    <item>
      <title>Neural Internal Model Control: Learning a Robust Control Policy via Predictive Error Feedback</title>
      <link>https://paperswithcode.com/paper/neural-internal-model-control-learning-a</link>
      <description><![CDATA[In this paper, we propose a novel framework, Neural Internal Model Control, which integrates model-based control with RL-based control to enhance robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-internal-model-control-learning-a</guid>
    </item>
    <item>
      <title>VBench++: Comprehensive and Versatile Benchmark Suite for Video Generative Models</title>
      <link>https://paperswithcode.com/paper/vbench-comprehensive-and-versatile-benchmark</link>
      <description><![CDATA[Video generation has witnessed significant advancements, yet evaluating these models remains a challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vbench-comprehensive-and-versatile-benchmark</guid>
    </item>
    <item>
      <title>A Resource Efficient Fusion Network for Object Detection in Bird's-Eye View using Camera and Raw Radar Data</title>
      <link>https://paperswithcode.com/paper/a-resource-efficient-fusion-network-for</link>
      <description><![CDATA[Cameras can be used to perceive the environment around the vehicle, while affordable radar sensors are popular in autonomous driving systems as they can withstand adverse weather conditions unlike cameras.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-resource-efficient-fusion-network-for</guid>
    </item>
    <item>
      <title>Globally Correlation-Aware Hard Negative Generation</title>
      <link>https://paperswithcode.com/paper/globally-correlation-aware-hard-negative</link>
      <description><![CDATA[In this work, we propose a Globally Correlation-Aware Hard Negative Generation (GCA-HNG) framework, which first learns sample correlations from a global perspective and exploits these correlations to guide generating hardness-adaptive and diverse negatives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/globally-correlation-aware-hard-negative</guid>
    </item>
    <item>
      <title>Teaching VLMs to Localize Specific Objects from In-context Examples</title>
      <link>https://paperswithcode.com/paper/teaching-vlms-to-localize-specific-objects</link>
      <description><![CDATA[In this work, we focus on the task of few-shot personalized localization, where a model is given a small set of annotated images (in-context examples) -- each with a category label and bounding box -- and is tasked with localizing the same object type in a query image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teaching-vlms-to-localize-specific-objects</guid>
    </item>
    <item>
      <title>Multipath Mitigation Technology-integrated GNSS Direct Position Estimation Plug-in Module</title>
      <link>https://paperswithcode.com/paper/multipath-mitigation-technology-integrated</link>
      <description><![CDATA[Referred to as Multipath Mitigation Technology (MMT)-integrated DPE, it is proposed as a variant of DPE that is better suit for urban environment applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multipath-mitigation-technology-integrated</guid>
    </item>
    <item>
      <title>When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training</title>
      <link>https://paperswithcode.com/paper/when-precision-meets-position-bfloat16-breaks</link>
      <description><![CDATA[To address this, we develop AnchorAttention, a plug-and-play attention method that alleviates numerical issues caused by BFloat16, improves long-context capabilities, and speeds up training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-precision-meets-position-bfloat16-breaks</guid>
    </item>
    <item>
      <title>XMask3D: Cross-modal Mask Reasoning for Open Vocabulary 3D Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/xmask3d-cross-modal-mask-reasoning-for-open</link>
      <description><![CDATA[In our approach, we developed a mask generator based on the denoising UNet from a pre-trained diffusion model, leveraging its capability for precise textual control over dense pixel representations and enhancing the open-world adaptability of the generated masks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xmask3d-cross-modal-mask-reasoning-for-open</guid>
    </item>
    <item>
      <title>Attentive Contextual Attention for Cloud Removal</title>
      <link>https://paperswithcode.com/paper/attentive-contextual-attention-for-cloud</link>
      <description><![CDATA[By integrating the AC-Attention module into the DSen2-CR cloud removal framework, we significantly improve the model's ability to capture essential distant information, leading to more effective cloud removal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attentive-contextual-attention-for-cloud</guid>
    </item>
    <item>
      <title>A Foundation Model for Unified Urban Spatio-Temporal Flow Prediction</title>
      <link>https://paperswithcode.com/paper/a-foundation-model-for-unified-urban-spatio</link>
      <description><![CDATA[In this paper, we build UniFlow, a foundational model for general urban flow prediction that unifies both grid-based and graphbased data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-foundation-model-for-unified-urban-spatio</guid>
    </item>
    <item>
      <title>Comparative Analysis of Audio Feature Extraction for Real-Time Talking Portrait Synthesis</title>
      <link>https://paperswithcode.com/paper/comparative-analysis-of-audio-feature</link>
      <description><![CDATA[This paper examines the integration of real-time talking-head generation for interviewer training, focusing on overcoming challenges in Audio Feature Extraction (AFE), which often introduces latency and limits responsiveness in real-time applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comparative-analysis-of-audio-feature</guid>
    </item>
    <item>
      <title>Practical Compact Deep Compressed Sensing</title>
      <link>https://paperswithcode.com/paper/practical-compact-deep-compressed-sensing</link>
      <description><![CDATA[Recent years have witnessed the success of deep networks in compressed sensing (CS), which allows for a significant reduction in sampling cost and has gained growing attention since its inception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/practical-compact-deep-compressed-sensing</guid>
    </item>
    <item>
      <title>Adapting Vision Foundation Models for Robust Cloud Segmentation in Remote Sensing Images</title>
      <link>https://paperswithcode.com/paper/adapting-vision-foundation-models-for-robust</link>
      <description><![CDATA[Cloud segmentation is a critical challenge in remote sensing image interpretation, as its accuracy directly impacts the effectiveness of subsequent data processing and analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adapting-vision-foundation-models-for-robust</guid>
    </item>
    <item>
      <title>LMM-driven Semantic Image-Text Coding for Ultra Low-bitrate Learned Image Compression</title>
      <link>https://paperswithcode.com/paper/lmm-driven-semantic-image-text-coding-for</link>
      <description><![CDATA[Supported by powerful generative models, low-bitrate learned image compression (LIC) models utilizing perceptual metrics have become feasible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lmm-driven-semantic-image-text-coding-for</guid>
    </item>
    <item>
      <title>DRL-Based Optimization for AoI and Energy Consumption in C-V2X Enabled IoV</title>
      <link>https://paperswithcode.com/paper/drl-based-optimization-for-aoi-and-energy</link>
      <description><![CDATA[Therefore, this paper analyzes the effects of multi-priority queues and NOMA on AoI in the C-V2X vehicular communication system and proposes an energy consumption and AoI optimization method based on DRL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drl-based-optimization-for-aoi-and-energy</guid>
    </item>
    <item>
      <title>Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension</title>
      <link>https://paperswithcode.com/paper/video-rag-visually-aligned-retrieval</link>
      <description><![CDATA[Existing large video-language models (LVLMs) struggle to comprehend long videos correctly due to limited context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-rag-visually-aligned-retrieval</guid>
    </item>
    <item>
      <title>On the Consistency of Video Large Language Models in Temporal Comprehension</title>
      <link>https://paperswithcode.com/paper/on-the-consistency-of-video-large-language</link>
      <description><![CDATA[So we conduct a study on prediction consistency -- a key indicator for robustness and trustworthiness of temporal grounding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-consistency-of-video-large-language</guid>
    </item>
    <item>
      <title>WHALES: A Multi-agent Scheduling Dataset for Enhanced Cooperation in Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/whales-a-multi-agent-scheduling-dataset-for</link>
      <description><![CDATA[Achieving high levels of safety and reliability in autonomous driving remains a critical challenge, especially due to occlusion and limited perception ranges in standalone systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/whales-a-multi-agent-scheduling-dataset-for</guid>
    </item>
    <item>
      <title>Disentangling Memory and Reasoning Ability in Large Language Models</title>
      <link>https://paperswithcode.com/paper/disentangling-memory-and-reasoning-ability-in</link>
      <description><![CDATA[Large Language Models (LLMs) have demonstrated strong performance in handling complex tasks requiring both extensive knowledge and reasoning abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disentangling-memory-and-reasoning-ability-in</guid>
    </item>
    <item>
      <title>X as Supervision: Contending with Depth Ambiguity in Unsupervised Monocular 3D Pose Estimation</title>
      <link>https://paperswithcode.com/paper/x-as-supervision-contending-with-depth</link>
      <description><![CDATA[Recent unsupervised methods for monocular 3D pose estimation have endeavored to reduce dependence on limited annotated 3D data, but most are solely formulated in 2D space, overlooking the inherent depth ambiguity issue.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-as-supervision-contending-with-depth</guid>
    </item>
    <item>
      <title>DriveMLLM: A Benchmark for Spatial Understanding with Multimodal Large Language Models in Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/drivemllm-a-benchmark-for-spatial</link>
      <description><![CDATA[Autonomous driving requires a comprehensive understanding of 3D environments to facilitate high-level tasks such as motion prediction, planning, and mapping.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drivemllm-a-benchmark-for-spatial</guid>
    </item>
    <item>
      <title>REDUCIO! Generating 1024$\times$1024 Video within 16 Seconds using Extremely Compressed Motion Latents</title>
      <link>https://paperswithcode.com/paper/reducio-generating-1024-times-1024-video</link>
      <description><![CDATA[Commercial video generation models have exhibited realistic, high-fidelity results but are still restricted to limited access.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reducio-generating-1024-times-1024-video</guid>
    </item>
    <item>
      <title>Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework</title>
      <link>https://paperswithcode.com/paper/recall-and-refine-a-simple-but-effective</link>
      <description><![CDATA[Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled source domain to an unlabeled target domain, where novel classes - also referred to as target-private unknown classes - are present.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recall-and-refine-a-simple-but-effective</guid>
    </item>
    <item>
      <title>M3D: Dual-Stream Selective State Spaces and Depth-Driven Framework for High-Fidelity Single-View 3D Reconstruction</title>
      <link>https://paperswithcode.com/paper/m3d-dual-stream-selective-state-spaces-and</link>
      <description><![CDATA[Existing neural implicit 3D representation methods face significant difficulties in balancing the extraction of global and local features, particularly in diverse and complex environments, leading to insufficient reconstruction precision and quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/m3d-dual-stream-selective-state-spaces-and</guid>
    </item>
    <item>
      <title>Signformer is all you need: Towards Edge AI for Sign Language</title>
      <link>https://paperswithcode.com/paper/signformer-is-all-you-need-towards-edge-ai-1</link>
      <description><![CDATA[Sign language translation, especially in gloss-free paradigm, is confronting a dilemma of impracticality and unsustainability due to growing resource-intensive methodologies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/signformer-is-all-you-need-towards-edge-ai-1</guid>
    </item>
    <item>
      <title>Evaluating the Prompt Steerability of Large Language Models</title>
      <link>https://paperswithcode.com/paper/evaluating-the-prompt-steerability-of-large</link>
      <description><![CDATA[Achieving this requires first being able to evaluate the degree to which a given model is capable of reflecting various personas.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-the-prompt-steerability-of-large</guid>
    </item>
    <item>
      <title>Contourlet Refinement Gate Framework for Thermal Spectrum Distribution Regularized Infrared Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/contourlet-refinement-gate-framework-for</link>
      <description><![CDATA[In this work, we emphasize the infrared spectral distribution fidelity and propose a Contourlet refinement gate framework to restore infrared modal-specific features while preserving spectral distribution fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contourlet-refinement-gate-framework-for</guid>
    </item>
    <item>
      <title>SG-LRA: Self-Generating Automatic Scoliosis Cobb Angle Measurement with Low-Rank Approximation</title>
      <link>https://paperswithcode.com/paper/sg-lra-self-generating-automatic-scoliosis</link>
      <description><![CDATA[Automatic Cobb angle measurement from X-ray images is crucial for scoliosis screening and diagnosis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sg-lra-self-generating-automatic-scoliosis</guid>
    </item>
    <item>
      <title>Predicting User Intents and Musical Attributes from Music Discovery Conversations</title>
      <link>https://paperswithcode.com/paper/predicting-user-intents-and-musical</link>
      <description><![CDATA[Intent classification is a text understanding task that identifies user needs from input text queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/predicting-user-intents-and-musical</guid>
    </item>
    <item>
      <title>A Multimodal Approach Combining Structural and Cross-domain Textual Guidance for Weakly Supervised OCT Segmentation</title>
      <link>https://paperswithcode.com/paper/a-multimodal-approach-combining-structural</link>
      <description><![CDATA[Accurate segmentation of Optical Coherence Tomography (OCT) images is crucial for diagnosing and monitoring retinal diseases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-multimodal-approach-combining-structural</guid>
    </item>
    <item>
      <title>Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline</title>
      <link>https://paperswithcode.com/paper/interactive-medical-image-segmentation-a</link>
      <description><![CDATA[To facilitate research on foundational models in medical computer vision, we release the IMed-361M and model at https://github. com/uni-medical/IMIS-Bench.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interactive-medical-image-segmentation-a</guid>
    </item>
    <item>
      <title>Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus</title>
      <link>https://paperswithcode.com/paper/enhancing-reasoning-capabilities-of-llms-via</link>
      <description><![CDATA[Large language models (LLMs) are capable of solving a wide range of tasks, yet they have struggled with reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-reasoning-capabilities-of-llms-via</guid>
    </item>
    <item>
      <title>RedPajama: an Open Dataset for Training Large Language Models</title>
      <link>https://paperswithcode.com/paper/redpajama-an-open-dataset-for-training-large</link>
      <description><![CDATA[In addition, we release RedPajama-V2, a massive web-only dataset consisting of raw, unfiltered text data together with quality signals and metadata.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/redpajama-an-open-dataset-for-training-large</guid>
    </item>
    <item>
      <title>Human-Robot Dialogue Annotation for Multi-Modal Common Ground</title>
      <link>https://paperswithcode.com/paper/human-robot-dialogue-annotation-for-multi</link>
      <description><![CDATA[In this paper, we describe the development of symbolic representations annotated on human-robot dialogue data to make dimensions of meaning accessible to autonomous systems participating in collaborative, natural language dialogue, and to enable common ground with human partners.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/human-robot-dialogue-annotation-for-multi</guid>
    </item>
    <item>
      <title>Diffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing</title>
      <link>https://paperswithcode.com/paper/diffusion-inspired-cold-start-with-sufficient</link>
      <description><![CDATA[Redundant and extraneous cognitive states can lead to limited transfer and negative transfer effects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-inspired-cold-start-with-sufficient</guid>
    </item>
    <item>
      <title>Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification</title>
      <link>https://paperswithcode.com/paper/contrast-similarity-aware-dual-pathway-mamba</link>
      <description><![CDATA[Firstly, to obtain the dynamic similarity of each sample, we initially use temporal contrast learning module to acquire MTS representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrast-similarity-aware-dual-pathway-mamba</guid>
    </item>
    <item>
      <title>Graph as a feature: improving node classification with non-neural graph-aware logistic regression</title>
      <link>https://paperswithcode.com/paper/graph-as-a-feature-improving-node</link>
      <description><![CDATA[Graph Neural Networks (GNNs) and their message passing framework that leverages both structural and feature information, have become a standard method for solving graph-based machine learning problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-as-a-feature-improving-node</guid>
    </item>
    <item>
      <title>Barttender: An approachable &amp; interpretable way to compare medical imaging and non-imaging data</title>
      <link>https://paperswithcode.com/paper/barttender-an-approachable-interpretable-way</link>
      <description><![CDATA[To bridge this gap, we introduce Barttender, an interpretable framework that uses deep learning for the direct comparison of the utility of imaging versus non-imaging tabular data for tasks like disease prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/barttender-an-approachable-interpretable-way</guid>
    </item>
    <item>
      <title>libcll: an Extendable Python Toolkit for Complementary-Label Learning</title>
      <link>https://paperswithcode.com/paper/libcll-an-extendable-python-toolkit-for</link>
      <description><![CDATA[Complementary-label learning (CLL) is a weakly supervised learning paradigm for multiclass classification, where only complementary labels -- indicating classes an instance does not belong to -- are provided to the learning algorithm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/libcll-an-extendable-python-toolkit-for</guid>
    </item>
    <item>
      <title>Self-supervised denoising of visual field data improves detection of glaucoma progression</title>
      <link>https://paperswithcode.com/paper/self-supervised-denoising-of-visual-field</link>
      <description><![CDATA[This denoising model can be integrated into future models for visual field analysis to enhance detection of glaucoma progression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-denoising-of-visual-field</guid>
    </item>
    <item>
      <title>A data driven approach to classify descriptors based on their efficiency in translating noisy trajectories into physically-relevant information</title>
      <link>https://paperswithcode.com/paper/a-data-driven-approach-to-classify</link>
      <description><![CDATA[For example, $d_5$, initially among the weakest, becomes the most effective at resolving the system's non-local dynamical complexity after denoising.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-data-driven-approach-to-classify</guid>
    </item>
    <item>
      <title>Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction</title>
      <link>https://paperswithcode.com/paper/probing-the-capacity-of-language-model-agents</link>
      <description><![CDATA[Large language model (LLM) agents show promise in an increasing number of domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probing-the-capacity-of-language-model-agents</guid>
    </item>
    <item>
      <title>Invariant Shape Representation Learning For Image Classification</title>
      <link>https://paperswithcode.com/paper/invariant-shape-representation-learning-for</link>
      <description><![CDATA[In this paper, we introduce a novel framework that for the first time develops invariant shape representation learning (ISRL) to further strengthen the robustness of image classifiers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/invariant-shape-representation-learning-for</guid>
    </item>
    <item>
      <title>Action-Attentive Deep Reinforcement Learning for Autonomous Alignment of Beamlines</title>
      <link>https://paperswithcode.com/paper/action-attentive-deep-reinforcement-learning</link>
      <description><![CDATA[Synchrotron radiation sources play a crucial role in fields such as materials science, biology, and chemistry.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/action-attentive-deep-reinforcement-learning</guid>
    </item>
    <item>
      <title>Loss-to-Loss Prediction: Scaling Laws for All Datasets</title>
      <link>https://paperswithcode.com/paper/loss-to-loss-prediction-scaling-laws-for-all</link>
      <description><![CDATA[While scaling laws provide a reliable methodology for predicting train loss across compute scales for a single data distribution, less is known about how these predictions should change as we change the distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/loss-to-loss-prediction-scaling-laws-for-all</guid>
    </item>
    <item>
      <title>Physics-Guided Detector for SAR Airplanes</title>
      <link>https://paperswithcode.com/paper/physics-guided-detector-for-sar-airplanes</link>
      <description><![CDATA[The main contributions of PGD include the physics-guided self-supervised learning, feature enhancement, and instance perception, denoted as PGSSL, PGFE, and PGIP, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physics-guided-detector-for-sar-airplanes</guid>
    </item>
    <item>
      <title>Multi-Grained Preference Enhanced Transformer for Multi-Behavior Sequential Recommendation</title>
      <link>https://paperswithcode.com/paper/multi-grained-preference-enhanced-transformer</link>
      <description><![CDATA[Secondly, a novel multi-scale transformer architecture equipped with multi-grained user preference extraction is proposed to encode the interaction-aware sequential pattern enhanced by capturing temporal behavior-aware multi-grained preference .]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-grained-preference-enhanced-transformer</guid>
    </item>
    <item>
      <title>FGP: Feature-Gradient-Prune for Efficient Convolutional Layer Pruning</title>
      <link>https://paperswithcode.com/paper/fgp-feature-gradient-prune-for-efficient</link>
      <description><![CDATA[To reduce computational overhead while maintaining model performance, model pruning techniques have been proposed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fgp-feature-gradient-prune-for-efficient</guid>
    </item>
    <item>
      <title>UrbanDiT: A Foundation Model for Open-World Urban Spatio-Temporal Learning</title>
      <link>https://paperswithcode.com/paper/urbandit-a-foundation-model-for-open-world</link>
      <description><![CDATA[This allows the model to unify both multi-data and multi-task learning, and effectively support a wide range of spatio-temporal applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/urbandit-a-foundation-model-for-open-world</guid>
    </item>
  </channel>
</rss>
