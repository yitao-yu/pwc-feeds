<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 26 Mar 2024 09:12:34 +0000</lastBuildDate>
    <item>
      <title>Multi-Scale Texture Loss for CT denoising with GANs</title>
      <link>https://paperswithcode.com/paper/multi-scale-texture-loss-for-ct-denoising</link>
      <description><![CDATA[To grasp highly complex and non-linear textural relationships in the training process, this work presents a loss function that leverages the intrinsic multi-scale nature of the Gray-Level-Co-occurrence Matrix (GLCM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-texture-loss-for-ct-denoising</guid>
    </item>
    <item>
      <title>Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion</title>
      <link>https://paperswithcode.com/paper/generating-potent-poisons-and-backdoors-from</link>
      <description><![CDATA[As a result, we may be able to craft more potent poisons by carefully choosing the base samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-potent-poisons-and-backdoors-from</guid>
    </item>
    <item>
      <title>Graph Augmentation for Recommendation</title>
      <link>https://paperswithcode.com/paper/graph-augmentation-for-recommendation</link>
      <description><![CDATA[To address these challenges, we propose a principled framework called GraphAug.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-augmentation-for-recommendation</guid>
    </item>
    <item>
      <title>RU22Fact: Optimizing Evidence for Multilingual Explainable Fact-Checking on Russia-Ukraine Conflict</title>
      <link>https://paperswithcode.com/paper/ru22fact-optimizing-evidence-for-multilingual</link>
      <description><![CDATA[Furthermore, we construct RU22Fact, a novel multilingual explainable fact-checking dataset on the Russia-Ukraine conflict in 2022 of 16K samples, each containing real-world claims, optimized evidence, and referenced explanation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ru22fact-optimizing-evidence-for-multilingual</guid>
    </item>
    <item>
      <title>ChatGPT Incorrectness Detection in Software Reviews</title>
      <link>https://paperswithcode.com/paper/chatgpt-incorrectness-detection-in-software</link>
      <description><![CDATA[We find that they want to use ChatGPT for SE tasks like software library selection but often worry about the truthfulness of ChatGPT responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatgpt-incorrectness-detection-in-software</guid>
    </item>
    <item>
      <title>DOCTR: Disentangled Object-Centric Transformer for Point Scene Understanding</title>
      <link>https://paperswithcode.com/paper/doctr-disentangled-object-centric-transformer</link>
      <description><![CDATA[In this work, we propose a novel Disentangled Object-Centric TRansformer (DOCTR) that explores object-centric representation to facilitate learning with multiple objects for the multiple sub-tasks in a unified manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/doctr-disentangled-object-centric-transformer</guid>
    </item>
    <item>
      <title>Residual Dense Swin Transformer for Continuous Depth-Independent Ultrasound Imaging</title>
      <link>https://paperswithcode.com/paper/residual-dense-swin-transformer-for</link>
      <description><![CDATA[Ultrasound imaging is crucial for evaluating organ morphology and function, yet depth adjustment can degrade image quality and field-of-view, presenting a depth-dependent dilemma.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/residual-dense-swin-transformer-for</guid>
    </item>
    <item>
      <title>RCBEVDet: Radar-camera Fusion in Bird's Eye View for 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/rcbevdet-radar-camera-fusion-in-bird-s-eye</link>
      <description><![CDATA[In the dual-stream radar backbone, a point-based encoder and a transformer-based encoder are proposed to extract radar features, with an injection and extraction module to facilitate communication between the two encoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rcbevdet-radar-camera-fusion-in-bird-s-eye</guid>
    </item>
    <item>
      <title>Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion</title>
      <link>https://paperswithcode.com/paper/text-if-leveraging-semantic-text-guidance-for</link>
      <description><![CDATA[Through the text semantic encoder and semantic interaction fusion decoder, Text-IF is accessible to the all-in-one infrared and visible image degradation-aware processing and the interactive flexible fusion outcomes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-if-leveraging-semantic-text-guidance-for</guid>
    </item>
    <item>
      <title>NSINA: A News Corpus for Sinhala</title>
      <link>https://paperswithcode.com/paper/nsina-a-news-corpus-for-sinhala</link>
      <description><![CDATA[NSINA is the largest news corpus for Sinhala, available up to date.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nsina-a-news-corpus-for-sinhala</guid>
    </item>
    <item>
      <title>Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning</title>
      <link>https://paperswithcode.com/paper/efficient-information-extraction-in-few-shot</link>
      <description><![CDATA[In this paper, we introduce a novel approach to enhance information extraction combining multiple sentence representations and contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-information-extraction-in-few-shot</guid>
    </item>
    <item>
      <title>VMRNN: Integrating Vision Mamba and LSTM for Efficient and Accurate Spatiotemporal Forecasting</title>
      <link>https://paperswithcode.com/paper/vmrnn-integrating-vision-mamba-and-lstm-for</link>
      <description><![CDATA[Combining CNNs or ViTs, with RNNs for spatiotemporal forecasting, has yielded unparalleled results in predicting temporal and spatial dynamics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vmrnn-integrating-vision-mamba-and-lstm-for</guid>
    </item>
    <item>
      <title>ModeTv2: GPU-accelerated Motion Decomposition Transformer for Pairwise Optimization in Medical Image Registration</title>
      <link>https://paperswithcode.com/paper/modetv2-gpu-accelerated-motion-decomposition</link>
      <description><![CDATA[Deformable image registration plays a crucial role in medical imaging, aiding in disease diagnosis and image-guided interventions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/modetv2-gpu-accelerated-motion-decomposition</guid>
    </item>
    <item>
      <title>ToXCL: A Unified Framework for Toxic Speech Detection and Explanation</title>
      <link>https://paperswithcode.com/paper/toxcl-a-unified-framework-for-toxic-speech</link>
      <description><![CDATA[This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toxcl-a-unified-framework-for-toxic-speech</guid>
    </item>
    <item>
      <title>Camera-aware Label Refinement for Unsupervised Person Re-identification</title>
      <link>https://paperswithcode.com/paper/camera-aware-label-refinement-for</link>
      <description><![CDATA[Unsupervised person re-identification aims to retrieve images of a specified person without identity labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camera-aware-label-refinement-for</guid>
    </item>
    <item>
      <title>If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions</title>
      <link>https://paperswithcode.com/paper/if-clip-could-talk-understanding-vision</link>
      <description><![CDATA[EX2 uses reinforcement learning to align a large language model with VLM preferences and generates descriptions that incorporate the important features for the VLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/if-clip-could-talk-understanding-vision</guid>
    </item>
    <item>
      <title>Elysium: Exploring Object-level Perception in Videos via MLLM</title>
      <link>https://paperswithcode.com/paper/elysium-exploring-object-level-perception-in</link>
      <description><![CDATA[To address the first challenge, we introduce ElysiumTrack-1M, a large-scale video dataset paired with novel tasks: Referring Single Object Tracking (RSOT) and Video Referring Expression Generation (Video-REG).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elysium-exploring-object-level-perception-in</guid>
    </item>
    <item>
      <title>CodeS: Natural Language to Code Repository via Multi-Layer Sketch</title>
      <link>https://paperswithcode.com/paper/codes-natural-language-to-code-repository-via</link>
      <description><![CDATA[For feedback-based evaluation, we develop a VSCode plugin for CodeS and engage 30 participants in conducting empirical studies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codes-natural-language-to-code-repository-via</guid>
    </item>
    <item>
      <title>PE: A Poincare Explanation Method for Fast Text Hierarchy Generation</title>
      <link>https://paperswithcode.com/paper/pe-a-poincare-explanation-method-for-fast</link>
      <description><![CDATA[The black-box nature of deep learning models in NLP hinders their widespread application.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pe-a-poincare-explanation-method-for-fast</guid>
    </item>
    <item>
      <title>Proprioception Is All You Need: Terrain Classification for Boreal Forests</title>
      <link>https://paperswithcode.com/paper/proprioception-is-all-you-need-terrain</link>
      <description><![CDATA[We show that the combination of two TC datasets yields a latent space that can be interpreted with the properties of the terrains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proprioception-is-all-you-need-terrain</guid>
    </item>
    <item>
      <title>QKFormer: Hierarchical Spiking Transformer using Q-K Attention</title>
      <link>https://paperswithcode.com/paper/qkformer-hierarchical-spiking-transformer</link>
      <description><![CDATA[ii) We incorporate the hierarchical structure, which significantly benefits the performance of both the brain and artificial neural networks, into spiking transformers to obtain multi-scale spiking representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qkformer-hierarchical-spiking-transformer</guid>
    </item>
    <item>
      <title>Producing and Leveraging Online Map Uncertainty in Trajectory Prediction</title>
      <link>https://paperswithcode.com/paper/producing-and-leveraging-online-map</link>
      <description><![CDATA[High-definition (HD) maps have played an integral role in the development of modern autonomous vehicle (AV) stacks, albeit with high associated labeling and maintenance costs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/producing-and-leveraging-online-map</guid>
    </item>
    <item>
      <title>DeepGleason: a System for Automated Gleason Grading of Prostate Cancer using Deep Neural Networks</title>
      <link>https://paperswithcode.com/paper/deepgleason-a-system-for-automated-gleason</link>
      <description><![CDATA[Our tool contributes to the wider adoption of AI-based Gleason grading within the research community and paves the way for broader clinical application of deep learning models in digital pathology.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepgleason-a-system-for-automated-gleason</guid>
    </item>
    <item>
      <title>Domain Adaptive Detection of MAVs: A Benchmark and Noise Suppression Network</title>
      <link>https://paperswithcode.com/paper/domain-adaptive-detection-of-mavs-a-benchmark</link>
      <description><![CDATA[A new benchmark for cross-domain MAV detection is proposed based on the proposed dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-adaptive-detection-of-mavs-a-benchmark</guid>
    </item>
    <item>
      <title>3D-EffiViTCaps: 3D Efficient Vision Transformer with Capsule for Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/3d-effivitcaps-3d-efficient-vision</link>
      <description><![CDATA[Our encoder uses capsule blocks and EfficientViT blocks to jointly capture local and global semantic information more effectively and efficiently with less information loss, while the decoder employs CNN blocks and EfficientViT blocks to catch ffner details for segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-effivitcaps-3d-efficient-vision</guid>
    </item>
    <item>
      <title>Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework</title>
      <link>https://paperswithcode.com/paper/make-your-anchor-a-diffusion-based-2d-avatar</link>
      <description><![CDATA[We adopt a two-stage training strategy for the diffusion model, effectively binding movements with specific appearances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/make-your-anchor-a-diffusion-based-2d-avatar</guid>
    </item>
    <item>
      <title>SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions</title>
      <link>https://paperswithcode.com/paper/sdxs-real-time-one-step-latent-diffusion</link>
      <description><![CDATA[Recent advancements in diffusion models have positioned them at the forefront of image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdxs-real-time-one-step-latent-diffusion</guid>
    </item>
    <item>
      <title>CT-Bound: Fast Boundary Estimation From Noisy Images Via Hybrid Convolution and Transformer Neural Networks</title>
      <link>https://paperswithcode.com/paper/ct-bound-fast-boundary-estimation-from-noisy</link>
      <description><![CDATA[We present CT-Bound, a fast boundary estimation method for noisy images using a hybrid Convolution and Transformer neural network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ct-bound-fast-boundary-estimation-from-noisy</guid>
    </item>
    <item>
      <title>Multiple Object Tracking as ID Prediction</title>
      <link>https://paperswithcode.com/paper/multiple-object-tracking-as-id-prediction</link>
      <description><![CDATA[In Multiple Object Tracking (MOT), tracking-by-detection methods have stood the test for a long time, which split the process into two parts according to the definition: object detection and association.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiple-object-tracking-as-id-prediction</guid>
    </item>
    <item>
      <title>SDSTrack: Self-Distillation Symmetric Adapter Learning for Multi-Modal Visual Object Tracking</title>
      <link>https://paperswithcode.com/paper/sdstrack-self-distillation-symmetric-adapter</link>
      <description><![CDATA[Multimodal Visual Object Tracking (VOT) has recently gained significant attention due to its robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdstrack-self-distillation-symmetric-adapter</guid>
    </item>
    <item>
      <title>CFAT: Unleashing TriangularWindows for Image Super-resolution</title>
      <link>https://paperswithcode.com/paper/cfat-unleashing-triangularwindows-for-image</link>
      <description><![CDATA[To overcome these weaknesses, we propose a non-overlapping triangular window technique that synchronously works with the rectangular one to mitigate boundary-level distortion and allows the model to access more unique sifting modes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cfat-unleashing-triangularwindows-for-image</guid>
    </item>
    <item>
      <title>A Transformer approach for Electricity Price Forecasting</title>
      <link>https://paperswithcode.com/paper/a-transformer-approach-for-electricity-price</link>
      <description><![CDATA[This paper presents a novel approach to electricity price forecasting (EPF) using a pure Transformer model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-transformer-approach-for-electricity-price</guid>
    </item>
    <item>
      <title>LexDrafter: Terminology Drafting for Legislative Documents using Retrieval Augmented Generation</title>
      <link>https://paperswithcode.com/paper/lexdrafter-terminology-drafting-for</link>
      <description><![CDATA[With the increase in legislative documents at the EU, the number of new terms and their definitions is increasing as well.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lexdrafter-terminology-drafting-for</guid>
    </item>
    <item>
      <title>A Survey on Self-Supervised Pre-Training of Graph Foundation Models: A Knowledge-Based Perspective</title>
      <link>https://paperswithcode.com/paper/a-survey-on-self-supervised-pre-training-of</link>
      <description><![CDATA[Graph self-supervised learning is now a go-to method for pre-training graph foundation models, including graph neural networks, graph transformers, and more recent large language model (LLM)-based graph models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-self-supervised-pre-training-of</guid>
    </item>
    <item>
      <title>An early warning indicator trained on stochastic disease-spreading models with different noises</title>
      <link>https://paperswithcode.com/paper/an-early-warning-indicator-trained-on</link>
      <description><![CDATA[The timely detection of disease outbreaks through reliable early warning signals (EWSs) is indispensable for effective public health mitigation strategies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-early-warning-indicator-trained-on</guid>
    </item>
    <item>
      <title>Pose-Guided Self-Training with Two-Stage Clustering for Unsupervised Landmark Discovery</title>
      <link>https://paperswithcode.com/paper/pose-guided-self-training-with-two-stage</link>
      <description><![CDATA[Second, motivated by the ZeroShot performance, we develop a ULD algorithm based on diffusion features using self-training and clustering which also outperforms prior methods by notable margins.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pose-guided-self-training-with-two-stage</guid>
    </item>
    <item>
      <title>Salience DETR: Enhancing Detection Transformer with Hierarchical Salience Filtering Refinement</title>
      <link>https://paperswithcode.com/paper/salience-detr-enhancing-detection-transformer-1</link>
      <description><![CDATA[DETR-like methods have significantly increased detection performance in an end-to-end manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/salience-detr-enhancing-detection-transformer-1</guid>
    </item>
    <item>
      <title>EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World</title>
      <link>https://paperswithcode.com/paper/egoexolearn-a-dataset-for-bridging</link>
      <description><![CDATA[Along with the videos we record high-quality gaze data and provide detailed multimodal annotations, formulating a playground for modeling the human ability to bridge asynchronous procedural actions from different viewpoints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/egoexolearn-a-dataset-for-bridging</guid>
    </item>
    <item>
      <title>An Analytic Solution to Covariance Propagation in Neural Networks</title>
      <link>https://paperswithcode.com/paper/an-analytic-solution-to-covariance</link>
      <description><![CDATA[Uncertainty quantification of neural networks is critical to measuring the reliability and robustness of deep learning systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-analytic-solution-to-covariance</guid>
    </item>
    <item>
      <title>Segment Anything Model for Road Network Graph Extraction</title>
      <link>https://paperswithcode.com/paper/segment-anything-model-for-road-network-graph</link>
      <description><![CDATA[We propose SAM-Road, an adaptation of the Segment Anything Model (SAM) for extracting large-scale, vectorized road network graphs from satellite imagery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-anything-model-for-road-network-graph</guid>
    </item>
    <item>
      <title>CBGT-Net: A Neuromimetic Architecture for Robust Classification of Streaming Data</title>
      <link>https://paperswithcode.com/paper/cbgt-net-a-neuromimetic-architecture-for</link>
      <description><![CDATA[This paper describes CBGT-Net, a neural network model inspired by the cortico-basal ganglia-thalamic (CBGT) circuits found in mammalian brains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cbgt-net-a-neuromimetic-architecture-for</guid>
    </item>
    <item>
      <title>Mixed-Initiative Human-Robot Teaming under Suboptimality with Online Bayesian Adaptation</title>
      <link>https://paperswithcode.com/paper/mixed-initiative-human-robot-teaming-under</link>
      <description><![CDATA[For effective human-agent teaming, robots and other artificial intelligence (AI) agents must infer their human partner's abilities and behavioral response patterns and adapt accordingly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixed-initiative-human-robot-teaming-under</guid>
    </item>
    <item>
      <title>Knowledge-aware Dual-side Attribute-enhanced Recommendation</title>
      <link>https://paperswithcode.com/paper/knowledge-aware-dual-side-attribute-enhanced</link>
      <description><![CDATA[Specifically, we build \textit{user preference representations} and \textit{attribute fusion representations} upon the attribute information in knowledge graphs, which are utilized to enhance \textit{collaborative filtering} (CF) based user and item representations, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/knowledge-aware-dual-side-attribute-enhanced</guid>
    </item>
    <item>
      <title>A Survey on Consumer IoT Traffic: Security and Privacy</title>
      <link>https://paperswithcode.com/paper/a-survey-on-consumer-iot-traffic-security-and</link>
      <description><![CDATA[From the security and privacy perspective, this survey seeks out the new characteristics in CIoT traffic analysis, the state-of-the-art progress in CIoT traffic analysis, and the challenges yet to be solved.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-consumer-iot-traffic-security-and</guid>
    </item>
    <item>
      <title>PKU-DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling</title>
      <link>https://paperswithcode.com/paper/pku-dymvhumans-a-multi-view-video-benchmark</link>
      <description><![CDATA[To facilitate the development of these fields, in this paper, we present PKU-DyMVHumans, a versatile human-centric dataset for high-fidelity reconstruction and rendering of dynamic human scenarios from dense multi-view videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pku-dymvhumans-a-multi-view-video-benchmark</guid>
    </item>
    <item>
      <title>A Multi-Label Dataset of French Fake News: Human and Machine Insights</title>
      <link>https://paperswithcode.com/paper/a-multi-label-dataset-of-french-fake-news</link>
      <description><![CDATA[We present a corpus of 100 documents, OBSINFOX, selected from 17 sources of French press considered unreliable by expert agencies, annotated using 11 labels by 8 annotators.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-multi-label-dataset-of-french-fake-news</guid>
    </item>
    <item>
      <title>Systematic construction of continuous-time neural networks for linear dynamical systems</title>
      <link>https://paperswithcode.com/paper/systematic-construction-of-continuous-time</link>
      <description><![CDATA[Discovering a suitable neural network architecture for modeling complex dynamical systems poses a formidable challenge, often involving extensive trial and error and navigation through a high-dimensional hyper-parameter space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/systematic-construction-of-continuous-time</guid>
    </item>
    <item>
      <title>SAT Encoding of Partial Ordering Models for Graph Coloring Problems</title>
      <link>https://paperswithcode.com/paper/sat-encoding-of-partial-ordering-models-for</link>
      <description><![CDATA[For the widely studied GCP, we experimentally compare our new SAT encoding to the state-of-the-art approaches on the DIMACS benchmark set.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sat-encoding-of-partial-ordering-models-for</guid>
    </item>
    <item>
      <title>PNAS-MOT: Multi-Modal Object Tracking with Pareto Neural Architecture Search</title>
      <link>https://paperswithcode.com/paper/pnas-mot-multi-modal-object-tracking-with</link>
      <description><![CDATA[Multiple object tracking is a critical task in autonomous driving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pnas-mot-multi-modal-object-tracking-with</guid>
    </item>
    <item>
      <title>Space Group Informed Transformer for Crystalline Materials Generation</title>
      <link>https://paperswithcode.com/paper/space-group-informed-transformer-for</link>
      <description><![CDATA[We introduce CrystalFormer, a transformer-based autoregressive model specifically designed for space group-controlled generation of crystalline materials.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/space-group-informed-transformer-for</guid>
    </item>
  </channel>
</rss>
