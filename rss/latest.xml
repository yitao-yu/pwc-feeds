<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 05 Jul 2024 21:08:06 +0000</lastBuildDate>
    <item>
      <title>ECG signal processing and feature extraction to validate feature significance for arrythmia detection</title>
      <link>https://paperswithcode.com/paper/ecg-signal-processing-and-feature-extraction</link>
      <description><![CDATA[Arrhythmias, such as tachycardia and bradycardia, are prevalent in postoperative patients, especially within the first week after surgery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ecg-signal-processing-and-feature-extraction</guid>
    </item>
    <item>
      <title>A cross-sectional study to analyse the presence of low back pain in university students and its relationship with coffee</title>
      <link>https://paperswithcode.com/paper/a-cross-sectional-study-to-analyse-the</link>
      <description><![CDATA[This study aims to analyze electromyography (EMG) signals of the multifidus muscles using the BiTalino device to assess chronic LBP in university students.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-cross-sectional-study-to-analyse-the</guid>
    </item>
    <item>
      <title>Evaluating Automatic Metrics with Incremental Machine Translation Systems</title>
      <link>https://paperswithcode.com/paper/evaluating-automatic-metrics-with-incremental</link>
      <description><![CDATA[We introduce a dataset comprising commercial machine translations, gathered weekly over six years across 12 translation directions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-automatic-metrics-with-incremental</guid>
    </item>
    <item>
      <title>Translatotron-V(ison): An End-to-End Model for In-Image Machine Translation</title>
      <link>https://paperswithcode.com/paper/translatotron-v-ison-an-end-to-end-model-for</link>
      <description><![CDATA[Among them, the target text decoder is used to alleviate the language alignment burden, and the image tokenizer converts long sequences of pixels into shorter sequences of visual tokens, preventing the model from focusing on low-level visual features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/translatotron-v-ison-an-end-to-end-model-for</guid>
    </item>
    <item>
      <title>PosMLP-Video: Spatial and Temporal Relative Position Encoding for Efficient Video Recognition</title>
      <link>https://paperswithcode.com/paper/posmlp-video-spatial-and-temporal-relative</link>
      <description><![CDATA[In recent years, vision Transformers and MLPs have demonstrated remarkable performance in image understanding tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posmlp-video-spatial-and-temporal-relative</guid>
    </item>
    <item>
      <title>Emotion and Intent Joint Understanding in Multimodal Conversation: A Benchmarking Dataset</title>
      <link>https://paperswithcode.com/paper/emotion-and-intent-joint-understanding-in</link>
      <description><![CDATA[Together with the release of the dataset, we also develop an Emotion and Intent Interaction (EI$^2$) network as a reference system by modeling the deep correlation between emotion and intent in the multimodal conversation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emotion-and-intent-joint-understanding-in</guid>
    </item>
    <item>
      <title>Global Context Modeling in YOLOv8 for Pediatric Wrist Fracture Detection</title>
      <link>https://paperswithcode.com/paper/global-context-modeling-in-yolov8-for</link>
      <description><![CDATA[Children often suffer wrist injuries in daily life, while fracture injuring radiologists usually need to analyze and interpret X-ray images before surgical treatment by surgeons.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/global-context-modeling-in-yolov8-for</guid>
    </item>
    <item>
      <title>A Framework for Quantum Finite-State Languages with Density Mapping</title>
      <link>https://paperswithcode.com/paper/a-framework-for-quantum-finite-state</link>
      <description><![CDATA[We present a framework that provides a simple and intuitive way to build QFAs and maximize the simulation accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-framework-for-quantum-finite-state</guid>
    </item>
    <item>
      <title>IM-MoCo: Self-supervised MRI Motion Correction using Motion-Guided Implicit Neural Representations</title>
      <link>https://paperswithcode.com/paper/im-moco-self-supervised-mri-motion-correction</link>
      <description><![CDATA[Motion artifacts in Magnetic Resonance Imaging (MRI) arise due to relatively long acquisition times and can compromise the clinical utility of acquired images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/im-moco-self-supervised-mri-motion-correction</guid>
    </item>
    <item>
      <title>CoIR: A Comprehensive Benchmark for Code Information Retrieval Models</title>
      <link>https://paperswithcode.com/paper/coir-a-comprehensive-benchmark-for-code</link>
      <description><![CDATA[Despite the substantial success of Information Retrieval (IR) in various NLP tasks, most IR systems predominantly handle queries and corpora in natural language, neglecting the domain of code retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coir-a-comprehensive-benchmark-for-code</guid>
    </item>
    <item>
      <title>Knowledge Composition using Task Vectors with Learned Anisotropic Scaling</title>
      <link>https://paperswithcode.com/paper/knowledge-composition-using-task-vectors-with</link>
      <description><![CDATA[In particular, we show that (1) learned anisotropic scaling allows task vectors to be more disentangled, causing less interference in composition; (2) task vector composition excels with scarce or no labeled data and is less prone to domain shift, thus leading to better generalisability; (3) mixing the most informative parameter blocks across different task vectors prior to training can reduce the memory footprint and improve the flexibility of knowledge transfer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/knowledge-composition-using-task-vectors-with</guid>
    </item>
    <item>
      <title>Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages</title>
      <link>https://paperswithcode.com/paper/planetarium-a-rigorous-benchmark-for</link>
      <description><![CDATA[To bridge this gap, we introduce \benchmarkName, a benchmark designed to evaluate language models' ability to generate PDDL code from natural language descriptions of planning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/planetarium-a-rigorous-benchmark-for</guid>
    </item>
    <item>
      <title>Data Overfitting for On-Device Super-Resolution with Dynamic Algorithm and Compiler Co-Design</title>
      <link>https://paperswithcode.com/paper/data-overfitting-for-on-device-super</link>
      <description><![CDATA[By splitting videos into chunks and applying a super-resolution (SR) model to overfit each chunk, this scheme of SR models plus video chunks is able to replace traditional video transmission to enhance video quality and transmission efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-overfitting-for-on-device-super</guid>
    </item>
    <item>
      <title>Investigating the Contextualised Word Embedding Dimensions Responsible for Contextual and Temporal Semantic Changes</title>
      <link>https://paperswithcode.com/paper/investigating-the-contextualised-word</link>
      <description><![CDATA[Despite the superior performance of SCWEs in contextual/temporal semantic change detection (SCD) benchmarks, it remains unclear as to how the meaning changes are encoded in the embedding space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/investigating-the-contextualised-word</guid>
    </item>
    <item>
      <title>DyFADet: Dynamic Feature Aggregation for Temporal Action Detection</title>
      <link>https://paperswithcode.com/paper/dyfadet-dynamic-feature-aggregation-for</link>
      <description><![CDATA[Based on DFA, the proposed dynamic encoder layer aggregates the temporal features within the action time ranges and guarantees the discriminability of the extracted representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dyfadet-dynamic-feature-aggregation-for</guid>
    </item>
    <item>
      <title>TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts</title>
      <link>https://paperswithcode.com/paper/theoremllama-transforming-general-purpose</link>
      <description><![CDATA[This scarcity results in a paucity of methodologies for training LLMs and techniques to fully utilize their capabilities in composing formal proofs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/theoremllama-transforming-general-purpose</guid>
    </item>
    <item>
      <title>GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models</title>
      <link>https://paperswithcode.com/paper/gracore-benchmarking-graph-comprehension-and</link>
      <description><![CDATA[Evaluating the graph comprehension and reasoning abilities of Large Language Models (LLMs) is challenging and often incomplete.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gracore-benchmarking-graph-comprehension-and</guid>
    </item>
    <item>
      <title>Self-supervised Vision Transformer are Scalable Generative Models for Domain Generalization</title>
      <link>https://paperswithcode.com/paper/self-supervised-vision-transformer-are</link>
      <description><![CDATA[To this end, we propose a novel generative method for domain generalization in histopathology images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-vision-transformer-are</guid>
    </item>
    <item>
      <title>Context-Aware Video Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/context-aware-video-instance-segmentation</link>
      <description><![CDATA[In this paper, we introduce the Context-Aware Video Instance Segmentation (CAVIS), a novel framework designed to enhance instance association by integrating contextual information adjacent to each object.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-aware-video-instance-segmentation</guid>
    </item>
    <item>
      <title>3D Multimodal Image Registration for Plant Phenotyping</title>
      <link>https://paperswithcode.com/paper/3d-multimodal-image-registration-for-plant</link>
      <description><![CDATA[By leveraging depth data, our method mitigates parallax effects and thus facilitates more accurate pixel alignment across camera modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-multimodal-image-registration-for-plant</guid>
    </item>
    <item>
      <title>Consistent Point Orientation for Manifold Surfaces via Boundary Integration</title>
      <link>https://paperswithcode.com/paper/consistent-point-orientation-for-manifold</link>
      <description><![CDATA[This paper introduces a new approach for generating globally consistent normals for point clouds sampled from manifold surfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/consistent-point-orientation-for-manifold</guid>
    </item>
    <item>
      <title>Complex Event Recognition with Symbolic Register Transducers: Extended Technical Report</title>
      <link>https://paperswithcode.com/paper/complex-event-recognition-with-symbolic</link>
      <description><![CDATA[In order to address this issue, our system is based on an automaton model which is a combination of symbolic and register automata.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/complex-event-recognition-with-symbolic</guid>
    </item>
    <item>
      <title>Fine-Grained Scene Image Classification with Modality-Agnostic Adapter</title>
      <link>https://paperswithcode.com/paper/fine-grained-scene-image-classification-with</link>
      <description><![CDATA[In this paper, we present a new multi-modal feature fusion approach named MAA (Modality-Agnostic Adapter), trying to make the model learn the importance of different modalities in different cases adaptively, without giving a prior setting in the model architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-grained-scene-image-classification-with</guid>
    </item>
    <item>
      <title>Revisiting the Performance of Deep Learning-Based Vulnerability Detection on Realistic Datasets</title>
      <link>https://paperswithcode.com/paper/revisiting-the-performance-of-deep-learning</link>
      <description><![CDATA[Despite deep learning models being proposed for vulnerability detection, their reliability is questionable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-the-performance-of-deep-learning</guid>
    </item>
    <item>
      <title>Towards a Scalable Reference-Free Evaluation of Generative Models</title>
      <link>https://paperswithcode.com/paper/towards-a-scalable-reference-free-evaluation</link>
      <description><![CDATA[While standard evaluation scores for generative models are mostly reference-based, a reference-dependent assessment of generative models could be generally difficult due to the unavailability of applicable reference datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-a-scalable-reference-free-evaluation</guid>
    </item>
    <item>
      <title>SegVG: Transferring Object Bounding Box to Segmentation for Visual Grounding</title>
      <link>https://paperswithcode.com/paper/segvg-transferring-object-bounding-box-to</link>
      <description><![CDATA[Specifically, we propose the Multi-layer Multi-task Encoder-Decoder as the target grounding stage, where we learn a regression query and multiple segmentation queries to ground the target by regression and segmentation of the box in each decoding layer, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segvg-transferring-object-bounding-box-to</guid>
    </item>
    <item>
      <title>Human-like Linguistic Biases in Neural Speech Models: Phonetic Categorization and Phonotactic Constraints in Wav2Vec2.0</title>
      <link>https://paperswithcode.com/paper/human-like-linguistic-biases-in-neural-speech</link>
      <description><![CDATA[What do deep neural speech models know about phonology?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/human-like-linguistic-biases-in-neural-speech</guid>
    </item>
    <item>
      <title>MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context</title>
      <link>https://paperswithcode.com/paper/medvh-towards-systematic-evaluation-of</link>
      <description><![CDATA[Large Vision Language Models (LVLMs) have recently achieved superior performance in various tasks on natural image and text data, which inspires a large amount of studies for LVLMs fine-tuning and training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medvh-towards-systematic-evaluation-of</guid>
    </item>
    <item>
      <title>Value-Penalized Auxiliary Control from Examples for Learning without Rewards or Demonstrations</title>
      <link>https://paperswithcode.com/paper/value-penalized-auxiliary-control-from</link>
      <description><![CDATA[We resolve this problem, which is exacerbated by learning auxiliary tasks, through the addition of an above-success-level value penalty.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/value-penalized-auxiliary-control-from</guid>
    </item>
    <item>
      <title>Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks</title>
      <link>https://paperswithcode.com/paper/safe-unlearning-a-surprisingly-effective-and</link>
      <description><![CDATA[LLMs are known to be vulnerable to jailbreak attacks, even after safety alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safe-unlearning-a-surprisingly-effective-and</guid>
    </item>
    <item>
      <title>Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models</title>
      <link>https://paperswithcode.com/paper/fine-tuning-with-divergent-chains-of-thought</link>
      <description><![CDATA[In fact, it has been found that instruction tuning on these intermediary reasoning steps improves model performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-with-divergent-chains-of-thought</guid>
    </item>
    <item>
      <title>Explicitly Guided Information Interaction Network for Cross-modal Point Cloud Completion</title>
      <link>https://paperswithcode.com/paper/explicitly-guided-information-interaction</link>
      <description><![CDATA[Corresponding author}In this paper, we explore a novel framework, EGIInet (Explicitly Guided Information Interaction Network), a model for View-guided Point cloud Completion (ViPC) task, which aims to restore a complete point cloud from a partial one with a single view image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explicitly-guided-information-interaction</guid>
    </item>
    <item>
      <title>Anti-Collapse Loss for Deep Metric Learning Based on Coding Rate Metric</title>
      <link>https://paperswithcode.com/paper/anti-collapse-loss-for-deep-metric-learning</link>
      <description><![CDATA[Deep metric learning (DML) aims to learn a discriminative high-dimensional embedding space for downstream tasks like classification, clustering, and retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anti-collapse-loss-for-deep-metric-learning</guid>
    </item>
    <item>
      <title>Effect of Prolonged Smartphone Use on Trapezius and Neck Extensor Muscle Activity, Using sEMG</title>
      <link>https://paperswithcode.com/paper/effect-of-prolonged-smartphone-use-on</link>
      <description><![CDATA[Intensive use of touchscreen mobile devices has increased musculoskeletal problems, particularly in the neck and shoulders, known as "text-neck."]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effect-of-prolonged-smartphone-use-on</guid>
    </item>
    <item>
      <title>Position and Altitude of the Nao Camera Head from Two Points on the Soccer Field plus the Gravitational Direction</title>
      <link>https://paperswithcode.com/paper/position-and-altitude-of-the-nao-camera-head</link>
      <description><![CDATA[When the distance between the two points is known, and the directions to the points plus the gravitational direction are measured, all dimensions of the tetrahedron can be determined.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/position-and-altitude-of-the-nao-camera-head</guid>
    </item>
    <item>
      <title>InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output</title>
      <link>https://paperswithcode.com/paper/internlm-xcomposer-2-5-a-versatile-large</link>
      <description><![CDATA[This long-context capability allows IXC-2. 5 to excel in tasks requiring extensive input and output contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internlm-xcomposer-2-5-a-versatile-large</guid>
    </item>
    <item>
      <title>Frequency-Controlled Diffusion Model for Versatile Text-Guided Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/frequency-controlled-diffusion-model-for</link>
      <description><![CDATA[At the heart of our framework is a feature-space frequency-domain filtering module based on Discrete Cosine Transform, which filters the latent features of the source image in the DCT domain, yielding filtered image features bearing different DCT spectral bands as different control signals to the pre-trained Latent Diffusion Model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/frequency-controlled-diffusion-model-for</guid>
    </item>
    <item>
      <title>LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control</title>
      <link>https://paperswithcode.com/paper/liveportrait-efficient-portrait-animation</link>
      <description><![CDATA[Instead of following mainstream diffusion-based methods, we explore and extend the potential of the implicit-keypoint-based framework, which effectively balances computational efficiency and controllability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/liveportrait-efficient-portrait-animation</guid>
    </item>
    <item>
      <title>MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications</title>
      <link>https://paperswithcode.com/paper/medpix-2-0-a-comprehensive-multimodal</link>
      <description><![CDATA[The increasing interest in developing Artificial Intelligence applications in the medical domain, suffers from the lack of high-quality dataset, mainly due to privacy-related issues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medpix-2-0-a-comprehensive-multimodal</guid>
    </item>
    <item>
      <title>Effect of caffeine and energy drinks on sleep quality and brain activity in college students</title>
      <link>https://paperswithcode.com/paper/effect-of-caffeine-and-energy-drinks-on-sleep</link>
      <description><![CDATA[This study investigates the impact of caffeine and energy drink consumption on sleep quality and brain activity among college students.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effect-of-caffeine-and-energy-drinks-on-sleep</guid>
    </item>
    <item>
      <title>Output Range Analysis for Deep Neural Networks based on Simulated Annealing Processes</title>
      <link>https://paperswithcode.com/paper/output-range-analysis-for-deep-neural-1</link>
      <description><![CDATA[This paper tackles the challenging problem of output range estimation for Deep Neural Networks (DNNs), introducing a novel algorithm based on Simulated Annealing (SA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/output-range-analysis-for-deep-neural-1</guid>
    </item>
    <item>
      <title>ValueScope: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions</title>
      <link>https://paperswithcode.com/paper/valuescope-unveiling-implicit-norms-and</link>
      <description><![CDATA[The framework thus highlights the pivotal role of social norms in shaping online interactions, presenting a substantial advance in both the theory and application of social norm studies in digital spaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/valuescope-unveiling-implicit-norms-and</guid>
    </item>
    <item>
      <title>CountFormer: Multi-View Crowd Counting Transformer</title>
      <link>https://paperswithcode.com/paper/countformer-multi-view-crowd-counting</link>
      <description><![CDATA[Multi-view counting (MVC) methods have shown their superiority over single-view counterparts, particularly in situations characterized by heavy occlusion and severe perspective distortions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/countformer-multi-view-crowd-counting</guid>
    </item>
    <item>
      <title>Towards a Holistic Framework for Multimodal Large Language Models in Three-dimensional Brain CT Report Generation</title>
      <link>https://paperswithcode.com/paper/towards-a-holistic-framework-for-multimodal</link>
      <description><![CDATA[Multi-modal large language models (MLLMs) have been given free rein to explore exciting medical applications with a primary focus on radiology report generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-a-holistic-framework-for-multimodal</guid>
    </item>
    <item>
      <title>MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation</title>
      <link>https://paperswithcode.com/paper/mememo-on-device-retrieval-augmentation-for</link>
      <description><![CDATA[To address the pressing need for client-side dense retrieval, we introduce MeMemo, the first open-source JavaScript toolkit that adapts the state-of-the-art approximate nearest neighbor search technique HNSW to browser environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mememo-on-device-retrieval-augmentation-for</guid>
    </item>
    <item>
      <title>Neurocache: Efficient Vector Retrieval for Long-range Language Modeling</title>
      <link>https://paperswithcode.com/paper/neurocache-efficient-vector-retrieval-for</link>
      <description><![CDATA[This paper introduces Neurocache, an approach to extend the effective context size of large language models (LLMs) using an external vector cache to store its past states.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neurocache-efficient-vector-retrieval-for</guid>
    </item>
    <item>
      <title>Tarsier: Recipes for Training and Evaluating Large Video Description Models</title>
      <link>https://paperswithcode.com/paper/tarsier-recipes-for-training-and-evaluating</link>
      <description><![CDATA[In this work, we introduce Tarsier, a family of large-scale video-language models designed to generate high-quality video descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tarsier-recipes-for-training-and-evaluating</guid>
    </item>
    <item>
      <title>Analysis of Ergonomic Risk in University Study Environments During Class Days</title>
      <link>https://paperswithcode.com/paper/analysis-of-ergonomic-risk-in-university</link>
      <description><![CDATA[This study investigates the ergonomic impact of university seating on studentsâ€™ musculoskeletal health, focusing on lumbar muscle fatigue during prolonged study sessions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/analysis-of-ergonomic-risk-in-university</guid>
    </item>
    <item>
      <title>Similarity Distance-Based Label Assignment for Tiny Object Detection</title>
      <link>https://paperswithcode.com/paper/similarity-distance-based-label-assignment</link>
      <description><![CDATA[Although there are some effective label assignment strategies for tiny objects, most of them focus on reducing the sensitivity to the bounding boxes to increase the number of positive samples and have some fixed hyperparameters need to set.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/similarity-distance-based-label-assignment</guid>
    </item>
    <item>
      <title>SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack</title>
      <link>https://paperswithcode.com/paper/sop-unlock-the-power-of-social-facilitation</link>
      <description><![CDATA[The widespread applications of large language models (LLMs) have brought about concerns regarding their potential misuse.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sop-unlock-the-power-of-social-facilitation</guid>
    </item>
  </channel>
</rss>
