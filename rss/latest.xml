<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 29 May 2023 21:06:06 +0000</lastBuildDate>
    <item>
      <title>Evaluating generation of chaotic time series by convolutional generative adversarial networks</title>
      <link>https://paperswithcode.com/paper/evaluating-generation-of-chaotic-time-series</link>
      <description><![CDATA[To understand the ability and limitations of convolutional neural networks to generate time series that mimic complex temporal signals, we trained a generative adversarial network consisting of deep convolutional networks to generate chaotic time series and used nonlinear time series analysis to evaluate the generated time series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-generation-of-chaotic-time-series</guid>
    </item>
    <item>
      <title>Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization</title>
      <link>https://paperswithcode.com/paper/domain-aligned-prefix-averaging-for-domain</link>
      <description><![CDATA[These source prefixes generate summaries for a small number of target domain documents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-aligned-prefix-averaging-for-domain</guid>
    </item>
    <item>
      <title>MixCE: Training Autoregressive Language Models by Mixing Forward and Reverse Cross-Entropies</title>
      <link>https://paperswithcode.com/paper/mixce-training-autoregressive-language-models</link>
      <description><![CDATA[Autoregressive language models are trained by minimizing the cross-entropy of the model distribution Q relative to the data distribution P -- that is, minimizing the forward cross-entropy, which is equivalent to maximum likelihood estimation (MLE).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixce-training-autoregressive-language-models</guid>
    </item>
    <item>
      <title>Multiview Identifiers Enhanced Generative Retrieval</title>
      <link>https://paperswithcode.com/paper/multiview-identifiers-enhanced-generative</link>
      <description><![CDATA[Instead of simply matching a query to pre-existing passages, generative retrieval generates identifier strings of passages as the retrieval target.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiview-identifiers-enhanced-generative</guid>
    </item>
    <item>
      <title>Dramatic Conversation Disentanglement</title>
      <link>https://paperswithcode.com/paper/dramatic-conversation-disentanglement</link>
      <description><![CDATA[We present a new dataset for studying conversation disentanglement in movies and TV series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dramatic-conversation-disentanglement</guid>
    </item>
    <item>
      <title>BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks</title>
      <link>https://paperswithcode.com/paper/biomedgpt-a-unified-and-generalist-biomedical</link>
      <description><![CDATA[In this paper, we introduce a unified and generalist Biomedical Generative Pre-trained Transformer (BiomedGPT) model, which leverages self-supervision on large and diverse datasets to accept multi-modal inputs and perform a range of downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biomedgpt-a-unified-and-generalist-biomedical</guid>
    </item>
    <item>
      <title>A Closer Look at In-Context Learning under Distribution Shifts</title>
      <link>https://paperswithcode.com/paper/a-closer-look-at-in-context-learning-under</link>
      <description><![CDATA[In-context learning, a capability that enables a model to learn from input examples on the fly without necessitating weight updates, is a defining characteristic of large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-closer-look-at-in-context-learning-under</guid>
    </item>
    <item>
      <title>Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation</title>
      <link>https://paperswithcode.com/paper/few-shot-fine-tuning-vs-in-context-learning-a</link>
      <description><![CDATA[In this paper, we compare the generalization of few-shot fine-tuning and in-context learning to challenge datasets, while controlling for the models used, the number of examples, and the number of parameters, ranging from 125M to 30B.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/few-shot-fine-tuning-vs-in-context-learning-a</guid>
    </item>
    <item>
      <title>MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting</title>
      <link>https://paperswithcode.com/paper/multitool-cot-gpt-3-can-use-multiple-external</link>
      <description><![CDATA[Large language models (LLMs) have achieved impressive performance on various reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multitool-cot-gpt-3-can-use-multiple-external</guid>
    </item>
    <item>
      <title>CRoSS: Diffusion Model Makes Controllable, Robust and Secure Image Steganography</title>
      <link>https://paperswithcode.com/paper/cross-diffusion-model-makes-controllable</link>
      <description><![CDATA[Current image steganography techniques are mainly focused on cover-based methods, which commonly have the risk of leaking secret images and poor robustness against degraded container images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-diffusion-model-makes-controllable</guid>
    </item>
    <item>
      <title>Adaptive PD Control using Deep Reinforcement Learning for Local-Remote Teleoperation with Stochastic Time Delays</title>
      <link>https://paperswithcode.com/paper/adaptive-pd-control-using-deep-reinforcement</link>
      <description><![CDATA[By adjusting controller parameters in real-time, this adaptive controller compensates for stochastic delays and improves synchronicity between local and remote robotic manipulators.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-pd-control-using-deep-reinforcement</guid>
    </item>
    <item>
      <title>An Empirical Comparison of LM-based Question and Answer Generation Methods</title>
      <link>https://paperswithcode.com/paper/an-empirical-comparison-of-lm-based-question</link>
      <description><![CDATA[This task has a variety of applications, such as data augmentation for question answering (QA) models, information retrieval and education.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-empirical-comparison-of-lm-based-question</guid>
    </item>
    <item>
      <title>On Evaluating Adversarial Robustness of Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/on-evaluating-adversarial-robustness-of-large</link>
      <description><![CDATA[Large vision-language models (VLMs) such as GPT-4 have achieved unprecedented performance in response generation, especially with visual inputs, enabling more creative and adaptable interaction than large language models such as ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-evaluating-adversarial-robustness-of-large</guid>
    </item>
    <item>
      <title>Free Lunch: Robust Cross-Lingual Transfer via Model Checkpoint Averaging</title>
      <link>https://paperswithcode.com/paper/free-lunch-robust-cross-lingual-transfer-via</link>
      <description><![CDATA[The results indicate that averaging model checkpoints yields systematic and consistent performance gains across diverse target languages in all tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/free-lunch-robust-cross-lingual-transfer-via</guid>
    </item>
    <item>
      <title>An Investigation of Noise in Morphological Inflection</title>
      <link>https://paperswithcode.com/paper/an-investigation-of-noise-in-morphological</link>
      <description><![CDATA[We aim at closing this gap by investigating the types of noise encountered within a pipeline for truly unsupervised morphological paradigm completion and its impact on morphological inflection systems: First, we propose an error taxonomy and annotation pipeline for inflection training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-investigation-of-noise-in-morphological</guid>
    </item>
    <item>
      <title>Large Language Models as Tool Makers</title>
      <link>https://paperswithcode.com/paper/large-language-models-as-tool-makers</link>
      <description><![CDATA[Our approach consists of two key phases: 1) tool making: an LLM acts as the tool maker that crafts tools for given tasks, where a tool is implemented as a Python utility function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-as-tool-makers</guid>
    </item>
    <item>
      <title>SSSegmenation: An Open Source Supervised Semantic Segmentation Toolbox Based on PyTorch</title>
      <link>https://paperswithcode.com/paper/sssegmenation-an-open-source-supervised</link>
      <description><![CDATA[This paper presents SSSegmenation, which is an open source supervised semantic image segmentation toolbox based on PyTorch.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sssegmenation-an-open-source-supervised</guid>
    </item>
    <item>
      <title>CREST: A Joint Framework for Rationalization and Counterfactual Text Generation</title>
      <link>https://paperswithcode.com/paper/crest-a-joint-framework-for-rationalization</link>
      <description><![CDATA[Selective rationales and counterfactual examples have emerged as two effective, complementary classes of interpretability methods for analyzing and training NLP models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/crest-a-joint-framework-for-rationalization</guid>
    </item>
    <item>
      <title>A Hierarchical Approach to Population Training for Human-AI Collaboration</title>
      <link>https://paperswithcode.com/paper/a-hierarchical-approach-to-population</link>
      <description><![CDATA[A major challenge for deep reinforcement learning (DRL) agents is to collaborate with novel partners that were not encountered by them during the training phase.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-hierarchical-approach-to-population</guid>
    </item>
    <item>
      <title>Hierarchical Verbalizer for Few-Shot Hierarchical Text Classification</title>
      <link>https://paperswithcode.com/paper/hierarchical-verbalizer-for-few-shot</link>
      <description><![CDATA[Due to the complex label hierarchy and intensive labeling cost in practice, the hierarchical text classification (HTC) suffers a poor performance especially when low-resource or few-shot settings are considered.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-verbalizer-for-few-shot</guid>
    </item>
    <item>
      <title>Confidence-Based Feature Imputation for Graphs with Partially Known Features</title>
      <link>https://paperswithcode.com/paper/confidence-based-feature-imputation-for</link>
      <description><![CDATA[To overcome this limitation, we introduce a novel concept of channel-wise confidence in a node feature, which is assigned to each imputed channel feature of a node for reflecting certainty of the imputation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/confidence-based-feature-imputation-for</guid>
    </item>
    <item>
      <title>S4M: Generating Radiology Reports by A Single Model for Multiple Body Parts</title>
      <link>https://paperswithcode.com/paper/s4m-generating-radiology-reports-by-a-single</link>
      <description><![CDATA[In this paper, we seek to design a report generation model that is able to generate reasonable reports even given different images of various body parts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s4m-generating-radiology-reports-by-a-single</guid>
    </item>
    <item>
      <title>Meta-prediction Model for Distillation-Aware NAS on Unseen Datasets</title>
      <link>https://paperswithcode.com/paper/meta-prediction-model-for-distillation-aware</link>
      <description><![CDATA[Previous DaNAS methods have mostly tackled the search for the neural architecture for fixed datasets and the teacher, which are not generalized well on a new task consisting of an unseen dataset and an unseen teacher, thus need to perform a costly search for any new combination of the datasets and the teachers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-prediction-model-for-distillation-aware</guid>
    </item>
    <item>
      <title>Extremely weakly-supervised blood vessel segmentation with physiologically based synthesis and domain adaptation</title>
      <link>https://paperswithcode.com/paper/extremely-weakly-supervised-blood-vessel</link>
      <description><![CDATA[Accurate analysis and modeling of renal functions require a precise segmentation of the renal blood vessels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extremely-weakly-supervised-blood-vessel</guid>
    </item>
    <item>
      <title>Learning to Imagine: Visually-Augmented Natural Language Generation</title>
      <link>https://paperswithcode.com/paper/learning-to-imagine-visually-augmented</link>
      <description><![CDATA[People often imagine relevant scenes to aid in the writing process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-imagine-visually-augmented</guid>
    </item>
    <item>
      <title>Songs Across Borders: Singable and Controllable Neural Lyric Translation</title>
      <link>https://paperswithcode.com/paper/songs-across-borders-singable-and</link>
      <description><![CDATA[The development of general-domain neural machine translation (NMT) methods has advanced significantly in recent years, but the lack of naturalness and musical constraints in the outputs makes them unable to produce singable lyric translations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/songs-across-borders-singable-and</guid>
    </item>
    <item>
      <title>Controlling Learned Effects to Reduce Spurious Correlations in Text Classifiers</title>
      <link>https://paperswithcode.com/paper/controlling-learned-effects-to-reduce</link>
      <description><![CDATA[Therefore, using methods from the causal inference literature, we propose an algorithm to regularize the learnt effect of the features on the model's prediction to the estimated effect of feature on label.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controlling-learned-effects-to-reduce</guid>
    </item>
    <item>
      <title>Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning</title>
      <link>https://paperswithcode.com/paper/language-models-can-improve-event-prediction</link>
      <description><![CDATA[Large language models have shown astonishing performance on a wide range of reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-can-improve-event-prediction</guid>
    </item>
    <item>
      <title>Tree-Based Diffusion Schr√∂dinger Bridge with Applications to Wasserstein Barycenters</title>
      <link>https://paperswithcode.com/paper/tree-based-diffusion-schrodinger-bridge-with</link>
      <description><![CDATA[In this paper, we consider an entropic version of mOT with a tree-structured quadratic cost, i. e., a function that can be written as a sum of pairwise cost functions between the nodes of a tree.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tree-based-diffusion-schrodinger-bridge-with</guid>
    </item>
    <item>
      <title>Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for Financial Tasks</title>
      <link>https://paperswithcode.com/paper/zero-is-not-hero-yet-benchmarking-zero-shot</link>
      <description><![CDATA[Recently large language models (LLMs) like ChatGPT have shown impressive performance on many natural language processing tasks with zero-shot.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-is-not-hero-yet-benchmarking-zero-shot</guid>
    </item>
    <item>
      <title>Improving Knowledge Distillation via Regularizing Feature Norm and Direction</title>
      <link>https://paperswithcode.com/paper/improving-knowledge-distillation-via-1</link>
      <description><![CDATA[Finally, we propose a rather simple loss term (dubbed ND loss) to simultaneously (1) encourage student to produce large-\emph{norm} features, and (2) align the \emph{direction} of student features and teacher class-means.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-knowledge-distillation-via-1</guid>
    </item>
    <item>
      <title>Training Socially Aligned Language Models in Simulated Human Society</title>
      <link>https://paperswithcode.com/paper/training-socially-aligned-language-models-in</link>
      <description><![CDATA[Social alignment in AI systems aims to ensure that these models behave according to established societal values.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-socially-aligned-language-models-in</guid>
    </item>
    <item>
      <title>Dual Bayesian ResNet: A Deep Learning Approach to Heart Murmur Detection</title>
      <link>https://paperswithcode.com/paper/dual-bayesian-resnet-a-deep-learning-approach-1</link>
      <description><![CDATA[The second model is the output of DBRes integrated with demographic data and signal features using XGBoost. DBRes achieved our best weighted accuracy of $0. 771$ on the hidden test set for murmur classification, which placed us fourth for the murmur task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-bayesian-resnet-a-deep-learning-approach-1</guid>
    </item>
    <item>
      <title>UMSE: Unified Multi-scenario Summarization Evaluation</title>
      <link>https://paperswithcode.com/paper/umse-unified-multi-scenario-summarization</link>
      <description><![CDATA[Experimental results across three typical scenarios on the benchmark dataset SummEval indicate that our UMSE can achieve comparable performance with several existing strong methods which are specifically designed for each scenario.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/umse-unified-multi-scenario-summarization</guid>
    </item>
    <item>
      <title>NeuroX Library for Neuron Analysis of Deep NLP Models</title>
      <link>https://paperswithcode.com/paper/neurox-library-for-neuron-analysis-of-deep</link>
      <description><![CDATA[The Python toolkit is available at https://www. github. com/fdalvi/NeuroX.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neurox-library-for-neuron-analysis-of-deep</guid>
    </item>
    <item>
      <title>Teamwork Is Not Always Good: An Empirical Study of Classifier Drift in Class-incremental Information Extraction</title>
      <link>https://paperswithcode.com/paper/teamwork-is-not-always-good-an-empirical</link>
      <description><![CDATA[Class-incremental learning (CIL) aims to develop a learning system that can continually learn new classes from a data stream without forgetting previously learned classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teamwork-is-not-always-good-an-empirical</guid>
    </item>
    <item>
      <title>Geometric deep learning approach to knot theory</title>
      <link>https://paperswithcode.com/paper/geometric-deep-learning-approach-to-knot</link>
      <description><![CDATA[In this paper, we introduce a novel way to use geometric deep learning for knot data by constructing a functor that takes knots to graphs and using graph neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geometric-deep-learning-approach-to-knot</guid>
    </item>
    <item>
      <title>Improving Position Encoding of Transformers for Multivariate Time Series Classification</title>
      <link>https://paperswithcode.com/paper/improving-position-encoding-of-transformers</link>
      <description><![CDATA[We then proposed a new absolute position encoding method dedicated to time series data called time Absolute Position Encoding (tAPE).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-position-encoding-of-transformers</guid>
    </item>
    <item>
      <title>Future-conditioned Unsupervised Pretraining for Decision Transformer</title>
      <link>https://paperswithcode.com/paper/future-conditioned-unsupervised-pretraining</link>
      <description><![CDATA[While promising, return conditioning is limited to training data labeled with rewards and therefore faces challenges in learning from unsupervised data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/future-conditioned-unsupervised-pretraining</guid>
    </item>
    <item>
      <title>A Reminder of its Brittleness: Language Reward Shaping May Hinder Learning for Instruction Following Agents</title>
      <link>https://paperswithcode.com/paper/a-reminder-of-its-brittleness-language-reward</link>
      <description><![CDATA[Teaching agents to follow complex written instructions has been an important yet elusive goal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-reminder-of-its-brittleness-language-reward</guid>
    </item>
    <item>
      <title>Modulate Your Spectrum in Self-Supervised Learning</title>
      <link>https://paperswithcode.com/paper/modulate-your-spectrum-in-self-supervised</link>
      <description><![CDATA[We show that whitening transformation is a special instance of ST by definition, and there exist other instances that can avoid collapse by our empirical investigation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/modulate-your-spectrum-in-self-supervised</guid>
    </item>
    <item>
      <title>Score-balanced Loss for Multi-aspect Pronunciation Assessment</title>
      <link>https://paperswithcode.com/paper/score-balanced-loss-for-multi-aspect</link>
      <description><![CDATA[With rapid technological growth, automatic pronunciation assessment has transitioned toward systems that evaluate pronunciation in various aspects, such as fluency and stress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/score-balanced-loss-for-multi-aspect</guid>
    </item>
    <item>
      <title>Zero-shot Visual Question Answering with Language Model Feedback</title>
      <link>https://paperswithcode.com/paper/zero-shot-visual-question-answering-with</link>
      <description><![CDATA[In this paper, we propose a novel language model guided captioning approach, LAMOC, for knowledge-based visual question answering (VQA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-visual-question-answering-with</guid>
    </item>
    <item>
      <title>Sentence-Incremental Neural Coreference Resolution</title>
      <link>https://paperswithcode.com/paper/sentence-incremental-neural-coreference</link>
      <description><![CDATA[We propose a sentence-incremental neural coreference resolution system which incrementally builds clusters after marking mention boundaries in a shift-reduce method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sentence-incremental-neural-coreference</guid>
    </item>
    <item>
      <title>Finspector: A Human-Centered Visual Inspection Tool for Exploring and Comparing Biases among Foundation Models</title>
      <link>https://paperswithcode.com/paper/finspector-a-human-centered-visual-inspection</link>
      <description><![CDATA[Pre-trained transformer-based language models are becoming increasingly popular due to their exceptional performance on various benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finspector-a-human-centered-visual-inspection</guid>
    </item>
    <item>
      <title>Levin Tree Search with Context Models</title>
      <link>https://paperswithcode.com/paper/levin-tree-search-with-context-models</link>
      <description><![CDATA[Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a probability distribution over actions) and comes with a theoretical guarantee on the number of expansions before reaching a goal node, depending on the quality of the policy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/levin-tree-search-with-context-models</guid>
    </item>
    <item>
      <title>NLP Reproducibility For All: Understanding Experiences of Beginners</title>
      <link>https://paperswithcode.com/paper/nlp-reproducibility-for-all-understanding</link>
      <description><![CDATA[As natural language processing (NLP) has recently seen an unprecedented level of excitement, and more people are eager to enter the field, it is unclear whether current research reproducibility efforts are sufficient for this group of beginners to apply the latest developments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nlp-reproducibility-for-all-understanding</guid>
    </item>
    <item>
      <title>Graph Neural Convection-Diffusion with Heterophily</title>
      <link>https://paperswithcode.com/paper/graph-neural-convection-diffusion-with</link>
      <description><![CDATA[Graph neural networks (GNNs) have shown promising results across various graph learning tasks, but they often assume homophily, which can result in poor performance on heterophilic graphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-neural-convection-diffusion-with</guid>
    </item>
    <item>
      <title>Automatic Tuning of Loss Trade-offs without Hyper-parameter Search in End-to-End Zero-Shot Speech Synthesis</title>
      <link>https://paperswithcode.com/paper/automatic-tuning-of-loss-trade-offs-without</link>
      <description><![CDATA[With our framework, we show superior performance compared to baselines in zero-shot TTS and VC, achieving state-of-the-art performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automatic-tuning-of-loss-trade-offs-without</guid>
    </item>
    <item>
      <title>Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues</title>
      <link>https://paperswithcode.com/paper/schema-guided-user-satisfaction-modeling-for</link>
      <description><![CDATA[Further, it employs a fulfillment representation layer for learning how many task attributes have been fulfilled in the dialogue, an importance predictor component for calculating the importance of task attributes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/schema-guided-user-satisfaction-modeling-for</guid>
    </item>
  </channel>
</rss>
