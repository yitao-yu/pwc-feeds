<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 22 Oct 2023 09:10:33 +0000</lastBuildDate>
    <item>
      <title>Is Weakly-supervised Action Segmentation Ready For Human-Robot Interaction? No, Let's Improve It With Action-union Learning</title>
      <link>https://paperswithcode.com/paper/is-weakly-supervised-action-segmentation</link>
      <description><![CDATA[To alleviate this issue, we proposed a novel learning pattern in our training stage, which maximizes the probability of action union of surrounding timestamps for unlabeled frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-weakly-supervised-action-segmentation</guid>
    </item>
    <item>
      <title>Mutual Information-Based Integrated Sensing and Communications: A WMMSE Framework</title>
      <link>https://paperswithcode.com/paper/mutual-information-based-integrated-sensing</link>
      <description><![CDATA[In this letter, a weighted minimum mean square error (WMMSE) empowered integrated sensing and communication (ISAC) system is investigated.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mutual-information-based-integrated-sensing</guid>
    </item>
    <item>
      <title>Minimalist and High-Performance Semantic Segmentation with Plain Vision Transformers</title>
      <link>https://paperswithcode.com/paper/minimalist-and-high-performance-semantic</link>
      <description><![CDATA[Building upon the original motivations of plain ViTs, which are simplicity and generality, we explore high-performance `minimalist' systems to this end.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minimalist-and-high-performance-semantic</guid>
    </item>
    <item>
      <title>AgentTuning: Enabling Generalized Agent Abilities for LLMs</title>
      <link>https://paperswithcode.com/paper/agenttuning-enabling-generalized-agent</link>
      <description><![CDATA[Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of LLMs themselves without compromising their general abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agenttuning-enabling-generalized-agent</guid>
    </item>
    <item>
      <title>Product Attribute Value Extraction using Large Language Models</title>
      <link>https://paperswithcode.com/paper/product-attribute-value-extraction-using</link>
      <description><![CDATA[E-commerce applications such as faceted product search or product comparison are based on structured product descriptions like attribute/value pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/product-attribute-value-extraction-using</guid>
    </item>
    <item>
      <title>Towards Real-World Streaming Speech Translation for Code-Switched Speech</title>
      <link>https://paperswithcode.com/paper/towards-real-world-streaming-speech</link>
      <description><![CDATA[Code-switching (CS), i. e. mixing different languages in a single sentence, is a common phenomenon in communication and can be challenging in many Natural Language Processing (NLP) settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-real-world-streaming-speech</guid>
    </item>
    <item>
      <title>AutoMix: Automatically Mixing Language Models</title>
      <link>https://paperswithcode.com/paper/automix-automatically-mixing-language-models</link>
      <description><![CDATA[Large language models (LLMs) are now available in various sizes and configurations from cloud API providers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automix-automatically-mixing-language-models</guid>
    </item>
    <item>
      <title>Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization</title>
      <link>https://paperswithcode.com/paper/are-structural-concepts-universal-in</link>
      <description><![CDATA[We then propose a meta-learning-based method to learn to align conceptual spaces of different languages, which facilitates zero-shot and few-shot generalization in concept classification and also offers insights into the cross-lingual in-context learning phenomenon.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/are-structural-concepts-universal-in</guid>
    </item>
    <item>
      <title>DCSI -- An improved measure of cluster separability based on separation and connectedness</title>
      <link>https://paperswithcode.com/paper/dcsi-an-improved-measure-of-cluster</link>
      <description><![CDATA[Detailed evaluation on frequently used real-world data sets shows that DCSI can correctly identify touching or overlapping classes that do not form meaningful clusters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dcsi-an-improved-measure-of-cluster</guid>
    </item>
    <item>
      <title>Non-Autoregressive Sentence Ordering</title>
      <link>https://paperswithcode.com/paper/non-autoregressive-sentence-ordering</link>
      <description><![CDATA[Existing sentence ordering approaches generally employ encoder-decoder frameworks with the pointer net to recover the coherence by recurrently predicting each sentence step-by-step.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/non-autoregressive-sentence-ordering</guid>
    </item>
    <item>
      <title>Discretize Relaxed Solution of Spectral Clustering via a Non-Heuristic Algorithm</title>
      <link>https://paperswithcode.com/paper/discretize-relaxed-solution-of-spectral</link>
      <description><![CDATA[Unfortunately, the goal of the existing methods is not to find a discrete solution that minimizes the original objective.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/discretize-relaxed-solution-of-spectral</guid>
    </item>
    <item>
      <title>Character-level Chinese Backpack Language Models</title>
      <link>https://paperswithcode.com/paper/character-level-chinese-backpack-language</link>
      <description><![CDATA[The Backpack is a Transformer alternative shown to improve interpretability in English language modeling by decomposing predictions into a weighted sum of token sense components.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/character-level-chinese-backpack-language</guid>
    </item>
    <item>
      <title>Compression of Recurrent Neural Networks using Matrix Factorization</title>
      <link>https://paperswithcode.com/paper/compression-of-recurrent-neural-networks</link>
      <description><![CDATA[Compressing neural networks is a key step when deploying models for real-time or embedded applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compression-of-recurrent-neural-networks</guid>
    </item>
    <item>
      <title>Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models</title>
      <link>https://paperswithcode.com/paper/rethinking-the-construction-of-effective</link>
      <description><![CDATA[We have specifically designed a family of metrics along this line of investigation, and the model used to compute these metrics is referred to as the tree topological probe.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-the-construction-of-effective</guid>
    </item>
    <item>
      <title>TabuLa: Harnessing Language Models for Tabular Data Synthesis</title>
      <link>https://paperswithcode.com/paper/tabula-harnessing-language-models-for-tabular</link>
      <description><![CDATA[Results show that Tabula averagely reduces 46. 2% training time per epoch comparing to current LLMs-based state-of-the-art algorithm and consistently achieves even higher synthetic data utility.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tabula-harnessing-language-models-for-tabular</guid>
    </item>
    <item>
      <title>PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models</title>
      <link>https://paperswithcode.com/paper/poisonprompt-backdoor-attack-on-prompt-based</link>
      <description><![CDATA[Prompts have significantly improved the performance of pretrained Large Language Models (LLMs) on various downstream tasks recently, making them increasingly indispensable for a diverse range of LLM application scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poisonprompt-backdoor-attack-on-prompt-based</guid>
    </item>
    <item>
      <title>Predicting Ovarian Cancer Treatment Response in Histopathology using Hierarchical Vision Transformers and Multiple Instance Learning</title>
      <link>https://paperswithcode.com/paper/predicting-ovarian-cancer-treatment-response</link>
      <description><![CDATA[For some therapies, it is not possible to predict patients' responses, potentially exposing them to the adverse effects of treatment without any therapeutic benefit.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/predicting-ovarian-cancer-treatment-response</guid>
    </item>
    <item>
      <title>DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text</title>
      <link>https://paperswithcode.com/paper/depwignn-a-depth-wise-graph-neural-network</link>
      <description><![CDATA[Spatial reasoning in text plays a crucial role in various real-world applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depwignn-a-depth-wise-graph-neural-network</guid>
    </item>
    <item>
      <title>MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models</title>
      <link>https://paperswithcode.com/paper/maf-multi-aspect-feedback-for-improving</link>
      <description><![CDATA[Language Models (LMs) have shown impressive performance in various natural language tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maf-multi-aspect-feedback-for-improving</guid>
    </item>
    <item>
      <title>Differentiable Vertex Fitting for Jet Flavour Tagging</title>
      <link>https://paperswithcode.com/paper/differentiable-vertex-fitting-for-jet-flavour</link>
      <description><![CDATA[We propose a differentiable vertex fitting algorithm that can be used for secondary vertex fitting, and that can be seamlessly integrated into neural networks for jet flavour tagging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/differentiable-vertex-fitting-for-jet-flavour</guid>
    </item>
    <item>
      <title>On the Representational Capacity of Recurrent Neural Language Models</title>
      <link>https://paperswithcode.com/paper/on-the-representational-capacity-of-recurrent</link>
      <description><![CDATA[We extend the Turing completeness result to the probabilistic case, showing how a rationally weighted RLM with unbounded computation time can simulate any probabilistic Turing machine (PTM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-representational-capacity-of-recurrent</guid>
    </item>
    <item>
      <title>Not Just Learning from Others but Relying on Yourself: A New Perspective on Few-Shot Segmentation in Remote Sensing</title>
      <link>https://paperswithcode.com/paper/not-just-learning-from-others-but-relying-on</link>
      <description><![CDATA[In addition, to prevent the co-existence of multiple classes in remote sensing scenes from exacerbating the collapse of FSS generalization, we also propose a new Known-class Meta Suppressor (KMS) module to suppress the activation of known-class objects in the sample.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/not-just-learning-from-others-but-relying-on</guid>
    </item>
    <item>
      <title>The Foundation Model Transparency Index</title>
      <link>https://paperswithcode.com/paper/the-foundation-model-transparency-index</link>
      <description><![CDATA[We score 10 major foundation model developers (e. g. OpenAI, Google, Meta) against the 100 indicators to assess their transparency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-foundation-model-transparency-index</guid>
    </item>
    <item>
      <title>How a student becomes a teacher: learning and forgetting through Spectral methods</title>
      <link>https://paperswithcode.com/paper/how-a-student-becomes-a-teacher-learning-and</link>
      <description><![CDATA[In theoretical ML, the teacher-student paradigm is often employed as an effective metaphor for real-life tuition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-a-student-becomes-a-teacher-learning-and</guid>
    </item>
    <item>
      <title>An Improved Metarounding Algorithm via Frank-Wolfe</title>
      <link>https://paperswithcode.com/paper/an-improved-metarounding-algorithm-via-frank</link>
      <description><![CDATA[Metarounding is an approach to convert an approximation algorithm for linear optimization over some combinatorial classes to an online linear optimization algorithm for the same class.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-improved-metarounding-algorithm-via-frank</guid>
    </item>
    <item>
      <title>Neural networks for insurance pricing with frequency and severity data: a benchmark study from data preprocessing to technical tariff</title>
      <link>https://paperswithcode.com/paper/neural-networks-for-insurance-pricing-with</link>
      <description><![CDATA[We compare in detail the performance of: a generalized linear model on binned input data, a gradient-boosted tree model, a feed-forward neural network (FFNN), and the combined actuarial neural network (CANN).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-networks-for-insurance-pricing-with</guid>
    </item>
    <item>
      <title>Safe RLHF: Safe Reinforcement Learning from Human Feedback</title>
      <link>https://paperswithcode.com/paper/safe-rlhf-safe-reinforcement-learning-from</link>
      <description><![CDATA[However, the inherent tension between the objectives of helpfulness and harmlessness presents a significant challenge during LLM training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safe-rlhf-safe-reinforcement-learning-from</guid>
    </item>
    <item>
      <title>The Locality and Symmetry of Positional Encodings</title>
      <link>https://paperswithcode.com/paper/the-locality-and-symmetry-of-positional</link>
      <description><![CDATA[Positional Encodings (PEs) are used to inject word-order information into transformer-based language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-locality-and-symmetry-of-positional</guid>
    </item>
    <item>
      <title>Representing and Computing Uncertainty in Phonological Reconstruction</title>
      <link>https://paperswithcode.com/paper/representing-and-computing-uncertainty-in</link>
      <description><![CDATA[Despite the inherently fuzzy nature of reconstructions in historical linguistics, most scholars do not represent their uncertainty when proposing proto-forms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representing-and-computing-uncertainty-in</guid>
    </item>
    <item>
      <title>Transformer-based Entity Legal Form Classification</title>
      <link>https://paperswithcode.com/paper/transformer-based-entity-legal-form</link>
      <description><![CDATA[We propose the application of Transformer-based language models for classifying entity legal forms from raw legal entity names.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-based-entity-legal-form</guid>
    </item>
    <item>
      <title>SemantIC: Semantic Interference Cancellation Towards 6G Wireless Communications</title>
      <link>https://paperswithcode.com/paper/semantic-semantic-interference-cancellation</link>
      <description><![CDATA[This letter proposes a novel anti-interference technique, semantic interference cancellation (SemantIC), for enhancing information quality towards the sixth-generation (6G) wireless networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-semantic-interference-cancellation</guid>
    </item>
    <item>
      <title>Putting the Object Back into Video Object Segmentation</title>
      <link>https://paperswithcode.com/paper/putting-the-object-back-into-video-object</link>
      <description><![CDATA[The object queries act as a high-level summary of the target object, while high-resolution feature maps are retained for accurate segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/putting-the-object-back-into-video-object</guid>
    </item>
    <item>
      <title>DocXChain: A Powerful Open-Source Toolchain for Document Parsing and Beyond</title>
      <link>https://paperswithcode.com/paper/docxchain-a-powerful-open-source-toolchain</link>
      <description><![CDATA[In this report, we introduce DocXChain, a powerful open-source toolchain for document parsing, which is designed and developed to automatically convert the rich information embodied in unstructured documents, such as text, tables and charts, into structured representations that are readable and manipulable by machines.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/docxchain-a-powerful-open-source-toolchain</guid>
    </item>
    <item>
      <title>Frozen Transformers in Language Models Are Effective Visual Encoder Layers</title>
      <link>https://paperswithcode.com/paper/frozen-transformers-in-language-models-are</link>
      <description><![CDATA[This paper reveals that large language models (LLMs), despite being trained solely on textual data, are surprisingly strong encoders for purely visual tasks in the absence of language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/frozen-transformers-in-language-models-are</guid>
    </item>
    <item>
      <title>MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter</title>
      <link>https://paperswithcode.com/paper/molca-molecular-graph-language-modeling-with</link>
      <description><![CDATA[MolCA enables an LM (e. g., Galactica) to understand both text- and graph-based molecular contents via the cross-modal projector.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/molca-molecular-graph-language-modeling-with</guid>
    </item>
    <item>
      <title>Cousins Of The Vendi Score: A Family Of Similarity-Based Diversity Metrics For Science And Machine Learning</title>
      <link>https://paperswithcode.com/paper/cousins-of-the-vendi-score-a-family-of</link>
      <description><![CDATA[Contrary to many diversity metrics in ecology, the Vendi Score accounts for similarity and does not require knowledge of the prevalence of the categories in the collection to be evaluated for diversity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cousins-of-the-vendi-score-a-family-of</guid>
    </item>
    <item>
      <title>Revisiting Sparse Retrieval for Few-shot Entity Linking</title>
      <link>https://paperswithcode.com/paper/revisiting-sparse-retrieval-for-few-shot</link>
      <description><![CDATA[Entity linking aims to link ambiguous mentions to their corresponding entities in a knowledge base.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-sparse-retrieval-for-few-shot</guid>
    </item>
    <item>
      <title>Representation Learning via Consistent Assignment of Views over Random Partitions</title>
      <link>https://paperswithcode.com/paper/representation-learning-via-consistent-1</link>
      <description><![CDATA[We extensively ablate our method and demonstrate that our proposed random partition pretext task improves the quality of the learned representations by devising multiple random classification tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representation-learning-via-consistent-1</guid>
    </item>
    <item>
      <title>Prompt Injection Attacks and Defenses in LLM-Integrated Applications</title>
      <link>https://paperswithcode.com/paper/prompt-injection-attacks-and-defenses-in-llm</link>
      <description><![CDATA[As a result, the literature lacks a systematic understanding of prompt injection attacks and their defenses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-injection-attacks-and-defenses-in-llm</guid>
    </item>
    <item>
      <title>Generative Marginalization Models</title>
      <link>https://paperswithcode.com/paper/generative-marginalization-models</link>
      <description><![CDATA[We introduce marginalization models (MaMs), a new family of generative models for high-dimensional discrete data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-marginalization-models</guid>
    </item>
    <item>
      <title>Predicting a Protein's Stability under a Million Mutations</title>
      <link>https://paperswithcode.com/paper/predicting-a-protein-s-stability-under-a</link>
      <description><![CDATA[We build Mutate Everything on top of ESM2 and AlphaFold, neither of which were trained to predict thermodynamic stability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/predicting-a-protein-s-stability-under-a</guid>
    </item>
    <item>
      <title>Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model</title>
      <link>https://paperswithcode.com/paper/identifying-and-adapting-transformer</link>
      <description><![CDATA[Language models (LMs) exhibit and amplify many types of undesirable biases learned from the training data, including gender bias.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/identifying-and-adapting-transformer</guid>
    </item>
    <item>
      <title>Attack Prompt Generation for Red Teaming and Defending Large Language Models</title>
      <link>https://paperswithcode.com/paper/attack-prompt-generation-for-red-teaming-and</link>
      <description><![CDATA[Furthermore, we propose a defense framework that fine-tunes victim LLMs through iterative interactions with the attack framework to enhance their safety against red teaming attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attack-prompt-generation-for-red-teaming-and</guid>
    </item>
    <item>
      <title>Time-Aware Representation Learning for Time-Sensitive Question Answering</title>
      <link>https://paperswithcode.com/paper/time-aware-representation-learning-for-time</link>
      <description><![CDATA[The model is trained to extract the answer span from the sentence that is both correct in time and context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/time-aware-representation-learning-for-time</guid>
    </item>
    <item>
      <title>Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning</title>
      <link>https://paperswithcode.com/paper/survival-of-the-most-influential-prompts</link>
      <description><![CDATA[Prompt-based learning has been an effective paradigm for large pretrained language models (LLM), enabling few-shot or even zero-shot learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/survival-of-the-most-influential-prompts</guid>
    </item>
    <item>
      <title>Pretraining Language Models with Text-Attributed Heterogeneous Graphs</title>
      <link>https://paperswithcode.com/paper/pretraining-language-models-with-text</link>
      <description><![CDATA[In many real-world scenarios (e. g., academic networks, social platforms), different types of entities are not only associated with texts but also connected by various relationships, which can be abstracted as Text-Attributed Heterogeneous Graphs (TAHGs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pretraining-language-models-with-text</guid>
    </item>
    <item>
      <title>Causal Similarity-Based Hierarchical Bayesian Models</title>
      <link>https://paperswithcode.com/paper/causal-similarity-based-hierarchical-bayesian</link>
      <description><![CDATA[Common approaches for learning supervised models with heterogeneous datasets include learning a global model for the entire dataset, learning local models for each tasks' data, or utilising hierarchical, meta-learning and multi-task learning approaches to learn how to generalise from data pooled across multiple tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causal-similarity-based-hierarchical-bayesian</guid>
    </item>
    <item>
      <title>FinEntity: Entity-level Sentiment Classification for Financial Texts</title>
      <link>https://paperswithcode.com/paper/finentity-entity-level-sentiment</link>
      <description><![CDATA[In this work, we introduce an entity-level sentiment classification dataset, called \textbf{FinEntity}, that annotates financial entity spans and their sentiment (positive, neutral, and negative) in financial news.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finentity-entity-level-sentiment</guid>
    </item>
    <item>
      <title>Testing the Consistency of Performance Scores Reported for Binary Classification Problems</title>
      <link>https://paperswithcode.com/paper/testing-the-consistency-of-performance-scores</link>
      <description><![CDATA[In this paper, we introduce numerical techniques to assess the consistency of reported performance scores and the assumed experimental setup.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/testing-the-consistency-of-performance-scores</guid>
    </item>
    <item>
      <title>SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation</title>
      <link>https://paperswithcode.com/paper/salun-empowering-machine-unlearning-via</link>
      <description><![CDATA[The resultant method that we call saliency unlearning (SalUn) narrows the performance gap with 'exact' unlearning (model retraining from scratch after removing the forgetting dataset).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/salun-empowering-machine-unlearning-via</guid>
    </item>
  </channel>
</rss>
