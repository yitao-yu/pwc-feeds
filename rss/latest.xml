<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 17 Mar 2024 09:10:46 +0000</lastBuildDate>
    <item>
      <title>GroupContrast: Semantic-aware Self-supervised Representation Learning for 3D Understanding</title>
      <link>https://paperswithcode.com/paper/groupcontrast-semantic-aware-self-supervised</link>
      <description><![CDATA[To address this issue, we propose GroupContrast, a novel approach that combines segment grouping and semantic-aware contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/groupcontrast-semantic-aware-self-supervised</guid>
    </item>
    <item>
      <title>Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/relaxing-accurate-initialization-constraint</link>
      <description><![CDATA[Through extensive analysis of SfM initialization in the frequency domain and analysis of a 1D regression task with multiple 1D Gaussians, we propose a novel optimization strategy dubbed RAIN-GS (Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting), that successfully trains 3D Gaussians from random point clouds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relaxing-accurate-initialization-constraint</guid>
    </item>
    <item>
      <title>Learning to optimize with convergence guarantees using nonlinear system theory</title>
      <link>https://paperswithcode.com/paper/learning-to-optimize-with-convergence</link>
      <description><![CDATA[The emerging paradigm of learning to optimize (L2O) automates the discovery of algorithms with optimized performance leveraging learning models and data - yet, it lacks a theoretical framework to analyze convergence and robustness of the learned algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-optimize-with-convergence</guid>
    </item>
    <item>
      <title>Don't Judge by the Look: A Motion Coherent Augmentation for Video Recognition</title>
      <link>https://paperswithcode.com/paper/don-t-judge-by-the-look-a-motion-coherent</link>
      <description><![CDATA[Current training pipelines in object recognition neglect Hue Jittering when doing data augmentation as it not only brings appearance changes that are detrimental to classification, but also the implementation is inefficient in practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-judge-by-the-look-a-motion-coherent</guid>
    </item>
    <item>
      <title>Faceptor: A Generalist Model for Face Perception</title>
      <link>https://paperswithcode.com/paper/faceptor-a-generalist-model-for-face</link>
      <description><![CDATA[This design enhances the unification of model structure while improving application efficiency in terms of storage overhead.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/faceptor-a-generalist-model-for-face</guid>
    </item>
    <item>
      <title>Eta Inversion: Designing an Optimal Eta Function for Diffusion-based Real Image Editing</title>
      <link>https://paperswithcode.com/paper/eta-inversion-designing-an-optimal-eta</link>
      <description><![CDATA[A commonly adopted strategy for editing real images involves inverting the diffusion process to obtain a noisy representation of the original image, which is then denoised to achieve the desired edits.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eta-inversion-designing-an-optimal-eta</guid>
    </item>
    <item>
      <title>Deep Limit Order Book Forecasting</title>
      <link>https://paperswithcode.com/paper/deep-limit-order-book-forecasting</link>
      <description><![CDATA[We exploit cutting-edge deep learning methodologies to explore the predictability of high-frequency Limit Order Book mid-price changes for a heterogeneous set of stocks traded on the NASDAQ exchange.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-limit-order-book-forecasting</guid>
    </item>
    <item>
      <title>Semiparametric Token-Sequence Co-Supervision</title>
      <link>https://paperswithcode.com/paper/semiparametric-token-sequence-co-supervision</link>
      <description><![CDATA[Especially, the robustness of parametric token space which is established during the pretraining step tends to effectively enhance the stability of nonparametric sequence embedding space, a new space established by another language model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semiparametric-token-sequence-co-supervision</guid>
    </item>
    <item>
      <title>Reawakening knowledge: Anticipatory recovery from catastrophic interference via structured training</title>
      <link>https://paperswithcode.com/paper/reawakening-knowledge-anticipatory-recovery</link>
      <description><![CDATA[We explore the training dynamics of neural networks in a structured non-IID setting where documents are presented cyclically in a fixed, repeated sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reawakening-knowledge-anticipatory-recovery</guid>
    </item>
    <item>
      <title>Uncertainty Quantification for cross-subject Motor Imagery classification</title>
      <link>https://paperswithcode.com/paper/uncertainty-quantification-for-cross-subject</link>
      <description><![CDATA[We applied a variety of Uncertainty Quantification methods to predict misclassifications for a Motor Imagery Brain Computer Interface.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncertainty-quantification-for-cross-subject</guid>
    </item>
    <item>
      <title>Unveiling the Generalization Power of Fine-Tuned Large Language Models</title>
      <link>https://paperswithcode.com/paper/unveiling-the-generalization-power-of-fine</link>
      <description><![CDATA[While Large Language Models (LLMs) have demonstrated exceptional multitasking abilities, fine-tuning these models on downstream, domain-specific datasets is often necessary to yield superior performance on test sets compared to their counterparts without fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unveiling-the-generalization-power-of-fine</guid>
    </item>
    <item>
      <title>LocalMamba: Visual State Space Model with Windowed Selective Scan</title>
      <link>https://paperswithcode.com/paper/localmamba-visual-state-space-model-with</link>
      <description><![CDATA[This paper posits that the key to enhancing Vision Mamba (ViM) lies in optimizing scan directions for sequence modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/localmamba-visual-state-space-model-with</guid>
    </item>
    <item>
      <title>Adversarial Fine-tuning of Compressed Neural Networks for Joint Improvement of Robustness and Efficiency</title>
      <link>https://paperswithcode.com/paper/adversarial-fine-tuning-of-compressed-neural</link>
      <description><![CDATA[We present experiments on two benchmark datasets showing that adversarial fine-tuning of compressed models can achieve robustness performance comparable to adversarially trained models, while also improving computational efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-fine-tuning-of-compressed-neural</guid>
    </item>
    <item>
      <title>AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting</title>
      <link>https://paperswithcode.com/paper/adashield-safeguarding-multimodal-large</link>
      <description><![CDATA[However, with the integration of additional modalities, MLLMs are exposed to new vulnerabilities, rendering them prone to structured-based jailbreak attacks, where semantic content (e. g., "harmful text") has been injected into the images to mislead MLLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adashield-safeguarding-multimodal-large</guid>
    </item>
    <item>
      <title>VM-UNET-V2 Rethinking Vision Mamba UNet for Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/vm-unet-v2-rethinking-vision-mamba-unet-for</link>
      <description><![CDATA[In the field of medical image segmentation, models based on both CNN and Transformer have been thoroughly investigated.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vm-unet-v2-rethinking-vision-mamba-unet-for</guid>
    </item>
    <item>
      <title>DiTMoS: Delving into Diverse Tiny-Model Selection on Microcontrollers</title>
      <link>https://paperswithcode.com/paper/ditmos-delving-into-diverse-tiny-model</link>
      <description><![CDATA[Enabling efficient and accurate deep neural network (DNN) inference on microcontrollers is non-trivial due to the constrained on-chip resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ditmos-delving-into-diverse-tiny-model</guid>
    </item>
    <item>
      <title>Score-Guided Diffusion for 3D Human Recovery</title>
      <link>https://paperswithcode.com/paper/score-guided-diffusion-for-3d-human-recovery</link>
      <description><![CDATA[We present Score-Guided Human Mesh Recovery (ScoreHMR), an approach for solving inverse problems for 3D human pose and shape reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/score-guided-diffusion-for-3d-human-recovery</guid>
    </item>
    <item>
      <title>SkateFormer: Skeletal-Temporal Transformer for Human Action Recognition</title>
      <link>https://paperswithcode.com/paper/skateformer-skeletal-temporal-transformer-for</link>
      <description><![CDATA[We categorize the key skeletal-temporal relations for action recognition into a total of four distinct types.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/skateformer-skeletal-temporal-transformer-for</guid>
    </item>
    <item>
      <title>PreSight: Enhancing Autonomous Vehicle Perception with City-Scale NeRF Priors</title>
      <link>https://paperswithcode.com/paper/presight-enhancing-autonomous-vehicle</link>
      <description><![CDATA[Autonomous vehicles rely extensively on perception systems to navigate and interpret their surroundings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/presight-enhancing-autonomous-vehicle</guid>
    </item>
    <item>
      <title>Large Language Models are Parallel Multilingual Learners</title>
      <link>https://paperswithcode.com/paper/large-language-models-are-parallel</link>
      <description><![CDATA[In this study, we reveal an in-context learning (ICL) capability of multilingual large language models (LLMs): by translating the input to several languages, we provide Parallel Input in Multiple Languages (PiM) to LLMs, which significantly enhances their comprehension abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-are-parallel</guid>
    </item>
    <item>
      <title>Gradient-Aware Logit Adjustment Loss for Long-tailed Classifier</title>
      <link>https://paperswithcode.com/paper/gradient-aware-logit-adjustment-loss-for-long</link>
      <description><![CDATA[Additionally, We find that most of the solutions to long-tailed problems are still biased towards head classes in the end, and we propose a simple and post hoc prediction re-balancing strategy to further mitigate the basis toward head class.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gradient-aware-logit-adjustment-loss-for-long</guid>
    </item>
    <item>
      <title>uaMix-MAE: Efficient Tuning of Pretrained Audio Transformers with Unsupervised Audio Mixtures</title>
      <link>https://paperswithcode.com/paper/uamix-mae-efficient-tuning-of-pretrained</link>
      <description><![CDATA[Masked Autoencoders (MAEs) learn rich low-level representations from unlabeled data but require substantial labeled data to effectively adapt to downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uamix-mae-efficient-tuning-of-pretrained</guid>
    </item>
    <item>
      <title>SpikeReveal: Unlocking Temporal Sequences from Real Blurry Inputs with Spike Streams</title>
      <link>https://paperswithcode.com/paper/spikereveal-unlocking-temporal-sequences-from</link>
      <description><![CDATA[Our approach begins with the formulation of a spike-guided deblurring model that explores the theoretical relationships among spike streams, blurry images, and their corresponding sharp sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spikereveal-unlocking-temporal-sequences-from</guid>
    </item>
    <item>
      <title>OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments</title>
      <link>https://paperswithcode.com/paper/opengraph-open-vocabulary-hierarchical-3d</link>
      <description><![CDATA[Environment maps endowed with sophisticated semantics are pivotal for facilitating seamless interaction between robots and humans, enabling them to effectively carry out various tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/opengraph-open-vocabulary-hierarchical-3d</guid>
    </item>
    <item>
      <title>Generalized Predictive Model for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/generalized-predictive-model-for-autonomous</link>
      <description><![CDATA[In this paper, we introduce the first large-scale video prediction model in the autonomous driving discipline.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-predictive-model-for-autonomous</guid>
    </item>
    <item>
      <title>Counterfactual contrastive learning: robust representations via causal image synthesis</title>
      <link>https://paperswithcode.com/paper/counterfactual-contrastive-learning-robust</link>
      <description><![CDATA[Contrastive pretraining is well-known to improve downstream task performance and model generalisation, especially in limited label settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-contrastive-learning-robust</guid>
    </item>
    <item>
      <title>CardioCaps: Attention-based Capsule Network for Class-Imbalanced Echocardiogram Classification</title>
      <link>https://paperswithcode.com/paper/cardiocaps-attention-based-capsule-network</link>
      <description><![CDATA[In this paper, we explore the potential of DR-CapsNets and propose CardioCaps, a novel attention-based DR-CapsNet architecture for class-imbalanced echocardiogram classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cardiocaps-attention-based-capsule-network</guid>
    </item>
    <item>
      <title>EventRPG: Event Data Augmentation with Relevance Propagation Guidance</title>
      <link>https://paperswithcode.com/paper/eventrpg-event-data-augmentation-with</link>
      <description><![CDATA[Based on this, we propose EventRPG, which leverages relevance propagation on the spiking neural network for more efficient augmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eventrpg-event-data-augmentation-with</guid>
    </item>
    <item>
      <title>Pantypes: Diverse Representatives for Self-Explainable Models</title>
      <link>https://paperswithcode.com/paper/pantypes-diverse-representatives-for-self</link>
      <description><![CDATA[Prototypical self-explainable classifiers have emerged to meet the growing demand for interpretable AI systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pantypes-diverse-representatives-for-self</guid>
    </item>
    <item>
      <title>GiT: Towards Generalist Vision Transformer through Universal Language Interface</title>
      <link>https://paperswithcode.com/paper/git-towards-generalist-vision-transformer</link>
      <description><![CDATA[Due to its simple design, this paradigm holds promise for narrowing the architectural gap between vision and language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/git-towards-generalist-vision-transformer</guid>
    </item>
    <item>
      <title>StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control</title>
      <link>https://paperswithcode.com/paper/streammultidiffusion-real-time-interactive</link>
      <description><![CDATA[The enormous success of diffusion models in text-to-image synthesis has made them promising candidates for the next generation of end-user applications for image generation and editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streammultidiffusion-real-time-interactive</guid>
    </item>
    <item>
      <title>EfficientMFD: Towards More Efficient Multimodal Synchronous Fusion Detection</title>
      <link>https://paperswithcode.com/paper/efficientmfd-towards-more-efficient</link>
      <description><![CDATA[Multimodal image fusion and object detection play a vital role in autonomous driving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficientmfd-towards-more-efficient</guid>
    </item>
    <item>
      <title>Are Vision Language Models Texture or Shape Biased and Can We Steer Them?</title>
      <link>https://paperswithcode.com/paper/are-vision-language-models-texture-or-shape</link>
      <description><![CDATA[If text does indeed influence visual biases, this suggests that we may be able to steer visual biases not just through visual input but also through language: a hypothesis that we confirm through extensive experiments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/are-vision-language-models-texture-or-shape</guid>
    </item>
    <item>
      <title>SD-Net: Symmetric-Aware Keypoint Prediction and Domain Adaptation for 6D Pose Estimation In Bin-picking Scenarios</title>
      <link>https://paperswithcode.com/paper/sd-net-symmetric-aware-keypoint-prediction</link>
      <description><![CDATA[Specifically, at the keypoint prediction stage, we designe a robust 3D keypoints selection strategy considering the symmetry class of objects and equivalent keypoints, which facilitate locating 3D keypoints even in highly occluded scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sd-net-symmetric-aware-keypoint-prediction</guid>
    </item>
    <item>
      <title>Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision</title>
      <link>https://paperswithcode.com/paper/easy-to-hard-generalization-scalable</link>
      <description><![CDATA[This paper answers this question in the context of tackling hard reasoning tasks (e. g., level 4-5 MATH problems) via learning from human annotations on easier tasks (e. g., level 1-3 MATH problems), which we term as \textit{easy-to-hard generalization}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easy-to-hard-generalization-scalable</guid>
    </item>
    <item>
      <title>Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking</title>
      <link>https://paperswithcode.com/paper/quiet-star-language-models-can-teach</link>
      <description><![CDATA[Crucially, these improvements require no fine-tuning on these tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quiet-star-language-models-can-teach</guid>
    </item>
    <item>
      <title>Recursive Causal Discovery</title>
      <link>https://paperswithcode.com/paper/recursive-causal-discovery</link>
      <description><![CDATA[Presence and identification of removable variables allow recursive approaches for causal discovery, a promising solution that helps to address the aforementioned challenges by reducing the problem size successively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recursive-causal-discovery</guid>
    </item>
    <item>
      <title>S^2MVTC: a Simple yet Efficient Scalable Multi-View Tensor Clustering</title>
      <link>https://paperswithcode.com/paper/s-2mvtc-a-simple-yet-efficient-scalable-multi</link>
      <description><![CDATA[Specifically, we first construct the embedding feature tensor by stacking the embedding features of different views into a tensor and rotating it.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s-2mvtc-a-simple-yet-efficient-scalable-multi</guid>
    </item>
    <item>
      <title>Transformers Get Stable: An End-to-End Signal Propagation Theory for Language Models</title>
      <link>https://paperswithcode.com/paper/transformers-get-stable-an-end-to-end-signal</link>
      <description><![CDATA[In spite of their huge success, transformer models remain difficult to scale in depth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformers-get-stable-an-end-to-end-signal</guid>
    </item>
    <item>
      <title>The First to Know: How Token Distributions Reveal Hidden Knowledge in Large Vision-Language Models?</title>
      <link>https://paperswithcode.com/paper/the-first-to-know-how-token-distributions</link>
      <description><![CDATA[This study uses linear probing to shed light on the hidden knowledge at the output layer of LVLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-first-to-know-how-token-distributions</guid>
    </item>
    <item>
      <title>SELECTOR: Heterogeneous graph network with convolutional masked autoencoder for multimodal robust prediction of cancer survival</title>
      <link>https://paperswithcode.com/paper/selector-heterogeneous-graph-network-with</link>
      <description><![CDATA[To mitigate the impact of missing features within the modality on prediction accuracy, we devised a convolutional masked autoencoder (CMAE) to process the heterogeneous graph post-feature reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/selector-heterogeneous-graph-network-with</guid>
    </item>
    <item>
      <title>TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Sematic Tasks</title>
      <link>https://paperswithcode.com/paper/taxollama-wordnet-based-model-for-solving</link>
      <description><![CDATA[It achieves 11 SotA results, 4 top-2 results out of 16 tasks for the Taxonomy Enrichment, Hypernym Discovery, Taxonomy Construction, and Lexical Entailment tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taxollama-wordnet-based-model-for-solving</guid>
    </item>
    <item>
      <title>StainFuser: Controlling Diffusion for Faster Neural Style Transfer in Multi-Gigapixel Histology Images</title>
      <link>https://paperswithcode.com/paper/stainfuser-controlling-diffusion-for-faster</link>
      <description><![CDATA[Stain normalization algorithms aim to transform the color and intensity characteristics of a source multi-gigapixel histology image to match those of a target image, mitigating inconsistencies in the appearance of stains used to highlight cellular components in the images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stainfuser-controlling-diffusion-for-faster</guid>
    </item>
    <item>
      <title>Mixture of Mixups for Multi-label Classification of Rare Anuran Sounds</title>
      <link>https://paperswithcode.com/paper/mixture-of-mixups-for-multi-label</link>
      <description><![CDATA[Multi-label imbalanced classification poses a significant challenge in machine learning, particularly evident in bioacoustics where animal sounds often co-occur, and certain sounds are much less frequent than others.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixture-of-mixups-for-multi-label</guid>
    </item>
    <item>
      <title>Towards a theory of model distillation</title>
      <link>https://paperswithcode.com/paper/towards-a-theory-of-model-distillation</link>
      <description><![CDATA[Distillation is the task of replacing a complicated machine learning model with a simpler model that approximates the original [BCNM06, HVD15].]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-a-theory-of-model-distillation</guid>
    </item>
    <item>
      <title>Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding</title>
      <link>https://paperswithcode.com/paper/video-mamba-suite-state-space-model-as-a</link>
      <description><![CDATA[We categorize Mamba into four roles for modeling videos, deriving a Video Mamba Suite composed of 14 models/modules, and evaluating them on 12 video understanding tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-mamba-suite-state-space-model-as-a</guid>
    </item>
    <item>
      <title>CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences</title>
      <link>https://paperswithcode.com/paper/codeultrafeedback-an-llm-as-a-judge-dataset</link>
      <description><![CDATA[We generate responses to the instructions using a pool of 14 diverse LLMs, which we then annotate according to their alignment with five coding preferences using the LLM-as-a-Judge approach with GPT-3. 5, producing both numerical and textual feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codeultrafeedback-an-llm-as-a-judge-dataset</guid>
    </item>
    <item>
      <title>BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences</title>
      <link>https://paperswithcode.com/paper/burstattention-an-efficient-distributed</link>
      <description><![CDATA[Effective attention modules have played a crucial role in the success of Transformer-based large language models (LLMs), but the quadratic time and memory complexities of these attention modules also pose a challenge when processing long sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/burstattention-an-efficient-distributed</guid>
    </item>
    <item>
      <title>Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring</title>
      <link>https://paperswithcode.com/paper/griffon-v2-advancing-multimodal-perception</link>
      <description><![CDATA[Large Vision Language Models have achieved fine-grained object perception, but the limitation of image resolution remains a significant obstacle to surpass the performance of task-specific experts in complex and dense scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/griffon-v2-advancing-multimodal-perception</guid>
    </item>
    <item>
      <title>Clinical Reasoning over Tabular Data and Text with Bayesian Networks</title>
      <link>https://paperswithcode.com/paper/clinical-reasoning-over-tabular-data-and-text</link>
      <description><![CDATA[Bayesian networks are well-suited for clinical reasoning on tabular data, but are less compatible with natural language data, for which neural networks provide a successful framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clinical-reasoning-over-tabular-data-and-text</guid>
    </item>
  </channel>
</rss>
