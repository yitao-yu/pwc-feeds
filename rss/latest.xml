<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 05 Sep 2024 21:08:28 +0000</lastBuildDate>
    <item>
      <title>StyleTokenizer: Defining Image Style by a Single Instance for Controlling Diffusion Models</title>
      <link>https://paperswithcode.com/paper/styletokenizer-defining-image-style-by-a</link>
      <description><![CDATA[To tackle these challenges, we introduce StyleTokenizer, a zero-shot style control image generation method that aligns style representation with text representation using a style tokenizer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/styletokenizer-defining-image-style-by-a</guid>
    </item>
    <item>
      <title>TP-GMOT: Tracking Generic Multiple Object by Textual Prompt with Motion-Appearance Cost (MAC) SORT</title>
      <link>https://paperswithcode.com/paper/tp-gmot-tracking-generic-multiple-object-by</link>
      <description><![CDATA[While Multi-Object Tracking (MOT) has made substantial advancements, it is limited by heavy reliance on prior knowledge and limited to predefined categories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tp-gmot-tracking-generic-multiple-object-by</guid>
    </item>
    <item>
      <title>Hybrid-Segmentor: A Hybrid Approach to Automated Fine-Grained Crack Segmentation in Civil Infrastructure</title>
      <link>https://paperswithcode.com/paper/hybrid-segmentor-a-hybrid-approach-to</link>
      <description><![CDATA[Detecting and segmenting cracks in infrastructure, such as roads and buildings, is crucial for safety and cost-effective maintenance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hybrid-segmentor-a-hybrid-approach-to</guid>
    </item>
    <item>
      <title>Detecting Korean Food Using Image using Hierarchical Model</title>
      <link>https://paperswithcode.com/paper/detecting-korean-food-using-image-using</link>
      <description><![CDATA[A solution was made available for Korean Food lovers who have dietary restrictions to identify the Korean food before consuming.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detecting-korean-food-using-image-using</guid>
    </item>
    <item>
      <title>Hypothesizing Missing Causal Variables with LLMs</title>
      <link>https://paperswithcode.com/paper/hypothesizing-missing-causal-variables-with</link>
      <description><![CDATA[Motivated by the scientific discovery process, in this work, we formulate a novel task where the input is a partial causal graph with missing variables, and the output is a hypothesis about the missing variables to complete the partial graph.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hypothesizing-missing-causal-variables-with</guid>
    </item>
    <item>
      <title>Benchmarking Spurious Bias in Few-Shot Image Classifiers</title>
      <link>https://paperswithcode.com/paper/benchmarking-spurious-bias-in-few-shot-image</link>
      <description><![CDATA[In this paper, we propose a systematic and rigorous benchmark framework, termed FewSTAB, to fairly demonstrate and quantify varied degrees of robustness of few-shot classifiers to spurious bias.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-spurious-bias-in-few-shot-image</guid>
    </item>
    <item>
      <title>Pooling And Attention: What Are Effective Designs For LLm-Based Embedding Models?</title>
      <link>https://paperswithcode.com/paper/pooling-and-attention-what-are-effective</link>
      <description><![CDATA[While these models, employing different pooling and attention strategies, have achieved state-of-the-art performance on public embedding benchmarks, questions still arise about what constitutes an effective design for LLM-based embedding models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pooling-and-attention-what-are-effective</guid>
    </item>
    <item>
      <title>SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments</title>
      <link>https://paperswithcode.com/paper/surgtrack-cad-free-3d-tracking-of-real-world</link>
      <description><![CDATA[Compared with 2D instrument tracking methods, 3D instrument tracking has broader value in clinical practice, but is also more challenging due to weak texture, occlusion, and lack of Computer-Aided Design (CAD) models for 3D registration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surgtrack-cad-free-3d-tracking-of-real-world</guid>
    </item>
    <item>
      <title>LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture</title>
      <link>https://paperswithcode.com/paper/longllava-scaling-multi-modal-llms-to-1000</link>
      <description><![CDATA[Expanding the long-context capabilities of Multi-modal Large Language Models~(MLLMs) is crucial for video understanding, high-resolution image understanding, and multi-modal agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longllava-scaling-multi-modal-llms-to-1000</guid>
    </item>
    <item>
      <title>AdvSecureNet: A Python Toolkit for Adversarial Machine Learning</title>
      <link>https://paperswithcode.com/paper/advsecurenet-a-python-toolkit-for-adversarial</link>
      <description><![CDATA[We introduce AdvSecureNet, a PyTorch based toolkit for adversarial machine learning that is the first to natively support multi-GPU setups for attacks, defenses, and evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advsecurenet-a-python-toolkit-for-adversarial</guid>
    </item>
    <item>
      <title>Topological Methods in Machine Learning: A Tutorial for Practitioners</title>
      <link>https://paperswithcode.com/paper/topological-methods-in-machine-learning-a</link>
      <description><![CDATA[Topological Machine Learning (TML) is an emerging field that leverages techniques from algebraic topology to analyze complex data structures in ways that traditional machine learning methods may not capture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/topological-methods-in-machine-learning-a</guid>
    </item>
    <item>
      <title>UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views</title>
      <link>https://paperswithcode.com/paper/uc-nerf-uncertainty-aware-conditional-neural</link>
      <description><![CDATA[In neural rendering, we design a base-adaptive NeRF network to exploit the uncertainty estimation for explicitly handling the photometric inconsistencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uc-nerf-uncertainty-aware-conditional-neural</guid>
    </item>
    <item>
      <title>Oops, I Sampled it Again: Reinterpreting Confidence Intervals in Few-Shot Learning</title>
      <link>https://paperswithcode.com/paper/oops-i-sampled-it-again-reinterpreting</link>
      <description><![CDATA[The predominant method for computing confidence intervals (CI) in few-shot learning (FSL) is based on sampling the tasks with replacement, i. e.\ allowing the same samples to appear in multiple tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oops-i-sampled-it-again-reinterpreting</guid>
    </item>
    <item>
      <title>MAPF-GPT: Imitation Learning for Multi-Agent Pathfinding at Scale</title>
      <link>https://paperswithcode.com/paper/mapf-gpt-imitation-learning-for-multi-agent</link>
      <description><![CDATA[The resulting MAPF-GPT model demonstrates zero-shot learning abilities when solving the MAPF problem instances that were not present in the training dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mapf-gpt-imitation-learning-for-multi-agent</guid>
    </item>
    <item>
      <title>HiPrompt: Tuning-free Higher-Resolution Generation with Hierarchical MLLM Prompts</title>
      <link>https://paperswithcode.com/paper/hiprompt-tuning-free-higher-resolution</link>
      <description><![CDATA[The hierarchical prompts offer both global and local guidance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hiprompt-tuning-free-higher-resolution</guid>
    </item>
    <item>
      <title>AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction</title>
      <link>https://paperswithcode.com/paper/agentre-an-agent-based-framework-for</link>
      <description><![CDATA[The relation extraction (RE) in complex scenarios faces challenges such as diverse relation types and ambiguous relations between entities within a single sentence, leading to the poor performance of pure "text-in, text-out" language models (LMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentre-an-agent-based-framework-for</guid>
    </item>
    <item>
      <title>Map-Assisted Remote-Sensing Image Compression at Extremely Low Bitrates</title>
      <link>https://paperswithcode.com/paper/map-assisted-remote-sensing-image-compression</link>
      <description><![CDATA[However, these generative models struggle to reconstruct visually plausible images due to the highly ill-posed nature of extremely low-bitrate image compression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/map-assisted-remote-sensing-image-compression</guid>
    </item>
    <item>
      <title>EPRecon: An Efficient Framework for Real-Time Panoptic 3D Reconstruction from Monocular Video</title>
      <link>https://paperswithcode.com/paper/eprecon-an-efficient-framework-for-real-time</link>
      <description><![CDATA[To end this, we propose a lightweight module to directly estimate scene depth priors in a 3D volume for reconstruction quality improvement by generating occupancy probabilities of all voxels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eprecon-an-efficient-framework-for-real-time</guid>
    </item>
    <item>
      <title>FC-KAN: Function Combinations in Kolmogorov-Arnold Networks</title>
      <link>https://paperswithcode.com/paper/fc-kan-function-combinations-in-kolmogorov</link>
      <description><![CDATA[In this paper, we introduce FC-KAN, a Kolmogorov-Arnold Network (KAN) that leverages combinations of popular mathematical functions such as B-splines, wavelets, and radial basis functions on low-dimensional data through element-wise operations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fc-kan-function-combinations-in-kolmogorov</guid>
    </item>
    <item>
      <title>Taming CLIP for Fine-grained and Structured Visual Understanding of Museum Exhibits</title>
      <link>https://paperswithcode.com/paper/taming-clip-for-fine-grained-and-structured</link>
      <description><![CDATA[In this work, we aim to adapt CLIP for fine-grained and structured -- in the form of tabular data -- visual understanding of museum exhibits.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taming-clip-for-fine-grained-and-structured</guid>
    </item>
    <item>
      <title>Dual Advancement of Representation Learning and Clustering for Sparse and Noisy Images</title>
      <link>https://paperswithcode.com/paper/dual-advancement-of-representation-learning</link>
      <description><![CDATA[Sparse and noisy images (SNIs), like those in spatial gene expression data, pose significant challenges for effective representation learning and clustering, which are essential for thorough data analysis and interpretation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-advancement-of-representation-learning</guid>
    </item>
    <item>
      <title>Application of Langevin Dynamics to Advance the Quantum Natural Gradient Optimization Algorithm</title>
      <link>https://paperswithcode.com/paper/application-of-langevin-dynamics-to-advance</link>
      <description><![CDATA[A Quantum Natural Gradient (QNG) algorithm for optimization of variational quantum circuits has been proposed recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/application-of-langevin-dynamics-to-advance</guid>
    </item>
    <item>
      <title>LinFusion: 1 GPU, 1 Minute, 16K Image</title>
      <link>https://paperswithcode.com/paper/linfusion-1-gpu-1-minute-16k-image</link>
      <description><![CDATA[We find that the distilled model, termed LinFusion, achieves performance on par with or superior to the original SD after only modest training, while significantly reducing time and memory complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linfusion-1-gpu-1-minute-16k-image</guid>
    </item>
    <item>
      <title>Buffer-based Gradient Projection for Continual Federated Learning</title>
      <link>https://paperswithcode.com/paper/buffer-based-gradient-projection-for</link>
      <description><![CDATA[For example, in a task-incremental learning scenario using the CIFAR-100 dataset, our method can increase the accuracy by up to 27%.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/buffer-based-gradient-projection-for</guid>
    </item>
    <item>
      <title>Foundations of Large Language Model Compression -- Part 1: Weight Quantization</title>
      <link>https://paperswithcode.com/paper/foundations-of-large-language-model</link>
      <description><![CDATA[In recent years, compression of large language models (LLMs) has emerged as an important problem to allow language model deployment on resource-constrained devices, reduce computational costs, and mitigate the environmental footprint of large-scale AI infrastructure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundations-of-large-language-model</guid>
    </item>
    <item>
      <title>Unveiling Deep Shadows: A Survey on Image and Video Shadow Detection, Removal, and Generation in the Era of Deep Learning</title>
      <link>https://paperswithcode.com/paper/unveiling-deep-shadows-a-survey-on-image-and</link>
      <description><![CDATA[Shadows are formed when light encounters obstacles, leading to areas of diminished illumination.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unveiling-deep-shadows-a-survey-on-image-and</guid>
    </item>
    <item>
      <title>Unveiling Advanced Frequency Disentanglement Paradigm for Low-Light Image Enhancement</title>
      <link>https://paperswithcode.com/paper/unveiling-advanced-frequency-disentanglement</link>
      <description><![CDATA[Previous low-light image enhancement (LLIE) approaches, while employing frequency decomposition techniques to address the intertwined challenges of low frequency (e. g., illumination recovery) and high frequency (e. g., noise reduction), primarily focused on the development of dedicated and complex networks to achieve improved performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unveiling-advanced-frequency-disentanglement</guid>
    </item>
    <item>
      <title>Boosting Vision-Language Models for Histopathology Classification: Predict all at once</title>
      <link>https://paperswithcode.com/paper/boosting-vision-language-models-for</link>
      <description><![CDATA[The development of vision-language models (VLMs) for histo-pathology has shown promising new usages and zero-shot performances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-vision-language-models-for</guid>
    </item>
    <item>
      <title>Stacked ensemble\-based mutagenicity prediction model using multiple modalities with graph attention network</title>
      <link>https://paperswithcode.com/paper/stacked-ensemble-based-mutagenicity</link>
      <description><![CDATA[Notably, we achieve an area under the curve of 95. 21\% on the Hansen benchmark dataset, affirming the efficacy of our method in predicting mutagenicity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stacked-ensemble-based-mutagenicity</guid>
    </item>
    <item>
      <title>SpannerLib: Embedding Declarative Information Extraction in an Imperative Workflow</title>
      <link>https://paperswithcode.com/paper/spannerlib-embedding-declarative-information</link>
      <description><![CDATA[This demonstration presents SpannerLib a library for embedding document spanners in Python code.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spannerlib-embedding-declarative-information</guid>
    </item>
    <item>
      <title>Booster: Tackling Harmful Fine-tuing for Large Language Models via Attenuating Harmful Perturbation</title>
      <link>https://paperswithcode.com/paper/booster-tackling-harmful-fine-tuing-for-large</link>
      <description><![CDATA[For the first time in the literature, we in this paper show that \textit{harmful perturbation} over the model weights should be the root cause of alignment-broken of harmful fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/booster-tackling-harmful-fine-tuing-for-large</guid>
    </item>
    <item>
      <title>Frequency-Spatial Entanglement Learning for Camouflaged Object Detection</title>
      <link>https://paperswithcode.com/paper/frequency-spatial-entanglement-learning-for</link>
      <description><![CDATA[Camouflaged object detection has attracted a lot of attention in computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/frequency-spatial-entanglement-learning-for</guid>
    </item>
    <item>
      <title>LSTMSE-Net: Long Short Term Speech Enhancement Network for Audio-visual Speech Enhancement</title>
      <link>https://paperswithcode.com/paper/lstmse-net-long-short-term-speech-enhancement</link>
      <description><![CDATA[The system scales and concatenates visual and audio features, then processes them through a separator network for optimized speech enhancement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lstmse-net-long-short-term-speech-enhancement</guid>
    </item>
    <item>
      <title>SPiKE: 3D Human Pose from Point Cloud Sequences</title>
      <link>https://paperswithcode.com/paper/spike-3d-human-pose-from-point-cloud</link>
      <description><![CDATA[3D Human Pose Estimation (HPE) is the task of locating keypoints of the human body in 3D space from 2D or 3D representations such as RGB images, depth maps or point clouds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spike-3d-human-pose-from-point-cloud</guid>
    </item>
    <item>
      <title>When Does Visual Prompting Outperform Linear Probing for Vision-Language Models? A Likelihood Perspective</title>
      <link>https://paperswithcode.com/paper/when-does-visual-prompting-outperform-linear</link>
      <description><![CDATA[Adapting pre-trained models to new tasks can exhibit varying effectiveness across datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-does-visual-prompting-outperform-linear</guid>
    </item>
    <item>
      <title>Speech Foundation Model Ensembles for the Controlled Singing Voice Deepfake Detection (CtrSVDD) Challenge 2024</title>
      <link>https://paperswithcode.com/paper/speech-foundation-model-ensembles-for-the</link>
      <description><![CDATA[This work details our approach to achieving a leading system with a 1. 79% pooled equal error rate (EER) on the evaluation set of the Controlled Singing Voice Deepfake Detection (CtrSVDD).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/speech-foundation-model-ensembles-for-the</guid>
    </item>
    <item>
      <title>PMLBmini: A Tabular Classification Benchmark Suite for Data-Scarce Applications</title>
      <link>https://paperswithcode.com/paper/pmlbmini-a-tabular-classification-benchmark</link>
      <description><![CDATA[In practice, we are often faced with small-sized tabular data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pmlbmini-a-tabular-classification-benchmark</guid>
    </item>
    <item>
      <title>Latent Distillation for Continual Object Detection at the Edge</title>
      <link>https://paperswithcode.com/paper/latent-distillation-for-continual-object</link>
      <description><![CDATA[In this work, we address the memory and computation constraints of edge devices in the Continual Learning for Object Detection (CLOD) scenario.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-distillation-for-continual-object</guid>
    </item>
    <item>
      <title>PINNIES: An Efficient Physics-Informed Neural Network Framework to Integral Operator Problems</title>
      <link>https://paperswithcode.com/paper/pinnies-an-efficient-physics-informed-neural</link>
      <description><![CDATA[This paper introduces an efficient tensor-vector product technique for the rapid and accurate approximation of integral operators within physics-informed deep learning frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pinnies-an-efficient-physics-informed-neural</guid>
    </item>
    <item>
      <title>NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack Through White Gaussian Noise</title>
      <link>https://paperswithcode.com/paper/noiseattack-an-evasive-sample-specific-multi</link>
      <description><![CDATA[In these attacks, data can be manipulated to cause a trained model to behave improperly when a specific trigger pattern is applied, providing the adversary with unauthorized advantages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/noiseattack-an-evasive-sample-specific-multi</guid>
    </item>
    <item>
      <title>Segmenting Object Affordances: Reproducibility and Sensitivity to Scale</title>
      <link>https://paperswithcode.com/paper/segmenting-object-affordances-reproducibility</link>
      <description><![CDATA[Visual affordance segmentation identifies image regions of an object an agent can interact with.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segmenting-object-affordances-reproducibility</guid>
    </item>
    <item>
      <title>Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor</title>
      <link>https://paperswithcode.com/paper/exploiting-the-vulnerability-of-large</link>
      <description><![CDATA[We demonstrate that the training-free architectural backdoor on a large language model poses a genuine threat.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploiting-the-vulnerability-of-large</guid>
    </item>
    <item>
      <title>Understanding Multimodal Hallucination with Parameter-Free Representation Alignment</title>
      <link>https://paperswithcode.com/paper/understanding-multimodal-hallucination-with</link>
      <description><![CDATA[To analyze image representations while completely avoiding the influence of all other factors other than the image representation itself, we propose a parametric-free representation alignment metric (Pfram) that can measure the similarities between any two representation systems without requiring additional training parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-multimodal-hallucination-with</guid>
    </item>
    <item>
      <title>Towards Student Actions in Classroom Scenes: New Dataset and Baseline</title>
      <link>https://paperswithcode.com/paper/towards-student-actions-in-classroom-scenes</link>
      <description><![CDATA[In this paper, we present a new multi-label student action video (SAV) dataset for complex classroom scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-student-actions-in-classroom-scenes</guid>
    </item>
    <item>
      <title>Progressive Retinal Image Registration via Global and Local Deformable Transformations</title>
      <link>https://paperswithcode.com/paper/progressive-retinal-image-registration-via</link>
      <description><![CDATA[For that, we use a keypoint detector and a deformation network called GAMorph to estimate the global transformation and local deformable transformation, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progressive-retinal-image-registration-via</guid>
    </item>
    <item>
      <title>CMOB: Large-Scale Cancer Multi-Omics Benchmark with Open Datasets, Tasks, and Baselines</title>
      <link>https://paperswithcode.com/paper/cmob-large-scale-cancer-multi-omics-benchmark</link>
      <description><![CDATA[Machine learning has shown great potential in the field of cancer multi-omics studies, offering incredible opportunities for advancing precision medicine.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cmob-large-scale-cancer-multi-omics-benchmark</guid>
    </item>
    <item>
      <title>Kvasir-VQA: A Text-Image Pair GI Tract Dataset</title>
      <link>https://paperswithcode.com/paper/kvasir-vqa-a-text-image-pair-gi-tract-dataset</link>
      <description><![CDATA[We introduce Kvasir-VQA, an extended dataset derived from the HyperKvasir and Kvasir-Instrument datasets, augmented with question-and-answer annotations to facilitate advanced machine learning tasks in Gastrointestinal (GI) diagnostics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kvasir-vqa-a-text-image-pair-gi-tract-dataset</guid>
    </item>
    <item>
      <title>MV-Match: Multi-View Matching for Domain-Adaptive Identification of Plant Nutrient Deficiencies</title>
      <link>https://paperswithcode.com/paper/mv-match-multi-view-matching-for-domain</link>
      <description><![CDATA[Despite its relevance for practical applications, unsupervised domain adaptation where multiple views are available for the labeled source domain as well as the unlabeled target domain is an unexplored research area.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mv-match-multi-view-matching-for-domain</guid>
    </item>
    <item>
      <title>MobileIQA: Exploiting Mobile-level Diverse Opinion Network For No-Reference Image Quality Assessment Using Knowledge Distillation</title>
      <link>https://paperswithcode.com/paper/mobileiqa-exploiting-mobile-level-diverse</link>
      <description><![CDATA[With the rising demand for high-resolution (HR) images, No-Reference Image Quality Assessment (NR-IQA) gains more attention, as it can ecaluate image quality in real-time on mobile devices and enhance user experience.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobileiqa-exploiting-mobile-level-diverse</guid>
    </item>
    <item>
      <title>Personalized Lip Reading: Adapting to Your Unique Lip Movements with Vision and Language</title>
      <link>https://paperswithcode.com/paper/personalized-lip-reading-adapting-to-your</link>
      <description><![CDATA[To address this challenge, speaker adaptive lip reading technologies have advanced by focusing on effectively adapting a lip reading model to target speakers in the visual modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalized-lip-reading-adapting-to-your</guid>
    </item>
  </channel>
</rss>
