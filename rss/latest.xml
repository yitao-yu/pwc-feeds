<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 12 Aug 2023 21:04:41 +0000</lastBuildDate>
    <item>
      <title>Deep Fusion Transformer Network with Weighted Vector-Wise Keypoints Voting for Robust 6D Object Pose Estimation</title>
      <link>https://paperswithcode.com/paper/deep-fusion-transformer-network-with-weighted</link>
      <description><![CDATA[One critical challenge in 6D object pose estimation from a single RGBD image is efficient integration of two different modalities, i. e., color and depth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-fusion-transformer-network-with-weighted</guid>
    </item>
    <item>
      <title>PlankAssembly: Robust 3D Reconstruction from Three Orthographic Views with Learnt Shape Programs</title>
      <link>https://paperswithcode.com/paper/plankassembly-robust-3d-reconstruction-from</link>
      <description><![CDATA[In this paper, we develop a new method to automatically convert 2D line drawings from three orthographic views into 3D CAD models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plankassembly-robust-3d-reconstruction-from</guid>
    </item>
    <item>
      <title>A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment</title>
      <link>https://paperswithcode.com/paper/a-preliminary-study-of-the-intrinsic</link>
      <description><![CDATA[By adjusting the number of added nodes, we can control the difficulty level in the modified instruction data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-preliminary-study-of-the-intrinsic</guid>
    </item>
    <item>
      <title>FINER: Enhancing State-of-the-art Classifiers with Feature Attribution to Facilitate Security Analysis</title>
      <link>https://paperswithcode.com/paper/finer-enhancing-state-of-the-art-classifiers</link>
      <description><![CDATA[Although feature attribution (FA) methods can be used to explain deep learning, the underlying classifier is still blind to what behavior is suspicious, and the generated explanation cannot adapt to downstream tasks, incurring poor explanation fidelity and intelligibility.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finer-enhancing-state-of-the-art-classifiers</guid>
    </item>
    <item>
      <title>SSLRec: A Self-Supervised Learning Library for Recommendation</title>
      <link>https://paperswithcode.com/paper/sslrec-a-self-supervised-learning-library-for</link>
      <description><![CDATA[Our SSLRec platform covers a comprehensive set of state-of-the-art SSL-enhanced recommendation models across different scenarios, enabling researchers to evaluate these cutting-edge models and drive further innovation in the field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sslrec-a-self-supervised-learning-library-for</guid>
    </item>
    <item>
      <title>Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative Convolution Network</title>
      <link>https://paperswithcode.com/paper/self-supervised-monocular-depth-estimation-by</link>
      <description><![CDATA[To bridge this gap, we propose a new Direction-aware Cumulative Convolution Network (DaCCN), which improves the depth feature representation in two aspects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-monocular-depth-estimation-by</guid>
    </item>
    <item>
      <title>Interaction-aware Joint Attention Estimation Using People Attributes</title>
      <link>https://paperswithcode.com/paper/interaction-aware-joint-attention-estimation</link>
      <description><![CDATA[We introduce a specialized MLP head with positional embedding to the Transformer so that it predicts pixelwise confidence of joint attention for generating the confidence heatmap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interaction-aware-joint-attention-estimation</guid>
    </item>
    <item>
      <title>Counterfactual Cross-modality Reasoning for Weakly Supervised Video Moment Localization</title>
      <link>https://paperswithcode.com/paper/counterfactual-cross-modality-reasoning-for</link>
      <description><![CDATA[Finally, by suppressing the unimodal effect of masked query, we can rectify the reconstructions of video proposals to perform reasonable contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-cross-modality-reasoning-for</guid>
    </item>
    <item>
      <title>Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning</title>
      <link>https://paperswithcode.com/paper/beyond-semantics-learning-a-behavior</link>
      <description><![CDATA[Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-semantics-learning-a-behavior</guid>
    </item>
    <item>
      <title>A Comparative Assessment of Multi-view fusion learning for Crop Classification</title>
      <link>https://paperswithcode.com/paper/a-comparative-assessment-of-multi-view-fusion</link>
      <description><![CDATA[Instead, we present a comparison of multi-view fusion methods for three different datasets and show that, depending on the test region, different methods obtain the best performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparative-assessment-of-multi-view-fusion</guid>
    </item>
    <item>
      <title>Exploring XAI for the Arts: Explaining Latent Space in Generative Music</title>
      <link>https://paperswithcode.com/paper/exploring-xai-for-the-arts-explaining-latent</link>
      <description><![CDATA[We increase the explainability of the model by: i) using latent space regularisation to force some specific dimensions of the latent space to map to meaningful musical attributes, ii) providing a user interface feedback loop to allow people to adjust dimensions of the latent space and observe the results of these changes in real-time, iii) providing a visualisation of the musical attributes in the latent space to help people understand and predict the effect of changes to latent space dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-xai-for-the-arts-explaining-latent</guid>
    </item>
    <item>
      <title>Adaptive Taxonomy Learning and Historical Patterns Modelling for Patent Classification</title>
      <link>https://paperswithcode.com/paper/adaptive-taxonomy-learning-and-historical</link>
      <description><![CDATA[Finally, we combine the contextual information of patent texts that contains the semantics of IPC codes, and assignees' sequential preferences to make predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-taxonomy-learning-and-historical</guid>
    </item>
    <item>
      <title>Double-chain Constraints for 3D Human Pose Estimation in Images and Videos</title>
      <link>https://paperswithcode.com/paper/double-chain-constraints-for-3d-human-pose</link>
      <description><![CDATA[Notably, our model achieves state-of-the-art performance on all action categories in the Human3. 6M dataset using detected 2D poses from CPN, and our code is available at: https://github. com/KHB1698/DC-GCT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/double-chain-constraints-for-3d-human-pose</guid>
    </item>
    <item>
      <title>A Comparative Visual Analytics Framework for Evaluating Evolutionary Processes in Multi-objective Optimization</title>
      <link>https://paperswithcode.com/paper/a-comparative-visual-analytics-framework-for</link>
      <description><![CDATA[Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparative-visual-analytics-framework-for</guid>
    </item>
    <item>
      <title>Multi-domain Recommendation with Embedding Disentangling and Domain Alignment</title>
      <link>https://paperswithcode.com/paper/multi-domain-recommendation-with-embedding</link>
      <description><![CDATA[We propose a new MDR method named EDDA with two key components, i. e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-domain-recommendation-with-embedding</guid>
    </item>
    <item>
      <title>Speech-Driven 3D Face Animation with Composite and Regional Facial Movements</title>
      <link>https://paperswithcode.com/paper/speech-driven-3d-face-animation-with</link>
      <description><![CDATA[This paper emphasizes the importance of considering both the composite and regional natures of facial movements in speech-driven 3D face animation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/speech-driven-3d-face-animation-with</guid>
    </item>
    <item>
      <title>Enhancing Low-light Light Field Images with A Deep Compensation Unfolding Network</title>
      <link>https://paperswithcode.com/paper/enhancing-low-light-light-field-images-with-a</link>
      <description><![CDATA[This paper presents a novel and interpretable end-to-end learning framework, called the deep compensation unfolding network (DCUNet), for restoring light field (LF) images captured under low-light conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-low-light-light-field-images-with-a</guid>
    </item>
    <item>
      <title>RLSAC: Reinforcement Learning enhanced Sample Consensus for End-to-End Robust Estimation</title>
      <link>https://paperswithcode.com/paper/rlsac-reinforcement-learning-enhanced-sample</link>
      <description><![CDATA[Therefore, RLSAC can avoid differentiating to learn the features and the feedback of downstream tasks for end-to-end robust estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rlsac-reinforcement-learning-enhanced-sample</guid>
    </item>
    <item>
      <title>Robust Asymmetric Loss for Multi-Label Long-Tailed Learning</title>
      <link>https://paperswithcode.com/paper/robust-asymmetric-loss-for-multi-label-long</link>
      <description><![CDATA[Although a model can be highly fine-tuned due to a large number of hyper-parameters, it is difficult to optimize all hyper-parameters at the same time, and there might be a risk of overfitting a model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-asymmetric-loss-for-multi-label-long</guid>
    </item>
    <item>
      <title>Is there progress in activity progress prediction?</title>
      <link>https://paperswithcode.com/paper/is-there-progress-in-activity-progress</link>
      <description><![CDATA[We conclude that the progress prediction task is ill-posed on the currently used real-world datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-there-progress-in-activity-progress</guid>
    </item>
    <item>
      <title>Deformable Mixer Transformer with Gating for Multi-Task Learning of Dense Prediction</title>
      <link>https://paperswithcode.com/paper/deformable-mixer-transformer-with-gating-for</link>
      <description><![CDATA[In this work, we present a novel MTL model by combining both merits of deformable CNN and query-based Transformer with shared gating for multi-task learning of dense prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deformable-mixer-transformer-with-gating-for</guid>
    </item>
    <item>
      <title>MapTRv2: An End-to-End Framework for Online Vectorized HD Map Construction</title>
      <link>https://paperswithcode.com/paper/maptrv2-an-end-to-end-framework-for-online</link>
      <description><![CDATA[We propose a unified permutation-equivalent modeling approach, \ie, modeling map element as a point set with a group of equivalent permutations, which accurately describes the shape of map element and stabilizes the learning process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maptrv2-an-end-to-end-framework-for-online</guid>
    </item>
    <item>
      <title>Surface Masked AutoEncoder: Self-Supervision for Cortical Imaging Data</title>
      <link>https://paperswithcode.com/paper/surface-masked-autoencoder-self-supervision</link>
      <description><![CDATA[By reconstructing surface data from a masked version of the input, the proposed method effectively models cortical structure to learn strong representations that translate to improved performance in downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surface-masked-autoencoder-self-supervision</guid>
    </item>
    <item>
      <title>Progressive Spatio-temporal Perception for Audio-Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/progressive-spatio-temporal-perception-for</link>
      <description><![CDATA[Such naturally multi-modal videos are composed of rich and complex dynamic audio-visual components, where most of which could be unrelated to the given questions, or even play as interference in answering the content of interest.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progressive-spatio-temporal-perception-for</guid>
    </item>
    <item>
      <title>Shadow Datasets, New challenging datasets for Causal Representation Learning</title>
      <link>https://paperswithcode.com/paper/shadow-datasets-new-challenging-datasets-for</link>
      <description><![CDATA[Most causal representation learning (CRL) methods are fully supervised, which is impractical due to costly labeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shadow-datasets-new-challenging-datasets-for</guid>
    </item>
    <item>
      <title>Robust Object Modeling for Visual Tracking</title>
      <link>https://paperswithcode.com/paper/robust-object-modeling-for-visual-tracking</link>
      <description><![CDATA[To enjoy the merits of both methods, we propose a robust object modeling framework for visual tracking (ROMTrack), which simultaneously models the inherent template and the hybrid template features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-object-modeling-for-visual-tracking</guid>
    </item>
    <item>
      <title>Kairos: : Practical Intrusion Detection and Investigation using Whole-system Provenance</title>
      <link>https://paperswithcode.com/paper/kairos-practical-intrusion-detection-and</link>
      <description><![CDATA[Sifting through their design documents, we identify four common dimensions that drive the development of provenance-based intrusion detection systems (PIDSes): scope (can PIDSes detect modern attacks that infiltrate across application boundaries?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kairos-practical-intrusion-detection-and</guid>
    </item>
    <item>
      <title>Transferable Models for Bioacoustics with Human Language Supervision</title>
      <link>https://paperswithcode.com/paper/transferable-models-for-bioacoustics-with</link>
      <description><![CDATA[After training on this dataset to connect language and audio representations, our model can identify over a thousand species' calls across taxa, complete bioacoustic tasks zero-shot, and retrieve animal vocalization recordings from natural text queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transferable-models-for-bioacoustics-with</guid>
    </item>
    <item>
      <title>Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories</title>
      <link>https://paperswithcode.com/paper/multi-class-deep-svdd-anomaly-detection</link>
      <description><![CDATA[Our results demonstrate the efficacy of MCDSVDD in detecting anomalous sources while leveraging the presence of different inlier categories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-class-deep-svdd-anomaly-detection</guid>
    </item>
    <item>
      <title>Advancing Early Detection of Virus Yellows: Developing a Hybrid Convolutional Neural Network for Automatic Aphid Counting in Sugar Beet Fields</title>
      <link>https://paperswithcode.com/paper/advancing-early-detection-of-virus-yellows</link>
      <description><![CDATA[Aphids are efficient vectors to transmit virus yellows in sugar beet fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-early-detection-of-virus-yellows</guid>
    </item>
    <item>
      <title>SelectNAdapt: Support Set Selection for Few-Shot Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/selectnadapt-support-set-selection-for-few</link>
      <description><![CDATA[Few-shot domain adaptation mitigates this issue by adapting deep neural networks pre-trained on the source domain to the target domain using a randomly selected and annotated support set from the target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/selectnadapt-support-set-selection-for-few</guid>
    </item>
    <item>
      <title>Directed differential equation discovery using modified mutation and cross-over operators</title>
      <link>https://paperswithcode.com/paper/directed-differential-equation-discovery</link>
      <description><![CDATA[The discovery of equations with knowledge of the process origin is a tempting prospect.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/directed-differential-equation-discovery</guid>
    </item>
    <item>
      <title>Dual Intents Graph Modeling for User-centric Group Discovery</title>
      <link>https://paperswithcode.com/paper/dual-intents-graph-modeling-for-user-centric</link>
      <description><![CDATA[Therefore, user-centric group discovery task, i. e., recommending groups to users can help both users' online experiences and platforms' long-term developments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-intents-graph-modeling-for-user-centric</guid>
    </item>
    <item>
      <title>SUnAA: Sparse Unmixing using Archetypal Analysis</title>
      <link>https://paperswithcode.com/paper/sunaa-sparse-unmixing-using-archetypal</link>
      <description><![CDATA[Unlike most conventional sparse unmixing methods, here the minimization problem is non-convex.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sunaa-sparse-unmixing-using-archetypal</guid>
    </item>
    <item>
      <title>A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge</title>
      <link>https://paperswithcode.com/paper/a-bipartite-graph-is-all-we-need-for</link>
      <description><![CDATA[However, most previous knowledge infusion methods perform empirical knowledge filtering and design highly customized architectures for knowledge interaction with the utterances, which can discard useful knowledge aspects and limit their generalizability to different knowledge sources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-bipartite-graph-is-all-we-need-for</guid>
    </item>
    <item>
      <title>DiVa: An Iterative Framework to Harvest More Diverse and Valid Labels from User Comments for Music</title>
      <link>https://paperswithcode.com/paper/diva-an-iterative-framework-to-harvest-more</link>
      <description><![CDATA[Based on the observation that such missing information may already be presented in user comments, we propose to study the automated music labeling in an essential but under-explored setting, where the model is required to harvest more diverse and valid labels from the users' comments given limited gold labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diva-an-iterative-framework-to-harvest-more</guid>
    </item>
    <item>
      <title>Parallel Knowledge Enhancement based Framework for Multi-behavior Recommendation</title>
      <link>https://paperswithcode.com/paper/parallel-knowledge-enhancement-based</link>
      <description><![CDATA[In the fusion step, advanced neural networks are used to model the hierarchical correlations between user behaviors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parallel-knowledge-enhancement-based</guid>
    </item>
    <item>
      <title>LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking</title>
      <link>https://paperswithcode.com/paper/llmebench-a-flexible-framework-for</link>
      <description><![CDATA[Initially developed to evaluate Arabic NLP tasks using OpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task and model, regardless of language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llmebench-a-flexible-framework-for</guid>
    </item>
    <item>
      <title>Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/resource-constrained-model-compression-via</link>
      <description><![CDATA[We propose an improved end-to-end Minimax optimization method for this sparse learning problem to better balance the model performance and the computation efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/resource-constrained-model-compression-via</guid>
    </item>
    <item>
      <title>PromptPaint: Steering Text-to-Image Generation Through Paint Medium-like Interactions</title>
      <link>https://paperswithcode.com/paper/promptpaint-steering-text-to-image-generation</link>
      <description><![CDATA[Just as we iteratively tune colors through layered placements of paint on a physical canvas, PromptPaint similarly allows users to apply different prompts to different canvas areas and times of the generative process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/promptpaint-steering-text-to-image-generation</guid>
    </item>
    <item>
      <title>Evaluating the Generation Capabilities of Large Chinese Language Models</title>
      <link>https://paperswithcode.com/paper/evaluating-the-generation-capabilities-of</link>
      <description><![CDATA[This paper presents CG-Eval, the first comprehensive evaluation of the generation capabilities of large Chinese language models across a wide range of academic disciplines.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-the-generation-capabilities-of</guid>
    </item>
    <item>
      <title>CasCIFF: A Cross-Domain Information Fusion Framework Tailored for Cascade Prediction in Social Networks</title>
      <link>https://paperswithcode.com/paper/casciff-a-cross-domain-information-fusion</link>
      <description><![CDATA[Existing approaches for information cascade prediction fall into three main categories: feature-driven methods, point process-based methods, and deep learning-based methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/casciff-a-cross-domain-information-fusion</guid>
    </item>
    <item>
      <title>Vector quantization loss analysis in VQGANs: a single-GPU ablation study for image-to-image synthesis</title>
      <link>https://paperswithcode.com/paper/vector-quantization-loss-analysis-in-vqgans-a</link>
      <description><![CDATA[This study performs an ablation analysis of Vector Quantized Generative Adversarial Networks (VQGANs), concentrating on image-to-image synthesis utilizing a single NVIDIA A100 GPU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vector-quantization-loss-analysis-in-vqgans-a</guid>
    </item>
    <item>
      <title>Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/enhancing-efficient-continual-learning-with</link>
      <description><![CDATA[In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each task).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-efficient-continual-learning-with</guid>
    </item>
    <item>
      <title>Objects do not disappear: Video object detection by single-frame object location anticipation</title>
      <link>https://paperswithcode.com/paper/objects-do-not-disappear-video-object</link>
      <description><![CDATA[2) Improved efficiency by only doing the expensive feature computations on a small subset of all frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/objects-do-not-disappear-video-object</guid>
    </item>
    <item>
      <title>AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities</title>
      <link>https://paperswithcode.com/paper/aspectmmkg-a-multi-modal-knowledge-graph-with</link>
      <description><![CDATA[Multi-modal knowledge graphs (MMKGs) combine different modal data (e. g., text and image) for a comprehensive understanding of entities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aspectmmkg-a-multi-modal-knowledge-graph-with</guid>
    </item>
    <item>
      <title>Separate Anything You Describe</title>
      <link>https://paperswithcode.com/paper/separate-anything-you-describe</link>
      <description><![CDATA[In this work, we introduce AudioSep, a foundation model for open-domain audio source separation with natural language queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/separate-anything-you-describe</guid>
    </item>
    <item>
      <title>Exploring Multilingual Text Data Distillation</title>
      <link>https://paperswithcode.com/paper/exploring-multilingual-text-data-distillation</link>
      <description><![CDATA[In the paper, we propose several data distillation techniques for multilingual text classification datasets using language-model-based learning methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-multilingual-text-data-distillation</guid>
    </item>
    <item>
      <title>Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization</title>
      <link>https://paperswithcode.com/paper/induction-network-audio-visual-modality-gap</link>
      <description><![CDATA[By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/induction-network-audio-visual-modality-gap</guid>
    </item>
    <item>
      <title>Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution</title>
      <link>https://paperswithcode.com/paper/generative-perturbation-analysis-for</link>
      <description><![CDATA[We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-perturbation-analysis-for</guid>
    </item>
  </channel>
</rss>
