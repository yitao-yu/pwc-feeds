<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 15 Dec 2024 21:08:44 +0000</lastBuildDate>
    <item>
      <title>Robust Portfolio Optimization using GOPALS: Geospatial Optimization and Portfolio Allocation using Landscape Segmentation</title>
      <link>https://paperswithcode.com/paper/robust-portfolio-optimization-using-gopals</link>
      <description><![CDATA[This study introduces GOPALS: Geospatial Optimization and Portfolio Allocation using Landscape Segmentation, a simulation-based portfolio optimization framework designed to overcome these limitations and improve the robustness of the portfolio optimization process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-portfolio-optimization-using-gopals</guid>
    </item>
    <item>
      <title>Olympus: A Universal Task Router for Computer Vision Tasks</title>
      <link>https://paperswithcode.com/paper/olympus-a-universal-task-router-for-computer</link>
      <description><![CDATA[We introduce Olympus, a new approach that transforms Multimodal Large Language Models (MLLMs) into a unified framework capable of handling a wide array of computer vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/olympus-a-universal-task-router-for-computer</guid>
    </item>
    <item>
      <title>Elevating Flow-Guided Video Inpainting with Reference Generation</title>
      <link>https://paperswithcode.com/paper/elevating-flow-guided-video-inpainting-with</link>
      <description><![CDATA[Powered by a strong generative model, our method not only significantly enhances frame-level quality for object removal but also synthesizes new content in the missing areas based on user-provided text prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elevating-flow-guided-video-inpainting-with</guid>
    </item>
    <item>
      <title>GoHD: Gaze-oriented and Highly Disentangled Portrait Animation with Rhythmic Poses and Realistic Expression</title>
      <link>https://paperswithcode.com/paper/gohd-gaze-oriented-and-highly-disentangled</link>
      <description><![CDATA[Audio-driven talking head generation necessitates seamless integration of audio and visual data amidst the challenges posed by diverse input portraits and intricate correlations between audio and facial motions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gohd-gaze-oriented-and-highly-disentangled</guid>
    </item>
    <item>
      <title>Dynamic-VLM: Simple Dynamic Visual Token Compression for VideoLLM</title>
      <link>https://paperswithcode.com/paper/dynamic-vlm-simple-dynamic-visual-token</link>
      <description><![CDATA[The application of Large Vision-Language Models (LVLMs) for analyzing images and videos is an exciting and rapidly evolving field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-vlm-simple-dynamic-visual-token</guid>
    </item>
    <item>
      <title>Exploring Enhanced Contextual Information for Video-Level Object Tracking</title>
      <link>https://paperswithcode.com/paper/exploring-enhanced-contextual-information-for</link>
      <description><![CDATA[Contextual information at the video level has become increasingly crucial for visual object tracking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-enhanced-contextual-information-for</guid>
    </item>
    <item>
      <title>Finite-PINN: A Physics-Informed Neural Network Architecture for Solving Solid Mechanics Problems with General Geometries</title>
      <link>https://paperswithcode.com/paper/finite-pinn-a-physics-informed-neural-network</link>
      <description><![CDATA[Specifically: a) PINN models generate solutions over an infinite domain, which conflicts with the finite boundaries typical of most solid structures; and b) the solution space utilised by PINN is Euclidean, which is inadequate for addressing the complex geometries often present in solid structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finite-pinn-a-physics-informed-neural-network</guid>
    </item>
    <item>
      <title>Make Satire Boring Again: Reducing Stylistic Bias of Satirical Corpus by Utilizing Generative LLMs</title>
      <link>https://paperswithcode.com/paper/make-satire-boring-again-reducing-stylistic</link>
      <description><![CDATA[Results show that the debiasing method enhances the robustness and generalizability of the models for satire and irony detection tasks in Turkish and English.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/make-satire-boring-again-reducing-stylistic</guid>
    </item>
    <item>
      <title>MultiEYE: Dataset and Benchmark for OCT-Enhanced Retinal Disease Recognition from Fundus Images</title>
      <link>https://paperswithcode.com/paper/multieye-dataset-and-benchmark-for-oct</link>
      <description><![CDATA[Existing multi-modal learning methods on fundus and OCT images mostly require both modalities to be available and strictly paired for training and testing, which appears less practical in clinical scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multieye-dataset-and-benchmark-for-oct</guid>
    </item>
    <item>
      <title>Motor Imagery Classification for Asynchronous EEG-Based Brain-Computer Interfaces</title>
      <link>https://paperswithcode.com/paper/motor-imagery-classification-for-asynchronous</link>
      <description><![CDATA[Motor imagery (MI) based brain-computer interfaces (BCIs) enable the direct control of external devices through the imagined movements of various body parts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motor-imagery-classification-for-asynchronous</guid>
    </item>
    <item>
      <title>Advancing Attribution-Based Neural Network Explainability through Relative Absolute Magnitude Layer-Wise Relevance Propagation and Multi-Component Evaluation</title>
      <link>https://paperswithcode.com/paper/advancing-attribution-based-neural-network</link>
      <description><![CDATA[We utilize this new metric to evaluate the performance of various attribution-based methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-attribution-based-neural-network</guid>
    </item>
    <item>
      <title>Hidden Biases of End-to-End Driving Datasets</title>
      <link>https://paperswithcode.com/paper/hidden-biases-of-end-to-end-driving-datasets</link>
      <description><![CDATA[End-to-end driving systems have made rapid progress, but have so far not been applied to the challenging new CARLA Leaderboard 2. 0.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hidden-biases-of-end-to-end-driving-datasets</guid>
    </item>
    <item>
      <title>Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine</title>
      <link>https://paperswithcode.com/paper/towards-a-multimodal-large-language-model</link>
      <description><![CDATA[In this paper, we introduce a novel end-to-end multimodal large language model for the biomedical domain, named MedPLIB, which possesses pixel-level understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-a-multimodal-large-language-model</guid>
    </item>
    <item>
      <title>InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions</title>
      <link>https://paperswithcode.com/paper/internlm-xcomposer2-5-omnilive-a</link>
      <description><![CDATA[Recent advancements in multimodal large language models (MLLMs) have made significant strides in open-world understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internlm-xcomposer2-5-omnilive-a</guid>
    </item>
    <item>
      <title>Uplift modeling with continuous treatments: A predict-then-optimize approach</title>
      <link>https://paperswithcode.com/paper/uplift-modeling-with-continuous-treatments-a</link>
      <description><![CDATA[One common approach involves two steps: first, an inference step that estimates conditional average treatment effects (CATEs), and second, an optimization step that ranks entities based on their CATE values and assigns treatment to the top k within a given budget.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uplift-modeling-with-continuous-treatments-a</guid>
    </item>
    <item>
      <title>Representing Long Volumetric Video with Temporal Gaussian Hierarchy</title>
      <link>https://paperswithcode.com/paper/representing-long-volumetric-video-with</link>
      <description><![CDATA[In addition, the tree-like structure of the Gaussian hierarchy allows us to efficiently represent the scene at a particular moment with a subset of Gaussian primitives, leading to nearly constant GPU memory usage during the training or rendering regardless of the video length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representing-long-volumetric-video-with</guid>
    </item>
    <item>
      <title>Dynamic Prompt Allocation and Tuning for Continual Test-Time Adaptation</title>
      <link>https://paperswithcode.com/paper/dynamic-prompt-allocation-and-tuning-for</link>
      <description><![CDATA[For known domains, the corresponding domain-specific prompt is directly selected, while for previously unseen domains, a new prompt is allocated.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-prompt-allocation-and-tuning-for</guid>
    </item>
    <item>
      <title>Transfer Learning of RSSI to Improve Indoor Localisation Performance</title>
      <link>https://paperswithcode.com/paper/transfer-learning-of-rssi-to-improve-indoor</link>
      <description><![CDATA[With the growing demand for health monitoring systems, in-home localisation is essential for tracking patient conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transfer-learning-of-rssi-to-improve-indoor</guid>
    </item>
    <item>
      <title>Causal Graphical Models for Vision-Language Compositional Understanding</title>
      <link>https://paperswithcode.com/paper/causal-graphical-models-for-vision-language</link>
      <description><![CDATA[Recent work has empirically shown that Vision-Language Models (VLMs) struggle to fully understand the compositional properties of the human language, usually modeling an image caption as a "bag of words".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causal-graphical-models-for-vision-language</guid>
    </item>
    <item>
      <title>OFTSR: One-Step Flow for Image Super-Resolution with Tunable Fidelity-Realism Trade-offs</title>
      <link>https://paperswithcode.com/paper/oftsr-one-step-flow-for-image-super</link>
      <description><![CDATA[Specifically, we force the predictions from our one-step student model for same input to lie on the same sampling ODE trajectory of the teacher model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oftsr-one-step-flow-for-image-super</guid>
    </item>
    <item>
      <title>MOS: Model Surgery for Pre-Trained Model-Based Class-Incremental Learning</title>
      <link>https://paperswithcode.com/paper/mos-model-surgery-for-pre-trained-model-based</link>
      <description><![CDATA[Class-Incremental Learning (CIL) requires models to continually acquire knowledge of new classes without forgetting old ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mos-model-surgery-for-pre-trained-model-based</guid>
    </item>
    <item>
      <title>Mining Word Boundaries from Speech-Text Parallel Data for Cross-domain Chinese Word Segmentation</title>
      <link>https://paperswithcode.com/paper/mining-word-boundaries-from-speech-text</link>
      <description><![CDATA[Inspired by early research on exploring naturally annotated data for Chinese Word Segmentation (CWS), and also by recent research on integration of speech and text processing, this work for the first time proposes to explicitly mine word boundaries from speech-text parallel data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mining-word-boundaries-from-speech-text</guid>
    </item>
    <item>
      <title>RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios</title>
      <link>https://paperswithcode.com/paper/rulearena-a-benchmark-for-rule-guided</link>
      <description><![CDATA[This paper introduces RuleArena, a novel and challenging benchmark designed to evaluate the ability of large language models (LLMs) to follow complex, real-world rules in reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rulearena-a-benchmark-for-rule-guided</guid>
    </item>
    <item>
      <title>Exemplar Masking for Multimodal Incremental Learning</title>
      <link>https://paperswithcode.com/paper/exemplar-masking-for-multimodal-incremental</link>
      <description><![CDATA[Specifically, the non-important tokens are masked based on the attention weights and the correlation across different modalities, significantly reducing the storage size of an exemplar and consequently saving more exemplars under the same memory buffer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exemplar-masking-for-multimodal-incremental</guid>
    </item>
    <item>
      <title>OLA-VLM: Elevating Visual Perception in Multimodal LLMs with Auxiliary Embedding Distillation</title>
      <link>https://paperswithcode.com/paper/ola-vlm-elevating-visual-perception-in</link>
      <description><![CDATA[The standard practice for developing contemporary MLLMs is to feed features from vision encoder(s) into the LLM and train with natural language supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ola-vlm-elevating-visual-perception-in</guid>
    </item>
    <item>
      <title>Grothendieck Graph Neural Networks Framework: An Algebraic Platform for Crafting Topology-Aware GNNs</title>
      <link>https://paperswithcode.com/paper/grothendieck-graph-neural-networks-framework</link>
      <description><![CDATA[Based on the GGNN framework, we propose Sieve Neural Networks (SNN), a new GNN model that leverages the notion of sieves from category theory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grothendieck-graph-neural-networks-framework</guid>
    </item>
    <item>
      <title>Multimodal Industrial Anomaly Detection by Crossmodal Reverse Distillation</title>
      <link>https://paperswithcode.com/paper/multimodal-industrial-anomaly-detection-by-1</link>
      <description><![CDATA[Anomalies in one modality may not be effectively captured in the fused teacher features, leading to detection failures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-industrial-anomaly-detection-by-1</guid>
    </item>
    <item>
      <title>A physics-informed transformer neural operator for learning generalized solutions of initial boundary value problems</title>
      <link>https://paperswithcode.com/paper/a-physics-informed-transformer-neural</link>
      <description><![CDATA[A major drawback of existing neural approaches is the requirement to retrain with new initial/boundary conditions, and the necessity for a large amount of simulation data for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-physics-informed-transformer-neural</guid>
    </item>
    <item>
      <title>Multimodal Music Generation with Explicit Bridges and Retrieval Augmentation</title>
      <link>https://paperswithcode.com/paper/multimodal-music-generation-with-explicit</link>
      <description><![CDATA[Multimodal music generation aims to produce music from diverse input modalities, including text, videos, and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-music-generation-with-explicit</guid>
    </item>
    <item>
      <title>A Context-Enhanced Framework for Sequential Graph Reasoning</title>
      <link>https://paperswithcode.com/paper/a-context-enhanced-framework-for-sequential</link>
      <description><![CDATA[The paper studies sequential reasoning over graph-structured data, which stands as a fundamental task in various trending fields like automated math problem solving and neural graph algorithm learning, attracting a lot of research interest.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-context-enhanced-framework-for-sequential</guid>
    </item>
    <item>
      <title>RingFormer: A Ring-Enhanced Graph Transformer for Organic Solar Cell Property Prediction</title>
      <link>https://paperswithcode.com/paper/ringformer-a-ring-enhanced-graph-transformer</link>
      <description><![CDATA[Existing methods fail to capture the unique structural features of OSC molecules, particularly the intricate ring systems that critically influence OSC properties, leading to suboptimal performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ringformer-a-ring-enhanced-graph-transformer</guid>
    </item>
    <item>
      <title>Enhancing Implicit Neural Representations via Symmetric Power Transformation</title>
      <link>https://paperswithcode.com/paper/enhancing-implicit-neural-representations-via</link>
      <description><![CDATA[Specifically, we first investigate the characteristics of data that can benefit the training of INR, proposing the Range-Defined Symmetric Hypothesis, which posits that specific range and symmetry can improve the expressive ability of INR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-implicit-neural-representations-via</guid>
    </item>
    <item>
      <title>MOPI-HFRS: A Multi-objective Personalized Health-aware Food Recommendation System with LLM-enhanced Interpretation</title>
      <link>https://paperswithcode.com/paper/mopi-hfrs-a-multi-objective-personalized</link>
      <description><![CDATA[The prevalence of unhealthy eating habits has become an increasingly concerning issue in the United States.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mopi-hfrs-a-multi-objective-personalized</guid>
    </item>
    <item>
      <title>Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders</title>
      <link>https://paperswithcode.com/paper/gaze-lle-gaze-target-estimation-via-large</link>
      <description><![CDATA[We address the problem of gaze target estimation, which aims to predict where a person is looking in a scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaze-lle-gaze-target-estimation-via-large</guid>
    </item>
    <item>
      <title>Reversing the Damage: A QP-Aware Transformer-Diffusion Approach for 8K Video Restoration under Codec Compression</title>
      <link>https://paperswithcode.com/paper/reversing-the-damage-a-qp-aware-transformer</link>
      <description><![CDATA[In this paper, we introduce DiQP; a novel Transformer-Diffusion model for restoring 8K video quality degraded by codec compression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reversing-the-damage-a-qp-aware-transformer</guid>
    </item>
    <item>
      <title>Auto-Regressive Moving Diffusion Models for Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/auto-regressive-moving-diffusion-models-for</link>
      <description><![CDATA[This design aligns the diffusion model's sampling procedure with the forecasting objective, resulting in an unconditional, continuous sequential diffusion TSF model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/auto-regressive-moving-diffusion-models-for</guid>
    </item>
    <item>
      <title>Single-View Graph Contrastive Learning with Soft Neighborhood Awareness</title>
      <link>https://paperswithcode.com/paper/single-view-graph-contrastive-learning-with</link>
      <description><![CDATA[Most graph contrastive learning (GCL) methods heavily rely on cross-view contrast, thus facing several concomitant challenges, such as the complexity of designing effective augmentations, the potential for information loss between views, and increased computational costs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/single-view-graph-contrastive-learning-with</guid>
    </item>
    <item>
      <title>Doe-1: Closed-Loop Autonomous Driving with Large World Model</title>
      <link>https://paperswithcode.com/paper/doe-1-closed-loop-autonomous-driving-with</link>
      <description><![CDATA[In this paper, we explore a closed-loop framework for autonomous driving and propose a large Driving wOrld modEl (Doe-1) for unified perception, prediction, and planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/doe-1-closed-loop-autonomous-driving-with</guid>
    </item>
    <item>
      <title>DrivingRecon: Large 4D Gaussian Reconstruction Model For Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/drivingrecon-large-4d-gaussian-reconstruction</link>
      <description><![CDATA[To this end, we introduce the Large 4D Gaussian Reconstruction Model (DrivingRecon), a generalizable driving scene reconstruction model, which directly predicts 4D Gaussian from surround view videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drivingrecon-large-4d-gaussian-reconstruction</guid>
    </item>
    <item>
      <title>Motif Guided Graph Transformer with Combinatorial Skeleton Prototype Learning for Skeleton-Based Person Re-Identification</title>
      <link>https://paperswithcode.com/paper/motif-guided-graph-transformer-with</link>
      <description><![CDATA[This paper presents a generic Motif guided graph transformer with Combinatorial skeleton prototype learning (MoCos) that exploits structure-specific and gait-related body relations as well as combinatorial features of skeleton graphs to learn effective skeleton representations for person re-ID.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motif-guided-graph-transformer-with</guid>
    </item>
    <item>
      <title>Temporal Action Localization with Cross Layer Task Decoupling and Refinement</title>
      <link>https://paperswithcode.com/paper/temporal-action-localization-with-cross-layer</link>
      <description><![CDATA[Temporal action localization (TAL) involves dual tasks to classify and localize actions within untrimmed videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-action-localization-with-cross-layer</guid>
    </item>
    <item>
      <title>MaskTerial: A Foundation Model for Automated 2D Material Flake Detection</title>
      <link>https://paperswithcode.com/paper/maskterial-a-foundation-model-for-automated</link>
      <description><![CDATA[The detection and classification of exfoliated two-dimensional (2D) material flakes from optical microscope images can be automated using computer vision algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maskterial-a-foundation-model-for-automated</guid>
    </item>
    <item>
      <title>Owl-1: Omni World Model for Consistent Long Video Generation</title>
      <link>https://paperswithcode.com/paper/owl-1-omni-world-model-for-consistent-long</link>
      <description><![CDATA[As videos are observations of the underlying evolving world, we propose to model the long-term developments in a latent space and use VGMs to film them into videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/owl-1-omni-world-model-for-consistent-long</guid>
    </item>
    <item>
      <title>Neptune: The Long Orbit to Benchmarking Long Video Understanding</title>
      <link>https://paperswithcode.com/paper/neptune-the-long-orbit-to-benchmarking-long</link>
      <description><![CDATA[This paper describes a semi-automatic pipeline to generate challenging question-answer-decoy sets for understanding long videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neptune-the-long-orbit-to-benchmarking-long</guid>
    </item>
    <item>
      <title>Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion</title>
      <link>https://paperswithcode.com/paper/filter-then-generate-large-language-models</link>
      <description><![CDATA[Fundamentally, applying LLMs on KGC introduces several critical challenges, including a vast set of entity candidates, hallucination issue of LLMs, and under-exploitation of the graph structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/filter-then-generate-large-language-models</guid>
    </item>
    <item>
      <title>Learned Compression for Compressed Learning</title>
      <link>https://paperswithcode.com/paper/learned-compression-for-compressed-learning</link>
      <description><![CDATA[Linear transform coding and end-to-end learned compression systems reduce bitrate, but do not uniformly reduce dimensionality; thus, they do not meaningfully increase efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learned-compression-for-compressed-learning</guid>
    </item>
    <item>
      <title>Federated Foundation Models on Heterogeneous Time Series</title>
      <link>https://paperswithcode.com/paper/federated-foundation-models-on-heterogeneous</link>
      <description><![CDATA[Training a general-purpose time series foundation models with robust generalization capabilities across diverse applications from scratch is still an open challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/federated-foundation-models-on-heterogeneous</guid>
    </item>
    <item>
      <title>Loss function to optimise signal significance in particle physics</title>
      <link>https://paperswithcode.com/paper/loss-function-to-optimise-signal-significance</link>
      <description><![CDATA[We construct a surrogate loss to directly optimise the significance metric used in particle physics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/loss-function-to-optimise-signal-significance</guid>
    </item>
    <item>
      <title>Diffusion Predictive Control with Constraints</title>
      <link>https://paperswithcode.com/paper/diffusion-predictive-control-with-constraints</link>
      <description><![CDATA[Diffusion models have recently gained popularity for policy learning in robotics due to their ability to capture high-dimensional and multimodal distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-predictive-control-with-constraints</guid>
    </item>
    <item>
      <title>Kajal: Extracting Grammar of a Source Code Using Large Language Models</title>
      <link>https://paperswithcode.com/paper/kajal-extracting-grammar-of-a-source-code</link>
      <description><![CDATA[Understanding and extracting the grammar of a domain-specific language (DSL) is crucial for various software engineering tasks; however, manually creating these grammars is time-intensive and error-prone.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kajal-extracting-grammar-of-a-source-code</guid>
    </item>
  </channel>
</rss>
