<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 07 Nov 2024 09:15:57 +0000</lastBuildDate>
    <item>
      <title>RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/ravl-discovering-and-mitigating-spurious</link>
      <description><![CDATA[Fine-tuned vision-language models (VLMs) often capture spurious correlations between image features and textual attributes, resulting in degraded zero-shot performance at test time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ravl-discovering-and-mitigating-spurious</guid>
    </item>
    <item>
      <title>Generalize or Detect? Towards Robust Semantic Segmentation Under Multiple Distribution Shifts</title>
      <link>https://paperswithcode.com/paper/generalize-or-detect-towards-robust-semantic</link>
      <description><![CDATA[We validate the effectiveness of our method across benchmarks featuring both semantic and domain shifts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalize-or-detect-towards-robust-semantic</guid>
    </item>
    <item>
      <title>HRDecoder: High-Resolution Decoder Network for Fundus Image Lesion Segmentation</title>
      <link>https://paperswithcode.com/paper/hrdecoder-high-resolution-decoder-network-for</link>
      <description><![CDATA[Our method effectively improves the overall segmentation accuracy of fundus lesions while consuming reasonable memory and computational overhead, and maintaining satisfying inference speed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hrdecoder-high-resolution-decoder-network-for</guid>
    </item>
    <item>
      <title>Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?</title>
      <link>https://paperswithcode.com/paper/touchstone-benchmark-are-we-on-the-right-way</link>
      <description><![CDATA[We are committed to expanding this benchmark to encourage more innovation of AI algorithms for the medical domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/touchstone-benchmark-are-we-on-the-right-way</guid>
    </item>
    <item>
      <title>ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization</title>
      <link>https://paperswithcode.com/paper/robin-robust-and-invisible-watermarks-for</link>
      <description><![CDATA[They empirically inject a watermark that is both invisible and robust and passively achieve concealment by limiting the strength of the watermark, thus reducing the robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robin-robust-and-invisible-watermarks-for</guid>
    </item>
    <item>
      <title>A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement</title>
      <link>https://paperswithcode.com/paper/a-collaborative-content-moderation-framework</link>
      <description><![CDATA[Content moderation typically combines the efforts of human moderators and machine learning models. However, these systems often rely on data where significant disagreement occurs during moderation, reflecting the subjective nature of toxicity perception. Rather than dismissing this disagreement as noise, we interpret it as a valuable signal that highlights the inherent ambiguity of the content, an insight missed when only the majority label is considered. In this work, we introduce a novel content moderation framework that emphasizes the importance of capturing annotation disagreement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-collaborative-content-moderation-framework</guid>
    </item>
    <item>
      <title>Beyond Model Adaptation at Test Time: A Survey</title>
      <link>https://paperswithcode.com/paper/beyond-model-adaptation-at-test-time-a-survey</link>
      <description><![CDATA[Machine learning algorithms have achieved remarkable success across various disciplines, use cases and applications, under the prevailing assumption that training and test samples are drawn from the same distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-model-adaptation-at-test-time-a-survey</guid>
    </item>
    <item>
      <title>MEG: Medical Knowledge-Augmented Large Language Models for Question Answering</title>
      <link>https://paperswithcode.com/paper/meg-medical-knowledge-augmented-large</link>
      <description><![CDATA[We evaluate our method on four popular medical multiple-choice datasets and show that LLMs greatly benefit from the factual grounding provided by knowledge graph embeddings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meg-medical-knowledge-augmented-large</guid>
    </item>
    <item>
      <title>Number Cookbook: Number Understanding of Language Models and How to Improve It</title>
      <link>https://paperswithcode.com/paper/number-cookbook-number-understanding-of</link>
      <description><![CDATA[We also finetune practical-scale LLMs on our proposed NUPA tasks and find that 1) naive finetuning can improve NUPA a lot on many but not all tasks, and 2) surprisingly, techniques designed to enhance NUPA prove ineffective for finetuning pretrained models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/number-cookbook-number-understanding-of</guid>
    </item>
    <item>
      <title>Policy Aggregation</title>
      <link>https://paperswithcode.com/paper/policy-aggregation</link>
      <description><![CDATA[We consider the challenge of AI value alignment with multiple individuals that have different reward functions and optimal policies in an underlying Markov decision process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/policy-aggregation</guid>
    </item>
    <item>
      <title>Structure Consistent Gaussian Splatting with Matching Prior for Few-shot Novel View Synthesis</title>
      <link>https://paperswithcode.com/paper/structure-consistent-gaussian-splatting-with</link>
      <description><![CDATA[In this paper, we propose SCGaussian, a Structure Consistent Gaussian Splatting method using matching priors to learn 3D consistent scene structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structure-consistent-gaussian-splatting-with</guid>
    </item>
    <item>
      <title>Optimal Defenses Against Gradient Reconstruction Attacks</title>
      <link>https://paperswithcode.com/paper/optimal-defenses-against-gradient</link>
      <description><![CDATA[Federated Learning (FL) is designed to prevent data leakage through collaborative model training without centralized data storage.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimal-defenses-against-gradient</guid>
    </item>
    <item>
      <title>Pseudo-labeling with Keyword Refining for Few-Supervised Video Captioning</title>
      <link>https://paperswithcode.com/paper/pseudo-labeling-with-keyword-refining-for-few</link>
      <description><![CDATA[Meanwhile, the former employs the repetition penalized sampling to encourage the model to yield concise pseudo-labeled sentences with less repetition, and selects the most relevant sentences upon a pretrained video-text model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pseudo-labeling-with-keyword-refining-for-few</guid>
    </item>
    <item>
      <title>AMNCutter: Affinity-Attention-Guided Multi-View Normalized Cutter for Unsupervised Surgical Instrument Segmentation</title>
      <link>https://paperswithcode.com/paper/amncutter-affinity-attention-guided-multi</link>
      <description><![CDATA[Recent unsupervised surgical instrument segmentation (USIS) methods primarily rely on pseudo-labels derived from low-level features such as color and optical flow, but these methods show limited effectiveness and generalizability in complex and unseen endoscopic scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/amncutter-affinity-attention-guided-multi</guid>
    </item>
    <item>
      <title>EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning</title>
      <link>https://paperswithcode.com/paper/explora-efficient-exemplar-subset-selection</link>
      <description><![CDATA[Answering reasoning-based complex questions over text and hybrid sources, including tables, is a challenging task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explora-efficient-exemplar-subset-selection</guid>
    </item>
    <item>
      <title>SA3DIP: Segment Any 3D Instance with Potential 3D Priors</title>
      <link>https://paperswithcode.com/paper/sa3dip-segment-any-3d-instance-with-potential</link>
      <description><![CDATA[Thus, we present ScanNetV2-INS with complete ground truth labels and supplement additional instances for 3D class-agnostic instance segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sa3dip-segment-any-3d-instance-with-potential</guid>
    </item>
    <item>
      <title>QUILL: Quotation Generation Enhancement of Large Language Models</title>
      <link>https://paperswithcode.com/paper/quill-quotation-generation-enhancement-of</link>
      <description><![CDATA[To improve the LLMs' quotation generation abilities, we construct a bilingual knowledge base that is broad in scope and rich in dimensions, containing up to 32, 022 quotes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quill-quotation-generation-enhancement-of</guid>
    </item>
    <item>
      <title>Reconsidering the Performance of GAE in Link Prediction</title>
      <link>https://paperswithcode.com/paper/reconsidering-the-performance-of-gae-in-link</link>
      <description><![CDATA[Various graph neural networks (GNNs) with advanced training techniques and model designs have been proposed for link prediction tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reconsidering-the-performance-of-gae-in-link</guid>
    </item>
    <item>
      <title>AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making</title>
      <link>https://paperswithcode.com/paper/adasociety-an-adaptive-environment-with</link>
      <description><![CDATA[As agents progress, the environment adaptively generates new tasks with social structures for agents to undertake.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adasociety-an-adaptive-environment-with</guid>
    </item>
    <item>
      <title>LCP-Fusion: A Neural Implicit SLAM with Enhanced Local Constraints and Computable Prior</title>
      <link>https://paperswithcode.com/paper/lcp-fusion-a-neural-implicit-slam-with</link>
      <description><![CDATA[In this paper, we present LCP-Fusion, a neural implicit SLAM system with enhanced local constraints and computable prior, which takes the sparse voxel octree structure containing feature grids and SDF priors as hybrid scene representation, enabling the scalability and robustness during mapping and tracking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lcp-fusion-a-neural-implicit-slam-with</guid>
    </item>
    <item>
      <title>Multi3Hate: Multimodal, Multilingual, and Multicultural Hate Speech Detection with Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/multi3hate-multimodal-multilingual-and</link>
      <description><![CDATA[To investigate this, we create the first multimodal and multilingual parallel hate speech dataset, annotated by a multicultural set of annotators, called Multi3Hate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi3hate-multimodal-multilingual-and</guid>
    </item>
    <item>
      <title>Efficient Fourier Filtering Network with Contrastive Learning for UAV-based Unaligned Bi-modal Salient Object Detection</title>
      <link>https://paperswithcode.com/paper/efficient-fourier-filtering-network-with</link>
      <description><![CDATA[Extensive experiments on the UAV RGB-T 2400 and three weakly aligned datasets demonstrate that AlignSal achieves both real-time inference speed and better performance and generalizability compared to sixteen state-of-the-art BSOD models across most evaluation metrics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-fourier-filtering-network-with</guid>
    </item>
    <item>
      <title>Evaluating Moral Beliefs across LLMs through a Pluralistic Framework</title>
      <link>https://paperswithcode.com/paper/evaluating-moral-beliefs-across-llms-through</link>
      <description><![CDATA[Additionally, through moral debates, we investigate the firmness of these models to their moral choices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-moral-beliefs-across-llms-through</guid>
    </item>
    <item>
      <title>Your copula is a classifier in disguise: classification-based copula density estimation</title>
      <link>https://paperswithcode.com/paper/your-copula-is-a-classifier-in-disguise</link>
      <description><![CDATA[We propose reinterpreting copula density estimation as a discriminative task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/your-copula-is-a-classifier-in-disguise</guid>
    </item>
    <item>
      <title>SUDS: A Strategy for Unsupervised Drift Sampling</title>
      <link>https://paperswithcode.com/paper/suds-a-strategy-for-unsupervised-drift</link>
      <description><![CDATA[We also introduce the Harmonized Annotated Data Accuracy Metric (HADAM), a metric that evaluates classifier performance in relation to the quantity of annotated data required to achieve the stated performance, thereby taking into account the difficulty of acquiring labeled data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/suds-a-strategy-for-unsupervised-drift</guid>
    </item>
    <item>
      <title>Compositional simulation-based inference for time series</title>
      <link>https://paperswithcode.com/paper/compositional-simulation-based-inference-for</link>
      <description><![CDATA[Amortized simulation-based inference (SBI) methods train neural networks on simulated data to perform Bayesian inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compositional-simulation-based-inference-for</guid>
    </item>
    <item>
      <title>On the loss of context-awareness in general instruction fine-tuning</title>
      <link>https://paperswithcode.com/paper/on-the-loss-of-context-awareness-in-general</link>
      <description><![CDATA[We are the first to identify and show that the loss of context-awareness appears on instruction-finetuned LLMs when the chat template is applied to the input prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-loss-of-context-awareness-in-general</guid>
    </item>
    <item>
      <title>Real-Time Text Detection with Similar Mask in Traffic, Industrial, and Natural Scenes</title>
      <link>https://paperswithcode.com/paper/real-time-text-detection-with-similar-mask-in</link>
      <description><![CDATA[In addition, to validate the scene robustness of the SM-Net, we conduct experiments on traffic, industrial, and natural scene datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-text-detection-with-similar-mask-in</guid>
    </item>
    <item>
      <title>Label Critic: Design Data Before Models</title>
      <link>https://paperswithcode.com/paper/label-critic-design-data-before-models</link>
      <description><![CDATA[Label Critic can also check the label quality of a single AI Label with 71. 8% accuracy when no alternatives are available for comparison, prompting radiologists to review and edit if the estimated quality is low (19% depending on body structures).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/label-critic-design-data-before-models</guid>
    </item>
    <item>
      <title>Conditional Vendi Score: An Information-Theoretic Approach to Diversity Evaluation of Prompt-based Generative Models</title>
      <link>https://paperswithcode.com/paper/conditional-vendi-score-an-information</link>
      <description><![CDATA[We introduce the \emph{Conditional-Vendi} score based on $H(X|T)$ to quantify the internal diversity of the model and the \emph{Information-Vendi} score based on $I(X; T)$ to measure the statistical relevance between the generated data and text prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conditional-vendi-score-an-information</guid>
    </item>
    <item>
      <title>SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction</title>
      <link>https://paperswithcode.com/paper/sauce-synchronous-and-asynchronous-user</link>
      <description><![CDATA[Many human interactions, such as political debates, are carried out in group settings, where there are arbitrarily many participants, each with different views and agendas.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sauce-synchronous-and-asynchronous-user</guid>
    </item>
    <item>
      <title>HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems</title>
      <link>https://paperswithcode.com/paper/htmlrag-html-is-better-than-plain-text-for</link>
      <description><![CDATA[To alleviate this problem, we propose HtmlRAG, which uses HTML instead of plain text as the format of retrieved knowledge in RAG.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/htmlrag-html-is-better-than-plain-text-for</guid>
    </item>
    <item>
      <title>Membership Inference Attacks against Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/membership-inference-attacks-against-large</link>
      <description><![CDATA[Large vision-language models (VLLMs) exhibit promising capabilities for processing multi-modal tasks across various application scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/membership-inference-attacks-against-large</guid>
    </item>
    <item>
      <title>Correlating Variational Autoencoders Natively For Multi-View Imputation</title>
      <link>https://paperswithcode.com/paper/correlating-variational-autoencoders-natively</link>
      <description><![CDATA[A multi-view VAE approach is proposed that incorporates a joint prior with a non-zero correlation structure between the latent spaces of the VAEs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/correlating-variational-autoencoders-natively</guid>
    </item>
    <item>
      <title>The Unreasonable Effectiveness of LLMs for Query Optimization</title>
      <link>https://paperswithcode.com/paper/the-unreasonable-effectiveness-of-llms-for</link>
      <description><![CDATA[Recent work in database query optimization has used complex machine learning strategies, such as customized reinforcement learning schemes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-unreasonable-effectiveness-of-llms-for</guid>
    </item>
    <item>
      <title>Classification Done Right for Vision-Language Pre-Training</title>
      <link>https://paperswithcode.com/paper/classification-done-right-for-vision-language</link>
      <description><![CDATA[Due to the absence of the text encoding as contrastive target, SuperClass does not require a text encoder and does not need to maintain a large batch size as CLIP does.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/classification-done-right-for-vision-language</guid>
    </item>
    <item>
      <title>Query-Efficient Adversarial Attack Against Vertical Federated Graph Learning</title>
      <link>https://paperswithcode.com/paper/query-efficient-adversarial-attack-against</link>
      <description><![CDATA[As a result, the shadow model can improve the attack success rate of various centralized attacks with a few queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/query-efficient-adversarial-attack-against</guid>
    </item>
    <item>
      <title>Leveraging Large Language Models in Code Question Answering: Baselines and Issues</title>
      <link>https://paperswithcode.com/paper/leveraging-large-language-models-in-code</link>
      <description><![CDATA[This paper presents a work devoted to using large language models for question answering over source code in Python.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-large-language-models-in-code</guid>
    </item>
    <item>
      <title>Automatic doubly robust inference for linear functionals via calibrated debiased machine learning</title>
      <link>https://paperswithcode.com/paper/automatic-doubly-robust-inference-for-linear</link>
      <description><![CDATA[For learning such estimands, in this work, we propose novel debiased machine learning estimators that are doubly robust asymptotically linear, thus providing not only doubly robust consistency but also facilitating doubly robust inference (e. g., confidence intervals and hypothesis tests).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automatic-doubly-robust-inference-for-linear</guid>
    </item>
    <item>
      <title>Game Plot Design with an LLM-powered Assistant: An Empirical Study with Game Designers</title>
      <link>https://paperswithcode.com/paper/game-plot-design-with-an-llm-powered</link>
      <description><![CDATA[We introduce GamePlot, an LLM-powered assistant that supports game designers in crafting immersive narratives for turn-based games, and allows them to test these games through a collaborative game play and refine the plot throughout the process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/game-plot-design-with-an-llm-powered</guid>
    </item>
    <item>
      <title>LiVOS: Light Video Object Segmentation with Gated Linear Matching</title>
      <link>https://paperswithcode.com/paper/livos-light-video-object-segmentation-with</link>
      <description><![CDATA[Semi-supervised video object segmentation (VOS) has been largely driven by space-time memory (STM) networks, which store past frame features in a spatiotemporal memory to segment the current frame via softmax attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/livos-light-video-object-segmentation-with</guid>
    </item>
    <item>
      <title>DDFAV: Remote Sensing Large Vision Language Models Dataset and Evaluation Benchmark</title>
      <link>https://paperswithcode.com/paper/ddfav-remote-sensing-large-vision-language</link>
      <description><![CDATA[Next, a training instruction set is produced based on some high-quality remote sensing images selected from the proposed dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ddfav-remote-sensing-large-vision-language</guid>
    </item>
    <item>
      <title>SynthSet: Generative Diffusion Model for Semantic Segmentation in Precision Agriculture</title>
      <link>https://paperswithcode.com/paper/synthset-generative-diffusion-model-for</link>
      <description><![CDATA[This paper introduces a methodology for generating synthetic annotated data to address data scarcity in semantic segmentation tasks within the precision agriculture domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synthset-generative-diffusion-model-for</guid>
    </item>
    <item>
      <title>Lost in Context: The Influence of Context on Feature Attribution Methods for Object Recognition</title>
      <link>https://paperswithcode.com/paper/lost-in-context-the-influence-of-context-on</link>
      <description><![CDATA[This study investigates how context manipulation influences both model accuracy and feature attribution, providing insights into the reliance of object recognition models on contextual information as understood through the lens of feature attribution methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lost-in-context-the-influence-of-context-on</guid>
    </item>
    <item>
      <title>V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization</title>
      <link>https://paperswithcode.com/paper/v-dpo-mitigating-hallucination-in-large</link>
      <description><![CDATA[Recent research indicates that the over-reliance on the Large Language Model (LLM) backbone, as one cause of the LVLM hallucination, inherently introduces bias from language priors, leading to insufficient context attention to the visual inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/v-dpo-mitigating-hallucination-in-large</guid>
    </item>
    <item>
      <title>Specialized Foundation Models Struggle to Beat Supervised Baselines</title>
      <link>https://paperswithcode.com/paper/specialized-foundation-models-struggle-to</link>
      <description><![CDATA[Following its success for vision and text, the "foundation model" (FM) paradigm -- pretraining large models on massive data, then fine-tuning on target tasks -- has rapidly expanded to domains in the sciences, engineering, healthcare, and beyond.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/specialized-foundation-models-struggle-to</guid>
    </item>
    <item>
      <title>Adversarial multi-task underwater acoustic target recognition: towards robustness against various influential factors</title>
      <link>https://paperswithcode.com/paper/adversarial-multi-task-underwater-acoustic</link>
      <description><![CDATA[While significant efforts have been dedicated to addressing these influential factors in other domains of underwater acoustics, they are often neglected in the field of underwater acoustic target recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-multi-task-underwater-acoustic</guid>
    </item>
    <item>
      <title>Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset</title>
      <link>https://paperswithcode.com/paper/benchmarking-vision-language-model-unlearning</link>
      <description><![CDATA[Specifically, we formulate the VLM unlearning task via constructing the Fictitious Facial Identity VQA dataset and apply a two-stage evaluation pipeline that is designed to precisely control the sources of information and their exposure levels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-vision-language-model-unlearning</guid>
    </item>
    <item>
      <title>A Machine Learning Approach for the Efficient Estimation of Ground-Level Air Temperature in Urban Areas</title>
      <link>https://paperswithcode.com/paper/a-machine-learning-approach-for-the-efficient</link>
      <description><![CDATA[Based on the obtained results, deep neural networks are confirmed to be faster and less computationally expensive alternative for ground-level air temperature compared to numerical models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-machine-learning-approach-for-the-efficient</guid>
    </item>
    <item>
      <title>Continual Audio-Visual Sound Separation</title>
      <link>https://paperswithcode.com/paper/continual-audio-visual-sound-separation</link>
      <description><![CDATA[The task is inherently challenging as our models must not only effectively utilize information from both modalities in current tasks but also preserve their cross-modal association in old tasks to mitigate catastrophic forgetting during audio-visual continual learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/continual-audio-visual-sound-separation</guid>
    </item>
  </channel>
</rss>
