<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 13 Oct 2024 21:09:09 +0000</lastBuildDate>
    <item>
      <title>Semi-Supervised Video Desnowing Network via Temporal Decoupling Experts and Distribution-Driven Contrastive Regularization</title>
      <link>https://paperswithcode.com/paper/semi-supervised-video-desnowing-network-via</link>
      <description><![CDATA[Specifically, we construct a real-world dataset with 85 snowy videos, and then present a Semi-supervised Video Desnowing Network (SemiVDN) equipped by a novel Distribution-driven Contrastive Regularization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semi-supervised-video-desnowing-network-via</guid>
    </item>
    <item>
      <title>Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs</title>
      <link>https://paperswithcode.com/paper/efficiently-learning-at-test-time-active-fine</link>
      <description><![CDATA[To address this, we introduce SIFT, a data selection algorithm designed to reduce uncertainty about the model's response given a prompt, which unifies ideas from retrieval and active learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiently-learning-at-test-time-active-fine</guid>
    </item>
    <item>
      <title>DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory</title>
      <link>https://paperswithcode.com/paper/delta-an-online-document-level-translation</link>
      <description><![CDATA[Large language models (LLMs) have achieved reasonable quality improvements in machine translation (MT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/delta-an-online-document-level-translation</guid>
    </item>
    <item>
      <title>Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models</title>
      <link>https://paperswithcode.com/paper/teaching-inspired-integrated-prompting</link>
      <description><![CDATA[Experiments are conducted on nine benchmarks which demonstrates that our approach improves the reasoning accuracy of LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teaching-inspired-integrated-prompting</guid>
    </item>
    <item>
      <title>Provable Privacy Attacks on Trained Shallow Neural Networks</title>
      <link>https://paperswithcode.com/paper/provable-privacy-attacks-on-trained-shallow</link>
      <description><![CDATA[We study what provable privacy attacks can be shown on trained, 2-layer ReLU neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/provable-privacy-attacks-on-trained-shallow</guid>
    </item>
    <item>
      <title>Deconstructing equivariant representations in molecular systems</title>
      <link>https://paperswithcode.com/paper/deconstructing-equivariant-representations-in</link>
      <description><![CDATA[In this work, we report on a set of experiments using a simple equivariant graph convolution model on the QM9 dataset, focusing on correlating quantitative performance with the resulting molecular graph embeddings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deconstructing-equivariant-representations-in</guid>
    </item>
    <item>
      <title>Meta-Learning Integration in Hierarchical Reinforcement Learning for Advanced Task Complexity</title>
      <link>https://paperswithcode.com/paper/meta-learning-integration-in-hierarchical</link>
      <description><![CDATA[To address this, we integrate meta-learning into HRL to enhance the agent's ability to learn and adapt hierarchical policies swiftly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-learning-integration-in-hierarchical</guid>
    </item>
    <item>
      <title>Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits</title>
      <link>https://paperswithcode.com/paper/almost-minimax-optimal-best-arm</link>
      <description><![CDATA[When PS$\varepsilon$BAI and N$\varepsilon$BAI are utilized judiciously in parallel, PS$\varepsilon$BAI$^+$ is shown to have a finite expected sample complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/almost-minimax-optimal-best-arm</guid>
    </item>
    <item>
      <title>LADIMO: Face Morph Generation through Biometric Template Inversion with Latent Diffusion</title>
      <link>https://paperswithcode.com/paper/ladimo-face-morph-generation-through</link>
      <description><![CDATA[Face morphing attacks pose a severe security threat to face recognition systems, enabling the morphed face image to be verified against multiple identities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ladimo-face-morph-generation-through</guid>
    </item>
    <item>
      <title>Reversible Decoupling Network for Single Image Reflection Removal</title>
      <link>https://paperswithcode.com/paper/reversible-decoupling-network-for-single</link>
      <description><![CDATA[Recent deep-learning-based approaches to single-image reflection removal have shown promising advances, primarily for two reasons: 1) the utilization of recognition-pretrained features as inputs, and 2) the design of dual-stream interaction networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reversible-decoupling-network-for-single</guid>
    </item>
    <item>
      <title>Optimal-State Dynamics Estimation for Physics-based Human Motion Capture from Videos</title>
      <link>https://paperswithcode.com/paper/optimal-state-dynamics-estimation-for-physics</link>
      <description><![CDATA[We develop a control loop as a meta-PD controller to predict internal joint torques and external reaction forces, followed by a physics-based motion simulation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimal-state-dynamics-estimation-for-physics</guid>
    </item>
    <item>
      <title>IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera</title>
      <link>https://paperswithcode.com/paper/inceventgs-pose-free-gaussian-splatting-from</link>
      <description><![CDATA[To recover the 3D scene representation incrementally, we exploit the tracking and mapping paradigm of conventional SLAM pipelines for IncEventGS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inceventgs-pose-free-gaussian-splatting-from</guid>
    </item>
    <item>
      <title>Linguistically-Informed Multilingual Instruction Tuning: Is There an Optimal Set of Languages to Tune?</title>
      <link>https://paperswithcode.com/paper/linguistically-informed-multilingual</link>
      <description><![CDATA[All resources, including the code for language selection and multilingual instruction tuning, are made available in our official repository at https://github. com/GGLAB-KU/ling-informed-mit enabling reproducibility and further research in this area.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linguistically-informed-multilingual</guid>
    </item>
    <item>
      <title>A Closer Look at Machine Unlearning for Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-closer-look-at-machine-unlearning-for-large</link>
      <description><![CDATA[Specifically, the behavior that untargeted unlearning attempts to approximate is unpredictable and may involve hallucinations, and existing regularization is insufficient for targeted unlearning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-closer-look-at-machine-unlearning-for-large</guid>
    </item>
    <item>
      <title>The Effect of Surprisal on Reading Times in Information Seeking and Repeated Reading</title>
      <link>https://paperswithcode.com/paper/the-effect-of-surprisal-on-reading-times-in</link>
      <description><![CDATA[However, when using surprisal estimates from regime-specific contexts that match the contexts and tasks given to humans, we find that in information seeking, such estimates do not improve the predictive power of processing times compared to standard surprisals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-effect-of-surprisal-on-reading-times-in</guid>
    </item>
    <item>
      <title>OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting</title>
      <link>https://paperswithcode.com/paper/onenet-a-fine-tuning-free-framework-for-few</link>
      <description><![CDATA[Entity Linking (EL) is the process of associating ambiguous textual mentions to specific entities in a knowledge base.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/onenet-a-fine-tuning-free-framework-for-few</guid>
    </item>
    <item>
      <title>Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning</title>
      <link>https://paperswithcode.com/paper/packing-analysis-packing-is-more-appropriate</link>
      <description><![CDATA[Although it has demonstrated effectiveness during pre-training, there remains a lack of comprehensive analysis for the supervised fine-tuning (SFT) stage on the following points: (1) whether packing can effectively enhance training efficiency while maintaining performance, (2) the suitable size of the model and dataset for fine-tuning with the packing method, and (3) whether packing unrelated or related training samples might cause the model to either excessively disregard or over-rely on the context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/packing-analysis-packing-is-more-appropriate</guid>
    </item>
    <item>
      <title>Detecting Training Data of Large Language Models via Expectation Maximization</title>
      <link>https://paperswithcode.com/paper/detecting-training-data-of-large-language</link>
      <description><![CDATA[In this paper, we introduce EM-MIA, a novel MIA method for LLMs that iteratively refines membership scores and prefix scores via an expectation-maximization algorithm, leveraging the duality that the estimates of these scores can be improved by each other.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detecting-training-data-of-large-language</guid>
    </item>
    <item>
      <title>CoPESD: A Multi-Level Surgical Motion Dataset for Training Large Vision-Language Models to Co-Pilot Endoscopic Submucosal Dissection</title>
      <link>https://paperswithcode.com/paper/copesd-a-multi-level-surgical-motion-dataset</link>
      <description><![CDATA[In this paper, we design a hierarchical decomposition of ESD motion granularity and introduce a multi-level surgical motion dataset (CoPESD) for training LVLMs as the robotic \textbf{Co}-\textbf{P}ilot of \textbf{E}ndoscopic \textbf{S}ubmucosal \textbf{D}issection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/copesd-a-multi-level-surgical-motion-dataset</guid>
    </item>
    <item>
      <title>Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines</title>
      <link>https://paperswithcode.com/paper/executing-arithmetic-fine-tuning-large</link>
      <description><![CDATA[Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing and reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/executing-arithmetic-fine-tuning-large</guid>
    </item>
    <item>
      <title>Reward-Augmented Data Enhances Direct Preference Alignment of LLMs</title>
      <link>https://paperswithcode.com/paper/reward-augmented-data-enhances-direct</link>
      <description><![CDATA[This dataset is easily integrated with existing direct alignment algorithms and is applicable to any preference dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reward-augmented-data-enhances-direct</guid>
    </item>
    <item>
      <title>Temporal-Difference Variational Continual Learning</title>
      <link>https://paperswithcode.com/paper/temporal-difference-variational-continual</link>
      <description><![CDATA[To mitigate this, we propose new learning objectives that integrate the regularization effects of multiple previous posterior estimations, preventing individual errors from dominating future posterior updates and compounding over time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-difference-variational-continual</guid>
    </item>
    <item>
      <title>When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context</title>
      <link>https://paperswithcode.com/paper/when-and-where-did-it-happen-an-encoder</link>
      <description><![CDATA[We introduce a neural architecture finetuned for the task of scenario context generation: The relevant location and time of an event or entity mentioned in text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-and-where-did-it-happen-an-encoder</guid>
    </item>
    <item>
      <title>Cost-aware Simulation-based Inference</title>
      <link>https://paperswithcode.com/paper/cost-aware-simulation-based-inference</link>
      <description><![CDATA[Simulation-based inference (SBI) is the preferred framework for estimating parameters of intractable models in science and engineering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cost-aware-simulation-based-inference</guid>
    </item>
    <item>
      <title>Window Function-less DFT with Reduced Noise and Latency for Real-Time Music Analysis</title>
      <link>https://paperswithcode.com/paper/window-function-less-dft-with-reduced-noise</link>
      <description><![CDATA[Music analysis applications demand algorithms that can provide both high time and frequency resolution while minimizing noise in an already-noisy signal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/window-function-less-dft-with-reduced-noise</guid>
    </item>
    <item>
      <title>Thought2Text: Text Generation from EEG Signal using Large Language Models (LLMs)</title>
      <link>https://paperswithcode.com/paper/thought2text-text-generation-from-eeg-signal</link>
      <description><![CDATA[Decoding and expressing brain activity in a comprehensible form is a challenging frontier in AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/thought2text-text-generation-from-eeg-signal</guid>
    </item>
    <item>
      <title>Reachability Analysis for Black-Box Dynamical Systems</title>
      <link>https://paperswithcode.com/paper/reachability-analysis-for-black-box-dynamical</link>
      <description><![CDATA[In this work, we propose a novel reachability method to compute reachable sets and safe controllers for black-box dynamical systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reachability-analysis-for-black-box-dynamical</guid>
    </item>
    <item>
      <title>Neural Reasoning Networks: Efficient Interpretable Neural Networks With Automatic Textual Explanations</title>
      <link>https://paperswithcode.com/paper/neural-reasoning-networks-efficient</link>
      <description><![CDATA[Recent advances in machine learning have led to a surge in adoption of neural networks for various tasks, but lack of interpretability remains an issue for many others in which an understanding of the features influencing the prediction is necessary to ensure fairness, safety, and legal compliance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-reasoning-networks-efficient</guid>
    </item>
    <item>
      <title>OneRef: Unified One-tower Expression Grounding and Segmentation with Mask Referring Modeling</title>
      <link>https://paperswithcode.com/paper/oneref-unified-one-tower-expression-grounding</link>
      <description><![CDATA[Simultaneously, the current mask visual language modeling (MVLM) fails to capture the nuanced referential relationship between image-text in referring tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oneref-unified-one-tower-expression-grounding</guid>
    </item>
    <item>
      <title>Poison-splat: Computation Cost Attack on 3D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/poison-splat-computation-cost-attack-on-3d</link>
      <description><![CDATA[However, in this work, we reveal a significant security vulnerability that has been largely overlooked in 3DGS: the computation cost of training 3DGS could be maliciously tampered by poisoning the input data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poison-splat-computation-cost-attack-on-3d</guid>
    </item>
    <item>
      <title>MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code</title>
      <link>https://paperswithcode.com/paper/mathcoder2-better-math-reasoning-from</link>
      <description><![CDATA[Training several popular base models with this corpus significantly improves their mathematical abilities, leading to the creation of the MathCoder2 family of models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mathcoder2-better-math-reasoning-from</guid>
    </item>
    <item>
      <title>Explainability of Deep Neural Networks for Brain Tumor Detection</title>
      <link>https://paperswithcode.com/paper/explainability-of-deep-neural-networks-for</link>
      <description><![CDATA[Medical image classification is crucial for supporting healthcare professionals in decision-making and training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explainability-of-deep-neural-networks-for</guid>
    </item>
    <item>
      <title>Pretraining Graph Transformers with Atom-in-a-Molecule Quantum Properties for Improved ADMET Modeling</title>
      <link>https://paperswithcode.com/paper/pretraining-graph-transformers-with-atom-in-a</link>
      <description><![CDATA[After fine-tuning on Therapeutic Data Commons ADMET datasets, we evaluate the performance improvement in the different models observing that models pretrained with atomic quantum mechanical properties produce in general better results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pretraining-graph-transformers-with-atom-in-a</guid>
    </item>
    <item>
      <title>Synthesizing Multi-Class Surgical Datasets with Anatomy-Aware Diffusion Models</title>
      <link>https://paperswithcode.com/paper/synthesizing-multi-class-surgical-datasets</link>
      <description><![CDATA[We introduce a multi-stage approach using diffusion models to generate multi-class surgical datasets with annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synthesizing-multi-class-surgical-datasets</guid>
    </item>
    <item>
      <title>MinorityPrompt: Text to Minority Image Generation via Prompt Optimization</title>
      <link>https://paperswithcode.com/paper/minorityprompt-text-to-minority-image</link>
      <description><![CDATA[We investigate the generation of minority samples using pretrained text-to-image (T2I) latent diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minorityprompt-text-to-minority-image</guid>
    </item>
    <item>
      <title>Fast Feedforward 3D Gaussian Splatting Compression</title>
      <link>https://paperswithcode.com/paper/fast-feedforward-3d-gaussian-splatting</link>
      <description><![CDATA[With 3D Gaussian Splatting (3DGS) advancing real-time and high-fidelity rendering for novel view synthesis, storage requirements pose challenges for their widespread adoption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-feedforward-3d-gaussian-splatting</guid>
    </item>
    <item>
      <title>Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions</title>
      <link>https://paperswithcode.com/paper/closing-the-loop-learning-to-generate-writing</link>
      <description><![CDATA[However, it remains unclear whether the feedback generated by these models is truly effective in enhancing the quality of student revisions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/closing-the-loop-learning-to-generate-writing</guid>
    </item>
    <item>
      <title>Orthogonal Nonnegative Matrix Factorization with the Kullback-Leibler divergence</title>
      <link>https://paperswithcode.com/paper/orthogonal-nonnegative-matrix-factorization</link>
      <description><![CDATA[Orthogonal nonnegative matrix factorization (ONMF) has become a standard approach for clustering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/orthogonal-nonnegative-matrix-factorization</guid>
    </item>
    <item>
      <title>GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps</title>
      <link>https://paperswithcode.com/paper/gametraversalbenchmark-evaluating-planning</link>
      <description><![CDATA[Large language models (LLMs) have recently demonstrated great success in generating and understanding natural language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gametraversalbenchmark-evaluating-planning</guid>
    </item>
    <item>
      <title>Parameter-Efficient Fine-Tuning in Spectral Domain for Point Cloud Learning</title>
      <link>https://paperswithcode.com/paper/parameter-efficient-fine-tuning-in-spectral</link>
      <description><![CDATA[PointGST freezes the pre-trained model and introduces a lightweight, trainable Point Cloud Spectral Adapter (PCSA) to fine-tune parameters in the spectral domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parameter-efficient-fine-tuning-in-spectral</guid>
    </item>
    <item>
      <title>SNN-PAR: Energy Efficient Pedestrian Attribute Recognition via Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/snn-par-energy-efficient-pedestrian-attribute</link>
      <description><![CDATA[To address this issue, in this paper, we propose a Spiking Neural Network (SNN) based framework for energy-efficient attribute recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/snn-par-energy-efficient-pedestrian-attribute</guid>
    </item>
    <item>
      <title>Firzen: Firing Strict Cold-Start Items with Frozen Heterogeneous and Homogeneous Graphs for Recommendation</title>
      <link>https://paperswithcode.com/paper/firzen-firing-strict-cold-start-items-with</link>
      <description><![CDATA[Recommendation models utilizing unique identities (IDs) to represent distinct users and items have dominated the recommender systems literature for over a decade.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/firzen-firing-strict-cold-start-items-with</guid>
    </item>
    <item>
      <title>RayEmb: Arbitrary Landmark Detection in X-Ray Images Using Ray Embedding Subspace</title>
      <link>https://paperswithcode.com/paper/rayemb-arbitrary-landmark-detection-in-x-ray</link>
      <description><![CDATA[Anatomical landmarks pre-annotated in the CT volume can be detected in X-ray images to establish 2D-3D correspondences, which are then utilized for registration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rayemb-arbitrary-landmark-detection-in-x-ray</guid>
    </item>
    <item>
      <title>Robustness Auditing for Linear Regression: To Singularity and Beyond</title>
      <link>https://paperswithcode.com/paper/robustness-auditing-for-linear-regression-to</link>
      <description><![CDATA[These conclusions are typically based on the results of one or more Ordinary Least Squares (OLS) regressions, raising the question: given a dataset, can we certify the robustness of an OLS fit on this dataset to the removal of a given number of samples?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robustness-auditing-for-linear-regression-to</guid>
    </item>
    <item>
      <title>The Rise of AI-Generated Content in Wikipedia</title>
      <link>https://paperswithcode.com/paper/the-rise-of-ai-generated-content-in-wikipedia</link>
      <description><![CDATA[The rise of AI-generated content in popular information sources raises significant concerns about accountability, accuracy, and bias amplification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-rise-of-ai-generated-content-in-wikipedia</guid>
    </item>
    <item>
      <title>TurboRAG: Accelerating Retrieval-Augmented Generation with Precomputed KV Caches for Chunked Text</title>
      <link>https://paperswithcode.com/paper/turborag-accelerating-retrieval-augmented</link>
      <description><![CDATA[To reduce the computation overhead as well as TTFT, we introduce TurboRAG, a novel RAG system that redesigns the inference paradigm of the current RAG system by first pre-computing and storing the key-value (KV) caches of documents offline, and then directly retrieving the saved KV cache for prefill.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/turborag-accelerating-retrieval-augmented</guid>
    </item>
    <item>
      <title>Efficient Dictionary Learning with Switch Sparse Autoencoders</title>
      <link>https://paperswithcode.com/paper/efficient-dictionary-learning-with-switch</link>
      <description><![CDATA[We present experiments comparing Switch SAEs with other SAE architectures, and find that Switch SAEs deliver a substantial Pareto improvement in the reconstruction vs. sparsity frontier for a given fixed training compute budget.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-dictionary-learning-with-switch</guid>
    </item>
    <item>
      <title>QCircuitNet: A Large-Scale Hierarchical Dataset for Quantum Algorithm Design</title>
      <link>https://paperswithcode.com/paper/qcircuitnet-a-large-scale-hierarchical</link>
      <description><![CDATA[In this work, we introduce QCircuitNet, the first benchmark and test dataset designed to evaluate AI's capability in designing and implementing quantum algorithms in the form of quantum circuit codes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qcircuitnet-a-large-scale-hierarchical</guid>
    </item>
    <item>
      <title>CrackSegDiff: Diffusion Probability Model-based Multi-modal Crack Segmentation</title>
      <link>https://paperswithcode.com/paper/cracksegdiff-diffusion-probability-model</link>
      <description><![CDATA[Our experimental evaluation on the three-class crack image segmentation tasks within the FIND dataset demonstrates that CrackSegDiff outperforms state-of-the-art methods, particularly excelling in the detection of shallow cracks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cracksegdiff-diffusion-probability-model</guid>
    </item>
    <item>
      <title>Scaling Up Your Kernels: Large Kernel Design in ConvNets towards Universal Representations</title>
      <link>https://paperswithcode.com/paper/scaling-up-your-kernels-large-kernel-design</link>
      <description><![CDATA[This paper proposes the paradigm of large convolutional kernels in designing modern Convolutional Neural Networks (ConvNets).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-up-your-kernels-large-kernel-design</guid>
    </item>
  </channel>
</rss>
