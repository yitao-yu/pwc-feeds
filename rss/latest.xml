<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 14 Jul 2022 21:08:31 +0000</lastBuildDate>
    <item>
      <title>Context-Consistent Semantic Image Editing with Style-Preserved Modulation</title>
      <link>https://paperswithcode.com/paper/context-consistent-semantic-image-editing</link>
      <description><![CDATA[Semantic image editing utilizes local semantic label maps to generate the desired content in the edited region.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-consistent-semantic-image-editing</guid>
    </item>
    <item>
      <title>Semi-supervised Ranking for Object Image Blur Assessment</title>
      <link>https://paperswithcode.com/paper/semi-supervised-ranking-for-object-image-blur</link>
      <description><![CDATA[Based on this dataset, we propose a method to obtain the blur scores only with the pairwise rank labels as supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semi-supervised-ranking-for-object-image-blur</guid>
    </item>
    <item>
      <title>Teachers in concordance for pseudo-labeling of 3D sequential data</title>
      <link>https://paperswithcode.com/paper/teachers-in-concordance-for-pseudo-labeling</link>
      <description><![CDATA[We propose to leverage the sequentiality of the captures to boost the pseudo-labeling technique in a teacher-student setup via training multiple teachers, each with access to different temporal information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teachers-in-concordance-for-pseudo-labeling</guid>
    </item>
    <item>
      <title>A General Contextualized Rewriting Framework for Text Summarization</title>
      <link>https://paperswithcode.com/paper/a-general-contextualized-rewriting-framework</link>
      <description><![CDATA[The rewriting method for text summarization combines extractive and abstractive approaches, improving the conciseness and readability of extractive summaries using an abstractive model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-general-contextualized-rewriting-framework</guid>
    </item>
    <item>
      <title>Monotonicity in Undirected Networks</title>
      <link>https://paperswithcode.com/paper/monotonicity-in-undirected-networks</link>
      <description><![CDATA[In this paper, we study the problem of score and rank monotonicity for classical centrality measures in the case of undirected networks: in this case, we require that score, or relative importance, improve at both endpoints of the new edge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monotonicity-in-undirected-networks</guid>
    </item>
    <item>
      <title>Goal-Oriented Sensitivity Analysis of Hyperparameters in Deep Learning</title>
      <link>https://paperswithcode.com/paper/goal-oriented-sensitivity-analysis-of</link>
      <description><![CDATA[In this work, we study the use of goal-oriented sensitivity analysis, based on the Hilbert-Schmidt Independence Criterion (HSIC), for hyperparameter analysis and optimization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/goal-oriented-sensitivity-analysis-of</guid>
    </item>
    <item>
      <title>Bootstrap Latent Representations for Multi-modal Recommendation</title>
      <link>https://paperswithcode.com/paper/bootstrap-latent-representations-for-multi</link>
      <description><![CDATA[Specifically, BM3 first bootstraps latent contrastive views from the representations of users and items with a simple dropout augmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bootstrap-latent-representations-for-multi</guid>
    </item>
    <item>
      <title>Verifying Attention Robustness of Deep Neural Networks against Semantic Perturbations</title>
      <link>https://paperswithcode.com/paper/verifying-attention-robustness-of-deep-neural</link>
      <description><![CDATA[Semantic perturbations can significantly change the saliency-map.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/verifying-attention-robustness-of-deep-neural</guid>
    </item>
    <item>
      <title>Iterative Linear Quadratic Optimization for Nonlinear Control: Differentiable Programming Algorithmic Templates</title>
      <link>https://paperswithcode.com/paper/iterative-linear-quadratic-optimization-for</link>
      <description><![CDATA[We present the implementation of nonlinear control algorithms based on linear and quadratic approximations of the objective from a functional viewpoint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/iterative-linear-quadratic-optimization-for</guid>
    </item>
    <item>
      <title>Symmetry-Aware Transformer-based Mirror Detection</title>
      <link>https://paperswithcode.com/paper/symmetry-aware-transformer-based-mirror</link>
      <description><![CDATA[Mirror detection aims to identify the mirror regions in the given input image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/symmetry-aware-transformer-based-mirror</guid>
    </item>
    <item>
      <title>A comparison between PMBM Bayesian track initiation and labelled RFS adaptive birth</title>
      <link>https://paperswithcode.com/paper/a-comparison-between-pmbm-bayesian-track</link>
      <description><![CDATA[This paper provides a comparative analysis between the adaptive birth model used in the labelled random finite set literature and the track initiation in the Poisson multi-Bernoulli mixture (PMBM) filter, with point-target models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparison-between-pmbm-bayesian-track</guid>
    </item>
    <item>
      <title>AdamNODEs: When Neural ODE Meets Adaptive Moment Estimation</title>
      <link>https://paperswithcode.com/paper/adamnodes-when-neural-ode-meets-adaptive</link>
      <description><![CDATA[In this work, we propose adaptive momentum estimation neural ODEs (AdamNODEs) that adaptively control the acceleration of the classical momentum-based approach.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adamnodes-when-neural-ode-meets-adaptive</guid>
    </item>
    <item>
      <title>Adversarially-Aware Robust Object Detector</title>
      <link>https://paperswithcode.com/paper/adversarially-aware-robust-object-detector</link>
      <description><![CDATA[In this work, we empirically explore the model training for adversarial robustness in object detection, which greatly attributes to the conflict between learning clean images and adversarial images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarially-aware-robust-object-detector</guid>
    </item>
    <item>
      <title>Perturbation Inactivation Based Adversarial Defense for Face Recognition</title>
      <link>https://paperswithcode.com/paper/perturbation-inactivation-based-adversarial</link>
      <description><![CDATA[A straightforward approach is to inactivate the adversarial perturbations so that they can be easily handled as general perturbations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perturbation-inactivation-based-adversarial</guid>
    </item>
    <item>
      <title>Eliminating Gradient Conflict in Reference-based Line-art Colorization</title>
      <link>https://paperswithcode.com/paper/eliminating-gradient-conflict-in-reference</link>
      <description><![CDATA[To understand the instability in training, we detect the gradient flow of attention and observe gradient conflict among attention branches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eliminating-gradient-conflict-in-reference</guid>
    </item>
    <item>
      <title>DynaST: Dynamic Sparse Transformer for Exemplar-Guided Image Generation</title>
      <link>https://paperswithcode.com/paper/dynast-dynamic-sparse-transformer-for</link>
      <description><![CDATA[Prior approaches, despite the promising results, have relied on either estimating dense attention to compute per-point matching, which is limited to only coarse scales due to the quadratic memory cost, or fixing the number of correspondences to achieve linear complexity, which lacks flexibility.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynast-dynamic-sparse-transformer-for</guid>
    </item>
    <item>
      <title>Sample-dependent Adaptive Temperature Scaling for Improved Calibration</title>
      <link>https://paperswithcode.com/paper/sample-dependent-adaptive-temperature-scaling</link>
      <description><![CDATA[The most common post-hoc approach to compensate for this is to perform temperature scaling, which adjusts the confidences of the predictions on any input by scaling the logits by a fixed value.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sample-dependent-adaptive-temperature-scaling</guid>
    </item>
    <item>
      <title>PointNorm: Normalization is All You Need for Point Cloud Analysis</title>
      <link>https://paperswithcode.com/paper/pointnorm-normalization-is-all-you-need-for</link>
      <description><![CDATA[We also generalize our model to point cloud part segmentation and demonstrate competitive performance on the ShapeNetPart dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pointnorm-normalization-is-all-you-need-for</guid>
    </item>
    <item>
      <title>Appearance-guided Attentive Self-Paced Learning for Unsupervised Salient Object Detection</title>
      <link>https://paperswithcode.com/paper/appearance-guided-attentive-self-paced</link>
      <description><![CDATA[Specifically, for the first issue, we propose an Attentive Self-Paced Learning (ASPL) paradigm that organizes the training samples in a meaningful order to excavate gradually more detailed saliency information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/appearance-guided-attentive-self-paced</guid>
    </item>
    <item>
      <title>Diverse Dance Synthesis via Keyframes with Transformer Controllers</title>
      <link>https://paperswithcode.com/paper/diverse-dance-synthesis-via-keyframes-with</link>
      <description><![CDATA[The video and qualitative experimental results demonstrate that the complex motion sequences generated by our algorithm can achieve diverse and smooth motion transitions between keyframes, even for long-term synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diverse-dance-synthesis-via-keyframes-with</guid>
    </item>
    <item>
      <title>Task Agnostic Representation Consolidation: a Self-supervised based Continual Learning Approach</title>
      <link>https://paperswithcode.com/paper/task-agnostic-representation-consolidation-a</link>
      <description><![CDATA[Furthermore, the domain shift between pre-training data distribution and the task distribution reduces the generalizability of the learned representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/task-agnostic-representation-consolidation-a</guid>
    </item>
    <item>
      <title>DeepTIMe: Deep Time-Index Meta-Learning for Non-Stationary Time-Series Forecasting</title>
      <link>https://paperswithcode.com/paper/deeptime-deep-time-index-meta-learning-for</link>
      <description><![CDATA[Yet, despite the attractive properties of time-index based models, such as being a continuous signal function over time leading to smooth representations, little attention has been given to them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deeptime-deep-time-index-meta-learning-for</guid>
    </item>
    <item>
      <title>Hybrid Spatial-Temporal Entropy Modelling for Neural Video Compression</title>
      <link>https://paperswithcode.com/paper/hybrid-spatial-temporal-entropy-modelling-for</link>
      <description><![CDATA[Besides estimating the probability distribution, our entropy model also generates the quantization step at spatial-channel-wise.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hybrid-spatial-temporal-entropy-modelling-for</guid>
    </item>
    <item>
      <title>DocCoder: Generating Code by Retrieving and Reading Docs</title>
      <link>https://paperswithcode.com/paper/doccoder-generating-code-by-retrieving-and</link>
      <description><![CDATA[Inspired by this observation, we introduce DocCoder: an approach that explicitly leverages code manuals and documentation by (1) retrieving the relevant documentation given the NL intent, and (2) generating the code based on the NL intent and the retrieved documentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/doccoder-generating-code-by-retrieving-and</guid>
    </item>
    <item>
      <title>Global-local Motion Transformer for Unsupervised Skeleton-based Action Learning</title>
      <link>https://paperswithcode.com/paper/global-local-motion-transformer-for</link>
      <description><![CDATA[To tackle the learning of whole-body motion, long-range temporal dynamics, and person-to-person interactions, we design a global and local attention mechanism, where, global body motions and local joint motions pay attention to each other.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/global-local-motion-transformer-for</guid>
    </item>
    <item>
      <title>ACLNet: An Attention and Clustering-based Cloud Segmentation Network</title>
      <link>https://paperswithcode.com/paper/aclnet-an-attention-and-clustering-based</link>
      <description><![CDATA[We propose a novel deep learning model named ACLNet, for cloud segmentation from ground images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aclnet-an-attention-and-clustering-based</guid>
    </item>
    <item>
      <title>On the Robustness of Bayesian Neural Networks to Adversarial Attacks</title>
      <link>https://paperswithcode.com/paper/on-the-robustness-of-bayesian-neural-networks</link>
      <description><![CDATA[Despite significant efforts, both practical and theoretical, training deep learning models robust to adversarial attacks is still an open problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-robustness-of-bayesian-neural-networks</guid>
    </item>
    <item>
      <title>Re2G: Retrieve, Rerank, Generate</title>
      <link>https://paperswithcode.com/paper/re2g-retrieve-rerank-generate-2</link>
      <description><![CDATA[As demonstrated by GPT-3 and T5, transformers grow in capability as parameter spaces become larger and larger.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/re2g-retrieve-rerank-generate-2</guid>
    </item>
    <item>
      <title>Masked Autoencoders that Listen</title>
      <link>https://paperswithcode.com/paper/masked-autoencoders-that-listen</link>
      <description><![CDATA[Following the Transformer encoder-decoder design in MAE, our Audio-MAE first encodes audio spectrogram patches with a high masking ratio, feeding only the non-masked tokens through encoder layers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-autoencoders-that-listen</guid>
    </item>
    <item>
      <title>Enhanced Security and Privacy via Fragmented Federated Learning</title>
      <link>https://paperswithcode.com/paper/enhanced-security-and-privacy-via-fragmented</link>
      <description><![CDATA[To tackle the accuracy-privacy-security conflict, we propose {\em fragmented federated learning} (FFL), in which participants randomly exchange and mix fragments of their updates before sending them to the server.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhanced-security-and-privacy-via-fragmented</guid>
    </item>
    <item>
      <title>Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation</title>
      <link>https://paperswithcode.com/paper/multi-behavior-hypergraph-enhanced</link>
      <description><![CDATA[Further ablation studies validate the effectiveness of our model design and benefits of the new MBHT framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-behavior-hypergraph-enhanced</guid>
    </item>
    <item>
      <title>Online Game Level Generation from Music</title>
      <link>https://paperswithcode.com/paper/online-game-level-generation-from-music</link>
      <description><![CDATA[Game consists of multiple types of content, while the harmony of different content types play an essential role in game design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/online-game-level-generation-from-music</guid>
    </item>
    <item>
      <title>Logistics, Graphs, and Transformers: Towards improving Travel Time Estimation</title>
      <link>https://paperswithcode.com/paper/logistics-graphs-and-transformers-towards</link>
      <description><![CDATA[The problem of travel time estimation is widely considered as the fundamental challenge of modern logistics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/logistics-graphs-and-transformers-towards</guid>
    </item>
    <item>
      <title>RcTorch: a PyTorch Reservoir Computing Package with Automated Hyper-Parameter Optimization</title>
      <link>https://paperswithcode.com/paper/rctorch-a-pytorch-reservoir-computing-package</link>
      <description><![CDATA[However, RC adoption has lagged other neural network models because of the model's sensitivity to its hyper-parameters (HPs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rctorch-a-pytorch-reservoir-computing-package</guid>
    </item>
    <item>
      <title>Towards Hard-Positive Query Mining for DETR-based Human-Object Interaction Detection</title>
      <link>https://paperswithcode.com/paper/towards-hard-positive-query-mining-for-detr</link>
      <description><![CDATA[Specifically, we shift the GT bounding boxes of each labeled human-object pair so that the shifted boxes cover only a certain portion of the GT ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-hard-positive-query-mining-for-detr</guid>
    </item>
    <item>
      <title>Learning to Estimate External Forces of Human Motion in Video</title>
      <link>https://paperswithcode.com/paper/learning-to-estimate-external-forces-of-human</link>
      <description><![CDATA[Analyzing sports performance or preventing injuries requires capturing ground reaction forces (GRFs) exerted by the human body during certain movements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-estimate-external-forces-of-human</guid>
    </item>
    <item>
      <title>PLM-ICD: Automatic ICD Coding with Pretrained Language Models</title>
      <link>https://paperswithcode.com/paper/plm-icd-automatic-icd-coding-with-pretrained-1</link>
      <description><![CDATA[Prior work has shown that pretrained language models underperformed on this task with the regular finetuning scheme.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plm-icd-automatic-icd-coding-with-pretrained-1</guid>
    </item>
    <item>
      <title>Utilizing Excess Resources in Training Neural Networks</title>
      <link>https://paperswithcode.com/paper/utilizing-excess-resources-in-training-neural</link>
      <description><![CDATA[In this work, we suggest Kernel Filtering Linear Overparameterization (KFLO), where a linear cascade of filtering layers is used during training to improve network performance in test time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/utilizing-excess-resources-in-training-neural</guid>
    </item>
    <item>
      <title>Exploring Adversarial Examples and Adversarial Robustness of Convolutional Neural Networks by Mutual Information</title>
      <link>https://paperswithcode.com/paper/exploring-adversarial-examples-and</link>
      <description><![CDATA[We show that 1) the amount of mutual information that CNNs extract from original and adversarial examples is almost similar, whether CNNs are in normal training or adversarial training; the reason why adversarial examples mislead CNNs may be that they contain more texture-based information about other categories; 2) compared with normal training, adversarial training is more difficult and the amount of information extracted by the robust CNNs is less; 3) the CNNs trained with different methods have different preferences for certain types of information; normally trained CNNs tend to extract texture-based information from the inputs, while adversarially trained models prefer to shape-based information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-adversarial-examples-and</guid>
    </item>
    <item>
      <title>UniNet: Unified Architecture Search with Convolution, Transformer, and MLP</title>
      <link>https://paperswithcode.com/paper/uninet-unified-architecture-search-with-1</link>
      <description><![CDATA[Finally, we integrate configurable operators and DSMs into a unified search space and search with a Reinforcement Learning-based search algorithm to fully explore the optimal combination of the operators.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uninet-unified-architecture-search-with-1</guid>
    </item>
    <item>
      <title>Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/temporal-disentanglement-of-representations</link>
      <description><![CDATA[In real-world robotics applications, Reinforcement Learning (RL) agents are often unable to generalise to environment variations that were not observed during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-disentanglement-of-representations</guid>
    </item>
    <item>
      <title>Modality-Aware Contrastive Instance Learning with Self-Distillation for Weakly-Supervised Audio-Visual Violence Detection</title>
      <link>https://paperswithcode.com/paper/modality-aware-contrastive-instance-learning</link>
      <description><![CDATA[In this paper, we analyze the modality asynchrony and undifferentiated instances phenomena of the multiple instance learning (MIL) procedure, and further investigate its negative impact on weakly-supervised audio-visual learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/modality-aware-contrastive-instance-learning</guid>
    </item>
    <item>
      <title>EfficientLEAF: A Faster LEarnable Audio Frontend of Questionable Use</title>
      <link>https://paperswithcode.com/paper/efficientleaf-a-faster-learnable-audio</link>
      <description><![CDATA[In audio classification, differentiable auditory filterbanks with few parameters cover the middle ground between hard-coded spectrograms and raw audio.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficientleaf-a-faster-learnable-audio</guid>
    </item>
    <item>
      <title>Camera Pose Auto-Encoders for Improving Pose Regression</title>
      <link>https://paperswithcode.com/paper/camera-pose-auto-encoders-for-improving-pose</link>
      <description><![CDATA[In this work, we introduce Camera Pose Auto-Encoders (PAEs), multilayer perceptrons that are trained via a Teacher-Student approach to encode camera poses using APRs as their teachers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camera-pose-auto-encoders-for-improving-pose</guid>
    </item>
    <item>
      <title>Reactive Exploration to Cope with Non-Stationarity in Lifelong Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/reactive-exploration-to-cope-with-non</link>
      <description><![CDATA[Therefore, exploration strategies and learning methods are required that are capable of tracking the steady domain shifts, and adapting to them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reactive-exploration-to-cope-with-non</guid>
    </item>
    <item>
      <title>Learning Diverse Tone Styles for Image Retouching</title>
      <link>https://paperswithcode.com/paper/learning-diverse-tone-styles-for-image</link>
      <description><![CDATA[In particular, the style encoder predicts the target style representation of an input image, which serves as the conditional information in the RetouchNet for retouching, while the TSFlow maps the style representation vector into a Gaussian distribution in the forward pass.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-diverse-tone-styles-for-image</guid>
    </item>
    <item>
      <title>Occluded Human Body Capture with Self-Supervised Spatial-Temporal Motion Prior</title>
      <link>https://paperswithcode.com/paper/occluded-human-body-capture-with-self</link>
      <description><![CDATA[To address the obstacles, our key-idea is to employ non-occluded human data to learn a joint-level spatial-temporal motion prior for occluded human with a self-supervised strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/occluded-human-body-capture-with-self</guid>
    </item>
    <item>
      <title>LightViT: Towards Light-Weight Convolution-Free Vision Transformers</title>
      <link>https://paperswithcode.com/paper/lightvit-towards-light-weight-convolution</link>
      <description><![CDATA[Vision transformers (ViTs) are usually considered to be less light-weight than convolutional neural networks (CNNs) due to the lack of inductive bias.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightvit-towards-light-weight-convolution</guid>
    </item>
    <item>
      <title>A Data-Based Perspective on Transfer Learning</title>
      <link>https://paperswithcode.com/paper/a-data-based-perspective-on-transfer-learning</link>
      <description><![CDATA[It is commonly believed that in transfer learning including more pre-training data translates into better performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-data-based-perspective-on-transfer-learning</guid>
    </item>
    <item>
      <title>DGPO: Discovering Multiple Strategies with Diversity-Guided Policy Optimization</title>
      <link>https://paperswithcode.com/paper/dgpo-discovering-multiple-strategies-with</link>
      <description><![CDATA[Recent algorithms designed for reinforcement learning tasks focus on finding a single optimal solution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dgpo-discovering-multiple-strategies-with</guid>
    </item>
  </channel>
</rss>
