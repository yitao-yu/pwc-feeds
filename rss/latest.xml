<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 04 Apr 2024 09:12:42 +0000</lastBuildDate>
    <item>
      <title>Efficient Multi-Vector Dense Retrieval Using Bit Vectors</title>
      <link>https://paperswithcode.com/paper/efficient-multi-vector-dense-retrieval-using</link>
      <description><![CDATA[This paper proposes ``Efficient Multi-Vector dense retrieval with Bit vectors'' (EMVB), a novel framework for efficient query processing in multi-vector dense retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-multi-vector-dense-retrieval-using</guid>
    </item>
    <item>
      <title>SG-BEV: Satellite-Guided BEV Fusion for Cross-View Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/sg-bev-satellite-guided-bev-fusion-for-cross</link>
      <description><![CDATA[This paper aims at achieving fine-grained building attribute segmentation in a cross-view scenario, i. e., using satellite and street-view image pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sg-bev-satellite-guided-bev-fusion-for-cross</guid>
    </item>
    <item>
      <title>Guarantees of confidentiality via Hammersley-Chapman-Robbins bounds</title>
      <link>https://paperswithcode.com/paper/guarantees-of-confidentiality-via-hammersley</link>
      <description><![CDATA[The HCR bounds appear to be insufficient on their own to guarantee confidentiality of the inputs to inference with standard deep neural nets, "ResNet-18" and "Swin-T," pre-trained on the data set, "ImageNet-1000," which contains 1000 classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/guarantees-of-confidentiality-via-hammersley</guid>
    </item>
    <item>
      <title>Grid-Mapping Pseudo-Count Constraint for Offline Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/grid-mapping-pseudo-count-constraint-for</link>
      <description><![CDATA[Offline reinforcement learning learns from a static dataset without interacting with the environment, which ensures security and thus owns a good prospect of application.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grid-mapping-pseudo-count-constraint-for</guid>
    </item>
    <item>
      <title>Scalable Model Editing via Customized Expert Networks</title>
      <link>https://paperswithcode.com/paper/scalable-model-editing-via-customized-expert</link>
      <description><![CDATA[Our experiments on two different sizes of open-source large language models, the Llama2 7B and 13B, achieve state-of-the-art results compared to existing mainstream Model Editing methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-model-editing-via-customized-expert</guid>
    </item>
    <item>
      <title>Masked Completion via Structured Diffusion with White-Box Transformers</title>
      <link>https://paperswithcode.com/paper/masked-completion-via-structured-diffusion</link>
      <description><![CDATA[We do this by exploiting a fundamental connection between diffusion, compression, and (masked) completion, deriving a deep transformer-like masked autoencoder architecture, called CRATE-MAE, in which the role of each layer is mathematically fully interpretable: they transform the data distribution to and from a structured representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-completion-via-structured-diffusion</guid>
    </item>
    <item>
      <title>CAPE: CAM as a Probabilistic Ensemble for Enhanced DNN Interpretation</title>
      <link>https://paperswithcode.com/paper/cape-cam-as-a-probabilistic-ensemble-for</link>
      <description><![CDATA[Deep Neural Networks (DNNs) are widely used for visual classification tasks, but their complex computation process and black-box nature hinder decision transparency and interpretability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cape-cam-as-a-probabilistic-ensemble-for</guid>
    </item>
    <item>
      <title>Exploring Backdoor Vulnerabilities of Chat Models</title>
      <link>https://paperswithcode.com/paper/exploring-backdoor-vulnerabilities-of-chat</link>
      <description><![CDATA[Chat models are extensively adopted across various real-world scenarios, thus the security of chat models deserves increasing attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-backdoor-vulnerabilities-of-chat</guid>
    </item>
    <item>
      <title>Unsupervised Learning of Effective Actions in Robotics</title>
      <link>https://paperswithcode.com/paper/unsupervised-learning-of-effective-actions-in</link>
      <description><![CDATA[Learning actions that are relevant to decision-making and can be executed effectively is a key problem in autonomous robotics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-learning-of-effective-actions-in</guid>
    </item>
    <item>
      <title>BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models</title>
      <link>https://paperswithcode.com/paper/badam-a-memory-efficient-full-parameter</link>
      <description><![CDATA[This work presents BAdam, an optimizer that leverages the block coordinate optimization framework with Adam as the inner solver.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/badam-a-memory-efficient-full-parameter</guid>
    </item>
    <item>
      <title>What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases</title>
      <link>https://paperswithcode.com/paper/what-are-we-measuring-when-we-evaluate-large</link>
      <description><![CDATA[Vision-language (VL) models, pretrained on colossal image-text datasets, have attained broad VL competence that is difficult to evaluate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-are-we-measuring-when-we-evaluate-large</guid>
    </item>
    <item>
      <title>Vestibular schwannoma growth_prediction from longitudinal MRI by time conditioned neural fields</title>
      <link>https://paperswithcode.com/paper/vestibular-schwannoma-growth-prediction-from</link>
      <description><![CDATA[In the proposed method, each tumor is represented as a signed distance function (SDF) conditioned on a low-dimensional latent code.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vestibular-schwannoma-growth-prediction-from</guid>
    </item>
    <item>
      <title>A School Student Essay Corpus for Analyzing Interactions of Argumentative Structure and Quality</title>
      <link>https://paperswithcode.com/paper/a-school-student-essay-corpus-for-analyzing</link>
      <description><![CDATA[When combined with automatic essay scoring, interactions of the argumentative structure and quality scores can be exploited for comprehensive writing support.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-school-student-essay-corpus-for-analyzing</guid>
    </item>
    <item>
      <title>Low-resource neural machine translation with morphological modeling</title>
      <link>https://paperswithcode.com/paper/low-resource-neural-machine-translation-with-1</link>
      <description><![CDATA[An attention augmentation scheme to the transformer model is proposed in a generic form to allow integration of pre-trained language models and also facilitate modeling of word order relationships between the source and target languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/low-resource-neural-machine-translation-with-1</guid>
    </item>
    <item>
      <title>Deep Image Composition Meets Image Forgery</title>
      <link>https://paperswithcode.com/paper/deep-image-composition-meets-image-forgery</link>
      <description><![CDATA[Unlike other automated data generation frameworks, we use state of the art image composition deep learning models to generate spliced images close to the quality of real-life manipulations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-image-composition-meets-image-forgery</guid>
    </item>
    <item>
      <title>Semi-Supervised Unconstrained Head Pose Estimation in the Wild</title>
      <link>https://paperswithcode.com/paper/semi-supervised-unconstrained-head-pose</link>
      <description><![CDATA[Existing head pose estimation datasets are either composed of numerous samples by non-realistic synthesis or lab collection, or limited images by labor-intensive annotating.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semi-supervised-unconstrained-head-pose</guid>
    </item>
    <item>
      <title>Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models</title>
      <link>https://paperswithcode.com/paper/conifer-improving-complex-constrained</link>
      <description><![CDATA[To address this challenge, we introduce Conifer, a novel instruction tuning dataset, designed to enhance LLMs to follow multi-level instructions with complex constraints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conifer-improving-complex-constrained</guid>
    </item>
    <item>
      <title>RS3Mamba: Visual State Space Model for Remote Sensing Images Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/rs3mamba-visual-state-space-model-for-remote</link>
      <description><![CDATA[Experimental results on two widely used datasets, ISPRS Vaihingen and LoveDA Urban, demonstrate the effectiveness and potential of the proposed RS3Mamba.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rs3mamba-visual-state-space-model-for-remote</guid>
    </item>
    <item>
      <title>Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset</title>
      <link>https://paperswithcode.com/paper/unbiased-learning-to-rank-meets-reality</link>
      <description><![CDATA[However, these gains in click prediction do not translate to enhanced ranking performance on expert relevance annotations, implying that conclusions strongly depend on how success is measured in this benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unbiased-learning-to-rank-meets-reality</guid>
    </item>
    <item>
      <title>Learning Alternative Ways of Performing a Task</title>
      <link>https://paperswithcode.com/paper/learning-alternative-ways-of-performing-a</link>
      <description><![CDATA[We evaluate the inferred models with respect to two metrics that measure how well the models represent the examples and capture the different forms of executing a task showed by the examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-alternative-ways-of-performing-a</guid>
    </item>
    <item>
      <title>Unsegment Anything by Simulating Deformation</title>
      <link>https://paperswithcode.com/paper/unsegment-anything-by-simulating-deformation</link>
      <description><![CDATA[Foundation segmentation models, while powerful, pose a significant risk: they enable users to effortlessly extract any objects from any digital content with a single click, potentially leading to copyright infringement or malicious misuse.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsegment-anything-by-simulating-deformation</guid>
    </item>
    <item>
      <title>uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?</title>
      <link>https://paperswithcode.com/paper/utebc-nlp-at-semeval-2024-task-9-can-llms-be</link>
      <description><![CDATA[Inspired by human cognition, Jiang et al.(2023c) create a benchmark for assessing LLMs' lateral thinking-thinking outside the box.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/utebc-nlp-at-semeval-2024-task-9-can-llms-be</guid>
    </item>
    <item>
      <title>SliceIt! -- A Dual Simulator Framework for Learning Robot Food Slicing</title>
      <link>https://paperswithcode.com/paper/sliceit-a-dual-simulator-framework-for</link>
      <description><![CDATA[Our approach involves using Reinforcement Learning (RL) to train a robot to compliantly manipulate a knife, by reducing the contact forces exerted by the food items and by the cutting board.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sliceit-a-dual-simulator-framework-for</guid>
    </item>
    <item>
      <title>LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis</title>
      <link>https://paperswithcode.com/paper/lidar4d-dynamic-neural-fields-for-novel-space</link>
      <description><![CDATA[In light of this, we propose LiDAR4D, a differentiable LiDAR-only framework for novel space-time LiDAR view synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lidar4d-dynamic-neural-fields-for-novel-space</guid>
    </item>
    <item>
      <title>Event Camera Demosaicing via Swin Transformer and Pixel-focus Loss</title>
      <link>https://paperswithcode.com/paper/event-camera-demosaicing-via-swin-transformer</link>
      <description><![CDATA[To end this, we present a Swin-Transformer-based backbone and a pixel-focus loss function for demosaicing with missing pixel values in RAW domain processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/event-camera-demosaicing-via-swin-transformer</guid>
    </item>
    <item>
      <title>Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/cross-attention-makes-inference-cumbersome-in</link>
      <description><![CDATA[This study explores the role of cross-attention during inference in text-conditional diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-attention-makes-inference-cumbersome-in</guid>
    </item>
    <item>
      <title>Linear Attention Sequence Parallelism</title>
      <link>https://paperswithcode.com/paper/linear-attention-sequence-parallelism</link>
      <description><![CDATA[In this paper, we introduce Linear Attention Sequence Parallel (LASP), an efficient SP method tailored to linear attention-based language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linear-attention-sequence-parallelism</guid>
    </item>
    <item>
      <title>ANGOFA: Leveraging OFA Embedding Initialization and Synthetic Data for Angolan Language Model</title>
      <link>https://paperswithcode.com/paper/angofa-leveraging-ofa-embedding</link>
      <description><![CDATA[In recent years, the development of pre-trained language models (PLMs) has gained momentum, showcasing their capacity to transcend linguistic barriers and facilitate knowledge transfer across diverse languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/angofa-leveraging-ofa-embedding</guid>
    </item>
    <item>
      <title>CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models</title>
      <link>https://paperswithcode.com/paper/cmulab-an-open-source-framework-for-training</link>
      <description><![CDATA[Effectively using Natural Language Processing (NLP) tools in under-resourced languages requires a thorough understanding of the language itself, familiarity with the latest models and training methodologies, and technical expertise to deploy these models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cmulab-an-open-source-framework-for-training</guid>
    </item>
    <item>
      <title>Large Language Models for Expansion of Spoken Language Understanding Systems to New Languages</title>
      <link>https://paperswithcode.com/paper/large-language-models-for-expansion-of-spoken</link>
      <description><![CDATA[In the on-device scenario (tiny and not pretrained SLU), our method improved the Overall Accuracy from 5. 31% to 22. 06% over the baseline Global-Local Contrastive Learning Framework (GL-CLeF) method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-for-expansion-of-spoken</guid>
    </item>
    <item>
      <title>FPT: Feature Prompt Tuning for Few-shot Readability Assessment</title>
      <link>https://paperswithcode.com/paper/fpt-feature-prompt-tuning-for-few-shot</link>
      <description><![CDATA[Our proposed method establishes a new architecture for prompt tuning that sheds light on how linguistic features can be easily adapted to linguistic-related tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fpt-feature-prompt-tuning-for-few-shot</guid>
    </item>
    <item>
      <title>DUQGen: Effective Unsupervised Domain Adaptation of Neural Rankers by Diversifying Synthetic Query Generation</title>
      <link>https://paperswithcode.com/paper/duqgen-effective-unsupervised-domain</link>
      <description><![CDATA[State-of-the-art neural rankers pre-trained on large task-specific training data such as MS-MARCO, have been shown to exhibit strong performance on various ranking tasks without domain adaptation, also called zero-shot.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/duqgen-effective-unsupervised-domain</guid>
    </item>
    <item>
      <title>Can We Understand Plasticity Through Neural Collapse?</title>
      <link>https://paperswithcode.com/paper/can-we-understand-plasticity-through-neural</link>
      <description><![CDATA[This paper explores the connection between two recently identified phenomena in deep learning: plasticity loss and neural collapse.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-we-understand-plasticity-through-neural</guid>
    </item>
    <item>
      <title>RS-Mamba for Large Remote Sensing Image Dense Prediction</title>
      <link>https://paperswithcode.com/paper/rs-mamba-for-large-remote-sensing-image-dense</link>
      <description><![CDATA[RSM is designed to model global features of remote sensing images with linear complexity, enabling it to process large VHR images effectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rs-mamba-for-large-remote-sensing-image-dense</guid>
    </item>
    <item>
      <title>FlightScope: A Deep Comprehensive Assessment of Aircraft Detection Algorithms in Satellite Imagery</title>
      <link>https://paperswithcode.com/paper/flightscope-a-deep-comprehensive-assessment</link>
      <description><![CDATA[Object detection in remotely sensed satellite pictures is fundamental in many fields such as biophysical, and environmental monitoring.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flightscope-a-deep-comprehensive-assessment</guid>
    </item>
    <item>
      <title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title>
      <link>https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</link>
      <description><![CDATA[We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine "next-scale prediction" or "next-resolution prediction", diverging from the standard raster-scan "next-token prediction".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</guid>
    </item>
    <item>
      <title>Effector: A Python package for regional explanations</title>
      <link>https://paperswithcode.com/paper/effector-a-python-package-for-regional</link>
      <description><![CDATA[Effector implements well-established global effect methods, assesses the heterogeneity of each method and, based on that, provides regional effects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effector-a-python-package-for-regional</guid>
    </item>
    <item>
      <title>On the Multilingual Ability of Decoder-based Pre-trained Language Models: Finding and Controlling Language-Specific Neurons</title>
      <link>https://paperswithcode.com/paper/on-the-multilingual-ability-of-decoder-based</link>
      <description><![CDATA[Additionally, we tamper with less than 1% of the total neurons in each model during inference and demonstrate that tampering with a few language-specific neurons drastically changes the probability of target language occurrence in text generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-multilingual-ability-of-decoder-based</guid>
    </item>
    <item>
      <title>HENet: Hybrid Encoding for End-to-end Multi-task 3D Perception from Multi-view Cameras</title>
      <link>https://paperswithcode.com/paper/henet-hybrid-encoding-for-end-to-end-multi</link>
      <description><![CDATA[Three-dimensional perception from multi-view cameras is a crucial component in autonomous driving systems, which involves multiple tasks like 3D object detection and bird's-eye-view (BEV) semantic segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/henet-hybrid-encoding-for-end-to-end-multi</guid>
    </item>
    <item>
      <title>The VoicePrivacy 2024 Challenge Evaluation Plan</title>
      <link>https://paperswithcode.com/paper/the-voiceprivacy-2024-challenge-evaluation</link>
      <description><![CDATA[The task of the challenge is to develop a voice anonymization system for speech data which conceals the speaker's voice identity while protecting linguistic content and emotional states.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-voiceprivacy-2024-challenge-evaluation</guid>
    </item>
    <item>
      <title>Multi-Granularity Guided Fusion-in-Decoder</title>
      <link>https://paperswithcode.com/paper/multi-granularity-guided-fusion-in-decoder</link>
      <description><![CDATA[In Open-domain Question Answering (ODQA), it is essential to discern relevant contexts as evidence and avoid spurious ones among retrieved results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-granularity-guided-fusion-in-decoder</guid>
    </item>
    <item>
      <title>A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability</title>
      <link>https://paperswithcode.com/paper/a-unified-membership-inference-method-for</link>
      <description><![CDATA[In this setting, considering that self-supervised model could be trained by completely different self-supervised paradigms, e. g., masked image modeling and contrastive learning, with complex training details, we propose a unified membership inference method called PartCrop.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-unified-membership-inference-method-for</guid>
    </item>
    <item>
      <title>InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/instantstyle-free-lunch-towards-style</link>
      <description><![CDATA[Tuning-free diffusion-based models have demonstrated significant potential in the realm of image personalization and customization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantstyle-free-lunch-towards-style</guid>
    </item>
    <item>
      <title>Adaptive Cross-lingual Text Classification through In-Context One-Shot Demonstrations</title>
      <link>https://paperswithcode.com/paper/adaptive-cross-lingual-text-classification</link>
      <description><![CDATA[Zero-Shot Cross-lingual Transfer (ZS-XLT) utilizes a model trained in a source language to make predictions in another language, often with a performance loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-cross-lingual-text-classification</guid>
    </item>
    <item>
      <title>The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers</title>
      <link>https://paperswithcode.com/paper/the-realhumaneval-evaluating-large-language</link>
      <description><![CDATA[Evaluation of large language models (LLMs) for code has primarily relied on static benchmarks, including HumanEval (Chen et al., 2021), which measure the ability of LLMs to generate complete code that passes unit tests.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-realhumaneval-evaluating-large-language</guid>
    </item>
    <item>
      <title>Event Detection from Social Media for Epidemic Prediction</title>
      <link>https://paperswithcode.com/paper/event-detection-from-social-media-for</link>
      <description><![CDATA[In our work, we pioneer exploiting Event Detection (ED) for better preparedness and early warnings of any upcoming epidemic by developing a framework to extract and analyze epidemic-related events from social media posts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/event-detection-from-social-media-for</guid>
    </item>
    <item>
      <title>FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning</title>
      <link>https://paperswithcode.com/paper/flawn-t5-an-empirical-examination-of</link>
      <description><![CDATA[In this work, we curate LawInstruct, a large legal instruction dataset, covering 17 jurisdictions, 24 languages and a total of 12M examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flawn-t5-an-empirical-examination-of</guid>
    </item>
    <item>
      <title>OOSTraj: Out-of-Sight Trajectory Prediction With Vision-Positioning Denoising</title>
      <link>https://paperswithcode.com/paper/oostraj-out-of-sight-trajectory-prediction</link>
      <description><![CDATA[By enhancing trajectory prediction accuracy and addressing the challenges of out-of-sight objects, our work significantly contributes to improving the safety and reliability of autonomous driving in complex environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oostraj-out-of-sight-trajectory-prediction</guid>
    </item>
    <item>
      <title>Deep Neural Networks with 3D Point Clouds for Empirical Friction Measurements in Hydrodynamic Flood Models</title>
      <link>https://paperswithcode.com/paper/deep-neural-networks-with-3d-point-clouds-for</link>
      <description><![CDATA[For these reasons, the lidar measurements of Manning's n were found to improve both regulatory models and forecasts for extreme storm events, while simultaneously providing a pathway to standardize the measurement of FFs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-neural-networks-with-3d-point-clouds-for</guid>
    </item>
    <item>
      <title>Scene Adaptive Sparse Transformer for Event-based Object Detection</title>
      <link>https://paperswithcode.com/paper/scene-adaptive-sparse-transformer-for-event</link>
      <description><![CDATA[However, they display inadequate sparsity and adaptability when applied to event-based object detection, since these approaches cannot balance the fine granularity of token-level sparsification and the efficiency of window-based Transformers, leading to reduced performance and efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scene-adaptive-sparse-transformer-for-event</guid>
    </item>
  </channel>
</rss>
