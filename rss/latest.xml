<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 13 May 2025 09:18:56 +0000</lastBuildDate>
    <item>
      <title>Unified Continuous Generative Models</title>
      <link>https://paperswithcode.com/paper/unified-continuous-generative-models</link>
      <description><![CDATA[We introduce a unified framework for training, sampling, and analyzing these models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-continuous-generative-models</guid>
    </item>
    <item>
      <title>You Only Look One Step: Accelerating Backpropagation in Diffusion Sampling with Gradient Shortcuts</title>
      <link>https://paperswithcode.com/paper/you-only-look-one-step-accelerating</link>
      <description><![CDATA[However, many downstream tasks require guiding the generated content based on specific differentiable metrics, typically necessitating backpropagation during the generation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/you-only-look-one-step-accelerating</guid>
    </item>
    <item>
      <title>AIS Data-Driven Maritime Monitoring Based on Transformer: A Comprehensive Review</title>
      <link>https://paperswithcode.com/paper/ais-data-driven-maritime-monitoring-based-on</link>
      <description><![CDATA[Therefore, this paper reviews the research on Transformer-based AIS data-driven maritime monitoring, providing a comprehensive overview of the current applications of Transformer models in the marine field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ais-data-driven-maritime-monitoring-based-on</guid>
    </item>
    <item>
      <title>Pre-training vs. Fine-tuning: A Reproducibility Study on Dense Retrieval Knowledge Acquisition</title>
      <link>https://paperswithcode.com/paper/pre-training-vs-fine-tuning-a-reproducibility</link>
      <description><![CDATA[Recent research has questioned the role of fine-tuning vs. that of pre-training within dense retrievers, specifically arguing that retrieval knowledge is primarily gained during pre-training, meaning knowledge not acquired during pre-training cannot be sub-sequentially acquired via fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pre-training-vs-fine-tuning-a-reproducibility</guid>
    </item>
    <item>
      <title>HALO: Half Life-Based Outdated Fact Filtering in Temporal Knowledge Graphs</title>
      <link>https://paperswithcode.com/paper/halo-half-life-based-outdated-fact-filtering</link>
      <description><![CDATA[HALO consists of three modules: the temporal fact attention module, the dynamic relation-aware encoder module, and the outdated fact filtering module.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/halo-half-life-based-outdated-fact-filtering</guid>
    </item>
    <item>
      <title>Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model</title>
      <link>https://paperswithcode.com/paper/ophora-a-large-scale-data-driven-text-guided</link>
      <description><![CDATA[In ophthalmic surgery, developing an AI system capable of interpreting surgical videos and predicting subsequent operations requires numerous ophthalmic surgical videos with high-quality annotations, which are difficult to collect due to privacy concerns and labor consumption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ophora-a-large-scale-data-driven-text-guided</guid>
    </item>
    <item>
      <title>ReCDAP: Relation-Based Conditional Diffusion with Attention Pooling for Few-Shot Knowledge Graph Completion</title>
      <link>https://paperswithcode.com/paper/recdap-relation-based-conditional-diffusion</link>
      <description><![CDATA[Knowledge Graphs (KGs), composed of triples in the form of (head, relation, tail) and consisting of entities and relations, play a key role in information retrieval systems such as question answering, entity search, and recommendation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recdap-relation-based-conditional-diffusion</guid>
    </item>
    <item>
      <title>ABS-Mamba: SAM2-Driven Bidirectional Spiral Mamba Network for Medical Image Translation</title>
      <link>https://paperswithcode.com/paper/abs-mamba-sam2-driven-bidirectional-spiral</link>
      <description><![CDATA[Accurate multi-modal medical image translation requires ha-rmonizing global anatomical semantics and local structural fidelity, a challenge complicated by intermodality information loss and structural distortion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/abs-mamba-sam2-driven-bidirectional-spiral</guid>
    </item>
    <item>
      <title>From Search To Sampling: Generative Models For Robust Algorithmic Recourse</title>
      <link>https://paperswithcode.com/paper/from-search-to-sampling-generative-models-for</link>
      <description><![CDATA[We show that existing methods train for these objectives separately and then search for recourse through a joint optimization over the recourse goals during inference, leading to poor recourse recommendations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-search-to-sampling-generative-models-for</guid>
    </item>
    <item>
      <title>Anatomical Attention Alignment representation for Radiology Report Generation</title>
      <link>https://paperswithcode.com/paper/anatomical-attention-alignment-representation</link>
      <description><![CDATA[Automated Radiology report generation (RRG) aims at producing detailed descriptions of medical images, reducing radiologists' workload and improving access to high-quality diagnostic services.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anatomical-attention-alignment-representation</guid>
    </item>
    <item>
      <title>Towards Autonomous 1/8th Offroad RC Racing -- The TruggySense Educational Platform</title>
      <link>https://paperswithcode.com/paper/towards-autonomous-1-8th-offroad-rc-racing</link>
      <description><![CDATA[This paper presents a state-of-the-art Data Acquisition System designed for off-road conditions, deployed on a Team Corally Kagama 1/8 Remote Controlled Vehicle.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-autonomous-1-8th-offroad-rc-racing</guid>
    </item>
    <item>
      <title>Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving</title>
      <link>https://paperswithcode.com/paper/agent-rl-scaling-law-agent-rl-with</link>
      <description><![CDATA[Large Language Models (LLMs) often struggle with mathematical reasoning tasks requiring precise, verifiable computation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agent-rl-scaling-law-agent-rl-with</guid>
    </item>
    <item>
      <title>ALPCAH: Subspace Learning for Sample-wise Heteroscedastic Data</title>
      <link>https://paperswithcode.com/paper/alpcah-subspace-learning-for-sample-wise</link>
      <description><![CDATA[This paper develops a subspace learning method, named ALPCAH, that can estimate the sample-wise noise variances and use this information to improve the estimate of the subspace basis associated with the low-rank structure of the data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alpcah-subspace-learning-for-sample-wise</guid>
    </item>
    <item>
      <title>Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs</title>
      <link>https://paperswithcode.com/paper/structural-entropy-guided-agent-for-detecting</link>
      <description><![CDATA[Large language models (LLMs) have achieved unprecedented performance by leveraging vast pretraining corpora, yet their performance remains suboptimal in knowledge-intensive domains such as medicine and scientific research, where high factual precision is required.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structural-entropy-guided-agent-for-detecting</guid>
    </item>
    <item>
      <title>Boosting Global-Local Feature Matching via Anomaly Synthesis for Multi-Class Point Cloud Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/boosting-global-local-feature-matching-via-1</link>
      <description><![CDATA[Specifically, GLFM is structured into three stages: Stage-I proposes an anomaly synthesis pipeline that stretches point clouds to create abundant anomaly data that are utilized to adapt the point cloud feature extractor for better feature representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-global-local-feature-matching-via-1</guid>
    </item>
    <item>
      <title>Continuous Visual Autoregressive Generation via Score Maximization</title>
      <link>https://paperswithcode.com/paper/continuous-visual-autoregressive-generation</link>
      <description><![CDATA[When applied to continuous modalities such as visual data, Visual AutoRegressive modeling (VAR) typically resorts to quantization-based approaches to cast the data into a discrete space, which can introduce significant information loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/continuous-visual-autoregressive-generation</guid>
    </item>
    <item>
      <title>MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining</title>
      <link>https://paperswithcode.com/paper/mimo-unlocking-the-reasoning-potential-of</link>
      <description><![CDATA[We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mimo-unlocking-the-reasoning-potential-of</guid>
    </item>
    <item>
      <title>Kalman Filter Enhanced GRPO for Reinforcement Learning-Based Language Model Reasoning</title>
      <link>https://paperswithcode.com/paper/kalman-filter-enhanced-grpo-for-reinforcement</link>
      <description><![CDATA[Recently, for language modeling, Group Relative Policy Optimization (GRPO) is proposed to compute the advantage for each output by subtracting the mean reward, as the baseline, for all outputs in the group.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kalman-filter-enhanced-grpo-for-reinforcement</guid>
    </item>
    <item>
      <title>DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/dynamicrag-leveraging-outputs-of-large</link>
      <description><![CDATA[Retrieval-augmented generation (RAG) systems combine large language models (LLMs) with external knowledge retrieval, making them highly effective for knowledge-intensive tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamicrag-leveraging-outputs-of-large</guid>
    </item>
    <item>
      <title>Language-Driven Dual Style Mixing for Single-Domain Generalized Object Detection</title>
      <link>https://paperswithcode.com/paper/language-driven-dual-style-mixing-for-single</link>
      <description><![CDATA[Then, we propose image-level style mixing between the diversified images and source domain images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-driven-dual-style-mixing-for-single</guid>
    </item>
    <item>
      <title>High-Frequency Prior-Driven Adaptive Masking for Accelerating Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/high-frequency-prior-driven-adaptive-masking</link>
      <description><![CDATA[The primary challenge in accelerating image super-resolution lies in reducing computation while maintaining performance and adaptability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-frequency-prior-driven-adaptive-masking</guid>
    </item>
    <item>
      <title>A Split-then-Join Approach to Abstractive Summarization for Very Long Documents in a Low Resource Setting</title>
      <link>https://paperswithcode.com/paper/a-split-then-join-approach-to-abstractive</link>
      <description><![CDATA[We'll use the pretrained $\texttt{BIGBIRD-PEGASUS}$ model by fine tuned the model on other domain dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-split-then-join-approach-to-abstractive</guid>
    </item>
    <item>
      <title>From Knowledge to Reasoning: Evaluating LLMs for Ionic Liquids Research in Chemical and Biological Engineering</title>
      <link>https://paperswithcode.com/paper/from-knowledge-to-reasoning-evaluating-llms</link>
      <description><![CDATA[Although Large Language Models (LLMs) have achieved remarkable performance in diverse general knowledge and reasoning tasks, their utility in the scientific domain of Chemical and Biological Engineering (CBE) is unclear.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-knowledge-to-reasoning-evaluating-llms</guid>
    </item>
    <item>
      <title>MELLM: Exploring LLM-Powered Micro-Expression Understanding Enhanced by Subtle Motion Perception</title>
      <link>https://paperswithcode.com/paper/mellm-exploring-llm-powered-micro-expression</link>
      <description><![CDATA[In this paper, we propose a novel Micro-Expression Large Language Model (MELLM), which incorporates a subtle facial motion perception strategy with the strong inference capabilities of MLLMs, representing the first exploration of MLLMs in the domain of ME analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mellm-exploring-llm-powered-micro-expression</guid>
    </item>
    <item>
      <title>Learning Soft Sparse Shapes for Efficient Time-Series Classification</title>
      <link>https://paperswithcode.com/paper/learning-soft-sparse-shapes-for-efficient</link>
      <description><![CDATA[To this end, we propose a \textbf{Soft} sparse \textbf{Shape}s (\textbf{SoftShape}) model for efficient time series classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-soft-sparse-shapes-for-efficient</guid>
    </item>
    <item>
      <title>Semantic-Guided Diffusion Model for Single-Step Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/semantic-guided-diffusion-model-for-single</link>
      <description><![CDATA[To address this limitation, we propose SAMSR, a semantic-guided diffusion framework that incorporates semantic segmentation masks into the sampling process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-guided-diffusion-model-for-single</guid>
    </item>
    <item>
      <title>Multimodal Fake News Detection: MFND Dataset and Shallow-Deep Multitask Learning</title>
      <link>https://paperswithcode.com/paper/multimodal-fake-news-detection-mfnd-dataset</link>
      <description><![CDATA[Furthermore, we propose a Shallow-Deep Multitask Learning (SDML) model for fake news, which fully uses unimodal and mutual modal features to mine the intrinsic semantics of news.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-fake-news-detection-mfnd-dataset</guid>
    </item>
    <item>
      <title>GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance</title>
      <link>https://paperswithcode.com/paper/guidedquant-large-language-model-quantization</link>
      <description><![CDATA[Post-training quantization is a key technique for reducing the memory and inference latency of large language models by quantizing weights and activations without requiring retraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/guidedquant-large-language-model-quantization</guid>
    </item>
    <item>
      <title>Transformer-Based Dual-Optical Attention Fusion Crowd Head Point Counting and Localization Network</title>
      <link>https://paperswithcode.com/paper/transformer-based-dual-optical-attention</link>
      <description><![CDATA[In this paper, the dual-optical attention fusion crowd head point counting model (TAPNet) is proposed to address the problem of the difficulty of accurate counting in complex scenes such as crowd dense occlusion and low light in crowd counting tasks under UAV view.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-based-dual-optical-attention</guid>
    </item>
    <item>
      <title>TACFN: Transformer-based Adaptive Cross-modal Fusion Network for Multimodal Emotion Recognition</title>
      <link>https://paperswithcode.com/paper/tacfn-transformer-based-adaptive-cross-modal</link>
      <description><![CDATA[Specifically, for the redundant features, we make one modality perform intra-modal feature selection through a self-attention mechanism, so that the selected features can adaptively and efficiently interact with another modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tacfn-transformer-based-adaptive-cross-modal</guid>
    </item>
    <item>
      <title>FNBench: Benchmarking Robust Federated Learning against Noisy Labels</title>
      <link>https://paperswithcode.com/paper/fnbench-benchmarking-robust-federated</link>
      <description><![CDATA[There have been some early attempts to tackle noisy labels in FL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fnbench-benchmarking-robust-federated</guid>
    </item>
    <item>
      <title>Compact and Efficient Neural Networks for Image Recognition Based on Learned 2D Separable Transform</title>
      <link>https://paperswithcode.com/paper/compact-and-efficient-neural-networks-for</link>
      <description><![CDATA[The LST based on the idea of sharing the weights of one fullyconnected (FC) layer to process all rows of an image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compact-and-efficient-neural-networks-for</guid>
    </item>
    <item>
      <title>ReplayCAD: Generative Diffusion Replay for Continual Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/replaycad-generative-diffusion-replay-for</link>
      <description><![CDATA[Specifically, we compress historical data by searching for a class semantic embedding in the conditional space of the pre-trained diffusion model, which can guide the model to replay data with fine-grained pixel details, thus improving the segmentation performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/replaycad-generative-diffusion-replay-for</guid>
    </item>
    <item>
      <title>Quadrupedal Robot Skateboard Mounting via Reverse Curriculum Learning</title>
      <link>https://paperswithcode.com/paper/quadrupedal-robot-skateboard-mounting-via</link>
      <description><![CDATA[The aim of this work is to enable quadrupedal robots to mount skateboards using Reverse Curriculum Reinforcement Learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quadrupedal-robot-skateboard-mounting-via</guid>
    </item>
    <item>
      <title>Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model Capabilities</title>
      <link>https://paperswithcode.com/paper/text-to-cadquery-a-new-paradigm-for-cad</link>
      <description><![CDATA[To tackle this issue, we propose generating CadQuery code directly from text, leveraging the strengths of pretrained LLMs to produce 3D models without intermediate representations, using this Python-based scripting language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-to-cadquery-a-new-paradigm-for-cad</guid>
    </item>
    <item>
      <title>Improving Generalization of Medical Image Registration Foundation Model</title>
      <link>https://paperswithcode.com/paper/improving-generalization-of-medical-image</link>
      <description><![CDATA[Deformable registration is a fundamental task in medical image processing, aiming to achieve precise alignment by establishing nonlinear correspondences between images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-generalization-of-medical-image</guid>
    </item>
    <item>
      <title>SmartPilot: A Multiagent CoPilot for Adaptive and Intelligent Manufacturing</title>
      <link>https://paperswithcode.com/paper/smartpilot-a-multiagent-copilot-for-adaptive</link>
      <description><![CDATA[In the dynamic landscape of Industry 4. 0, achieving efficiency, precision, and adaptability is essential to optimize manufacturing operations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smartpilot-a-multiagent-copilot-for-adaptive</guid>
    </item>
    <item>
      <title>HCMA: Hierarchical Cross-model Alignment for Grounded Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/hcma-hierarchical-cross-model-alignment-for</link>
      <description><![CDATA[Text-to-image synthesis has progressed to the point where models can generate visually compelling images from natural language prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hcma-hierarchical-cross-model-alignment-for</guid>
    </item>
    <item>
      <title>Quantum RNNs and LSTMs Through Entangling and Disentangling Power of Unitary Transformations</title>
      <link>https://paperswithcode.com/paper/quantum-rnns-and-lstms-through-entangling-and</link>
      <description><![CDATA[In this paper, we discuss how quantum recurrent neural networks (RNNs) and their enhanced version, long short-term memory (LSTM) networks, can be modeled using the core ideas presented in Ref.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quantum-rnns-and-lstms-through-entangling-and</guid>
    </item>
    <item>
      <title>Learning Graph Representation of Agent Diffuser</title>
      <link>https://paperswithcode.com/paper/learning-graph-representation-of-agent</link>
      <description><![CDATA[Our approach employs a coordination mechanism based on top-$k$ maximum spanning trees, optimizing the generation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-graph-representation-of-agent</guid>
    </item>
    <item>
      <title>GBDTSVM: Combined Support Vector Machine and Gradient Boosting Decision Tree Framework for efficient snoRNA-disease association prediction</title>
      <link>https://paperswithcode.com/paper/gbdtsvm-combined-support-vector-machine-and</link>
      <description><![CDATA[Consequently, the precise identification of snoRNA-disease associations (SDAs) is essential for the progression of diseases and the advancement of treatment strategies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gbdtsvm-combined-support-vector-machine-and</guid>
    </item>
    <item>
      <title>Enhancing BERTopic with Intermediate Layer Representations</title>
      <link>https://paperswithcode.com/paper/enhancing-bertopic-with-intermediate-layer</link>
      <description><![CDATA[BERTopic is a topic modeling algorithm that leverages transformer-based embeddings to create dense clusters, enabling the estimation of topic structures and the extraction of valuable insights from a corpus of documents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-bertopic-with-intermediate-layer</guid>
    </item>
    <item>
      <title>Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free</title>
      <link>https://paperswithcode.com/paper/gated-attention-for-large-language-models-non</link>
      <description><![CDATA[Gating mechanisms have been widely utilized, from early models like LSTMs and Highway Networks to recent state space models, linear attention, and also softmax attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gated-attention-for-large-language-models-non</guid>
    </item>
    <item>
      <title>Batch Augmentation with Unimodal Fine-tuning for Multimodal Learning</title>
      <link>https://paperswithcode.com/paper/batch-augmentation-with-unimodal-fine-tuning</link>
      <description><![CDATA[We also prescribe pre-training initial layers with investigated medical data before the multimodal training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/batch-augmentation-with-unimodal-fine-tuning</guid>
    </item>
    <item>
      <title>MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG</title>
      <link>https://paperswithcode.com/paper/macrag-compress-slice-and-scale-up-for-multi</link>
      <description><![CDATA[Long-context (LC) Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) hold strong potential for complex multi-hop and large-document tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/macrag-compress-slice-and-scale-up-for-multi</guid>
    </item>
    <item>
      <title>Probing In-Context Learning: Impact of Task Complexity and Model Architecture on Generalization and Efficiency</title>
      <link>https://paperswithcode.com/paper/probing-in-context-learning-impact-of-task</link>
      <description><![CDATA[We investigate in-context learning (ICL) through a meticulous experimental framework that systematically varies task complexity and model architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probing-in-context-learning-impact-of-task</guid>
    </item>
    <item>
      <title>Dual-level Fuzzy Learning with Patch Guidance for Image Ordinal Regression</title>
      <link>https://paperswithcode.com/paper/dual-level-fuzzy-learning-with-patch-guidance</link>
      <description><![CDATA[In this paper, we propose a Dual-level Fuzzy Learning with Patch Guidance framework, named DFPG that learns precise feature-based grading boundaries from ambiguous ordinal labels, with patch-level supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-level-fuzzy-learning-with-patch-guidance</guid>
    </item>
    <item>
      <title>Open Set Label Shift with Test Time Out-of-Distribution Reference</title>
      <link>https://paperswithcode.com/paper/open-set-label-shift-with-test-time-out-of</link>
      <description><![CDATA[With reasonable assumptions on the ID/OOD classifier, the estimators are assembled into a sequence of three stages: 1) an estimate of the source label distribution of the OOD class, 2) an EM algorithm for Maximum Likelihood estimates (MLE) of the target label distribution, and 3) an estimate of the target label distribution of OOD class under relaxed assumptions on the OOD classifier.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-set-label-shift-with-test-time-out-of</guid>
    </item>
    <item>
      <title>LLMs Get Lost In Multi-Turn Conversation</title>
      <link>https://paperswithcode.com/paper/llms-get-lost-in-multi-turn-conversation</link>
      <description><![CDATA[Large Language Models (LLMs) are conversational interfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llms-get-lost-in-multi-turn-conversation</guid>
    </item>
    <item>
      <title>Deep Diffusion Maps</title>
      <link>https://paperswithcode.com/paper/deep-diffusion-maps</link>
      <description><![CDATA[Dimensionality reduction methods make it possible to combat the so-called curse of dimensionality, visualize high-dimensional data and, in general, improve the efficiency of storing and processing large data sets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-diffusion-maps</guid>
    </item>
  </channel>
</rss>
