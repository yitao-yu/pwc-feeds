<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 25 Aug 2023 09:11:20 +0000</lastBuildDate>
    <item>
      <title>Large Language Models Vote: Prompting for Rare Disease Identification</title>
      <link>https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</link>
      <description><![CDATA[The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</guid>
    </item>
    <item>
      <title>REB: Reducing Biases in Representation for Industrial Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/reb-reducing-biases-in-representation-for</link>
      <description><![CDATA[Additionally, we propose a local density KNN (LDKNN) to reduce the local density bias and obtain effective anomaly detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reb-reducing-biases-in-representation-for</guid>
    </item>
    <item>
      <title>Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods</title>
      <link>https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</link>
      <description><![CDATA[We introduce an open-source GitHub repository containing comprehensive benchmarks for a wide range of machine scheduling problems, including Job Shop Scheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling (FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent Setup Times (FJSP-SDST), and the online FJSP (with online job arrivals).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</guid>
    </item>
    <item>
      <title>Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis</title>
      <link>https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</link>
      <description><![CDATA[The model pretrained on large-scale rs-fMRI data has been released to the public.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</guid>
    </item>
    <item>
      <title>CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias</title>
      <link>https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</link>
      <description><![CDATA[To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</guid>
    </item>
    <item>
      <title>Fast Adversarial Training with Smooth Convergence</title>
      <link>https://paperswithcode.com/paper/fast-adversarial-training-with-smooth</link>
      <description><![CDATA[To address this, we analyze the training process of prior FAT work and observe that catastrophic overfitting is accompanied by the appearance of loss convergence outliers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-adversarial-training-with-smooth</guid>
    </item>
    <item>
      <title>Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities</title>
      <link>https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</link>
      <description><![CDATA[We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</guid>
    </item>
    <item>
      <title>American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers</title>
      <link>https://paperswithcode.com/paper/american-stories-a-large-scale-structured</link>
      <description><![CDATA[The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/american-stories-a-large-scale-structured</guid>
    </item>
    <item>
      <title>Masked Autoencoders are Efficient Class Incremental Learners</title>
      <link>https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</link>
      <description><![CDATA[Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</guid>
    </item>
    <item>
      <title>NOVA: NOvel View Augmentation for Neural Composition of Dynamic Objects</title>
      <link>https://paperswithcode.com/paper/nova-novel-view-augmentation-for-neural</link>
      <description><![CDATA[We propose a novel-view augmentation (NOVA) strategy to train NeRFs for photo-realistic 3D composition of dynamic objects in a static scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nova-novel-view-augmentation-for-neural</guid>
    </item>
    <item>
      <title>Mutual-Guided Dynamic Network for Image Fusion</title>
      <link>https://paperswithcode.com/paper/mutual-guided-dynamic-network-for-image</link>
      <description><![CDATA[Image fusion aims to generate a high-quality image from multiple images captured under varying conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mutual-guided-dynamic-network-for-image</guid>
    </item>
    <item>
      <title>BridgeData V2: A Dataset for Robot Learning at Scale</title>
      <link>https://paperswithcode.com/paper/bridgedata-v2-a-dataset-for-robot-learning-at</link>
      <description><![CDATA[By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridgedata-v2-a-dataset-for-robot-learning-at</guid>
    </item>
    <item>
      <title>Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?</title>
      <link>https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</link>
      <description><![CDATA[The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</guid>
    </item>
    <item>
      <title>Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines</title>
      <link>https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</link>
      <description><![CDATA[This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</guid>
    </item>
    <item>
      <title>Robotic Scene Segmentation with Memory Network for Runtime Surgical Context Inference</title>
      <link>https://paperswithcode.com/paper/robotic-scene-segmentation-with-memory</link>
      <description><![CDATA[However, runtime context inference is challenging since it requires timely and accurate detection of the interactions among the tools and objects in the surgical scene based on the segmentation of video data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robotic-scene-segmentation-with-memory</guid>
    </item>
    <item>
      <title>HuBo-VLM: Unified Vision-Language Model designed for HUman roBOt interaction tasks</title>
      <link>https://paperswithcode.com/paper/hubo-vlm-unified-vision-language-model</link>
      <description><![CDATA[Human robot interaction is an exciting task, which aimed to guide robots following instructions from human.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hubo-vlm-unified-vision-language-model</guid>
    </item>
    <item>
      <title>Implicit Obstacle Map-driven Indoor Navigation Model for Robust Obstacle Avoidance</title>
      <link>https://paperswithcode.com/paper/implicit-obstacle-map-driven-indoor</link>
      <description><![CDATA[Robust obstacle avoidance is one of the critical steps for successful goal-driven indoor navigation tasks. Due to the obstacle missing in the visual image and the possible missed detection issue, visual image-based obstacle avoidance techniques still suffer from unsatisfactory robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implicit-obstacle-map-driven-indoor</guid>
    </item>
    <item>
      <title>DD-GCN: Directed Diffusion Graph Convolutional Network for Skeleton-based Human Action Recognition</title>
      <link>https://paperswithcode.com/paper/dd-gcn-directed-diffusion-graph-convolutional</link>
      <description><![CDATA[Graph Convolutional Networks (GCNs) have been widely used in skeleton-based human action recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dd-gcn-directed-diffusion-graph-convolutional</guid>
    </item>
    <item>
      <title>Grounded Entity-Landmark Adaptive Pre-training for Vision-and-Language Navigation</title>
      <link>https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</link>
      <description><![CDATA[To address this problem, we propose a novel Grounded Entity-Landmark Adaptive (GELA) pre-training paradigm for VLN tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</guid>
    </item>
    <item>
      <title>Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</link>
      <description><![CDATA[The challenges of this task lie in the complexity of the scenes, the unique features of anime style, and the lack of high-quality datasets to bridge the domain gap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</guid>
    </item>
    <item>
      <title>Perspective-aware Convolution for Monocular 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</link>
      <description><![CDATA[Monocular 3D object detection is a crucial and challenging task for autonomous driving vehicle, while it uses only a single camera image to infer 3D objects in the scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</guid>
    </item>
    <item>
      <title>Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]</title>
      <link>https://paperswithcode.com/paper/unified-data-management-and-comprehensive</link>
      <description><![CDATA[The field of urban spatial-temporal prediction is advancing rapidly with the development of deep learning techniques and the availability of large-scale datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-data-management-and-comprehensive</guid>
    </item>
    <item>
      <title>Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers</title>
      <link>https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</link>
      <description><![CDATA[Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</guid>
    </item>
    <item>
      <title>Single-shot Bayesian approximation for neural networks</title>
      <link>https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</link>
      <description><![CDATA[We demonstrate that our single-shot MC dropout approximation resembles the point estimate and the uncertainty estimate of the predictive distribution that is achieved with an MC approach, while being fast enough for real-time deployments of BNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</guid>
    </item>
    <item>
      <title>Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints</title>
      <link>https://paperswithcode.com/paper/master-slave-deep-architecture-for-top-k</link>
      <description><![CDATA[We propose a novel master-slave architecture to solve the top-$K$ combinatorial multi-armed bandits problem with non-linear bandit feedback and diversity constraints, which, to the best of our knowledge, is the first combinatorial bandits setting considering diversity constraints under bandit feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/master-slave-deep-architecture-for-top-k</guid>
    </item>
    <item>
      <title>Less is More: Towards Efficient Few-shot 3D Semantic Segmentation via Training-free Networks</title>
      <link>https://paperswithcode.com/paper/less-is-more-towards-efficient-few-shot-3d</link>
      <description><![CDATA[However, the prior pre-training stage not only introduces excessive time overhead, but also incurs a significant domain gap on `unseen' classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-is-more-towards-efficient-few-shot-3d</guid>
    </item>
    <item>
      <title>kTrans: Knowledge-Aware Transformer for Binary Code Embedding</title>
      <link>https://paperswithcode.com/paper/ktrans-knowledge-aware-transformer-for-binary</link>
      <description><![CDATA[By feeding explicit knowledge as additional inputs to the Transformer, and fusing implicit knowledge with a novel pre-training task, kTrans provides a new perspective to incorporating domain knowledge into a Transformer framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ktrans-knowledge-aware-transformer-for-binary</guid>
    </item>
    <item>
      <title>On Popularity Bias of Multimodal-aware Recommender Systems: a Modalities-driven Analysis</title>
      <link>https://paperswithcode.com/paper/on-popularity-bias-of-multimodal-aware</link>
      <description><![CDATA[Multimodal-aware recommender systems (MRSs) exploit multimodal content (e. g., product images or descriptions) as items' side information to improve recommendation accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-popularity-bias-of-multimodal-aware</guid>
    </item>
    <item>
      <title>Laying foundations to quantify the "Effort of Reproducibility"</title>
      <link>https://paperswithcode.com/paper/laying-foundations-to-quantify-the-effort-of</link>
      <description><![CDATA[Why are some research studies easy to reproduce while others are difficult?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/laying-foundations-to-quantify-the-effort-of</guid>
    </item>
    <item>
      <title>HR-Pro: Point-supervised Temporal Action Localization via Hierarchical Reliability Propagation</title>
      <link>https://paperswithcode.com/paper/hr-pro-point-supervised-temporal-action</link>
      <description><![CDATA[For snippet-level learning, we introduce an online-updated memory to store reliable snippet prototypes for each class.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hr-pro-point-supervised-temporal-action</guid>
    </item>
    <item>
      <title>Improving Translation Faithfulness of Large Language Models via Augmenting Instructions</title>
      <link>https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</link>
      <description><![CDATA[The experimental results demonstrate significant improvements in translation performance with SWIE based on BLOOMZ-3b, particularly in zero-shot and long text translations due to reduced instruction forgetting risk.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</guid>
    </item>
    <item>
      <title>Learning Heavily-Degraded Prior for Underwater Object Detection</title>
      <link>https://paperswithcode.com/paper/learning-heavily-degraded-prior-for</link>
      <description><![CDATA[Therefore, we propose a residual feature transference module (RFTM) to learn a mapping between deep representations of the heavily degraded patches of DFUI- and underwater- images, and make the mapping as a heavily degraded prior (HDP) for underwater detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-heavily-degraded-prior-for</guid>
    </item>
    <item>
      <title>Ground-to-Aerial Person Search: Benchmark Dataset and Approach</title>
      <link>https://paperswithcode.com/paper/ground-to-aerial-person-search-benchmark</link>
      <description><![CDATA[In this work, we construct a large-scale dataset for Ground-to-Aerial Person Search, named G2APS, which contains 31, 770 images of 260, 559 annotated bounding boxes for 2, 644 identities appearing in both of the UAVs and ground surveillance cameras.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ground-to-aerial-person-search-benchmark</guid>
    </item>
    <item>
      <title>Dense Text-to-Image Generation with Attention Modulation</title>
      <link>https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</link>
      <description><![CDATA[To address this, we propose DenseDiffusion, a training-free method that adapts a pre-trained text-to-image model to handle such dense captions while offering control over the scene layout.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</guid>
    </item>
    <item>
      <title>Evolutionary Dynamic Optimization Laboratory: A MATLAB Optimization Platform for Education and Experimentation in Dynamic Environments</title>
      <link>https://paperswithcode.com/paper/evolutionary-dynamic-optimization-laboratory</link>
      <description><![CDATA[In this paper, to assist researchers in performing experiments and comparing their algorithms against several EDOAs, we develop an open-source MATLAB platform for EDOAs, called Evolutionary Dynamic Optimization LABoratory (EDOLAB).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evolutionary-dynamic-optimization-laboratory</guid>
    </item>
    <item>
      <title>Motion In-Betweening with Phase Manifolds</title>
      <link>https://paperswithcode.com/paper/motion-in-betweening-with-phase-manifolds</link>
      <description><![CDATA[This paper introduces a novel data-driven motion in-betweening system to reach target poses of characters by making use of phases variables learned by a Periodic Autoencoder.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motion-in-betweening-with-phase-manifolds</guid>
    </item>
    <item>
      <title>Attention-Based Acoustic Feature Fusion Network for Depression Detection</title>
      <link>https://paperswithcode.com/paper/attention-based-acoustic-feature-fusion</link>
      <description><![CDATA[To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-based-acoustic-feature-fusion</guid>
    </item>
    <item>
      <title>Self-Supervised Learning for Endoscopic Video Analysis</title>
      <link>https://paperswithcode.com/paper/self-supervised-learning-for-endoscopic-video</link>
      <description><![CDATA[To fully exploit the power of SSL, we create sizable unlabeled endoscopic video datasets for training MSNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-learning-for-endoscopic-video</guid>
    </item>
    <item>
      <title>FOSA: Full Information Maximum Likelihood (FIML) Optimized Self-Attention Imputation for Missing Data</title>
      <link>https://paperswithcode.com/paper/fosa-full-information-maximum-likelihood-fiml</link>
      <description><![CDATA[In data imputation, effectively addressing missing values is pivotal, especially in intricate datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fosa-full-information-maximum-likelihood-fiml</guid>
    </item>
    <item>
      <title>An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems</title>
      <link>https://paperswithcode.com/paper/an-intentional-forgetting-driven-self-healing</link>
      <description><![CDATA[Dr. DRL successfully helps agents to adapt to 19. 63% of drifted environments left unsolved by vanilla CL while maintaining and even enhancing by up to 45% the obtained rewards for drifted environments that are resolved by both approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-intentional-forgetting-driven-self-healing</guid>
    </item>
    <item>
      <title>TAI-GAN: Temporally and Anatomically Informed GAN for early-to-late frame conversion in dynamic cardiac PET motion correction</title>
      <link>https://paperswithcode.com/paper/tai-gan-temporally-and-anatomically-informed</link>
      <description><![CDATA[The rapid tracer kinetics of rubidium-82 ($^{82}$Rb) and high variation of cross-frame distribution in dynamic cardiac positron emission tomography (PET) raise significant challenges for inter-frame motion correction, particularly for the early frames where conventional intensity-based image registration techniques are not applicable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tai-gan-temporally-and-anatomically-informed</guid>
    </item>
    <item>
      <title>SPPNet: A Single-Point Prompt Network for Nuclei Image Segmentation</title>
      <link>https://paperswithcode.com/paper/sppnet-a-single-point-prompt-network-for</link>
      <description><![CDATA[Compared to the segment anything model, SPPNet shows roughly 20 times faster inference, with 1/70 parameters and computational cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sppnet-a-single-point-prompt-network-for</guid>
    </item>
    <item>
      <title>Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages</title>
      <link>https://paperswithcode.com/paper/large-multilingual-models-pivot-zero-shot</link>
      <description><![CDATA[Building a competitive counterpart in other languages is highly challenging due to the low-resource nature of non-English multimodal data (i. e., lack of large-scale, high-quality image-text data).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-multilingual-models-pivot-zero-shot</guid>
    </item>
    <item>
      <title>Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning</title>
      <link>https://paperswithcode.com/paper/diffusion-language-models-can-perform-many</link>
      <description><![CDATA[We then reprogram pretrained masked language models into diffusion language models via diffusive adaptation, wherein task-specific finetuning and instruction finetuning are explored to unlock their versatility in solving general language tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-language-models-can-perform-many</guid>
    </item>
    <item>
      <title>RemovalNet: DNN Fingerprint Removal Attacks</title>
      <link>https://paperswithcode.com/paper/removalnet-dnn-fingerprint-removal-attacks</link>
      <description><![CDATA[After our DNN fingerprint removal attack, the model distance between the target and surrogate models is x100 times higher than that of the baseline attacks, (2) the RemovalNet is efficient.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/removalnet-dnn-fingerprint-removal-attacks</guid>
    </item>
    <item>
      <title>With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning</title>
      <link>https://paperswithcode.com/paper/with-a-little-help-from-your-own-past</link>
      <description><![CDATA[Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/with-a-little-help-from-your-own-past</guid>
    </item>
    <item>
      <title>Data-driven decision-focused surrogate modeling</title>
      <link>https://paperswithcode.com/paper/data-driven-decision-focused-surrogate</link>
      <description><![CDATA[We introduce the concept of decision-focused surrogate modeling for solving computationally challenging nonlinear optimization problems in real-time settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-driven-decision-focused-surrogate</guid>
    </item>
    <item>
      <title>Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations</title>
      <link>https://paperswithcode.com/paper/topical-chat-towards-knowledge-grounded-open-1</link>
      <description><![CDATA[We introduce Topical-Chat, a knowledge-grounded human-human conversation dataset where the underlying knowledge spans 8 broad topics and conversation partners don't have explicitly defined roles, to help further research in open-domain conversational AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/topical-chat-towards-knowledge-grounded-open-1</guid>
    </item>
    <item>
      <title>Semantic Change Detection for the Romanian Language</title>
      <link>https://paperswithcode.com/paper/semantic-change-detection-for-the-romanian</link>
      <description><![CDATA[Automatic semantic change methods try to identify the changes that appear over time in the meaning of words by analyzing their usage in diachronic corpora.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-change-detection-for-the-romanian</guid>
    </item>
    <item>
      <title>Quantifying degeneracy in singular models via the learning coefficient</title>
      <link>https://paperswithcode.com/paper/quantifying-degeneracy-in-singular-models-via</link>
      <description><![CDATA[Deep neural networks (DNN) are singular statistical models which exhibit complex degeneracies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quantifying-degeneracy-in-singular-models-via</guid>
    </item>
  </channel>
</rss>
