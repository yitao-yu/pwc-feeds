<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 08 Feb 2024 09:12:19 +0000</lastBuildDate>
    <item>
      <title>Troublemaker Learning for Low-Light Image Enhancement</title>
      <link>https://paperswithcode.com/paper/troublemaker-learning-for-low-light-image</link>
      <description><![CDATA[Second, the predicting model (PM) enhances the brightness of pseudo low-light images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/troublemaker-learning-for-low-light-image</guid>
    </item>
    <item>
      <title>BOWLL: A Deceptively Simple Open World Lifelong Learner</title>
      <link>https://paperswithcode.com/paper/bowll-a-deceptively-simple-open-world</link>
      <description><![CDATA[The quest to improve scalar performance numbers on predetermined benchmarks seems to be deeply engraved in deep learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bowll-a-deceptively-simple-open-world</guid>
    </item>
    <item>
      <title>UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised Fine-tuning Dataset</title>
      <link>https://paperswithcode.com/paper/ultralink-an-open-source-knowledge-enhanced</link>
      <description><![CDATA[Nevertheless, the majority of studies primarily concentrate on English, with only limited exploration into the realm of multilingual supervised fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ultralink-an-open-source-knowledge-enhanced</guid>
    </item>
    <item>
      <title>EfficientViT-SAM: Accelerated Segment Anything Model Without Performance Loss</title>
      <link>https://paperswithcode.com/paper/efficientvit-sam-accelerated-segment-anything</link>
      <description><![CDATA[For the training, we begin with the knowledge distillation from the SAM-ViT-H image encoder to EfficientViT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficientvit-sam-accelerated-segment-anything</guid>
    </item>
    <item>
      <title>Data-efficient Large Vision Models through Sequential Autoregression</title>
      <link>https://paperswithcode.com/paper/data-efficient-large-vision-models-through</link>
      <description><![CDATA[Training general-purpose vision models on purely sequential visual data, eschewing linguistic inputs, has heralded a new frontier in visual understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-efficient-large-vision-models-through</guid>
    </item>
    <item>
      <title>The Strain of Success: A Predictive Model for Injury Risk Mitigation and Team Success in Soccer</title>
      <link>https://paperswithcode.com/paper/the-strain-of-success-a-predictive-model-for</link>
      <description><![CDATA[In this paper, we present a novel sequential team selection model in soccer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-strain-of-success-a-predictive-model-for</guid>
    </item>
    <item>
      <title>Noise Map Guidance: Inversion with Spatial Context for Real Image Editing</title>
      <link>https://paperswithcode.com/paper/noise-map-guidance-inversion-with-spatial</link>
      <description><![CDATA[Text-guided diffusion models have become a popular tool in image synthesis, known for producing high-quality and diverse images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/noise-map-guidance-inversion-with-spatial</guid>
    </item>
    <item>
      <title>A Bayesian Approach to Online Learning for Contextual Restless Bandits with Applications to Public Health</title>
      <link>https://paperswithcode.com/paper/a-bayesian-approach-to-online-learning-for</link>
      <description><![CDATA[Restless multi-armed bandits (RMABs) are used to model sequential resource allocation in public health intervention programs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-bayesian-approach-to-online-learning-for</guid>
    </item>
    <item>
      <title>ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation</title>
      <link>https://paperswithcode.com/paper/colorswap-a-color-and-word-order-dataset-for</link>
      <description><![CDATA[We evaluate image-text matching (ITM) and visual language models (VLMs) and find that even the latest ones are still not robust at this task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/colorswap-a-color-and-word-order-dataset-for</guid>
    </item>
    <item>
      <title>AlphaFold Meets Flow Matching for Generating Protein Ensembles</title>
      <link>https://paperswithcode.com/paper/alphafold-meets-flow-matching-for-generating</link>
      <description><![CDATA[When trained and evaluated on the PDB, our method provides a superior combination of precision and diversity compared to AlphaFold with MSA subsampling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alphafold-meets-flow-matching-for-generating</guid>
    </item>
    <item>
      <title>SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph</title>
      <link>https://paperswithcode.com/paper/sparql-generation-an-analysis-on-fine-tuning</link>
      <description><![CDATA[The recent success of Large Language Models (LLM) in a wide range of Natural Language Processing applications opens the path towards novel Question Answering Systems over Knowledge Graphs leveraging LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparql-generation-an-analysis-on-fine-tuning</guid>
    </item>
    <item>
      <title>Personalized Text Generation with Fine-Grained Linguistic Control</title>
      <link>https://paperswithcode.com/paper/personalized-text-generation-with-fine</link>
      <description><![CDATA[As the text generation capabilities of large language models become increasingly prominent, recent studies have focused on controlling particular aspects of the generated text to make it more personalized.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalized-text-generation-with-fine</guid>
    </item>
    <item>
      <title>A Comprehensive Survey of Cross-Domain Policy Transfer for Embodied Agents</title>
      <link>https://paperswithcode.com/paper/a-comprehensive-survey-of-cross-domain-policy</link>
      <description><![CDATA[Consequently, researchers often resort to data from easily accessible source domains, such as simulation and laboratory environments, for cost-effective data acquisition and rapid model iteration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comprehensive-survey-of-cross-domain-policy</guid>
    </item>
    <item>
      <title>Can Large Language Model Agents Simulate Human Trust Behaviors?</title>
      <link>https://paperswithcode.com/paper/can-large-language-model-agents-simulate</link>
      <description><![CDATA[Then, we discover that LLM agents can have high behavioral alignment with humans regarding trust behaviors, indicating the feasibility to simulate human trust behaviors with LLM agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-large-language-model-agents-simulate</guid>
    </item>
    <item>
      <title>How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data</title>
      <link>https://paperswithcode.com/paper/how-realistic-is-your-synthetic-data</link>
      <description><![CDATA[Further, we show how our CL does not necessarily need to be integrated at training time, as it can be also used as a guardrail at inference time, still producing some improvements in the overall performance of the models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-realistic-is-your-synthetic-data</guid>
    </item>
    <item>
      <title>Fast Timing-Conditioned Latent Audio Diffusion</title>
      <link>https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</link>
      <description><![CDATA[Generating long-form 44. 1kHz stereo audio from text prompts can be computationally demanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</guid>
    </item>
    <item>
      <title>Edu-ConvoKit: An Open-Source Library for Education Conversation Data</title>
      <link>https://paperswithcode.com/paper/edu-convokit-an-open-source-library-for</link>
      <description><![CDATA[We introduce Edu-ConvoKit, an open-source library designed to handle pre-processing, annotation and analysis of conversation data in education.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edu-convokit-an-open-source-library-for</guid>
    </item>
    <item>
      <title>Moco: A Learnable Meta Optimizer for Combinatorial Optimization</title>
      <link>https://paperswithcode.com/paper/moco-a-learnable-meta-optimizer-for</link>
      <description><![CDATA[Our approach, Moco, learns a graph neural network that updates the solution construction procedure based on features extracted from the current search state.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moco-a-learnable-meta-optimizer-for</guid>
    </item>
    <item>
      <title>Dual-Path Coupled Image Deraining Network via Spatial-Frequency Interaction</title>
      <link>https://paperswithcode.com/paper/dual-path-coupled-image-deraining-network-via</link>
      <description><![CDATA[Transformers have recently emerged as a significant force in the field of image deraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-path-coupled-image-deraining-network-via</guid>
    </item>
    <item>
      <title>A Hypothesis-Driven Framework for the Analysis of Self-Rationalising Models</title>
      <link>https://paperswithcode.com/paper/a-hypothesis-driven-framework-for-the</link>
      <description><![CDATA[The self-rationalising capabilities of LLMs are appealing because the generated explanations can give insights into the plausibility of the predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-hypothesis-driven-framework-for-the</guid>
    </item>
    <item>
      <title>A Sober Look at LLMs for Material Discovery: Are They Actually Good for Bayesian Optimization Over Molecules?</title>
      <link>https://paperswithcode.com/paper/a-sober-look-at-llms-for-material-discovery</link>
      <description><![CDATA[Bayesian optimization (BO) is an essential part of such workflows, enabling scientists to leverage prior domain knowledge into efficient exploration of a large molecular space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-sober-look-at-llms-for-material-discovery</guid>
    </item>
    <item>
      <title>NORMY: Non-Uniform History Modeling for Open Retrieval Conversational Question Answering</title>
      <link>https://paperswithcode.com/paper/normy-non-uniform-history-modeling-for-open</link>
      <description><![CDATA[A typical OrConvQA pipeline consists of three modules: a Retriever to retrieve relevant documents from the collection, a Reranker to rerank them given the question and the context, and a Reader to extract an answer span.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/normy-non-uniform-history-modeling-for-open</guid>
    </item>
    <item>
      <title>ConvLoRA and AdaBN based Domain Adaptation via Self-Training</title>
      <link>https://paperswithcode.com/paper/convlora-and-adabn-based-domain-adaptation</link>
      <description><![CDATA[To further boost adaptation, we utilize Adaptive Batch Normalization (AdaBN) which computes target-specific running statistics and use it along with ConvLoRA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/convlora-and-adabn-based-domain-adaptation</guid>
    </item>
    <item>
      <title>S-Agents: self-organizing agents in open-ended environment</title>
      <link>https://paperswithcode.com/paper/s-agents-self-organizing-agents-in-open-ended</link>
      <description><![CDATA[Leveraging large language models (LLMs), autonomous agents have significantly improved, gaining the ability to handle a variety of tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s-agents-self-organizing-agents-in-open-ended</guid>
    </item>
    <item>
      <title>Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs with Recurrent Message Passing</title>
      <link>https://paperswithcode.com/paper/towards-generalizability-of-multi-agent</link>
      <description><![CDATA[The size of the observed neighborhood limits the generalizability to different graphs and affects the reactivity of agents, the quality of the selected actions, and the communication overhead.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-generalizability-of-multi-agent</guid>
    </item>
    <item>
      <title>Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/mamba-unet-unet-like-pure-visual-mamba-for</link>
      <description><![CDATA[In recent advancements in medical image analysis, Convolutional Neural Networks (CNN) and Vision Transformers (ViT) have set significant benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mamba-unet-unet-like-pure-visual-mamba-for</guid>
    </item>
    <item>
      <title>SumRec: A Framework for Recommendation using Open-Domain Dialogue</title>
      <link>https://paperswithcode.com/paper/sumrec-a-framework-for-recommendation-using</link>
      <description><![CDATA[Chat dialogues contain considerable useful information about a speaker's interests, preferences, and experiences. Thus, knowledge from open-domain chat dialogue can be used to personalize various systems and offer recommendations for advanced information. This study proposed a novel framework SumRec for recommending information from open-domain chat dialogue. The study also examined the framework using ChatRec, a newly constructed dataset for training and evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sumrec-a-framework-for-recommendation-using</guid>
    </item>
    <item>
      <title>Towards Biologically Plausible and Private Gene Expression Data Generation</title>
      <link>https://paperswithcode.com/paper/towards-biologically-plausible-and-private</link>
      <description><![CDATA[In this paper, we initiate a systematic analysis of how DP generative models perform in their natural application scenarios, specifically focusing on real-world gene expression data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-biologically-plausible-and-private</guid>
    </item>
    <item>
      <title>Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention</title>
      <link>https://paperswithcode.com/paper/attention-guided-cam-visual-explanations-of</link>
      <description><![CDATA[This approach of our method provides elaborate high-level semantic explanations with great localization performance only with the class labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-guided-cam-visual-explanations-of</guid>
    </item>
    <item>
      <title>E(3)-Equivariant Mesh Neural Networks</title>
      <link>https://paperswithcode.com/paper/e-3-equivariant-mesh-neural-networks</link>
      <description><![CDATA[Triangular meshes are widely used to represent three-dimensional objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/e-3-equivariant-mesh-neural-networks</guid>
    </item>
    <item>
      <title>Efficient Multi-Resolution Fusion for Remote Sensing Data with Label Uncertainty</title>
      <link>https://paperswithcode.com/paper/efficient-multi-resolution-fusion-for-remote</link>
      <description><![CDATA[Previously, we developed a Multiple Instance Multi-Resolution Fusion (MIMRF) framework that addresses label uncertainty for fusion, but it can be slow to train due to the large search space for the fuzzy measures used to integrate sensor data sources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-multi-resolution-fusion-for-remote</guid>
    </item>
    <item>
      <title>Asymptotics of feature learning in two-layer networks after one gradient-step</title>
      <link>https://paperswithcode.com/paper/asymptotics-of-feature-learning-in-two-layer</link>
      <description><![CDATA[To our knowledge, our results provides the first tight description of the impact of feature learning in the generalization of two-layer neural networks in the large learning rate regime $\eta=\Theta_{d}(d)$, beyond perturbative finite width corrections of the conjugate and neural tangent kernels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asymptotics-of-feature-learning-in-two-layer</guid>
    </item>
    <item>
      <title>G-NAS: Generalizable Neural Architecture Search for Single Domain Generalization Object Detection</title>
      <link>https://paperswithcode.com/paper/g-nas-generalizable-neural-architecture</link>
      <description><![CDATA[To address this issue, we propose the Generalizable loss (G-loss), which is an OoD-aware objective, preventing NAS from over-fitting by using gradient descent to optimize parameters not only on a subset of easy-to-learn features but also the remaining predictive features for generalization, and the overall framework is named G-NAS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/g-nas-generalizable-neural-architecture</guid>
    </item>
    <item>
      <title>Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design</title>
      <link>https://paperswithcode.com/paper/generative-flows-on-discrete-state-spaces</link>
      <description><![CDATA[Our approach achieves state-of-the-art co-design performance while allowing the same multimodal model to be used for flexible generation of the sequence or structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-flows-on-discrete-state-spaces</guid>
    </item>
    <item>
      <title>EvoSeed: Unveiling the Threat on Deep Neural Networks with Real-World Illusions</title>
      <link>https://paperswithcode.com/paper/evoseed-unveiling-the-threat-on-deep-neural</link>
      <description><![CDATA[Deep neural networks are exploited using natural adversarial samples, which have no impact on human perception but are misclassified.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evoseed-unveiling-the-threat-on-deep-neural</guid>
    </item>
    <item>
      <title>BRI3L: A Brightness Illusion Image Dataset for Identification and Localization of Regions of Illusory Perception</title>
      <link>https://paperswithcode.com/paper/bri3l-a-brightness-illusion-image-dataset-for</link>
      <description><![CDATA[To this end, we generate a large-scale dataset of 22, 366 images (BRI3L: BRightness Illusion Image dataset for Identification and Localization of illusory perception) of the five types of brightness illusions and benchmark the dataset using data-driven neural network based approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bri3l-a-brightness-illusion-image-dataset-for</guid>
    </item>
    <item>
      <title>SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models</title>
      <link>https://paperswithcode.com/paper/salad-bench-a-hierarchical-and-comprehensive</link>
      <description><![CDATA[In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/salad-bench-a-hierarchical-and-comprehensive</guid>
    </item>
    <item>
      <title>Two Trades is not Baffled: Condense Graph via Crafting Rational Gradient Matching</title>
      <link>https://paperswithcode.com/paper/two-trades-is-not-baffled-condense-graph-via</link>
      <description><![CDATA[Training on large-scale graphs has achieved remarkable results in graph representation learning, but its cost and storage have raised growing concerns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/two-trades-is-not-baffled-condense-graph-via</guid>
    </item>
    <item>
      <title>Deep Reinforcement Learning with Dynamic Graphs for Adaptive Informative Path Planning</title>
      <link>https://paperswithcode.com/paper/deep-reinforcement-learning-with-dynamic-1</link>
      <description><![CDATA[To address these issues, we propose a novel deep reinforcement learning approach for adaptively replanning robot paths to map targets of interest in unknown 3D environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-reinforcement-learning-with-dynamic-1</guid>
    </item>
    <item>
      <title>BEBLID: Boosted efficient binary local image descriptor</title>
      <link>https://paperswithcode.com/paper/beblid-boosted-efficient-binary-local-image</link>
      <description><![CDATA[Efficient matching of local image features is a fundamental task in many computer vision applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beblid-boosted-efficient-binary-local-image</guid>
    </item>
    <item>
      <title>Progressive Gradient Flow for Robust N:M Sparsity Training in Transformers</title>
      <link>https://paperswithcode.com/paper/progressive-gradient-flow-for-robust-n-m</link>
      <description><![CDATA[In this work, we study the effectiveness of existing sparse training recipes at \textit{high-sparsity regions} and argue that these methods fail to sustain the model quality on par with low-sparsity regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progressive-gradient-flow-for-robust-n-m</guid>
    </item>
    <item>
      <title>The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs</title>
      <link>https://paperswithcode.com/paper/the-instinctive-bias-spurious-images-lead-to</link>
      <description><![CDATA[In this paper, we identify a typical class of inputs that baffles MLLMs, which consist of images that are highly relevant but inconsistent with answers, causing MLLMs to suffer from hallucination.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-instinctive-bias-spurious-images-lead-to</guid>
    </item>
    <item>
      <title>DistiLLM: Towards Streamlined Distillation for Large Language Models</title>
      <link>https://paperswithcode.com/paper/distillm-towards-streamlined-distillation-for</link>
      <description><![CDATA[Knowledge distillation (KD) is widely used for compressing a teacher model to a smaller student model, reducing its inference cost and memory footprint while preserving model capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distillm-towards-streamlined-distillation-for</guid>
    </item>
    <item>
      <title>Virtual Classification: Modulating Domain-Specific Knowledge for Multidomain Crowd Counting</title>
      <link>https://paperswithcode.com/paper/virtual-classification-modulating-domain</link>
      <description><![CDATA[Multidomain crowd counting aims to learn a general model for multiple diverse datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/virtual-classification-modulating-domain</guid>
    </item>
    <item>
      <title>Vision Superalignment: Weak-to-Strong Generalization for Vision Foundation Models</title>
      <link>https://paperswithcode.com/paper/vision-superalignment-weak-to-strong</link>
      <description><![CDATA[Recent advancements in large language models have sparked interest in their extraordinary and near-superhuman capabilities, leading researchers to explore methods for evaluating and optimizing these abilities, which is called superalignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-superalignment-weak-to-strong</guid>
    </item>
    <item>
      <title>AttackNet: Enhancing Biometric Security via Tailored Convolutional Neural Network Architectures for Liveness Detection</title>
      <link>https://paperswithcode.com/paper/attacknet-enhancing-biometric-security-via</link>
      <description><![CDATA[Biometric security is the cornerstone of modern identity verification and authentication systems, where the integrity and reliability of biometric samples is of paramount importance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attacknet-enhancing-biometric-security-via</guid>
    </item>
    <item>
      <title>Similarity-based Neighbor Selection for Graph LLMs</title>
      <link>https://paperswithcode.com/paper/similarity-based-neighbor-selection-for-graph</link>
      <description><![CDATA[Our research further underscores the significance of graph structure integration in LLM applications and identifies key factors for their success in node classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/similarity-based-neighbor-selection-for-graph</guid>
    </item>
    <item>
      <title>SEABO: A Simple Search-Based Method for Offline Imitation Learning</title>
      <link>https://paperswithcode.com/paper/seabo-a-simple-search-based-method-for</link>
      <description><![CDATA[Offline reinforcement learning (RL) has attracted much attention due to its ability in learning from static offline datasets and eliminating the need of interacting with the environment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seabo-a-simple-search-based-method-for</guid>
    </item>
    <item>
      <title>MobileVLM V2: Faster and Stronger Baseline for Vision Language Model</title>
      <link>https://paperswithcode.com/paper/2402-03766</link>
      <description><![CDATA[We introduce MobileVLM V2, a family of significantly improved vision language models upon MobileVLM, which proves that a delicate orchestration of novel architectural design, an improved training scheme tailored for mobile VLMs, and rich high-quality dataset curation can substantially benefit VLMs' performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2402-03766</guid>
    </item>
    <item>
      <title>Dynastic Potential Crossover Operator</title>
      <link>https://paperswithcode.com/paper/dynastic-potential-crossover-operator</link>
      <description><![CDATA[In this paper, we present a recombination operator, called Dynastic Potential Crossover (DPX), that runs in polynomial time and behaves like an optimal recombination operator for low-epistasis combinatorial problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynastic-potential-crossover-operator</guid>
    </item>
  </channel>
</rss>
