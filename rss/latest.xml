<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 29 May 2025 09:18:55 +0000</lastBuildDate>
    <item>
      <title>Zero-Shot Vision Encoder Grafting via LLM Surrogates</title>
      <link>https://paperswithcode.com/paper/zero-shot-vision-encoder-grafting-via-llm</link>
      <description><![CDATA[Vision encoders trained on the surrogate can then be directly transferred to the larger model, a process we call zero-shot grafting -- when plugged directly into the full-size target LLM, the grafted pair surpasses the encoder-surrogate pair and, on some benchmarks, even performs on par with full decoder training with the target LLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-vision-encoder-grafting-via-llm</guid>
    </item>
    <item>
      <title>RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination</title>
      <link>https://paperswithcode.com/paper/renderformer-transformer-based-neural</link>
      <description><![CDATA[We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of a scene with full global illumination effects and that does not require per-scene training or fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/renderformer-transformer-based-neural</guid>
    </item>
    <item>
      <title>ChatPD: An LLM-driven Paper-Dataset Networking System</title>
      <link>https://paperswithcode.com/paper/chatpd-an-llm-driven-paper-dataset-networking</link>
      <description><![CDATA[Scientific research heavily depends on suitable datasets for method validation, but existing academic platforms with dataset management like PapersWithCode suffer from inefficiencies in their manual workflow.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatpd-an-llm-driven-paper-dataset-networking</guid>
    </item>
    <item>
      <title>UniTalk: Towards Universal Active Speaker Detection in Real World Scenarios</title>
      <link>https://paperswithcode.com/paper/unitalk-towards-universal-active-speaker</link>
      <description><![CDATA[We present UniTalk, a novel dataset specifically designed for the task of active speaker detection, emphasizing challenging scenarios to enhance model generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unitalk-towards-universal-active-speaker</guid>
    </item>
    <item>
      <title>Dual-Polarization Stacked Intelligent Metasurfaces for Holographic MIMO</title>
      <link>https://paperswithcode.com/paper/dual-polarization-stacked-intelligent</link>
      <description><![CDATA[To address the limited wave domain signal processing capabilities of traditional single-polarized stacked intelligent metasurfaces (SIMs) in holographic multiple-input multiple-output (HMIMO) systems, which stems from limited integration space, this paper proposes a dual-polarized SIM (DPSIM) architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-polarization-stacked-intelligent</guid>
    </item>
    <item>
      <title>Scaling External Knowledge Input Beyond Context Windows of LLMs via Multi-Agent Collaboration</title>
      <link>https://paperswithcode.com/paper/scaling-external-knowledge-input-beyond</link>
      <description><![CDATA[However, the limited context window of LLMs obstructs scaling the amount of external knowledge input, prohibiting further improvement, especially for tasks requiring significant amount of external knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-external-knowledge-input-beyond</guid>
    </item>
    <item>
      <title>Counterfactual Multi-player Bandits for Explainable Recommendation Diversification</title>
      <link>https://paperswithcode.com/paper/counterfactual-multi-player-bandits-for</link>
      <description><![CDATA[Existing recommender systems tend to prioritize items closely aligned with users' historical interactions, inevitably trapping users in the dilemma of ``filter bubble''.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-multi-player-bandits-for</guid>
    </item>
    <item>
      <title>RoBiS: Robust Binary Segmentation for High-Resolution Industrial Images</title>
      <link>https://paperswithcode.com/paper/robis-robust-binary-segmentation-for-high</link>
      <description><![CDATA[Robust unsupervised anomaly detection (AD) in real-world scenarios is an important task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robis-robust-binary-segmentation-for-high</guid>
    </item>
    <item>
      <title>A domain adaptation neural network for digital twin-supported fault diagnosis</title>
      <link>https://paperswithcode.com/paper/a-domain-adaptation-neural-network-for</link>
      <description><![CDATA[For example, applying DANN to a baseline CNN model improves its accuracy from 70. 00% to 80. 22% on real-world test data, demonstrating the effectiveness of domain adaptation in bridging the sim-to-real gap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-domain-adaptation-neural-network-for</guid>
    </item>
    <item>
      <title>MLMC-based Resource Adequacy Assessment with Active Learning Trained Surrogate Models</title>
      <link>https://paperswithcode.com/paper/mlmc-based-resource-adequacy-assessment-with</link>
      <description><![CDATA[For large-scale systems, the efficiency gains from surrogate models are often offset by the substantial time required for labeling training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mlmc-based-resource-adequacy-assessment-with</guid>
    </item>
    <item>
      <title>Stationary MMD Points for Cubature</title>
      <link>https://paperswithcode.com/paper/stationary-mmd-points-for-cubature</link>
      <description><![CDATA[Approximation of a target probability distribution using a finite set of points is a problem of fundamental importance, arising in cubature, data compression, and optimisation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stationary-mmd-points-for-cubature</guid>
    </item>
    <item>
      <title>FeatInv: Spatially resolved mapping from feature space to input space using conditional diffusion models</title>
      <link>https://paperswithcode.com/paper/featinv-spatially-resolved-mapping-from</link>
      <description><![CDATA[Internal representations are crucial for understanding deep neural networks, such as their properties and reasoning patterns, but remain difficult to interpret.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/featinv-spatially-resolved-mapping-from</guid>
    </item>
    <item>
      <title>DeSocial: Blockchain-based Decentralized Social Networks</title>
      <link>https://paperswithcode.com/paper/desocial-blockchain-based-decentralized</link>
      <description><![CDATA[Web 2. 0 social platforms are inherently centralized, with user data and algorithmic decisions controlled by the platform.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/desocial-blockchain-based-decentralized</guid>
    </item>
    <item>
      <title>OVERT: A Benchmark for Over-Refusal Evaluation on Text-to-Image Models</title>
      <link>https://paperswithcode.com/paper/overt-a-benchmark-for-over-refusal-evaluation</link>
      <description><![CDATA[Text-to-Image (T2I) models have achieved remarkable success in generating visual content from text inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/overt-a-benchmark-for-over-refusal-evaluation</guid>
    </item>
    <item>
      <title>Mel-McNet: A Mel-Scale Framework for Online Multichannel Speech Enhancement</title>
      <link>https://paperswithcode.com/paper/mel-mcnet-a-mel-scale-framework-for-online</link>
      <description><![CDATA[Online multichannel speech enhancement has been intensively studied recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mel-mcnet-a-mel-scale-framework-for-online</guid>
    </item>
    <item>
      <title>Accelerating Diffusion-based Text-to-Speech Model Training with Dual Modality Alignment</title>
      <link>https://paperswithcode.com/paper/accelerating-diffusion-based-text-to-speech</link>
      <description><![CDATA[While recent studies have achieved remarkable advancements, their training demands substantial time and computational costs, largely due to the implicit guidance of diffusion models in learning complex intermediate representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-diffusion-based-text-to-speech</guid>
    </item>
    <item>
      <title>Advanced long-term earth system forecasting by learning the small-scale nature</title>
      <link>https://paperswithcode.com/paper/advanced-long-term-earth-system-forecasting</link>
      <description><![CDATA[Reliable long-term forecast of Earth system dynamics is heavily hampered by instabilities in current AI models during extended autoregressive simulations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advanced-long-term-earth-system-forecasting</guid>
    </item>
    <item>
      <title>Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks</title>
      <link>https://paperswithcode.com/paper/towards-video-to-piano-music-generation-with</link>
      <description><![CDATA[Generating high-quality piano audio from video requires precise synchronization between visual cues and musical output, ensuring accurate semantic and temporal alignment. However, existing evaluation datasets do not fully capture the intricate synchronization required for piano music generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-video-to-piano-music-generation-with</guid>
    </item>
    <item>
      <title>Lifelong Safety Alignment for Language Models</title>
      <link>https://paperswithcode.com/paper/lifelong-safety-alignment-for-language-models</link>
      <description><![CDATA[LLMs have made impressive progress, but their growing capabilities also expose them to highly flexible jailbreaking attacks designed to bypass safety alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lifelong-safety-alignment-for-language-models</guid>
    </item>
    <item>
      <title>MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness</title>
      <link>https://paperswithcode.com/paper/mmperspective-do-mllms-understand-perspective</link>
      <description><![CDATA[Understanding perspective is fundamental to human visual perception, yet the extent to which multimodal large language models (MLLMs) internalize perspective geometry remains unclear.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmperspective-do-mllms-understand-perspective</guid>
    </item>
    <item>
      <title>Position: Mechanistic Interpretability Should Prioritize Feature Consistency in SAEs</title>
      <link>https://paperswithcode.com/paper/position-mechanistic-interpretability-should</link>
      <description><![CDATA[Sparse Autoencoders (SAEs) are a prominent tool in mechanistic interpretability (MI) for decomposing neural network activations into interpretable features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/position-mechanistic-interpretability-should</guid>
    </item>
    <item>
      <title>Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression</title>
      <link>https://paperswithcode.com/paper/can-compressed-llms-truly-act-an-empirical</link>
      <description><![CDATA[Post-training compression reduces the computational and memory costs of large language models (LLMs), enabling resource-efficient deployment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-compressed-llms-truly-act-an-empirical</guid>
    </item>
    <item>
      <title>Balancing Interference and Correlation in Spatial Experimental Designs: A Causal Graph Cut Approach</title>
      <link>https://paperswithcode.com/paper/balancing-interference-and-correlation-in</link>
      <description><![CDATA[This paper focuses on the design of spatial experiments to optimize the amount of information derived from the experimental data and enhance the accuracy of the resulting causal effect estimator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/balancing-interference-and-correlation-in</guid>
    </item>
    <item>
      <title>TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent</title>
      <link>https://paperswithcode.com/paper/trojanstego-your-language-model-can-secretly</link>
      <description><![CDATA[As large language models (LLMs) become integrated into sensitive workflows, concerns grow over their potential to leak confidential information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trojanstego-your-language-model-can-secretly</guid>
    </item>
    <item>
      <title>AMQA: An Adversarial Dataset for Benchmarking Bias of LLMs in Medicine and Healthcare</title>
      <link>https://paperswithcode.com/paper/amqa-an-adversarial-dataset-for-benchmarking</link>
      <description><![CDATA[Large language models (LLMs) are reaching expert-level accuracy on medical diagnosis questions, yet their mistakes and the biases behind them pose life-critical risks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/amqa-an-adversarial-dataset-for-benchmarking</guid>
    </item>
    <item>
      <title>Measure Domain's Gap: A Similar Domain Selection Principle for Multi-Domain Recommendation</title>
      <link>https://paperswithcode.com/paper/measure-domain-s-gap-a-similar-domain</link>
      <description><![CDATA[Thereafter, the proposed SDSP can dynamically find similar domains for each domain based on the supervised signals of the domain metrics and the unsupervised distance measure from the learned domain prototype.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/measure-domain-s-gap-a-similar-domain</guid>
    </item>
    <item>
      <title>Concise Reasoning, Big Gains: Pruning Long Reasoning Trace with Difficulty-Aware Prompting</title>
      <link>https://paperswithcode.com/paper/concise-reasoning-big-gains-pruning-long</link>
      <description><![CDATA[Existing chain-of-thought (CoT) distillation methods can effectively transfer reasoning abilities to base models but suffer from two major limitations: excessive verbosity of reasoning traces and inadequate adaptability to problem difficulty.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/concise-reasoning-big-gains-pruning-long</guid>
    </item>
    <item>
      <title>DiEmo-TTS: Disentangled Emotion Representations via Self-Supervised Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech</title>
      <link>https://paperswithcode.com/paper/diemo-tts-disentangled-emotion</link>
      <description><![CDATA[To address this, we propose DiEmo-TTS, a self-supervised distillation method to minimize emotional information loss and preserve speaker identity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diemo-tts-disentangled-emotion</guid>
    </item>
    <item>
      <title>Beyond Freezing: Sparse Tuning Enhances Plasticity in Continual Learning with Pre-Trained Models</title>
      <link>https://paperswithcode.com/paper/beyond-freezing-sparse-tuning-enhances</link>
      <description><![CDATA[Continual Learning with Pre-trained Models holds great promise for efficient adaptation across sequential tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-freezing-sparse-tuning-enhances</guid>
    </item>
    <item>
      <title>Beyond Safe Answers: A Benchmark for Evaluating True Risk Awareness in Large Reasoning Models</title>
      <link>https://paperswithcode.com/paper/beyond-safe-answers-a-benchmark-for</link>
      <description><![CDATA[Despite the remarkable proficiency of \textit{Large Reasoning Models} (LRMs) in handling complex reasoning tasks, their reliability in safety-critical scenarios remains uncertain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-safe-answers-a-benchmark-for</guid>
    </item>
    <item>
      <title>BizFinBench: A Business-Driven Real-World Financial Benchmark for Evaluating LLMs</title>
      <link>https://paperswithcode.com/paper/bizfinbench-a-business-driven-real-world</link>
      <description><![CDATA[Our evaluation reveals distinct capability patterns: (1) In Numerical Calculation, Claude-3. 5-Sonnet (63. 18) and DeepSeek-R1 (64. 04) lead, while smaller models like Qwen2. 5-VL-3B (15. 92) lag significantly; (2) In Reasoning, proprietary models dominate (ChatGPT-o3: 83. 58, Gemini-2. 0-Flash: 81. 15), with open-source models trailing by up to 19. 49 points; (3) In Information Extraction, the performance spread is the largest, with DeepSeek-R1 scoring 71. 46, while Qwen3-1. 7B scores 11. 23; (4) In Prediction Recognition, performance variance is minimal, with top models scoring between 39. 16 and 50. 00.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bizfinbench-a-business-driven-real-world</guid>
    </item>
    <item>
      <title>Learning to Trust Bellman Updates: Selective State-Adaptive Regularization for Offline RL</title>
      <link>https://paperswithcode.com/paper/learning-to-trust-bellman-updates-selective</link>
      <description><![CDATA[Offline reinforcement learning (RL) aims to learn an effective policy from a static dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-trust-bellman-updates-selective</guid>
    </item>
    <item>
      <title>FinLoRA: Benchmarking LoRA Methods for Fine-Tuning LLMs on Financial Datasets</title>
      <link>https://paperswithcode.com/paper/finlora-benchmarking-lora-methods-for-fine</link>
      <description><![CDATA[In this paper, we present the open-source FinLoRA project that benchmarks LoRA methods on both general and highly professional financial tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finlora-benchmarking-lora-methods-for-fine</guid>
    </item>
    <item>
      <title>Deep Active Inference Agents for Delayed and Long-Horizon Environments</title>
      <link>https://paperswithcode.com/paper/deep-active-inference-agents-for-delayed-and</link>
      <description><![CDATA[With the recent success of world-model agents, which extend the core idea of model-based reinforcement learning by learning a differentiable model for sample-efficient control across diverse tasks, active inference (AIF) offers a complementary, neuroscience-grounded paradigm that unifies perception, learning, and action within a single probabilistic framework powered by a generative model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-active-inference-agents-for-delayed-and</guid>
    </item>
    <item>
      <title>EmoSphere-SER: Enhancing Speech Emotion Recognition Through Spherical Representation with Auxiliary Classification</title>
      <link>https://paperswithcode.com/paper/emosphere-ser-enhancing-speech-emotion</link>
      <description><![CDATA[Speech emotion recognition predicts a speaker's emotional state from speech signals using discrete labels or continuous dimensions such as arousal, valence, and dominance (VAD).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emosphere-ser-enhancing-speech-emotion</guid>
    </item>
    <item>
      <title>ExAnte: A Benchmark for Ex-Ante Inference in Large Language Models</title>
      <link>https://paperswithcode.com/paper/exante-a-benchmark-for-ex-ante-inference-in</link>
      <description><![CDATA[Large language models (LLMs) face significant challenges in ex-ante reasoning, where analysis, inference, or predictions must be made without access to information from future events.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exante-a-benchmark-for-ex-ante-inference-in</guid>
    </item>
    <item>
      <title>HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters</title>
      <link>https://paperswithcode.com/paper/hunyuanvideo-avatar-high-fidelity-audio</link>
      <description><![CDATA[This ensures the dynamic motion and strong character consistency; (ii) An Audio Emotion Module (AEM) is introduced to extract and transfer the emotional cues from an emotion reference image to the target generated video, enabling fine-grained and accurate emotion style control; (iii) A Face-Aware Audio Adapter (FAA) is proposed to isolate the audio-driven character with latent-level face mask, enabling independent audio injection via cross-attention for multi-character scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuanvideo-avatar-high-fidelity-audio</guid>
    </item>
    <item>
      <title>Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents via Offline Hierarchical Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/divide-and-conquer-grounding-llms-as</link>
      <description><![CDATA[While showing sophisticated reasoning abilities, large language models (LLMs) still struggle with long-horizon decision-making tasks due to deficient exploration and long-term credit assignment, especially in sparse-reward scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/divide-and-conquer-grounding-llms-as</guid>
    </item>
    <item>
      <title>How Well Do Large Reasoning Models Translate? A Comprehensive Evaluation for Multi-Domain Machine Translation</title>
      <link>https://paperswithcode.com/paper/how-well-do-large-reasoning-models-translate</link>
      <description><![CDATA[Large language models (LLMs) have demonstrated strong performance in general-purpose machine translation, but their effectiveness in complex, domain-sensitive translation tasks remains underexplored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-well-do-large-reasoning-models-translate</guid>
    </item>
    <item>
      <title>Unifying Multimodal Large Language Model Capabilities and Modalities via Model Merging</title>
      <link>https://paperswithcode.com/paper/unifying-multimodal-large-language-model</link>
      <description><![CDATA[While foundation models update slowly due to resource-intensive training requirements, domain-specific models evolve between updates.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unifying-multimodal-large-language-model</guid>
    </item>
    <item>
      <title>TabPFN: One Model to Rule Them All?</title>
      <link>https://paperswithcode.com/paper/tabpfn-one-model-to-rule-them-all</link>
      <description><![CDATA[Hollmann et al. (Nature 637 (2025) 319-326) recently introduced TabPFN, a transformer-based deep learning model for regression and classification on tabular data, which they claim "outperforms all previous methods on datasets with up to 10, 000 samples by a wide margin, using substantially less training time."]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tabpfn-one-model-to-rule-them-all</guid>
    </item>
    <item>
      <title>TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos</title>
      <link>https://paperswithcode.com/paper/tuna-comprehensive-fine-grained-temporal</link>
      <description><![CDATA[Videos are unique in their integration of temporal elements, including camera, scene, action, and attribute, along with their dynamic relationships over time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tuna-comprehensive-fine-grained-temporal</guid>
    </item>
    <item>
      <title>Judging with Many Minds: Do More Perspectives Mean Less Prejudice?</title>
      <link>https://paperswithcode.com/paper/judging-with-many-minds-do-more-perspectives</link>
      <description><![CDATA[LLM-as-Judge has emerged as a scalable alternative to human evaluation, enabling large language models (LLMs) to provide reward signals in trainings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/judging-with-many-minds-do-more-perspectives</guid>
    </item>
    <item>
      <title>Grokking ExPLAIND: Unifying Model, Data, and Training Attribution to Study Model Behavior</title>
      <link>https://paperswithcode.com/paper/grokking-explaind-unifying-model-data-and</link>
      <description><![CDATA[Post-hoc interpretability methods typically attribute a model's behavior to its components, data, or training trajectory in isolation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grokking-explaind-unifying-model-data-and</guid>
    </item>
    <item>
      <title>Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models</title>
      <link>https://paperswithcode.com/paper/advancements-in-medical-image-classification</link>
      <description><![CDATA[This study investigates the application of recent state-of-the-art foundation models, DINOv2, MAE, VMamba, CoCa, SAM2, and AIMv2, for medical image classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancements-in-medical-image-classification</guid>
    </item>
    <item>
      <title>OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction</title>
      <link>https://paperswithcode.com/paper/omnicharacter-towards-immersive-role-playing</link>
      <description><![CDATA[Role-Playing Agents (RPAs), benefiting from large language models, is an emerging interactive AI system that simulates roles or characters with diverse personalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnicharacter-towards-immersive-role-playing</guid>
    </item>
    <item>
      <title>Hierarchical Masked Autoregressive Models with Low-Resolution Token Pivots</title>
      <link>https://paperswithcode.com/paper/hierarchical-masked-autoregressive-models</link>
      <description><![CDATA[The current de-facto standard of next token prediction commonly operates over a single-scale sequence of dense image tokens, and is incapable of utilizing global context especially for early tokens prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-masked-autoregressive-models</guid>
    </item>
    <item>
      <title>Large Language Models for Planning: A Comprehensive and Systematic Survey</title>
      <link>https://paperswithcode.com/paper/large-language-models-for-planning-a</link>
      <description><![CDATA[Planning represents a fundamental capability of intelligent agents, requiring comprehensive environmental understanding, rigorous logical reasoning, and effective sequential decision-making.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-for-planning-a</guid>
    </item>
    <item>
      <title>LLM Meets Scene Graph: Can Large Language Models Understand and Generate Scene Graphs? A Benchmark and Empirical Study</title>
      <link>https://paperswithcode.com/paper/llm-meets-scene-graph-can-large-language</link>
      <description><![CDATA[In this work, we introduce Text-Scene Graph (TSG) Bench, a benchmark designed to systematically assess LLMs' ability to (1) understand scene graphs and (2) generate them from textual narratives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-meets-scene-graph-can-large-language</guid>
    </item>
    <item>
      <title>CulFiT: A Fine-grained Cultural-aware LLM Training Paradigm via Multilingual Critique Data Synthesis</title>
      <link>https://paperswithcode.com/paper/culfit-a-fine-grained-cultural-aware-llm</link>
      <description><![CDATA[Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, yet they often exhibit a specific cultural biases, neglecting the values and linguistic diversity of low-resource regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/culfit-a-fine-grained-cultural-aware-llm</guid>
    </item>
  </channel>
</rss>
