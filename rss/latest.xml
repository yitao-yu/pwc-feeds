<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 11 Aug 2023 09:11:10 +0000</lastBuildDate>
    <item>
      <title>Deep Fusion Transformer Network with Weighted Vector-Wise Keypoints Voting for Robust 6D Object Pose Estimation</title>
      <link>https://paperswithcode.com/paper/deep-fusion-transformer-network-with-weighted</link>
      <description><![CDATA[One critical challenge in 6D object pose estimation from a single RGBD image is efficient integration of two different modalities, i. e., color and depth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-fusion-transformer-network-with-weighted</guid>
    </item>
    <item>
      <title>PlankAssembly: Robust 3D Reconstruction from Three Orthographic Views with Learnt Shape Programs</title>
      <link>https://paperswithcode.com/paper/plankassembly-robust-3d-reconstruction-from</link>
      <description><![CDATA[In this paper, we develop a new method to automatically convert 2D line drawings from three orthographic views into 3D CAD models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plankassembly-robust-3d-reconstruction-from</guid>
    </item>
    <item>
      <title>Speech-Driven 3D Face Animation with Composite and Regional Facial Movements</title>
      <link>https://paperswithcode.com/paper/speech-driven-3d-face-animation-with</link>
      <description><![CDATA[This paper emphasizes the importance of considering both the composite and regional natures of facial movements in speech-driven 3D face animation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/speech-driven-3d-face-animation-with</guid>
    </item>
    <item>
      <title>Surface Masked AutoEncoder: Self-Supervision for Cortical Imaging Data</title>
      <link>https://paperswithcode.com/paper/surface-masked-autoencoder-self-supervision</link>
      <description><![CDATA[By reconstructing surface data from a masked version of the input, the proposed method effectively models cortical structure to learn strong representations that translate to improved performance in downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surface-masked-autoencoder-self-supervision</guid>
    </item>
    <item>
      <title>RLSAC: Reinforcement Learning enhanced Sample Consensus for End-to-End Robust Estimation</title>
      <link>https://paperswithcode.com/paper/rlsac-reinforcement-learning-enhanced-sample</link>
      <description><![CDATA[Therefore, RLSAC can avoid differentiating to learn the features and the feedback of downstream tasks for end-to-end robust estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rlsac-reinforcement-learning-enhanced-sample</guid>
    </item>
    <item>
      <title>Enhancing Low-light Light Field Images with A Deep Compensation Unfolding Network</title>
      <link>https://paperswithcode.com/paper/enhancing-low-light-light-field-images-with-a</link>
      <description><![CDATA[This paper presents a novel and interpretable end-to-end learning framework, called the deep compensation unfolding network (DCUNet), for restoring light field (LF) images captured under low-light conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-low-light-light-field-images-with-a</guid>
    </item>
    <item>
      <title>MapTRv2: An End-to-End Framework for Online Vectorized HD Map Construction</title>
      <link>https://paperswithcode.com/paper/maptrv2-an-end-to-end-framework-for-online</link>
      <description><![CDATA[We propose a unified permutation-equivalent modeling approach, \ie, modeling map element as a point set with a group of equivalent permutations, which accurately describes the shape of map element and stabilizes the learning process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maptrv2-an-end-to-end-framework-for-online</guid>
    </item>
    <item>
      <title>Deformable Mixer Transformer with Gating for Multi-Task Learning of Dense Prediction</title>
      <link>https://paperswithcode.com/paper/deformable-mixer-transformer-with-gating-for</link>
      <description><![CDATA[In this work, we present a novel MTL model by combining both merits of deformable CNN and query-based Transformer with shared gating for multi-task learning of dense prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deformable-mixer-transformer-with-gating-for</guid>
    </item>
    <item>
      <title>FINER: Enhancing State-of-the-art Classifiers with Feature Attribution to Facilitate Security Analysis</title>
      <link>https://paperswithcode.com/paper/finer-enhancing-state-of-the-art-classifiers</link>
      <description><![CDATA[Although feature attribution (FA) methods can be used to explain deep learning, the underlying classifier is still blind to what behavior is suspicious, and the generated explanation cannot adapt to downstream tasks, incurring poor explanation fidelity and intelligibility.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finer-enhancing-state-of-the-art-classifiers</guid>
    </item>
    <item>
      <title>Robust Asymmetric Loss for Multi-Label Long-Tailed Learning</title>
      <link>https://paperswithcode.com/paper/robust-asymmetric-loss-for-multi-label-long</link>
      <description><![CDATA[Although a model can be highly fine-tuned due to a large number of hyper-parameters, it is difficult to optimize all hyper-parameters at the same time, and there might be a risk of overfitting a model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-asymmetric-loss-for-multi-label-long</guid>
    </item>
    <item>
      <title>Progressive Spatio-temporal Perception for Audio-Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/progressive-spatio-temporal-perception-for</link>
      <description><![CDATA[Such naturally multi-modal videos are composed of rich and complex dynamic audio-visual components, where most of which could be unrelated to the given questions, or even play as interference in answering the content of interest.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progressive-spatio-temporal-perception-for</guid>
    </item>
    <item>
      <title>Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative Convolution Network</title>
      <link>https://paperswithcode.com/paper/self-supervised-monocular-depth-estimation-by</link>
      <description><![CDATA[To bridge this gap, we propose a new Direction-aware Cumulative Convolution Network (DaCCN), which improves the depth feature representation in two aspects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-monocular-depth-estimation-by</guid>
    </item>
    <item>
      <title>A Comparative Visual Analytics Framework for Evaluating Evolutionary Processes in Multi-objective Optimization</title>
      <link>https://paperswithcode.com/paper/a-comparative-visual-analytics-framework-for</link>
      <description><![CDATA[Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparative-visual-analytics-framework-for</guid>
    </item>
    <item>
      <title>Counterfactual Cross-modality Reasoning for Weakly Supervised Video Moment Localization</title>
      <link>https://paperswithcode.com/paper/counterfactual-cross-modality-reasoning-for</link>
      <description><![CDATA[Finally, by suppressing the unimodal effect of masked query, we can rectify the reconstructions of video proposals to perform reasonable contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-cross-modality-reasoning-for</guid>
    </item>
    <item>
      <title>SSLRec: A Self-Supervised Learning Library for Recommendation</title>
      <link>https://paperswithcode.com/paper/sslrec-a-self-supervised-learning-library-for</link>
      <description><![CDATA[Our SSLRec platform covers a comprehensive set of state-of-the-art SSL-enhanced recommendation models across different scenarios, enabling researchers to evaluate these cutting-edge models and drive further innovation in the field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sslrec-a-self-supervised-learning-library-for</guid>
    </item>
    <item>
      <title>Adaptive Taxonomy Learning and Historical Patterns Modelling for Patent Classification</title>
      <link>https://paperswithcode.com/paper/adaptive-taxonomy-learning-and-historical</link>
      <description><![CDATA[Finally, we combine the contextual information of patent texts that contains the semantics of IPC codes, and assignees' sequential preferences to make predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-taxonomy-learning-and-historical</guid>
    </item>
    <item>
      <title>Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning</title>
      <link>https://paperswithcode.com/paper/beyond-semantics-learning-a-behavior</link>
      <description><![CDATA[Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-semantics-learning-a-behavior</guid>
    </item>
    <item>
      <title>Exploring XAI for the Arts: Explaining Latent Space in Generative Music</title>
      <link>https://paperswithcode.com/paper/exploring-xai-for-the-arts-explaining-latent</link>
      <description><![CDATA[We increase the explainability of the model by: i) using latent space regularisation to force some specific dimensions of the latent space to map to meaningful musical attributes, ii) providing a user interface feedback loop to allow people to adjust dimensions of the latent space and observe the results of these changes in real-time, iii) providing a visualisation of the musical attributes in the latent space to help people understand and predict the effect of changes to latent space dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-xai-for-the-arts-explaining-latent</guid>
    </item>
    <item>
      <title>A Comparative Assessment of Multi-view fusion learning for Crop Classification</title>
      <link>https://paperswithcode.com/paper/a-comparative-assessment-of-multi-view-fusion</link>
      <description><![CDATA[Instead, we present a comparison of multi-view fusion methods for three different datasets and show that, depending on the test region, different methods obtain the best performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparative-assessment-of-multi-view-fusion</guid>
    </item>
    <item>
      <title>Interaction-aware Joint Attention Estimation Using People Attributes</title>
      <link>https://paperswithcode.com/paper/interaction-aware-joint-attention-estimation</link>
      <description><![CDATA[We introduce a specialized MLP head with positional embedding to the Transformer so that it predicts pixelwise confidence of joint attention for generating the confidence heatmap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interaction-aware-joint-attention-estimation</guid>
    </item>
    <item>
      <title>Double-chain Constraints for 3D Human Pose Estimation in Images and Videos</title>
      <link>https://paperswithcode.com/paper/double-chain-constraints-for-3d-human-pose</link>
      <description><![CDATA[Notably, our model achieves state-of-the-art performance on all action categories in the Human3. 6M dataset using detected 2D poses from CPN, and our code is available at: https://github. com/KHB1698/DC-GCT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/double-chain-constraints-for-3d-human-pose</guid>
    </item>
    <item>
      <title>Multi-domain Recommendation with Embedding Disentangling and Domain Alignment</title>
      <link>https://paperswithcode.com/paper/multi-domain-recommendation-with-embedding</link>
      <description><![CDATA[We propose a new MDR method named EDDA with two key components, i. e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-domain-recommendation-with-embedding</guid>
    </item>
    <item>
      <title>Robust Object Modeling for Visual Tracking</title>
      <link>https://paperswithcode.com/paper/robust-object-modeling-for-visual-tracking</link>
      <description><![CDATA[To enjoy the merits of both methods, we propose a robust object modeling framework for visual tracking (ROMTrack), which simultaneously models the inherent template and the hybrid template features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-object-modeling-for-visual-tracking</guid>
    </item>
    <item>
      <title>Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection</title>
      <link>https://paperswithcode.com/paper/performance-analysis-of-transformer-based</link>
      <description><![CDATA[However, some studies suggest the performance can be improved with the use of improved BERT models known as ALBERT and RoBERTa.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/performance-analysis-of-transformer-based</guid>
    </item>
    <item>
      <title>Intrinsic Motivation via Surprise Memory</title>
      <link>https://paperswithcode.com/paper/intrinsic-motivation-via-surprise-memory</link>
      <description><![CDATA[We present a new computing model for intrinsic rewards in reinforcement learning that addresses the limitations of existing surprise-driven explorations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intrinsic-motivation-via-surprise-memory</guid>
    </item>
    <item>
      <title>Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/resource-constrained-model-compression-via</link>
      <description><![CDATA[We propose an improved end-to-end Minimax optimization method for this sparse learning problem to better balance the model performance and the computation efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/resource-constrained-model-compression-via</guid>
    </item>
    <item>
      <title>Improved Multi-Shot Diffusion-Weighted MRI with Zero-Shot Self-Supervised Learning Reconstruction</title>
      <link>https://paperswithcode.com/paper/improved-multi-shot-diffusion-weighted-mri</link>
      <description><![CDATA[In this study, we introduce a novel msEPI reconstruction approach called zero-MIRID (zero-shot self-supervised learning of Multi-shot Image Reconstruction for Improved Diffusion MRI).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-multi-shot-diffusion-weighted-mri</guid>
    </item>
    <item>
      <title>Towards true discovery of the differential equations</title>
      <link>https://paperswithcode.com/paper/towards-true-discovery-of-the-differential</link>
      <description><![CDATA[Differential equation discovery, a machine learning subfield, is used to develop interpretable models, particularly in nature-related applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-true-discovery-of-the-differential</guid>
    </item>
    <item>
      <title>SelectNAdapt: Support Set Selection for Few-Shot Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/selectnadapt-support-set-selection-for-few</link>
      <description><![CDATA[Few-shot domain adaptation mitigates this issue by adapting deep neural networks pre-trained on the source domain to the target domain using a randomly selected and annotated support set from the target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/selectnadapt-support-set-selection-for-few</guid>
    </item>
    <item>
      <title>Directed differential equation discovery using modified mutation and cross-over operators</title>
      <link>https://paperswithcode.com/paper/directed-differential-equation-discovery</link>
      <description><![CDATA[The discovery of equations with knowledge of the process origin is a tempting prospect.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/directed-differential-equation-discovery</guid>
    </item>
    <item>
      <title>Deep Learning for Morphological Identification of Extended Radio Galaxies using Weak Labels</title>
      <link>https://paperswithcode.com/paper/deep-learning-for-morphological</link>
      <description><![CDATA[The CAMs are further refined using an inter-pixel relations network (IRNet) to get instance segmentation masks over radio galaxies and the positions of their infrared hosts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-learning-for-morphological</guid>
    </item>
    <item>
      <title>SUnAA: Sparse Unmixing using Archetypal Analysis</title>
      <link>https://paperswithcode.com/paper/sunaa-sparse-unmixing-using-archetypal</link>
      <description><![CDATA[Unlike most conventional sparse unmixing methods, here the minimization problem is non-convex.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sunaa-sparse-unmixing-using-archetypal</guid>
    </item>
    <item>
      <title>Dual Intents Graph Modeling for User-centric Group Discovery</title>
      <link>https://paperswithcode.com/paper/dual-intents-graph-modeling-for-user-centric</link>
      <description><![CDATA[Therefore, user-centric group discovery task, i. e., recommending groups to users can help both users' online experiences and platforms' long-term developments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-intents-graph-modeling-for-user-centric</guid>
    </item>
    <item>
      <title>DiVa: An Iterative Framework to Harvest More Diverse and Valid Labels from User Comments for Music</title>
      <link>https://paperswithcode.com/paper/diva-an-iterative-framework-to-harvest-more</link>
      <description><![CDATA[Based on the observation that such missing information may already be presented in user comments, we propose to study the automated music labeling in an essential but under-explored setting, where the model is required to harvest more diverse and valid labels from the users' comments given limited gold labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diva-an-iterative-framework-to-harvest-more</guid>
    </item>
    <item>
      <title>A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge</title>
      <link>https://paperswithcode.com/paper/a-bipartite-graph-is-all-we-need-for</link>
      <description><![CDATA[However, most previous knowledge infusion methods perform empirical knowledge filtering and design highly customized architectures for knowledge interaction with the utterances, which can discard useful knowledge aspects and limit their generalizability to different knowledge sources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-bipartite-graph-is-all-we-need-for</guid>
    </item>
    <item>
      <title>Parallel Knowledge Enhancement based Framework for Multi-behavior Recommendation</title>
      <link>https://paperswithcode.com/paper/parallel-knowledge-enhancement-based</link>
      <description><![CDATA[In the fusion step, advanced neural networks are used to model the hierarchical correlations between user behaviors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parallel-knowledge-enhancement-based</guid>
    </item>
    <item>
      <title>LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking</title>
      <link>https://paperswithcode.com/paper/llmebench-a-flexible-framework-for</link>
      <description><![CDATA[Initially developed to evaluate Arabic NLP tasks using OpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task and model, regardless of language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llmebench-a-flexible-framework-for</guid>
    </item>
    <item>
      <title>Spatial Gated Multi-Layer Perceptron for Land Use and Land Cover Mapping</title>
      <link>https://paperswithcode.com/paper/spatial-gated-multi-layer-perceptron-for-land</link>
      <description><![CDATA[Results illustrated the superiority of the developed SGU-MLP classification algorithm over several CNN and CNN-ViT-based models, including HybridSN, ResNet, iFormer, EfficientFormer and CoAtNet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatial-gated-multi-layer-perceptron-for-land</guid>
    </item>
    <item>
      <title>Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization</title>
      <link>https://paperswithcode.com/paper/induction-network-audio-visual-modality-gap</link>
      <description><![CDATA[By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/induction-network-audio-visual-modality-gap</guid>
    </item>
    <item>
      <title>GIFD: A Generative Gradient Inversion Method with Feature Domain Optimization</title>
      <link>https://paperswithcode.com/paper/gifd-a-generative-gradient-inversion-method</link>
      <description><![CDATA[Federated Learning (FL) has recently emerged as a promising distributed machine learning framework to preserve clients' privacy, by allowing multiple clients to upload the gradients calculated from their local data to a central server.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gifd-a-generative-gradient-inversion-method</guid>
    </item>
    <item>
      <title>Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution</title>
      <link>https://paperswithcode.com/paper/generative-perturbation-analysis-for</link>
      <description><![CDATA[We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-perturbation-analysis-for</guid>
    </item>
    <item>
      <title>Advancing Early Detection of Virus Yellows: Developing a Hybrid Convolutional Neural Network for Automatic Aphid Counting in Sugar Beet Fields</title>
      <link>https://paperswithcode.com/paper/advancing-early-detection-of-virus-yellows</link>
      <description><![CDATA[Aphids are efficient vectors to transmit virus yellows in sugar beet fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-early-detection-of-virus-yellows</guid>
    </item>
    <item>
      <title>Sound propagation in realistic interactive 3D scenes with parameterized sources using deep neural operators</title>
      <link>https://paperswithcode.com/paper/sound-propagation-in-realistic-interactive-3d</link>
      <description><![CDATA[We address the challenge of sound propagation simulations in $3$D virtual rooms with moving sources, which have applications in virtual/augmented reality, game audio, and spatial computing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sound-propagation-in-realistic-interactive-3d</guid>
    </item>
    <item>
      <title>Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/enhancing-efficient-continual-learning-with</link>
      <description><![CDATA[In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each task).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-efficient-continual-learning-with</guid>
    </item>
    <item>
      <title>Objects do not disappear: Video object detection by single-frame object location anticipation</title>
      <link>https://paperswithcode.com/paper/objects-do-not-disappear-video-object</link>
      <description><![CDATA[2) Improved efficiency by only doing the expensive feature computations on a small subset of all frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/objects-do-not-disappear-video-object</guid>
    </item>
    <item>
      <title>Joint-Relation Transformer for Multi-Person Motion Prediction</title>
      <link>https://paperswithcode.com/paper/joint-relation-transformer-for-multi-person</link>
      <description><![CDATA[Multi-person motion prediction is a challenging problem due to the dependency of motion on both individual past movements and interactions with other people.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/joint-relation-transformer-for-multi-person</guid>
    </item>
    <item>
      <title>HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction</title>
      <link>https://paperswithcode.com/paper/hypercoil-recon-a-hypernetwork-based-adaptive</link>
      <description><![CDATA[Experiments reveal that our approach 1) adapts on the fly to various unseen configurations up to 32 coils when trained on lower numbers (i. e. 7 to 11) of randomly varying coils, and to 120 deviated unseen configurations when trained on 18 configurations in a single model, 2) matches the performance of coil configuration-specific models, and 3) outperforms configuration-invariant models with improvement margins of around 1 dB / 0. 03 and 0. 3 dB / 0. 02 in PSNR / SSIM for knee and brain data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hypercoil-recon-a-hypernetwork-based-adaptive</guid>
    </item>
    <item>
      <title>Foreground Object Search by Distilling Composite Image Feature</title>
      <link>https://paperswithcode.com/paper/foreground-object-search-by-distilling</link>
      <description><![CDATA[Additionally, previous works did not release their datasets, so we contribute two datasets for FOS task: S-FOSD dataset with synthetic composite images and R-FOSD dataset with real composite images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foreground-object-search-by-distilling</guid>
    </item>
    <item>
      <title>AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities</title>
      <link>https://paperswithcode.com/paper/aspectmmkg-a-multi-modal-knowledge-graph-with</link>
      <description><![CDATA[Multi-modal knowledge graphs (MMKGs) combine different modal data (e. g., text and image) for a comprehensive understanding of entities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aspectmmkg-a-multi-modal-knowledge-graph-with</guid>
    </item>
    <item>
      <title>Separate Anything You Describe</title>
      <link>https://paperswithcode.com/paper/separate-anything-you-describe</link>
      <description><![CDATA[In this work, we introduce AudioSep, a foundation model for open-domain audio source separation with natural language queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/separate-anything-you-describe</guid>
    </item>
  </channel>
</rss>
