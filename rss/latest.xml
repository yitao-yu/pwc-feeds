<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 18 Mar 2024 21:08:18 +0000</lastBuildDate>
    <item>
      <title>Strong and Controllable Blind Image Decomposition</title>
      <link>https://paperswithcode.com/paper/strong-and-controllable-blind-image</link>
      <description><![CDATA[To address this need, we add controllability to the blind image decomposition process, allowing users to enter which types of degradation to remove or retain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/strong-and-controllable-blind-image</guid>
    </item>
    <item>
      <title>NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices</title>
      <link>https://paperswithcode.com/paper/neuflow-real-time-high-accuracy-optical-flow</link>
      <description><![CDATA[Given the features of the input images extracted at different spatial resolutions, global matching is employed to estimate an initial optical flow on the 1/16 resolution, capturing large displacement, which is then refined on the 1/8 resolution with lightweight CNN layers for better accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuflow-real-time-high-accuracy-optical-flow</guid>
    </item>
    <item>
      <title>GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery</title>
      <link>https://paperswithcode.com/paper/get-unlocking-the-multi-modal-potential-of</link>
      <description><![CDATA[Specifically, our TES leverages the property that CLIP can generate aligned vision-language features, converting visual embeddings into tokens of the CLIP's text encoder to generate pseudo text embeddings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/get-unlocking-the-multi-modal-potential-of</guid>
    </item>
    <item>
      <title>SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores</title>
      <link>https://paperswithcode.com/paper/socialgenpod-privacy-friendly-generative-ai</link>
      <description><![CDATA[Unlike centralised Web and data architectures that keep user data tied to application and service providers, we show how one can use Solid -- a decentralised Web specification -- to decouple user data from generative AI applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/socialgenpod-privacy-friendly-generative-ai</guid>
    </item>
    <item>
      <title>Rethinking Low-quality Optical Flow in Unsupervised Surgical Instrument Segmentation</title>
      <link>https://paperswithcode.com/paper/rethinking-low-quality-optical-flow-in</link>
      <description><![CDATA[Video-based surgical instrument segmentation plays an important role in robot-assisted surgeries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-low-quality-optical-flow-in</guid>
    </item>
    <item>
      <title>Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification</title>
      <link>https://paperswithcode.com/paper/magic-tokens-select-diverse-tokens-for-multi</link>
      <description><![CDATA[To address above issues, we propose a novel learning framework named \textbf{EDITOR} to select diverse tokens from vision Transformers for multi-modal object ReID.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magic-tokens-select-diverse-tokens-for-multi</guid>
    </item>
    <item>
      <title>Triple GNNs: Introducing Syntactic and Semantic Information for Conversational Aspect-Based Quadruple Sentiment Analysis</title>
      <link>https://paperswithcode.com/paper/triple-gnns-introducing-syntactic-and</link>
      <description><![CDATA[This necessitates a dual focus on both the syntactic information of individual utterances and the semantic interaction among them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triple-gnns-introducing-syntactic-and</guid>
    </item>
    <item>
      <title>Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study</title>
      <link>https://paperswithcode.com/paper/benchmarking-zero-shot-robustness-of</link>
      <description><![CDATA[We show that CLIP leads to a significant robustness drop compared to supervised ImageNet models on our benchmark, especially under synthetic distribution shift and adversarial attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-zero-shot-robustness-of</guid>
    </item>
    <item>
      <title>Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding</title>
      <link>https://paperswithcode.com/paper/isotropic3d-image-to-3d-generation-based-on-a</link>
      <description><![CDATA[As a result, with a single image CLIP embedding, Isotropic3D is capable of generating multi-view mutually consistent images and also a 3D model with more symmetrical and neat content, well-proportioned geometry, rich colored texture, and less distortion compared with existing image-to-3D methods while still preserving the similarity to the reference image to a large extent.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/isotropic3d-image-to-3d-generation-based-on-a</guid>
    </item>
    <item>
      <title>Leveraging Neural Radiance Field in Descriptor Synthesis for Keypoints Scene Coordinate Regression</title>
      <link>https://paperswithcode.com/paper/leveraging-neural-radiance-field-in</link>
      <description><![CDATA[Classical structural-based visual localization methods offer high accuracy but face trade-offs in terms of storage, speed, and privacy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-neural-radiance-field-in</guid>
    </item>
    <item>
      <title>Attention-Enhanced Hybrid Feature Aggregation Network for 3D Brain Tumor Segmentation</title>
      <link>https://paperswithcode.com/paper/attention-enhanced-hybrid-feature-aggregation</link>
      <description><![CDATA[In our approach, we utilized a multi-scale, attention-guided and hybrid U-Net-shaped model -- GLIMS -- to perform 3D brain tumor segmentation in three regions: Enhancing Tumor (ET), Tumor Core (TC), and Whole Tumor (WT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-enhanced-hybrid-feature-aggregation</guid>
    </item>
    <item>
      <title>RAFT: Adapting Language Model to Domain Specific RAG</title>
      <link>https://paperswithcode.com/paper/raft-adapting-language-model-to-domain</link>
      <description><![CDATA[In this paper, we present Retrieval Augmented FineTuning (RAFT), a training recipe that improves the model's ability to answer questions in a "open-book" in-domain settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/raft-adapting-language-model-to-domain</guid>
    </item>
    <item>
      <title>Efficient Multiplayer Battle Game Optimizer for Adversarial Robust Neural Architecture Search</title>
      <link>https://paperswithcode.com/paper/efficient-multiplayer-battle-game-optimizer</link>
      <description><![CDATA[This paper introduces a novel metaheuristic algorithm, known as the efficient multiplayer battle game optimizer (EMBGO), specifically designed for addressing complex numerical optimization tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-multiplayer-battle-game-optimizer</guid>
    </item>
    <item>
      <title>What Makes Good Collaborative Views? Contrastive Mutual Information Maximization for Multi-Agent Perception</title>
      <link>https://paperswithcode.com/paper/what-makes-good-collaborative-views</link>
      <description><![CDATA[The core philosophy of CMiMC is to preserve discriminative information of individual views in the collaborative view by maximizing mutual information between pre- and post-collaboration features while enhancing the efficacy of collaborative views by minimizing the loss function of downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-makes-good-collaborative-views</guid>
    </item>
    <item>
      <title>Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction</title>
      <link>https://paperswithcode.com/paper/take-care-of-your-prompt-bias-investigating</link>
      <description><![CDATA[Hopefully, our plug-and-play approach can be a golden standard to strengthen PLMs toward reliable knowledge bases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/take-care-of-your-prompt-bias-investigating</guid>
    </item>
    <item>
      <title>Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation Guided by the Characteristic Dance Primitives</title>
      <link>https://paperswithcode.com/paper/lodge-a-coarse-to-fine-diffusion-network-for</link>
      <description><![CDATA[In contrast, the second-stage is the local diffusion, which parallelly generates detailed motion sequences under the guidance of the dance primitives and choreographic rules.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lodge-a-coarse-to-fine-diffusion-network-for</guid>
    </item>
    <item>
      <title>Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification with Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/team-trifecta-at-factify5wqa-setting-the</link>
      <description><![CDATA[In this paper, we present Pre-CoFactv3, a comprehensive framework comprised of Question Answering and Text Classification components for fact verification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/team-trifecta-at-factify5wqa-setting-the</guid>
    </item>
    <item>
      <title>Hybrid Convolutional and Attention Network for Hyperspectral Image Denoising</title>
      <link>https://paperswithcode.com/paper/hybrid-convolutional-and-attention-network</link>
      <description><![CDATA[To enhance the modeling of both global and local features, we have devised a convolution and attention fusion module aimed at capturing long-range dependencies and neighborhood spectral correlations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hybrid-convolutional-and-attention-network</guid>
    </item>
    <item>
      <title>Revisiting Adversarial Training under Long-Tailed Distributions</title>
      <link>https://paperswithcode.com/paper/revisiting-adversarial-training-under-long</link>
      <description><![CDATA[Extensive experiments further corroborate that data augmentation alone can significantly improve robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-adversarial-training-under-long</guid>
    </item>
    <item>
      <title>NECA: Neural Customizable Human Avatar</title>
      <link>https://paperswithcode.com/paper/neca-neural-customizable-human-avatar</link>
      <description><![CDATA[The core of our approach is to represent humans in complementary dual spaces and predict disentangled neural fields of geometry, albedo, shadow, as well as an external lighting, from which we are able to derive realistic rendering with high-frequency details via volumetric rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neca-neural-customizable-human-avatar</guid>
    </item>
    <item>
      <title>Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs</title>
      <link>https://paperswithcode.com/paper/less-is-more-one-shot-subgraph-reasoning-on</link>
      <description><![CDATA[To deduce new facts on a knowledge graph (KG), a link predictor learns from the graph structure and collects local evidence to find the answer to a given query.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-is-more-one-shot-subgraph-reasoning-on</guid>
    </item>
    <item>
      <title>Real-Time Image Segmentation via Hybrid Convolutional-Transformer Architecture Search</title>
      <link>https://paperswithcode.com/paper/real-time-image-segmentation-via-hybrid</link>
      <description><![CDATA[Manually replacing convolution layers with multi-head self-attention is non-trivial due to the costly overhead in memory to maintain high resolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-image-segmentation-via-hybrid</guid>
    </item>
    <item>
      <title>Interpretable Machine Learning for Survival Analysis</title>
      <link>https://paperswithcode.com/paper/interpretable-machine-learning-for-survival</link>
      <description><![CDATA[With the spread and rapid advancement of black box machine learning models, the field of interpretable machine learning (IML) or explainable artificial intelligence (XAI) has become increasingly important over the last decade.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpretable-machine-learning-for-survival</guid>
    </item>
    <item>
      <title>The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation</title>
      <link>https://paperswithcode.com/paper/the-whole-is-better-than-the-sum-using</link>
      <description><![CDATA[Large language models (LLMs) have shown excellent performance on various NLP tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-whole-is-better-than-the-sum-using</guid>
    </item>
    <item>
      <title>CDMAD: Class-Distribution-Mismatch-Aware Debiasing for Class-Imbalanced Semi-Supervised Learning</title>
      <link>https://paperswithcode.com/paper/cdmad-class-distribution-mismatch-aware</link>
      <description><![CDATA[Pseudo-label-based semi-supervised learning (SSL) algorithms trained on a class-imbalanced set face two cascading challenges: 1) Classifiers tend to be biased towards majority classes, and 2) Biased pseudo-labels are used for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cdmad-class-distribution-mismatch-aware</guid>
    </item>
    <item>
      <title>Progressive Divide-and-Conquer via Subsampling Decomposition for Accelerated MRI</title>
      <link>https://paperswithcode.com/paper/progressive-divide-and-conquer-via</link>
      <description><![CDATA[Starting from decomposing the original maximum-a-posteriori problem of accelerated MRI, we present a rigorous derivation of the proposed PDAC framework, which could be further unfolded into an end-to-end trainable network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progressive-divide-and-conquer-via</guid>
    </item>
    <item>
      <title>KP-RED: Exploiting Semantic Keypoints for Joint 3D Shape Retrieval and Deformation</title>
      <link>https://paperswithcode.com/paper/kp-red-exploiting-semantic-keypoints-for</link>
      <description><![CDATA[In this paper, we present KP-RED, a unified KeyPoint-driven REtrieval and Deformation framework that takes object scans as input and jointly retrieves and deforms the most geometrically similar CAD models from a pre-processed database to tightly match the target.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kp-red-exploiting-semantic-keypoints-for</guid>
    </item>
    <item>
      <title>CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model</title>
      <link>https://paperswithcode.com/paper/cdgp-automatic-cloze-distractor-generation</link>
      <description><![CDATA[Manually designing cloze test consumes enormous time and efforts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cdgp-automatic-cloze-distractor-generation</guid>
    </item>
    <item>
      <title>Monkeypox disease recognition model based on improved SE-InceptionV3</title>
      <link>https://paperswithcode.com/paper/monkeypox-disease-recognition-model-based-on</link>
      <description><![CDATA[In the wake of the global spread of monkeypox, accurate disease recognition has become crucial.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monkeypox-disease-recognition-model-based-on</guid>
    </item>
    <item>
      <title>Towards Generalizable Deepfake Video Detection with Thumbnail Layout and Graph Reasoning</title>
      <link>https://paperswithcode.com/paper/towards-generalizable-deepfake-video</link>
      <description><![CDATA[The deepfake threats to society and cybersecurity have provoked significant public apprehension, driving intensified efforts within the realm of deepfake video detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-generalizable-deepfake-video</guid>
    </item>
    <item>
      <title>Generative Region-Language Pretraining for Open-Ended Object Detection</title>
      <link>https://paperswithcode.com/paper/generative-region-language-pretraining-for</link>
      <description><![CDATA[To address it, we formulate object detection as a generative problem and propose a simple framework named GenerateU, which can detect dense objects and generate their names in a free-form way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-region-language-pretraining-for</guid>
    </item>
    <item>
      <title>A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges</title>
      <link>https://paperswithcode.com/paper/a-survey-on-game-playing-agents-and-large</link>
      <description><![CDATA[The swift evolution of Large-scale Models (LMs), either language-focused or multi-modal, has garnered extensive attention in both academy and industry.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-game-playing-agents-and-large</guid>
    </item>
    <item>
      <title>VRHCF: Cross-Source Point Cloud Registration via Voxel Representation and Hierarchical Correspondence Filtering</title>
      <link>https://paperswithcode.com/paper/vrhcf-cross-source-point-cloud-registration</link>
      <description><![CDATA[Our method exhibits versatile applicability and excels in both traditional homologous registration and challenging cross-source registration scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vrhcf-cross-source-point-cloud-registration</guid>
    </item>
    <item>
      <title>FeatUp: A Model-Agnostic Framework for Features at Any Resolution</title>
      <link>https://paperswithcode.com/paper/featup-a-model-agnostic-framework-for</link>
      <description><![CDATA[Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/featup-a-model-agnostic-framework-for</guid>
    </item>
    <item>
      <title>Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A Case Study on Domain-Specific Queries in Private Knowledge-Bases</title>
      <link>https://paperswithcode.com/paper/enhancing-llm-factual-accuracy-with-rag-to</link>
      <description><![CDATA[We proposed an end-to-end system design towards utilizing Retrieval Augmented Generation (RAG) to improve the factual accuracy of Large Language Models (LLMs) for domain-specific and time-sensitive queries related to private knowledge-bases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-llm-factual-accuracy-with-rag-to</guid>
    </item>
    <item>
      <title>From Chaos to Clarity: Time Series Anomaly Detection in Astronomical Observations</title>
      <link>https://paperswithcode.com/paper/from-chaos-to-clarity-time-series-anomaly</link>
      <description><![CDATA[However, existing time series anomaly detection methods fall short in tackling the unique characteristics of astronomical observations where each star is inherently independent but interfered by random concurrent noise, resulting in a high rate of false alarms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-chaos-to-clarity-time-series-anomaly</guid>
    </item>
    <item>
      <title>Online GNN Evaluation Under Test-time Graph Distribution Shifts</title>
      <link>https://paperswithcode.com/paper/online-gnn-evaluation-under-test-time-graph</link>
      <description><![CDATA[This enables the effective evaluation of the well-trained GNNs' ability to capture test node semantics and structural representations, making it an expressive metric for estimating the generalization error in online GNN evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/online-gnn-evaluation-under-test-time-graph</guid>
    </item>
    <item>
      <title>Visual Foundation Models Boost Cross-Modal Unsupervised Domain Adaptation for 3D Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/visual-foundation-models-boost-cross-modal</link>
      <description><![CDATA[Then, another VFM trained on fine-grained 2D masks is adopted to guide the generation of semantically augmented images and point clouds to enhance the performance of neural networks, which mix the data from source and target domains like view frustums (FrustumMixing).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-foundation-models-boost-cross-modal</guid>
    </item>
    <item>
      <title>BlindDiff: Empowering Degradation Modelling in Diffusion Models for Blind Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/blinddiff-empowering-degradation-modelling-in</link>
      <description><![CDATA[BlindDiff seamlessly integrates the MAP-based optimization into DMs, which constructs a joint distribution of the low-resolution (LR) observation, high-resolution (HR) data, and degradation kernels for the data and kernel priors, and solves the blind SR problem by unfolding MAP approach along with the reverse process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blinddiff-empowering-degradation-modelling-in</guid>
    </item>
    <item>
      <title>DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models</title>
      <link>https://paperswithcode.com/paper/dragin-dynamic-retrieval-augmented-generation</link>
      <description><![CDATA[Our framework is specifically designed to make decisions on when and what to retrieve based on the LLM's real-time information needs during the text generation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dragin-dynamic-retrieval-augmented-generation</guid>
    </item>
    <item>
      <title>Histo-Genomic Knowledge Distillation For Cancer Prognosis From Histopathology Whole Slide Images</title>
      <link>https://paperswithcode.com/paper/histo-genomic-knowledge-distillation-for</link>
      <description><![CDATA[G-HANet is expected to be explored as a useful tool by the research community to address the current bottleneck of insufficient histo-genomic data pairing in the context of cancer prognosis and precision oncology.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/histo-genomic-knowledge-distillation-for</guid>
    </item>
    <item>
      <title>SpikeReveal: Unlocking Temporal Sequences from Real Blurry Inputs with Spike Streams</title>
      <link>https://paperswithcode.com/paper/spikereveal-unlocking-temporal-sequences-from</link>
      <description><![CDATA[Our approach begins with the formulation of a spike-guided deblurring model that explores the theoretical relationships among spike streams, blurry images, and their corresponding sharp sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spikereveal-unlocking-temporal-sequences-from</guid>
    </item>
    <item>
      <title>Gradient-Aware Logit Adjustment Loss for Long-tailed Classifier</title>
      <link>https://paperswithcode.com/paper/gradient-aware-logit-adjustment-loss-for-long</link>
      <description><![CDATA[Additionally, We find that most of the solutions to long-tailed problems are still biased towards head classes in the end, and we propose a simple and post hoc prediction re-balancing strategy to further mitigate the basis toward head class.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gradient-aware-logit-adjustment-loss-for-long</guid>
    </item>
    <item>
      <title>Generalized Predictive Model for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/generalized-predictive-model-for-autonomous</link>
      <description><![CDATA[In this paper, we introduce the first large-scale video prediction model in the autonomous driving discipline.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-predictive-model-for-autonomous</guid>
    </item>
    <item>
      <title>When Semantic Segmentation Meets Frequency Aliasing</title>
      <link>https://paperswithcode.com/paper/when-semantic-segmentation-meets-frequency</link>
      <description><![CDATA[While positively correlated with the proposed aliasing score, three types of hard pixels exhibit different patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-semantic-segmentation-meets-frequency</guid>
    </item>
    <item>
      <title>Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking</title>
      <link>https://paperswithcode.com/paper/quiet-star-language-models-can-teach</link>
      <description><![CDATA[Crucially, these improvements require no fine-tuning on these tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quiet-star-language-models-can-teach</guid>
    </item>
    <item>
      <title>Transformers Get Stable: An End-to-End Signal Propagation Theory for Language Models</title>
      <link>https://paperswithcode.com/paper/transformers-get-stable-an-end-to-end-signal</link>
      <description><![CDATA[In spite of their huge success, transformer models remain difficult to scale in depth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformers-get-stable-an-end-to-end-signal</guid>
    </item>
    <item>
      <title>DiTMoS: Delving into Diverse Tiny-Model Selection on Microcontrollers</title>
      <link>https://paperswithcode.com/paper/ditmos-delving-into-diverse-tiny-model</link>
      <description><![CDATA[Enabling efficient and accurate deep neural network (DNN) inference on microcontrollers is non-trivial due to the constrained on-chip resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ditmos-delving-into-diverse-tiny-model</guid>
    </item>
    <item>
      <title>Large Language Models are Parallel Multilingual Learners</title>
      <link>https://paperswithcode.com/paper/large-language-models-are-parallel</link>
      <description><![CDATA[In this study, we reveal an in-context learning (ICL) capability of multilingual large language models (LLMs): by translating the input to several languages, we provide Parallel Input in Multiple Languages (PiM) to LLMs, which significantly enhances their comprehension abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-are-parallel</guid>
    </item>
    <item>
      <title>S^2MVTC: a Simple yet Efficient Scalable Multi-View Tensor Clustering</title>
      <link>https://paperswithcode.com/paper/s-2mvtc-a-simple-yet-efficient-scalable-multi</link>
      <description><![CDATA[Specifically, we first construct the embedding feature tensor by stacking the embedding features of different views into a tensor and rotating it.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s-2mvtc-a-simple-yet-efficient-scalable-multi</guid>
    </item>
  </channel>
</rss>
