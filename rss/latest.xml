<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 14 Oct 2022 09:22:33 +0000</lastBuildDate>
    <item>
      <title>Data augmentation on-the-fly and active learning in data stream classification</title>
      <link>https://paperswithcode.com/paper/data-augmentation-on-the-fly-and-active</link>
      <description><![CDATA[Second, learning models have access to more labelled data without the need to increase the active learning budget and / or the original memory size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-augmentation-on-the-fly-and-active</guid>
    </item>
    <item>
      <title>Empirical Evaluation of Data Augmentations for Biobehavioral Time Series Data with Deep Learning</title>
      <link>https://paperswithcode.com/paper/empirical-evaluation-of-data-augmentations</link>
      <description><![CDATA[As an effective technique to increase the data variability and thus train deep models with better generalization, data augmentation (DA) is a critical step for the success of deep learning models on biobehavioral time series data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/empirical-evaluation-of-data-augmentations</guid>
    </item>
    <item>
      <title>Improved Bounds on Neural Complexity for Representing Piecewise Linear Functions</title>
      <link>https://paperswithcode.com/paper/improved-bounds-on-neural-complexity-for</link>
      <description><![CDATA[When the number of pieces is unknown, we prove that, in terms of the number of distinct linear components, the neural complexity of any CPWL function is at most polynomial growth for low-dimensional inputs and a factorial growth for the worst-case scenario, which are significantly better than existing results in the literature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-bounds-on-neural-complexity-for</guid>
    </item>
    <item>
      <title>ezCoref: Towards Unifying Annotation Guidelines for Coreference Resolution</title>
      <link>https://paperswithcode.com/paper/ezcoref-towards-unifying-annotation</link>
      <description><![CDATA[Large-scale, high-quality corpora are critical for advancing research in coreference resolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ezcoref-towards-unifying-annotation</guid>
    </item>
    <item>
      <title>AccelAT: A Framework for Accelerating the Adversarial Training of Deep Neural Networks through Accuracy Gradient</title>
      <link>https://paperswithcode.com/paper/accelat-a-framework-for-accelerating-the</link>
      <description><![CDATA[The experiments show comparable results with the related works, and in several experiments, the adversarial training of DNNs using our AccelAT framework is conducted up to 2 times faster than the existing techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelat-a-framework-for-accelerating-the</guid>
    </item>
    <item>
      <title>SubeventWriter: Iterative Sub-event Sequence Generation with Coherence Controller</title>
      <link>https://paperswithcode.com/paper/subeventwriter-iterative-sub-event-sequence</link>
      <description><![CDATA[In this paper, we propose a new task of sub-event generation for an unseen process to evaluate the understanding of the coherence of sub-event actions and objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/subeventwriter-iterative-sub-event-sequence</guid>
    </item>
    <item>
      <title>ImaginaryNet: Learning Object Detectors without Real Images and Annotations</title>
      <link>https://paperswithcode.com/paper/imaginarynet-learning-object-detectors</link>
      <description><![CDATA[Given a class label, the language model is used to generate a full description of a scene with a target object, and the text-to-image model deployed to generate a photo-realistic image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imaginarynet-learning-object-detectors</guid>
    </item>
    <item>
      <title>Feature-Proxy Transformer for Few-Shot Segmentation</title>
      <link>https://paperswithcode.com/paper/feature-proxy-transformer-for-few-shot</link>
      <description><![CDATA[With a rethink of recent advances, we find that the current FSS framework has deviated far from the supervised segmentation framework: Given the deep features, FSS methods typically use an intricate decoder to perform sophisticated pixel-wise matching, while the supervised segmentation methods use a simple linear classification head.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/feature-proxy-transformer-for-few-shot</guid>
    </item>
    <item>
      <title>HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial Networks</title>
      <link>https://paperswithcode.com/paper/hoechstgan-virtual-lymphocyte-staining-using</link>
      <description><![CDATA[The presence and density of specific types of immune cells are important to understand a patient's immune response to cancer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hoechstgan-virtual-lymphocyte-staining-using</guid>
    </item>
    <item>
      <title>RTFormer: Efficient Design for Real-Time Semantic Segmentation with Transformer</title>
      <link>https://paperswithcode.com/paper/rtformer-efficient-design-for-real-time</link>
      <description><![CDATA[Recently, transformer-based networks have shown impressive results in semantic segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rtformer-efficient-design-for-real-time</guid>
    </item>
    <item>
      <title>Exploring Long-Sequence Masked Autoencoders</title>
      <link>https://paperswithcode.com/paper/exploring-long-sequence-masked-autoencoders</link>
      <description><![CDATA[Masked Autoencoding (MAE) has emerged as an effective approach for pre-training representations across multiple domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-long-sequence-masked-autoencoders</guid>
    </item>
    <item>
      <title>Attribution-aware Weight Transfer: A Warm-Start Initialization for Class-Incremental Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/attribution-aware-weight-transfer-a-warm</link>
      <description><![CDATA[In class-incremental semantic segmentation (CISS), deep learning architectures suffer from the critical problems of catastrophic forgetting and semantic background shift.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attribution-aware-weight-transfer-a-warm</guid>
    </item>
    <item>
      <title>Prompt-based Connective Prediction Method for Fine-grained Implicit Discourse Relation Recognition</title>
      <link>https://paperswithcode.com/paper/prompt-based-connective-prediction-method-for</link>
      <description><![CDATA[Due to the absence of connectives, implicit discourse relation recognition (IDRR) is still a challenging and crucial task in discourse analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-based-connective-prediction-method-for</guid>
    </item>
    <item>
      <title>Shape Preserving Facial Landmarks with Graph Attention Networks</title>
      <link>https://paperswithcode.com/paper/shape-preserving-facial-landmarks-with-graph</link>
      <description><![CDATA[Top-performing landmark estimation algorithms are based on exploiting the excellent ability of large convolutional neural networks (CNNs) to represent local appearance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shape-preserving-facial-landmarks-with-graph</guid>
    </item>
    <item>
      <title>Sparse in Space and Time: Audio-visual Synchronisation with Trainable Selectors</title>
      <link>https://paperswithcode.com/paper/sparse-in-space-and-time-audio-visual</link>
      <description><![CDATA[This contrasts with the case of synchronising videos of talking heads, where audio-visual correspondence is dense in both time and space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparse-in-space-and-time-audio-visual</guid>
    </item>
    <item>
      <title>Corneal endothelium assessment in specular microscopy images with Fuchs' dystrophy via deep regression of signed distance maps</title>
      <link>https://paperswithcode.com/paper/corneal-endothelium-assessment-in-specular</link>
      <description><![CDATA[Specular microscopy assessment of the human corneal endothelium (CE) in Fuchs' dystrophy is challenging due to the presence of dark image regions called guttae.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/corneal-endothelium-assessment-in-specular</guid>
    </item>
    <item>
      <title>Sentence Ambiguity, Grammaticality and Complexity Probes</title>
      <link>https://paperswithcode.com/paper/sentence-ambiguity-grammaticality-and</link>
      <description><![CDATA[It is unclear whether, how and where large pre-trained language models capture subtle linguistic traits like ambiguity, grammaticality and sentence complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sentence-ambiguity-grammaticality-and</guid>
    </item>
    <item>
      <title>LIME: Weakly-Supervised Text Classification Without Seeds</title>
      <link>https://paperswithcode.com/paper/lime-weakly-supervised-text-classification-1</link>
      <description><![CDATA[With just an off-the-shelf textual entailment model, LIME outperforms recent baselines in weakly-supervised text classification and achieves state-of-the-art in 4 benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lime-weakly-supervised-text-classification-1</guid>
    </item>
    <item>
      <title>Few-shot Relational Reasoning via Connection Subgraph Pretraining</title>
      <link>https://paperswithcode.com/paper/few-shot-relational-reasoning-via-connection</link>
      <description><![CDATA[Our pretrained model can then be directly applied to target few-shot tasks on without the need for training few-shot tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/few-shot-relational-reasoning-via-connection</guid>
    </item>
    <item>
      <title>H2RBox: Horizonal Box Annotation is All You Need for Oriented Object Detection</title>
      <link>https://paperswithcode.com/paper/h2rbox-horizonal-box-annotation-is-all-you</link>
      <description><![CDATA[This paper proposes a simple yet effective oriented object detection approach called H2RBox merely using horizontal box annotation for weakly-supervised training, which closes the above gap and shows competitive performance even against those trained with rotated boxes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h2rbox-horizonal-box-annotation-is-all-you</guid>
    </item>
    <item>
      <title>Re3: Generating Longer Stories With Recursive Reprompting and Revision</title>
      <link>https://paperswithcode.com/paper/re3-generating-longer-stories-with-recursive</link>
      <description><![CDATA[We consider the problem of automatically generating longer stories of over two thousand words.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/re3-generating-longer-stories-with-recursive</guid>
    </item>
    <item>
      <title>Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features</title>
      <link>https://paperswithcode.com/paper/decoding-visual-neural-representations-by</link>
      <description><![CDATA[Finally, we construct three trimodal matching datasets, and the extensive experiments lead to some interesting conclusions and cognitive insights: 1) decoding novel visual categories from human brain activity is practically possible with good accuracy; 2) decoding models using the combination of visual and linguistic features perform much better than those using either of them alone; 3) visual perception may be accompanied by linguistic influences to represent the semantics of visual stimuli.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decoding-visual-neural-representations-by</guid>
    </item>
    <item>
      <title>Multi-agent Dynamic Algorithm Configuration</title>
      <link>https://paperswithcode.com/paper/multi-agent-dynamic-algorithm-configuration</link>
      <description><![CDATA[MA-DAC formulates the dynamic configuration of a complex algorithm with multiple types of hyperparameters as a contextual multi-agent Markov decision process and solves it by a cooperative multi-agent RL (MARL) algorithm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-agent-dynamic-algorithm-configuration</guid>
    </item>
    <item>
      <title>Unified Vision and Language Prompt Learning</title>
      <link>https://paperswithcode.com/paper/unified-vision-and-language-prompt-learning</link>
      <description><![CDATA[Prompt tuning, a parameter- and data-efficient transfer learning paradigm that tunes only a small number of parameters in a model's input space, has become a trend in the vision community since the emergence of large vision-language models like CLIP.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-vision-and-language-prompt-learning</guid>
    </item>
    <item>
      <title>Sample-Then-Optimize Batch Neural Thompson Sampling</title>
      <link>https://paperswithcode.com/paper/sample-then-optimize-batch-neural-thompson</link>
      <description><![CDATA[linear model), which is equivalently sampled from the GP posterior with the NTK as the kernel function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sample-then-optimize-batch-neural-thompson</guid>
    </item>
    <item>
      <title>Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/intermediate-prototype-mining-transformer-for</link>
      <description><![CDATA[To solve this problem, we are the first to introduce an intermediate prototype for mining both deterministic category information from the support and adaptive category knowledge from the query.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intermediate-prototype-mining-transformer-for</guid>
    </item>
    <item>
      <title>RaP: Redundancy-aware Video-language Pre-training for Text-Video Retrieval</title>
      <link>https://paperswithcode.com/paper/rap-redundancy-aware-video-language-pre</link>
      <description><![CDATA[Sparse sampling is also likely to miss important frames corresponding to some text portions, resulting in textual redundancy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rap-redundancy-aware-video-language-pre</guid>
    </item>
    <item>
      <title>Threshold Treewidth and Hypertree Width</title>
      <link>https://paperswithcode.com/paper/threshold-treewidth-and-hypertree-width</link>
      <description><![CDATA[However, here the order of the polynomial in the running time depends on the width, and this is known to be unavoidable; therefore, the problem is not fixed-parameter tractable parameterized by either of these width measures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/threshold-treewidth-and-hypertree-width</guid>
    </item>
    <item>
      <title>Sustainable Online Reinforcement Learning for Auto-bidding</title>
      <link>https://paperswithcode.com/paper/sustainable-online-reinforcement-learning-for</link>
      <description><![CDATA[Due to safety concerns, it was believed that the RL training process can only be carried out in an offline virtual advertising system (VAS) that is built based on the historical data generated in the RAS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sustainable-online-reinforcement-learning-for</guid>
    </item>
    <item>
      <title>CORL: Research-oriented Deep Offline Reinforcement Learning Library</title>
      <link>https://paperswithcode.com/paper/corl-research-oriented-deep-offline</link>
      <description><![CDATA[CORL is an open-source library that provides single-file implementations of Deep Offline Reinforcement Learning algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/corl-research-oriented-deep-offline</guid>
    </item>
    <item>
      <title>SageMix: Saliency-Guided Mixup for Point Clouds</title>
      <link>https://paperswithcode.com/paper/sagemix-saliency-guided-mixup-for-point</link>
      <description><![CDATA[Mixup is a simple and widely-used data augmentation technique that has proven effective in alleviating the problems of overfitting and data scarcity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sagemix-saliency-guided-mixup-for-point</guid>
    </item>
    <item>
      <title>Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation</title>
      <link>https://paperswithcode.com/paper/scaling-back-translation-with-domain-text</link>
      <description><![CDATA[In this paper, to overcome the limitation, we propose a Prompt based domain text Generation (PGEN) approach to produce the large-scale in-domain spoken language text data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-back-translation-with-domain-text</guid>
    </item>
    <item>
      <title>Towards a Unified Multi-Dimensional Evaluator for Text Generation</title>
      <link>https://paperswithcode.com/paper/towards-a-unified-multi-dimensional-evaluator</link>
      <description><![CDATA[We re-frame NLG evaluation as a Boolean Question Answering (QA) task, and by guiding the model with different questions, we can use one evaluator to evaluate from multiple dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-a-unified-multi-dimensional-evaluator</guid>
    </item>
    <item>
      <title>OpenOOD: Benchmarking Generalized Out-of-Distribution Detection</title>
      <link>https://paperswithcode.com/paper/openood-benchmarking-generalized-out-of</link>
      <description><![CDATA[Out-of-distribution (OOD) detection is vital to safety-critical machine learning applications and has thus been extensively studied, with a plethora of methods developed in the literature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openood-benchmarking-generalized-out-of</guid>
    </item>
    <item>
      <title>Wasserstein Barycenter-based Model Fusion and Linear Mode Connectivity of Neural Networks</title>
      <link>https://paperswithcode.com/paper/wasserstein-barycenter-based-model-fusion-and</link>
      <description><![CDATA[In our framework, the fusion occurs in a layer-wise manner and builds on an interpretation of a node in a network as a function of the layer preceding it.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wasserstein-barycenter-based-model-fusion-and</guid>
    </item>
    <item>
      <title>Language Models of Code are Few-Shot Commonsense Learners</title>
      <link>https://paperswithcode.com/paper/language-models-of-code-are-few-shot</link>
      <description><![CDATA[In all these natural language tasks, we show that using our approach, a code generation LM (CODEX) outperforms natural-LMs that are fine-tuned on the target task (e. g., T5) and other strong LMs such as GPT-3 in the few-shot setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-of-code-are-few-shot</guid>
    </item>
    <item>
      <title>Equal Improvability: A New Fairness Notion Considering the Long-term Impact</title>
      <link>https://paperswithcode.com/paper/equal-improvability-a-new-fairness-notion</link>
      <description><![CDATA[In order to promote long-term fairness, we propose a new fairness notion called Equal Improvability (EI), which equalizes the potential acceptance rate of the rejected samples across different groups assuming a bounded level of effort will be spent by each rejected sample.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/equal-improvability-a-new-fairness-notion</guid>
    </item>
    <item>
      <title>Hybrid RL: Using Both Offline and Online Data Can Make RL Efficient</title>
      <link>https://paperswithcode.com/paper/hybrid-rl-using-both-offline-and-online-data</link>
      <description><![CDATA[We consider a hybrid reinforcement learning setting (Hybrid RL), in which an agent has access to an offline dataset and the ability to collect experience via real-world online interaction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hybrid-rl-using-both-offline-and-online-data</guid>
    </item>
    <item>
      <title>U-HRNet: Delving into Improving Semantic Representation of High Resolution Network for Dense Prediction</title>
      <link>https://paperswithcode.com/paper/u-hrnet-delving-into-improving-semantic</link>
      <description><![CDATA[Therefore, we designed a U-shaped High-Resolution Network (U-HRNet), which adds more stages after the feature map with strongest semantic representation and relaxes the constraint in HRNet that all resolutions need to be calculated parallel for a newly added stage.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/u-hrnet-delving-into-improving-semantic</guid>
    </item>
    <item>
      <title>Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer</title>
      <link>https://paperswithcode.com/paper/q-vit-accurate-and-fully-quantized-low-bit</link>
      <description><![CDATA[The large pre-trained vision transformers (ViTs) have demonstrated remarkable performance on various visual tasks, but suffer from expensive computational and memory cost problems when deployed on resource-constrained devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/q-vit-accurate-and-fully-quantized-low-bit</guid>
    </item>
    <item>
      <title>Utilizing supervised models to infer consensus labels and their quality from data with multiple annotators</title>
      <link>https://paperswithcode.com/paper/utilizing-supervised-models-to-infer</link>
      <description><![CDATA[Many algorithms also rely solely on annotator statistics, ignoring the features of the examples from which the annotations derive.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/utilizing-supervised-models-to-infer</guid>
    </item>
    <item>
      <title>PDEBENCH: An Extensive Benchmark for Scientific Machine Learning</title>
      <link>https://paperswithcode.com/paper/pdebench-an-extensive-benchmark-for</link>
      <description><![CDATA[With those metrics we identify tasks which are challenging for recent ML methods and propose these tasks as future challenges for the community.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pdebench-an-extensive-benchmark-for</guid>
    </item>
    <item>
      <title>Improving Out-of-Distribution Generalization by Adversarial Training with Structured Priors</title>
      <link>https://paperswithcode.com/paper/improving-out-of-distribution-generalization-1</link>
      <description><![CDATA[In this paper, we empirically show that sample-wise AT has limited improvement on OOD performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-out-of-distribution-generalization-1</guid>
    </item>
    <item>
      <title>Real Spike: Learning Real-valued Spikes for Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/real-spike-learning-real-valued-spikes-for</link>
      <description><![CDATA[Motivated by this assumption, a training-inference decoupling method for SNNs named as Real Spike is proposed, which not only enjoys both unshared convolution kernels and binary spikes in inference-time but also maintains both shared convolution kernels and Real-valued Spikes during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-spike-learning-real-valued-spikes-for</guid>
    </item>
    <item>
      <title>How to Train Vision Transformer on Small-scale Datasets?</title>
      <link>https://paperswithcode.com/paper/how-to-train-vision-transformer-on-small</link>
      <description><![CDATA[However, in contrast to convolutional neural networks, Vision Transformer lacks inherent inductive biases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-to-train-vision-transformer-on-small</guid>
    </item>
    <item>
      <title>Model-Based Offline Reinforcement Learning with Pessimism-Modulated Dynamics Belief</title>
      <link>https://paperswithcode.com/paper/model-based-offline-reinforcement-learning</link>
      <description><![CDATA[To make practical, we further devise an offline RL algorithm to approximately find the solution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/model-based-offline-reinforcement-learning</guid>
    </item>
    <item>
      <title>CROP: Zero-shot Cross-lingual Named Entity Recognition with Multilingual Labeled Sequence Translation</title>
      <link>https://paperswithcode.com/paper/crop-zero-shot-cross-lingual-named-entity</link>
      <description><![CDATA[Specifically, the target sequence is first translated into the source language and then tagged by a source NER model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/crop-zero-shot-cross-lingual-named-entity</guid>
    </item>
    <item>
      <title>A Mixture of Surprises for Unsupervised Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/a-mixture-of-surprises-for-unsupervised</link>
      <description><![CDATA[However, both strategies rely on a strong assumption: the entropy of the environment's dynamics is either high or low.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-mixture-of-surprises-for-unsupervised</guid>
    </item>
    <item>
      <title>On the Utility of Self-supervised Models for Prosody-related Tasks</title>
      <link>https://paperswithcode.com/paper/on-the-utility-of-self-supervised-models-for</link>
      <description><![CDATA[We find that 13 of the 15 SSL models outperformed the baseline on all the prosody-related tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-utility-of-self-supervised-models-for</guid>
    </item>
    <item>
      <title>Two approaches to inpainting microstructure with deep convolutional generative adversarial networks</title>
      <link>https://paperswithcode.com/paper/two-approaches-to-inpainting-microstructure</link>
      <description><![CDATA[Imaging is critical to the characterisation of materials.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/two-approaches-to-inpainting-microstructure</guid>
    </item>
  </channel>
</rss>
