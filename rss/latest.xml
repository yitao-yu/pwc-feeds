<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 29 Feb 2024 09:12:52 +0000</lastBuildDate>
    <item>
      <title>Downstream Task Guided Masking Learning in Masked Autoencoders Using Multi-Level Optimization</title>
      <link>https://paperswithcode.com/paper/downstream-task-guided-masking-learning-in</link>
      <description><![CDATA[Masked Autoencoder (MAE) is a notable method for self-supervised pretraining in visual representation learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/downstream-task-guided-masking-learning-in</guid>
    </item>
    <item>
      <title>3DSFLabelling: Boosting 3D Scene Flow Estimation by Pseudo Auto-labelling</title>
      <link>https://paperswithcode.com/paper/3dsflabelling-boosting-3d-scene-flow</link>
      <description><![CDATA[We present a novel approach from the perspective of auto-labelling, aiming to generate a large number of 3D scene flow pseudo labels for real-world LiDAR point clouds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dsflabelling-boosting-3d-scene-flow</guid>
    </item>
    <item>
      <title>Spannotation: Enhancing Semantic Segmentation for Autonomous Navigation with Efficient Image Annotation</title>
      <link>https://paperswithcode.com/paper/spannotation-enhancing-semantic-segmentation</link>
      <description><![CDATA[Spannotation is an open source user-friendly tool developed for image annotation for semantic segmentation specifically in autonomous navigation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spannotation-enhancing-semantic-segmentation</guid>
    </item>
    <item>
      <title>Sequence-level Semantic Representation Fusion for Recommender Systems</title>
      <link>https://paperswithcode.com/paper/sequence-level-semantic-representation-fusion</link>
      <description><![CDATA[The core idea of our approach is to conduct a sequence-level semantic fusion approach by better integrating global contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sequence-level-semantic-representation-fusion</guid>
    </item>
    <item>
      <title>Detection of Micromobility Vehicles in Urban Traffic Videos</title>
      <link>https://paperswithcode.com/paper/detection-of-micromobility-vehicles-in-urban</link>
      <description><![CDATA[Urban traffic environments present unique challenges for object detection, particularly with the increasing presence of micromobility vehicles like e-scooters and bikes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detection-of-micromobility-vehicles-in-urban</guid>
    </item>
    <item>
      <title>Representing 3D sparse map points and lines for camera relocalization</title>
      <link>https://paperswithcode.com/paper/representing-3d-sparse-map-points-and-lines</link>
      <description><![CDATA[Recent advancements in visual localization and mapping have demonstrated considerable success in integrating point and line features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representing-3d-sparse-map-points-and-lines</guid>
    </item>
    <item>
      <title>RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval</title>
      <link>https://paperswithcode.com/paper/rnns-are-not-transformers-yet-the-key</link>
      <description><![CDATA[This paper investigates the gap in representation powers of Recurrent Neural Networks (RNNs) and Transformers in the context of solving algorithmic problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rnns-are-not-transformers-yet-the-key</guid>
    </item>
    <item>
      <title>Hierarchical Multi-Relational Graph Representation Learning for Large-Scale Prediction of Drug-Drug Interactions</title>
      <link>https://paperswithcode.com/paper/hierarchical-multi-relational-graph</link>
      <description><![CDATA[Within the MVDSC, we utilize multiple DP features to construct graphs, where nodes represent DPs and edges denote different implicit correlations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-multi-relational-graph</guid>
    </item>
    <item>
      <title>Deep Confident Steps to New Pockets: Strategies for Docking Generalization</title>
      <link>https://paperswithcode.com/paper/deep-confident-steps-to-new-pockets</link>
      <description><![CDATA[Accurate blind docking has the potential to lead to new biological breakthroughs, but for this promise to be realized, docking methods must generalize well across the proteome.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-confident-steps-to-new-pockets</guid>
    </item>
    <item>
      <title>Attention-Propagation Network for Egocentric Heatmap to 3D Pose Lifting</title>
      <link>https://paperswithcode.com/paper/attention-propagation-network-for-egocentric</link>
      <description><![CDATA[We propose a novel heatmap-to-3D lifting method composed of the Grid ViT Encoder and the Propagation Network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-propagation-network-for-egocentric</guid>
    </item>
    <item>
      <title>Separate and Conquer: Decoupling Co-occurrence via Decomposition and Representation for Weakly Supervised Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/separate-and-conquer-decoupling-co-occurrence</link>
      <description><![CDATA[In the feature space, we propose to 'conquer' the false activation by enhancing semantic representation with multi-granularity knowledge contrast.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/separate-and-conquer-decoupling-co-occurrence</guid>
    </item>
    <item>
      <title>All in a Single Image: Large Multimodal Models are In-Image Learners</title>
      <link>https://paperswithcode.com/paper/all-in-a-single-image-large-multimodal-models</link>
      <description><![CDATA[This paper introduces a new in-context learning (ICL) mechanism called In-Image Learning (I$^2$L) that combines demonstration examples, visual cues, and instructions into a single image to enhance the capabilities of GPT-4V.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/all-in-a-single-image-large-multimodal-models</guid>
    </item>
    <item>
      <title>Prospect Personalized Recommendation on Large Language Model-based Agent Platform</title>
      <link>https://paperswithcode.com/paper/prospect-personalized-recommendation-on-large</link>
      <description><![CDATA[Additionally, we prospect the evolution of Rec4Agentverse and conceptualize it into three stages based on the enhancement of the interaction and information exchange among Agent Items, Agent Recommender, and the user.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prospect-personalized-recommendation-on-large</guid>
    </item>
    <item>
      <title>A BiRGAT Model for Multi-intent Spoken Language Understanding with Hierarchical Semantic Frames</title>
      <link>https://paperswithcode.com/paper/a-birgat-model-for-multi-intent-spoken</link>
      <description><![CDATA[Previous work on spoken language understanding (SLU) mainly focuses on single-intent settings, where each input utterance merely contains one user intent.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-birgat-model-for-multi-intent-spoken</guid>
    </item>
    <item>
      <title>Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation</title>
      <link>https://paperswithcode.com/paper/clustering-and-ranking-diversity-preserved</link>
      <description><![CDATA[The second step involves preserving dataset diversity through a clustering process. In our experiment, CaR selected a subset containing only 1. 96% of Alpaca's IT data, yet the underlying AlpaCaR model trained on this subset outperforms Alpaca by an average of 32. 1% in GPT-4 evaluations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clustering-and-ranking-diversity-preserved</guid>
    </item>
    <item>
      <title>EchoTrack: Auditory Referring Multi-Object Tracking for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/echotrack-auditory-referring-multi-object</link>
      <description><![CDATA[This paper introduces the task of Auditory Referring Multi-Object Tracking (AR-MOT), which dynamically tracks specific objects in a video sequence based on audio expressions and appears as a challenging problem in autonomous driving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/echotrack-auditory-referring-multi-object</guid>
    </item>
    <item>
      <title>Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards</title>
      <link>https://paperswithcode.com/paper/arithmetic-control-of-llms-for-diverse-user</link>
      <description><![CDATA[Additionally, DPA models user preferences as directions (i. e., unit vectors) in the reward space to achieve user-dependent preference control.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/arithmetic-control-of-llms-for-diverse-user</guid>
    </item>
    <item>
      <title>Sample-Efficient Preference-based Reinforcement Learning with Dynamics Aware Rewards</title>
      <link>https://paperswithcode.com/paper/sample-efficient-preference-based</link>
      <description><![CDATA[Preference-based reinforcement learning (PbRL) aligns a robot behavior with human preferences via a reward function learned from binary feedback over agent behaviors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sample-efficient-preference-based</guid>
    </item>
    <item>
      <title>Learning Invariant Inter-pixel Correlations for Superpixel Generation</title>
      <link>https://paperswithcode.com/paper/learning-invariant-inter-pixel-correlations</link>
      <description><![CDATA[To address this issue, we propose the Content Disentangle Superpixel (CDS) algorithm to selectively separate the invariant inter-pixel correlations and statistical properties, i. e., style noise.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-invariant-inter-pixel-correlations</guid>
    </item>
    <item>
      <title>CogBench: a large language model walks into a psychology lab</title>
      <link>https://paperswithcode.com/paper/cogbench-a-large-language-model-walks-into-a</link>
      <description><![CDATA[Large language models (LLMs) have significantly advanced the field of artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cogbench-a-large-language-model-walks-into-a</guid>
    </item>
    <item>
      <title>On the use of Silver Standard Data for Zero-shot Classification Tasks in Information Extraction</title>
      <link>https://paperswithcode.com/paper/on-the-use-of-silver-standard-data-for-zero</link>
      <description><![CDATA[Recent zero-shot classification methods converted the task to other NLP tasks (e. g., textual entailment) and used off-the-shelf models of these NLP tasks to directly perform inference on the test data without using a large amount of IE annotation data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-use-of-silver-standard-data-for-zero</guid>
    </item>
    <item>
      <title>Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/unsupervised-information-refinement-training</link>
      <description><![CDATA[Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating additional information from retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-information-refinement-training</guid>
    </item>
    <item>
      <title>Unsupervised Cross-Domain Image Retrieval via Prototypical Optimal Transport</title>
      <link>https://paperswithcode.com/paper/unsupervised-cross-domain-image-retrieval-via</link>
      <description><![CDATA[This paper introduces ProtoOT, a novel Optimal Transport formulation explicitly tailored for UCIR, which integrates intra-domain feature representation learning and cross-domain alignment into a unified framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-cross-domain-image-retrieval-via</guid>
    </item>
    <item>
      <title>Fast and Interpretable 2D Homography Decomposition: Similarity-Kernel-Similarity and Affine-Core-Affine Transformations</title>
      <link>https://paperswithcode.com/paper/fast-and-interpretable-2d-homography</link>
      <description><![CDATA[Under the minimal $4$-point configuration, the first and the last similarity transformations in SKS are computed by two anchor points on target and source planes, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-and-interpretable-2d-homography</guid>
    </item>
    <item>
      <title>UniVS: Unified and Universal Video Segmentation with Prompts as Queries</title>
      <link>https://paperswithcode.com/paper/univs-unified-and-universal-video</link>
      <description><![CDATA[Despite the recent advances in unified image segmentation (IS), developing a unified video segmentation (VS) model remains a challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/univs-unified-and-universal-video</guid>
    </item>
    <item>
      <title>Reflection Removal Using Recurrent Polarization-to-Polarization Network</title>
      <link>https://paperswithcode.com/paper/reflection-removal-using-recurrent</link>
      <description><![CDATA[This paper addresses reflection removal, which is the task of separating reflection components from a captured image and deriving the image with only transmission components.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reflection-removal-using-recurrent</guid>
    </item>
    <item>
      <title>Region-Aware Exposure Consistency Network for Mixed Exposure Correction</title>
      <link>https://paperswithcode.com/paper/region-aware-exposure-consistency-network-for</link>
      <description><![CDATA[Exposure correction aims to enhance images suffering from improper exposure to achieve satisfactory visual effects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/region-aware-exposure-consistency-network-for</guid>
    </item>
    <item>
      <title>Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis</title>
      <link>https://paperswithcode.com/paper/coarse-to-fine-latent-diffusion-for-pose</link>
      <description><![CDATA[While existing methods simply align the person appearance to the target pose, they are prone to overfitting due to the lack of a high-level semantic understanding on the source person image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coarse-to-fine-latent-diffusion-for-pose</guid>
    </item>
    <item>
      <title>Evaluating Quantized Large Language Models</title>
      <link>https://paperswithcode.com/paper/evaluating-quantized-large-language-models</link>
      <description><![CDATA[Post-training quantization (PTQ) has emerged as a promising technique to reduce the cost of large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-quantized-large-language-models</guid>
    </item>
    <item>
      <title>Grid-Based Continuous Normal Representation for Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/grid-based-continuous-normal-representation</link>
      <description><![CDATA[Several recent methods aim to detect anomalies based on a memory, comparing the input and the directly stored normal features (or trained features with normal images).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grid-based-continuous-normal-representation</guid>
    </item>
    <item>
      <title>Improving Open-Ended Text Generation via Adaptive Decoding</title>
      <link>https://paperswithcode.com/paper/improving-open-ended-text-generation-via</link>
      <description><![CDATA[Current language models decode text token by token according to probabilistic distribution, and determining the appropriate candidates for the next token is crucial to ensure generation quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-open-ended-text-generation-via</guid>
    </item>
    <item>
      <title>Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models</title>
      <link>https://paperswithcode.com/paper/editing-factual-knowledge-and-explanatory</link>
      <description><![CDATA[In this paper, we propose two model editing studies and validate them in the medical domain: (1) directly editing the factual medical knowledge and (2) editing the explanations to facts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/editing-factual-knowledge-and-explanatory</guid>
    </item>
    <item>
      <title>Constrained Decoding for Code Language Models via Efficient Left and Right Quotienting of Context-Sensitive Grammars</title>
      <link>https://paperswithcode.com/paper/constrained-decoding-for-code-language-models</link>
      <description><![CDATA[Large Language Models are powerful tools for program synthesis and advanced auto-completion, but come with no guarantee that their output code is syntactically correct.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/constrained-decoding-for-code-language-models</guid>
    </item>
    <item>
      <title>Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation</title>
      <link>https://paperswithcode.com/paper/learning-to-generate-instruction-tuning</link>
      <description><![CDATA[Overall, we show that learning with synthetic instruction tuning datasets is an effective way to adapt language models to new domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-generate-instruction-tuning</guid>
    </item>
    <item>
      <title>ResLoRA: Identity Residual Mapping in Low-Rank Adaption</title>
      <link>https://paperswithcode.com/paper/reslora-identity-residual-mapping-in-low-rank</link>
      <description><![CDATA[As one of the most popular parameter-efficient fine-tuning (PEFT) methods, low-rank adaptation (LoRA) is commonly applied to fine-tune large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reslora-identity-residual-mapping-in-low-rank</guid>
    </item>
    <item>
      <title>Dual-Context Aggregation for Universal Image Matting</title>
      <link>https://paperswithcode.com/paper/dual-context-aggregation-for-universal-image</link>
      <description><![CDATA[However, existing matting methods are designed for specific objects or guidance, neglecting the common requirement of aggregating global and local contexts in image matting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-context-aggregation-for-universal-image</guid>
    </item>
    <item>
      <title>NiteDR: Nighttime Image De-Raining with Cross-View Sensor Cooperative Learning for Dynamic Driving Scenes</title>
      <link>https://paperswithcode.com/paper/nitedr-nighttime-image-de-raining-with-cross</link>
      <description><![CDATA[Specifically, we introduce cooperative learning between visible and infrared images captured by different sensors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nitedr-nighttime-image-de-raining-with-cross</guid>
    </item>
    <item>
      <title>PiShield: A NeSy Framework for Learning with Requirements</title>
      <link>https://paperswithcode.com/paper/pishield-a-nesy-framework-for-learning-with</link>
      <description><![CDATA[Given the widespread application of deep learning, there is a growing need for frameworks allowing for the integration of the requirements across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pishield-a-nesy-framework-for-learning-with</guid>
    </item>
    <item>
      <title>Datasets for Large Language Models: A Comprehensive Survey</title>
      <link>https://paperswithcode.com/paper/datasets-for-large-language-models-a</link>
      <description><![CDATA[Additionally, a comprehensive review of the existing available dataset resources is also provided, including statistics from 444 datasets, covering 8 language categories and spanning 32 domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datasets-for-large-language-models-a</guid>
    </item>
    <item>
      <title>Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models</title>
      <link>https://paperswithcode.com/paper/token-specific-watermarking-with-enhanced</link>
      <description><![CDATA[Large language models generate high-quality responses with potential misinformation, underscoring the need for regulation by distinguishing AI-generated and human-written texts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/token-specific-watermarking-with-enhanced</guid>
    </item>
    <item>
      <title>How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning</title>
      <link>https://paperswithcode.com/paper/how-to-think-step-by-step-a-mechanistic</link>
      <description><![CDATA[Despite superior reasoning prowess demonstrated by Large Language Models (LLMs) with Chain-of-Thought (CoT) prompting, a lack of understanding prevails around the internal mechanisms of the models that facilitate CoT generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-to-think-step-by-step-a-mechanistic</guid>
    </item>
    <item>
      <title>Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication</title>
      <link>https://paperswithcode.com/paper/beyond-natural-language-llms-leveraging</link>
      <description><![CDATA[Natural language (NL) has long been the predominant format for human cognition and communication, and by extension, has been similarly pivotal in the development and application of Large Language Models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-natural-language-llms-leveraging</guid>
    </item>
    <item>
      <title>Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings</title>
      <link>https://paperswithcode.com/paper/unsupervised-zero-shot-reinforcement-learning</link>
      <description><![CDATA[Can we pre-train a generalist agent from a large amount of unlabeled offline trajectories such that it can be immediately adapted to any new downstream tasks in a zero-shot manner?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-zero-shot-reinforcement-learning</guid>
    </item>
    <item>
      <title>Training-Free Long-Context Scaling of Large Language Models</title>
      <link>https://paperswithcode.com/paper/training-free-long-context-scaling-of-large</link>
      <description><![CDATA[The ability of Large Language Models (LLMs) to process and generate coherent text is markedly weakened when the number of input tokens exceeds their pretraining length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-free-long-context-scaling-of-large</guid>
    </item>
    <item>
      <title>QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations</title>
      <link>https://paperswithcode.com/paper/quce-the-minimisation-and-quantification-of</link>
      <description><![CDATA[In this context, we introduce Quantified Uncertainty Counterfactual Explanations (QUCE), a method designed to mitigate out-of-distribution traversal by minimizing path uncertainty.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quce-the-minimisation-and-quantification-of</guid>
    </item>
    <item>
      <title>Transfer Learning Bayesian Optimization to Design Competitor DNA Molecules for Use in Diagnostic Assays</title>
      <link>https://paperswithcode.com/paper/transfer-learning-bayesian-optimization-to</link>
      <description><![CDATA[With the rise in engineered biomolecular devices, there is an increased need for tailor-made biological sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transfer-learning-bayesian-optimization-to</guid>
    </item>
    <item>
      <title>SongComposer: A Large Language Model for Lyric and Melody Composition in Song Generation</title>
      <link>https://paperswithcode.com/paper/songcomposer-a-large-language-model-for-lyric</link>
      <description><![CDATA[We present SongComposer, an innovative LLM designed for song composition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/songcomposer-a-large-language-model-for-lyric</guid>
    </item>
    <item>
      <title>Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis</title>
      <link>https://paperswithcode.com/paper/learning-dynamic-tetrahedra-for-high-quality</link>
      <description><![CDATA[Recent works in implicit representations, such as Neural Radiance Fields (NeRF), have advanced the generation of realistic and animatable head avatars from video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-dynamic-tetrahedra-for-high-quality</guid>
    </item>
    <item>
      <title>Diffusion Model-Based Image Editing: A Survey</title>
      <link>https://paperswithcode.com/paper/diffusion-model-based-image-editing-a-survey</link>
      <description><![CDATA[In this survey, we provide an exhaustive overview of existing methods using diffusion models for image editing, covering both theoretical and practical aspects in the field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-model-based-image-editing-a-survey</guid>
    </item>
    <item>
      <title>Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models</title>
      <link>https://paperswithcode.com/paper/sora-a-review-on-background-technology</link>
      <description><![CDATA[Sora is a text-to-video generative AI model, released by OpenAI in February 2024.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sora-a-review-on-background-technology</guid>
    </item>
  </channel>
</rss>
