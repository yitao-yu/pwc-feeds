<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 27 Aug 2023 09:10:01 +0000</lastBuildDate>
    <item>
      <title>BridgeData V2: A Dataset for Robot Learning at Scale</title>
      <link>https://paperswithcode.com/paper/bridgedata-v2-a-dataset-for-robot-learning-at</link>
      <description><![CDATA[By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridgedata-v2-a-dataset-for-robot-learning-at</guid>
    </item>
    <item>
      <title>Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]</title>
      <link>https://paperswithcode.com/paper/unified-data-management-and-comprehensive</link>
      <description><![CDATA[The field of urban spatial-temporal prediction is advancing rapidly with the development of deep learning techniques and the availability of large-scale datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-data-management-and-comprehensive</guid>
    </item>
    <item>
      <title>Fast Adversarial Training with Smooth Convergence</title>
      <link>https://paperswithcode.com/paper/fast-adversarial-training-with-smooth</link>
      <description><![CDATA[To address this, we analyze the training process of prior FAT work and observe that catastrophic overfitting is accompanied by the appearance of loss convergence outliers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-adversarial-training-with-smooth</guid>
    </item>
    <item>
      <title>Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?</title>
      <link>https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</link>
      <description><![CDATA[The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</guid>
    </item>
    <item>
      <title>A Small and Fast BERT for Chinese Medical Punctuation Restoration</title>
      <link>https://paperswithcode.com/paper/a-small-and-fast-bert-for-chinese-medical</link>
      <description><![CDATA[In clinical dictation, utterances after automatic speech recognition (ASR) without explicit punctuation marks may lead to the misunderstanding of dictated reports.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-small-and-fast-bert-for-chinese-medical</guid>
    </item>
    <item>
      <title>Masked Autoencoders are Efficient Class Incremental Learners</title>
      <link>https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</link>
      <description><![CDATA[Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</guid>
    </item>
    <item>
      <title>NOVA: NOvel View Augmentation for Neural Composition of Dynamic Objects</title>
      <link>https://paperswithcode.com/paper/nova-novel-view-augmentation-for-neural</link>
      <description><![CDATA[We propose a novel-view augmentation (NOVA) strategy to train NeRFs for photo-realistic 3D composition of dynamic objects in a static scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nova-novel-view-augmentation-for-neural</guid>
    </item>
    <item>
      <title>HuBo-VLM: Unified Vision-Language Model designed for HUman roBOt interaction tasks</title>
      <link>https://paperswithcode.com/paper/hubo-vlm-unified-vision-language-model</link>
      <description><![CDATA[Human robot interaction is an exciting task, which aimed to guide robots following instructions from human.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hubo-vlm-unified-vision-language-model</guid>
    </item>
    <item>
      <title>On Popularity Bias of Multimodal-aware Recommender Systems: a Modalities-driven Analysis</title>
      <link>https://paperswithcode.com/paper/on-popularity-bias-of-multimodal-aware</link>
      <description><![CDATA[Multimodal-aware recommender systems (MRSs) exploit multimodal content (e. g., product images or descriptions) as items' side information to improve recommendation accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-popularity-bias-of-multimodal-aware</guid>
    </item>
    <item>
      <title>Single-shot Bayesian approximation for neural networks</title>
      <link>https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</link>
      <description><![CDATA[We demonstrate that our single-shot MC dropout approximation resembles the point estimate and the uncertainty estimate of the predictive distribution that is achieved with an MC approach, while being fast enough for real-time deployments of BNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</guid>
    </item>
    <item>
      <title>Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints</title>
      <link>https://paperswithcode.com/paper/master-slave-deep-architecture-for-top-k</link>
      <description><![CDATA[We propose a novel master-slave architecture to solve the top-$K$ combinatorial multi-armed bandits problem with non-linear bandit feedback and diversity constraints, which, to the best of our knowledge, is the first combinatorial bandits setting considering diversity constraints under bandit feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/master-slave-deep-architecture-for-top-k</guid>
    </item>
    <item>
      <title>NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes</title>
      <link>https://paperswithcode.com/paper/neo-360-neural-fields-for-sparse-view</link>
      <description><![CDATA[NeO 360's representation allows us to learn from a large collection of unbounded 3D scenes while offering generalizability to new views and novel scenes from as few as a single image during inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neo-360-neural-fields-for-sparse-view</guid>
    </item>
    <item>
      <title>Mutual-Guided Dynamic Network for Image Fusion</title>
      <link>https://paperswithcode.com/paper/mutual-guided-dynamic-network-for-image</link>
      <description><![CDATA[Image fusion aims to generate a high-quality image from multiple images captured under varying conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mutual-guided-dynamic-network-for-image</guid>
    </item>
    <item>
      <title>Towards Realistic Zero-Shot Classification via Self Structural Semantic Alignment</title>
      <link>https://paperswithcode.com/paper/towards-realistic-zero-shot-classification</link>
      <description><![CDATA[To address this challenge, we propose the Self Structural Semantic Alignment (S^3A) framework, which extracts the structural semantic information from unlabeled data while simultaneously self-learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-realistic-zero-shot-classification</guid>
    </item>
    <item>
      <title>Code Llama: Open Foundation Models for Code</title>
      <link>https://paperswithcode.com/paper/code-llama-open-foundation-models-for-code</link>
      <description><![CDATA[We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/code-llama-open-foundation-models-for-code</guid>
    </item>
    <item>
      <title>Learning Heavily-Degraded Prior for Underwater Object Detection</title>
      <link>https://paperswithcode.com/paper/learning-heavily-degraded-prior-for</link>
      <description><![CDATA[Therefore, we propose a residual feature transference module (RFTM) to learn a mapping between deep representations of the heavily degraded patches of DFUI- and underwater- images, and make the mapping as a heavily degraded prior (HDP) for underwater detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-heavily-degraded-prior-for</guid>
    </item>
    <item>
      <title>HR-Pro: Point-supervised Temporal Action Localization via Hierarchical Reliability Propagation</title>
      <link>https://paperswithcode.com/paper/hr-pro-point-supervised-temporal-action</link>
      <description><![CDATA[For snippet-level learning, we introduce an online-updated memory to store reliable snippet prototypes for each class.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hr-pro-point-supervised-temporal-action</guid>
    </item>
    <item>
      <title>Attention-Based Acoustic Feature Fusion Network for Depression Detection</title>
      <link>https://paperswithcode.com/paper/attention-based-acoustic-feature-fusion</link>
      <description><![CDATA[To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-based-acoustic-feature-fusion</guid>
    </item>
    <item>
      <title>FastSurfer-HypVINN: Automated sub-segmentation of the hypothalamus and adjacent structures on high-resolutional brain MRI</title>
      <link>https://paperswithcode.com/paper/fastsurfer-hypvinn-automated-sub-segmentation</link>
      <description><![CDATA[The hypothalamus plays a crucial role in the regulation of a broad range of physiological, behavioural, and cognitive functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fastsurfer-hypvinn-automated-sub-segmentation</guid>
    </item>
    <item>
      <title>Ground-to-Aerial Person Search: Benchmark Dataset and Approach</title>
      <link>https://paperswithcode.com/paper/ground-to-aerial-person-search-benchmark</link>
      <description><![CDATA[In this work, we construct a large-scale dataset for Ground-to-Aerial Person Search, named G2APS, which contains 31, 770 images of 260, 559 annotated bounding boxes for 2, 644 identities appearing in both of the UAVs and ground surveillance cameras.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ground-to-aerial-person-search-benchmark</guid>
    </item>
    <item>
      <title>Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</link>
      <description><![CDATA[The challenges of this task lie in the complexity of the scenes, the unique features of anime style, and the lack of high-quality datasets to bridge the domain gap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</guid>
    </item>
    <item>
      <title>PoseSync: Robust pose based video synchronization</title>
      <link>https://paperswithcode.com/paper/posesync-robust-pose-based-video</link>
      <description><![CDATA[Pose based video sychronization can have applications in multiple domains such as gameplay performance evaluation, choreography or guiding athletes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posesync-robust-pose-based-video</guid>
    </item>
    <item>
      <title>LISTER: Neighbor Decoding for Length-Insensitive Scene Text Recognition</title>
      <link>https://paperswithcode.com/paper/lister-neighbor-decoding-for-length</link>
      <description><![CDATA[The diversity in length constitutes a significant characteristic of text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lister-neighbor-decoding-for-length</guid>
    </item>
    <item>
      <title>Less is More: Towards Efficient Few-shot 3D Semantic Segmentation via Training-free Networks</title>
      <link>https://paperswithcode.com/paper/less-is-more-towards-efficient-few-shot-3d</link>
      <description><![CDATA[However, the prior pre-training stage not only introduces excessive time overhead, but also incurs a significant domain gap on `unseen' classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-is-more-towards-efficient-few-shot-3d</guid>
    </item>
    <item>
      <title>CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias</title>
      <link>https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</link>
      <description><![CDATA[To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</guid>
    </item>
    <item>
      <title>American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers</title>
      <link>https://paperswithcode.com/paper/american-stories-a-large-scale-structured</link>
      <description><![CDATA[The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/american-stories-a-large-scale-structured</guid>
    </item>
    <item>
      <title>Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods</title>
      <link>https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</link>
      <description><![CDATA[We introduce an open-source GitHub repository containing comprehensive benchmarks for a wide range of machine scheduling problems, including Job Shop Scheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling (FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent Setup Times (FJSP-SDST), and the online FJSP (with online job arrivals).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</guid>
    </item>
    <item>
      <title>Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis</title>
      <link>https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</link>
      <description><![CDATA[The model pretrained on large-scale rs-fMRI data has been released to the public.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</guid>
    </item>
    <item>
      <title>REB: Reducing Biases in Representation for Industrial Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/reb-reducing-biases-in-representation-for</link>
      <description><![CDATA[Additionally, we propose a local density KNN (LDKNN) to reduce the local density bias and obtain effective anomaly detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reb-reducing-biases-in-representation-for</guid>
    </item>
    <item>
      <title>Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers</title>
      <link>https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</link>
      <description><![CDATA[Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</guid>
    </item>
    <item>
      <title>Perspective-aware Convolution for Monocular 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</link>
      <description><![CDATA[Monocular 3D object detection is a crucial and challenging task for autonomous driving vehicle, while it uses only a single camera image to infer 3D objects in the scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</guid>
    </item>
    <item>
      <title>Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines</title>
      <link>https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</link>
      <description><![CDATA[This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</guid>
    </item>
    <item>
      <title>Acquiring Qualitative Explainable Graphs for Automated Driving Scene Interpretation</title>
      <link>https://paperswithcode.com/paper/acquiring-qualitative-explainable-graphs-for</link>
      <description><![CDATA[The future of automated driving (AD) is rooted in the development of robust, fair and explainable artificial intelligence methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/acquiring-qualitative-explainable-graphs-for</guid>
    </item>
    <item>
      <title>Robotic Scene Segmentation with Memory Network for Runtime Surgical Context Inference</title>
      <link>https://paperswithcode.com/paper/robotic-scene-segmentation-with-memory</link>
      <description><![CDATA[However, runtime context inference is challenging since it requires timely and accurate detection of the interactions among the tools and objects in the surgical scene based on the segmentation of video data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robotic-scene-segmentation-with-memory</guid>
    </item>
    <item>
      <title>Implicit Obstacle Map-driven Indoor Navigation Model for Robust Obstacle Avoidance</title>
      <link>https://paperswithcode.com/paper/implicit-obstacle-map-driven-indoor</link>
      <description><![CDATA[Robust obstacle avoidance is one of the critical steps for successful goal-driven indoor navigation tasks. Due to the obstacle missing in the visual image and the possible missed detection issue, visual image-based obstacle avoidance techniques still suffer from unsatisfactory robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implicit-obstacle-map-driven-indoor</guid>
    </item>
    <item>
      <title>Grounded Entity-Landmark Adaptive Pre-training for Vision-and-Language Navigation</title>
      <link>https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</link>
      <description><![CDATA[To address this problem, we propose a novel Grounded Entity-Landmark Adaptive (GELA) pre-training paradigm for VLN tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</guid>
    </item>
    <item>
      <title>Laying foundations to quantify the "Effort of Reproducibility"</title>
      <link>https://paperswithcode.com/paper/laying-foundations-to-quantify-the-effort-of</link>
      <description><![CDATA[Why are some research studies easy to reproduce while others are difficult?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/laying-foundations-to-quantify-the-effort-of</guid>
    </item>
    <item>
      <title>Motion In-Betweening with Phase Manifolds</title>
      <link>https://paperswithcode.com/paper/motion-in-betweening-with-phase-manifolds</link>
      <description><![CDATA[This paper introduces a novel data-driven motion in-betweening system to reach target poses of characters by making use of phases variables learned by a Periodic Autoencoder.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motion-in-betweening-with-phase-manifolds</guid>
    </item>
    <item>
      <title>DD-GCN: Directed Diffusion Graph Convolutional Network for Skeleton-based Human Action Recognition</title>
      <link>https://paperswithcode.com/paper/dd-gcn-directed-diffusion-graph-convolutional</link>
      <description><![CDATA[Graph Convolutional Networks (GCNs) have been widely used in skeleton-based human action recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dd-gcn-directed-diffusion-graph-convolutional</guid>
    </item>
    <item>
      <title>Dense Text-to-Image Generation with Attention Modulation</title>
      <link>https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</link>
      <description><![CDATA[To address this, we propose DenseDiffusion, a training-free method that adapts a pre-trained text-to-image model to handle such dense captions while offering control over the scene layout.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</guid>
    </item>
    <item>
      <title>Improving Translation Faithfulness of Large Language Models via Augmenting Instructions</title>
      <link>https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</link>
      <description><![CDATA[The experimental results demonstrate significant improvements in translation performance with SWIE based on BLOOMZ-3b, particularly in zero-shot and long text translations due to reduced instruction forgetting risk.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</guid>
    </item>
    <item>
      <title>kTrans: Knowledge-Aware Transformer for Binary Code Embedding</title>
      <link>https://paperswithcode.com/paper/ktrans-knowledge-aware-transformer-for-binary</link>
      <description><![CDATA[By feeding explicit knowledge as additional inputs to the Transformer, and fusing implicit knowledge with a novel pre-training task, kTrans provides a new perspective to incorporating domain knowledge into a Transformer framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ktrans-knowledge-aware-transformer-for-binary</guid>
    </item>
    <item>
      <title>Evolutionary Dynamic Optimization Laboratory: A MATLAB Optimization Platform for Education and Experimentation in Dynamic Environments</title>
      <link>https://paperswithcode.com/paper/evolutionary-dynamic-optimization-laboratory</link>
      <description><![CDATA[In this paper, to assist researchers in performing experiments and comparing their algorithms against several EDOAs, we develop an open-source MATLAB platform for EDOAs, called Evolutionary Dynamic Optimization LABoratory (EDOLAB).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evolutionary-dynamic-optimization-laboratory</guid>
    </item>
    <item>
      <title>Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities</title>
      <link>https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</link>
      <description><![CDATA[We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</guid>
    </item>
    <item>
      <title>Large Language Models Vote: Prompting for Rare Disease Identification</title>
      <link>https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</link>
      <description><![CDATA[The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</guid>
    </item>
    <item>
      <title>Match-And-Deform: Time Series Domain Adaptation through Optimal Transport and Temporal Alignment</title>
      <link>https://paperswithcode.com/paper/match-and-deform-time-series-domain</link>
      <description><![CDATA[While large volumes of unlabeled data are usually available, associated labels are often scarce.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/match-and-deform-time-series-domain</guid>
    </item>
    <item>
      <title>StreamMapNet: Streaming Mapping Network for Vectorized Online HD Map Construction</title>
      <link>https://paperswithcode.com/paper/streammapnet-streaming-mapping-network-for</link>
      <description><![CDATA[High-Definition (HD) maps are essential for the safety of autonomous driving systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streammapnet-streaming-mapping-network-for</guid>
    </item>
    <item>
      <title>Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning</title>
      <link>https://paperswithcode.com/paper/diffusion-language-models-can-perform-many</link>
      <description><![CDATA[We then reprogram pretrained masked language models into diffusion language models via diffusive adaptation, wherein task-specific finetuning and instruction finetuning are explored to unlock their versatility in solving general language tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-language-models-can-perform-many</guid>
    </item>
    <item>
      <title>Prompt2Model: Generating Deployable Models from Natural Language Instructions</title>
      <link>https://paperswithcode.com/paper/prompt2model-generating-deployable-models</link>
      <description><![CDATA[In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt2model-generating-deployable-models</guid>
    </item>
    <item>
      <title>With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning</title>
      <link>https://paperswithcode.com/paper/with-a-little-help-from-your-own-past</link>
      <description><![CDATA[Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/with-a-little-help-from-your-own-past</guid>
    </item>
  </channel>
</rss>
