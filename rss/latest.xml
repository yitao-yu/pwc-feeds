<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 13 Jul 2024 21:08:00 +0000</lastBuildDate>
    <item>
      <title>Transductive Active Learning with Application to Safe Bayesian Optimization</title>
      <link>https://paperswithcode.com/paper/transductive-active-learning-with-application</link>
      <description><![CDATA[We analyze Safe BO under the lens of a generalization of active learning with concrete prediction targets where sampling is restricted to an accessible region of the domain, while prediction targets may lie outside this region.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transductive-active-learning-with-application</guid>
    </item>
    <item>
      <title>AutoBencher: Creating Salient, Novel, Difficult Datasets for Language Models</title>
      <link>https://paperswithcode.com/paper/autobencher-creating-salient-novel-difficult</link>
      <description><![CDATA[In this paper, we present three desiderata for a good benchmark for language models: (i) salience (e. g., knowledge about World War II is more salient than a random day in history), (ii) novelty (i. e., the benchmark reveals new trends in model rankings not shown by previous benchmarks), and (iii) difficulty (i. e., the benchmark should be difficult for existing models, leaving headroom for future improvement).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autobencher-creating-salient-novel-difficult</guid>
    </item>
    <item>
      <title>Multimodal contrastive learning for spatial gene expression prediction using histology images</title>
      <link>https://paperswithcode.com/paper/multimodal-contrastive-learning-for-spatial</link>
      <description><![CDATA[In this paper, we propose \textbf{mclSTExp}, a multimodal contrastive learning with Transformer and Densenet-121 encoder for Spatial Transcriptomics Expression prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-contrastive-learning-for-spatial</guid>
    </item>
    <item>
      <title>DSCENet: Dynamic Screening and Clinical-Enhanced Multimodal Fusion for MPNs Subtype Classification</title>
      <link>https://paperswithcode.com/paper/dscenet-dynamic-screening-and-clinical</link>
      <description><![CDATA[(1) A dynamic screening module is proposed to flexibly adapt the feature learning of local patches, reducing the interference of irrelevant features and enhancing their diagnostic representativeness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dscenet-dynamic-screening-and-clinical</guid>
    </item>
    <item>
      <title>RTMW: Real-Time Multi-Person 2D and 3D Whole-body Pose Estimation</title>
      <link>https://paperswithcode.com/paper/rtmw-real-time-multi-person-2d-and-3d-whole</link>
      <description><![CDATA[In this work, we present RTMW (Real-Time Multi-person Whole-body pose estimation models), a series of high-performance models for 2D/3D whole-body pose estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rtmw-real-time-multi-person-2d-and-3d-whole</guid>
    </item>
    <item>
      <title>Gradient Boosting Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/gradient-boosting-reinforcement-learning</link>
      <description><![CDATA[GBRL expands the toolkit for RL practitioners, demonstrating the viability and promise of GBT within the RL paradigm, particularly in domains characterized by structured or categorical features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gradient-boosting-reinforcement-learning</guid>
    </item>
    <item>
      <title>LLMs' morphological analyses of complex FST-generated Finnish words</title>
      <link>https://paperswithcode.com/paper/llms-morphological-analyses-of-complex-fst</link>
      <description><![CDATA[Rule-based language processing systems have been overshadowed by neural systems in terms of utility, but it remains unclear whether neural NLP systems, in practice, learn the grammar rules that humans use.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llms-morphological-analyses-of-complex-fst</guid>
    </item>
    <item>
      <title>Chromosomal Structural Abnormality Diagnosis by Homologous Similarity</title>
      <link>https://paperswithcode.com/paper/chromosomal-structural-abnormality-diagnosis</link>
      <description><![CDATA[Pathogenic chromosome abnormalities are very common among the general population.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chromosomal-structural-abnormality-diagnosis</guid>
    </item>
    <item>
      <title>Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation</title>
      <link>https://paperswithcode.com/paper/natural-language-is-not-enough-benchmarking</link>
      <description><![CDATA[Natural language interfaces have exhibited considerable potential in the automation of Verilog generation derived from high-level specifications through the utilization of large language models, garnering significant attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/natural-language-is-not-enough-benchmarking</guid>
    </item>
    <item>
      <title>Beyond Benchmarks: Evaluating Embedding Model Similarity for Retrieval Augmented Generation Systems</title>
      <link>https://paperswithcode.com/paper/beyond-benchmarks-evaluating-embedding-model</link>
      <description><![CDATA[Through our experiments we identify clusters of models corresponding to model families, but interestingly, also some inter-family clusters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-benchmarks-evaluating-embedding-model</guid>
    </item>
    <item>
      <title>Adaptive Compressed Sensing with Diffusion-Based Posterior Sampling</title>
      <link>https://paperswithcode.com/paper/adaptive-compressed-sensing-with-diffusion</link>
      <description><![CDATA[Our experiments demonstrate the effectiveness of AdaSense in reconstructing facial images from a small number of measurements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-compressed-sensing-with-diffusion</guid>
    </item>
    <item>
      <title>WayveScenes101: A Dataset and Benchmark for Novel View Synthesis in Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/wayvescenes101-a-dataset-and-benchmark-for</link>
      <description><![CDATA[We present WayveScenes101, a dataset designed to help the community advance the state of the art in novel view synthesis that focuses on challenging driving scenes containing many dynamic and deformable elements with changing geometry and texture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wayvescenes101-a-dataset-and-benchmark-for</guid>
    </item>
    <item>
      <title>Hardware Neural Control of CartPole and F1TENTH Race Car</title>
      <link>https://paperswithcode.com/paper/hardware-neural-control-of-cartpole-and</link>
      <description><![CDATA[We demonstrate kHz control rates for a physical cartpole and offloading control to the FPGA hardware on the F1TENTH car.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hardware-neural-control-of-cartpole-and</guid>
    </item>
    <item>
      <title>Video Diffusion Alignment via Reward Gradients</title>
      <link>https://paperswithcode.com/paper/video-diffusion-alignment-via-reward</link>
      <description><![CDATA[We show that backpropagating gradients from these reward models to a video diffusion model can allow for compute and sample efficient alignment of the video diffusion model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-diffusion-alignment-via-reward</guid>
    </item>
    <item>
      <title>Approaching Outside: Scaling Unsupervised 3D Object Detection from 2D Scene</title>
      <link>https://paperswithcode.com/paper/approaching-outside-scaling-unsupervised-3d</link>
      <description><![CDATA[In this paper, we are among the early attempts to integrate LiDAR data with 2D images for unsupervised 3D detection and introduce a new method, dubbed LiDAR-2D Self-paced Learning (LiSe).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/approaching-outside-scaling-unsupervised-3d</guid>
    </item>
    <item>
      <title>VideoMamba: Spatio-Temporal Selective State Space Model</title>
      <link>https://paperswithcode.com/paper/videomamba-spatio-temporal-selective-state</link>
      <description><![CDATA[We introduce VideoMamba, a novel adaptation of the pure Mamba architecture, specifically designed for video recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videomamba-spatio-temporal-selective-state</guid>
    </item>
    <item>
      <title>Adaptive Parametric Activation</title>
      <link>https://paperswithcode.com/paper/adaptive-parametric-activation</link>
      <description><![CDATA[In this work, we delve deeper in this phenomenon by performing a comprehensive statistical analysis in the classification and intermediate layers of both balanced and imbalanced networks and we empirically show that aligning the activation function with the data distribution, enhances the performance in both balanced and imbalanced tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-parametric-activation</guid>
    </item>
    <item>
      <title>Exemplar-free Continual Representation Learning via Learnable Drift Compensation</title>
      <link>https://paperswithcode.com/paper/exemplar-free-continual-representation</link>
      <description><![CDATA[Prototype-based approaches, when continually updated, face the critical issue of semantic drift due to which the old class prototypes drift to different positions in the new feature space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exemplar-free-continual-representation</guid>
    </item>
    <item>
      <title>Towards stable training of parallel continual learning</title>
      <link>https://paperswithcode.com/paper/towards-stable-training-of-parallel-continual</link>
      <description><![CDATA[Parallel Continual Learning (PCL) tasks investigate the training methods for continual learning with multi-source input, where data from different tasks are learned as they arrive.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-stable-training-of-parallel-continual</guid>
    </item>
    <item>
      <title>Generalization Error Matters in Decentralized Learning Under Byzantine Attacks</title>
      <link>https://paperswithcode.com/paper/generalization-error-matters-in-decentralized</link>
      <description><![CDATA[Recently, decentralized learning has emerged as a popular peer-to-peer signal and information processing paradigm that enables model training across geographically distributed agents in a scalable manner, without the presence of any central server.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalization-error-matters-in-decentralized</guid>
    </item>
    <item>
      <title>SCPNet: Unsupervised Cross-modal Homography Estimation via Intra-modal Self-supervised Learning</title>
      <link>https://paperswithcode.com/paper/scpnet-unsupervised-cross-modal-homography</link>
      <description><![CDATA[The correlation-based homography estimation network and the consistent feature map projection are combined to form the learnable architecture of SCPNet, boosting the unsupervised learning framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scpnet-unsupervised-cross-modal-homography</guid>
    </item>
    <item>
      <title>HDT: Hierarchical Document Transformer</title>
      <link>https://paperswithcode.com/paper/hdt-hierarchical-document-transformer</link>
      <description><![CDATA[We address the technical challenge of implementing HDT's sample-dependent hierarchical attention pattern by developing a novel sparse attention kernel that considers the hierarchical structure of documents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hdt-hierarchical-document-transformer</guid>
    </item>
    <item>
      <title>SEED-Story: Multimodal Long Story Generation with Large Language Model</title>
      <link>https://paperswithcode.com/paper/seed-story-multimodal-long-story-generation</link>
      <description><![CDATA[We further propose multimodal attention sink mechanism to enable the generation of stories with up to 25 sequences (only 10 for training) in a highly efficient autoregressive manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seed-story-multimodal-long-story-generation</guid>
    </item>
    <item>
      <title>Transformer Circuit Faithfulness Metrics are not Robust</title>
      <link>https://paperswithcode.com/paper/transformer-circuit-faithfulness-metrics-are</link>
      <description><![CDATA[Prior work has attempted to measure circuit 'faithfulness' -- the degree to which the circuit replicates the performance of the full model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-circuit-faithfulness-metrics-are</guid>
    </item>
    <item>
      <title>Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter</title>
      <link>https://paperswithcode.com/paper/urban-waterlogging-detection-a-challenging</link>
      <description><![CDATA[Urban waterlogging poses a major risk to public safety and infrastructure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/urban-waterlogging-detection-a-challenging</guid>
    </item>
    <item>
      <title>DALL-M: Context-Aware Clinical Data Augmentation with LLMs</title>
      <link>https://paperswithcode.com/paper/dall-m-context-aware-clinical-data</link>
      <description><![CDATA[We present a novel technique to enhance the clinical context through augmentation techniques with clinical tabular data, thereby improving its applicability and reliability in AI medical diagnostics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dall-m-context-aware-clinical-data</guid>
    </item>
    <item>
      <title>The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective</title>
      <link>https://paperswithcode.com/paper/the-synergy-between-data-and-multi-modal</link>
      <description><![CDATA[As LLMs and MLLMs rely on vast amounts of model parameters and data to achieve emergent capabilities, the importance of data is receiving increasingly widespread attention and recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-synergy-between-data-and-multi-modal</guid>
    </item>
    <item>
      <title>MAVIS: Mathematical Visual Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/mavis-mathematical-visual-instruction-tuning</link>
      <description><![CDATA[We identify three key areas within MLLMs that need to be improved: visual encoding of math diagrams, diagram-language alignment, and mathematical reasoning skills.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mavis-mathematical-visual-instruction-tuning</guid>
    </item>
    <item>
      <title>AddressCLIP: Empowering Vision-Language Models for City-wide Image Address Localization</title>
      <link>https://paperswithcode.com/paper/addressclip-empowering-vision-language-models</link>
      <description><![CDATA[In this study, we introduce a new problem raised by social media and photojournalism, named Image Address Localization (IAL), which aims to predict the readable textual address where an image was taken.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/addressclip-empowering-vision-language-models</guid>
    </item>
    <item>
      <title>Histopathological Image Classification with Cell Morphology Aware Deep Neural Networks</title>
      <link>https://paperswithcode.com/paper/histopathological-image-classification-with</link>
      <description><![CDATA[To deal with this problem, we propose a novel DeepCMorph model pre-trained to learn cell morphology and identify a large number of different cancer types.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/histopathological-image-classification-with</guid>
    </item>
    <item>
      <title>SciQu: Accelerating Materials Properties Prediction with Automated Literature Mining for Self-Driving Laboratories</title>
      <link>https://paperswithcode.com/paper/sciqu-accelerating-materials-properties</link>
      <description><![CDATA[As a proof of concept, we predicted the refractive index of materials using data extracted from numerous research articles with SciQu, considering input descriptors such as space group, volume, and bandgap with Root Mean Square Error (RMSE) 0. 068 and R2 0. 94.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sciqu-accelerating-materials-properties</guid>
    </item>
    <item>
      <title>Knowledge distillation to effectively attain both region-of-interest and global semantics from an image where multiple objects appear</title>
      <link>https://paperswithcode.com/paper/knowledge-distillation-to-effectively-attain</link>
      <description><![CDATA[The images in which only the ROI was preserved were fed as inputs to fine-tune various off-the-shelf models that encoded their own inductive biases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/knowledge-distillation-to-effectively-attain</guid>
    </item>
    <item>
      <title>BiasPruner: Debiased Continual Learning for Medical Image Classification</title>
      <link>https://paperswithcode.com/paper/biaspruner-debiased-continual-learning-for</link>
      <description><![CDATA[Utilizing a new bias score that measures the contribution of each unit in the network to learning spurious features, BiasPruner prunes those units with the highest bias scores to form a debiased subnetwork preserved for a given task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biaspruner-debiased-continual-learning-for</guid>
    </item>
    <item>
      <title>Enhancing Thermal Infrared Tracking with Natural Language Modeling and Coordinate Sequence Generation</title>
      <link>https://paperswithcode.com/paper/enhancing-thermal-infrared-tracking-with</link>
      <description><![CDATA[In this paper, to address these issues, we apply natural language modeling to TIR tracking and propose a novel model called NLMTrack, which enhances the utilization of coordinate and temporal information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-thermal-infrared-tracking-with</guid>
    </item>
    <item>
      <title>stEnTrans: Transformer-based deep learning for spatial transcriptomics enhancement</title>
      <link>https://paperswithcode.com/paper/stentrans-transformer-based-deep-learning-for</link>
      <description><![CDATA[The spatial location of cells within tissues and organs is crucial for the manifestation of their specific functions. Spatial transcriptomics technology enables comprehensive measurement of the gene expression patterns in tissues while retaining spatial information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stentrans-transformer-based-deep-learning-for</guid>
    </item>
    <item>
      <title>eyeballvul: a future-proof benchmark for vulnerability detection in the wild</title>
      <link>https://paperswithcode.com/paper/eyeballvul-a-future-proof-benchmark-for</link>
      <description><![CDATA[The benchmark consists of a list of revisions in different repositories, each associated with the list of known vulnerabilities present at that revision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eyeballvul-a-future-proof-benchmark-for</guid>
    </item>
    <item>
      <title>Latent Spaces Enable Transformer-Based Dose Prediction in Complex Radiotherapy Plans</title>
      <link>https://paperswithcode.com/paper/latent-spaces-enable-transformer-based-dose</link>
      <description><![CDATA[Evidence is accumulating in favour of using stereotactic ablative body radiotherapy (SABR) to treat multiple cancer lesions in the lung.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-spaces-enable-transformer-based-dose</guid>
    </item>
    <item>
      <title>$β$-DPO: Direct Preference Optimization with Dynamic $β$</title>
      <link>https://paperswithcode.com/paper/b-dpo-direct-preference-optimization-with</link>
      <description><![CDATA[Direct Preference Optimization (DPO) has emerged as a compelling approach for training Large Language Models (LLMs) to adhere to human preferences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/b-dpo-direct-preference-optimization-with</guid>
    </item>
    <item>
      <title>Subgroup-Specific Risk-Controlled Dose Estimation in Radiotherapy</title>
      <link>https://paperswithcode.com/paper/subgroup-specific-risk-controlled-dose</link>
      <description><![CDATA[We evaluate our algorithm on real clinical planing volumes from five different anatomical regions and show that our novel subgroup RCPS (SG-RCPS) algorithm leads to prediction intervals that jointly control the risk for multiple subgroups.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/subgroup-specific-risk-controlled-dose</guid>
    </item>
    <item>
      <title>Enriching Information and Preserving Semantic Consistency in Expanding Curvilinear Object Segmentation Datasets</title>
      <link>https://paperswithcode.com/paper/enriching-information-and-preserving-semantic</link>
      <description><![CDATA[To address these challenges, this paper introduces a novel approach for expanding curvilinear object segmentation datasets, focusing on enhancing the informativeness of generated data and the consistency between semantic maps and generated images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enriching-information-and-preserving-semantic</guid>
    </item>
    <item>
      <title>MeshAvatar: Learning High-quality Triangular Human Avatars from Multi-view Videos</title>
      <link>https://paperswithcode.com/paper/meshavatar-learning-high-quality-triangular</link>
      <description><![CDATA[We present a novel pipeline for learning high-quality triangular human avatars from multi-view videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meshavatar-learning-high-quality-triangular</guid>
    </item>
    <item>
      <title>GTA: A Benchmark for General Tool Agents</title>
      <link>https://paperswithcode.com/paper/gta-a-benchmark-for-general-tool-agents</link>
      <description><![CDATA[This poses a challenge to LLMs' tool-use capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gta-a-benchmark-for-general-tool-agents</guid>
    </item>
    <item>
      <title>CAR-MFL: Cross-Modal Augmentation by Retrieval for Multimodal Federated Learning with Missing Modalities</title>
      <link>https://paperswithcode.com/paper/car-mfl-cross-modal-augmentation-by-retrieval</link>
      <description><![CDATA[Toward this, we propose a novel method for multimodal federated learning with missing modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/car-mfl-cross-modal-augmentation-by-retrieval</guid>
    </item>
    <item>
      <title>Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models</title>
      <link>https://paperswithcode.com/paper/establishing-rigorous-and-cost-effective</link>
      <description><![CDATA[We envision DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and transformative evaluation methodologies for AI models in clinical practice, offering a preclinical-like setting mirroring conventional medicine, and reshaping development paradigms in a cost-effective and fast-iterative manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/establishing-rigorous-and-cost-effective</guid>
    </item>
    <item>
      <title>Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates</title>
      <link>https://paperswithcode.com/paper/highway-networks-for-improved-surface</link>
      <description><![CDATA[Surface reconstruction from point clouds is a fundamental challenge in computer graphics and medical imaging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/highway-networks-for-improved-surface</guid>
    </item>
    <item>
      <title>Adversarial-MidiBERT: Symbolic Music Understanding Model Based on Unbias Pre-training and Mask Fine-tuning</title>
      <link>https://paperswithcode.com/paper/adversarial-midibert-symbolic-music</link>
      <description><![CDATA[Recently, pre-trained language models have been widely adopted in SMU because the symbolic music shares a huge similarity with natural language, and the pre-trained manner also helps make full use of limited music data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-midibert-symbolic-music</guid>
    </item>
    <item>
      <title>SRPose: Two-view Relative Pose Estimation with Sparse Keypoints</title>
      <link>https://paperswithcode.com/paper/srpose-two-view-relative-pose-estimation-with</link>
      <description><![CDATA[Two-view pose estimation is essential for map-free visual relocalization and object pose tracking tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/srpose-two-view-relative-pose-estimation-with</guid>
    </item>
    <item>
      <title>Improving Visual Place Recognition Based Robot Navigation Through Verification of Localization Estimates</title>
      <link>https://paperswithcode.com/paper/improving-visual-place-recognition-based</link>
      <description><![CDATA[Experiment 2 showed a decrease in aggregate mean along-track localization error from ~2. 0m to ~0. 5m, and an increase in the aggregate precision of localization attempts from ~97% to ~99%.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-visual-place-recognition-based</guid>
    </item>
    <item>
      <title>GraphMamba: An Efficient Graph Structure Learning Vision Mamba for Hyperspectral Image Classification</title>
      <link>https://paperswithcode.com/paper/graphmamba-an-efficient-graph-structure</link>
      <description><![CDATA[Efficient extraction of spectral sequences and geospatial information has always been a hot topic in hyperspectral image classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphmamba-an-efficient-graph-structure</guid>
    </item>
    <item>
      <title>DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception</title>
      <link>https://paperswithcode.com/paper/densefusion-1m-merging-vision-experts-for</link>
      <description><![CDATA[To facilitate the cutting-edge research of MLLMs on comprehensive vision perception, we thereby propose Perceptual Fusion, using a low-budget but highly effective caption engine for complete and accurate image descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/densefusion-1m-merging-vision-experts-for</guid>
    </item>
  </channel>
</rss>
