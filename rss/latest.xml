<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 28 May 2025 09:18:42 +0000</lastBuildDate>
    <item>
      <title>BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Behavioural Change</title>
      <link>https://paperswithcode.com/paper/bah-dataset-for-ambivalence-hesitancy</link>
      <description><![CDATA[This paper introduces a first Behavioural Ambivalence/Hesitancy (BAH) dataset collected for subject-based multimodal recognition of A/H in videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bah-dataset-for-ambivalence-hesitancy</guid>
    </item>
    <item>
      <title>FastCAV: Efficient Computation of Concept Activation Vectors for Explaining Deep Neural Networks</title>
      <link>https://paperswithcode.com/paper/fastcav-efficient-computation-of-concept</link>
      <description><![CDATA[To address this limitation, we introduce FastCAV, a novel approach that accelerates the extraction of CAVs by up to 63. 6x (on average 46. 4x).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fastcav-efficient-computation-of-concept</guid>
    </item>
    <item>
      <title>Daily-Omni: Towards Audio-Visual Reasoning with Temporal Alignment across Modalities</title>
      <link>https://paperswithcode.com/paper/daily-omni-towards-audio-visual-reasoning</link>
      <description><![CDATA[Recent Multimodal Large Language Models (MLLMs) achieve promising performance on visual and audio benchmarks independently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/daily-omni-towards-audio-visual-reasoning</guid>
    </item>
    <item>
      <title>XMolCap: Advancing Molecular Captioning through Multimodal Fusion and Explainable Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/xmolcap-advancing-molecular-captioning</link>
      <description><![CDATA[Large language models (LLMs) have significantly advanced computational biology by enabling the integration of molecular, protein, and natural language data to accelerate drug discovery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xmolcap-advancing-molecular-captioning</guid>
    </item>
    <item>
      <title>CLIMB: Class-imbalanced Learning Benchmark on Tabular Data</title>
      <link>https://paperswithcode.com/paper/climb-class-imbalanced-learning-benchmark-on</link>
      <description><![CDATA[Class-imbalanced learning (CIL) on tabular data is important in many real-world applications where the minority class holds the critical but rare outcomes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/climb-class-imbalanced-learning-benchmark-on</guid>
    </item>
    <item>
      <title>Semantic Correspondence: Unified Benchmarking and a Strong Baseline</title>
      <link>https://paperswithcode.com/paper/semantic-correspondence-unified-benchmarking</link>
      <description><![CDATA[We hope this survey serves as a comprehensive reference and consolidated baseline for future development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-correspondence-unified-benchmarking</guid>
    </item>
    <item>
      <title>PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation</title>
      <link>https://paperswithcode.com/paper/posebh-prototypical-multi-dataset-training</link>
      <description><![CDATA[First, we propose nonparametric keypoint prototypes that learn within a unified embedding space, enabling seamless integration across skeleton types.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posebh-prototypical-multi-dataset-training</guid>
    </item>
    <item>
      <title>Stochastic Forward-Forward Learning through Representational Dimensionality Compression</title>
      <link>https://paperswithcode.com/paper/stochastic-forward-forward-learning-through</link>
      <description><![CDATA[The Forward-Forward (FF) algorithm provides a bottom-up alternative to backpropagation (BP) for training neural networks, relying on a layer-wise "goodness" function to guide learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stochastic-forward-forward-learning-through</guid>
    </item>
    <item>
      <title>RealEngine: Simulating Autonomous Driving in Realistic Context</title>
      <link>https://paperswithcode.com/paper/realengine-simulating-autonomous-driving-in</link>
      <description><![CDATA[To bridge this gap, this paper introduces RealEngine, a novel driving simulation framework that holistically integrates 3D scene reconstruction and novel view synthesis techniques to achieve realistic and flexible closed-loop simulation in the driving context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/realengine-simulating-autonomous-driving-in</guid>
    </item>
    <item>
      <title>Perceptual Quality Assessment for Embodied AI</title>
      <link>https://paperswithcode.com/paper/perceptual-quality-assessment-for-embodied-ai</link>
      <description><![CDATA[Embodied AI has developed rapidly in recent years, but it is still mainly deployed in laboratories, with various distortions in the Real-world limiting its application.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perceptual-quality-assessment-for-embodied-ai</guid>
    </item>
    <item>
      <title>GCAL: Adapting Graph Models to Evolving Domain Shifts</title>
      <link>https://paperswithcode.com/paper/gcal-adapting-graph-models-to-evolving-domain</link>
      <description><![CDATA[This paper addresses the challenge of graph domain adaptation on evolving, multiple out-of-distribution (OOD) graphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gcal-adapting-graph-models-to-evolving-domain</guid>
    </item>
    <item>
      <title>Understanding Prompt Tuning and In-Context Learning via Meta-Learning</title>
      <link>https://paperswithcode.com/paper/understanding-prompt-tuning-and-in-context</link>
      <description><![CDATA[In this paper we discuss how optimal prompting can be understood through a Bayesian view, which also implies some fundamental limitations of prompting that can only be overcome by tuning weights.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-prompt-tuning-and-in-context</guid>
    </item>
    <item>
      <title>RE-TRIP : Reflectivity Instance Augmented Triangle Descriptor for 3D Place Recognition</title>
      <link>https://paperswithcode.com/paper/re-trip-reflectivity-instance-augmented</link>
      <description><![CDATA[In this paper, we propose a novel descriptor for 3D PR, named RE-TRIP (REflectivity-instance augmented TRIangle descriPtor).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/re-trip-reflectivity-instance-augmented</guid>
    </item>
    <item>
      <title>CausalDynamics: A large-scale benchmark for structural discovery of dynamical causal models</title>
      <link>https://paperswithcode.com/paper/causaldynamics-a-large-scale-benchmark-for</link>
      <description><![CDATA[Causal discovery for dynamical systems poses a major challenge in fields where active interventions are infeasible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causaldynamics-a-large-scale-benchmark-for</guid>
    </item>
    <item>
      <title>All You Need is "Leet": Evading Hate-speech Detection AI</title>
      <link>https://paperswithcode.com/paper/all-you-need-is-leet-evading-hate-speech</link>
      <description><![CDATA[Social media and online forums are increasingly becoming popular.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/all-you-need-is-leet-evading-hate-speech</guid>
    </item>
    <item>
      <title>SEED: Speaker Embedding Enhancement Diffusion Model</title>
      <link>https://paperswithcode.com/paper/seed-speaker-embedding-enhancement-diffusion</link>
      <description><![CDATA[For training, our approach progressively adds Gaussian noise to both clean and noisy speaker embeddings extracted from clean and noisy speech, respectively, via forward process of a diffusion model, and then reconstructs them to clean embeddings in the reverse process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seed-speaker-embedding-enhancement-diffusion</guid>
    </item>
    <item>
      <title>ChemMLLM: Chemical Multimodal Large Language Model</title>
      <link>https://paperswithcode.com/paper/chemmllm-chemical-multimodal-large-language</link>
      <description><![CDATA[To fill this gap, in this paper, we propose ChemMLLM, a unified chemical multimodal large language model for molecule understanding and generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chemmllm-chemical-multimodal-large-language</guid>
    </item>
    <item>
      <title>MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning</title>
      <link>https://paperswithcode.com/paper/maple-many-shot-adaptive-pseudo-labeling-for</link>
      <description><![CDATA[In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle diverse tasks by incorporating multiple input-output examples, known as demonstrations, into the input of LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maple-many-shot-adaptive-pseudo-labeling-for</guid>
    </item>
    <item>
      <title>How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance</title>
      <link>https://paperswithcode.com/paper/how-do-scaling-laws-apply-to-knowledge-graph</link>
      <description><![CDATA[Additionally, we inspect how the general score development of single models and families of models correlates to their size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-do-scaling-laws-apply-to-knowledge-graph</guid>
    </item>
    <item>
      <title>PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association</title>
      <link>https://paperswithcode.com/paper/paeff-precise-alignment-and-enhanced-gated</link>
      <description><![CDATA[We study the task of learning association between faces and voices, which is gaining interest in the multimodal community lately.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paeff-precise-alignment-and-enhanced-gated</guid>
    </item>
    <item>
      <title>O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering</title>
      <link>https://paperswithcode.com/paper/o-2-searcher-a-searching-based-agent-model</link>
      <description><![CDATA[Large Language Models (LLMs), despite their advancements, are fundamentally limited by their static parametric knowledge, hindering performance on tasks requiring open-domain up-to-date information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/o-2-searcher-a-searching-based-agent-model</guid>
    </item>
    <item>
      <title>A Japanese Language Model and Three New Evaluation Benchmarks for Pharmaceutical NLP</title>
      <link>https://paperswithcode.com/paper/a-japanese-language-model-and-three-new</link>
      <description><![CDATA[We present a Japanese domain-specific language model for the pharmaceutical field, developed through continual pretraining on 2 billion Japanese pharmaceutical tokens and 8 billion English biomedical tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-japanese-language-model-and-three-new</guid>
    </item>
    <item>
      <title>Dysfluent WFST: A Framework for Zero-Shot Speech Dysfluency Transcription and Detection</title>
      <link>https://paperswithcode.com/paper/dysfluent-wfst-a-framework-for-zero-shot</link>
      <description><![CDATA[Automatic detection of speech dysfluency aids speech-language pathologists in efficient transcription of disordered speech, enhancing diagnostics and treatment planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dysfluent-wfst-a-framework-for-zero-shot</guid>
    </item>
    <item>
      <title>EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance</title>
      <link>https://paperswithcode.com/paper/enstom-enhancing-dialogue-systems-with</link>
      <description><![CDATA[However, sLLMs often struggle to maintain topic consistency in task-oriented dialogue systems, which is critical for scenarios such as service chatbots.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enstom-enhancing-dialogue-systems-with</guid>
    </item>
    <item>
      <title>MPL: Multiple Programming Languages with Large Language Models for Information Extraction</title>
      <link>https://paperswithcode.com/paper/mpl-multiple-programming-languages-with-large</link>
      <description><![CDATA[In this research, we propose \textbf{M}ultiple \textbf{P}rogramming \textbf{L}anguages with large language models for information extraction (abbreviated as \textbf{MPL}), a novel framework that explores the potential of incorporating different PLs in the SFT phase.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mpl-multiple-programming-languages-with-large</guid>
    </item>
    <item>
      <title>HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation</title>
      <link>https://paperswithcode.com/paper/hygenar-an-llm-driven-hybrid-genetic</link>
      <description><![CDATA[In this paper, we aim to study and improve the ability of LLMs for few-shot grammar generation, where grammars are inferred from sets of a small number of positive and negative examples and generated in Backus-Naur Form.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hygenar-an-llm-driven-hybrid-genetic</guid>
    </item>
    <item>
      <title>EMULATE: A Multi-Agent Framework for Determining the Veracity of Atomic Claims by Emulating Human Actions</title>
      <link>https://paperswithcode.com/paper/emulate-a-multi-agent-framework-for</link>
      <description><![CDATA[Many approaches tackle this problem by first retrieving evidence by querying a search engine and then performing classification by providing the evidence set and atomic claim to a large language model, but this process deviates from what a human would do in order to perform the task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emulate-a-multi-agent-framework-for</guid>
    </item>
    <item>
      <title>Materials Generation in the Era of Artificial Intelligence: A Comprehensive Survey</title>
      <link>https://paperswithcode.com/paper/materials-generation-in-the-era-of-artificial</link>
      <description><![CDATA[Materials are the foundation of modern society, underpinning advancements in energy, electronics, healthcare, transportation, and infrastructure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/materials-generation-in-the-era-of-artificial</guid>
    </item>
    <item>
      <title>Ask, Retrieve, Summarize: A Modular Pipeline for Scientific Literature Summarization</title>
      <link>https://paperswithcode.com/paper/ask-retrieve-summarize-a-modular-pipeline-for</link>
      <description><![CDATA[The exponential growth of scientific publications has made it increasingly difficult for researchers to stay updated and synthesize knowledge effectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ask-retrieve-summarize-a-modular-pipeline-for</guid>
    </item>
    <item>
      <title>IFEval-Audio: Benchmarking Instruction-Following Capability in Audio-based Large Language Models</title>
      <link>https://paperswithcode.com/paper/ifeval-audio-benchmarking-instruction</link>
      <description><![CDATA[To bridge this gap, we introduce IFEval-Audio, a novel evaluation dataset designed to assess the ability to follow instructions in an audio LLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ifeval-audio-benchmarking-instruction</guid>
    </item>
    <item>
      <title>R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/r1-searcher-incentivizing-the-dynamic</link>
      <description><![CDATA[In this paper, we introduce R1-Searcher++, a novel framework designed to train LLMs to adaptively leverage both internal and external knowledge sources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r1-searcher-incentivizing-the-dynamic</guid>
    </item>
    <item>
      <title>AppealCase: A Dataset and Benchmark for Civil Case Appeal Scenarios</title>
      <link>https://paperswithcode.com/paper/appealcase-a-dataset-and-benchmark-for-civil</link>
      <description><![CDATA[Recent advances in LegalAI have primarily focused on individual case judgment analysis, often overlooking the critical appellate process within the judicial system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/appealcase-a-dataset-and-benchmark-for-civil</guid>
    </item>
    <item>
      <title>SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis</title>
      <link>https://paperswithcode.com/paper/simpledeepsearcher-deep-information-seeking</link>
      <description><![CDATA[Retrieval-augmented generation (RAG) systems have advanced large language models (LLMs) in complex deep search scenarios requiring multi-step reasoning and iterative information retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simpledeepsearcher-deep-information-seeking</guid>
    </item>
    <item>
      <title>CoNav: Collaborative Cross-Modal Reasoning for Embodied Navigation</title>
      <link>https://paperswithcode.com/paper/conav-collaborative-cross-modal-reasoning-for</link>
      <description><![CDATA[Embodied navigation demands comprehensive scene understanding and precise spatial reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conav-collaborative-cross-modal-reasoning-for</guid>
    </item>
    <item>
      <title>Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability</title>
      <link>https://paperswithcode.com/paper/accidental-misalignment-fine-tuning-language</link>
      <description><![CDATA[As large language models gain popularity, their vulnerability to adversarial attacks remains a primary concern.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accidental-misalignment-fine-tuning-language</guid>
    </item>
    <item>
      <title>A Generic Framework for Conformal Fairness</title>
      <link>https://paperswithcode.com/paper/a-generic-framework-for-conformal-fairness</link>
      <description><![CDATA[Conformal Prediction (CP) is a popular method for uncertainty quantification with machine learning models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-generic-framework-for-conformal-fairness</guid>
    </item>
    <item>
      <title>Reading Between the Prompts: How Stereotypes Shape LLM's Implicit Personalization</title>
      <link>https://paperswithcode.com/paper/reading-between-the-prompts-how-stereotypes</link>
      <description><![CDATA[Generative Large Language Models (LLMs) infer user's demographic information from subtle cues in the conversation -- a phenomenon called implicit personalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reading-between-the-prompts-how-stereotypes</guid>
    </item>
    <item>
      <title>Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/teaching-large-language-models-to-maintain</link>
      <description><![CDATA[Therefore, we propose a systematic framework, CANOE, to improve the faithfulness of LLMs in both short-form and long-form generation tasks without human annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teaching-large-language-models-to-maintain</guid>
    </item>
    <item>
      <title>Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?</title>
      <link>https://paperswithcode.com/paper/do-large-language-models-excel-in-complex</link>
      <description><![CDATA[Large Language Models (LLMs) have been shown to achieve breakthrough performance on complex logical reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-large-language-models-excel-in-complex</guid>
    </item>
    <item>
      <title>Accelerating Targeted Hard-Label Adversarial Attacks in Low-Query Black-Box Settings</title>
      <link>https://paperswithcode.com/paper/accelerating-targeted-hard-label-adversarial</link>
      <description><![CDATA[In contrast, we propose Targeted Edge-informed Attack (TEA), a novel attack that utilizes edge information from the target image to carefully perturb it, thereby producing an adversarial image that is closer to the source image while still achieving the desired target classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-targeted-hard-label-adversarial</guid>
    </item>
    <item>
      <title>SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward</title>
      <link>https://paperswithcode.com/paper/sophiavl-r1-reinforcing-mllms-reasoning-with</link>
      <description><![CDATA[Given that the thinking reward may be unreliable for certain samples due to reward hacking, we propose the Trust-GRPO method, which assigns a trustworthiness weight to the thinking reward during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sophiavl-r1-reinforcing-mllms-reasoning-with</guid>
    </item>
    <item>
      <title>Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification</title>
      <link>https://paperswithcode.com/paper/breaking-mbad-supervised-fine-tuning-for</link>
      <description><![CDATA[As large language models (LLMs) become increasingly prevalent in global applications, ensuring that they are toxicity-free across diverse linguistic contexts remains a critical challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/breaking-mbad-supervised-fine-tuning-for</guid>
    </item>
    <item>
      <title>$\text{R}^2\text{ec}$: Towards Large Recommender Models with Reasoning</title>
      <link>https://paperswithcode.com/paper/text-r-2-text-ec-towards-large-recommender</link>
      <description><![CDATA[To address these issues, we propose \name, a unified large recommender model with intrinsic reasoning capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-r-2-text-ec-towards-large-recommender</guid>
    </item>
    <item>
      <title>Training Long-Context LLMs Efficiently via Chunk-wise Optimization</title>
      <link>https://paperswithcode.com/paper/training-long-context-llms-efficiently-via</link>
      <description><![CDATA[While long-context large language models (LLMs) exhibit remarkable document processing capabilities, their prohibitively high training costs often hinder customized applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-long-context-llms-efficiently-via</guid>
    </item>
    <item>
      <title>CASTILLO: Characterizing Response Length Distributions of Large Language Models</title>
      <link>https://paperswithcode.com/paper/castillo-characterizing-response-length</link>
      <description><![CDATA[Efficiently managing compute resources for Large Language Model (LLM) inference remains challenging due to the inherently stochastic and variable lengths of autoregressive text generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/castillo-characterizing-response-length</guid>
    </item>
    <item>
      <title>MPO: Multilingual Safety Alignment via Reward Gap Optimization</title>
      <link>https://paperswithcode.com/paper/mpo-multilingual-safety-alignment-via-reward</link>
      <description><![CDATA[Large language models (LLMs) have become increasingly central to AI applications worldwide, necessitating robust multilingual safety alignment to ensure secure deployment across diverse linguistic contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mpo-multilingual-safety-alignment-via-reward</guid>
    </item>
    <item>
      <title>LIFEBench: Evaluating Length Instruction Following in Large Language Models</title>
      <link>https://paperswithcode.com/paper/lifebench-evaluating-length-instruction</link>
      <description><![CDATA[To this end, we introduce Length Instruction Following Evaluation Benchmark (LIFEBench) to comprehensively evaluate LLMs' ability to follow length instructions across diverse tasks and a wide range of specified lengths.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lifebench-evaluating-length-instruction</guid>
    </item>
    <item>
      <title>Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/circle-rope-cone-like-decoupled-rotary</link>
      <description><![CDATA[This configuration ensures that each text token maintains an equal distance to all image tokens, reducing artificial cross-modal biases while preserving intra-image spatial information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/circle-rope-cone-like-decoupled-rotary</guid>
    </item>
    <item>
      <title>R1-Compress: Long Chain-of-Thought Compression via Chunk Compression and Search</title>
      <link>https://paperswithcode.com/paper/r1-compress-long-chain-of-thought-compression</link>
      <description><![CDATA[Chain-of-Thought (CoT) reasoning enhances large language models (LLMs) by enabling step-by-step problem-solving, yet its extension to Long-CoT introduces substantial computational overhead due to increased token length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r1-compress-long-chain-of-thought-compression</guid>
    </item>
    <item>
      <title>Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding</title>
      <link>https://paperswithcode.com/paper/dimple-discrete-diffusion-multimodal-large</link>
      <description><![CDATA[We observe that training with a purely discrete diffusion approach leads to significant training instability, suboptimal performance, and severe length bias issues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dimple-discrete-diffusion-multimodal-large</guid>
    </item>
  </channel>
</rss>
