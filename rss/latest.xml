<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 31 Mar 2023 09:12:26 +0000</lastBuildDate>
    <item>
      <title>PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models</title>
      <link>https://paperswithcode.com/paper/pair-diffusion-object-level-image-editing</link>
      <description><![CDATA[Nevertheless, most of them lack fine-grained control over the properties of the different objects present in the image, i. e. object-level image editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pair-diffusion-object-level-image-editing</guid>
    </item>
    <item>
      <title>Discriminative Class Tokens for Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/discriminative-class-tokens-for-text-to-image</link>
      <description><![CDATA[This comes with a downside, doing so limits their expressive power: (i) supervised datasets are generally small compared to large-scale scraped text-image datasets on which text-to-image models are trained, and so the quality and diversity of generated images are severely affected, or (ii) the input is a hard-coded label, as opposed to free-form text, which limits the control over the generated images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/discriminative-class-tokens-for-text-to-image</guid>
    </item>
    <item>
      <title>Efficient distributed representations beyond negative sampling</title>
      <link>https://paperswithcode.com/paper/efficient-distributed-representations-beyond</link>
      <description><![CDATA[Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-distributed-representations-beyond</guid>
    </item>
    <item>
      <title>Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study</title>
      <link>https://paperswithcode.com/paper/assessing-cross-cultural-alignment-between</link>
      <description><![CDATA[The recent release of ChatGPT has garnered widespread recognition for its exceptional ability to generate human-like responses in dialogue.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/assessing-cross-cultural-alignment-between</guid>
    </item>
    <item>
      <title>Shapley Chains: Extending Shapley Values to Classifier Chains</title>
      <link>https://paperswithcode.com/paper/shapley-chains-extending-shapley-values-to</link>
      <description><![CDATA[Compared to existing methods, this approach allows to attribute a more complete feature contribution to the predictions of multi-output classification tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shapley-chains-extending-shapley-values-to</guid>
    </item>
    <item>
      <title>Recognition, recall, and retention of few-shot memories in large language models</title>
      <link>https://paperswithcode.com/paper/recognition-recall-and-retention-of-few-shot</link>
      <description><![CDATA[In recognition experiments, we ask if the model can distinguish the seen example from a novel example; in recall experiments, we ask if the model can correctly recall the seen example when cued by a part of it; and in retention experiments, we periodically probe the model's memory for the original examples as the model is trained continuously with new examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recognition-recall-and-retention-of-few-shot</guid>
    </item>
    <item>
      <title>Neglected Free Lunch -- Learning Image Classifiers Using Annotation Byproducts</title>
      <link>https://paperswithcode.com/paper/neglected-free-lunch-learning-image</link>
      <description><![CDATA[We refer to the new paradigm of training models with annotation byproducts as learning using annotation byproducts (LUAB).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neglected-free-lunch-learning-image</guid>
    </item>
    <item>
      <title>Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/forget-me-not-learning-to-forget-in-text-to</link>
      <description><![CDATA[The unlearning problem of deep learning models, once primarily an academic concern, has become a prevalent issue in the industry.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/forget-me-not-learning-to-forget-in-text-to</guid>
    </item>
    <item>
      <title>OpenMix: Exploring Outlier Samples for Misclassification Detection</title>
      <link>https://paperswithcode.com/paper/openmix-exploring-outlier-samples-for</link>
      <description><![CDATA[Reliable confidence estimation for deep neural classifiers is a challenging yet fundamental requirement in high-stakes applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openmix-exploring-outlier-samples-for</guid>
    </item>
    <item>
      <title>Beyond Appearance: a Semantic Controllable Self-Supervised Learning Framework for Human-Centric Visual Tasks</title>
      <link>https://paperswithcode.com/paper/beyond-appearance-a-semantic-controllable</link>
      <description><![CDATA[Unlike the existing self-supervised learning methods, prior knowledge from human images is utilized in SOLIDER to build pseudo semantic labels and import more semantic information into the learned representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-appearance-a-semantic-controllable</guid>
    </item>
    <item>
      <title>Dynamic Conceptional Contrastive Learning for Generalized Category Discovery</title>
      <link>https://paperswithcode.com/paper/dynamic-conceptional-contrastive-learning-for</link>
      <description><![CDATA[This leads traditional novel category discovery (NCD) methods to be incapacitated for GCD, due to their assumption of unlabeled data are only from novel categories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-conceptional-contrastive-learning-for</guid>
    </item>
    <item>
      <title>NeRF-Supervised Deep Stereo</title>
      <link>https://paperswithcode.com/paper/nerf-supervised-deep-stereo</link>
      <description><![CDATA[We introduce a novel framework for training deep stereo networks effortlessly and without any ground-truth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nerf-supervised-deep-stereo</guid>
    </item>
    <item>
      <title>PoseFormerV2: Exploring Frequency Domain for Efficient and Robust 3D Human Pose Estimation</title>
      <link>https://paperswithcode.com/paper/poseformerv2-exploring-frequency-domain-for</link>
      <description><![CDATA[However, in real scenarios, the performance of PoseFormer and its follow-ups is limited by two factors: (a) The length of the input joint sequence; (b) The quality of 2D joint detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poseformerv2-exploring-frequency-domain-for</guid>
    </item>
    <item>
      <title>3D Line Mapping Revisited</title>
      <link>https://paperswithcode.com/paper/3d-line-mapping-revisited</link>
      <description><![CDATA[In contrast to sparse keypoints, a handful of line segments can concisely encode the high-level scene layout, as they often delineate the main structural elements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-line-mapping-revisited</guid>
    </item>
    <item>
      <title>Streaming Video Model</title>
      <link>https://paperswithcode.com/paper/streaming-video-model</link>
      <description><![CDATA[We believe that the concept of streaming video model and the implementation of S-ViT are solid steps towards a unified deep learning architecture for video understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streaming-video-model</guid>
    </item>
    <item>
      <title>DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents</title>
      <link>https://paperswithcode.com/paper/dera-enhancing-large-language-model</link>
      <description><![CDATA[Large language models (LLMs) have emerged as valuable tools for many natural language understanding tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dera-enhancing-large-language-model</guid>
    </item>
    <item>
      <title>Adversarial Attack and Defense for Dehazing Networks</title>
      <link>https://paperswithcode.com/paper/adversarial-attack-and-defense-for-dehazing</link>
      <description><![CDATA[In this paper, we focus on designing a group of attack methods based on first order gradient to verify the robustness of the existing dehazing algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-attack-and-defense-for-dehazing</guid>
    </item>
    <item>
      <title>An evaluation framework for comparing epidemic intelligence systems</title>
      <link>https://paperswithcode.com/paper/an-evaluation-framework-for-comparing</link>
      <description><![CDATA[In the context of Epidemic Intelligence, many Event-Based Surveillance (EBS) systems have been proposed in the literature to promote the early identification and characterization of potential health threats from online sources of any nature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-evaluation-framework-for-comparing</guid>
    </item>
    <item>
      <title>ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing</title>
      <link>https://paperswithcode.com/paper/imagenet-e-benchmarking-neural-network</link>
      <description><![CDATA[We also evaluate some robust models including both adversarially trained models and other robust trained models and find that some models show worse robustness against attribute changes than vanilla models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imagenet-e-benchmarking-neural-network</guid>
    </item>
    <item>
      <title>WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research</title>
      <link>https://paperswithcode.com/paper/wavcaps-a-chatgpt-assisted-weakly-labelled</link>
      <description><![CDATA[To address this data scarcity issue, we introduce WavCaps, the first large-scale weakly-labelled audio captioning dataset, comprising approximately 400k audio clips with paired captions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wavcaps-a-chatgpt-assisted-weakly-labelled</guid>
    </item>
    <item>
      <title>LayoutDiffusion: Controllable Diffusion Model for Layout-to-image Generation</title>
      <link>https://paperswithcode.com/paper/layoutdiffusion-controllable-diffusion-model</link>
      <description><![CDATA[To overcome the difficult multimodal fusion of image and layout, we propose to construct a structural image patch with region information and transform the patched image into a special layout to fuse with the normal layout in a unified form.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/layoutdiffusion-controllable-diffusion-model</guid>
    </item>
    <item>
      <title>Masked Autoencoders as Image Processors</title>
      <link>https://paperswithcode.com/paper/masked-autoencoders-as-image-processors</link>
      <description><![CDATA[Recently, masked autoencoders (MAE) for feature pre-training have further unleashed the potential of Transformers, leading to state-of-the-art performances on various high-level vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-autoencoders-as-image-processors</guid>
    </item>
    <item>
      <title>Robo3D: Towards Robust and Reliable 3D Perception against Corruptions</title>
      <link>https://paperswithcode.com/paper/robo3d-towards-robust-and-reliable-3d</link>
      <description><![CDATA[The robustness of 3D perception systems under natural corruptions from environments and sensors is pivotal for safety-critical applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robo3d-towards-robust-and-reliable-3d</guid>
    </item>
    <item>
      <title>Token Merging for Fast Stable Diffusion</title>
      <link>https://paperswithcode.com/paper/token-merging-for-fast-stable-diffusion</link>
      <description><![CDATA[In the process, we speed up image generation by up to 2x and reduce memory consumption by up to 5. 6x.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/token-merging-for-fast-stable-diffusion</guid>
    </item>
    <item>
      <title>Invertible Convolution with Symmetric Paddings</title>
      <link>https://paperswithcode.com/paper/invertible-convolution-with-symmetric</link>
      <description><![CDATA[We show that symmetrically padded convolution can be analytically inverted via DFT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/invertible-convolution-with-symmetric</guid>
    </item>
    <item>
      <title>Zero-Shot Video Editing Using Off-The-Shelf Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/zero-shot-video-editing-using-off-the-shelf</link>
      <description><![CDATA[Our vid2vid-zero leverages off-the-shelf image diffusion models, and doesn't require training on any video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-video-editing-using-off-the-shelf</guid>
    </item>
    <item>
      <title>Complementary Random Masking for RGB-Thermal Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/complementary-random-masking-for-rgb-thermal</link>
      <description><![CDATA[Also, the proposed self-distillation loss encourages the network to extract complementary and meaningful representations from a single modality or complementary masked modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/complementary-random-masking-for-rgb-thermal</guid>
    </item>
    <item>
      <title>Masked and Adaptive Transformer for Exemplar Based Image Translation</title>
      <link>https://paperswithcode.com/paper/masked-and-adaptive-transformer-for-exemplar</link>
      <description><![CDATA[To overcome this challenge, we improve the accuracy of matching on the one hand, and diminish the role of matching in image generation on the other hand.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-and-adaptive-transformer-for-exemplar</guid>
    </item>
    <item>
      <title>Rethinking the Approximation Error in 3D Surface Fitting for Point Cloud Normal Estimation</title>
      <link>https://paperswithcode.com/paper/rethinking-the-approximation-error-in-3d</link>
      <description><![CDATA[Most existing approaches for point cloud normal estimation aim to locally fit a geometric surface and calculate the normal from the fitted surface.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-the-approximation-error-in-3d</guid>
    </item>
    <item>
      <title>Whose Opinions Do Language Models Reflect?</title>
      <link>https://paperswithcode.com/paper/whose-opinions-do-language-models-reflect</link>
      <description><![CDATA[Language models (LMs) are increasingly being used in open-ended contexts, where the opinions reflected by LMs in response to subjective queries can have a profound impact, both on user satisfaction, as well as shaping the views of society at large.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/whose-opinions-do-language-models-reflect</guid>
    </item>
    <item>
      <title>Photometric LiDAR and RGB-D Bundle Adjustment</title>
      <link>https://paperswithcode.com/paper/photometric-lidar-and-rgb-d-bundle-adjustment</link>
      <description><![CDATA[This paper presents a novel BA photometric strategy that accounts for both RGB-D and LiDAR in the same way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photometric-lidar-and-rgb-d-bundle-adjustment</guid>
    </item>
    <item>
      <title>Neuro-symbolic Rule Learning in Real-world Classification Tasks</title>
      <link>https://paperswithcode.com/paper/neuro-symbolic-rule-learning-in-real-world</link>
      <description><![CDATA[Neuro-symbolic rule learning has attracted lots of attention as it offers better interpretability than pure neural models and scales better than symbolic rule learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuro-symbolic-rule-learning-in-real-world</guid>
    </item>
    <item>
      <title>RusTitW: Russian Language Text Dataset for Visual Text in-the-Wild Recognition</title>
      <link>https://paperswithcode.com/paper/rustitw-russian-language-text-dataset-for</link>
      <description><![CDATA[In this paper, we present a large-scale human-labeled dataset for Russian text recognition in-the-wild.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rustitw-russian-language-text-dataset-for</guid>
    </item>
    <item>
      <title>Are Neural Architecture Search Benchmarks Well Designed? A Deeper Look Into Operation Importance</title>
      <link>https://paperswithcode.com/paper/are-neural-architecture-search-benchmarks</link>
      <description><![CDATA[We found that only a subset of the operation pool is required to generate architectures close to the upper-bound of the performance range.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/are-neural-architecture-search-benchmarks</guid>
    </item>
    <item>
      <title>Multi-View Azimuth Stereo via Tangent Space Consistency</title>
      <link>https://paperswithcode.com/paper/multi-view-azimuth-stereo-via-tangent-space</link>
      <description><![CDATA[We present a method for 3D reconstruction only using calibrated multi-view surface azimuth maps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-view-azimuth-stereo-via-tangent-space</guid>
    </item>
    <item>
      <title>BEVSimDet: Simulated Multi-modal Distillation in Bird's-Eye View for Multi-view 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/bevsimdet-simulated-multi-modal-distillation</link>
      <description><![CDATA[In this paper, we approach this challenge from the perspective of both architecture design and knowledge distillation and present a new simulated multi-modal 3D object detection method named BEVSimDet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bevsimdet-simulated-multi-modal-distillation</guid>
    </item>
    <item>
      <title>GAT-COBO: Cost-Sensitive Graph Neural Network for Telecom Fraud Detection</title>
      <link>https://paperswithcode.com/paper/gat-cobo-cost-sensitive-graph-neural-network</link>
      <description><![CDATA[Extensive experiments on two real-world telecom fraud detection datasets demonstrate that our proposed method is effective for the graph imbalance problem, outperforming the state-of-the-art GNNs and GNN-based fraud detectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gat-cobo-cost-sensitive-graph-neural-network</guid>
    </item>
    <item>
      <title>Leveraging joint sparsity in hierarchical Bayesian learning</title>
      <link>https://paperswithcode.com/paper/leveraging-joint-sparsity-in-hierarchical</link>
      <description><![CDATA[We present a hierarchical Bayesian learning approach to infer jointly sparse parameter vectors from multiple measurement vectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-joint-sparsity-in-hierarchical</guid>
    </item>
    <item>
      <title>Robust Dancer: Long-term 3D Dance Synthesis Using Unpaired Data</title>
      <link>https://paperswithcode.com/paper/robust-dancer-long-term-3d-dance-synthesis</link>
      <description><![CDATA[How to automatically synthesize natural-looking dance movements based on a piece of music is an incrementally popular yet challenging task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-dancer-long-term-3d-dance-synthesis</guid>
    </item>
    <item>
      <title>An intelligent modular real-time vision-based system for environment perception</title>
      <link>https://paperswithcode.com/paper/an-intelligent-modular-real-time-vision-based</link>
      <description><![CDATA[Each section is accompanied by novel techniques to improve the accuracy of others along with the entire system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-intelligent-modular-real-time-vision-based</guid>
    </item>
    <item>
      <title>Training Feedforward Neural Networks with Bayesian Hyper-Heuristics</title>
      <link>https://paperswithcode.com/paper/training-feedforward-neural-networks-with-1</link>
      <description><![CDATA[The process of training feedforward neural networks (FFNNs) can benefit from an automated process where the best heuristic to train the network is sought out automatically by means of a high-level probabilistic-based heuristic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-feedforward-neural-networks-with-1</guid>
    </item>
    <item>
      <title>Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning</title>
      <link>https://paperswithcode.com/paper/larger-probes-tell-a-different-story</link>
      <description><![CDATA[Language model probing is often used to test specific capabilities of these models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/larger-probes-tell-a-different-story</guid>
    </item>
    <item>
      <title>MDP: A Generalized Framework for Text-Guided Image Editing by Manipulating the Diffusion Path</title>
      <link>https://paperswithcode.com/paper/mdp-a-generalized-framework-for-text-guided</link>
      <description><![CDATA[Image generation using diffusion can be controlled in multiple ways.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mdp-a-generalized-framework-for-text-guided</guid>
    </item>
    <item>
      <title>InceptionNeXt: When Inception Meets ConvNeXt</title>
      <link>https://paperswithcode.com/paper/inceptionnext-when-inception-meets-convnext</link>
      <description><![CDATA[Inspired by the long-range modeling ability of ViTs, large-kernel convolutions are widely studied and adopted recently to enlarge the receptive field and improve model performance, like the remarkable work ConvNeXt which employs 7x7 depthwise convolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inceptionnext-when-inception-meets-convnext</guid>
    </item>
    <item>
      <title>A Video-based End-to-end Pipeline for Non-nutritive Sucking Action Recognition and Segmentation in Young Infants</title>
      <link>https://paperswithcode.com/paper/a-video-based-end-to-end-pipeline-for-non</link>
      <description><![CDATA[Tested on our second, independent, and public NNS in-the-wild dataset, NNS recognition classification reaches 92. 3\% accuracy, and NNS segmentation achieves 90. 8\% precision and 84. 2\% recall.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-video-based-end-to-end-pipeline-for-non</guid>
    </item>
    <item>
      <title>4D Facial Expression Diffusion Model</title>
      <link>https://paperswithcode.com/paper/4d-facial-expression-diffusion-model</link>
      <description><![CDATA[It is composed of two tasks: (1) Learning the generative model that is trained over a set of 3D landmark sequences, and (2) Generating 3D mesh sequences of an input facial mesh driven by the generated landmark sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/4d-facial-expression-diffusion-model</guid>
    </item>
    <item>
      <title>Implicit Diffusion Models for Continuous Super-Resolution</title>
      <link>https://paperswithcode.com/paper/implicit-diffusion-models-for-continuous</link>
      <description><![CDATA[IDM integrates an implicit neural representation and a denoising diffusion model in a unified end-to-end framework, where the implicit neural representation is adopted in the decoding process to learn continuous-resolution representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implicit-diffusion-models-for-continuous</guid>
    </item>
    <item>
      <title>Latent Feature Relation Consistency for Adversarial Robustness</title>
      <link>https://paperswithcode.com/paper/latent-feature-relation-consistency-for</link>
      <description><![CDATA[Deep neural networks have been applied in many computer vision tasks and achieved state-of-the-art performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-feature-relation-consistency-for</guid>
    </item>
    <item>
      <title>Pgx: Hardware-accelerated parallel game simulation for reinforcement learning</title>
      <link>https://paperswithcode.com/paper/pgx-hardware-accelerated-parallel-game</link>
      <description><![CDATA[We propose Pgx, a collection of board game simulators written in JAX.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pgx-hardware-accelerated-parallel-game</guid>
    </item>
    <item>
      <title>From axioms over graphs to vectors, and back again: evaluating the properties of graph-based ontology embeddings</title>
      <link>https://paperswithcode.com/paper/from-axioms-over-graphs-to-vectors-and-back</link>
      <description><![CDATA[Several approaches have been developed that generate embeddings for Description Logic ontologies and use these embeddings in machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-axioms-over-graphs-to-vectors-and-back</guid>
    </item>
  </channel>
</rss>
