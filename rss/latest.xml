<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 24 Jul 2024 21:08:47 +0000</lastBuildDate>
    <item>
      <title>Diffusion Prior-Based Amortized Variational Inference for Noisy Inverse Problems</title>
      <link>https://paperswithcode.com/paper/diffusion-prior-based-amortized-variational</link>
      <description><![CDATA[Recent studies on inverse problems have proposed posterior samplers that leverage the pre-trained diffusion models as powerful priors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-prior-based-amortized-variational</guid>
    </item>
    <item>
      <title>Audio Prompt Adapter: Unleashing Music Editing Abilities for Text-to-Music with Lightweight Finetuning</title>
      <link>https://paperswithcode.com/paper/audio-prompt-adapter-unleashing-music-editing</link>
      <description><![CDATA[Text-to-music models allow users to generate nearly realistic musical audio with textual commands.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audio-prompt-adapter-unleashing-music-editing</guid>
    </item>
    <item>
      <title>PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing</title>
      <link>https://paperswithcode.com/paper/primeguard-safe-and-helpful-llms-through</link>
      <description><![CDATA[To address this, we propose PrimeGuard, a novel ITG method that utilizes structured control flow.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/primeguard-safe-and-helpful-llms-through</guid>
    </item>
    <item>
      <title>EgoCVR: An Egocentric Benchmark for Fine-Grained Composed Video Retrieval</title>
      <link>https://paperswithcode.com/paper/egocvr-an-egocentric-benchmark-for-fine</link>
      <description><![CDATA[In this work, we introduce EgoCVR, a new evaluation benchmark for fine-grained Composed Video Retrieval using large-scale egocentric video datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/egocvr-an-egocentric-benchmark-for-fine</guid>
    </item>
    <item>
      <title>On ADMM in Heterogeneous Federated Learning: Personalization, Robustness, and Fairness</title>
      <link>https://paperswithcode.com/paper/on-admm-in-heterogeneous-federated-learning</link>
      <description><![CDATA[Personalized FL (PFL) is an approach that aims to reduce the impact of statistical heterogeneity by developing personalized models for individual users, while also inherently providing benefits in terms of fairness and robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-admm-in-heterogeneous-federated-learning</guid>
    </item>
    <item>
      <title>On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis</title>
      <link>https://paperswithcode.com/paper/on-the-utility-of-speech-and-audio-foundation</link>
      <description><![CDATA[Marmoset monkeys encode vital information in their calls and serve as a surrogate model for neuro-biologists to understand the evolutionary origins of human vocal communication.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-utility-of-speech-and-audio-foundation</guid>
    </item>
    <item>
      <title>Hi-EF: Benchmarking Emotion Forecasting in Human-interaction</title>
      <link>https://paperswithcode.com/paper/hi-ef-benchmarking-emotion-forecasting-in</link>
      <description><![CDATA[We propose a novel Emotion Forecasting (EF) task grounded in the theory that an individuals emotions are easily influenced by the emotions or other information conveyed during interactions with another person.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hi-ef-benchmarking-emotion-forecasting-in</guid>
    </item>
    <item>
      <title>A deeper look at depth pruning of LLMs</title>
      <link>https://paperswithcode.com/paper/a-deeper-look-at-depth-pruning-of-llms</link>
      <description><![CDATA[Large Language Models (LLMs) are not only resource-intensive to train but even more costly to deploy in production.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-deeper-look-at-depth-pruning-of-llms</guid>
    </item>
    <item>
      <title>KAN or MLP: A Fairer Comparison</title>
      <link>https://paperswithcode.com/paper/kan-or-mlp-a-fairer-comparison</link>
      <description><![CDATA[This paper does not introduce a novel method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kan-or-mlp-a-fairer-comparison</guid>
    </item>
    <item>
      <title>SOAP: Enhancing Spatio-Temporal Relation and Motion Information Capturing for Few-Shot Action Recognition</title>
      <link>https://paperswithcode.com/paper/soap-enhancing-spatio-temporal-relation-and</link>
      <description><![CDATA[High frame-rate (HFR) videos of action recognition improve fine-grained expression while reducing the spatio-temporal relation and motion information density.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/soap-enhancing-spatio-temporal-relation-and</guid>
    </item>
    <item>
      <title>FoRA: Low-Rank Adaptation Model beyond Multimodal Siamese Network</title>
      <link>https://paperswithcode.com/paper/fora-low-rank-adaptation-model-beyond</link>
      <description><![CDATA[In this paper, we propose a novel multimodal object detector, named Low-rank Modal Adaptors (LMA) with a shared backbone.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fora-low-rank-adaptation-model-beyond</guid>
    </item>
    <item>
      <title>QPT V2: Masked Image Modeling Advances Visual Scoring</title>
      <link>https://paperswithcode.com/paper/qpt-v2-masked-image-modeling-advances-visual</link>
      <description><![CDATA[To this end, we propose Quality- and aesthetics-aware pretraining (QPT V2), the first pretraining framework based on MIM that offers a unified solution to quality and aesthetics assessment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qpt-v2-masked-image-modeling-advances-visual</guid>
    </item>
    <item>
      <title>INF-LLaVA: Dual-perspective Perception for High-Resolution Multimodal Large Language Model</title>
      <link>https://paperswithcode.com/paper/inf-llava-dual-perspective-perception-for</link>
      <description><![CDATA[However, the quadratic complexity of the vision encoder in MLLMs constrains the resolution of input images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inf-llava-dual-perspective-perception-for</guid>
    </item>
    <item>
      <title>Cross-Domain Separable Translation Network for Multimodal Image Change Detection</title>
      <link>https://paperswithcode.com/paper/cross-domain-separable-translation-network</link>
      <description><![CDATA[To overcome these limitations, a novel unsupervised cross-domain separable translation network (CSTN) is proposed, which uniquely integrates a within-domain self-reconstruction and a cross-domain image translation and cycle-reconstruction workflow with change detection constraints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-domain-separable-translation-network</guid>
    </item>
    <item>
      <title>Beyond Binary Gender: Evaluating Gender-Inclusive Machine Translation with Ambiguous Attitude Words</title>
      <link>https://paperswithcode.com/paper/beyond-binary-gender-evaluating-gender</link>
      <description><![CDATA[This study presents a benchmark AmbGIMT (Gender-Inclusive Machine Translation with Ambiguous attitude words), which assesses gender bias beyond binary gender.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-binary-gender-evaluating-gender</guid>
    </item>
    <item>
      <title>Advancing Brain Imaging Analysis Step-by-step via Progressive Self-paced Learning</title>
      <link>https://paperswithcode.com/paper/advancing-brain-imaging-analysis-step-by-step</link>
      <description><![CDATA[However, several challenges remain, such as heterogeneity, individual variations, and the contradiction between the high dimensionality and small size of brain imaging datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-brain-imaging-analysis-step-by-step</guid>
    </item>
    <item>
      <title>Aggregated Attributions for Explanatory Analysis of 3D Segmentation Models</title>
      <link>https://paperswithcode.com/paper/aggregated-attributions-for-explanatory</link>
      <description><![CDATA[To this end, we introduce Agg^2Exp, a methodology for aggregating fine-grained voxel attributions of the segmentation model's predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aggregated-attributions-for-explanatory</guid>
    </item>
    <item>
      <title>Diffusion Models for Monocular Depth Estimation: Overcoming Challenging Conditions</title>
      <link>https://paperswithcode.com/paper/diffusion-models-for-monocular-depth</link>
      <description><![CDATA[We present a novel approach designed to address the complexities posed by challenging, out-of-distribution data in the single-image depth estimation task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-for-monocular-depth</guid>
    </item>
    <item>
      <title>Open-Set Biometrics: Beyond Good Closed-Set Models</title>
      <link>https://paperswithcode.com/paper/open-set-biometrics-beyond-good-closed-set</link>
      <description><![CDATA[Biometric recognition has primarily addressed closed-set identification, assuming all probe subjects are in the gallery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-set-biometrics-beyond-good-closed-set</guid>
    </item>
    <item>
      <title>DC is all you need: describing ReLU from a signal processing standpoint</title>
      <link>https://paperswithcode.com/paper/dc-is-all-you-need-describing-relu-from-a</link>
      <description><![CDATA[In this work, we study the spectral behavior of ReLU, a popular activation function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dc-is-all-you-need-describing-relu-from-a</guid>
    </item>
    <item>
      <title>Dynamic Retraining-Updating Mean Teacher for Source-Free Object Detection</title>
      <link>https://paperswithcode.com/paper/dynamic-retraining-updating-mean-teacher-for</link>
      <description><![CDATA[In object detection, unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-retraining-updating-mean-teacher-for</guid>
    </item>
    <item>
      <title>Spatiotemporal Graph Guided Multi-modal Network for Livestreaming Product Retrieval</title>
      <link>https://paperswithcode.com/paper/spatiotemporal-graph-guided-multi-modal</link>
      <description><![CDATA[The LPR task encompasses three primary dilemmas in real-world scenarios: 1) the recognition of intended products from distractor products present in the background; 2) the video-image heterogeneity that the appearance of products showcased in live streams often deviates substantially from standardized product images in stores; 3) there are numerous confusing products with subtle visual nuances in the shop.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatiotemporal-graph-guided-multi-modal</guid>
    </item>
    <item>
      <title>On Differentially Private 3D Medical Image Synthesis with Controllable Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/on-differentially-private-3d-medical-image</link>
      <description><![CDATA[Generally, the small size of public medical imaging datasets coupled with stringent privacy concerns, hampers the advancement of data-hungry deep learning models in medical imaging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-differentially-private-3d-medical-image</guid>
    </item>
    <item>
      <title>A Simulation Benchmark for Autonomous Racing with Large-Scale Human Data</title>
      <link>https://paperswithcode.com/paper/a-simulation-benchmark-for-autonomous-racing</link>
      <description><![CDATA[Despite the availability of international prize-money competitions, scaled vehicles, and simulation environments, research on autonomous racing and the control of sports cars operating close to the limit of handling has been limited by the high costs of vehicle acquisition and management, as well as the limited physics accuracy of open-source simulators.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-simulation-benchmark-for-autonomous-racing</guid>
    </item>
    <item>
      <title>HyTAS: A Hyperspectral Image Transformer Architecture Search Benchmark and Analysis</title>
      <link>https://paperswithcode.com/paper/hytas-a-hyperspectral-image-transformer</link>
      <description><![CDATA[Hyperspectral Imaging (HSI) plays an increasingly critical role in precise vision tasks within remote sensing, capturing a wide spectrum of visual data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hytas-a-hyperspectral-image-transformer</guid>
    </item>
    <item>
      <title>Ranking protein-protein models with large language models and graph neural networks</title>
      <link>https://paperswithcode.com/paper/ranking-protein-protein-models-with-large</link>
      <description><![CDATA[A challenging step in this process is the identification of good models (near-native PPI conformations) from the large pool of generated models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ranking-protein-protein-models-with-large</guid>
    </item>
    <item>
      <title>Representation Magnitude has a Liability to Privacy Vulnerability</title>
      <link>https://paperswithcode.com/paper/representation-magnitude-has-a-liability-to</link>
      <description><![CDATA[The privacy-preserving approaches to machine learning (ML) models have made substantial progress in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representation-magnitude-has-a-liability-to</guid>
    </item>
    <item>
      <title>Efficient Detection of Commutative Factors in Factor Graphs</title>
      <link>https://paperswithcode.com/paper/efficient-detection-of-commutative-factors-in</link>
      <description><![CDATA[Lifted probabilistic inference exploits symmetries in probabilistic graphical models to allow for tractable probabilistic inference with respect to domain sizes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-detection-of-commutative-factors-in</guid>
    </item>
    <item>
      <title>Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion</title>
      <link>https://paperswithcode.com/paper/finetuning-generative-large-language-models</link>
      <description><![CDATA[Traditional knowledge graph (KG) completion models learn embeddings to predict missing facts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finetuning-generative-large-language-models</guid>
    </item>
    <item>
      <title>MOMAland: A Set of Benchmarks for Multi-Objective Multi-Agent Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/momaland-a-set-of-benchmarks-for-multi</link>
      <description><![CDATA[Many challenging tasks such as managing traffic systems, electricity grids, or supply chains involve complex decision-making processes that must balance multiple conflicting objectives and coordinate the actions of various independent decision-makers (DMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/momaland-a-set-of-benchmarks-for-multi</guid>
    </item>
    <item>
      <title>Strike a Balance in Continual Panoptic Segmentation</title>
      <link>https://paperswithcode.com/paper/strike-a-balance-in-continual-panoptic</link>
      <description><![CDATA[First, we introduce past-class backtrace distillation to balance the stability of existing knowledge with the adaptability to new information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/strike-a-balance-in-continual-panoptic</guid>
    </item>
    <item>
      <title>SEDS: Semantically Enhanced Dual-Stream Encoder for Sign Language Retrieval</title>
      <link>https://paperswithcode.com/paper/seds-semantically-enhanced-dual-stream</link>
      <description><![CDATA[Furthermore, existing RGB-based sign retrieval works suffer from the huge memory cost of dense visual data embedding in end-to-end training, and adopt offline RGB encoder instead, leading to suboptimal feature representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seds-semantically-enhanced-dual-stream</guid>
    </item>
    <item>
      <title>Fr√©chet Video Motion Distance: A Metric for Evaluating Motion Consistency in Videos</title>
      <link>https://paperswithcode.com/paper/frechet-video-motion-distance-a-metric-for</link>
      <description><![CDATA[Despite the impressive progress, research on metrics for evaluating the quality of generated videos, especially concerning temporal and motion consistency, remains underexplored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/frechet-video-motion-distance-a-metric-for</guid>
    </item>
    <item>
      <title>MonoWAD: Weather-Adaptive Diffusion Model for Robust Monocular 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/monowad-weather-adaptive-diffusion-model-for</link>
      <description><![CDATA[It contains two components: (1) the weather codebook to memorize the knowledge of the clear weather and generate a weather-reference feature for any input, and (2) the weather-adaptive diffusion model to enhance the feature representation of the input feature by incorporating a weather-reference feature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monowad-weather-adaptive-diffusion-model-for</guid>
    </item>
    <item>
      <title>Learning Trimodal Relation for AVQA with Missing Modality</title>
      <link>https://paperswithcode.com/paper/learning-trimodal-relation-for-avqa-with</link>
      <description><![CDATA[Recent Audio-Visual Question Answering (AVQA) methods rely on complete visual and audio input to answer questions accurately.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-trimodal-relation-for-avqa-with</guid>
    </item>
    <item>
      <title>BONES: a Benchmark fOr Neural Estimation of Shapley values</title>
      <link>https://paperswithcode.com/paper/bones-a-benchmark-for-neural-estimation-of</link>
      <description><![CDATA[To bridge this gap, we present BONES, a new benchmark focused on neural estimation of Shapley Value.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bones-a-benchmark-for-neural-estimation-of</guid>
    </item>
    <item>
      <title>SAFNet: Selective Alignment Fusion Network for Efficient HDR Imaging</title>
      <link>https://paperswithcode.com/paper/safnet-selective-alignment-fusion-network-for</link>
      <description><![CDATA[Multi-exposure High Dynamic Range (HDR) imaging is a challenging task when facing truncated texture and complex motion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safnet-selective-alignment-fusion-network-for</guid>
    </item>
    <item>
      <title>Coarse-to-Fine Proposal Refinement Framework for Audio Temporal Forgery Detection and Localization</title>
      <link>https://paperswithcode.com/paper/coarse-to-fine-proposal-refinement-framework</link>
      <description><![CDATA[Recently, a novel form of audio partial forgery has posed challenges to its forensics, requiring advanced countermeasures to detect subtle forgery manipulations within long-duration audio.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coarse-to-fine-proposal-refinement-framework</guid>
    </item>
    <item>
      <title>Diffusion Models as Optimizers for Efficient Planning in Offline RL</title>
      <link>https://paperswithcode.com/paper/diffusion-models-as-optimizers-for-efficient</link>
      <description><![CDATA[To evaluate the effectiveness and efficiency of the Trajectory Diffuser, we conduct experiments on the D4RL benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-as-optimizers-for-efficient</guid>
    </item>
    <item>
      <title>Local All-Pair Correspondence for Point Tracking</title>
      <link>https://paperswithcode.com/paper/local-all-pair-correspondence-for-point</link>
      <description><![CDATA[We introduce LocoTrack, a highly accurate and efficient model designed for the task of tracking any point (TAP) across video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/local-all-pair-correspondence-for-point</guid>
    </item>
    <item>
      <title>YOLOv10 for Automated Fracture Detection in Pediatric Wrist Trauma X-rays</title>
      <link>https://paperswithcode.com/paper/yolov10-for-automated-fracture-detection-in</link>
      <description><![CDATA[Wrist fractures are highly prevalent among children and can significantly impact their daily activities, such as attending school, participating in sports, and performing basic self-care tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov10-for-automated-fracture-detection-in</guid>
    </item>
    <item>
      <title>CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning</title>
      <link>https://paperswithcode.com/paper/clip-with-generative-latent-replay-a-strong</link>
      <description><![CDATA[Through extensive experiments on different domains, we demonstrate the effectiveness of our framework in adapting to new tasks while improving zero-shot capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clip-with-generative-latent-replay-a-strong</guid>
    </item>
    <item>
      <title>Multi-Modality Co-Learning for Efficient Skeleton-based Action Recognition</title>
      <link>https://paperswithcode.com/paper/multi-modality-co-learning-for-efficient-1</link>
      <description><![CDATA[Skeleton-based action recognition has garnered significant attention due to the utilization of concise and resilient skeletons.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-modality-co-learning-for-efficient-1</guid>
    </item>
    <item>
      <title>LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding</title>
      <link>https://paperswithcode.com/paper/longvideobench-a-benchmark-for-long-context</link>
      <description><![CDATA[In addition, our results indicate that model performance on the benchmark improves only when they are capable of processing more frames, positioning LongVideoBench as a valuable benchmark for evaluating future-generation long-context LMMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longvideobench-a-benchmark-for-long-context</guid>
    </item>
    <item>
      <title>Odyssey: Empowering Agents with Open-World Skills</title>
      <link>https://paperswithcode.com/paper/odyssey-empowering-agents-with-open-world</link>
      <description><![CDATA[In this work, we introduce ODYSSEY, a new framework that empowers Large Language Model (LLM)-based agents with open-world skills to explore the vast Minecraft world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/odyssey-empowering-agents-with-open-world</guid>
    </item>
    <item>
      <title>Learning at a Glance: Towards Interpretable Data-limited Continual Semantic Segmentation via Semantic-Invariance Modelling</title>
      <link>https://paperswithcode.com/paper/learning-at-a-glance-towards-interpretable</link>
      <description><![CDATA[Concretely, the proposed decoupling manner includes two ways, i. e., channel-wise decoupling and spatial-level neuron-relevant semantic consistency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-at-a-glance-towards-interpretable</guid>
    </item>
    <item>
      <title>Perceptions of Linguistic Uncertainty by Language Models and Humans</title>
      <link>https://paperswithcode.com/paper/perceptions-of-linguistic-uncertainty-by</link>
      <description><![CDATA[In this paper, we investigate how language models map linguistic expressions of uncertainty to numerical responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perceptions-of-linguistic-uncertainty-by</guid>
    </item>
    <item>
      <title>Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability</title>
      <link>https://paperswithcode.com/paper/do-large-language-models-have-compositional</link>
      <description><![CDATA[In this study, we delve into the ICL capabilities of LLMs on composite tasks, with only simple tasks as in-context examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-large-language-models-have-compositional</guid>
    </item>
    <item>
      <title>LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models</title>
      <link>https://paperswithcode.com/paper/llast-improved-end-to-end-speech-translation</link>
      <description><![CDATA[We introduces LLaST, a framework for building high-performance Large Language model based Speech-to-text Translation systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llast-improved-end-to-end-speech-translation</guid>
    </item>
    <item>
      <title>SwinSF: Image Reconstruction from Spatial-Temporal Spike Streams</title>
      <link>https://paperswithcode.com/paper/swinsf-image-reconstruction-from-spatial</link>
      <description><![CDATA[Furthermore, we build a new synthesized dataset for spike image reconstruction which matches the resolution of the latest spike camera, ensuring its relevance and applicability to the latest developments in spike camera imaging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/swinsf-image-reconstruction-from-spatial</guid>
    </item>
  </channel>
</rss>
