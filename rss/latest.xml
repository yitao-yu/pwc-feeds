<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 16 Aug 2023 21:05:31 +0000</lastBuildDate>
    <item>
      <title>Multimodal Dataset Distillation for Image-Text Retrieval</title>
      <link>https://paperswithcode.com/paper/multimodal-dataset-distillation-for-image</link>
      <description><![CDATA[Dataset distillation methods offer the promise of reducing a large-scale dataset down to a significantly smaller set of (potentially synthetic) training examples, which preserve sufficient information for training a new model from scratch.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-dataset-distillation-for-image</guid>
    </item>
    <item>
      <title>Dynamic Low-Rank Instance Adaptation for Universal Neural Image Compression</title>
      <link>https://paperswithcode.com/paper/dynamic-low-rank-instance-adaptation-for</link>
      <description><![CDATA[We thus introduce a dynamic gating network on top of the low-rank adaptation method, in order to decide which decoder layer should employ adaptation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-low-rank-instance-adaptation-for</guid>
    </item>
    <item>
      <title>Real-time Automatic M-mode Echocardiography Measurement with Panel Attention from Local-to-Global Pixels</title>
      <link>https://paperswithcode.com/paper/real-time-automatic-m-mode-echocardiography</link>
      <description><![CDATA[Motion mode (M-mode) recording is an essential part of echocardiography to measure cardiac dimension and function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-automatic-m-mode-echocardiography</guid>
    </item>
    <item>
      <title>Prompt Switch: Efficient CLIP Adaptation for Text-Video Retrieval</title>
      <link>https://paperswithcode.com/paper/prompt-switch-efficient-clip-adaptation-for</link>
      <description><![CDATA[In text-video retrieval, recent works have benefited from the powerful learning capabilities of pre-trained text-image foundation models (e. g., CLIP) by adapting them to the video domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-switch-efficient-clip-adaptation-for</guid>
    </item>
    <item>
      <title>Simple and Efficient Partial Graph Adversarial Attack: A New Perspective</title>
      <link>https://paperswithcode.com/paper/simple-and-efficient-partial-graph</link>
      <description><![CDATA[To this end, we propose a totally new method named partial graph attack (PGA), which selects the vulnerable nodes as attack targets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simple-and-efficient-partial-graph</guid>
    </item>
    <item>
      <title>Back to Basics: A Sanity Check on Modern Time Series Classification Algorithms</title>
      <link>https://paperswithcode.com/paper/back-to-basics-a-sanity-check-on-modern-time</link>
      <description><![CDATA[The state-of-the-art in time series classification has come a long way, from the 1NN-DTW algorithm to the ROCKET family of classifiers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/back-to-basics-a-sanity-check-on-modern-time</guid>
    </item>
    <item>
      <title>Context-Aware Pseudo-Label Refinement for Source-Free Domain Adaptive Fundus Image Segmentation</title>
      <link>https://paperswithcode.com/paper/context-aware-pseudo-label-refinement-for</link>
      <description><![CDATA[To this end, we propose a context-aware pseudo-label refinement method for SF-UDA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-aware-pseudo-label-refinement-for</guid>
    </item>
    <item>
      <title>SEDA: Self-Ensembling ViT with Defensive Distillation and Adversarial Training for robust Chest X-rays Classification</title>
      <link>https://paperswithcode.com/paper/seda-self-ensembling-vit-with-defensive</link>
      <description><![CDATA[Deep Learning methods have recently seen increased adoption in medical imaging applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seda-self-ensembling-vit-with-defensive</guid>
    </item>
    <item>
      <title>Memory-and-Anticipation Transformer for Online Action Understanding</title>
      <link>https://paperswithcode.com/paper/memory-and-anticipation-transformer-for</link>
      <description><![CDATA[Based on this idea, we present Memory-and-Anticipation Transformer (MAT), a memory-anticipation-based approach, to address the online action detection and anticipation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memory-and-anticipation-transformer-for</guid>
    </item>
    <item>
      <title>Identity-Consistent Aggregation for Video Object Detection</title>
      <link>https://paperswithcode.com/paper/identity-consistent-aggregation-for-video</link>
      <description><![CDATA[In Video Object Detection (VID), a common practice is to leverage the rich temporal contexts from the video to enhance the object representations in each frame.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/identity-consistent-aggregation-for-video</guid>
    </item>
    <item>
      <title>Helping Hands: An Object-Aware Ego-Centric Video Recognition Model</title>
      <link>https://paperswithcode.com/paper/helping-hands-an-object-aware-ego-centric</link>
      <description><![CDATA[We demonstrate the performance of the object-aware representations learnt by our model, by: (i) evaluating it for strong transfer, i. e. through zero-shot testing, on a number of downstream video-text retrieval and classification benchmarks; and (ii) by using the representations learned as input for long-term video understanding tasks (e. g. Episodic Memory in Ego4D).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/helping-hands-an-object-aware-ego-centric</guid>
    </item>
    <item>
      <title>Benchmarking Scalable Epistemic Uncertainty Quantification in Organ Segmentation</title>
      <link>https://paperswithcode.com/paper/benchmarking-scalable-epistemic-uncertainty</link>
      <description><![CDATA[Deep learning based methods for automatic organ segmentation have shown promise in aiding diagnosis and treatment planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-scalable-epistemic-uncertainty</guid>
    </item>
    <item>
      <title>Self-Prompting Large Vision Models for Few-Shot Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/self-prompting-large-vision-models-for-few</link>
      <description><![CDATA[Recent advancements in large foundation models have shown promising potential in the medical industry due to their flexible prompting capability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-prompting-large-vision-models-for-few</guid>
    </item>
    <item>
      <title>ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces</title>
      <link>https://paperswithcode.com/paper/objectsdf-improved-object-compositional</link>
      <description><![CDATA[Unlike traditional multi-view stereo approaches, the neural implicit surface-based methods leverage neural networks to represent 3D scenes as signed distance functions (SDFs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/objectsdf-improved-object-compositional</guid>
    </item>
    <item>
      <title>Improved Region Proposal Network for Enhanced Few-Shot Object Detection</title>
      <link>https://paperswithcode.com/paper/improved-region-proposal-network-for-enhanced</link>
      <description><![CDATA[Specifically, we develop a hierarchical ternary classification region proposal network (HTRPN) to localize the potential unlabeled novel objects and assign them new objectness labels to distinguish these objects from the base training dataset classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-region-proposal-network-for-enhanced</guid>
    </item>
    <item>
      <title>UniTR: A Unified and Efficient Multi-Modal Transformer for Bird's-Eye-View Representation</title>
      <link>https://paperswithcode.com/paper/unitr-a-unified-and-efficient-multi-modal</link>
      <description><![CDATA[Jointly processing information from multiple sensors is crucial to achieving accurate and robust perception for reliable autonomous driving systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unitr-a-unified-and-efficient-multi-modal</guid>
    </item>
    <item>
      <title>Whale Detection Enhancement through Synthetic Satellite Images</title>
      <link>https://paperswithcode.com/paper/whale-detection-enhancement-through-synthetic</link>
      <description><![CDATA[With a number of marine populations in rapid decline, collecting and analyzing data about marine populations has become increasingly important to develop effective conservation policies for a wide range of marine animals, including whales.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/whale-detection-enhancement-through-synthetic</guid>
    </item>
    <item>
      <title>DiffV2S: Diffusion-based Video-to-Speech Synthesis with Vision-guided Speaker Embedding</title>
      <link>https://paperswithcode.com/paper/diffv2s-diffusion-based-video-to-speech</link>
      <description><![CDATA[In doing so, the rich speaker embedding information can be produced solely from input visual information, and the extra audio information is not necessary during the inference time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffv2s-diffusion-based-video-to-speech</guid>
    </item>
    <item>
      <title>A Foundation LAnguage-Image model of the Retina (FLAIR): Encoding expert knowledge in text supervision</title>
      <link>https://paperswithcode.com/paper/a-foundation-language-image-model-of-the</link>
      <description><![CDATA[Foundation vision-language models are currently transforming computer vision, and are on the rise in medical imaging fueled by their very promising generalization capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-foundation-language-image-model-of-the</guid>
    </item>
    <item>
      <title>ICAFusion: Iterative Cross-Attention Guided Feature Fusion for Multispectral Object Detection</title>
      <link>https://paperswithcode.com/paper/icafusion-iterative-cross-attention-guided</link>
      <description><![CDATA[Effective feature fusion of multispectral images plays a crucial role in multi-spectral object detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/icafusion-iterative-cross-attention-guided</guid>
    </item>
    <item>
      <title>Link-Context Learning for Multimodal LLMs</title>
      <link>https://paperswithcode.com/paper/link-context-learning-for-multimodal-llms</link>
      <description><![CDATA[The ability to learn from context with novel concepts, and deliver appropriate responses are essential in human conversations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/link-context-learning-for-multimodal-llms</guid>
    </item>
    <item>
      <title>ImbSAM: A Closer Look at Sharpness-Aware Minimization in Class-Imbalanced Recognition</title>
      <link>https://paperswithcode.com/paper/imbsam-a-closer-look-at-sharpness-aware</link>
      <description><![CDATA[To overcome this bottleneck, we leverage class priors to restrict the generalization scope of the class-agnostic SAM and propose a class-aware smoothness optimization algorithm named Imbalanced-SAM (ImbSAM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imbsam-a-closer-look-at-sharpness-aware</guid>
    </item>
    <item>
      <title>CoDeF: Content Deformation Fields for Temporally Consistent Video Processing</title>
      <link>https://paperswithcode.com/paper/codef-content-deformation-fields-for</link>
      <description><![CDATA[We present the content deformation field CoDeF as a new type of video representation, which consists of a canonical content field aggregating the static contents in the entire video and a temporal deformation field recording the transformations from the canonical image (i. e., rendered from the canonical content field) to each individual frame along the time axis. Given a target video, these two fields are jointly optimized to reconstruct it through a carefully tailored rendering pipeline. We advisedly introduce some regularizations into the optimization process, urging the canonical content field to inherit semantics (e. g., the object shape) from the video. With such a design, CoDeF naturally supports lifting image algorithms for video processing, in the sense that one can apply an image algorithm to the canonical image and effortlessly propagate the outcomes to the entire video with the aid of the temporal deformation field. We experimentally show that CoDeF is able to lift image-to-image translation to video-to-video translation and lift keypoint detection to keypoint tracking without any training. More importantly, thanks to our lifting strategy that deploys the algorithms on only one image, we achieve superior cross-frame consistency in processed videos compared to existing video-to-video translation approaches, and even manage to track non-rigid objects like water and smog. Project page can be found at https://qiuyu96. github. io/CoDeF/.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codef-content-deformation-fields-for</guid>
    </item>
    <item>
      <title>Complete Instances Mining for Weakly Supervised Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/complete-instances-mining-for-weakly</link>
      <description><![CDATA[To address this problem, we propose a novel approach for WSIS that focuses on the online refinement of complete instances through the use of MaskIoU heads to predict the integrity scores of proposals and a Complete Instances Mining (CIM) strategy to explicitly model the redundant segmentation problem and generate refined pseudo labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/complete-instances-mining-for-weakly</guid>
    </item>
    <item>
      <title>Dyadic Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/dyadic-reinforcement-learning</link>
      <description><![CDATA[This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dyadic-reinforcement-learning</guid>
    </item>
    <item>
      <title>Fast Machine Unlearning Without Retraining Through Selective Synaptic Dampening</title>
      <link>https://paperswithcode.com/paper/fast-machine-unlearning-without-retraining</link>
      <description><![CDATA[We present Selective Synaptic Dampening (SSD), a novel two-step, post hoc, retrain-free approach to machine unlearning which is fast, performant, and does not require long-term storage of the training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-machine-unlearning-without-retraining</guid>
    </item>
    <item>
      <title>Boosting Multi-modal Model Performance with Adaptive Gradient Modulation</title>
      <link>https://paperswithcode.com/paper/boosting-multi-modal-model-performance-with</link>
      <description><![CDATA[In addition, we find that the jointly trained model typically has a preferred modality on which the competition is weaker than other modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-multi-modal-model-performance-with</guid>
    </item>
    <item>
      <title>DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models</title>
      <link>https://paperswithcode.com/paper/diffguard-semantic-mismatch-guided-out-of</link>
      <description><![CDATA[There is a recent work that directly applies it to OOD detection, which employs a conditional Generative Adversarial Network (cGAN) to enlarge semantic mismatch in the image space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffguard-semantic-mismatch-guided-out-of</guid>
    </item>
    <item>
      <title>EduSAT: A Pedagogical Tool for Theory and Applications of Boolean Satisfiability</title>
      <link>https://paperswithcode.com/paper/edusat-a-pedagogical-tool-for-theory-and</link>
      <description><![CDATA[Boolean Satisfiability (SAT) and Satisfiability Modulo Theories (SMT) are widely used in automated verification, but there is a lack of interactive tools designed for educational purposes in this field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edusat-a-pedagogical-tool-for-theory-and</guid>
    </item>
    <item>
      <title>Do We Fully Understand Students' Knowledge States? Identifying and Mitigating Answer Bias in Knowledge Tracing</title>
      <link>https://paperswithcode.com/paper/do-we-fully-understand-students-knowledge</link>
      <description><![CDATA[Existing models tend to memorize the answer bias as a shortcut for achieving high prediction performance in KT, thereby failing to fully understand students' knowledge states.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-we-fully-understand-students-knowledge</guid>
    </item>
    <item>
      <title>Probabilistic Phase Labeling and Lattice Refinement for Autonomous Material Research</title>
      <link>https://paperswithcode.com/paper/probabilistic-phase-labeling-and-lattice</link>
      <description><![CDATA[X-ray diffraction (XRD) is an essential technique to determine a material's crystal structure in high-throughput experimentation, and has recently been incorporated in artificially intelligent agents in autonomous scientific discovery processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probabilistic-phase-labeling-and-lattice</guid>
    </item>
    <item>
      <title>Better Zero-Shot Reasoning with Role-Play Prompting</title>
      <link>https://paperswithcode.com/paper/better-zero-shot-reasoning-with-role-play</link>
      <description><![CDATA[This highlights its potential to augment the reasoning capabilities of LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/better-zero-shot-reasoning-with-role-play</guid>
    </item>
    <item>
      <title>Towards Temporal Edge Regression: A Case Study on Agriculture Trade Between Nations</title>
      <link>https://paperswithcode.com/paper/towards-temporal-edge-regression-a-case-study</link>
      <description><![CDATA[In this paper, we explore the application of GNNs to edge regression tasks in both static and dynamic settings, focusing on predicting food and agriculture trade values between nations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-temporal-edge-regression-a-case-study</guid>
    </item>
    <item>
      <title>Fairness and Privacy in Federated Learning and Their Implications in Healthcare</title>
      <link>https://paperswithcode.com/paper/fairness-and-privacy-in-federated-learning</link>
      <description><![CDATA[This paper endeavors to outline the typical lifecycle of fair federated learning in research as well as provide an updated taxonomy to account for the current state of fairness in implementations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fairness-and-privacy-in-federated-learning</guid>
    </item>
    <item>
      <title>Handwritten Stenography Recognition and the LION Dataset</title>
      <link>https://paperswithcode.com/paper/handwritten-stenography-recognition-and-the</link>
      <description><![CDATA[Methods: A state-of-the-art text recognition model is trained to establish a baseline.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/handwritten-stenography-recognition-and-the</guid>
    </item>
    <item>
      <title>Geometry of the Visual Cortex with Applications to Image Inpainting and Enhancement</title>
      <link>https://paperswithcode.com/paper/geometry-of-the-visual-cortex-with</link>
      <description><![CDATA[Equipping the rototranslation group $SE(2)$ with a sub-Riemannian structure inspired by the visual cortex V1, we propose algorithms for image inpainting and enhancement based on hypoelliptic diffusion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geometry-of-the-visual-cortex-with</guid>
    </item>
    <item>
      <title>EQ-Net: Elastic Quantization Neural Networks</title>
      <link>https://paperswithcode.com/paper/eq-net-elastic-quantization-neural-networks</link>
      <description><![CDATA[In this paper, we explore a one-shot network quantization regime, named Elastic Quantization Neural Networks (EQ-Net), which aims to train a robust weight-sharing quantization supernet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eq-net-elastic-quantization-neural-networks</guid>
    </item>
    <item>
      <title>Learning to Identify Critical States for Reinforcement Learning from Videos</title>
      <link>https://paperswithcode.com/paper/learning-to-identify-critical-states-for</link>
      <description><![CDATA[Recent work on deep reinforcement learning (DRL) has pointed out that algorithmic information about good policies can be extracted from offline data which lack explicit information about executed actions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-identify-critical-states-for</guid>
    </item>
    <item>
      <title>From Commit Message Generation to History-Aware Commit Message Completion</title>
      <link>https://paperswithcode.com/paper/from-commit-message-generation-to-history</link>
      <description><![CDATA[We use this dataset to evaluate the completion setting and the usefulness of the historical context for state-of-the-art CMG models and GPT-3. 5-turbo.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-commit-message-generation-to-history</guid>
    </item>
    <item>
      <title>Ske2Grid: Skeleton-to-Grid Representation Learning for Action Recognition</title>
      <link>https://paperswithcode.com/paper/ske2grid-skeleton-to-grid-representation</link>
      <description><![CDATA[This paper presents Ske2Grid, a new representation learning framework for improved skeleton-based action recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ske2grid-skeleton-to-grid-representation</guid>
    </item>
    <item>
      <title>A Genetic Algorithm Meta-Heuristic for a Generalized Quadratic Assignment Problem</title>
      <link>https://paperswithcode.com/paper/a-genetic-algorithm-meta-heuristic-for-a</link>
      <description><![CDATA[The GQAP addressed in this work is defined as the task of minimizing the assignment and transportation costs of assigning a set of facilities to a set of locations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-genetic-algorithm-meta-heuristic-for-a</guid>
    </item>
    <item>
      <title>Color-NeuS: Reconstructing Neural Implicit Surfaces with Color</title>
      <link>https://paperswithcode.com/paper/color-neus-reconstructing-neural-implicit</link>
      <description><![CDATA[Mesh is extracted from the signed distance function (SDF) network for the surface, and color for each surface vertex is drawn from the global color network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/color-neus-reconstructing-neural-implicit</guid>
    </item>
    <item>
      <title>Generative Interpretation</title>
      <link>https://paperswithcode.com/paper/generative-interpretation</link>
      <description><![CDATA[We introduce generative interpretation, a new approach to estimating contractual meaning using large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-interpretation</guid>
    </item>
    <item>
      <title>SOTASTREAM: A Streaming Approach to Machine Translation Training</title>
      <link>https://paperswithcode.com/paper/sotastream-a-streaming-approach-to-machine</link>
      <description><![CDATA[Many machine translation toolkits make use of a data preparation step wherein raw data is transformed into a tensor format that can be used directly by the trainer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sotastream-a-streaming-approach-to-machine</guid>
    </item>
    <item>
      <title>Large Language Models for Information Retrieval: A Survey</title>
      <link>https://paperswithcode.com/paper/large-language-models-for-information</link>
      <description><![CDATA[This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-for-information</guid>
    </item>
    <item>
      <title>ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate</title>
      <link>https://paperswithcode.com/paper/chateval-towards-better-llm-based-evaluators</link>
      <description><![CDATA[Text evaluation has historically posed significant challenges, often demanding substantial labor and time cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chateval-towards-better-llm-based-evaluators</guid>
    </item>
    <item>
      <title>#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models</title>
      <link>https://paperswithcode.com/paper/instag-instruction-tagging-for-diversity-and</link>
      <description><![CDATA[Based on this observation, we propose a data selector based on InsTag to select 6K diverse and complex samples from open-source datasets and fine-tune models on InsTag-selected data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instag-instruction-tagging-for-diversity-and</guid>
    </item>
    <item>
      <title>Robustified ANNs Reveal Wormholes Between Human Category Percepts</title>
      <link>https://paperswithcode.com/paper/robustified-anns-reveal-wormholes-between</link>
      <description><![CDATA[Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations -- and locally stable in general -- this argues that ANNs are incomplete scientific models of human visual perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robustified-anns-reveal-wormholes-between</guid>
    </item>
    <item>
      <title>Probabilistic MIMO U-Net: Efficient and Accurate Uncertainty Estimation for Pixel-wise Regression</title>
      <link>https://paperswithcode.com/paper/probabilistic-mimo-u-net-efficient-and</link>
      <description><![CDATA[For that purpose, we adapted the U-Net architecture to train multiple subnetworks within a single model, harnessing the overparameterization in deep neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probabilistic-mimo-u-net-efficient-and</guid>
    </item>
    <item>
      <title>Hierarchy Flow For High-Fidelity Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/hierarchy-flow-for-high-fidelity-image-to</link>
      <description><![CDATA[In this work, we propose Hierarchy Flow, a novel flow-based model to achieve better content preservation during translation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchy-flow-for-high-fidelity-image-to</guid>
    </item>
  </channel>
</rss>
