<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 26 Aug 2023 09:10:04 +0000</lastBuildDate>
    <item>
      <title>American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers</title>
      <link>https://paperswithcode.com/paper/american-stories-a-large-scale-structured</link>
      <description><![CDATA[The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/american-stories-a-large-scale-structured</guid>
    </item>
    <item>
      <title>Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods</title>
      <link>https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</link>
      <description><![CDATA[We introduce an open-source GitHub repository containing comprehensive benchmarks for a wide range of machine scheduling problems, including Job Shop Scheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling (FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent Setup Times (FJSP-SDST), and the online FJSP (with online job arrivals).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</guid>
    </item>
    <item>
      <title>Perspective-aware Convolution for Monocular 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</link>
      <description><![CDATA[Monocular 3D object detection is a crucial and challenging task for autonomous driving vehicle, while it uses only a single camera image to infer 3D objects in the scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</guid>
    </item>
    <item>
      <title>Fast Adversarial Training with Smooth Convergence</title>
      <link>https://paperswithcode.com/paper/fast-adversarial-training-with-smooth</link>
      <description><![CDATA[To address this, we analyze the training process of prior FAT work and observe that catastrophic overfitting is accompanied by the appearance of loss convergence outliers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-adversarial-training-with-smooth</guid>
    </item>
    <item>
      <title>Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers</title>
      <link>https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</link>
      <description><![CDATA[Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</guid>
    </item>
    <item>
      <title>Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints</title>
      <link>https://paperswithcode.com/paper/master-slave-deep-architecture-for-top-k</link>
      <description><![CDATA[We propose a novel master-slave architecture to solve the top-$K$ combinatorial multi-armed bandits problem with non-linear bandit feedback and diversity constraints, which, to the best of our knowledge, is the first combinatorial bandits setting considering diversity constraints under bandit feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/master-slave-deep-architecture-for-top-k</guid>
    </item>
    <item>
      <title>Masked Autoencoders are Efficient Class Incremental Learners</title>
      <link>https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</link>
      <description><![CDATA[Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</guid>
    </item>
    <item>
      <title>Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities</title>
      <link>https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</link>
      <description><![CDATA[We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</guid>
    </item>
    <item>
      <title>NOVA: NOvel View Augmentation for Neural Composition of Dynamic Objects</title>
      <link>https://paperswithcode.com/paper/nova-novel-view-augmentation-for-neural</link>
      <description><![CDATA[We propose a novel-view augmentation (NOVA) strategy to train NeRFs for photo-realistic 3D composition of dynamic objects in a static scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nova-novel-view-augmentation-for-neural</guid>
    </item>
    <item>
      <title>Evolutionary Dynamic Optimization Laboratory: A MATLAB Optimization Platform for Education and Experimentation in Dynamic Environments</title>
      <link>https://paperswithcode.com/paper/evolutionary-dynamic-optimization-laboratory</link>
      <description><![CDATA[In this paper, to assist researchers in performing experiments and comparing their algorithms against several EDOAs, we develop an open-source MATLAB platform for EDOAs, called Evolutionary Dynamic Optimization LABoratory (EDOLAB).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evolutionary-dynamic-optimization-laboratory</guid>
    </item>
    <item>
      <title>Match-And-Deform: Time Series Domain Adaptation through Optimal Transport and Temporal Alignment</title>
      <link>https://paperswithcode.com/paper/match-and-deform-time-series-domain</link>
      <description><![CDATA[While large volumes of unlabeled data are usually available, associated labels are often scarce.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/match-and-deform-time-series-domain</guid>
    </item>
    <item>
      <title>Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis</title>
      <link>https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</link>
      <description><![CDATA[The model pretrained on large-scale rs-fMRI data has been released to the public.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</guid>
    </item>
    <item>
      <title>BridgeData V2: A Dataset for Robot Learning at Scale</title>
      <link>https://paperswithcode.com/paper/bridgedata-v2-a-dataset-for-robot-learning-at</link>
      <description><![CDATA[By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridgedata-v2-a-dataset-for-robot-learning-at</guid>
    </item>
    <item>
      <title>Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines</title>
      <link>https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</link>
      <description><![CDATA[This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</guid>
    </item>
    <item>
      <title>CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias</title>
      <link>https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</link>
      <description><![CDATA[To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</guid>
    </item>
    <item>
      <title>REB: Reducing Biases in Representation for Industrial Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/reb-reducing-biases-in-representation-for</link>
      <description><![CDATA[Additionally, we propose a local density KNN (LDKNN) to reduce the local density bias and obtain effective anomaly detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reb-reducing-biases-in-representation-for</guid>
    </item>
    <item>
      <title>Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?</title>
      <link>https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</link>
      <description><![CDATA[The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</guid>
    </item>
    <item>
      <title>Robotic Scene Segmentation with Memory Network for Runtime Surgical Context Inference</title>
      <link>https://paperswithcode.com/paper/robotic-scene-segmentation-with-memory</link>
      <description><![CDATA[However, runtime context inference is challenging since it requires timely and accurate detection of the interactions among the tools and objects in the surgical scene based on the segmentation of video data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robotic-scene-segmentation-with-memory</guid>
    </item>
    <item>
      <title>Ground-to-Aerial Person Search: Benchmark Dataset and Approach</title>
      <link>https://paperswithcode.com/paper/ground-to-aerial-person-search-benchmark</link>
      <description><![CDATA[In this work, we construct a large-scale dataset for Ground-to-Aerial Person Search, named G2APS, which contains 31, 770 images of 260, 559 annotated bounding boxes for 2, 644 identities appearing in both of the UAVs and ground surveillance cameras.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ground-to-aerial-person-search-benchmark</guid>
    </item>
    <item>
      <title>Less is More: Towards Efficient Few-shot 3D Semantic Segmentation via Training-free Networks</title>
      <link>https://paperswithcode.com/paper/less-is-more-towards-efficient-few-shot-3d</link>
      <description><![CDATA[However, the prior pre-training stage not only introduces excessive time overhead, but also incurs a significant domain gap on `unseen' classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-is-more-towards-efficient-few-shot-3d</guid>
    </item>
    <item>
      <title>Implicit Obstacle Map-driven Indoor Navigation Model for Robust Obstacle Avoidance</title>
      <link>https://paperswithcode.com/paper/implicit-obstacle-map-driven-indoor</link>
      <description><![CDATA[Robust obstacle avoidance is one of the critical steps for successful goal-driven indoor navigation tasks. Due to the obstacle missing in the visual image and the possible missed detection issue, visual image-based obstacle avoidance techniques still suffer from unsatisfactory robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implicit-obstacle-map-driven-indoor</guid>
    </item>
    <item>
      <title>Grounded Entity-Landmark Adaptive Pre-training for Vision-and-Language Navigation</title>
      <link>https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</link>
      <description><![CDATA[To address this problem, we propose a novel Grounded Entity-Landmark Adaptive (GELA) pre-training paradigm for VLN tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</guid>
    </item>
    <item>
      <title>Learning Heavily-Degraded Prior for Underwater Object Detection</title>
      <link>https://paperswithcode.com/paper/learning-heavily-degraded-prior-for</link>
      <description><![CDATA[Therefore, we propose a residual feature transference module (RFTM) to learn a mapping between deep representations of the heavily degraded patches of DFUI- and underwater- images, and make the mapping as a heavily degraded prior (HDP) for underwater detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-heavily-degraded-prior-for</guid>
    </item>
    <item>
      <title>Improving Translation Faithfulness of Large Language Models via Augmenting Instructions</title>
      <link>https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</link>
      <description><![CDATA[The experimental results demonstrate significant improvements in translation performance with SWIE based on BLOOMZ-3b, particularly in zero-shot and long text translations due to reduced instruction forgetting risk.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</guid>
    </item>
    <item>
      <title>Attention-Based Acoustic Feature Fusion Network for Depression Detection</title>
      <link>https://paperswithcode.com/paper/attention-based-acoustic-feature-fusion</link>
      <description><![CDATA[To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-based-acoustic-feature-fusion</guid>
    </item>
    <item>
      <title>Dense Text-to-Image Generation with Attention Modulation</title>
      <link>https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</link>
      <description><![CDATA[To address this, we propose DenseDiffusion, a training-free method that adapts a pre-trained text-to-image model to handle such dense captions while offering control over the scene layout.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</guid>
    </item>
    <item>
      <title>HR-Pro: Point-supervised Temporal Action Localization via Hierarchical Reliability Propagation</title>
      <link>https://paperswithcode.com/paper/hr-pro-point-supervised-temporal-action</link>
      <description><![CDATA[For snippet-level learning, we introduce an online-updated memory to store reliable snippet prototypes for each class.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hr-pro-point-supervised-temporal-action</guid>
    </item>
    <item>
      <title>Motion In-Betweening with Phase Manifolds</title>
      <link>https://paperswithcode.com/paper/motion-in-betweening-with-phase-manifolds</link>
      <description><![CDATA[This paper introduces a novel data-driven motion in-betweening system to reach target poses of characters by making use of phases variables learned by a Periodic Autoencoder.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motion-in-betweening-with-phase-manifolds</guid>
    </item>
    <item>
      <title>kTrans: Knowledge-Aware Transformer for Binary Code Embedding</title>
      <link>https://paperswithcode.com/paper/ktrans-knowledge-aware-transformer-for-binary</link>
      <description><![CDATA[By feeding explicit knowledge as additional inputs to the Transformer, and fusing implicit knowledge with a novel pre-training task, kTrans provides a new perspective to incorporating domain knowledge into a Transformer framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ktrans-knowledge-aware-transformer-for-binary</guid>
    </item>
    <item>
      <title>Laying foundations to quantify the "Effort of Reproducibility"</title>
      <link>https://paperswithcode.com/paper/laying-foundations-to-quantify-the-effort-of</link>
      <description><![CDATA[Why are some research studies easy to reproduce while others are difficult?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/laying-foundations-to-quantify-the-effort-of</guid>
    </item>
    <item>
      <title>Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]</title>
      <link>https://paperswithcode.com/paper/unified-data-management-and-comprehensive</link>
      <description><![CDATA[The field of urban spatial-temporal prediction is advancing rapidly with the development of deep learning techniques and the availability of large-scale datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-data-management-and-comprehensive</guid>
    </item>
    <item>
      <title>Mutual-Guided Dynamic Network for Image Fusion</title>
      <link>https://paperswithcode.com/paper/mutual-guided-dynamic-network-for-image</link>
      <description><![CDATA[Image fusion aims to generate a high-quality image from multiple images captured under varying conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mutual-guided-dynamic-network-for-image</guid>
    </item>
    <item>
      <title>HuBo-VLM: Unified Vision-Language Model designed for HUman roBOt interaction tasks</title>
      <link>https://paperswithcode.com/paper/hubo-vlm-unified-vision-language-model</link>
      <description><![CDATA[Human robot interaction is an exciting task, which aimed to guide robots following instructions from human.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hubo-vlm-unified-vision-language-model</guid>
    </item>
    <item>
      <title>Single-shot Bayesian approximation for neural networks</title>
      <link>https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</link>
      <description><![CDATA[We demonstrate that our single-shot MC dropout approximation resembles the point estimate and the uncertainty estimate of the predictive distribution that is achieved with an MC approach, while being fast enough for real-time deployments of BNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</guid>
    </item>
    <item>
      <title>On Popularity Bias of Multimodal-aware Recommender Systems: a Modalities-driven Analysis</title>
      <link>https://paperswithcode.com/paper/on-popularity-bias-of-multimodal-aware</link>
      <description><![CDATA[Multimodal-aware recommender systems (MRSs) exploit multimodal content (e. g., product images or descriptions) as items' side information to improve recommendation accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-popularity-bias-of-multimodal-aware</guid>
    </item>
    <item>
      <title>Large Language Models Vote: Prompting for Rare Disease Identification</title>
      <link>https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</link>
      <description><![CDATA[The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</guid>
    </item>
    <item>
      <title>DD-GCN: Directed Diffusion Graph Convolutional Network for Skeleton-based Human Action Recognition</title>
      <link>https://paperswithcode.com/paper/dd-gcn-directed-diffusion-graph-convolutional</link>
      <description><![CDATA[Graph Convolutional Networks (GCNs) have been widely used in skeleton-based human action recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dd-gcn-directed-diffusion-graph-convolutional</guid>
    </item>
    <item>
      <title>Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</link>
      <description><![CDATA[The challenges of this task lie in the complexity of the scenes, the unique features of anime style, and the lack of high-quality datasets to bridge the domain gap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</guid>
    </item>
    <item>
      <title>OFVL-MS: Once for Visual Localization across Multiple Indoor Scenes</title>
      <link>https://paperswithcode.com/paper/ofvl-ms-once-for-visual-localization-across</link>
      <description><![CDATA[In this work, we seek to predict camera poses across scenes with a multi-task learning manner, where we view the localization of each scene as a new task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ofvl-ms-once-for-visual-localization-across</guid>
    </item>
    <item>
      <title>Joint Prediction of Audio Event and Annoyance Rating in an Urban Soundscape by Hierarchical Graph Representation Learning</title>
      <link>https://paperswithcode.com/paper/joint-prediction-of-audio-event-and-annoyance</link>
      <description><![CDATA[Sound events in daily life carry rich information about the objective world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/joint-prediction-of-audio-event-and-annoyance</guid>
    </item>
    <item>
      <title>SILT: Shadow-aware Iterative Label Tuning for Learning to Detect Shadows from Noisy Labels</title>
      <link>https://paperswithcode.com/paper/silt-shadow-aware-iterative-label-tuning-for</link>
      <description><![CDATA[Existing shadow detection datasets often contain missing or mislabeled shadows, which can hinder the performance of deep learning models trained directly on such data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/silt-shadow-aware-iterative-label-tuning-for</guid>
    </item>
    <item>
      <title>System Identification Using the Signed Cumulative Distribution Transform In Structural Health Monitoring Applications</title>
      <link>https://paperswithcode.com/paper/system-identification-using-the-signed</link>
      <description><![CDATA[This paper presents a novel, data-driven approach to identifying partial differential equation (PDE) parameters of a dynamical system in structural health monitoring applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/system-identification-using-the-signed</guid>
    </item>
    <item>
      <title>Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges</title>
      <link>https://paperswithcode.com/paper/deploying-deep-reinforcement-learning-systems</link>
      <description><![CDATA[In this paper, we propose an empirical study on Stack Overflow (SO), the most popular Q&A forum for developers, to uncover and understand the challenges practitioners faced when deploying DRL systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deploying-deep-reinforcement-learning-systems</guid>
    </item>
    <item>
      <title>Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations</title>
      <link>https://paperswithcode.com/paper/topical-chat-towards-knowledge-grounded-open-1</link>
      <description><![CDATA[We introduce Topical-Chat, a knowledge-grounded human-human conversation dataset where the underlying knowledge spans 8 broad topics and conversation partners don't have explicitly defined roles, to help further research in open-domain conversational AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/topical-chat-towards-knowledge-grounded-open-1</guid>
    </item>
    <item>
      <title>IncreLoRA: Incremental Parameter Allocation Method for Parameter-Efficient Fine-tuning</title>
      <link>https://paperswithcode.com/paper/increlora-incremental-parameter-allocation</link>
      <description><![CDATA[This approach is different from the pruning method as it is not limited by the initial number of training parameters, and each parameter matrix has a higher rank upper bound for the same training overhead.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/increlora-incremental-parameter-allocation</guid>
    </item>
    <item>
      <title>The TYC Dataset for Understanding Instance-Level Semantics and Motions of Cells in Microstructures</title>
      <link>https://paperswithcode.com/paper/the-tyc-dataset-for-understanding-instance</link>
      <description><![CDATA[In this paper, we introduce the trapped yeast cell (TYC) dataset, a novel dataset for understanding instance-level semantics and motions of cells in microstructures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-tyc-dataset-for-understanding-instance</guid>
    </item>
    <item>
      <title>CLIPN for Zero-Shot OOD Detection: Teaching CLIP to Say No</title>
      <link>https://paperswithcode.com/paper/clipn-for-zero-shot-ood-detection-teaching</link>
      <description><![CDATA[Subsequently, we introduce two loss functions: the image-text binary-opposite loss and the text semantic-opposite loss, which we use to teach CLIPN to associate images with no prompts, thereby enabling it to identify unknown samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clipn-for-zero-shot-ood-detection-teaching</guid>
    </item>
    <item>
      <title>CgT-GAN: CLIP-guided Text GAN for Image Captioning</title>
      <link>https://paperswithcode.com/paper/cgt-gan-clip-guided-text-gan-for-image</link>
      <description><![CDATA[Particularly, we use adversarial training to teach CgT-GAN to mimic the phrases of an external text corpus and CLIP-based reward to provide semantic guidance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cgt-gan-clip-guided-text-gan-for-image</guid>
    </item>
    <item>
      <title>The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection</title>
      <link>https://paperswithcode.com/paper/the-challenges-of-machine-learning-for-trust</link>
      <description><![CDATA[We systematize literature on automated detection of misinformation across a corpus of 270 well-cited papers in the field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-challenges-of-machine-learning-for-trust</guid>
    </item>
    <item>
      <title>Towards Privacy-Supporting Fall Detection via Deep Unsupervised RGB2Depth Adaptation</title>
      <link>https://paperswithcode.com/paper/towards-privacy-supporting-fall-detection-via</link>
      <description><![CDATA[In this paper, we introduce a privacy-supporting solution that makes the RGB-trained model applicable in depth domain and utilizes depth data at test time for fall detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-privacy-supporting-fall-detection-via</guid>
    </item>
  </channel>
</rss>
