<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 05 Feb 2024 09:12:11 +0000</lastBuildDate>
    <item>
      <title>ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution</title>
      <link>https://paperswithcode.com/paper/reevo-large-language-models-as-hyper</link>
      <description><![CDATA[The omnipresence of NP-hard combinatorial optimization problems (COPs) compels domain experts to engage in trial-and-error heuristic design process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reevo-large-language-models-as-hyper</guid>
    </item>
    <item>
      <title>KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases</title>
      <link>https://paperswithcode.com/paper/kb-plugin-a-plug-and-play-framework-for-large</link>
      <description><![CDATA[Secondly, KB-Plugin utilizes abundant annotated data from a rich-resourced KB to train another pluggable module, namely PI plugin, which can help the LLM extract question-relevant schema information from the schema plugin of any KB and utilize this information to induce programs over this KB.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kb-plugin-a-plug-and-play-framework-for-large</guid>
    </item>
    <item>
      <title>Target inductive methods for zero-shot regression</title>
      <link>https://paperswithcode.com/paper/target-inductive-methods-for-zero-shot</link>
      <description><![CDATA[Considering the surrounding information as side information facilitates the generalization for predicting pollutants in new stations, leading to a zero-shot regression scenario.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/target-inductive-methods-for-zero-shot</guid>
    </item>
    <item>
      <title>Deep Multimodal Fusion of Data with Heterogeneous Dimensionality via Projective Networks</title>
      <link>https://paperswithcode.com/paper/deep-multimodal-fusion-of-data-with</link>
      <description><![CDATA[The use of multimodal imaging has led to significant improvements in the diagnosis and treatment of many diseases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-multimodal-fusion-of-data-with</guid>
    </item>
    <item>
      <title>SiMA-Hand: Boosting 3D Hand-Mesh Reconstruction by Single-to-Multi-View Adaptation</title>
      <link>https://paperswithcode.com/paper/sima-hand-boosting-3d-hand-mesh</link>
      <description><![CDATA[Estimating 3D hand mesh from RGB images is a longstanding track, in which occlusion is one of the most challenging problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sima-hand-boosting-3d-hand-mesh</guid>
    </item>
    <item>
      <title>GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/games-mesh-based-adapting-and-modification-of</link>
      <description><![CDATA[Furthermore, we demonstrate that in the absence of a predefined mesh, it is possible to fine-tune the initial mesh during the learning process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/games-mesh-based-adapting-and-modification-of</guid>
    </item>
    <item>
      <title>MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models</title>
      <link>https://paperswithcode.com/paper/magdi-structured-distillation-of-multi-agent</link>
      <description><![CDATA[Experiments on seven widely-used commonsense and math reasoning benchmarks show that MAGDi improves the reasoning capabilities of smaller models, outperforming several methods that distill from a single teacher and multiple teachers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magdi-structured-distillation-of-multi-agent</guid>
    </item>
    <item>
      <title>cmaes : A Simple yet Practical Python Library for CMA-ES</title>
      <link>https://paperswithcode.com/paper/cmaes-a-simple-yet-practical-python-library</link>
      <description><![CDATA[To address the need for an accessible yet potent tool in this domain, we developed cmaes, a simple and practical Python library for CMA-ES.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cmaes-a-simple-yet-practical-python-library</guid>
    </item>
    <item>
      <title>Simulator-Free Visual Domain Randomization via Video Games</title>
      <link>https://paperswithcode.com/paper/simulator-free-visual-domain-randomization</link>
      <description><![CDATA[In a more challenging setting, BehAVE manages to improve the zero-shot transferability of foundation models to unseen FPS games (up to 22%) even when trained on a game of a different genre (Minecraft).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simulator-free-visual-domain-randomization</guid>
    </item>
    <item>
      <title>PokéLLMon: A Human-Parity Agent for Pokémon Battles with Large Language Models</title>
      <link>https://paperswithcode.com/paper/pokellmon-a-human-parity-agent-for-pokemon</link>
      <description><![CDATA[We introduce \textsc{Pok\'eLLMon}, the first LLM-embodied agent that achieves human-parity performance in tactical battle games, as demonstrated in Pok\'emon battles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pokellmon-a-human-parity-agent-for-pokemon</guid>
    </item>
    <item>
      <title>TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution</title>
      <link>https://paperswithcode.com/paper/trustagent-towards-safe-and-trustworthy-llm</link>
      <description><![CDATA[This paper presents an Agent-Constitution-based agent framework, TrustAgent, an initial investigation into improving the safety dimension of trustworthiness in LLM-based agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trustagent-towards-safe-and-trustworthy-llm</guid>
    </item>
    <item>
      <title>Streaming Sequence Transduction through Dynamic Compression</title>
      <link>https://paperswithcode.com/paper/streaming-sequence-transduction-through</link>
      <description><![CDATA[We introduce STAR (Stream Transduction with Anchor Representations), a novel Transformer-based model designed for efficient sequence-to-sequence transduction over streams.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streaming-sequence-transduction-through</guid>
    </item>
    <item>
      <title>L2G2G: a Scalable Local-to-Global Network Embedding with Graph Autoencoders</title>
      <link>https://paperswithcode.com/paper/l2g2g-a-scalable-local-to-global-network</link>
      <description><![CDATA[For analysing real-world networks, graph representation learning is a popular tool.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/l2g2g-a-scalable-local-to-global-network</guid>
    </item>
    <item>
      <title>Immersive Video Compression using Implicit Neural Representations</title>
      <link>https://paperswithcode.com/paper/immersive-video-compression-using-implicit</link>
      <description><![CDATA[In this paper we, for the first time, extend their application to immersive (multi-view) videos, by proposing MV-HiNeRV, a new INR-based immersive video codec.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/immersive-video-compression-using-implicit</guid>
    </item>
    <item>
      <title>Code-Switched Language Identification is Harder Than You Think</title>
      <link>https://paperswithcode.com/paper/code-switched-language-identification-is</link>
      <description><![CDATA[Code switching (CS) is a very common phenomenon in written and spoken communication but one that is handled poorly by many natural language processing applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/code-switched-language-identification-is</guid>
    </item>
    <item>
      <title>Vaccine: Perturbation-aware Alignment for Large Language Model</title>
      <link>https://paperswithcode.com/paper/vaccine-perturbation-aware-alignment-for</link>
      <description><![CDATA[The new paradigm of finetuning-as-a-service introduces a new attack surface for Large Language Models (LLMs): a few harmful data uploaded by users can easily trick the finetuning to produce an alignment-broken model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vaccine-perturbation-aware-alignment-for</guid>
    </item>
    <item>
      <title>Privacy-Preserving Distributed Learning for Residential Short-Term Load Forecasting</title>
      <link>https://paperswithcode.com/paper/privacy-preserving-distributed-learning-for</link>
      <description><![CDATA[In the realm of power systems, the increasing involvement of residential users in load forecasting applications has heightened concerns about data privacy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/privacy-preserving-distributed-learning-for</guid>
    </item>
    <item>
      <title>A general framework for rotation invariant point cloud analysis</title>
      <link>https://paperswithcode.com/paper/a-general-framework-for-rotation-invariant</link>
      <description><![CDATA[We propose a general method for deep learning based point cloud analysis, which is invariant to rotation on the inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-general-framework-for-rotation-invariant</guid>
    </item>
    <item>
      <title>Direct side information learning for zero-shot regression</title>
      <link>https://paperswithcode.com/paper/direct-side-information-learning-for-zero</link>
      <description><![CDATA[Then, they aggregate those observed target models afterwards exploiting the target side information and the models for the unobserved targets are induced.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct-side-information-learning-for-zero</guid>
    </item>
    <item>
      <title>Climbing the Ladder of Interpretability with Counterfactual Concept Bottleneck Models</title>
      <link>https://paperswithcode.com/paper/climbing-the-ladder-of-interpretability-with</link>
      <description><![CDATA["), and imagine alternative scenarios that could result in different predictions (the "What if?").]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/climbing-the-ladder-of-interpretability-with</guid>
    </item>
    <item>
      <title>SMLP: Symbolic Machine Learning Prover</title>
      <link>https://paperswithcode.com/paper/smlp-symbolic-machine-learning-prover</link>
      <description><![CDATA[Symbolic Machine Learning Prover (SMLP) is a tool and a library for system exploration based on data samples obtained by simulating or executing the system on a number of input vectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smlp-symbolic-machine-learning-prover</guid>
    </item>
    <item>
      <title>AutoGCN -- Towards Generic Human Activity Recognition with Neural Architecture Search</title>
      <link>https://paperswithcode.com/paper/autogcn-towards-generic-human-activity</link>
      <description><![CDATA[This paper introduces AutoGCN, a generic Neural Architecture Search (NAS) algorithm for Human Activity Recognition (HAR) using Graph Convolution Networks (GCNs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autogcn-towards-generic-human-activity</guid>
    </item>
    <item>
      <title>Online conformal prediction with decaying step sizes</title>
      <link>https://paperswithcode.com/paper/online-conformal-prediction-with-decaying</link>
      <description><![CDATA[We introduce a method for online conformal prediction with decaying step sizes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/online-conformal-prediction-with-decaying</guid>
    </item>
    <item>
      <title>Nomic Embed: Training a Reproducible Long Context Text Embedder</title>
      <link>https://paperswithcode.com/paper/nomic-embed-training-a-reproducible-long</link>
      <description><![CDATA[This technical report describes the training of nomic-embed-text-v1, the first fully reproducible, open-source, open-weights, open-data, 8192 context length English text embedding model that outperforms both OpenAI Ada-002 and OpenAI text-embedding-3-small on short and long-context tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nomic-embed-training-a-reproducible-long</guid>
    </item>
    <item>
      <title>Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation to Enhance Coverage of Minorities</title>
      <link>https://paperswithcode.com/paper/chameleon-foundation-models-for-fairness</link>
      <description><![CDATA[The potential harms of the under-representation of minorities in training data, particularly in multi-modal settings, is a well-recognized concern.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chameleon-foundation-models-for-fairness</guid>
    </item>
    <item>
      <title>Can MLLMs Perform Text-to-Image In-Context Learning?</title>
      <link>https://paperswithcode.com/paper/can-mllms-perform-text-to-image-in-context</link>
      <description><![CDATA[The evolution from Large Language Models (LLMs) to Multimodal Large Language Models (MLLMs) has spurred research into extending In-Context Learning (ICL) to its multimodal counterpart.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-mllms-perform-text-to-image-in-context</guid>
    </item>
    <item>
      <title>Deep Conditional Generative Learning: Model and Error Analysis</title>
      <link>https://paperswithcode.com/paper/deep-conditional-generative-learning-model</link>
      <description><![CDATA[We introduce an Ordinary Differential Equation (ODE) based deep generative method for learning a conditional distribution, named the Conditional Follmer Flow.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-conditional-generative-learning-model</guid>
    </item>
    <item>
      <title>Deep Continuous Networks</title>
      <link>https://paperswithcode.com/paper/deep-continuous-networks-1</link>
      <description><![CDATA[CNNs and computational models of biological vision share some fundamental principles, which opened new avenues of research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-continuous-networks-1</guid>
    </item>
    <item>
      <title>Convolution kernel adaptation to calibrated fisheye</title>
      <link>https://paperswithcode.com/paper/convolution-kernel-adaptation-to-calibrated</link>
      <description><![CDATA[Convolution kernels are the basic structural component of convolutional neural networks (CNNs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/convolution-kernel-adaptation-to-calibrated</guid>
    </item>
    <item>
      <title>DeepAAT: Deep Automated Aerial Triangulation for Fast UAV-based Mapping</title>
      <link>https://paperswithcode.com/paper/deepaat-deep-automated-aerial-triangulation</link>
      <description><![CDATA[The experimental results demonstrate DeepAAT's substantial improvements over conventional AAT methods, highlighting its potential in the efficiency and accuracy of UAV-based 3D reconstruction tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepaat-deep-automated-aerial-triangulation</guid>
    </item>
    <item>
      <title>LIR: Efficient Degradation Removal for Lightweight Image Restoration</title>
      <link>https://paperswithcode.com/paper/lir-efficient-degradation-removal-for</link>
      <description><![CDATA[These works often focus on the basic block design and stack numerous basic blocks to the model, leading to redundant parameters and unnecessary computations and hindering the efficiency of the image restoration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lir-efficient-degradation-removal-for</guid>
    </item>
    <item>
      <title>On Measuring Context Utilization in Document-Level MT Systems</title>
      <link>https://paperswithcode.com/paper/on-measuring-context-utilization-in-document</link>
      <description><![CDATA[We propose to complement accuracy-based evaluation with measures of context utilization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-measuring-context-utilization-in-document</guid>
    </item>
    <item>
      <title>Few-Shot Class-Incremental Learning with Prior Knowledge</title>
      <link>https://paperswithcode.com/paper/few-shot-class-incremental-learning-with</link>
      <description><![CDATA[To tackle the issues of catastrophic forgetting and overfitting in few-shot class-incremental learning (FSCIL), previous work has primarily concentrated on preserving the memory of old knowledge during the incremental phase.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/few-shot-class-incremental-learning-with</guid>
    </item>
    <item>
      <title>A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation</title>
      <link>https://paperswithcode.com/paper/a-comparative-analysis-of-conversational</link>
      <description><![CDATA[In this study, we conduct an empirical analysis of conversational large language models in generating natural language text from semantic triples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparative-analysis-of-conversational</guid>
    </item>
    <item>
      <title>Source-Free Unsupervised Domain Adaptation with Hypothesis Consolidation of Prediction Rationale</title>
      <link>https://paperswithcode.com/paper/source-free-unsupervised-domain-adaptation-3</link>
      <description><![CDATA[Source-Free Unsupervised Domain Adaptation (SFUDA) is a challenging task where a model needs to be adapted to a new domain without access to target domain labels or source domain data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/source-free-unsupervised-domain-adaptation-3</guid>
    </item>
    <item>
      <title>Bayesian Deep Learning for Remaining Useful Life Estimation via Stein Variational Gradient Descent</title>
      <link>https://paperswithcode.com/paper/bayesian-deep-learning-for-remaining-useful</link>
      <description><![CDATA[In particular, we show through experimental studies on simulated run-to-failure turbofan engine degradation data that Bayesian deep learning models trained via Stein variational gradient descent consistently outperform with respect to convergence speed and predictive performance both the same models trained via parametric variational inference and their frequentist counterparts trained via backpropagation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bayesian-deep-learning-for-remaining-useful</guid>
    </item>
    <item>
      <title>HyperPlanes: Hypernetwork Approach to Rapid NeRF Adaptation</title>
      <link>https://paperswithcode.com/paper/hyperplanes-hypernetwork-approach-to-rapid</link>
      <description><![CDATA[Neural radiance fields (NeRFs) are a widely accepted standard for synthesizing new 3D object views from a small number of base images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyperplanes-hypernetwork-approach-to-rapid</guid>
    </item>
    <item>
      <title>A Comprehensive Survey on 3D Content Generation</title>
      <link>https://paperswithcode.com/paper/a-comprehensive-survey-on-3d-content</link>
      <description><![CDATA[Recent years have witnessed remarkable advances in artificial intelligence generated content(AIGC), with diverse input modalities, e. g., text, image, video, audio and 3D.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comprehensive-survey-on-3d-content</guid>
    </item>
    <item>
      <title>Style Vectors for Steering Generative Large Language Model</title>
      <link>https://paperswithcode.com/paper/style-vectors-for-steering-generative-large</link>
      <description><![CDATA[This research explores strategies for steering the output of large language models (LLMs) towards specific styles, such as sentiment, emotion, or writing style, by adding style vectors to the activations of hidden layers during text generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/style-vectors-for-steering-generative-large</guid>
    </item>
    <item>
      <title>DeepBranchTracer: A Generally-Applicable Approach to Curvilinear Structure Reconstruction Using Multi-Feature Learning</title>
      <link>https://paperswithcode.com/paper/deepbranchtracer-a-generally-applicable</link>
      <description><![CDATA[Curvilinear structures, which include line-like continuous objects, are fundamental geometrical elements in image-based applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepbranchtracer-a-generally-applicable</guid>
    </item>
    <item>
      <title>CABINET: Content Relevance based Noise Reduction for Table Question Answering</title>
      <link>https://paperswithcode.com/paper/cabinet-content-relevance-based-noise</link>
      <description><![CDATA[Typically, only a small part of the whole table is relevant to derive the answer for a given question.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cabinet-content-relevance-based-noise</guid>
    </item>
    <item>
      <title>Cheating Suffix: Targeted Attack to Text-To-Image Diffusion Models with Multi-Modal Priors</title>
      <link>https://paperswithcode.com/paper/cheating-suffix-targeted-attack-to-text-to</link>
      <description><![CDATA[The MMP-Attack shows a notable advantage over existing works with superior universality and transferability, which can effectively attack commercial text-to-image (T2I) models such as DALL-E 3.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cheating-suffix-targeted-attack-to-text-to</guid>
    </item>
    <item>
      <title>KTO: Model Alignment as Prospect Theoretic Optimization</title>
      <link>https://paperswithcode.com/paper/kto-model-alignment-as-prospect-theoretic</link>
      <description><![CDATA[Kahneman & Tversky's $\textit{prospect theory}$ tells us that humans perceive random variables in a biased but well-defined manner; for example, humans are famously loss-averse.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kto-model-alignment-as-prospect-theoretic</guid>
    </item>
    <item>
      <title>Root Cause Analysis In Microservice Using Neural Granger Causal Discovery</title>
      <link>https://paperswithcode.com/paper/root-cause-analysis-in-microservice-using</link>
      <description><![CDATA[To address these challenges, we propose RUN, a novel approach for root cause analysis using neural Granger causal discovery with contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/root-cause-analysis-in-microservice-using</guid>
    </item>
    <item>
      <title>Skip $\textbackslash n$: A simple method to reduce hallucination in Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/skip-textbackslash-n-a-simple-method-to</link>
      <description><![CDATA[Recent advancements in large vision-language models (LVLMs) have demonstrated impressive capability in visual information understanding with human language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/skip-textbackslash-n-a-simple-method-to</guid>
    </item>
    <item>
      <title>Automating Sound Change Prediction for Phylogenetic Inference: A Tukanoan Case Study</title>
      <link>https://paperswithcode.com/paper/automating-sound-change-prediction-for</link>
      <description><![CDATA[We describe a set of new methods to partially automate linguistic phylogenetic inference given (1) cognate sets with their respective protoforms and sound laws, (2) a mapping from phones to their articulatory features and (3) a typological database of sound changes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automating-sound-change-prediction-for</guid>
    </item>
    <item>
      <title>Visual Gyroscope: Combination of Deep Learning Features and Direct Alignment for Panoramic Stabilization</title>
      <link>https://paperswithcode.com/paper/visual-gyroscope-combination-of-deep-learning</link>
      <description><![CDATA[In this article we present a visual gyroscope based on equirectangular panoramas.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-gyroscope-combination-of-deep-learning</guid>
    </item>
    <item>
      <title>Zero-Shot Machine Unlearning at Scale via Lipschitz Regularization</title>
      <link>https://paperswithcode.com/paper/zero-shot-machine-unlearning-at-scale-via</link>
      <description><![CDATA[The key challenge in unlearning is forgetting the necessary data in a timely manner, while preserving model performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-machine-unlearning-at-scale-via</guid>
    </item>
    <item>
      <title>Flexible Variational Information Bottleneck: Achieving Diverse Compression with a Single Training</title>
      <link>https://paperswithcode.com/paper/flexible-variational-information-bottleneck</link>
      <description><![CDATA[We theoretically demonstrate that across all values of reasonable $\beta$, FVIB can simultaneously maximize an approximation of the objective function for Variational Information Bottleneck (VIB), the conventional IB method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flexible-variational-information-bottleneck</guid>
    </item>
    <item>
      <title>Can you see me now? Blind spot estimation for autonomous vehicles using scenario-based simulation with random reference sensors</title>
      <link>https://paperswithcode.com/paper/can-you-see-me-now-blind-spot-estimation-for</link>
      <description><![CDATA[In this paper, we introduce a method for estimating blind spots for sensor setups of autonomous or automated vehicles and/or robotics applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-you-see-me-now-blind-spot-estimation-for</guid>
    </item>
  </channel>
</rss>
