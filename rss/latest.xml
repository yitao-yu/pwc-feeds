<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 13 Jul 2025 09:21:51 +0000</lastBuildDate>
    <item>
      <title>JointRank: Rank Large Set with Single Pass</title>
      <link>https://paperswithcode.com/paper/jointrank-rank-large-set-with-single-pass</link>
      <description><![CDATA[Finally, these comparisons are aggregated to construct a global ranking using algorithms such as Winrate or PageRank.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jointrank-rank-large-set-with-single-pass</guid>
    </item>
    <item>
      <title>Out-of-Distribution Semantic Occupancy Prediction</title>
      <link>https://paperswithcode.com/paper/out-of-distribution-semantic-occupancy</link>
      <description><![CDATA[We introduce OccOoD, a novel framework integrating OoD detection into 3D semantic occupancy prediction, with Voxel-BEV Progressive Fusion (VBPF) leveraging an RWKV-based branch to enhance OoD detection via geometry-semantic fusion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/out-of-distribution-semantic-occupancy</guid>
    </item>
    <item>
      <title>Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation</title>
      <link>https://paperswithcode.com/paper/beyond-reactive-safety-risk-aware-llm</link>
      <description><![CDATA[Given the growing influence of language model-based agents on high-stakes societal decisions, from public policy to healthcare, ensuring their beneficial impact requires understanding the far-reaching implications of their suggestions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-reactive-safety-risk-aware-llm</guid>
    </item>
    <item>
      <title>Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?</title>
      <link>https://paperswithcode.com/paper/unveiling-causal-reasoning-in-large-language</link>
      <description><![CDATA[Causal reasoning capability is critical in advancing large language models (LLMs) toward strong artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unveiling-causal-reasoning-in-large-language</guid>
    </item>
    <item>
      <title>RecCoT: Enhancing Recommendation via Chain-of-Thought</title>
      <link>https://paperswithcode.com/paper/reccot-enhancing-recommendation-via-chain-of</link>
      <description><![CDATA[In real-world applications, users always interact with items in multiple aspects, such as through implicit binary feedback (e. g., clicks, dislikes, long views) and explicit feedback (e. g., comments, reviews).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reccot-enhancing-recommendation-via-chain-of</guid>
    </item>
    <item>
      <title>ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation</title>
      <link>https://paperswithcode.com/paper/reme-a-data-centric-framework-for-training</link>
      <description><![CDATA[Training-free open-vocabulary semantic segmentation (OVS) aims to segment images given a set of arbitrary textual categories without costly model fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reme-a-data-centric-framework-for-training</guid>
    </item>
    <item>
      <title>Class-Agnostic Region-of-Interest Matching in Document Images</title>
      <link>https://paperswithcode.com/paper/class-agnostic-region-of-interest-matching-in</link>
      <description><![CDATA[Document understanding and analysis have received a lot of attention due to their widespread application.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/class-agnostic-region-of-interest-matching-in</guid>
    </item>
    <item>
      <title>Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends</title>
      <link>https://paperswithcode.com/paper/parallels-between-vla-model-post-training-and</link>
      <description><![CDATA[VLA model post-training aims to address the challenge of improving an embodiment's ability to interact with the environment for the given tasks, analogous to the process of humans motor skills acquisition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parallels-between-vla-model-post-training-and</guid>
    </item>
    <item>
      <title>Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation</title>
      <link>https://paperswithcode.com/paper/transformer-based-spatial-temporal</link>
      <description><![CDATA[This paper proposes a novel framework for estimating counterfactual outcomes with spatial-temporal attributes using the Transformer, exhibiting stronger estimation ability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-based-spatial-temporal</guid>
    </item>
    <item>
      <title>OracleFusion: Assisting the Decipherment of Oracle Bone Script with Structurally Constrained Semantic Typography</title>
      <link>https://paperswithcode.com/paper/oraclefusion-assisting-the-decipherment-of</link>
      <description><![CDATA[As one of the earliest ancient languages, Oracle Bone Script (OBS) encapsulates the cultural records and intellectual expressions of ancient civilizations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oraclefusion-assisting-the-decipherment-of</guid>
    </item>
    <item>
      <title>Discovering multiple antibiotic resistance phenotypes using diverse top-k subgroup list discovery</title>
      <link>https://paperswithcode.com/paper/discovering-multiple-antibiotic-resistance</link>
      <description><![CDATA[The discovery of multiple patient phenotypes for the same medical phenomenon would be useful in such cases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/discovering-multiple-antibiotic-resistance</guid>
    </item>
    <item>
      <title>Robust Deep Learning for Myocardial Scar Segmentation in Cardiac MRI with Noisy Labels</title>
      <link>https://paperswithcode.com/paper/robust-deep-learning-for-myocardial-scar</link>
      <description><![CDATA[The accurate segmentation of myocardial scars from cardiac MRI is essential for clinical assessment and treatment planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-deep-learning-for-myocardial-scar</guid>
    </item>
    <item>
      <title>EraRAG: Efficient and Incremental Retrieval Augmented Generation for Growing Corpora</title>
      <link>https://paperswithcode.com/paper/erarag-efficient-and-incremental-retrieval</link>
      <description><![CDATA[Graph-based Retrieval-Augmented Generation (Graph-RAG) enhances large language models (LLMs) by structuring retrieval over an external corpus.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/erarag-efficient-and-incremental-retrieval</guid>
    </item>
    <item>
      <title>Learning to Skip the Middle Layers of Transformers</title>
      <link>https://paperswithcode.com/paper/learning-to-skip-the-middle-layers-of</link>
      <description><![CDATA[Conditional computation is a popular strategy to make Transformers more efficient.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-skip-the-middle-layers-of</guid>
    </item>
    <item>
      <title>Task-Aware KV Compression For Cost-Effective Long Video Understanding</title>
      <link>https://paperswithcode.com/paper/task-aware-kv-compression-for-cost-effective</link>
      <description><![CDATA[The first one is called bi-level KV compression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/task-aware-kv-compression-for-cost-effective</guid>
    </item>
    <item>
      <title>Learning to See in the Extremely Dark</title>
      <link>https://paperswithcode.com/paper/learning-to-see-in-the-extremely-dark</link>
      <description><![CDATA[Learning-based methods have made promising advances in low-light RAW image enhancement, while their capability to extremely dark scenes where the environmental illuminance drops as low as 0. 0001 lux remains to be explored due to the lack of corresponding datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-see-in-the-extremely-dark</guid>
    </item>
    <item>
      <title>TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding</title>
      <link>https://paperswithcode.com/paper/tablemoe-neuro-symbolic-routing-for</link>
      <description><![CDATA[To address these challenges, we propose TableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture specifically designed for robust, structured reasoning over multimodal table data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tablemoe-neuro-symbolic-routing-for</guid>
    </item>
    <item>
      <title>FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing</title>
      <link>https://paperswithcode.com/paper/fasta-fast-slow-toolpath-agent-with</link>
      <description><![CDATA[The reusable symbolic subroutines considerably save exploration cost on the same types of subtasks applied to similar images, yielding a human-like fast-slow toolpath agent "FaSTA$^*$'': fast subtask planning followed by rule-based subroutine selection per subtask is attempted by LLMs at first, which is expected to cover most tasks, while slow A$^*$ search is only triggered for novel and challenging subtasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fasta-fast-slow-toolpath-agent-with</guid>
    </item>
    <item>
      <title>Amortizing personalization in virtual brain twins</title>
      <link>https://paperswithcode.com/paper/amortizing-personalization-in-virtual-brain</link>
      <description><![CDATA[Virtual brain twins are personalized digital models of individual human subject or patient's brains, allowing for mechanistic interpretation of neuroimaging data features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/amortizing-personalization-in-virtual-brain</guid>
    </item>
    <item>
      <title>FedSC: Federated Learning with Semantic-Aware Collaboration</title>
      <link>https://paperswithcode.com/paper/fedsc-federated-learning-with-semantic-aware</link>
      <description><![CDATA[To explore the possibility of using intra-client semantically meaningful knowledge in handling data heterogeneity, in this paper, we propose Federated Learning with Semantic-Aware Collaboration (FedSC) to capture client-specific and class-relevant knowledge across heterogeneous clients.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedsc-federated-learning-with-semantic-aware</guid>
    </item>
    <item>
      <title>Homogenization of Multi-agent Learning Dynamics in Finite-state Markov Games</title>
      <link>https://paperswithcode.com/paper/homogenization-of-multi-agent-learning</link>
      <description><![CDATA[This paper introduces a new approach for approximating the learning dynamics of multiple reinforcement learning (RL) agents interacting in a finite-state Markov game.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/homogenization-of-multi-agent-learning</guid>
    </item>
    <item>
      <title>Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability</title>
      <link>https://paperswithcode.com/paper/boosting-domain-generalized-and-adaptive</link>
      <description><![CDATA[We propose to tackle these problems by extracting intermediate features from a single-step diffusion process, improving feature collection and fusion to reduce inference time by 75% while enhancing performance on source domains (i. e., Fitness).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-domain-generalized-and-adaptive</guid>
    </item>
    <item>
      <title>AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG Classification</title>
      <link>https://paperswithcode.com/paper/agtcnet-a-graph-temporal-approach-for</link>
      <description><![CDATA[Brain-computer interface (BCI) technology utilizing electroencephalography (EEG) marks a transformative innovation, empowering motor-impaired individuals to engage with their environment on equal footing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agtcnet-a-graph-temporal-approach-for</guid>
    </item>
    <item>
      <title>Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation</title>
      <link>https://paperswithcode.com/paper/unlocking-constraints-source-free-occlusion</link>
      <description><![CDATA[To address these, we introduce a more practical task, i. e., Source-Free Occlusion-Aware Seamless Segmentation (SFOASS), and propose its first solution, called UNconstrained Learning Omni-Context Knowledge (UNLOCK).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlocking-constraints-source-free-occlusion</guid>
    </item>
    <item>
      <title>Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference</title>
      <link>https://paperswithcode.com/paper/scalable-bayesian-low-rank-adaptation-of</link>
      <description><![CDATA[Furthermore, it allows us to scale up to the largest Bayesian LLM to date, with four times as a many base parameters as prior work.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-bayesian-low-rank-adaptation-of</guid>
    </item>
    <item>
      <title>A Hierarchical Deep Learning Approach for Minority Instrument Detection</title>
      <link>https://paperswithcode.com/paper/a-hierarchical-deep-learning-approach-for</link>
      <description><![CDATA[Identifying instrument activities within audio excerpts is vital in music information retrieval, with significant implications for music cataloging and discovery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-hierarchical-deep-learning-approach-for</guid>
    </item>
    <item>
      <title>FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language</title>
      <link>https://paperswithcode.com/paper/fineweb2-one-pipeline-to-scale-them-all</link>
      <description><![CDATA[Pre-training state-of-the-art large language models (LLMs) requires vast amounts of clean and diverse text data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fineweb2-one-pipeline-to-scale-them-all</guid>
    </item>
    <item>
      <title>Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents</title>
      <link>https://paperswithcode.com/paper/agent-rewardbench-towards-a-unified-benchmark</link>
      <description><![CDATA[It allows for the assessment of agent capabilities at the individual steps of a task, providing a more granular view of performance during the planning process; and (3) Appropriately difficulty and high-quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agent-rewardbench-towards-a-unified-benchmark</guid>
    </item>
    <item>
      <title>PsyLite Technical Report</title>
      <link>https://paperswithcode.com/paper/psylite-technical-report</link>
      <description><![CDATA[With the rapid development of digital technology, AI-driven psychological counseling has gradually become an important research direction in the field of mental health.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/psylite-technical-report</guid>
    </item>
    <item>
      <title>Model State Arithmetic for Machine Unlearning</title>
      <link>https://paperswithcode.com/paper/model-state-arithmetic-for-machine-unlearning</link>
      <description><![CDATA[Large language models are trained on massive corpora of web data, which may include private data, copyrighted material, factually inaccurate data, or data that degrades model performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/model-state-arithmetic-for-machine-unlearning</guid>
    </item>
    <item>
      <title>Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts</title>
      <link>https://paperswithcode.com/paper/latent-prototype-routing-achieving-near</link>
      <description><![CDATA[Mixture-of-Experts (MoE) architectures have emerged as a key strategy for scaling large language models (LLMs) efficiently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-prototype-routing-achieving-near</guid>
    </item>
    <item>
      <title>Complexity-aware fine-tuning</title>
      <link>https://paperswithcode.com/paper/complexity-aware-fine-tuning</link>
      <description><![CDATA[General-purpose Large Language Models (LLMs) are frequently fine-tuned through supervised fine-tuning (SFT) to enhance performance in specific domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/complexity-aware-fine-tuning</guid>
    </item>
    <item>
      <title>"What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets</title>
      <link>https://paperswithcode.com/paper/what-s-up-doc-analyzing-how-users-seek-health</link>
      <description><![CDATA[People are increasingly seeking healthcare information from large language models (LLMs) via interactive chatbots, yet the nature and inherent risks of these conversations remain largely unexplored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-s-up-doc-analyzing-how-users-seek-health</guid>
    </item>
    <item>
      <title>HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context</title>
      <link>https://paperswithcode.com/paper/humanomniv2-from-understanding-to-omni-modal</link>
      <description><![CDATA[With the rapid evolution of multimodal large language models, the capacity to deeply understand and interpret human intentions has emerged as a critical capability, which demands detailed and thoughtful reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/humanomniv2-from-understanding-to-omni-modal</guid>
    </item>
    <item>
      <title>HyperSORT: Self-Organising Robust Training with hyper-networks</title>
      <link>https://paperswithcode.com/paper/hypersort-self-organising-robust-training</link>
      <description><![CDATA[Medical imaging datasets often contain heterogeneous biases ranging from erroneous labels to inconsistent labeling styles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hypersort-self-organising-robust-training</guid>
    </item>
    <item>
      <title>Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology</title>
      <link>https://paperswithcode.com/paper/style-aligned-image-composition-for-robust</link>
      <description><![CDATA[This paper proposes a style-aligned image composition (SAIC) method that composes high-fidelity and style-preserved pathological images to enhance the effectiveness and robustness of detection models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/style-aligned-image-composition-for-robust</guid>
    </item>
    <item>
      <title>XVerse: Consistent Multi-Subject Control of Identity and Semantic Attributes via DiT Modulation</title>
      <link>https://paperswithcode.com/paper/xverse-consistent-multi-subject-control-of</link>
      <description><![CDATA[Achieving fine-grained control over subject identity and semantic attributes (pose, style, lighting) in text-to-image generation, particularly for multiple subjects, often undermines the editability and coherence of Diffusion Transformers (DiTs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xverse-consistent-multi-subject-control-of</guid>
    </item>
    <item>
      <title>Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks</title>
      <link>https://paperswithcode.com/paper/maintaining-mteb-towards-long-term-usability</link>
      <description><![CDATA[The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation platform for text embedding models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maintaining-mteb-towards-long-term-usability</guid>
    </item>
    <item>
      <title>DrishtiKon: Multi-Granular Visual Grounding for Text-Rich Document Images</title>
      <link>https://paperswithcode.com/paper/drishtikon-multi-granular-visual-grounding</link>
      <description><![CDATA[Visual grounding in text-rich document images is a critical yet underexplored challenge for document intelligence and visual question answering (VQA) systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drishtikon-multi-granular-visual-grounding</guid>
    </item>
    <item>
      <title>LLaVA-Pose: Enhancing Human Pose and Action Understanding via Keypoint-Integrated Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/llava-pose-enhancing-human-pose-and-action</link>
      <description><![CDATA[We fine-tune the LLaVA-1. 5-7B model using this dataset and evaluate our resulting LLaVA-Pose model on the benchmark, achieving significant improvements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llava-pose-enhancing-human-pose-and-action</guid>
    </item>
    <item>
      <title>Antibody Design and Optimization with Multi-scale Equivariant Graph Diffusion Models for Accurate Complex Antigen Binding</title>
      <link>https://paperswithcode.com/paper/antibody-design-and-optimization-with-multi</link>
      <description><![CDATA[Antibody design remains a critical challenge in therapeutic and diagnostic development, particularly for complex antigens with diverse binding interfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/antibody-design-and-optimization-with-multi</guid>
    </item>
    <item>
      <title>Towards Reliable Detection of Empty Space: Conditional Marked Point Processes for Object Detection</title>
      <link>https://paperswithcode.com/paper/towards-reliable-detection-of-empty-space</link>
      <description><![CDATA[Even with well calibrated predictions, object detectors fail to quantify uncertainty outside detected bounding boxes, i. e., the model does not make a probability assessment of whether an area without detected objects is truly free of obstacles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-reliable-detection-of-empty-space</guid>
    </item>
    <item>
      <title>G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation</title>
      <link>https://paperswithcode.com/paper/g-2-d-boosting-multimodal-learning-with</link>
      <description><![CDATA[Multimodal learning aims to leverage information from diverse data modalities to achieve more comprehensive performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/g-2-d-boosting-multimodal-learning-with</guid>
    </item>
    <item>
      <title>Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration</title>
      <link>https://paperswithcode.com/paper/mitigating-hallucination-of-large-vision</link>
      <description><![CDATA[Large Vision-Language Models (LVLMs) have demonstrated significant advancements in multimodal understanding, yet they are frequently hampered by hallucination-the generation of text that contradicts visual input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mitigating-hallucination-of-large-vision</guid>
    </item>
    <item>
      <title>Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation</title>
      <link>https://paperswithcode.com/paper/benchmarking-deep-learning-and-vision</link>
      <description><![CDATA[Atypical mitoses mark a deviation in the cell division process that can be an independent prognostically relevant marker for tumor malignancy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-deep-learning-and-vision</guid>
    </item>
    <item>
      <title>How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE</title>
      <link>https://paperswithcode.com/paper/how-good-are-synthetic-requirements</link>
      <description><![CDATA[We investigate four research questions assessing how prompting strategies, automated prompt optimization, and post-generation curation affect data quality across four classification tasks: defect detection, functional vs. non-functional, quality vs. non-quality, and security vs. non-security.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-good-are-synthetic-requirements</guid>
    </item>
    <item>
      <title>FairyGen: Storied Cartoon Video from a Single Child-Drawn Character</title>
      <link>https://paperswithcode.com/paper/fairygen-storied-cartoon-video-from-a-single</link>
      <description><![CDATA[To ensure visual consistency, we introduce a style propagation adapter that captures the character's visual style and applies it to the background, faithfully retaining the character's full visual identity while synthesizing style-consistent scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fairygen-storied-cartoon-video-from-a-single</guid>
    </item>
    <item>
      <title>LASFNet: A Lightweight Attention-Guided Self-Modulation Feature Fusion Network for Multimodal Object Detection</title>
      <link>https://paperswithcode.com/paper/lasfnet-a-lightweight-attention-guided-self</link>
      <description><![CDATA[Based on this approach, we propose a lightweight attention-guided self-modulation feature fusion network (LASFNet), which introduces a novel attention-guided self-modulation feature fusion (ASFF) module that adaptively adjusts the responses of fusion features at both global and local levels based on attention information from different modalities, thereby promoting comprehensive and enriched feature generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lasfnet-a-lightweight-attention-guided-self</guid>
    </item>
    <item>
      <title>WorldVLA: Towards Autoregressive Action World Model</title>
      <link>https://paperswithcode.com/paper/worldvla-towards-autoregressive-action-world</link>
      <description><![CDATA[We present WorldVLA, an autoregressive action world model that unifies action and image understanding and generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/worldvla-towards-autoregressive-action-world</guid>
    </item>
    <item>
      <title>DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding</title>
      <link>https://paperswithcode.com/paper/dbconformer-dual-branch-convolutional</link>
      <description><![CDATA[It integrates a temporal Conformer to model long-range temporal dependencies and a spatial Conformer to extract inter-channel interactions, capturing both temporal dynamics and spatial patterns in EEG signals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dbconformer-dual-branch-convolutional</guid>
    </item>
  </channel>
</rss>
