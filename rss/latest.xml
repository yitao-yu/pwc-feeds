<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 04 Jun 2024 09:15:26 +0000</lastBuildDate>
    <item>
      <title>ZeroSmooth: Training-free Diffuser Adaptation for High Frame Rate Video Generation</title>
      <link>https://paperswithcode.com/paper/zerosmooth-training-free-diffuser-adaptation</link>
      <description><![CDATA[Previous methods promote the frame rate by either training a video interpolation model in pixel space as a postprocessing stage or training an interpolation model in latent space for a specific base video model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zerosmooth-training-free-diffuser-adaptation</guid>
    </item>
    <item>
      <title>Lifting Factor Graphs with Some Unknown Factors</title>
      <link>https://paperswithcode.com/paper/lifting-factor-graphs-with-some-unknown</link>
      <description><![CDATA[Lifting exploits symmetries in probabilistic graphical models by using a representative for indistinguishable objects, allowing to carry out query answering more efficiently while maintaining exact answers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lifting-factor-graphs-with-some-unknown</guid>
    </item>
    <item>
      <title>animal2vec and MeerKAT: A self-supervised transformer for rare-event raw audio input and a large-scale reference dataset for bioacoustics</title>
      <link>https://paperswithcode.com/paper/animal2vec-and-meerkat-a-self-supervised</link>
      <description><![CDATA[Bioacoustic research provides invaluable insights into the behavior, ecology, and conservation of animals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animal2vec-and-meerkat-a-self-supervised</guid>
    </item>
    <item>
      <title>Non-destructive Degradation Pattern Decoupling for Ultra-early Battery Prototype Verification Using Physics-informed Machine Learning</title>
      <link>https://paperswithcode.com/paper/non-destructive-degradation-pattern</link>
      <description><![CDATA[Manufacturing complexities and uncertainties have impeded the transition from material prototypes to commercial batteries, making prototype verification critical to quality assessment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/non-destructive-degradation-pattern</guid>
    </item>
    <item>
      <title>Redefining Contributions: Shapley-Driven Federated Learning</title>
      <link>https://paperswithcode.com/paper/redefining-contributions-shapley-driven</link>
      <description><![CDATA[This paper proposes a novel contribution assessment method called ShapFed for fine-grained evaluation of participant contributions in FL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/redefining-contributions-shapley-driven</guid>
    </item>
    <item>
      <title>InterpreTabNet: Distilling Predictive Signals from Tabular Data by Salient Feature Interpretation</title>
      <link>https://paperswithcode.com/paper/interpretabnet-distilling-predictive-signals</link>
      <description><![CDATA[To remedy this, we propose InterpreTabNet, a variant of the TabNet model that models the attention mechanism as a latent variable sampled from a Gumbel-Softmax distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpretabnet-distilling-predictive-signals</guid>
    </item>
    <item>
      <title>Reward-based Input Construction for Cross-document Relation Extraction</title>
      <link>https://paperswithcode.com/paper/reward-based-input-construction-for-cross</link>
      <description><![CDATA[Relation extraction (RE) is a fundamental task in natural language processing, aiming to identify relations between target entities in text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reward-based-input-construction-for-cross</guid>
    </item>
    <item>
      <title>Diffusion Models Are Innate One-Step Generators</title>
      <link>https://paperswithcode.com/paper/diffusion-models-are-innate-one-step</link>
      <description><![CDATA[To address this problem, instance-based distillation methods have been proposed to distill a one-step generator from a DM by having a simpler student model mimic a more complex teacher model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-are-innate-one-step</guid>
    </item>
    <item>
      <title>MeshXL: Neural Coordinate Field for Generative 3D Foundation Models</title>
      <link>https://paperswithcode.com/paper/meshxl-neural-coordinate-field-for-generative</link>
      <description><![CDATA[The polygon mesh representation of 3D data exhibits great flexibility, fast rendering speed, and storage efficiency, which is widely preferred in various applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meshxl-neural-coordinate-field-for-generative</guid>
    </item>
    <item>
      <title>Hard Cases Detection in Motion Prediction by Vision-Language Foundation Models</title>
      <link>https://paperswithcode.com/paper/hard-cases-detection-in-motion-prediction-by</link>
      <description><![CDATA[However, the rarity and high-risk nature of these cases demand extensive, diverse datasets for training robust models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hard-cases-detection-in-motion-prediction-by</guid>
    </item>
    <item>
      <title>Cyclic image generation using chaotic dynamics</title>
      <link>https://paperswithcode.com/paper/cyclic-image-generation-using-chaotic</link>
      <description><![CDATA[The results suggest that chaotic dynamics in the image space defined by the deep generative model contribute to the diversity of the generated images, constituting a novel approach for multi-class image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cyclic-image-generation-using-chaotic</guid>
    </item>
    <item>
      <title>HOPE: A Reinforcement Learning-based Hybrid Policy Path Planner for Diverse Parking Scenarios</title>
      <link>https://paperswithcode.com/paper/hope-a-reinforcement-learning-based-hybrid</link>
      <description><![CDATA[To facilitate the training and evaluation of the proposed planner, we propose a criterion for categorizing the difficulty level of parking scenarios based on space and obstacle distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hope-a-reinforcement-learning-based-hybrid</guid>
    </item>
    <item>
      <title>Explaining Predictions by Characteristic Rules</title>
      <link>https://paperswithcode.com/paper/explaining-predictions-by-characteristic</link>
      <description><![CDATA[The results also indicate that using CEGA in combination with either SHAP or Anchors consistently leads to a higher fidelity compared to using LIME as the local explanation technique.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explaining-predictions-by-characteristic</guid>
    </item>
    <item>
      <title>Graph External Attention Enhanced Transformer</title>
      <link>https://paperswithcode.com/paper/graph-external-attention-enhanced-transformer</link>
      <description><![CDATA[The Transformer architecture has recently gained considerable attention in the field of graph representation learning, as it naturally overcomes several limitations of Graph Neural Networks (GNNs) with customized attention mechanisms or positional and structural encodings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-external-attention-enhanced-transformer</guid>
    </item>
    <item>
      <title>Power of Cooperative Supervision: Multiple Teachers Framework for Enhanced 3D Semi-Supervised Object Detection</title>
      <link>https://paperswithcode.com/paper/power-of-cooperative-supervision-multiple</link>
      <description><![CDATA[To address these two issues, we have constructed a multi-class 3D LiDAR dataset reflecting diverse urban environments and object characteristics, and developed a robust 3D semi-supervised object detection (SSOD) based on a multiple teachers framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/power-of-cooperative-supervision-multiple</guid>
    </item>
    <item>
      <title>Comparing information content of representation spaces for disentanglement with VAE ensembles</title>
      <link>https://paperswithcode.com/paper/comparing-information-content-of</link>
      <description><![CDATA[Disentanglement is the endeavour to use machine learning to divide information about a dataset into meaningful fragments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comparing-information-content-of</guid>
    </item>
    <item>
      <title>OpenTensor: Reproducing Faster Matrix Multiplication Discovering Algorithms</title>
      <link>https://paperswithcode.com/paper/opentensor-reproducing-faster-matrix</link>
      <description><![CDATA[OpenTensor is a reproduction of AlphaTensor, which discovered a new algorithm that outperforms the state-of-the-art methods for matrix multiplication by Deep Reinforcement Learning (DRL).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/opentensor-reproducing-faster-matrix</guid>
    </item>
    <item>
      <title>Position Coupling: Leveraging Task Structure for Improved Length Generalization of Transformers</title>
      <link>https://paperswithcode.com/paper/position-coupling-leveraging-task-structure</link>
      <description><![CDATA[Even for simple arithmetic tasks like integer addition, it is challenging for Transformers to generalize to longer sequences than those encountered during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/position-coupling-leveraging-task-structure</guid>
    </item>
    <item>
      <title>Diffusion Actor-Critic: Formulating Constrained Policy Iteration as Diffusion Noise Regression for Offline Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/diffusion-actor-critic-formulating</link>
      <description><![CDATA[In this paper, we propose Diffusion Actor-Critic (DAC) that formulates the Kullback-Leibler (KL) constraint policy iteration as a diffusion noise regression problem, enabling direct representation of target policies as diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-actor-critic-formulating</guid>
    </item>
    <item>
      <title>Generalization Beyond Data Imbalance: A Controlled Study on CLIP for Transferable Insights</title>
      <link>https://paperswithcode.com/paper/generalization-beyond-data-imbalance-a</link>
      <description><![CDATA[Severe data imbalance naturally exists among web-scale vision-language datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalization-beyond-data-imbalance-a</guid>
    </item>
    <item>
      <title>Conditioning GAN Without Training Dataset</title>
      <link>https://paperswithcode.com/paper/conditioning-gan-without-training-dataset</link>
      <description><![CDATA[In this study, the aim is to address the question, "Given an unconditioned pretrained generator network and a pretrained classifier, is it feasible to develop a conditioned generator without relying on any training dataset?"]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conditioning-gan-without-training-dataset</guid>
    </item>
    <item>
      <title>Improved Techniques for Optimization-Based Jailbreaking on Large Language Models</title>
      <link>https://paperswithcode.com/paper/improved-techniques-for-optimization-based</link>
      <description><![CDATA[Many red-teaming efforts aim to jailbreak LLMs, where among these efforts, the Greedy Coordinate Gradient (GCG) attack's success has led to a growing interest in the study of optimization-based jailbreaking techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-techniques-for-optimization-based</guid>
    </item>
    <item>
      <title>einspace: Searching for Neural Architectures from Fundamental Operations</title>
      <link>https://paperswithcode.com/paper/einspace-searching-for-neural-architectures</link>
      <description><![CDATA[Using this search space, we perform experiments to find novel architectures as well as improvements on existing ones on the diverse Unseen NAS datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/einspace-searching-for-neural-architectures</guid>
    </item>
    <item>
      <title>ABodyBuilder3: Improved and scalable antibody structure predictions</title>
      <link>https://paperswithcode.com/paper/abodybuilder3-improved-and-scalable-antibody</link>
      <description><![CDATA[Accurate prediction of antibody structure is a central task in the design and development of monoclonal antibodies, notably to understand both their developability and their binding properties.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/abodybuilder3-improved-and-scalable-antibody</guid>
    </item>
    <item>
      <title>In-Context Decision Transformer: Reinforcement Learning via Hierarchical Chain-of-Thought</title>
      <link>https://paperswithcode.com/paper/in-context-decision-transformer-reinforcement</link>
      <description><![CDATA[Recent works demonstrated that in-context RL could emerge with self-improvement in a trial-and-error manner when treating RL tasks as an across-episodic sequential prediction problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/in-context-decision-transformer-reinforcement</guid>
    </item>
    <item>
      <title>Popularity-Aware Alignment and Contrast for Mitigating Popularity Bias</title>
      <link>https://paperswithcode.com/paper/popularity-aware-alignment-and-contrast-for</link>
      <description><![CDATA[To alleviate popularity bias, existing efforts focus on emphasizing unpopular items or separating the correlation between item representations and their popularity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/popularity-aware-alignment-and-contrast-for</guid>
    </item>
    <item>
      <title>Revisiting and Maximizing Temporal Knowledge in Semi-supervised Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/revisiting-and-maximizing-temporal-knowledge</link>
      <description><![CDATA[The PrevMatch framework relies on two core strategies: (1) we reconsider the use of temporal knowledge and thus directly utilize previous models obtained during training to generate additional pseudo-label guidance, referred to as previous guidance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-and-maximizing-temporal-knowledge</guid>
    </item>
    <item>
      <title>Large Language Models are Zero-Shot Next Location Predictors</title>
      <link>https://paperswithcode.com/paper/large-language-models-are-zero-shot-next</link>
      <description><![CDATA[Moreover, we show that other LLMs are unable to perform the task properly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-are-zero-shot-next</guid>
    </item>
    <item>
      <title>SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales</title>
      <link>https://paperswithcode.com/paper/sayself-teaching-llms-to-express-confidence</link>
      <description><![CDATA[Large language models (LLMs) often generate inaccurate or fabricated information and generally fail to indicate their confidence, which limits their broader applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sayself-teaching-llms-to-express-confidence</guid>
    </item>
    <item>
      <title>Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality</title>
      <link>https://paperswithcode.com/paper/transformers-are-ssms-generalized-models-and</link>
      <description><![CDATA[While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformers-are-ssms-generalized-models-and</guid>
    </item>
    <item>
      <title>Amortizing intractable inference in diffusion models for vision, language, and control</title>
      <link>https://paperswithcode.com/paper/amortizing-intractable-inference-in-diffusion</link>
      <description><![CDATA[Diffusion models have emerged as effective distribution estimators in vision, language, and reinforcement learning, but their use as priors in downstream tasks poses an intractable posterior inference problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/amortizing-intractable-inference-in-diffusion</guid>
    </item>
    <item>
      <title>MASA: Motion-aware Masked Autoencoder with Semantic Alignment for Sign Language Recognition</title>
      <link>https://paperswithcode.com/paper/masa-motion-aware-masked-autoencoder-with</link>
      <description><![CDATA[To this end, we propose a Motion-Aware masked autoencoder with Semantic Alignment (MASA) that integrates rich motion cues and global semantic information in a self-supervised learning paradigm for SLR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masa-motion-aware-masked-autoencoder-with</guid>
    </item>
    <item>
      <title>ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model</title>
      <link>https://paperswithcode.com/paper/contextgs-compact-3d-gaussian-splatting-with</link>
      <description><![CDATA[Recently, 3D Gaussian Splatting (3DGS) has become a promising framework for novel view synthesis, offering fast rendering speeds and high fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contextgs-compact-3d-gaussian-splatting-with</guid>
    </item>
    <item>
      <title>MegActor: Harness the Power of Raw Video for Vivid Portrait Animation</title>
      <link>https://paperswithcode.com/paper/megactor-harness-the-power-of-raw-video-for</link>
      <description><![CDATA[Despite raw driving videos contain richer information on facial expressions than intermediate representations such as landmarks in the field of portrait animation, they are seldom the subject of research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/megactor-harness-the-power-of-raw-video-for</guid>
    </item>
    <item>
      <title>Learning Gaze-aware Compositional GAN</title>
      <link>https://paperswithcode.com/paper/learning-gaze-aware-compositional-gan</link>
      <description><![CDATA[In this work, we present a generative framework to create annotated gaze data by leveraging the benefits of labeled and unlabeled data sources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-gaze-aware-compositional-gan</guid>
    </item>
    <item>
      <title>Share Your Secrets for Privacy! Confidential Forecasting with Vertical Federated Learning</title>
      <link>https://paperswithcode.com/paper/share-your-secrets-for-privacy-confidential</link>
      <description><![CDATA[We address those challenges and propose 'Secret-shared Time Series Forecasting with VFL' (STV), a novel framework that exhibits the following key features: i) a privacy-preserving algorithm for forecasting with SARIMAX and autoregressive trees on vertically partitioned data; ii) serverless forecasting using secret sharing and multi-party computation; iii) novel N-party algorithms for matrix multiplication and inverse operations for direct parameter optimization, giving strong convergence with minimal hyperparameter tuning complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/share-your-secrets-for-privacy-confidential</guid>
    </item>
    <item>
      <title>Adv-KD: Adversarial Knowledge Distillation for Faster Diffusion Sampling</title>
      <link>https://paperswithcode.com/paper/adv-kd-adversarial-knowledge-distillation-for</link>
      <description><![CDATA[Diffusion Probabilistic Models (DPMs) have emerged as a powerful class of deep generative models, achieving remarkable performance in image synthesis tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adv-kd-adversarial-knowledge-distillation-for</guid>
    </item>
    <item>
      <title>SelfGNN: Self-Supervised Graph Neural Networks for Sequential Recommendation</title>
      <link>https://paperswithcode.com/paper/selfgnn-self-supervised-graph-neural-networks</link>
      <description><![CDATA[Firstly, existing sequential models primarily focus on long-term modeling of individual interaction sequences, overlooking the valuable short-term collaborative relationships among the behaviors of different users.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/selfgnn-self-supervised-graph-neural-networks</guid>
    </item>
    <item>
      <title>LACIE: Listener-Aware Finetuning for Confidence Calibration in Large Language Models</title>
      <link>https://paperswithcode.com/paper/lacie-listener-aware-finetuning-for</link>
      <description><![CDATA[To calibrate both implicit and explicit confidence markers, we introduce a pragmatic, listener-aware finetuning method (LACIE) that models the listener, considering not only whether an answer is right, but whether it will be accepted by a listener.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lacie-listener-aware-finetuning-for</guid>
    </item>
    <item>
      <title>Faces of the Mind: Unveiling Mental Health States Through Facial Expressions in 11,427 Adolescents</title>
      <link>https://paperswithcode.com/paper/faces-of-the-mind-unveiling-mental-health</link>
      <description><![CDATA[Mood disorders, including depression and anxiety, often manifest through facial expressions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/faces-of-the-mind-unveiling-mental-health</guid>
    </item>
    <item>
      <title>Robust Kernel Hypothesis Testing under Data Corruption</title>
      <link>https://paperswithcode.com/paper/robust-kernel-hypothesis-testing-under-data</link>
      <description><![CDATA[We propose two general methods for constructing robust permutation tests under data corruption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-kernel-hypothesis-testing-under-data</guid>
    </item>
    <item>
      <title>Near Optimal Decentralized Optimization with Compression and Momentum Tracking</title>
      <link>https://paperswithcode.com/paper/near-optimal-decentralized-optimization-with</link>
      <description><![CDATA[Communication efficiency has garnered significant attention as it is considered the main bottleneck for large-scale decentralized Machine Learning applications in distributed and federated settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/near-optimal-decentralized-optimization-with</guid>
    </item>
    <item>
      <title>MCDS-VSS: Moving Camera Dynamic Scene Video Semantic Segmentation by Filtering with Self-Supervised Geometry and Motion</title>
      <link>https://paperswithcode.com/paper/mcds-vss-moving-camera-dynamic-scene-video</link>
      <description><![CDATA[Autonomous systems, such as self-driving cars, rely on reliable semantic environment perception for decision making.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mcds-vss-moving-camera-dynamic-scene-video</guid>
    </item>
    <item>
      <title>Language Models Need Inductive Biases to Count Inductively</title>
      <link>https://paperswithcode.com/paper/language-models-need-inductive-biases-to</link>
      <description><![CDATA[We find that while traditional RNNs trivially achieve inductive counting, Transformers have to rely on positional embeddings to count out-of-domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-need-inductive-biases-to</guid>
    </item>
    <item>
      <title>Grokfast: Accelerated Grokking by Amplifying Slow Gradients</title>
      <link>https://paperswithcode.com/paper/grokfast-accelerated-grokking-by-amplifying</link>
      <description><![CDATA[One puzzling artifact in machine learning dubbed grokking is where delayed generalization is achieved tenfolds of iterations after near perfect overfitting to the training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grokfast-accelerated-grokking-by-amplifying</guid>
    </item>
    <item>
      <title>Landslide mapping from Sentinel-2 imagery through change detection</title>
      <link>https://paperswithcode.com/paper/landslide-mapping-from-sentinel-2-imagery</link>
      <description><![CDATA[Landslides are one of the most critical and destructive geohazards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/landslide-mapping-from-sentinel-2-imagery</guid>
    </item>
    <item>
      <title>Open-Set Domain Adaptation for Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/open-set-domain-adaptation-for-semantic</link>
      <description><![CDATA[Unsupervised domain adaptation (UDA) for semantic segmentation aims to transfer the pixel-wise knowledge from the labeled source domain to the unlabeled target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-set-domain-adaptation-for-semantic</guid>
    </item>
    <item>
      <title>Two Optimizers Are Better Than One: LLM Catalyst for Enhancing Gradient-Based Optimization</title>
      <link>https://paperswithcode.com/paper/two-optimizers-are-better-than-one-llm</link>
      <description><![CDATA[Learning a skill generally relies on both practical experience by doer and insightful high-level guidance by instructor.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/two-optimizers-are-better-than-one-llm</guid>
    </item>
    <item>
      <title>Multi-Aspect Controllable Text Generation with Disentangled Counterfactual Augmentation</title>
      <link>https://paperswithcode.com/paper/multi-aspect-controllable-text-generation</link>
      <description><![CDATA[We alleviate the issue of imbalanced attribute correlations during training using counterfactual feature vectors in the attribute latent space by disentanglement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-aspect-controllable-text-generation</guid>
    </item>
    <item>
      <title>Improving the Training of Rectified Flows</title>
      <link>https://paperswithcode.com/paper/improving-the-training-of-rectified-flows</link>
      <description><![CDATA[In this work, we propose improved techniques for training rectified flows, allowing them to compete with knowledge distillation methods even in the low NFE setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-the-training-of-rectified-flows</guid>
    </item>
  </channel>
</rss>
