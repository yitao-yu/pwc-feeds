<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 24 Aug 2024 09:13:07 +0000</lastBuildDate>
    <item>
      <title>EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts</title>
      <link>https://paperswithcode.com/paper/evalyaks-instruction-tuning-datasets-and-lora</link>
      <description><![CDATA[In addition, new instruction-tuned datasets are developed from the English Vocabulary Profile (up to CEFR B2 level) and the CEFR-SP WikiAuto datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evalyaks-instruction-tuning-datasets-and-lora</guid>
    </item>
    <item>
      <title>Real-Time Video Generation with Pyramid Attention Broadcast</title>
      <link>https://paperswithcode.com/paper/real-time-video-generation-with-pyramid</link>
      <description><![CDATA[We present Pyramid Attention Broadcast (PAB), a real-time, high quality and training-free approach for DiT-based video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-video-generation-with-pyramid</guid>
    </item>
    <item>
      <title>Tackling Data Heterogeneity in Federated Learning via Loss Decomposition</title>
      <link>https://paperswithcode.com/paper/tackling-data-heterogeneity-in-federated-1</link>
      <description><![CDATA[To mitigate the impact of data heterogeneity on FL performance, we start with analyzing how FL training influence FL performance by decomposing the global loss into three terms: local loss, distribution shift loss and aggregation loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tackling-data-heterogeneity-in-federated-1</guid>
    </item>
    <item>
      <title>ssProp: Energy-Efficient Training for Convolutional Neural Networks with Scheduled Sparse Back Propagation</title>
      <link>https://paperswithcode.com/paper/ssprop-energy-efficient-training-for</link>
      <description><![CDATA[Back-propagation (BP) is a major source of computational expense during training deep learning models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ssprop-energy-efficient-training-for</guid>
    </item>
    <item>
      <title>Generalized SAM: Efficient Fine-Tuning of SAM for Variable Input Image Sizes</title>
      <link>https://paperswithcode.com/paper/generalized-sam-efficient-fine-tuning-of-sam</link>
      <description><![CDATA[The input image size of SAM is fixed at 1024 x 1024, resulting in substantial computational demands during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-sam-efficient-fine-tuning-of-sam</guid>
    </item>
    <item>
      <title>Aligning (Medical) LLMs for (Counterfactual) Fairness</title>
      <link>https://paperswithcode.com/paper/aligning-medical-llms-for-counterfactual</link>
      <description><![CDATA[Large Language Models (LLMs) have emerged as promising solutions for a variety of medical and clinical decision support applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-medical-llms-for-counterfactual</guid>
    </item>
    <item>
      <title>SPARK: Multi-Vision Sensor Perception and Reasoning Benchmark for Large-scale Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/spark-multi-vision-sensor-perception-and</link>
      <description><![CDATA[However, we observe that current LVLMs view images taken from multi-vision sensors as if they were in the same RGB domain without considering the physical characteristics of multi-vision sensors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spark-multi-vision-sensor-perception-and</guid>
    </item>
    <item>
      <title>MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents</title>
      <link>https://paperswithcode.com/paper/mdd-5k-a-new-diagnostic-conversation-dataset</link>
      <description><![CDATA[By applying the proposed framework, we develop the largest Chinese mental disorders diagnosis dataset MDD-5k, which is built upon 1000 cleaned real patient cases by cooperating with a pioneering psychiatric hospital, and contains 5000 high-quality long conversations with diagnosis results as labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mdd-5k-a-new-diagnostic-conversation-dataset</guid>
    </item>
    <item>
      <title>ISETHDR: A Physics-based Synthetic Radiance Dataset for High Dynamic Range Driving Scenes</title>
      <link>https://paperswithcode.com/paper/isethdr-a-physics-based-synthetic-radiance</link>
      <description><![CDATA[This paper describes a physics-based end-to-end software simulation for image systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/isethdr-a-physics-based-synthetic-radiance</guid>
    </item>
    <item>
      <title>Fair Augmentation for Graph Collaborative Filtering</title>
      <link>https://paperswithcode.com/paper/fair-augmentation-for-graph-collaborative</link>
      <description><![CDATA[Despite emerging regulations addressing fairness of automated systems, unfairness issues in graph collaborative filtering remain underexplored, especially from the consumer's perspective.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fair-augmentation-for-graph-collaborative</guid>
    </item>
    <item>
      <title>FlexEdit: Marrying Free-Shape Masks to VLLM for Flexible Image Editing</title>
      <link>https://paperswithcode.com/paper/flexedit-marrying-free-shape-masks-to-vllm</link>
      <description><![CDATA[Our approach employs a VLLM in comprehending the image content, mask, and user instructions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flexedit-marrying-free-shape-masks-to-vllm</guid>
    </item>
    <item>
      <title>Accounts of using the Tustin-Net architecture on a rotary inverted pendulum</title>
      <link>https://paperswithcode.com/paper/accounts-of-using-the-tustin-net-architecture</link>
      <description><![CDATA[In this report we investigate the use of the Tustin neural network architecture (Tustin-Net) for the identification of a physical rotary inverse pendulum.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accounts-of-using-the-tustin-net-architecture</guid>
    </item>
    <item>
      <title>A Riemannian Approach for Spatiotemporal Analysis and Generation of 4D Tree-shaped Structures</title>
      <link>https://paperswithcode.com/paper/a-riemannian-approach-for-spatiotemporal</link>
      <description><![CDATA[In this paper, we propose a novel mathematical representation of the shape space of such trajectories, a Riemannian metric on that space, and computational tools for fast and accurate spatiotemporal registration and geodesics computation between 4D tree-shaped structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-riemannian-approach-for-spatiotemporal</guid>
    </item>
    <item>
      <title>Unlocking Attributes' Contribution to Successful Camouflage: A Combined Textual and VisualAnalysis Strategy</title>
      <link>https://paperswithcode.com/paper/unlocking-attributes-contribution-to</link>
      <description><![CDATA[In the domain of Camouflaged Object Segmentation (COS), despite continuous improvements in segmentation performance, the underlying mechanisms of effective camouflage remain poorly understood, akin to a black box.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlocking-attributes-contribution-to</guid>
    </item>
    <item>
      <title>Multiple testing for signal-agnostic searches of new physics with machine learning</title>
      <link>https://paperswithcode.com/paper/multiple-testing-for-signal-agnostic-searches</link>
      <description><![CDATA[In this work, we address the question of how to enhance signal-agnostic searches by leveraging multiple testing strategies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiple-testing-for-signal-agnostic-searches</guid>
    </item>
    <item>
      <title>WCEbleedGen: A wireless capsule endoscopy dataset and its benchmarking for automatic bleeding classification, detection, and segmentation</title>
      <link>https://paperswithcode.com/paper/wcebleedgen-a-wireless-capsule-endoscopy</link>
      <description><![CDATA[However, a medically annotated WCE dataset for training and evaluation of automatic classification, detection, and segmentation of bleeding and non-bleeding frames is currently lacking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wcebleedgen-a-wireless-capsule-endoscopy</guid>
    </item>
    <item>
      <title>Reasoning Factual Knowledge in Structured Data with Large Language Models</title>
      <link>https://paperswithcode.com/paper/reasoning-factual-knowledge-in-structured</link>
      <description><![CDATA[This benchmark allows us to investigate the capability of LLMs across five factual tasks derived from the unique characteristics of structural facts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reasoning-factual-knowledge-in-structured</guid>
    </item>
    <item>
      <title>Controllable Text Generation for Large Language Models: A Survey</title>
      <link>https://paperswithcode.com/paper/controllable-text-generation-for-large</link>
      <description><![CDATA[This paper systematically reviews the latest advancements in CTG for LLMs, offering a comprehensive definition of its core concepts and clarifying the requirements for control conditions and text quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controllable-text-generation-for-large</guid>
    </item>
    <item>
      <title>Scalable Autoregressive Image Generation with Mamba</title>
      <link>https://paperswithcode.com/paper/scalable-autoregressive-image-generation-with</link>
      <description><![CDATA[On the ImageNet1K 256*256 benchmark, our best AiM model achieves a FID of 2. 21, surpassing all existing AR models of comparable parameter counts and demonstrating significant competitiveness against diffusion models, with 2 to 10 times faster inference speed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-autoregressive-image-generation-with</guid>
    </item>
    <item>
      <title>UMERegRobust -- Universal Manifold Embedding Compatible Features for Robust Point Cloud Registration</title>
      <link>https://paperswithcode.com/paper/umeregrobust-universal-manifold-embedding</link>
      <description><![CDATA[We extend the UME framework by introducing a UME-compatible feature extraction method augmented with a unique UME contrastive loss and a sampling equalizer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/umeregrobust-universal-manifold-embedding</guid>
    </item>
    <item>
      <title>Show-o: One Single Transformer to Unify Multimodal Understanding and Generation</title>
      <link>https://paperswithcode.com/paper/show-o-one-single-transformer-to-unify</link>
      <description><![CDATA[We present a unified transformer, i. e., Show-o, that unifies multimodal understanding and generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/show-o-one-single-transformer-to-unify</guid>
    </item>
    <item>
      <title>Cross-Domain Foundation Model Adaptation: Pioneering Computer Vision Models for Geophysical Data Analysis</title>
      <link>https://paperswithcode.com/paper/cross-domain-foundation-model-adaptation</link>
      <description><![CDATA[We explore adapting foundation models (FMs) from the computer vision domain to geoscience.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-domain-foundation-model-adaptation</guid>
    </item>
    <item>
      <title>DRExplainer: Quantifiable Interpretability in Drug Response Prediction with Directed Graph Convolutional Network</title>
      <link>https://paperswithcode.com/paper/drexplainer-quantifiable-interpretability-in</link>
      <description><![CDATA[DRExplainer constructs a directed bipartite network integrating multi-omics profiles of cell lines, the chemical structure of drugs and known drug response to achieve directed prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drexplainer-quantifiable-interpretability-in</guid>
    </item>
    <item>
      <title>Behavior Pattern Mining-based Multi-Behavior Recommendation</title>
      <link>https://paperswithcode.com/paper/behavior-pattern-mining-based-multi-behavior</link>
      <description><![CDATA[Multi-behavior recommendation systems enhance effectiveness by leveraging auxiliary behaviors (such as page views and favorites) to address the limitations of traditional models that depend solely on sparse target behaviors like purchases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/behavior-pattern-mining-based-multi-behavior</guid>
    </item>
    <item>
      <title>Towards Evaluating and Building Versatile Large Language Models for Medicine</title>
      <link>https://paperswithcode.com/paper/towards-evaluating-and-building-versatile</link>
      <description><![CDATA[To promote further advancements in the application of LLMs to clinical challenges, we have made the MedS-Ins dataset fully accessible and invite the research community to contribute to its expansion. Additionally, we have launched a dynamic leaderboard for MedS-Bench, which we plan to regularly update the test set to track progress and enhance the adaptation of general LLMs to the medical domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-evaluating-and-building-versatile</guid>
    </item>
    <item>
      <title>CODE: Confident Ordinary Differential Editing</title>
      <link>https://paperswithcode.com/paper/code-confident-ordinary-differential-editing</link>
      <description><![CDATA[However, conditioning on noisy or Out-of-Distribution (OoD) images poses significant challenges, particularly in balancing fidelity to the input and realism of the output.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/code-confident-ordinary-differential-editing</guid>
    </item>
    <item>
      <title>Efficient Multivariate Time Series Anomaly Detection Through Transfer Learning for Large-Scale Web services</title>
      <link>https://paperswithcode.com/paper/efficient-multivariate-time-series-anomaly</link>
      <description><![CDATA[Large language models (LLMs) excel at general question-answering (Q&A) but often fall short in specialized domains due to a lack of domain-specific knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-multivariate-time-series-anomaly</guid>
    </item>
    <item>
      <title>GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models</title>
      <link>https://paperswithcode.com/paper/gendercare-a-comprehensive-framework-for</link>
      <description><![CDATA[By offering a realistic assessment and tailored reduction of gender biases, we hope that our GenderCARE can represent a significant step towards achieving fairness and equity in LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gendercare-a-comprehensive-framework-for</guid>
    </item>
    <item>
      <title>UMAD: University of Macau Anomaly Detection Benchmark Dataset</title>
      <link>https://paperswithcode.com/paper/umad-university-of-macau-anomaly-detection</link>
      <description><![CDATA[To our best knowledge, this is the first benchmark dataset designed specifically for anomaly detection with reference in robotic patrolling scenarios, e. g., where an autonomous robot is employed to detect anomalous objects by comparing a reference and a query video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/umad-university-of-macau-anomaly-detection</guid>
    </item>
    <item>
      <title>A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language</title>
      <link>https://paperswithcode.com/paper/a-percolation-model-of-emergence-analyzing</link>
      <description><![CDATA[Increase in data, size, or compute can lead to sudden learning of specific capabilities by a neural network -- a phenomenon often called "emergence".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-percolation-model-of-emergence-analyzing</guid>
    </item>
    <item>
      <title>Unrolled Decomposed Unpaired Learning for Controllable Low-Light Video Enhancement</title>
      <link>https://paperswithcode.com/paper/unrolled-decomposed-unpaired-learning-for</link>
      <description><![CDATA[To address the above challenge, we propose the Unrolled Decomposed Unpaired Network (UDU-Net) for enhancing low-light videos by unrolling the optimization functions into a deep network to decompose the signal into spatial and temporal-related factors, which are updated iteratively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unrolled-decomposed-unpaired-learning-for</guid>
    </item>
    <item>
      <title>Interactive DualChecker for Mitigating Hallucinations in Distilling Large Language Models</title>
      <link>https://paperswithcode.com/paper/interactive-dualchecker-for-mitigating</link>
      <description><![CDATA[Additionally, current methods for knowledge distillation using LLMs often struggle to enhance the effectiveness of both teacher and student models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interactive-dualchecker-for-mitigating</guid>
    </item>
    <item>
      <title>Adaptive Spiking Neural Networks with Hybrid Coding</title>
      <link>https://paperswithcode.com/paper/adaptive-spiking-neural-networks-with-hybrid</link>
      <description><![CDATA[The Spiking Neural Network (SNN), due to its unique spiking-driven nature, is a more energy-efficient and effective neural network compared to Artificial Neural Networks (ANNs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-spiking-neural-networks-with-hybrid</guid>
    </item>
    <item>
      <title>Graph Retrieval Augmented Trustworthiness Reasoning</title>
      <link>https://paperswithcode.com/paper/graph-retrieval-augmented-trustworthiness</link>
      <description><![CDATA[Trustworthiness reasoning is crucial in multiplayer games with incomplete information, enabling agents to identify potential allies and adversaries, thereby enhancing reasoning and decision-making processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-retrieval-augmented-trustworthiness</guid>
    </item>
    <item>
      <title>T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval</title>
      <link>https://paperswithcode.com/paper/t2vindexer-a-generative-video-indexer-for</link>
      <description><![CDATA[To enhance retrieval efficiency, in this paper, we introduce a model-based video indexer named T2VIndexer, which is a sequence-to-sequence generative model directly generating video identifiers and retrieving candidate videos with constant time complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t2vindexer-a-generative-video-indexer-for</guid>
    </item>
    <item>
      <title>MoE-LPR: Multilingual Extension of Large Language Models through Mixture-of-Experts with Language Priors Routing</title>
      <link>https://paperswithcode.com/paper/moe-lpr-multilingual-extension-of-large</link>
      <description><![CDATA[Then, the model reviews the knowledge of the original languages with replay data amounting to less than 1% of post-pretraining, where we incorporate language priors routing to better recover the abilities of the original languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moe-lpr-multilingual-extension-of-large</guid>
    </item>
    <item>
      <title>FATE: Focal-modulated Attention Encoder for Temperature Prediction</title>
      <link>https://paperswithcode.com/paper/fate-focal-modulated-attention-encoder-for</link>
      <description><![CDATA[Our CCPD dataset also achieved a 24\% improvement in accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fate-focal-modulated-attention-encoder-for</guid>
    </item>
    <item>
      <title>XDT-CXR: Investigating Cross-Disease Transferability in Zero-Shot Binary Classification of Chest X-Rays</title>
      <link>https://paperswithcode.com/paper/xdt-cxr-investigating-cross-disease</link>
      <description><![CDATA[This study explores the concept of cross-disease transferability (XDT) in medical imaging, focusing on the potential of binary classifiers trained on one disease to perform zero-shot classification on another disease affecting the same organ.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xdt-cxr-investigating-cross-disease</guid>
    </item>
    <item>
      <title>AIM 2024 Challenge on Compressed Video Quality Assessment: Methods and Results</title>
      <link>https://paperswithcode.com/paper/aim-2024-challenge-on-compressed-video</link>
      <description><![CDATA[The challenge aimed to evaluate the performance of VQA methods on a diverse dataset of 459 videos, encoded with 14 codecs of various compression standards (AVC/H. 264, HEVC/H. 265, AV1, and VVC/H. 266) and containing a comprehensive collection of compression artifacts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aim-2024-challenge-on-compressed-video</guid>
    </item>
    <item>
      <title>Interpretable Long-term Action Quality Assessment</title>
      <link>https://paperswithcode.com/paper/interpretable-long-term-action-quality</link>
      <description><![CDATA[Long-term Action Quality Assessment (AQA) evaluates the execution of activities in videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpretable-long-term-action-quality</guid>
    </item>
    <item>
      <title>OAPT: Offset-Aware Partition Transformer for Double JPEG Artifacts Removal</title>
      <link>https://paperswithcode.com/paper/oapt-offset-aware-partition-transformer-for</link>
      <description><![CDATA[Specifically, the predictor estimates pixel offsets between the first and second compression, which are then utilized to divide different patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oapt-offset-aware-partition-transformer-for</guid>
    </item>
    <item>
      <title>An Asymptotically Optimal Coordinate Descent Algorithm for Learning Bayesian Networks from Gaussian Models</title>
      <link>https://paperswithcode.com/paper/an-asymptotically-optimal-coordinate-descent</link>
      <description><![CDATA[To the best of our knowledge, our proposal is the first coordinate descent procedure endowed with optimality and statistical guarantees in the context of learning Bayesian networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-asymptotically-optimal-coordinate-descent</guid>
    </item>
    <item>
      <title>EMO-LLaMA: Enhancing Facial Emotion Understanding with Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/emo-llama-enhancing-facial-emotion</link>
      <description><![CDATA[However, current FER paradigms face challenges in generalization, lack semantic information aligned with natural language, and struggle to process both images and videos within a unified framework, making their application in multimodal emotion understanding and human-computer interaction difficult.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emo-llama-enhancing-facial-emotion</guid>
    </item>
    <item>
      <title>Persistent Homology via Ellipsoids</title>
      <link>https://paperswithcode.com/paper/persistent-homology-via-ellipsoids</link>
      <description><![CDATA[This complex is based on the idea that ellipsoids aligned with tangent directions better approximate the data compared to conventional (Euclidean) balls centered at sample points that are used in the construction of Rips and Alpha complexes, for instance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/persistent-homology-via-ellipsoids</guid>
    </item>
    <item>
      <title>A Novel Evaluation Perspective on GNNs-based Recommender Systems through the Topology of the User-Item Graph</title>
      <link>https://paperswithcode.com/paper/a-novel-evaluation-perspective-on-gnns-based</link>
      <description><![CDATA[Recently, graph neural networks (GNNs)-based recommender systems have encountered great success in recommendation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-novel-evaluation-perspective-on-gnns-based</guid>
    </item>
    <item>
      <title>DABench: A Benchmark Dataset for Data-Driven Weather Data Assimilation</title>
      <link>https://paperswithcode.com/paper/dabench-a-benchmark-dataset-for-data-driven</link>
      <description><![CDATA[While researchers are exploring data-driven data assimilation (DA) models to generate accurate initial fields for LWMs, the lack of a standard benchmark impedes the fair evaluation among different data-driven DA algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dabench-a-benchmark-dataset-for-data-driven</guid>
    </item>
    <item>
      <title>E-Bench: Subjective-Aligned Benchmark Suite for Text-Driven Video Editing Quality Assessment</title>
      <link>https://paperswithcode.com/paper/e-bench-subjective-aligned-benchmark-suite</link>
      <description><![CDATA[To the best of our knowledge, E-Bench introduces the first quality assessment dataset for video editing and an effective subjective-aligned quantitative metric for this domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/e-bench-subjective-aligned-benchmark-suite</guid>
    </item>
    <item>
      <title>Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks</title>
      <link>https://paperswithcode.com/paper/against-all-odds-overcoming-typology-script</link>
      <description><![CDATA[Large Language Models (LLMs) are susceptible to malicious influence by cyber attackers through intrusions such as adversarial, backdoor, and embedding inversion attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/against-all-odds-overcoming-typology-script</guid>
    </item>
    <item>
      <title>Revisiting FunnyBirds evaluation framework for prototypical parts networks</title>
      <link>https://paperswithcode.com/paper/revisiting-funnybirds-evaluation-framework</link>
      <description><![CDATA[In this study, we comprehensively compare metric scores obtained for two types of ProtoPNet visualizations: bounding boxes and similarity maps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-funnybirds-evaluation-framework</guid>
    </item>
    <item>
      <title>LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems</title>
      <link>https://paperswithcode.com/paper/lahaja-a-robust-multi-accent-benchmark-for</link>
      <description><![CDATA[Hindi, one of the most spoken language of India, exhibits a diverse array of accents due to its usage among individuals from diverse linguistic origins.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lahaja-a-robust-multi-accent-benchmark-for</guid>
    </item>
  </channel>
</rss>
