<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 02 Aug 2023 21:06:05 +0000</lastBuildDate>
    <item>
      <title>Contextual Emotion Recognition Using Transformer-Based Models</title>
      <link>https://paperswithcode.com/paper/contextual-emotion-recognition-using</link>
      <description><![CDATA[In order to increase the precision of emotion identification in text, this research suggests a context-aware emotion recognition system employing transformer models, especially BERT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contextual-emotion-recognition-using</guid>
    </item>
    <item>
      <title>ViT2EEG: Leveraging Hybrid Pretrained Vision Transformers for EEG Data</title>
      <link>https://paperswithcode.com/paper/vit2eeg-leveraging-hybrid-pretrained-vision</link>
      <description><![CDATA[In this study, we demonstrate the application of a hybrid Vision Transformer (ViT) model, pretrained on ImageNet, on an electroencephalogram (EEG) regression task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vit2eeg-leveraging-hybrid-pretrained-vision</guid>
    </item>
    <item>
      <title>ZRIGF: An Innovative Multimodal Framework for Zero-Resource Image-Grounded Dialogue Generation</title>
      <link>https://paperswithcode.com/paper/zrigf-an-innovative-multimodal-framework-for</link>
      <description><![CDATA[To overcome this challenge, we propose an innovative multimodal framework, called ZRIGF, which assimilates image-grounded information for dialogue generation in zero-resource situations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zrigf-an-innovative-multimodal-framework-for</guid>
    </item>
    <item>
      <title>Deep Image Harmonization with Globally Guided Feature Transformation and Relation Distillation</title>
      <link>https://paperswithcode.com/paper/deep-image-harmonization-with-globally-guided</link>
      <description><![CDATA[Given a composite image, image harmonization aims to adjust the foreground illumination to be consistent with background.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-image-harmonization-with-globally-guided</guid>
    </item>
    <item>
      <title>Generative adversarial networks with physical sound field priors</title>
      <link>https://paperswithcode.com/paper/generative-adversarial-networks-with-physical</link>
      <description><![CDATA[This paper presents a deep learning-based approach for the spatio-temporal reconstruction of sound fields using Generative Adversarial Networks (GANs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-adversarial-networks-with-physical</guid>
    </item>
    <item>
      <title>Beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers</title>
      <link>https://paperswithcode.com/paper/beyond-one-hot-encoding-injecting-semantics</link>
      <description><![CDATA[Finally, we discuss how this approach can be further exploited in terms of explainability and adversarial robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-one-hot-encoding-injecting-semantics</guid>
    </item>
    <item>
      <title>Zero-Shot Learning by Harnessing Adversarial Samples</title>
      <link>https://paperswithcode.com/paper/zero-shot-learning-by-harnessing-adversarial</link>
      <description><![CDATA[To take the advantage of image augmentations while mitigating the semantic distortion issue, we propose a novel ZSL approach by Harnessing Adversarial Samples (HAS).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-learning-by-harnessing-adversarial</guid>
    </item>
    <item>
      <title>ZADU: A Python Library for Evaluating the Reliability of Dimensionality Reduction Embeddings</title>
      <link>https://paperswithcode.com/paper/zadu-a-python-library-for-evaluating-the</link>
      <description><![CDATA[To address this issue, we present ZADU, a Python library that provides distortion measures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zadu-a-python-library-for-evaluating-the</guid>
    </item>
    <item>
      <title>Explainable Cost-Sensitive Deep Neural Networks for Brain Tumor Detection from Brain MRI Images considering Data Imbalance</title>
      <link>https://paperswithcode.com/paper/explainable-cost-sensitive-deep-neural</link>
      <description><![CDATA[This paper presents a research study on the use of Convolutional Neural Network (CNN), ResNet50, InceptionV3, EfficientNetB0 and NASNetMobile models to efficiently detect brain tumors in order to reduce the time required for manual review of the report and create an automated system for classifying brain tumors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explainable-cost-sensitive-deep-neural</guid>
    </item>
    <item>
      <title>Human-M3: A Multi-view Multi-modal Dataset for 3D Human Pose Estimation in Outdoor Scenes</title>
      <link>https://paperswithcode.com/paper/human-m3-a-multi-view-multi-modal-dataset-for</link>
      <description><![CDATA[In this article, we propose Human-M3, an outdoor multi-modal multi-view multi-person human pose database which includes not only multi-view RGB videos of outdoor scenes but also corresponding pointclouds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/human-m3-a-multi-view-multi-modal-dataset-for</guid>
    </item>
    <item>
      <title>Tackling Hallucinations in Neural Chart Summarization</title>
      <link>https://paperswithcode.com/paper/tackling-hallucinations-in-neural-chart</link>
      <description><![CDATA[Hallucinations in text generation occur when the system produces text that is not grounded in the input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tackling-hallucinations-in-neural-chart</guid>
    </item>
    <item>
      <title>ReCoMIF: Reading comprehension based multi-source information fusion network for Chinese spoken language understanding</title>
      <link>https://paperswithcode.com/paper/recomif-reading-comprehension-based-multi</link>
      <description><![CDATA[It usually includes slot filling and intent detection (SFID) tasks aiming at semantic parsing of utterances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recomif-reading-comprehension-based-multi</guid>
    </item>
    <item>
      <title>Learning Green's Function Efficiently Using Low-Rank Approximations</title>
      <link>https://paperswithcode.com/paper/learning-green-s-function-efficiently-using</link>
      <description><![CDATA[Learning the Green's function using deep learning models enables to solve different classes of partial differential equations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-green-s-function-efficiently-using</guid>
    </item>
    <item>
      <title>An L2-Normalized Spatial Attention Network For Accurate And Fast Classification Of Brain Tumors In 2D T1-Weighted CE-MRI Images</title>
      <link>https://paperswithcode.com/paper/an-l2-normalized-spatial-attention-network</link>
      <description><![CDATA[We compare our results against the state-of-the-art on this dataset and show that by integrating l2-normalized spatial attention into a baseline network we achieve a performance gain of 1. 79 percentage points.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-l2-normalized-spatial-attention-network</guid>
    </item>
    <item>
      <title>Relational Contrastive Learning for Scene Text Recognition</title>
      <link>https://paperswithcode.com/paper/relational-contrastive-learning-for-scene</link>
      <description><![CDATA[We argue that such prior contextual information can be interpreted as the relations of textual primitives due to the heterogeneous text and background, which can provide effective self-supervised labels for representation learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relational-contrastive-learning-for-scene</guid>
    </item>
    <item>
      <title>LISA: Reasoning Segmentation via Large Language Model</title>
      <link>https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</link>
      <description><![CDATA[In this work, we propose a new segmentation task -- reasoning segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</guid>
    </item>
    <item>
      <title>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</title>
      <link>https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</link>
      <description><![CDATA[Recently, remarkable progress has been made in automated task-solving through the use of multi-agents driven by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</guid>
    </item>
    <item>
      <title>DriveAdapter: Breaking the Coupling Barrier of Perception and Planning in End-to-End Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/driveadapter-breaking-the-coupling-barrier-of</link>
      <description><![CDATA[We find that even equipped with a SOTA perception model, directly letting the student model learn the required inputs of the teacher model leads to poor driving performance, which comes from the large distribution gap between predicted privileged inputs and the ground-truth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/driveadapter-breaking-the-coupling-barrier-of</guid>
    </item>
    <item>
      <title>NormKD: Normalized Logits for Knowledge Distillation</title>
      <link>https://paperswithcode.com/paper/normkd-normalized-logits-for-knowledge</link>
      <description><![CDATA[In this paper, we restudy the hyper-parameter temperature and figure out its incapability to distill the knowledge from each sample sufficiently when it is a single value.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/normkd-normalized-logits-for-knowledge</guid>
    </item>
    <item>
      <title>A Satellite Imagery Dataset for Long-Term Sustainable Development in United States Cities</title>
      <link>https://paperswithcode.com/paper/a-satellite-imagery-dataset-for-long-term</link>
      <description><![CDATA[Especially satellite imagery is a potential data source for studying sustainable urban development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-satellite-imagery-dataset-for-long-term</guid>
    </item>
    <item>
      <title>Deep Image Harmonization with Learnable Augmentation</title>
      <link>https://paperswithcode.com/paper/deep-image-harmonization-with-learnable</link>
      <description><![CDATA[In particular, our designed SYthetic COmposite Network (SycoNet) takes in a real image with foreground mask and a random vector to learn suitable color transformation, which is applied to the foreground of this real image to produce a synthetic composite image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-image-harmonization-with-learnable</guid>
    </item>
    <item>
      <title>On the Effects of Regional Spelling Conventions in Retrieval Models</title>
      <link>https://paperswithcode.com/paper/on-the-effects-of-regional-spelling</link>
      <description><![CDATA[One advantage of neural ranking models is that they are meant to generalise well in situations of synonymity i. e. where two words have similar or identical meanings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-effects-of-regional-spelling</guid>
    </item>
    <item>
      <title>Physics-Driven Spectrum-Consistent Federated Learning for Palmprint Verification</title>
      <link>https://paperswithcode.com/paper/physics-driven-spectrum-consistent-federated</link>
      <description><![CDATA[Subsequently, we introduce anchor models for short- and long-spectrum, which constrain the optimization directions of local models associated with long- and short-spectrum images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physics-driven-spectrum-consistent-federated</guid>
    </item>
    <item>
      <title>FLatten Transformer: Vision Transformer using Focused Linear Attention</title>
      <link>https://paperswithcode.com/paper/flatten-transformer-vision-transformer-using</link>
      <description><![CDATA[The quadratic computation complexity of self-attention has been a persistent challenge when applying Transformer models to vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flatten-transformer-vision-transformer-using</guid>
    </item>
    <item>
      <title>Benchmarking Ultra-High-Definition Image Reflection Removal</title>
      <link>https://paperswithcode.com/paper/benchmarking-ultra-high-definition-image-1</link>
      <description><![CDATA[To the best of our knowledge, these two datasets are the first largest-scale UHD datasets for SIRR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-ultra-high-definition-image-1</guid>
    </item>
    <item>
      <title>Multiscale Global and Regional Feature Learning Using Co-Tuplet Loss for Offline Handwritten Signature Verification</title>
      <link>https://paperswithcode.com/paper/multiscale-global-and-regional-feature</link>
      <description><![CDATA[To address these challenges, we propose a multiscale global and regional feature learning network (MGRNet) with the co-tuplet loss, a new metric learning loss, for offline handwritten signature verification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiscale-global-and-regional-feature</guid>
    </item>
    <item>
      <title>On the Generation of a Synthetic Event-Based Vision Dataset for Navigation and Landing</title>
      <link>https://paperswithcode.com/paper/on-the-generation-of-a-synthetic-event-based</link>
      <description><![CDATA[We anticipate that novel event-based vision datasets can be generated using this pipeline to support various spacecraft pose reconstruction problems given events as input, and we hope that the proposed methodology would attract the attention of researchers working at the intersection of neuromorphic vision and guidance navigation and control.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-generation-of-a-synthetic-event-based</guid>
    </item>
    <item>
      <title>Shape Completion with Prediction of Uncertain Regions</title>
      <link>https://paperswithcode.com/paper/shape-completion-with-prediction-of-uncertain</link>
      <description><![CDATA[We train on this dataset and test each method in shape completion and prediction of uncertain regions for known and novel object instances and on synthetic and real data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shape-completion-with-prediction-of-uncertain</guid>
    </item>
    <item>
      <title>SkullGAN: Synthetic Skull CT Generation with Generative Adversarial Networks</title>
      <link>https://paperswithcode.com/paper/skullgan-synthetic-skull-ct-generation-with</link>
      <description><![CDATA[Deep learning offers potential for various healthcare applications involving the human skull but requires extensive datasets of curated medical images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/skullgan-synthetic-skull-ct-generation-with</guid>
    </item>
    <item>
      <title>Classes are not Clusters: Improving Label-based Evaluation of Dimensionality Reduction</title>
      <link>https://paperswithcode.com/paper/classes-are-not-clusters-improving-label</link>
      <description><![CDATA[In this paper, we introduce two novel quality measures -- Label-Trustworthiness and Label-Continuity (Label-T&C) -- advancing the process of DR evaluation based on class labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/classes-are-not-clusters-improving-label</guid>
    </item>
    <item>
      <title>Robust Positive-Unlabeled Learning via Noise Negative Sample Self-correction</title>
      <link>https://paperswithcode.com/paper/robust-positive-unlabeled-learning-via-noise</link>
      <description><![CDATA[To mitigate the impact of label uncertainty and improve the robustness of learning with positive and unlabeled data, we propose a new robust PU learning method with a training strategy motivated by the nature of human learning: easy cases should be learned first.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-positive-unlabeled-learning-via-noise</guid>
    </item>
    <item>
      <title>SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning</title>
      <link>https://paperswithcode.com/paper/selfcheck-using-llms-to-zero-shot-check-their</link>
      <description><![CDATA[To this end, we propose a zero-shot verification scheme to recognize such errors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/selfcheck-using-llms-to-zero-shot-check-their</guid>
    </item>
    <item>
      <title>Boundary Difference Over Union Loss For Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/boundary-difference-over-union-loss-for</link>
      <description><![CDATA[However, current losses for medical image segmentation mainly focus on overall segmentation results, with fewer losses proposed to guide boundary segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boundary-difference-over-union-loss-for</guid>
    </item>
    <item>
      <title>The Algonauts Project 2023 Challenge: UARK-UAlbany Team Solution</title>
      <link>https://paperswithcode.com/paper/the-algonauts-project-2023-challenge-uark</link>
      <description><![CDATA[The goal is to predict brain responses across the entire visual brain, as it is the region where the most reliable responses to images have been observed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-algonauts-project-2023-challenge-uark</guid>
    </item>
    <item>
      <title>Partitioned Saliency Ranking with Dense Pyramid Transformers</title>
      <link>https://paperswithcode.com/paper/partitioned-saliency-ranking-with-dense</link>
      <description><![CDATA[The ranking by partition paradigm alleviates ranking ambiguities in a general sense, as it consistently improves the performance of other saliency ranking models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/partitioned-saliency-ranking-with-dense</guid>
    </item>
    <item>
      <title>Online Prototype Learning for Online Continual Learning</title>
      <link>https://paperswithcode.com/paper/online-prototype-learning-for-online</link>
      <description><![CDATA[Online continual learning (CL) studies the problem of learning continuously from a single-pass data stream while adapting to new data and mitigating catastrophic forgetting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/online-prototype-learning-for-online</guid>
    </item>
    <item>
      <title>Fundus-Enhanced Disease-Aware Distillation Model for Retinal Disease Classification from OCT Images</title>
      <link>https://paperswithcode.com/paper/fundus-enhanced-disease-aware-distillation</link>
      <description><![CDATA[Our framework enhances the OCT model during training by utilizing unpaired fundus images and does not require the use of fundus images during testing, which greatly improves the practicality and efficiency of our method for clinical use.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fundus-enhanced-disease-aware-distillation</guid>
    </item>
    <item>
      <title>PDBImages: A Command Line Tool for Automated Macromolecular Structure Visualization</title>
      <link>https://paperswithcode.com/paper/pdbimages-a-command-line-tool-for-automated</link>
      <description><![CDATA[Availability and Implementation: PDBImages is available as an npm package from https://www. npmjs. com/package/pdb-images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pdbimages-a-command-line-tool-for-automated</guid>
    </item>
    <item>
      <title>Improving Pixel-based MIM by Reducing Wasted Modeling Capability</title>
      <link>https://paperswithcode.com/paper/improving-pixel-based-mim-by-reducing-wasted</link>
      <description><![CDATA[There has been significant progress in Masked Image Modeling (MIM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-pixel-based-mim-by-reducing-wasted</guid>
    </item>
    <item>
      <title>A Majority Invariant Approach to Patch Robustness Certification for Deep Learning Models</title>
      <link>https://paperswithcode.com/paper/a-majority-invariant-approach-to-patch</link>
      <description><![CDATA[Patch robustness certification ensures no patch within a given bound on a sample can manipulate a deep learning model to predict a different label.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-majority-invariant-approach-to-patch</guid>
    </item>
    <item>
      <title>Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis</title>
      <link>https://paperswithcode.com/paper/challenging-the-myth-of-graph-collaborative</link>
      <description><![CDATA[The success of graph neural network-based models (GNNs) has significantly advanced recommender systems by effectively modeling users and items as a bipartite, undirected graph.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/challenging-the-myth-of-graph-collaborative</guid>
    </item>
    <item>
      <title>AnyLoc: Towards Universal Visual Place Recognition</title>
      <link>https://paperswithcode.com/paper/anyloc-towards-universal-visual-place</link>
      <description><![CDATA[In this work, we develop a universal solution to VPR -- a technique that works across a broad range of structured and unstructured environments (urban, outdoors, indoors, aerial, underwater, and subterranean environments) without any re-training or fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anyloc-towards-universal-visual-place</guid>
    </item>
    <item>
      <title>Camoscio: an Italian Instruction-tuned LLaMA</title>
      <link>https://paperswithcode.com/paper/camoscio-an-italian-instruction-tuned-llama</link>
      <description><![CDATA[In recent years Large Language Models (LLMs) have increased the state of the art on several natural language processing tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camoscio-an-italian-instruction-tuned-llama</guid>
    </item>
    <item>
      <title>CBCL-PR: A Cognitively Inspired Model for Class-Incremental Learning in Robotics</title>
      <link>https://paperswithcode.com/paper/cbcl-pr-a-cognitively-inspired-model-for</link>
      <description><![CDATA[For most real-world applications, robots need to adapt and learn continually with limited data in their environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cbcl-pr-a-cognitively-inspired-model-for</guid>
    </item>
    <item>
      <title>DiffProsody: Diffusion-based Latent Prosody Generation for Expressive Speech Synthesis with Prosody Conditional Adversarial Training</title>
      <link>https://paperswithcode.com/paper/diffprosody-diffusion-based-latent-prosody</link>
      <description><![CDATA[Expressive text-to-speech systems have undergone significant advancements owing to prosody modeling, but conventional methods can still be improved.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffprosody-diffusion-based-latent-prosody</guid>
    </item>
    <item>
      <title>JOTR: 3D Joint Contrastive Learning with Transformers for Occluded Human Mesh Recovery</title>
      <link>https://paperswithcode.com/paper/jotr-3d-joint-contrastive-learning-with</link>
      <description><![CDATA[Our method includes an encoder-decoder transformer architecture to fuse 2D and 3D representations for achieving 2D$\&$3D aligned results in a coarse-to-fine manner and a novel 3D joint contrastive learning approach for adding explicitly global supervision for the 3D feature space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jotr-3d-joint-contrastive-learning-with</guid>
    </item>
    <item>
      <title>BearingPGA-Net: A Lightweight and Deployable Bearing Fault Diagnosis Network via Decoupled Knowledge Distillation and FPGA Acceleration</title>
      <link>https://paperswithcode.com/paper/bearingpga-net-a-lightweight-and-deployable</link>
      <description><![CDATA[To the best of our knowledge, this is the first instance of deploying a CNN-based bearing fault diagnosis model on an FPGA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bearingpga-net-a-lightweight-and-deployable</guid>
    </item>
    <item>
      <title>Explainable Equivariant Neural Networks for Particle Physics: PELICAN</title>
      <link>https://paperswithcode.com/paper/explainable-equivariant-neural-networks-for</link>
      <description><![CDATA[We present a comprehensive study of the PELICAN machine learning algorithm architecture in the context of both tagging (classification) and reconstructing (regression) Lorentz-boosted top quarks, including the difficult task of specifically identifying and measuring the $W$-boson inside the dense environment of the boosted hadronic final state.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explainable-equivariant-neural-networks-for</guid>
    </item>
    <item>
      <title>Classifying multilingual party manifestos: Domain transfer across country, time, and genre</title>
      <link>https://paperswithcode.com/paper/classifying-multilingual-party-manifestos</link>
      <description><![CDATA[We explore the potential of domain transfer across geographical locations, languages, time, and genre in a large-scale database of political manifestos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/classifying-multilingual-party-manifestos</guid>
    </item>
    <item>
      <title>Lightweight Super-Resolution Head for Human Pose Estimation</title>
      <link>https://paperswithcode.com/paper/lightweight-super-resolution-head-for-human</link>
      <description><![CDATA[We first propose the SR head, which predicts heatmaps with a spatial resolution higher than the input feature maps (or even consistent with the input image) by super-resolution, to effectively reduce the quantization error and the dependence on further post-processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightweight-super-resolution-head-for-human</guid>
    </item>
  </channel>
</rss>
