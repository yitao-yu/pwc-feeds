<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 26 Feb 2024 21:08:34 +0000</lastBuildDate>
    <item>
      <title>Seamless Human Motion Composition with Blended Positional Encodings</title>
      <link>https://paperswithcode.com/paper/seamless-human-motion-composition-with</link>
      <description><![CDATA[Conditional human motion generation is an important topic with many applications in virtual reality, gaming, and robotics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seamless-human-motion-composition-with</guid>
    </item>
    <item>
      <title>Let's Rectify Step by Step: Improving Aspect-based Sentiment Analysis with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/let-s-rectify-step-by-step-improving-aspect</link>
      <description><![CDATA[Aspect-Based Sentiment Analysis (ABSA) stands as a crucial task in predicting the sentiment polarity associated with identified aspects within text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-s-rectify-step-by-step-improving-aspect</guid>
    </item>
    <item>
      <title>MemoryPrompt: A Light Wrapper to Improve Context Tracking in Pre-trained Language Models</title>
      <link>https://paperswithcode.com/paper/memoryprompt-a-light-wrapper-to-improve</link>
      <description><![CDATA[Transformer-based language models (LMs) track contextual information through large, hard-coded input windows.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memoryprompt-a-light-wrapper-to-improve</guid>
    </item>
    <item>
      <title>A Data-Centric Approach To Generate Faithful and High Quality Patient Summaries with Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-data-centric-approach-to-generate-faithful</link>
      <description><![CDATA[In this work, we investigate the potential of large language models to generate patient summaries based on doctors' notes and study the effect of training data on the faithfulness and quality of the generated summaries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-data-centric-approach-to-generate-faithful</guid>
    </item>
    <item>
      <title>ChildAugment: Data Augmentation Methods for Zero-Resource Children's Speaker Verification</title>
      <link>https://paperswithcode.com/paper/childaugment-data-augmentation-methods-for</link>
      <description><![CDATA[One promising approach is to align vocal-tract parameters between adults and children through children-specific data augmentation, referred here to as ChildAugment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/childaugment-data-augmentation-methods-for</guid>
    </item>
    <item>
      <title>EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems</title>
      <link>https://paperswithcode.com/paper/easyrl4rec-a-user-friendly-code-library-for</link>
      <description><![CDATA[Reinforcement Learning (RL)-Based Recommender Systems (RSs) are increasingly recognized for their ability to improve long-term user engagement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyrl4rec-a-user-friendly-code-library-for</guid>
    </item>
    <item>
      <title>Spatially-Aware Transformer Memory for Embodied Agents</title>
      <link>https://paperswithcode.com/paper/spatially-aware-transformer-memory-for</link>
      <description><![CDATA[Adopting this approach, we demonstrate that memory utilization efficiency can be improved, leading to enhanced accuracy in various place-centric downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatially-aware-transformer-memory-for</guid>
    </item>
    <item>
      <title>GPT-HateCheck: Can LLMs Write Better Functional Tests for Hate Speech Detection?</title>
      <link>https://paperswithcode.com/paper/gpt-hatecheck-can-llms-write-better</link>
      <description><![CDATA[A recent proposal in this direction is HateCheck, a suite for testing fine-grained model functionalities on synthesized data generated using templates of the kind "You are just a [slur] to me."]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-hatecheck-can-llms-write-better</guid>
    </item>
    <item>
      <title>Farsight: Fostering Responsible AI Awareness During AI Application Prototyping</title>
      <link>https://paperswithcode.com/paper/farsight-fostering-responsible-ai-awareness</link>
      <description><![CDATA[To address this, we present Farsight, a novel in situ interactive tool that helps people identify potential harms from the AI applications they are prototyping.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/farsight-fostering-responsible-ai-awareness</guid>
    </item>
    <item>
      <title>Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition</title>
      <link>https://paperswithcode.com/paper/gen4gen-generative-data-pipeline-for</link>
      <description><![CDATA[First, current personalization techniques fail to reliably extend to multiple concepts -- we hypothesize this to be due to the mismatch between complex scenes and simple text descriptions in the pre-training dataset (e. g., LAION).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gen4gen-generative-data-pipeline-for</guid>
    </item>
    <item>
      <title>Repetition Improves Language Model Embeddings</title>
      <link>https://paperswithcode.com/paper/repetition-improves-language-model-embeddings</link>
      <description><![CDATA[In this work, we address an architectural limitation of autoregressive models: token embeddings cannot contain information from tokens that appear later in the input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repetition-improves-language-model-embeddings</guid>
    </item>
    <item>
      <title>GS-EMA: Integrating Gradient Surgery Exponential Moving Average with Boundary-Aware Contrastive Learning for Enhanced Domain Generalization in Aneurysm Segmentation</title>
      <link>https://paperswithcode.com/paper/gs-ema-integrating-gradient-surgery</link>
      <description><![CDATA[The automated segmentation of cerebral aneurysms is pivotal for accurate diagnosis and treatment planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gs-ema-integrating-gradient-surgery</guid>
    </item>
    <item>
      <title>AttributionBench: How Hard is Automatic Attribution Evaluation?</title>
      <link>https://paperswithcode.com/paper/attributionbench-how-hard-is-automatic</link>
      <description><![CDATA[Modern generative search engines enhance the reliability of large language model (LLM) responses by providing cited evidence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attributionbench-how-hard-is-automatic</guid>
    </item>
    <item>
      <title>Unsupervised Domain Adaptation for Brain Vessel Segmentation through Transwarp Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/unsupervised-domain-adaptation-for-brain</link>
      <description><![CDATA[Unsupervised domain adaptation (UDA) aims to align the labelled source distribution with the unlabelled target distribution to obtain domain-invariant predictive models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-domain-adaptation-for-brain</guid>
    </item>
    <item>
      <title>The Impact of LoRA on the Emergence of Clusters in Transformers</title>
      <link>https://paperswithcode.com/paper/the-impact-of-lora-on-the-emergence-of</link>
      <description><![CDATA[In this paper, we employ the mathematical framework on Transformers developed by \citet{sander2022sinkformers, geshkovski2023emergence, geshkovski2023mathematical} to explore how variations in attention parameters and initial token values impact the structural dynamics of token clusters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-impact-of-lora-on-the-emergence-of</guid>
    </item>
    <item>
      <title>Source-Guided Similarity Preservation for Online Person Re-Identification</title>
      <link>https://paperswithcode.com/paper/source-guided-similarity-preservation-for</link>
      <description><![CDATA[Our framework is based on the extraction of a support set composed of source images that maximizes the similarity with the target data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/source-guided-similarity-preservation-for</guid>
    </item>
    <item>
      <title>Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing</title>
      <link>https://paperswithcode.com/paper/where-visual-speech-meets-language-vsp-llm</link>
      <description><![CDATA[In visual speech processing, context modeling capability is one of the most important requirements due to the ambiguous nature of lip movements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/where-visual-speech-meets-language-vsp-llm</guid>
    </item>
    <item>
      <title>Optimal Transport for Structure Learning Under Missing Data</title>
      <link>https://paperswithcode.com/paper/optimal-transport-for-structure-learning</link>
      <description><![CDATA[Merely filling in missing values with existing imputation methods and subsequently applying structure learning on the complete data is empirical shown to be sub-optimal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimal-transport-for-structure-learning</guid>
    </item>
    <item>
      <title>ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models against Stochastic Perturbation</title>
      <link>https://paperswithcode.com/paper/protip-probabilistic-robustness-verification</link>
      <description><![CDATA[Text-to-Image (T2I) Diffusion Models (DMs) have shown impressive abilities in generating high-quality images based on simple text descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/protip-probabilistic-robustness-verification</guid>
    </item>
    <item>
      <title>GraphEdit: Large Language Models for Graph Structure Learning</title>
      <link>https://paperswithcode.com/paper/graphedit-large-language-models-for-graph</link>
      <description><![CDATA[Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphedit-large-language-models-for-graph</guid>
    </item>
    <item>
      <title>PUAD: Frustratingly Simple Method for Robust Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/puad-frustratingly-simple-method-for-robust</link>
      <description><![CDATA[However, we argue that logical anomalies, such as the wrong number of objects, can not be well-represented by the spatial feature maps and require an alternative approach.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/puad-frustratingly-simple-method-for-robust</guid>
    </item>
    <item>
      <title>Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting</title>
      <link>https://paperswithcode.com/paper/enhancing-one-shot-federated-learning-through</link>
      <description><![CDATA[These hard samples are then employed to promote the quality of the ensemble model by adjusting the ensembling weights for each client model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-one-shot-federated-learning-through</guid>
    </item>
    <item>
      <title>On the Duality Between Sharpness-Aware Minimization and Adversarial Training</title>
      <link>https://paperswithcode.com/paper/on-the-duality-between-sharpness-aware</link>
      <description><![CDATA[Instead of perturbing the samples, Sharpness-Aware Minimization (SAM) perturbs the model weights during training to find a more flat loss landscape and improve generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-duality-between-sharpness-aware</guid>
    </item>
    <item>
      <title>Chitchat as Interference: Adding User Backstories to Task-Oriented Dialogues</title>
      <link>https://paperswithcode.com/paper/chitchat-as-interference-adding-user</link>
      <description><![CDATA[During task-oriented dialogues (TODs), human users naturally introduce chitchat that is beyond the immediate scope of the task, interfering with the flow of the conversation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chitchat-as-interference-adding-user</guid>
    </item>
    <item>
      <title>NeuralThink: Algorithm Synthesis that Extrapolates in General Tasks</title>
      <link>https://paperswithcode.com/paper/neuralthink-algorithm-synthesis-that</link>
      <description><![CDATA[To address this gap, we propose NeuralThink, a new recurrent architecture that can consistently extrapolate to both symmetrical and asymmetrical tasks, where the dimensionality of the input and output are different.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuralthink-algorithm-synthesis-that</guid>
    </item>
    <item>
      <title>Infusing Hierarchical Guidance into Prompt Tuning: A Parameter-Efficient Framework for Multi-level Implicit Discourse Relation Recognition</title>
      <link>https://paperswithcode.com/paper/infusing-hierarchical-guidance-into-prompt</link>
      <description><![CDATA[First, we leverage parameter-efficient prompt tuning to drive the inputted arguments to match the pre-trained space and realize the approximation with few parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infusing-hierarchical-guidance-into-prompt</guid>
    </item>
    <item>
      <title>Distributionally Robust Off-Dynamics Reinforcement Learning: Provable Efficiency with Linear Function Approximation</title>
      <link>https://paperswithcode.com/paper/distributionally-robust-off-dynamics</link>
      <description><![CDATA[We provide the first study on online DRMDPs with function approximation for off-dynamics RL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distributionally-robust-off-dynamics</guid>
    </item>
    <item>
      <title>MSPipe: Efficient Temporal GNN Training via Staleness-aware Pipeline</title>
      <link>https://paperswithcode.com/paper/mspipe-efficient-temporal-gnn-training-via</link>
      <description><![CDATA[However, the iterative reading and updating process of the memory module in MTGNNs to obtain up-to-date information needs to follow the temporal dependencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mspipe-efficient-temporal-gnn-training-via</guid>
    </item>
    <item>
      <title>Explorations of Self-Repair in Language Models</title>
      <link>https://paperswithcode.com/paper/explorations-of-self-repair-in-language</link>
      <description><![CDATA[Prior interpretability research studying narrow distributions has preliminarily identified self-repair, a phenomena where if components in large language models are ablated, later components will change their behavior to compensate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explorations-of-self-repair-in-language</guid>
    </item>
    <item>
      <title>EMIFF: Enhanced Multi-scale Image Feature Fusion for Vehicle-Infrastructure Cooperative 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/emiff-enhanced-multi-scale-image-feature</link>
      <description><![CDATA[In autonomous driving, cooperative perception makes use of multi-view cameras from both vehicles and infrastructure, providing a global vantage point with rich semantic context of road conditions beyond a single vehicle viewpoint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emiff-enhanced-multi-scale-image-feature</guid>
    </item>
    <item>
      <title>Counterfactual Generation with Identifiability Guarantees</title>
      <link>https://paperswithcode.com/paper/counterfactual-generation-with-1</link>
      <description><![CDATA[In this work, we tackle the domain-varying dependence between the content and the style variables inherent in the counterfactual generation task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-generation-with-1</guid>
    </item>
    <item>
      <title>Hierarchical Invariance for Robust and Interpretable Vision Tasks at Larger Scales</title>
      <link>https://paperswithcode.com/paper/hierarchical-invariance-for-robust-and</link>
      <description><![CDATA[Developing robust and interpretable vision systems is a crucial step towards trustworthy artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-invariance-for-robust-and</guid>
    </item>
    <item>
      <title>Grasp, See and Place: Efficient Unknown Object Rearrangement with Policy Structure Prior</title>
      <link>https://paperswithcode.com/paper/grasp-see-and-place-efficient-unknown-object</link>
      <description><![CDATA[For the inner loop, we learn an active seeing policy for self-confident object matching to improve the perception of place.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grasp-see-and-place-efficient-unknown-object</guid>
    </item>
    <item>
      <title>Leveraging Domain Knowledge for Efficient Reward Modelling in RLHF: A Case-Study in E-Commerce Opinion Summarization</title>
      <link>https://paperswithcode.com/paper/leveraging-domain-knowledge-for-efficient</link>
      <description><![CDATA[While this strategy has proven to be effective, the training methodology requires a lot of human preference annotation (usually of the order of tens of thousands) to train {$\varphi$}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-domain-knowledge-for-efficient</guid>
    </item>
    <item>
      <title>On the Multi-turn Instruction Following for Conversational Web Agents</title>
      <link>https://paperswithcode.com/paper/on-the-multi-turn-instruction-following-for</link>
      <description><![CDATA[Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-multi-turn-instruction-following-for</guid>
    </item>
    <item>
      <title>Transformers are Expressive, But Are They Expressive Enough for Regression?</title>
      <link>https://paperswithcode.com/paper/transformers-are-expressive-but-are-they</link>
      <description><![CDATA[Expressivity of a neural network is the class of functions it can approximate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformers-are-expressive-but-are-they</guid>
    </item>
    <item>
      <title>Multi-Agent Collaboration Framework for Recommender Systems</title>
      <link>https://paperswithcode.com/paper/multi-agent-collaboration-framework-for</link>
      <description><![CDATA[LLM-based agents have gained considerable attention for their decision-making skills and ability to handle complex tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-agent-collaboration-framework-for</guid>
    </item>
    <item>
      <title>Machine Unlearning of Pre-trained Large Language Models</title>
      <link>https://paperswithcode.com/paper/machine-unlearning-of-pre-trained-large</link>
      <description><![CDATA[This study investigates the concept of the `right to be forgotten' within the context of large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/machine-unlearning-of-pre-trained-large</guid>
    </item>
    <item>
      <title>SpanSeq: Similarity-based sequence data splitting method for improved development and assessment of deep learning projects</title>
      <link>https://paperswithcode.com/paper/spanseq-similarity-based-sequence-data</link>
      <description><![CDATA[The use of deep learning models in computational biology has increased massively in recent years, and is expected to do so further with the current advances in fields like Natural Language Processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spanseq-similarity-based-sequence-data</guid>
    </item>
    <item>
      <title>Federated Learning on Transcriptomic Data: Model Quality and Performance Trade-Offs</title>
      <link>https://paperswithcode.com/paper/federated-learning-on-transcriptomic-data</link>
      <description><![CDATA[However, our experiments confirm that both frameworks can readily build models on transcriptomic data, without transferring personal raw data to a third party with abundant computational resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/federated-learning-on-transcriptomic-data</guid>
    </item>
    <item>
      <title>Unleashing the Power of Imbalanced Modality Information for Multi-modal Knowledge Graph Completion</title>
      <link>https://paperswithcode.com/paper/unleashing-the-power-of-imbalanced-modality</link>
      <description><![CDATA[To address the mentioned problems, we propose Adaptive Multi-modal Fusion and Modality Adversarial Training (AdaMF-MAT) to unleash the power of imbalanced modality information for MMKGC.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unleashing-the-power-of-imbalanced-modality</guid>
    </item>
    <item>
      <title>Subobject-level Image Tokenization</title>
      <link>https://paperswithcode.com/paper/subobject-level-image-tokenization</link>
      <description><![CDATA[Transformer-based vision models typically tokenize images into fixed-size square patches as input units, which lacks the adaptability to image content and overlooks the inherent pixel grouping structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/subobject-level-image-tokenization</guid>
    </item>
    <item>
      <title>GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion</title>
      <link>https://paperswithcode.com/paper/geneoh-diffusion-towards-generalizable-hand</link>
      <description><![CDATA[We tackle those challenges through a novel approach, GeneOH Diffusion, incorporating two key designs: an innovative contact-centric HOI representation named GeneOH and a new domain-generalizable denoising scheme.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geneoh-diffusion-towards-generalizable-hand</guid>
    </item>
    <item>
      <title>Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration</title>
      <link>https://paperswithcode.com/paper/consistency-guided-temperature-scaling-using</link>
      <description><![CDATA[In this paper, we propose consistency-guided temperature scaling (CTS), a new temperature scaling strategy that can significantly enhance the OOD calibration performance by providing mutual supervision among data samples in the source domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/consistency-guided-temperature-scaling-using</guid>
    </item>
    <item>
      <title>Generative Adversarial Network with Soft-Dynamic Time Warping and Parallel Reconstruction for Energy Time Series Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/generative-adversarial-network-with-soft</link>
      <description><![CDATA[In this paper, we employ a 1D deep convolutional generative adversarial network (DCGAN) for sequential anomaly detection in energy time series data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-adversarial-network-with-soft</guid>
    </item>
    <item>
      <title>Global Safe Sequential Learning via Efficient Knowledge Transfer</title>
      <link>https://paperswithcode.com/paper/global-safe-sequential-learning-via-efficient</link>
      <description><![CDATA[As transferable source knowledge is often available in safety critical experiments, we propose to consider transfer safe sequential learning to accelerate the learning of safety.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/global-safe-sequential-learning-via-efficient</guid>
    </item>
    <item>
      <title>ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models</title>
      <link>https://paperswithcode.com/paper/conceptmath-a-bilingual-concept-wise</link>
      <description><![CDATA[This paper introduces ConceptMath, a bilingual (English and Chinese), fine-grained benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conceptmath-a-bilingual-concept-wise</guid>
    </item>
    <item>
      <title>Q-Probe: A Lightweight Approach to Reward Maximization for Language Models</title>
      <link>https://paperswithcode.com/paper/q-probe-a-lightweight-approach-to-reward</link>
      <description><![CDATA[The idea is to learn a simple linear function on a model's embedding space that can be used to reweight candidate completions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/q-probe-a-lightweight-approach-to-reward</guid>
    </item>
    <item>
      <title>Modeling 3D Infant Kinetics Using Adaptive Graph Convolutional Networks</title>
      <link>https://paperswithcode.com/paper/modeling-3d-infant-kinetics-using-adaptive</link>
      <description><![CDATA[Reliable methods for the neurodevelopmental assessment of infants are essential for early detection of medical issues that may need prompt interventions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/modeling-3d-infant-kinetics-using-adaptive</guid>
    </item>
    <item>
      <title>DualFocus: Integrating Macro and Micro Perspectives in Multi-modal Large Language Models</title>
      <link>https://paperswithcode.com/paper/dualfocus-integrating-macro-and-micro</link>
      <description><![CDATA[We present DualFocus, a novel framework for integrating macro and micro perspectives within multi-modal large language models (MLLMs) to enhance vision-language task performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dualfocus-integrating-macro-and-micro</guid>
    </item>
  </channel>
</rss>
