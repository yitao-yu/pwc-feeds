<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 20 May 2023 21:05:26 +0000</lastBuildDate>
    <item>
      <title>Take a Break in the Middle: Investigating Subgoals towards Hierarchical Script Generation</title>
      <link>https://paperswithcode.com/paper/take-a-break-in-the-middle-investigating</link>
      <description><![CDATA[Goal-oriented Script Generation is a new task of generating a list of steps that can fulfill the given goal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/take-a-break-in-the-middle-investigating</guid>
    </item>
    <item>
      <title>Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs</title>
      <link>https://paperswithcode.com/paper/domain-adaptive-sim-to-real-segmentation-of</link>
      <description><![CDATA[In this work, we propose a domain adaptive Sim-to-Real framework called IoU-Ranking Blend-ArtFlow (IRB-AF) for image segmentation of oropharyngeal organs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-adaptive-sim-to-real-segmentation-of</guid>
    </item>
    <item>
      <title>DiffUTE: Universal Text Editing Diffusion Model</title>
      <link>https://paperswithcode.com/paper/diffute-universal-text-editing-diffusion</link>
      <description><![CDATA[Specifically, we build our model on a diffusion model and carefully modify the network structure to enable the model for drawing multilingual characters with the help of glyph and position information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffute-universal-text-editing-diffusion</guid>
    </item>
    <item>
      <title>How does the task complexity of masked pretraining objectives affect downstream performance?</title>
      <link>https://paperswithcode.com/paper/how-does-the-task-complexity-of-masked</link>
      <description><![CDATA[Masked language modeling (MLM) is a widely used self-supervised pretraining objective, where a model needs to predict an original token that is replaced with a mask given contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-does-the-task-complexity-of-masked</guid>
    </item>
    <item>
      <title>Segment Any Anomaly without Training via Hybrid Prompt Regularization</title>
      <link>https://paperswithcode.com/paper/segment-any-anomaly-without-training-via-1</link>
      <description><![CDATA[We present a novel framework, i. e., Segment Any Anomaly + (SAA+), for zero-shot anomaly segmentation with hybrid prompt regularization to improve the adaptability of modern foundation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-any-anomaly-without-training-via-1</guid>
    </item>
    <item>
      <title>Less Can Be More: Unsupervised Graph Pruning for Large-scale Dynamic Graphs</title>
      <link>https://paperswithcode.com/paper/less-can-be-more-unsupervised-graph-pruning</link>
      <description><![CDATA[We approach the problem by our proposed STEP, a self-supervised temporal pruning framework that learns to remove potentially redundant edges from input dynamic graphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-can-be-more-unsupervised-graph-pruning</guid>
    </item>
    <item>
      <title>Scribble-Supervised Target Extraction Method Based on Inner Structure-Constraint for Remote Sensing Images</title>
      <link>https://paperswithcode.com/paper/scribble-supervised-target-extraction-method</link>
      <description><![CDATA[Weakly supervised learning based on scribble annotations in target extraction of remote sensing images has drawn much interest due to scribbles' flexibility in denoting winding objects and low cost of manually labeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scribble-supervised-target-extraction-method</guid>
    </item>
    <item>
      <title>SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities</title>
      <link>https://paperswithcode.com/paper/speechgpt-empowering-large-language-models</link>
      <description><![CDATA[Multi-modal large language models are regarded as a crucial step towards Artificial General Intelligence (AGI) and have garnered significant interest with the emergence of ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/speechgpt-empowering-large-language-models</guid>
    </item>
    <item>
      <title>Listen, Think, and Understand</title>
      <link>https://paperswithcode.com/paper/listen-think-and-understand</link>
      <description><![CDATA[In this paper, we propose a novel audio foundation model, called LTU (Listen, Think, and Understand).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/listen-think-and-understand</guid>
    </item>
    <item>
      <title>QPGesture: Quantization-Based and Phase-Guided Motion Matching for Natural Speech-Driven Gesture Generation</title>
      <link>https://paperswithcode.com/paper/qpgesture-quantization-based-and-phase-guided-1</link>
      <description><![CDATA[Levenshtein distance based on audio quantization as a similarity metric of corresponding speech of gestures helps match more appropriate gestures with speech, and solves the alignment problem of speech and gestures well.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qpgesture-quantization-based-and-phase-guided-1</guid>
    </item>
    <item>
      <title>BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER</title>
      <link>https://paperswithcode.com/paper/bioaug-conditional-generation-based-data</link>
      <description><![CDATA[Though data augmentation has shown to be highly effective for low-resource NER in general, existing data augmentation techniques fail to produce factual and diverse augmentations for BioNER.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bioaug-conditional-generation-based-data</guid>
    </item>
    <item>
      <title>TAPIR: Learning Adaptive Revision for Incremental Natural Language Understanding with a Two-Pass Model</title>
      <link>https://paperswithcode.com/paper/tapir-learning-adaptive-revision-for</link>
      <description><![CDATA[RNNs are fast but monotonic (cannot correct earlier output, which can be necessary in incremental processing).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tapir-learning-adaptive-revision-for</guid>
    </item>
    <item>
      <title>TEPrompt: Task Enlightenment Prompt Learning for Implicit Discourse Relation Recognition</title>
      <link>https://paperswithcode.com/paper/teprompt-task-enlightenment-prompt-learning</link>
      <description><![CDATA[Although an auxiliary task is not used to directly output final prediction, we argue that during the joint training some of its learned features can be useful to boost the main task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teprompt-task-enlightenment-prompt-learning</guid>
    </item>
    <item>
      <title>Discourse Centric Evaluation of Machine Translation with a Densely Annotated Parallel Corpus</title>
      <link>https://paperswithcode.com/paper/discourse-centric-evaluation-of-machine</link>
      <description><![CDATA[Several recent papers claim human parity at sentence-level Machine Translation (MT), especially in high-resource languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/discourse-centric-evaluation-of-machine</guid>
    </item>
    <item>
      <title>Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors</title>
      <link>https://paperswithcode.com/paper/aligning-instruction-tasks-unlocks-large</link>
      <description><![CDATA[Recent work has shown that fine-tuning large language models (LLMs) on large-scale instruction-following datasets substantially improves their performance on a wide range of NLP tasks, especially in the zero-shot setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-instruction-tasks-unlocks-large</guid>
    </item>
    <item>
      <title>CLEME: Debiasing Multi-reference Evaluation for Grammatical Error Correction</title>
      <link>https://paperswithcode.com/paper/cleme-debiasing-multi-reference-evaluation</link>
      <description><![CDATA[Our proposed CLEME approach consistently and substantially outperforms existing reference-based GEC metrics on multiple reference sets in both corpus-level and sentence-level settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cleme-debiasing-multi-reference-evaluation</guid>
    </item>
    <item>
      <title>Taxonomy Completion with Probabilistic Scorer via Box Embedding</title>
      <link>https://paperswithcode.com/paper/taxonomy-completion-with-probabilistic-scorer</link>
      <description><![CDATA[Specifically, TaxBox consists of three components: (1) a graph aggregation module to leverage the structural information of the taxonomy and two lightweight decoders that map features to box embedding and capture complex relationships between concepts; (2) two probabilistic scorers that correspond to attachment and insertion operations and ensure the avoidance of pseudo-leaves; and (3) three learning objectives that assist the model in mapping concepts more granularly onto the box embedding space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taxonomy-completion-with-probabilistic-scorer</guid>
    </item>
    <item>
      <title>Structural Pruning for Diffusion Models</title>
      <link>https://paperswithcode.com/paper/structural-pruning-for-diffusion-models</link>
      <description><![CDATA[Generative modeling has recently undergone remarkable advancements, primarily propelled by the transformative implications of Diffusion Probabilistic Models (DPMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structural-pruning-for-diffusion-models</guid>
    </item>
    <item>
      <title>A benchmark for computational analysis of animal behavior, using animal-borne tags</title>
      <link>https://paperswithcode.com/paper/a-benchmark-for-computational-analysis-of</link>
      <description><![CDATA[Animal-borne sensors ('bio-loggers') can record a suite of kinematic and environmental data, which can elucidate animal ecophysiology and improve conservation efforts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-benchmark-for-computational-analysis-of</guid>
    </item>
    <item>
      <title>Going Denser with Open-Vocabulary Part Segmentation</title>
      <link>https://paperswithcode.com/paper/going-denser-with-open-vocabulary-part</link>
      <description><![CDATA[In this paper, we propose a detector with the ability to predict both open-vocabulary objects and their part segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/going-denser-with-open-vocabulary-part</guid>
    </item>
    <item>
      <title>mdctGAN: Taming transformer-based GAN for speech super-resolution with Modified DCT spectra</title>
      <link>https://paperswithcode.com/paper/mdctgan-taming-transformer-based-gan-for</link>
      <description><![CDATA[Speech super-resolution (SSR) aims to recover a high resolution (HR) speech from its corresponding low resolution (LR) counterpart.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mdctgan-taming-transformer-based-gan-for</guid>
    </item>
    <item>
      <title>ConsistentNeRF: Enhancing Neural Radiance Fields with 3D Consistency for Sparse View Synthesis</title>
      <link>https://paperswithcode.com/paper/consistentnerf-enhancing-neural-radiance</link>
      <description><![CDATA[In this paper, we propose ConsistentNeRF, a method that leverages depth information to regularize both multi-view and single-view 3D consistency among pixels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/consistentnerf-enhancing-neural-radiance</guid>
    </item>
    <item>
      <title>Extracting Low-/High- Frequency Knowledge from Graph Neural Networks and Injecting it into MLPs: An Effective GNN-to-MLP Distillation Framework</title>
      <link>https://paperswithcode.com/paper/extracting-low-high-frequency-knowledge-from</link>
      <description><![CDATA[Furthermore, we identified a potential information drowning problem for existing GNN-to-MLP distillation, i. e., the high-frequency knowledge of the pre-trained GNNs may be overwhelmed by the low-frequency knowledge during distillation; we have described in detail what it represents, how it arises, what impact it has, and how to deal with it.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extracting-low-high-frequency-knowledge-from</guid>
    </item>
    <item>
      <title>Paxion: Patching Action Knowledge in Video-Language Foundation Models</title>
      <link>https://paperswithcode.com/paper/paxion-patching-action-knowledge-in-video</link>
      <description><![CDATA[The Paxion framework utilizes a Knowledge Patcher network to encode new action knowledge and a Knowledge Fuser component to integrate the Patcher into frozen VidLMs without compromising their existing capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paxion-patching-action-knowledge-in-video</guid>
    </item>
    <item>
      <title>Adjusting Logit in Gaussian Form for Long-Tailed Visual Recognition</title>
      <link>https://paperswithcode.com/paper/adjusting-logit-in-gaussian-form-for-long</link>
      <description><![CDATA[Based on these perturbed features, two novel logit adjustment methods are proposed to improve model performance at a modest computational overhead.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adjusting-logit-in-gaussian-form-for-long</guid>
    </item>
    <item>
      <title>Self-supervised Fine-tuning for Improved Content Representations by Speaker-invariant Clustering</title>
      <link>https://paperswithcode.com/paper/self-supervised-fine-tuning-for-improved</link>
      <description><![CDATA[Self-supervised speech representation models have succeeded in various tasks, but improving them for content-related problems using unlabeled data is challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-fine-tuning-for-improved</guid>
    </item>
    <item>
      <title>ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities</title>
      <link>https://paperswithcode.com/paper/one-peace-exploring-one-general</link>
      <description><![CDATA[In this work, we explore a scalable way for building a general representation model toward unlimited modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-peace-exploring-one-general</guid>
    </item>
    <item>
      <title>VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks</title>
      <link>https://paperswithcode.com/paper/visionllm-large-language-model-is-also-an</link>
      <description><![CDATA[We hope this model can set a new baseline for generalist vision and language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visionllm-large-language-model-is-also-an</guid>
    </item>
    <item>
      <title>Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency</title>
      <link>https://paperswithcode.com/paper/flatness-aware-prompt-selection-improves</link>
      <description><![CDATA[We provide theoretical foundations for this metric and its relationship with other prompt selection metrics, providing a comprehensive understanding of existing methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flatness-aware-prompt-selection-improves</guid>
    </item>
    <item>
      <title>Sharing Lifelong Reinforcement Learning Knowledge via Modulating Masks</title>
      <link>https://paperswithcode.com/paper/sharing-lifelong-reinforcement-learning</link>
      <description><![CDATA[The key idea is that the isolation of specific task knowledge to specific masks allows agents to transfer only specific knowledge on-demand, resulting in robust and effective distributed lifelong learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sharing-lifelong-reinforcement-learning</guid>
    </item>
    <item>
      <title>Generalized Planning in PDDL Domains with Pretrained Large Language Models</title>
      <link>https://paperswithcode.com/paper/generalized-planning-in-pddl-domains-with</link>
      <description><![CDATA[We investigate whether LLMs can serve as generalized planners: given a domain and training tasks, generate a program that efficiently produces plans for other tasks in the domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-planning-in-pddl-domains-with</guid>
    </item>
    <item>
      <title>Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model</title>
      <link>https://paperswithcode.com/paper/instruct2act-mapping-multi-modality</link>
      <description><![CDATA[This paper presents Instruct2Act, a framework that utilizes Large Language Models to map multi-modal instructions to sequential actions for robotic manipulation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instruct2act-mapping-multi-modality</guid>
    </item>
    <item>
      <title>Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization</title>
      <link>https://paperswithcode.com/paper/prompting-the-hidden-talent-of-web-scale</link>
      <description><![CDATA[We investigate the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompting-the-hidden-talent-of-web-scale</guid>
    </item>
    <item>
      <title>GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework</title>
      <link>https://paperswithcode.com/paper/getmusic-generating-any-music-tracks-with-a</link>
      <description><![CDATA[With separate tracks in GETScore and the non-autoregressive behavior of the model, GETMusic can explicitly control the generation of any target tracks from scratch or conditioning on source tracks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/getmusic-generating-any-music-tracks-with-a</guid>
    </item>
    <item>
      <title>ReGen: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval</title>
      <link>https://paperswithcode.com/paper/regen-zero-shot-text-classification-via</link>
      <description><![CDATA[With the development of large language models (LLMs), zero-shot learning has attracted much attention for various NLP tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/regen-zero-shot-text-classification-via</guid>
    </item>
    <item>
      <title>High-dimensional Asymptotics of Denoising Autoencoders</title>
      <link>https://paperswithcode.com/paper/high-dimensional-asymptotics-of-denoising</link>
      <description><![CDATA[We address the problem of denoising data from a Gaussian mixture using a two-layer non-linear autoencoder with tied weights and a skip connection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-dimensional-asymptotics-of-denoising</guid>
    </item>
    <item>
      <title>Unbiased Gradient Boosting Decision Tree with Unbiased Feature Importance</title>
      <link>https://paperswithcode.com/paper/unbiased-gradient-boosting-decision-tree-with</link>
      <description><![CDATA[To this end, we provide a fine-grained analysis of bias in GBDT and demonstrate that the bias originates from 1) the systematic bias in the gain estimation of each split and 2) the bias in the split finding algorithm resulting from the use of the same data to evaluate the split improvement and determine the best split.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unbiased-gradient-boosting-decision-tree-with</guid>
    </item>
    <item>
      <title>Seq-HGNN: Learning Sequential Node Representation on Heterogeneous Graph</title>
      <link>https://paperswithcode.com/paper/seq-hgnn-learning-sequential-node</link>
      <description><![CDATA[However, existing HGNNs usually represent each node as a single vector in the multi-layer graph convolution calculation, which makes the high-level graph convolution layer fail to distinguish information from different relations and different orders, resulting in the information loss in the message passing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seq-hgnn-learning-sequential-node</guid>
    </item>
    <item>
      <title>Difference of Submodular Minimization via DC Programming</title>
      <link>https://paperswithcode.com/paper/difference-of-submodular-minimization-via-dc</link>
      <description><![CDATA[We introduce variants of DCA and its complete form (CDCA) that we apply to the DC program corresponding to DS minimization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/difference-of-submodular-minimization-via-dc</guid>
    </item>
    <item>
      <title>Posterior Inference on Infinitely Wide Bayesian Neural Networks under Weights with Unbounded Variance</title>
      <link>https://paperswithcode.com/paper/posterior-inference-on-infinitely-wide</link>
      <description><![CDATA[From the classical and influential works of Neal (1996), it is known that the infinite width scaling limit of a Bayesian neural network with one hidden layer is a Gaussian process, \emph{when the network weights have bounded prior variance}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posterior-inference-on-infinitely-wide</guid>
    </item>
    <item>
      <title>SPENSER: Towards a NeuroEvolutionary Approach for Convolutional Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/spenser-towards-a-neuroevolutionary-approach</link>
      <description><![CDATA[DENSER is a NE framework for the automatic design and parametrization of ANNs, based on the principles of Genetic Algorithms (GA) and Structured Grammatical Evolution (SGE).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spenser-towards-a-neuroevolutionary-approach</guid>
    </item>
    <item>
      <title>A Survey on Time-Series Pre-Trained Models</title>
      <link>https://paperswithcode.com/paper/a-survey-on-time-series-pre-trained-models</link>
      <description><![CDATA[Time-Series Mining (TSM) is an important research area since it shows great potential in practical applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-time-series-pre-trained-models</guid>
    </item>
    <item>
      <title>Query Performance Prediction: From Ad-hoc to Conversational Search</title>
      <link>https://paperswithcode.com/paper/query-performance-prediction-from-ad-hoc-to</link>
      <description><![CDATA[The QPP task is to predict the retrieval quality of a search system for a query without relevance judgments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/query-performance-prediction-from-ad-hoc-to</guid>
    </item>
    <item>
      <title>FunASR: A Fundamental End-to-End Speech Recognition Toolkit</title>
      <link>https://paperswithcode.com/paper/funasr-a-fundamental-end-to-end-speech</link>
      <description><![CDATA[FunASR offers models trained on large-scale industrial corpora and the ability to deploy them in applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/funasr-a-fundamental-end-to-end-speech</guid>
    </item>
    <item>
      <title>TextDiffuser: Diffusion Models as Text Painters</title>
      <link>https://paperswithcode.com/paper/textdiffuser-diffusion-models-as-text</link>
      <description><![CDATA[Diffusion models have gained increasing attention for their impressive generation abilities but currently struggle with rendering accurate and coherent text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textdiffuser-diffusion-models-as-text</guid>
    </item>
    <item>
      <title>MiraBest: A Dataset of Morphologically Classified Radio Galaxies for Machine Learning</title>
      <link>https://paperswithcode.com/paper/mirabest-a-dataset-of-morphologically</link>
      <description><![CDATA[Existing applications that utilise the MiraBest dataset are reviewed, and an extended dataset of 2100 sources is created by cross-matching MiraBest with other catalogues of radio-loud AGN that have been used more widely in the literature for machine learning applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mirabest-a-dataset-of-morphologically</guid>
    </item>
    <item>
      <title>When Search Meets Recommendation: Learning Disentangled Search Representation for Recommendation</title>
      <link>https://paperswithcode.com/paper/when-search-meets-recommendation-learning</link>
      <description><![CDATA[In our paper, we propose a Search-Enhanced framework for the Sequential Recommendation (SESRec) that leverages users' search interests for recommendation, by disentangling similar and dissimilar representations within S&R behaviors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-search-meets-recommendation-learning</guid>
    </item>
    <item>
      <title>On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation</title>
      <link>https://paperswithcode.com/paper/on-the-off-target-problem-of-zero-shot</link>
      <description><![CDATA[We conduct experiments on a multilingual machine translation benchmark in 11 languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-off-target-problem-of-zero-shot</guid>
    </item>
    <item>
      <title>Making More of Little Data: Improving Low-Resource Automatic Speech Recognition Using Data Augmentation</title>
      <link>https://paperswithcode.com/paper/making-more-of-little-data-improving-low</link>
      <description><![CDATA[For Gronings, for which there was a pre-existing text-to-speech (TTS) system available, we also examined the use of TTS to generate ASR training data from text-only sources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/making-more-of-little-data-improving-low</guid>
    </item>
    <item>
      <title>Multilingual Event Extraction from Historical Newspaper Adverts</title>
      <link>https://paperswithcode.com/paper/multilingual-event-extraction-from-historical</link>
      <description><![CDATA[We find that: 1) even with scarce annotated data, it is possible to achieve surprisingly good results by formulating the problem as an extractive QA task and leveraging existing datasets and models for modern languages; and 2) cross-lingual low-resource learning for historical languages is highly challenging, and machine translation of the historical datasets to the considered target languages is, in practice, often the best-performing solution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multilingual-event-extraction-from-historical</guid>
    </item>
  </channel>
</rss>
