<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 11 Oct 2022 21:10:58 +0000</lastBuildDate>
    <item>
      <title>Distill the Image to Nowhere: Inversion Knowledge Distillation for Multimodal Machine Translation</title>
      <link>https://paperswithcode.com/paper/distill-the-image-to-nowhere-inversion</link>
      <description><![CDATA[Thus, in this work, we introduce IKD-MMT, a novel MMT framework to support the image-free inference phase via an inversion knowledge distillation scheme.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distill-the-image-to-nowhere-inversion</guid>
    </item>
    <item>
      <title>Ensemble Learning using Transformers and Convolutional Networks for Masked Face Recognition</title>
      <link>https://paperswithcode.com/paper/ensemble-learning-using-transformers-and</link>
      <description><![CDATA[In this work, we propose a system for masked face recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ensemble-learning-using-transformers-and</guid>
    </item>
    <item>
      <title>Contrastive Bayesian Analysis for Deep Metric Learning</title>
      <link>https://paperswithcode.com/paper/contrastive-bayesian-analysis-for-deep-metric</link>
      <description><![CDATA[Recent methods for deep metric learning have been focusing on designing different contrastive loss functions between positive and negative pairs of samples so that the learned feature embedding is able to pull positive samples of the same class closer and push negative samples from different classes away from each other.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-bayesian-analysis-for-deep-metric</guid>
    </item>
    <item>
      <title>BoundaryFace: A mining framework with noise label self-correction for Face Recognition</title>
      <link>https://paperswithcode.com/paper/boundaryface-a-mining-framework-with-noise</link>
      <description><![CDATA[Specifically, a closed-set noise label self-correction module is put forward, making this framework work well on datasets containing a lot of label noise.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boundaryface-a-mining-framework-with-noise</guid>
    </item>
    <item>
      <title>A Simple Baseline that Questions the Use of Pretrained-Models in Continual Learning</title>
      <link>https://paperswithcode.com/paper/a-simple-baseline-that-questions-the-use-of</link>
      <description><![CDATA[With the success of pretraining techniques in representation learning, a number of continual learning methods based on pretrained models have been proposed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-simple-baseline-that-questions-the-use-of</guid>
    </item>
    <item>
      <title>Margin-Based Few-Shot Class-Incremental Learning with Class-Level Overfitting Mitigation</title>
      <link>https://paperswithcode.com/paper/margin-based-few-shot-class-incremental</link>
      <description><![CDATA[Few-shot class-incremental learning (FSCIL) is designed to incrementally recognize novel classes with only few training samples after the (pre-)training on base classes with sufficient samples, which focuses on both base-class performance and novel-class generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/margin-based-few-shot-class-incremental</guid>
    </item>
    <item>
      <title>Uncertainty-aware LiDAR Panoptic Segmentation</title>
      <link>https://paperswithcode.com/paper/uncertainty-aware-lidar-panoptic-segmentation</link>
      <description><![CDATA[Current learning-based methods typically try to achieve maximum performance for this task, while neglecting a proper estimation of the associated uncertainties.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncertainty-aware-lidar-panoptic-segmentation</guid>
    </item>
    <item>
      <title>4D Unsupervised Object Discovery</title>
      <link>https://paperswithcode.com/paper/4d-unsupervised-object-discovery</link>
      <description><![CDATA[In this paper, we propose 4D unsupervised object discovery, jointly discovering objects from 4D data -- 3D point clouds and 2D RGB images with temporal information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/4d-unsupervised-object-discovery</guid>
    </item>
    <item>
      <title>CLIP-Diffusion-LM: Apply Diffusion Model on Image Captioning</title>
      <link>https://paperswithcode.com/paper/clip-diffusion-lm-apply-diffusion-model-on</link>
      <description><![CDATA[On the Flickr8k dataset, the model achieves 0. 1876 BLEU-4 score.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clip-diffusion-lm-apply-diffusion-model-on</guid>
    </item>
    <item>
      <title>Predicting Blossom Date of Cherry Tree With Support Vector Machine and Recurrent Neural Network</title>
      <link>https://paperswithcode.com/paper/predicting-blossom-date-of-cherry-tree-with</link>
      <description><![CDATA[Our project probes the relationship between temperatures and the blossom date of cherry trees.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/predicting-blossom-date-of-cherry-tree-with</guid>
    </item>
    <item>
      <title>Joint Multi-grained Popularity-aware Graph Convolution Collaborative Filtering for Recommendation</title>
      <link>https://paperswithcode.com/paper/joint-multi-grained-popularity-aware-graph</link>
      <description><![CDATA[In this work, we propose to model multi-grained popularity features and jointly learn them together with high-order connectivity, to match the differentiation of user preferences exhibited in popularity features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/joint-multi-grained-popularity-aware-graph</guid>
    </item>
    <item>
      <title>HiCo: Hierarchical Contrastive Learning for Ultrasound Video Model Pretraining</title>
      <link>https://paperswithcode.com/paper/hico-hierarchical-contrastive-learning-for</link>
      <description><![CDATA[This work proposes a hierarchical contrastive learning (HiCo) method to improve the transferability for the US video model pretraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hico-hierarchical-contrastive-learning-for</guid>
    </item>
    <item>
      <title>Language Prior Is Not the Only Shortcut: A Benchmark for Shortcut Learning in VQA</title>
      <link>https://paperswithcode.com/paper/language-prior-is-not-the-only-shortcut-a</link>
      <description><![CDATA[To overcome this limitation, we propose a new dataset that considers varying types of shortcuts by constructing different distribution shifts in multiple OOD test sets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-prior-is-not-the-only-shortcut-a</guid>
    </item>
    <item>
      <title>Association Graph Learning for Multi-Task Classification with Category Shifts</title>
      <link>https://paperswithcode.com/paper/association-graph-learning-for-multi-task</link>
      <description><![CDATA[To generalize to such test data, it is crucial for individual tasks to leverage knowledge from related tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/association-graph-learning-for-multi-task</guid>
    </item>
    <item>
      <title>FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in Realistic Healthcare Settings</title>
      <link>https://paperswithcode.com/paper/flamby-datasets-and-benchmarks-for-cross-silo</link>
      <description><![CDATA[In this work, we propose a novel cross-silo dataset suite focused on healthcare, FLamby (Federated Learning AMple Benchmark of Your cross-silo strategies), to bridge the gap between theory and practice of cross-silo FL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flamby-datasets-and-benchmarks-for-cross-silo</guid>
    </item>
    <item>
      <title>What the DAAM: Interpreting Stable Diffusion Using Cross Attention</title>
      <link>https://paperswithcode.com/paper/what-the-daam-interpreting-stable-diffusion</link>
      <description><![CDATA[In this paper, to shine some much-needed light on text-to-image diffusion models, we perform a text-image attribution analysis on Stable Diffusion, a recently open-sourced large diffusion model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-the-daam-interpreting-stable-diffusion</guid>
    </item>
    <item>
      <title>Universal Adversarial Perturbations: Efficiency on a small image dataset</title>
      <link>https://paperswithcode.com/paper/universal-adversarial-perturbations-1</link>
      <description><![CDATA[Although neural networks perform very well on the image classification task, they are still vulnerable to adversarial perturbations that can fool a neural network without visibly changing an input image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-adversarial-perturbations-1</guid>
    </item>
    <item>
      <title>The Eyecandies Dataset for Unsupervised Multimodal Anomaly Detection and Localization</title>
      <link>https://paperswithcode.com/paper/the-eyecandies-dataset-for-unsupervised</link>
      <description><![CDATA[We present Eyecandies, a novel synthetic dataset for unsupervised anomaly detection and localization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-eyecandies-dataset-for-unsupervised</guid>
    </item>
    <item>
      <title>Learning Robust Representations for Continual Relation Extraction via Adversarial Class Augmentation</title>
      <link>https://paperswithcode.com/paper/learning-robust-representations-for-continual</link>
      <description><![CDATA[In this paper, through empirical studies we argue that this assumption may not hold, and an important reason for catastrophic forgetting is that the learned representations do not have good robustness against the appearance of analogous relations in the subsequent learning process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-robust-representations-for-continual</guid>
    </item>
    <item>
      <title>Semi-supervised Semantic Segmentation with Prototype-based Consistency Regularization</title>
      <link>https://paperswithcode.com/paper/semi-supervised-semantic-segmentation-with-6</link>
      <description><![CDATA[Semi-supervised semantic segmentation requires the model to effectively propagate the label information from limited annotated images to unlabeled ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semi-supervised-semantic-segmentation-with-6</guid>
    </item>
    <item>
      <title>The Small Solution Hypothesis for MAPF on Directed Graphs Is True</title>
      <link>https://paperswithcode.com/paper/the-small-solution-hypothesis-for-mapf-on</link>
      <description><![CDATA[The determination of the computational complexity of multi-agent pathfinding on directed graphs has been an open problem for many years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-small-solution-hypothesis-for-mapf-on</guid>
    </item>
    <item>
      <title>Training Spiking Neural Networks with Local Tandem Learning</title>
      <link>https://paperswithcode.com/paper/training-spiking-neural-networks-with-local</link>
      <description><![CDATA[The LTL rule follows the teacher-student learning approach by mimicking the intermediate feature representations of a pre-trained ANN.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-spiking-neural-networks-with-local</guid>
    </item>
    <item>
      <title>Deep object detection for waterbird monitoring using aerial imagery</title>
      <link>https://paperswithcode.com/paper/deep-object-detection-for-waterbird</link>
      <description><![CDATA[In this work, we present a deep learning pipeline that can be used to precisely detect, count, and monitor waterbirds using aerial imagery collected by a commercial drone.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-object-detection-for-waterbird</guid>
    </item>
    <item>
      <title>PyHopper -- Hyperparameter optimization</title>
      <link>https://paperswithcode.com/paper/pyhopper-hyperparameter-optimization</link>
      <description><![CDATA[Hyperparameter tuning is a fundamental aspect of machine learning research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pyhopper-hyperparameter-optimization</guid>
    </item>
    <item>
      <title>Uncertainty Quantification with Pre-trained Language Models: A Large-Scale Empirical Analysis</title>
      <link>https://paperswithcode.com/paper/uncertainty-quantification-with-pre-trained</link>
      <description><![CDATA[In particular, there are various considerations behind the pipeline: (1) the choice and (2) the size of PLM, (3) the choice of uncertainty quantifier, (4) the choice of fine-tuning loss, and many more.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncertainty-quantification-with-pre-trained</guid>
    </item>
    <item>
      <title>ParaDime: A Framework for Parametric Dimensionality Reduction</title>
      <link>https://paperswithcode.com/paper/paradime-a-framework-for-parametric</link>
      <description><![CDATA[It provides a common interface to specify the way these relations and transformations are computed and how they are used within the losses that govern the training process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paradime-a-framework-for-parametric</guid>
    </item>
    <item>
      <title>Multi-Modal Fusion by Meta-Initialization</title>
      <link>https://paperswithcode.com/paper/multi-modal-fusion-by-meta-initialization</link>
      <description><![CDATA[In this work, we propose an extension to the Model-Agnostic Meta-Learning algorithm (MAML), which allows the model to adapt using auxiliary information as well as task experience.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-modal-fusion-by-meta-initialization</guid>
    </item>
    <item>
      <title>A policy gradient approach for Finite Horizon Constrained Markov Decision Processes</title>
      <link>https://paperswithcode.com/paper/a-policy-gradient-approach-for-finite-horizon</link>
      <description><![CDATA[The infinite horizon setting is widely adopted for problems of reinforcement learning (RL).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-policy-gradient-approach-for-finite-horizon</guid>
    </item>
    <item>
      <title>Don't Copy the Teacher: Data and Model Challenges in Embodied Dialogue</title>
      <link>https://paperswithcode.com/paper/don-t-copy-the-teacher-data-and-model</link>
      <description><![CDATA[We provide empirical comparisons of metrics, analysis of three models, and make suggestions for how the field might best progress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-copy-the-teacher-data-and-model</guid>
    </item>
    <item>
      <title>Self-explaining Hierarchical Model for Intraoperative Time Series</title>
      <link>https://paperswithcode.com/paper/self-explaining-hierarchical-model-for</link>
      <description><![CDATA[Towards this end, we propose a hierarchical model combining the strength of both attention and recurrent models for intraoperative time series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-explaining-hierarchical-model-for</guid>
    </item>
    <item>
      <title>CrowdChecked: Detecting Previously Fact-Checked Claims in Social Media</title>
      <link>https://paperswithcode.com/paper/crowdchecked-detecting-previously-fact-1</link>
      <description><![CDATA[Thus, an interesting approach has emerged: to perform automatic fact-checking by verifying whether an input claim has been previously fact-checked by professional fact-checkers and to return back an article that explains their decision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/crowdchecked-detecting-previously-fact-1</guid>
    </item>
    <item>
      <title>OGC: Unsupervised 3D Object Segmentation from Rigid Dynamics of Point Clouds</title>
      <link>https://paperswithcode.com/paper/ogc-unsupervised-3d-object-segmentation-from</link>
      <description><![CDATA[In this paper, we study the problem of 3D object segmentation from raw point clouds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ogc-unsupervised-3d-object-segmentation-from</guid>
    </item>
    <item>
      <title>Parameter-Efficient Tuning with Special Token Adaptation</title>
      <link>https://paperswithcode.com/paper/parameter-efficient-tuning-with-special-token</link>
      <description><![CDATA[Parameter-efficient tuning aims at updating only a small subset of parameters when adapting a pretrained model to downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parameter-efficient-tuning-with-special-token</guid>
    </item>
    <item>
      <title>DeepMed: Semiparametric Causal Mediation Analysis with Debiased Deep Learning</title>
      <link>https://paperswithcode.com/paper/deepmed-semiparametric-causal-mediation</link>
      <description><![CDATA[Causal mediation analysis can unpack the black box of causality and is therefore a powerful tool for disentangling causal pathways in biomedical and social sciences, and also for evaluating machine learning fairness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepmed-semiparametric-causal-mediation</guid>
    </item>
    <item>
      <title>SelfMix: Robust Learning Against Textual Label Noise with Self-Mixup Training</title>
      <link>https://paperswithcode.com/paper/selfmix-robust-learning-against-textual-label</link>
      <description><![CDATA[The conventional success of textual classification relies on annotated data, and the new paradigm of pre-trained language models (PLMs) still requires a few labeled data for downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/selfmix-robust-learning-against-textual-label</guid>
    </item>
    <item>
      <title>Empowering the Fact-checkers! Automatic Identification of Claim Spans on Twitter</title>
      <link>https://paperswithcode.com/paper/empowering-the-fact-checkers-automatic</link>
      <description><![CDATA[The current vogue is to employ manual fact-checkers to efficiently classify and verify such data to combat this avalanche of claim-ridden misinformation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/empowering-the-fact-checkers-automatic</guid>
    </item>
    <item>
      <title>Language Models Are Poor Learners of Directional Inference</title>
      <link>https://paperswithcode.com/paper/language-models-are-poor-learners-of</link>
      <description><![CDATA[We examine LMs' competence of directional predicate entailments by supervised fine-tuning with prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-are-poor-learners-of</guid>
    </item>
    <item>
      <title>Rieoptax: Riemannian Optimization in JAX</title>
      <link>https://paperswithcode.com/paper/rieoptax-riemannian-optimization-in-jax</link>
      <description><![CDATA[We present Rieoptax, an open source Python library for Riemannian optimization in JAX.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rieoptax-riemannian-optimization-in-jax</guid>
    </item>
    <item>
      <title>SCAM! Transferring humans between images with Semantic Cross Attention Modulation</title>
      <link>https://paperswithcode.com/paper/scam-transferring-humans-between-images-with</link>
      <description><![CDATA[In this work, we introduce SCAM (Semantic Cross Attention Modulation), a system that encodes rich and diverse information in each semantic region of the image (including foreground and background), thus achieving precise generation with emphasis on fine details.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scam-transferring-humans-between-images-with</guid>
    </item>
    <item>
      <title>Data types as a more ergonomic frontend for Grammar-Guided Genetic Programming</title>
      <link>https://paperswithcode.com/paper/data-types-as-a-more-ergonomic-frontend-for</link>
      <description><![CDATA[We conclude that our approach has better ergonomics with the same expressive power and performance of textual BNF-based grammar encodings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-types-as-a-more-ergonomic-frontend-for</guid>
    </item>
    <item>
      <title>DALE: Differential Accumulated Local Effects for efficient and accurate global explanations</title>
      <link>https://paperswithcode.com/paper/dale-differential-accumulated-local-effects</link>
      <description><![CDATA[In this paper, we propose a novel ALE approximation, called Differential Accumulated Local Effects (DALE), which can be used in cases where the ML model is differentiable and an auto-differentiable framework is accessible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dale-differential-accumulated-local-effects</guid>
    </item>
    <item>
      <title>CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation</title>
      <link>https://paperswithcode.com/paper/core-a-retrieve-then-edit-framework-for</link>
      <description><![CDATA[We present COunterfactual Generation via Retrieval and Editing (CORE), a retrieval-augmented generation framework for creating diverse counterfactual perturbations for CDA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/core-a-retrieve-then-edit-framework-for</guid>
    </item>
    <item>
      <title>NerfAcc: A General NeRF Acceleration Toolbox</title>
      <link>https://paperswithcode.com/paper/nerfacc-a-general-nerf-acceleration-toolbox</link>
      <description><![CDATA[We propose NerfAcc, a toolbox for efficient volumetric rendering of radiance fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nerfacc-a-general-nerf-acceleration-toolbox</guid>
    </item>
    <item>
      <title>Towards Robust Visual Question Answering: Making the Most of Biased Samples via Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/towards-robust-visual-question-answering</link>
      <description><![CDATA[However, these models reveal a trade-off that the improvements on OOD data severely sacrifice the performance on the in-distribution (ID) data (which is dominated by the biased samples).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-visual-question-answering</guid>
    </item>
    <item>
      <title>A Comprehensive Survey of Data Augmentation in Visual Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/a-comprehensive-survey-of-data-augmentation</link>
      <description><![CDATA[Visual reinforcement learning (RL), which makes decisions directly from high-dimensional visual inputs, has demonstrated significant potential in various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comprehensive-survey-of-data-augmentation</guid>
    </item>
    <item>
      <title>Controllable Dialogue Simulation with In-Context Learning</title>
      <link>https://paperswithcode.com/paper/controllable-dialogue-simulation-with-in</link>
      <description><![CDATA[Experimental results on the MultiWOZ dataset demonstrate that training a model on the simulated dialogues leads to even better performance than using the same amount of human-generated dialogues in the low-resource settings, with as few as 85 dialogues as the seed data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controllable-dialogue-simulation-with-in</guid>
    </item>
    <item>
      <title>ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models</title>
      <link>https://paperswithcode.com/paper/asdot-any-shot-data-to-text-generation-with</link>
      <description><![CDATA[In the data disambiguation stage, we employ the prompted GPT-3 model to understand possibly ambiguous triples from the input data and convert each into a short sentence with reduced ambiguity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asdot-any-shot-data-to-text-generation-with</guid>
    </item>
    <item>
      <title>CAGroup3D: Class-Aware Grouping for 3D Object Detection on Point Clouds</title>
      <link>https://paperswithcode.com/paper/cagroup3d-class-aware-grouping-for-3d-object</link>
      <description><![CDATA[We present a novel two-stage fully sparse convolutional 3D object detection framework, named CAGroup3D.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cagroup3d-class-aware-grouping-for-3d-object</guid>
    </item>
    <item>
      <title>Dual-distribution discrepancy with self-supervised refinement for anomaly detection in medical images</title>
      <link>https://paperswithcode.com/paper/dual-distribution-discrepancy-with-self</link>
      <description><![CDATA[Due to the high-cost annotations of abnormal images, most methods utilize only known normal images during training and identify samples not conforming to the normal profile as anomalies in the testing phase.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-distribution-discrepancy-with-self</guid>
    </item>
    <item>
      <title>Decomposed Mutual Information Optimization for Generalized Context in Meta-Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/decomposed-mutual-information-optimization</link>
      <description><![CDATA[This paper addresses such a challenge by Decomposed Mutual INformation Optimization (DOMINO) for context learning, which explicitly learns a disentangled context to maximize the mutual information between the context and historical trajectories, while minimizing the state transition prediction error.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decomposed-mutual-information-optimization</guid>
    </item>
  </channel>
</rss>
