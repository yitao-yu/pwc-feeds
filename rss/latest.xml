<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 15 Oct 2022 21:08:35 +0000</lastBuildDate>
    <item>
      <title>On the Utility of Self-supervised Models for Prosody-related Tasks</title>
      <link>https://paperswithcode.com/paper/on-the-utility-of-self-supervised-models-for</link>
      <description><![CDATA[We find that 13 of the 15 SSL models outperformed the baseline on all the prosody-related tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-utility-of-self-supervised-models-for</guid>
    </item>
    <item>
      <title>Real Spike: Learning Real-valued Spikes for Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/real-spike-learning-real-valued-spikes-for</link>
      <description><![CDATA[Motivated by this assumption, a training-inference decoupling method for SNNs named as Real Spike is proposed, which not only enjoys both unshared convolution kernels and binary spikes in inference-time but also maintains both shared convolution kernels and Real-valued Spikes during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-spike-learning-real-valued-spikes-for</guid>
    </item>
    <item>
      <title>Two approaches to inpainting microstructure with deep convolutional generative adversarial networks</title>
      <link>https://paperswithcode.com/paper/two-approaches-to-inpainting-microstructure</link>
      <description><![CDATA[Imaging is critical to the characterisation of materials.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/two-approaches-to-inpainting-microstructure</guid>
    </item>
    <item>
      <title>Large-Scale Open-Set Classification Protocols for ImageNet</title>
      <link>https://paperswithcode.com/paper/large-scale-open-set-classification-protocols</link>
      <description><![CDATA[Open-Set Classification (OSC) intends to adapt closed-set classification models to real-world scenarios, where the classifier must correctly label samples of known classes while rejecting previously unseen unknown samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-scale-open-set-classification-protocols</guid>
    </item>
    <item>
      <title>Overlooked Video Classification in Weakly Supervised Video Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/overlooked-video-classification-in-weakly</link>
      <description><![CDATA[In this paper, we study explicitly the power of video classification supervision using a BERT or LSTM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/overlooked-video-classification-in-weakly</guid>
    </item>
    <item>
      <title>How to Train Vision Transformer on Small-scale Datasets?</title>
      <link>https://paperswithcode.com/paper/how-to-train-vision-transformer-on-small</link>
      <description><![CDATA[However, in contrast to convolutional neural networks, Vision Transformer lacks inherent inductive biases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-to-train-vision-transformer-on-small</guid>
    </item>
    <item>
      <title>Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations</title>
      <link>https://paperswithcode.com/paper/forces-are-not-enough-benchmark-and-critical</link>
      <description><![CDATA[Our benchmark suite comes with a comprehensive open-source codebase for training and simulation with ML FFs to facilitate further work.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/forces-are-not-enough-benchmark-and-critical</guid>
    </item>
    <item>
      <title>CROP: Zero-shot Cross-lingual Named Entity Recognition with Multilingual Labeled Sequence Translation</title>
      <link>https://paperswithcode.com/paper/crop-zero-shot-cross-lingual-named-entity</link>
      <description><![CDATA[Specifically, the target sequence is first translated into the source language and then tagged by a source NER model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/crop-zero-shot-cross-lingual-named-entity</guid>
    </item>
    <item>
      <title>Re3: Generating Longer Stories With Recursive Reprompting and Revision</title>
      <link>https://paperswithcode.com/paper/re3-generating-longer-stories-with-recursive</link>
      <description><![CDATA[We consider the problem of automatically generating longer stories of over two thousand words.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/re3-generating-longer-stories-with-recursive</guid>
    </item>
    <item>
      <title>Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/intermediate-prototype-mining-transformer-for</link>
      <description><![CDATA[To solve this problem, we are the first to introduce an intermediate prototype for mining both deterministic category information from the support and adaptive category knowledge from the query.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intermediate-prototype-mining-transformer-for</guid>
    </item>
    <item>
      <title>Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer</title>
      <link>https://paperswithcode.com/paper/q-vit-accurate-and-fully-quantized-low-bit</link>
      <description><![CDATA[The large pre-trained vision transformers (ViTs) have demonstrated remarkable performance on various visual tasks, but suffer from expensive computational and memory cost problems when deployed on resource-constrained devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/q-vit-accurate-and-fully-quantized-low-bit</guid>
    </item>
    <item>
      <title>Multi-Target XGBoostLSS Regression</title>
      <link>https://paperswithcode.com/paper/multi-target-xgboostlss-regression</link>
      <description><![CDATA[Current implementations of Gradient Boosting Machines are mostly designed for single-target regression tasks and commonly assume independence between responses when used in multivariate settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-target-xgboostlss-regression</guid>
    </item>
    <item>
      <title>Anonymizing Speech with Generative Adversarial Networks to Preserve Speaker Privacy</title>
      <link>https://paperswithcode.com/paper/anonymizing-speech-with-generative</link>
      <description><![CDATA[In order to protect the privacy of speech data, speaker anonymization aims for hiding the identity of a speaker by changing the voice in speech recordings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anonymizing-speech-with-generative</guid>
    </item>
    <item>
      <title>Decentralized State Estimation In A Dimension-Reduced Linear Regression</title>
      <link>https://paperswithcode.com/paper/decentralized-state-estimation-in-a-dimension</link>
      <description><![CDATA[Several dimension-reducing algorithms are therefore proposed, where each algorithm corresponds to a commonly applied decentralized estimation method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decentralized-state-estimation-in-a-dimension</guid>
    </item>
    <item>
      <title>Sentence Ambiguity, Grammaticality and Complexity Probes</title>
      <link>https://paperswithcode.com/paper/sentence-ambiguity-grammaticality-and</link>
      <description><![CDATA[It is unclear whether, how and where large pre-trained language models capture subtle linguistic traits like ambiguity, grammaticality and sentence complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sentence-ambiguity-grammaticality-and</guid>
    </item>
    <item>
      <title>Empirical Evaluation of Data Augmentations for Biobehavioral Time Series Data with Deep Learning</title>
      <link>https://paperswithcode.com/paper/empirical-evaluation-of-data-augmentations</link>
      <description><![CDATA[As an effective technique to increase the data variability and thus train deep models with better generalization, data augmentation (DA) is a critical step for the success of deep learning models on biobehavioral time series data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/empirical-evaluation-of-data-augmentations</guid>
    </item>
    <item>
      <title>Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features</title>
      <link>https://paperswithcode.com/paper/decoding-visual-neural-representations-by</link>
      <description><![CDATA[Finally, we construct three trimodal matching datasets, and the extensive experiments lead to some interesting conclusions and cognitive insights: 1) decoding novel visual categories from human brain activity is practically possible with good accuracy; 2) decoding models using the combination of visual and linguistic features perform much better than those using either of them alone; 3) visual perception may be accompanied by linguistic influences to represent the semantics of visual stimuli.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decoding-visual-neural-representations-by</guid>
    </item>
    <item>
      <title>ezCoref: Towards Unifying Annotation Guidelines for Coreference Resolution</title>
      <link>https://paperswithcode.com/paper/ezcoref-towards-unifying-annotation</link>
      <description><![CDATA[Large-scale, high-quality corpora are critical for advancing research in coreference resolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ezcoref-towards-unifying-annotation</guid>
    </item>
    <item>
      <title>Sustainable Online Reinforcement Learning for Auto-bidding</title>
      <link>https://paperswithcode.com/paper/sustainable-online-reinforcement-learning-for</link>
      <description><![CDATA[Due to safety concerns, it was believed that the RL training process can only be carried out in an offline virtual advertising system (VAS) that is built based on the historical data generated in the RAS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sustainable-online-reinforcement-learning-for</guid>
    </item>
    <item>
      <title>LIME: Weakly-Supervised Text Classification Without Seeds</title>
      <link>https://paperswithcode.com/paper/lime-weakly-supervised-text-classification-1</link>
      <description><![CDATA[With just an off-the-shelf textual entailment model, LIME outperforms recent baselines in weakly-supervised text classification and achieves state-of-the-art in 4 benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lime-weakly-supervised-text-classification-1</guid>
    </item>
    <item>
      <title>Few-shot Relational Reasoning via Connection Subgraph Pretraining</title>
      <link>https://paperswithcode.com/paper/few-shot-relational-reasoning-via-connection</link>
      <description><![CDATA[Our pretrained model can then be directly applied to target few-shot tasks on without the need for training few-shot tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/few-shot-relational-reasoning-via-connection</guid>
    </item>
    <item>
      <title>A Mixture of Surprises for Unsupervised Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/a-mixture-of-surprises-for-unsupervised</link>
      <description><![CDATA[However, both strategies rely on a strong assumption: the entropy of the environment's dynamics is either high or low.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-mixture-of-surprises-for-unsupervised</guid>
    </item>
    <item>
      <title>H2RBox: Horizonal Box Annotation is All You Need for Oriented Object Detection</title>
      <link>https://paperswithcode.com/paper/h2rbox-horizonal-box-annotation-is-all-you</link>
      <description><![CDATA[This paper proposes a simple yet effective oriented object detection approach called H2RBox merely using horizontal box annotation for weakly-supervised training, which closes the above gap and shows competitive performance even against those trained with rotated boxes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h2rbox-horizonal-box-annotation-is-all-you</guid>
    </item>
    <item>
      <title>Multi-agent Dynamic Algorithm Configuration</title>
      <link>https://paperswithcode.com/paper/multi-agent-dynamic-algorithm-configuration</link>
      <description><![CDATA[MA-DAC formulates the dynamic configuration of a complex algorithm with multiple types of hyperparameters as a contextual multi-agent Markov decision process and solves it by a cooperative multi-agent RL (MARL) algorithm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-agent-dynamic-algorithm-configuration</guid>
    </item>
    <item>
      <title>Sample-Then-Optimize Batch Neural Thompson Sampling</title>
      <link>https://paperswithcode.com/paper/sample-then-optimize-batch-neural-thompson</link>
      <description><![CDATA[linear model), which is equivalently sampled from the GP posterior with the NTK as the kernel function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sample-then-optimize-batch-neural-thompson</guid>
    </item>
    <item>
      <title>Self-explaining deep models with logic rule reasoning</title>
      <link>https://paperswithcode.com/paper/self-explaining-deep-models-with-logic-rule</link>
      <description><![CDATA[We present SELOR, a framework for integrating self-explaining capabilities into a given deep model to achieve both high prediction performance and human precision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-explaining-deep-models-with-logic-rule</guid>
    </item>
    <item>
      <title>SageMix: Saliency-Guided Mixup for Point Clouds</title>
      <link>https://paperswithcode.com/paper/sagemix-saliency-guided-mixup-for-point</link>
      <description><![CDATA[Mixup is a simple and widely-used data augmentation technique that has proven effective in alleviating the problems of overfitting and data scarcity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sagemix-saliency-guided-mixup-for-point</guid>
    </item>
    <item>
      <title>RaP: Redundancy-aware Video-language Pre-training for Text-Video Retrieval</title>
      <link>https://paperswithcode.com/paper/rap-redundancy-aware-video-language-pre</link>
      <description><![CDATA[Sparse sampling is also likely to miss important frames corresponding to some text portions, resulting in textual redundancy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rap-redundancy-aware-video-language-pre</guid>
    </item>
    <item>
      <title>Threshold Treewidth and Hypertree Width</title>
      <link>https://paperswithcode.com/paper/threshold-treewidth-and-hypertree-width</link>
      <description><![CDATA[However, here the order of the polynomial in the running time depends on the width, and this is known to be unavoidable; therefore, the problem is not fixed-parameter tractable parameterized by either of these width measures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/threshold-treewidth-and-hypertree-width</guid>
    </item>
    <item>
      <title>CORL: Research-oriented Deep Offline Reinforcement Learning Library</title>
      <link>https://paperswithcode.com/paper/corl-research-oriented-deep-offline</link>
      <description><![CDATA[CORL is an open-source library that provides single-file implementations of Deep Offline Reinforcement Learning algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/corl-research-oriented-deep-offline</guid>
    </item>
    <item>
      <title>An Additive Autoencoder for Dimension Estimation</title>
      <link>https://paperswithcode.com/paper/an-additive-autoencoder-for-dimension</link>
      <description><![CDATA[An additive autoencoder for dimension reduction, which is composed of a serially performed bias estimation, linear trend estimation, and nonlinear residual estimation, is proposed and analyzed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-additive-autoencoder-for-dimension</guid>
    </item>
    <item>
      <title>Towards Trustworthy Automatic Diagnosis Systems by Emulating Doctors' Reasoning with Deep Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/towards-trustworthy-automatic-diagnosis</link>
      <description><![CDATA[In their initial interaction with patients, doctors do not only focus on identifying the pathology a patient is suffering from; they instead generate a differential diagnosis (in the form of a short list of plausible diseases) because the medical evidence collected from patients is often insufficient to establish a final diagnosis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-trustworthy-automatic-diagnosis</guid>
    </item>
    <item>
      <title>Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation</title>
      <link>https://paperswithcode.com/paper/scaling-back-translation-with-domain-text</link>
      <description><![CDATA[In this paper, to overcome the limitation, we propose a Prompt based domain text Generation (PGEN) approach to produce the large-scale in-domain spoken language text data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-back-translation-with-domain-text</guid>
    </item>
    <item>
      <title>WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis</title>
      <link>https://paperswithcode.com/paper/wavemix-lite-a-resource-efficient-neural-1</link>
      <description><![CDATA[For instance, it achieves state-of-the-art accuracy on five EMNIST datasets, outperforms CNNs and transformers in ImageNet-1K and Places-365, and achieves an mIoU of 77\% on Cityscapes validation set, while using less than one-fifth the number parameters and half the GPU RAM of comparable CNNs or transformers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wavemix-lite-a-resource-efficient-neural-1</guid>
    </item>
    <item>
      <title>Attribution-aware Weight Transfer: A Warm-Start Initialization for Class-Incremental Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/attribution-aware-weight-transfer-a-warm</link>
      <description><![CDATA[In class-incremental semantic segmentation (CISS), deep learning architectures suffer from the critical problems of catastrophic forgetting and semantic background shift.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attribution-aware-weight-transfer-a-warm</guid>
    </item>
    <item>
      <title>HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial Networks</title>
      <link>https://paperswithcode.com/paper/hoechstgan-virtual-lymphocyte-staining-using</link>
      <description><![CDATA[The presence and density of specific types of immune cells are important to understand a patient's immune response to cancer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hoechstgan-virtual-lymphocyte-staining-using</guid>
    </item>
    <item>
      <title>Shape Preserving Facial Landmarks with Graph Attention Networks</title>
      <link>https://paperswithcode.com/paper/shape-preserving-facial-landmarks-with-graph</link>
      <description><![CDATA[Top-performing landmark estimation algorithms are based on exploiting the excellent ability of large convolutional neural networks (CNNs) to represent local appearance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shape-preserving-facial-landmarks-with-graph</guid>
    </item>
    <item>
      <title>SubeventWriter: Iterative Sub-event Sequence Generation with Coherence Controller</title>
      <link>https://paperswithcode.com/paper/subeventwriter-iterative-sub-event-sequence</link>
      <description><![CDATA[In this paper, we propose a new task of sub-event generation for an unseen process to evaluate the understanding of the coherence of sub-event actions and objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/subeventwriter-iterative-sub-event-sequence</guid>
    </item>
    <item>
      <title>Model-Based Offline Reinforcement Learning with Pessimism-Modulated Dynamics Belief</title>
      <link>https://paperswithcode.com/paper/model-based-offline-reinforcement-learning</link>
      <description><![CDATA[To make practical, we further devise an offline RL algorithm to approximately find the solution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/model-based-offline-reinforcement-learning</guid>
    </item>
    <item>
      <title>Unified Vision and Language Prompt Learning</title>
      <link>https://paperswithcode.com/paper/unified-vision-and-language-prompt-learning</link>
      <description><![CDATA[Prompt tuning, a parameter- and data-efficient transfer learning paradigm that tunes only a small number of parameters in a model's input space, has become a trend in the vision community since the emergence of large vision-language models like CLIP.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-vision-and-language-prompt-learning</guid>
    </item>
    <item>
      <title>OpenOOD: Benchmarking Generalized Out-of-Distribution Detection</title>
      <link>https://paperswithcode.com/paper/openood-benchmarking-generalized-out-of</link>
      <description><![CDATA[Out-of-distribution (OOD) detection is vital to safety-critical machine learning applications and has thus been extensively studied, with a plethora of methods developed in the literature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openood-benchmarking-generalized-out-of</guid>
    </item>
    <item>
      <title>Sparse in Space and Time: Audio-visual Synchronisation with Trainable Selectors</title>
      <link>https://paperswithcode.com/paper/sparse-in-space-and-time-audio-visual</link>
      <description><![CDATA[This contrasts with the case of synchronising videos of talking heads, where audio-visual correspondence is dense in both time and space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparse-in-space-and-time-audio-visual</guid>
    </item>
    <item>
      <title>U-HRNet: Delving into Improving Semantic Representation of High Resolution Network for Dense Prediction</title>
      <link>https://paperswithcode.com/paper/u-hrnet-delving-into-improving-semantic</link>
      <description><![CDATA[Therefore, we designed a U-shaped High-Resolution Network (U-HRNet), which adds more stages after the feature map with strongest semantic representation and relaxes the constraint in HRNet that all resolutions need to be calculated parallel for a newly added stage.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/u-hrnet-delving-into-improving-semantic</guid>
    </item>
    <item>
      <title>Corneal endothelium assessment in specular microscopy images with Fuchs' dystrophy via deep regression of signed distance maps</title>
      <link>https://paperswithcode.com/paper/corneal-endothelium-assessment-in-specular</link>
      <description><![CDATA[Specular microscopy assessment of the human corneal endothelium (CE) in Fuchs' dystrophy is challenging due to the presence of dark image regions called guttae.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/corneal-endothelium-assessment-in-specular</guid>
    </item>
    <item>
      <title>Towards a Unified Multi-Dimensional Evaluator for Text Generation</title>
      <link>https://paperswithcode.com/paper/towards-a-unified-multi-dimensional-evaluator</link>
      <description><![CDATA[We re-frame NLG evaluation as a Boolean Question Answering (QA) task, and by guiding the model with different questions, we can use one evaluator to evaluate from multiple dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-a-unified-multi-dimensional-evaluator</guid>
    </item>
    <item>
      <title>Improved Bounds on Neural Complexity for Representing Piecewise Linear Functions</title>
      <link>https://paperswithcode.com/paper/improved-bounds-on-neural-complexity-for</link>
      <description><![CDATA[When the number of pieces is unknown, we prove that, in terms of the number of distinct linear components, the neural complexity of any CPWL function is at most polynomial growth for low-dimensional inputs and a factorial growth for the worst-case scenario, which are significantly better than existing results in the literature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-bounds-on-neural-complexity-for</guid>
    </item>
    <item>
      <title>Prompt-based Connective Prediction Method for Fine-grained Implicit Discourse Relation Recognition</title>
      <link>https://paperswithcode.com/paper/prompt-based-connective-prediction-method-for</link>
      <description><![CDATA[Due to the absence of connectives, implicit discourse relation recognition (IDRR) is still a challenging and crucial task in discourse analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-based-connective-prediction-method-for</guid>
    </item>
    <item>
      <title>PDEBENCH: An Extensive Benchmark for Scientific Machine Learning</title>
      <link>https://paperswithcode.com/paper/pdebench-an-extensive-benchmark-for</link>
      <description><![CDATA[With those metrics we identify tasks which are challenging for recent ML methods and propose these tasks as future challenges for the community.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pdebench-an-extensive-benchmark-for</guid>
    </item>
    <item>
      <title>Wasserstein Barycenter-based Model Fusion and Linear Mode Connectivity of Neural Networks</title>
      <link>https://paperswithcode.com/paper/wasserstein-barycenter-based-model-fusion-and</link>
      <description><![CDATA[In our framework, the fusion occurs in a layer-wise manner and builds on an interpretation of a node in a network as a function of the layer preceding it.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wasserstein-barycenter-based-model-fusion-and</guid>
    </item>
    <item>
      <title>Language Models of Code are Few-Shot Commonsense Learners</title>
      <link>https://paperswithcode.com/paper/language-models-of-code-are-few-shot</link>
      <description><![CDATA[In all these natural language tasks, we show that using our approach, a code generation LM (CODEX) outperforms natural-LMs that are fine-tuned on the target task (e. g., T5) and other strong LMs such as GPT-3 in the few-shot setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-of-code-are-few-shot</guid>
    </item>
  </channel>
</rss>
