<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 26 May 2023 21:05:59 +0000</lastBuildDate>
    <item>
      <title>Exploiting Noise as a Resource for Computation and Learning in Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/exploiting-noise-as-a-resource-for</link>
      <description><![CDATA[Our approach shows how noise may act as a resource for computation and learning and theoretically provides a framework for general SNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploiting-noise-as-a-resource-for</guid>
    </item>
    <item>
      <title>MTCue: Learning Zero-Shot Control of Extra-Textual Attributes by Leveraging Unstructured Context in Neural Machine Translation</title>
      <link>https://paperswithcode.com/paper/mtcue-learning-zero-shot-control-of-extra</link>
      <description><![CDATA[This work introduces MTCue, a novel neural machine translation (NMT) framework that interprets all context (including discrete variables) as text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mtcue-learning-zero-shot-control-of-extra</guid>
    </item>
    <item>
      <title>ChatCAD+: Towards a Universal and Reliable Interactive CAD using LLMs</title>
      <link>https://paperswithcode.com/paper/chatcad-towards-a-universal-and-reliable</link>
      <description><![CDATA[The potential of integrating Computer-Assisted Diagnosis (CAD) with Large Language Models (LLMs) in clinical applications, particularly in digital family doctor and clinic assistant roles, shows promise.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatcad-towards-a-universal-and-reliable</guid>
    </item>
    <item>
      <title>Text-to-Motion Retrieval: Towards Joint Understanding of Human Motion Data and Natural Language</title>
      <link>https://paperswithcode.com/paper/text-to-motion-retrieval-towards-joint</link>
      <description><![CDATA[Due to recent advances in pose-estimation methods, human motion can be extracted from a common video in the form of 3D skeleton sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-to-motion-retrieval-towards-joint</guid>
    </item>
    <item>
      <title>LFTK: Handcrafted Features in Computational Linguistics</title>
      <link>https://paperswithcode.com/paper/lftk-handcrafted-features-in-computational</link>
      <description><![CDATA[We open-source our system for public access to a rich set of pre-implemented handcrafted features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lftk-handcrafted-features-in-computational</guid>
    </item>
    <item>
      <title>Learning Directed Graphical Models with Optimal Transport</title>
      <link>https://paperswithcode.com/paper/learning-directed-graphical-models-with</link>
      <description><![CDATA[Estimating the parameters of a probabilistic directed graphical model from incomplete data remains a long-standing challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-directed-graphical-models-with</guid>
    </item>
    <item>
      <title>Detecting Adversarial Data by Probing Multiple Perturbations Using Expected Perturbation Score</title>
      <link>https://paperswithcode.com/paper/detecting-adversarial-data-by-probing</link>
      <description><![CDATA[Last, we propose an EPS-based adversarial detection (EPS-AD) method, in which we develop EPS-based maximum mean discrepancy (MMD) as a metric to measure the discrepancy between the test sample and natural samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detecting-adversarial-data-by-probing</guid>
    </item>
    <item>
      <title>Combinatorial Bandits for Maximum Value Reward Function under Max Value-Index Feedback</title>
      <link>https://paperswithcode.com/paper/combinatorial-bandits-for-maximum-value</link>
      <description><![CDATA[We propose an algorithm and provide a regret bound for problem instances with stochastic arm outcomes according to arbitrary distributions with finite supports.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/combinatorial-bandits-for-maximum-value</guid>
    </item>
    <item>
      <title>Diversity-Aware Coherence Loss for Improving Neural Topic Models</title>
      <link>https://paperswithcode.com/paper/diversity-aware-coherence-loss-for-improving</link>
      <description><![CDATA[The standard approach for neural topic modeling uses a variational autoencoder (VAE) framework that jointly minimizes the KL divergence between the estimated posterior and prior, in addition to the reconstruction loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diversity-aware-coherence-loss-for-improving</guid>
    </item>
    <item>
      <title>Beyond Reward: Offline Preference-guided Policy Optimization</title>
      <link>https://paperswithcode.com/paper/beyond-reward-offline-preference-guided</link>
      <description><![CDATA[Instead, the agent is provided with pre-existing offline trajectories and human preferences between pairs of trajectories to extract the dynamics and task information, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-reward-offline-preference-guided</guid>
    </item>
    <item>
      <title>Non-adversarial training of Neural SDEs with signature kernel scores</title>
      <link>https://paperswithcode.com/paper/non-adversarial-training-of-neural-sdes-with</link>
      <description><![CDATA[Neural SDEs are continuous-time generative models for sequential data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/non-adversarial-training-of-neural-sdes-with</guid>
    </item>
    <item>
      <title>A Guide Through the Zoo of Biased SGD</title>
      <link>https://paperswithcode.com/paper/a-guide-through-the-zoo-of-biased-sgd</link>
      <description><![CDATA[Although SGD with unbiased gradient estimators has been studied extensively over at least half a century, SGD variants relying on biased estimators are rare.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-guide-through-the-zoo-of-biased-sgd</guid>
    </item>
    <item>
      <title>Morphological Inflection: A Reality Check</title>
      <link>https://paperswithcode.com/paper/morphological-inflection-a-reality-check</link>
      <description><![CDATA[Morphological inflection is a popular task in sub-word NLP with both practical and cognitive applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/morphological-inflection-a-reality-check</guid>
    </item>
    <item>
      <title>Sharpness-Aware Minimization Leads to Low-Rank Features</title>
      <link>https://paperswithcode.com/paper/sharpness-aware-minimization-leads-to-low</link>
      <description><![CDATA[While its generalization improvement is well-known and is the primary motivation, we uncover an additional intriguing effect of SAM: reduction of the feature rank which happens at different layers of a neural network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sharpness-aware-minimization-leads-to-low</guid>
    </item>
    <item>
      <title>On the Planning Abilities of Large Language Models -- A Critical Investigation</title>
      <link>https://paperswithcode.com/paper/on-the-planning-abilities-of-large-language-1</link>
      <description><![CDATA[Intrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-planning-abilities-of-large-language-1</guid>
    </item>
    <item>
      <title>Anomaly Detection with Conditioned Denoising Diffusion Models</title>
      <link>https://paperswithcode.com/paper/anomaly-detection-with-conditioned-denoising</link>
      <description><![CDATA[We propose a novel denoising process for image reconstruction conditioned on a target image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anomaly-detection-with-conditioned-denoising</guid>
    </item>
    <item>
      <title>On sampling determinantal and Pfaffian point processes on a quantum computer</title>
      <link>https://paperswithcode.com/paper/on-sampling-determinantal-and-pfaffian-point</link>
      <description><![CDATA[Most applications require sampling from a DPP, and given their quantum origin, it is natural to wonder whether sampling a DPP on a quantum computer is easier than on a classical one.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-sampling-determinantal-and-pfaffian-point</guid>
    </item>
    <item>
      <title>ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation</title>
      <link>https://paperswithcode.com/paper/prolificdreamer-high-fidelity-and-diverse</link>
      <description><![CDATA[In this work, we propose to model the 3D parameter as a random variable instead of a constant as in SDS and present variational score distillation (VSD), a principled particle-based variational framework to explain and address the aforementioned issues in text-to-3D generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prolificdreamer-high-fidelity-and-diverse</guid>
    </item>
    <item>
      <title>SING: A Plug-and-Play DNN Learning Technique</title>
      <link>https://paperswithcode.com/paper/sing-a-plug-and-play-dnn-learning-technique</link>
      <description><![CDATA[We propose SING (StabIlized and Normalized Gradient), a plug-and-play technique that improves the stability and generalization of the Adam(W) optimizer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sing-a-plug-and-play-dnn-learning-technique</guid>
    </item>
    <item>
      <title>A Similarity Alignment Model for Video Copy Segment Matching</title>
      <link>https://paperswithcode.com/paper/a-similarity-alignment-model-for-video-copy</link>
      <description><![CDATA[We propose a Similarity Alignment Model(SAM) for video copy segment matching.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-similarity-alignment-model-for-video-copy</guid>
    </item>
    <item>
      <title>The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/the-benefits-of-being-distributional-small</link>
      <description><![CDATA[While distributional reinforcement learning (RL) has demonstrated empirical success, the question of when and why it is beneficial has remained unanswered.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-benefits-of-being-distributional-small</guid>
    </item>
    <item>
      <title>Knowledge Diffusion for Distillation</title>
      <link>https://paperswithcode.com/paper/knowledge-diffusion-for-distillation</link>
      <description><![CDATA[To address this, we propose to denoise student features using a diffusion model trained by teacher features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/knowledge-diffusion-for-distillation</guid>
    </item>
    <item>
      <title>MPE4G: Multimodal Pretrained Encoder for Co-Speech Gesture Generation</title>
      <link>https://paperswithcode.com/paper/mpe4g-multimodal-pretrained-encoder-for-co</link>
      <description><![CDATA[Through the series of experiments and human evaluation, the proposed method renders realistic co-speech gestures not only when all input modalities are given but also when the input modalities are missing or noisy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mpe4g-multimodal-pretrained-encoder-for-co</guid>
    </item>
    <item>
      <title>TLNets: Transformation Learning Networks for long-range time-series prediction</title>
      <link>https://paperswithcode.com/paper/tlnets-transformation-learning-networks-for</link>
      <description><![CDATA[Note that the FT and SVD blocks are capable of learning global information, while the Conv blocks focus on learning local information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tlnets-transformation-learning-networks-for</guid>
    </item>
    <item>
      <title>Revisiting non-English Text Simplification: A Unified Multilingual Benchmark</title>
      <link>https://paperswithcode.com/paper/revisiting-non-english-text-simplification-a</link>
      <description><![CDATA[However, less work has been done on multilingual text simplification due to the lack of a diverse evaluation benchmark that covers complex-simple sentence pairs in many languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-non-english-text-simplification-a</guid>
    </item>
    <item>
      <title>How to Turn Your Knowledge Graph Embeddings into Generative Models via Probabilistic Circuits</title>
      <link>https://paperswithcode.com/paper/how-to-turn-your-knowledge-graph-embeddings</link>
      <description><![CDATA[Some of the most successful knowledge graph embedding (KGE) models for link prediction -- CP, RESCAL, TuckER, ComplEx -- can be interpreted as energy-based models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-to-turn-your-knowledge-graph-embeddings</guid>
    </item>
    <item>
      <title>NaSGEC: a Multi-Domain Chinese Grammatical Error Correction Dataset from Native Speaker Texts</title>
      <link>https://paperswithcode.com/paper/nasgec-a-multi-domain-chinese-grammatical</link>
      <description><![CDATA[We introduce NaSGEC, a new dataset to facilitate research on Chinese grammatical error correction (CGEC) for native speaker texts from multiple domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nasgec-a-multi-domain-chinese-grammatical</guid>
    </item>
    <item>
      <title>UpMax: User partitioning for MaxSAT</title>
      <link>https://paperswithcode.com/paper/upmax-user-partitioning-for-maxsat</link>
      <description><![CDATA[It has been shown that Maximum Satisfiability (MaxSAT) problem instances can be effectively solved by partitioning the set of soft clauses into several disjoint sets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/upmax-user-partitioning-for-maxsat</guid>
    </item>
    <item>
      <title>Diversify Your Vision Datasets with Automatic Diffusion-Based Augmentation</title>
      <link>https://paperswithcode.com/paper/diversify-your-vision-datasets-with-automatic</link>
      <description><![CDATA[We introduce ALIA (Automated Language-guided Image Augmentation), a method which utilizes large vision and language models to automatically generate natural language descriptions of a dataset's domains and augment the training data via language-guided image editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diversify-your-vision-datasets-with-automatic</guid>
    </item>
    <item>
      <title>C-MCTS: Safe Planning with Monte Carlo Tree Search</title>
      <link>https://paperswithcode.com/paper/c-mcts-safe-planning-with-monte-carlo-tree</link>
      <description><![CDATA[We propose Constrained MCTS (C-MCTS), an algorithm that estimates cost using a safety critic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/c-mcts-safe-planning-with-monte-carlo-tree</guid>
    </item>
    <item>
      <title>Detecting Dataset Drift and Non-IID Sampling via k-Nearest Neighbors</title>
      <link>https://paperswithcode.com/paper/detecting-dataset-drift-and-non-iid-sampling</link>
      <description><![CDATA[We present a straightforward statistical test to detect certain violations of the assumption that the data are Independent and Identically Distributed (IID).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detecting-dataset-drift-and-non-iid-sampling</guid>
    </item>
    <item>
      <title>Fascinating Supervisory Signals and Where to Find Them: Deep Anomaly Detection with Scale Learning</title>
      <link>https://paperswithcode.com/paper/fascinating-supervisory-signals-and-where-to</link>
      <description><![CDATA[Due to the unsupervised nature of anomaly detection, the key to fueling deep models is finding supervisory signals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fascinating-supervisory-signals-and-where-to</guid>
    </item>
    <item>
      <title>Feature Collapse</title>
      <link>https://paperswithcode.com/paper/feature-collapse</link>
      <description><![CDATA[We formalize and study a phenomenon called feature collapse that makes precise the intuitive idea that entities playing a similar role in a learning task receive similar representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/feature-collapse</guid>
    </item>
    <item>
      <title>Revisiting Non-Autoregressive Translation at Scale</title>
      <link>https://paperswithcode.com/paper/revisiting-non-autoregressive-translation-at</link>
      <description><![CDATA[In real-world systems, scaling has been critical for improving the translation quality in autoregressive translation (AT), which however has not been well studied for non-autoregressive translation (NAT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-non-autoregressive-translation-at</guid>
    </item>
    <item>
      <title>MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization</title>
      <link>https://paperswithcode.com/paper/memex-detecting-explanatory-evidence-for</link>
      <description><![CDATA[In this work, we propose a novel task, MEMEX - given a meme and a related document, the aim is to mine the context that succinctly explains the background of the meme.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memex-detecting-explanatory-evidence-for</guid>
    </item>
    <item>
      <title>Referred by Multi-Modality: A Unified Temporal Transformer for Video Object Segmentation</title>
      <link>https://paperswithcode.com/paper/referred-by-multi-modality-a-unified-temporal</link>
      <description><![CDATA[In this paper, we propose MUTR, a Multi-modal Unified Temporal transformer for Referring video object segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/referred-by-multi-modality-a-unified-temporal</guid>
    </item>
    <item>
      <title>Private Meeting Summarization Without Performance Loss</title>
      <link>https://paperswithcode.com/paper/private-meeting-summarization-without</link>
      <description><![CDATA[Meeting summarization has an enormous business potential, but in addition to being a hard problem, roll-out is challenged by privacy concerns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/private-meeting-summarization-without</guid>
    </item>
    <item>
      <title>Sharpness-Aware Minimization Revisited: Weighted Sharpness as a Regularization Term</title>
      <link>https://paperswithcode.com/paper/sharpness-aware-minimization-revisited</link>
      <description><![CDATA[Deep Neural Networks (DNNs) generalization is known to be closely related to the flatness of minima, leading to the development of Sharpness-Aware Minimization (SAM) for seeking flatter minima and better generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sharpness-aware-minimization-revisited</guid>
    </item>
    <item>
      <title>Scaling Data-Constrained Language Models</title>
      <link>https://paperswithcode.com/paper/scaling-data-constrained-language-models</link>
      <description><![CDATA[We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-data-constrained-language-models</guid>
    </item>
    <item>
      <title>Surface-Based Retrieval Reduces Perplexity of Retrieval-Augmented Language Models</title>
      <link>https://paperswithcode.com/paper/surface-based-retrieval-reduces-perplexity-of</link>
      <description><![CDATA[Inspired by this, we replace the semantic retrieval in Retro with a surface-level method based on BM25, obtaining a significant reduction in perplexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surface-based-retrieval-reduces-perplexity-of</guid>
    </item>
    <item>
      <title>IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages</title>
      <link>https://paperswithcode.com/paper/indictrans2-towards-high-quality-and</link>
      <description><![CDATA[Prior to this work, there was (i) no parallel training data spanning all the 22 languages, (ii) no robust benchmarks covering all these languages and containing content relevant to India, and (iii) no existing translation models which support all the 22 scheduled languages of India.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/indictrans2-towards-high-quality-and</guid>
    </item>
    <item>
      <title>CSS: A Large-scale Cross-schema Chinese Text-to-SQL Medical Dataset</title>
      <link>https://paperswithcode.com/paper/css-a-large-scale-cross-schema-chinese-text</link>
      <description><![CDATA[Furthermore, we present CSS, a large-scale CrosS-Schema Chinese text-to-SQL dataset, to carry on corresponding studies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/css-a-large-scale-cross-schema-chinese-text</guid>
    </item>
    <item>
      <title>Bhasha-Abhijnaanam: Native-script and romanized Language Identification for 22 Indic languages</title>
      <link>https://paperswithcode.com/paper/bhasha-abhijnaanam-native-script-and</link>
      <description><![CDATA[We create publicly available language identification (LID) datasets and models in all 22 Indian languages listed in the Indian constitution in both native-script and romanized text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bhasha-abhijnaanam-native-script-and</guid>
    </item>
    <item>
      <title>Learn to Not Link: Exploring NIL Prediction in Entity Linking</title>
      <link>https://paperswithcode.com/paper/learn-to-not-link-exploring-nil-prediction-in</link>
      <description><![CDATA[We conduct a series of experiments with the widely used bi-encoder and cross-encoder entity linking models, results show that both types of NIL mentions in training data have a significant influence on the accuracy of NIL prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learn-to-not-link-exploring-nil-prediction-in</guid>
    </item>
    <item>
      <title>Multilingual Text-to-Speech Synthesis for Turkic Languages Using Transliteration</title>
      <link>https://paperswithcode.com/paper/multilingual-text-to-speech-synthesis-for</link>
      <description><![CDATA[This work aims to build a multilingual text-to-speech (TTS) synthesis system for ten lower-resourced Turkic languages: Azerbaijani, Bashkir, Kazakh, Kyrgyz, Sakha, Tatar, Turkish, Turkmen, Uyghur, and Uzbek.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multilingual-text-to-speech-synthesis-for</guid>
    </item>
    <item>
      <title>ConvGQR: Generative Query Reformulation for Conversational Search</title>
      <link>https://paperswithcode.com/paper/convgqr-generative-query-reformulation-for</link>
      <description><![CDATA[In this paper, we propose ConvGQR, a new framework to reformulate conversational queries based on generative pre-trained language models (PLMs), one for query rewriting and another for generating potential answers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/convgqr-generative-query-reformulation-for</guid>
    </item>
    <item>
      <title>Towards Higher Pareto Frontier in Multilingual Machine Translation</title>
      <link>https://paperswithcode.com/paper/towards-higher-pareto-frontier-in</link>
      <description><![CDATA[Multilingual neural machine translation has witnessed remarkable progress in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-higher-pareto-frontier-in</guid>
    </item>
    <item>
      <title>Enhancing Grammatical Error Correction Systems with Explanations</title>
      <link>https://paperswithcode.com/paper/enhancing-grammatical-error-correction</link>
      <description><![CDATA[Grammatical error correction systems improve written communication by detecting and correcting language mistakes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-grammatical-error-correction</guid>
    </item>
    <item>
      <title>Unifying gradient regularization for Heterogeneous Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/unifying-gradient-regularization-for</link>
      <description><![CDATA[Grug provides a unified framework integrating graph topology and node features, based on which we conduct a detailed theoretical analysis of their effectiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unifying-gradient-regularization-for</guid>
    </item>
    <item>
      <title>ProSpect: Expanded Conditioning for the Personalization of Attribute-aware Image Generation</title>
      <link>https://paperswithcode.com/paper/prospect-expanded-conditioning-for-the</link>
      <description><![CDATA[Personalizing generative models offers a way to guide image generation with user-provided references.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prospect-expanded-conditioning-for-the</guid>
    </item>
  </channel>
</rss>
