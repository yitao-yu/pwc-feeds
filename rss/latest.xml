<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 14 Jun 2024 21:08:35 +0000</lastBuildDate>
    <item>
      <title>Unpacking DPO and PPO: Disentangling Best Practices for Learning from Preference Feedback</title>
      <link>https://paperswithcode.com/paper/unpacking-dpo-and-ppo-disentangling-best</link>
      <description><![CDATA[High-quality preference data leads to improvements of up to 8% in instruction following and truthfulness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unpacking-dpo-and-ppo-disentangling-best</guid>
    </item>
    <item>
      <title>Few-Shot Anomaly Detection via Category-Agnostic Registration Learning</title>
      <link>https://paperswithcode.com/paper/few-shot-anomaly-detection-via-category</link>
      <description><![CDATA[Inspired by how humans detect anomalies, by comparing a query image to known normal ones, this paper proposes a novel few-shot anomaly detection (FSAD) framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/few-shot-anomaly-detection-via-category</guid>
    </item>
    <item>
      <title>Understanding the Generalizability of Link Predictors Under Distribution Shifts on Graphs</title>
      <link>https://paperswithcode.com/paper/understanding-the-generalizability-of-link</link>
      <description><![CDATA[To tackle the distribution shift problem, recent work focuses on creating datasets that feature distribution shifts and designing generalization methods that perform well on the new data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-the-generalizability-of-link</guid>
    </item>
    <item>
      <title>Chain of Preference Optimization: Improving Chain-of-Thought Reasoning in LLMs</title>
      <link>https://paperswithcode.com/paper/chain-of-preference-optimization-improving</link>
      <description><![CDATA[The recent development of chain-of-thought (CoT) decoding has enabled large language models (LLMs) to generate explicit logical reasoning paths for complex problem-solving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chain-of-preference-optimization-improving</guid>
    </item>
    <item>
      <title>Understanding Hallucinations in Diffusion Models through Mode Interpolation</title>
      <link>https://paperswithcode.com/paper/understanding-hallucinations-in-diffusion</link>
      <description><![CDATA[Specifically, we find that diffusion models smoothly "interpolate" between nearby data modes in the training set, to generate samples that are completely outside the support of the original training distribution; this phenomenon leads diffusion models to generate artifacts that never existed in real data (i. e., hallucinations).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-hallucinations-in-diffusion</guid>
    </item>
    <item>
      <title>AIM: Attributing, Interpreting, Mitigating Data Unfairness</title>
      <link>https://paperswithcode.com/paper/aim-attributing-interpreting-mitigating-data</link>
      <description><![CDATA[Data collected in the real world often encapsulates historical discrimination against disadvantaged groups and individuals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aim-attributing-interpreting-mitigating-data</guid>
    </item>
    <item>
      <title>VideoGPT+: Integrating Image and Video Encoders for Enhanced Video Understanding</title>
      <link>https://paperswithcode.com/paper/videogpt-integrating-image-and-video-encoders</link>
      <description><![CDATA[Building on the advances of language models, Large Multimodal Models (LMMs) have contributed significant improvements in video understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videogpt-integrating-image-and-video-encoders</guid>
    </item>
    <item>
      <title>AdaRevD: Adaptive Patch Exiting Reversible Decoder Pushes the Limit of Image Deblurring</title>
      <link>https://paperswithcode.com/paper/adarevd-adaptive-patch-exiting-reversible-1</link>
      <description><![CDATA[Despite the recent progress in enhancing the efficacy of image deblurring, the limited decoding capability constrains the upper limit of State-Of-The-Art (SOTA) methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adarevd-adaptive-patch-exiting-reversible-1</guid>
    </item>
    <item>
      <title>SR-CACO-2: A Dataset for Confocal Fluorescence Microscopy Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/sr-caco-2-a-dataset-for-confocal-fluorescence</link>
      <description><![CDATA[Given the new SR-CACO-2 dataset, we also provide benchmarking results for 15 state-of-the-art methods that are representative of the main SISR families.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sr-caco-2-a-dataset-for-confocal-fluorescence</guid>
    </item>
    <item>
      <title>MLKV: Multi-Layer Key-Value Heads for Memory Efficient Transformer Decoding</title>
      <link>https://paperswithcode.com/paper/mlkv-multi-layer-key-value-heads-for-memory</link>
      <description><![CDATA[Auto-regressive inference of transformers benefit greatly from Key-Value (KV) caching, but can lead to major memory bottlenecks as model size, batch size, and sequence length grow at scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mlkv-multi-layer-key-value-heads-for-memory</guid>
    </item>
    <item>
      <title>A Comprehensive Graph Pooling Benchmark: Effectiveness, Robustness and Generalizability</title>
      <link>https://paperswithcode.com/paper/a-comprehensive-graph-pooling-benchmark</link>
      <description><![CDATA[Graph pooling has gained attention for its ability to obtain effective node and graph representations for various downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comprehensive-graph-pooling-benchmark</guid>
    </item>
    <item>
      <title>Multi-Agent Software Development through Cross-Team Collaboration</title>
      <link>https://paperswithcode.com/paper/multi-agent-software-development-through</link>
      <description><![CDATA[We anticipate that our work will guide LLM agents towards a cross-team paradigm and contribute to their significant growth in but not limited to software development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-agent-software-development-through</guid>
    </item>
    <item>
      <title>ProxyLM: Predicting Language Model Performance on Multilingual Tasks via Proxy Models</title>
      <link>https://paperswithcode.com/paper/proxylm-predicting-language-model-performance</link>
      <description><![CDATA[Performance prediction is a method to estimate the performance of multilingual language models (LMs), mitigating computational costs associated with model capacity and data for fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proxylm-predicting-language-model-performance</guid>
    </item>
    <item>
      <title>Fredformer: Frequency Debiased Transformer for Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/fredformer-frequency-debiased-transformer-for</link>
      <description><![CDATA[This bias prevents the model from accurately capturing important high-frequency data features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fredformer-frequency-debiased-transformer-for</guid>
    </item>
    <item>
      <title>Large-Scale Evaluation of Open-Set Image Classification Techniques</title>
      <link>https://paperswithcode.com/paper/large-scale-evaluation-of-open-set-image</link>
      <description><![CDATA[However, most methods misclassify samples with unseen labels and assign them to one of the known classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-scale-evaluation-of-open-set-image</guid>
    </item>
    <item>
      <title>Learning conditional distributions on continuous spaces</title>
      <link>https://paperswithcode.com/paper/learning-conditional-distributions-on</link>
      <description><![CDATA[We propose to incorporate the nearest neighbors method into neural network training, as our empirical analysis indicates it has better performance in practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-conditional-distributions-on</guid>
    </item>
    <item>
      <title>JailbreakEval: An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models</title>
      <link>https://paperswithcode.com/paper/jailbreakeval-an-integrated-toolkit-for</link>
      <description><![CDATA[Jailbreak attacks aim to induce Large Language Models (LLMs) to generate harmful responses for forbidden instructions, presenting severe misuse threats to LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jailbreakeval-an-integrated-toolkit-for</guid>
    </item>
    <item>
      <title>Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs</title>
      <link>https://paperswithcode.com/paper/bag-of-tricks-benchmarking-of-jailbreak</link>
      <description><![CDATA[Although Large Language Models (LLMs) have demonstrated significant capabilities in executing complex tasks in a zero-shot manner, they are susceptible to jailbreak attacks and can be manipulated to produce harmful outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bag-of-tricks-benchmarking-of-jailbreak</guid>
    </item>
    <item>
      <title>Blind Super-Resolution via Meta-learning and Markov Chain Monte Carlo Simulation</title>
      <link>https://paperswithcode.com/paper/blind-super-resolution-via-meta-learning-and</link>
      <description><![CDATA[Learning-based approaches have witnessed great successes in blind single image super-resolution (SISR) tasks, however, handcrafted kernel priors and learning based kernel priors are typically required.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blind-super-resolution-via-meta-learning-and</guid>
    </item>
    <item>
      <title>INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance</title>
      <link>https://paperswithcode.com/paper/ins-mmbench-a-comprehensive-benchmark-for</link>
      <description><![CDATA[There is no systematic review of multimodal tasks in the insurance domain, nor a benchmark specifically designed to evaluate the capabilities of LVLMs in insurance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ins-mmbench-a-comprehensive-benchmark-for</guid>
    </item>
    <item>
      <title>Towards Evaluating the Robustness of Visual State Space Models</title>
      <link>https://paperswithcode.com/paper/towards-evaluating-the-robustness-of-visual</link>
      <description><![CDATA[To gain a deeper understanding of VSSMs' adversarial robustness, we conduct a frequency analysis of adversarial attacks, evaluating their performance against low-frequency and high-frequency perturbations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-evaluating-the-robustness-of-visual</guid>
    </item>
    <item>
      <title>Exploring the Spectrum of Visio-Linguistic Compositionality and Recognition</title>
      <link>https://paperswithcode.com/paper/exploring-the-spectrum-of-visio-linguistic</link>
      <description><![CDATA[Vision and language models (VLMs) such as CLIP have showcased remarkable zero-shot recognition abilities yet face challenges in visio-linguistic compositionality, particularly in linguistic comprehension and fine-grained image-text alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-spectrum-of-visio-linguistic</guid>
    </item>
    <item>
      <title>Conceptual Learning via Embedding Approximations for Reinforcing Interpretability and Transparency</title>
      <link>https://paperswithcode.com/paper/conceptual-learning-via-embedding</link>
      <description><![CDATA[The code for our experiments is available at https://github. com/clearProject/CLEAR/tree/main]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conceptual-learning-via-embedding</guid>
    </item>
    <item>
      <title>Scene Graph Generation in Large-Size VHR Satellite Imagery: A Large-Scale Dataset and A Context-Aware Approach</title>
      <link>https://paperswithcode.com/paper/scene-graph-generation-in-large-size-vhr</link>
      <description><![CDATA[Furthermore, a relationship prediction network with context-aware messaging (RPCM) is proposed to predict the relationship types of these pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scene-graph-generation-in-large-size-vhr</guid>
    </item>
    <item>
      <title>Scalable and Flexible Causal Discovery with an Efficient Test for Adjacency</title>
      <link>https://paperswithcode.com/paper/scalable-and-flexible-causal-discovery-with</link>
      <description><![CDATA[We build a graph learning method based on DAT, DAT-Graph, that can also learn from data with interventions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-and-flexible-causal-discovery-with</guid>
    </item>
    <item>
      <title>MMScan: A Multi-Modal 3D Scene Dataset with Hierarchical Grounded Language Annotations</title>
      <link>https://paperswithcode.com/paper/mmscan-a-multi-modal-3d-scene-dataset-with</link>
      <description><![CDATA[With the emergence of LLMs and their integration with other data modalities, multi-modal 3D perception attracts more attention due to its connectivity to the physical world and makes rapid progress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmscan-a-multi-modal-3d-scene-dataset-with</guid>
    </item>
    <item>
      <title>On Softmax Direct Preference Optimization for Recommendation</title>
      <link>https://paperswithcode.com/paper/on-softmax-direct-preference-optimization-for</link>
      <description><![CDATA[Specifically, we incorporate multiple negatives in user preference data and devise an alternative version of DPO loss tailored for LM-based recommenders, connected to softmax sampling strategies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-softmax-direct-preference-optimization-for</guid>
    </item>
    <item>
      <title>Vertical LoRA: Dense Expectation-Maximization Interpretation of Transformers</title>
      <link>https://paperswithcode.com/paper/vertical-lora-dense-expectation-maximization</link>
      <description><![CDATA[The results show that 1) with VLoRA, the Transformer model parameter count can be reduced dramatically and 2) the performance of the original model is preserved.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vertical-lora-dense-expectation-maximization</guid>
    </item>
    <item>
      <title>3D Building Generation in Minecraft via Large Language Models</title>
      <link>https://paperswithcode.com/paper/3d-building-generation-in-minecraft-via-large</link>
      <description><![CDATA[Recently, procedural content generation has exhibited considerable advancements in the domain of 2D game level generation such as Super Mario Bros. and Sokoban through large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-building-generation-in-minecraft-via-large</guid>
    </item>
    <item>
      <title>Classic GNNs are Strong Baselines: Reassessing GNNs for Node Classification</title>
      <link>https://paperswithcode.com/paper/classic-gnns-are-strong-baselines-reassessing</link>
      <description><![CDATA[Graph Transformers (GTs) have recently emerged as popular alternatives to traditional message-passing Graph Neural Networks (GNNs), due to their theoretically superior expressiveness and impressive performance reported on standard node classification benchmarks, often significantly outperforming GNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/classic-gnns-are-strong-baselines-reassessing</guid>
    </item>
    <item>
      <title>Potion: Towards Poison Unlearning</title>
      <link>https://paperswithcode.com/paper/potion-towards-poison-unlearning</link>
      <description><![CDATA[The requirements for this task significantly deviate from privacy-focused unlearning where all of the data to be forgotten by the model is known.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/potion-towards-poison-unlearning</guid>
    </item>
    <item>
      <title>Needle In A Video Haystack: A Scalable Synthetic Framework for Benchmarking Video MLLMs</title>
      <link>https://paperswithcode.com/paper/needle-in-a-video-haystack-a-scalable</link>
      <description><![CDATA[Additionally, we evaluated recent video-centric multimodal large language models (MLLMs), both open-source and proprietary, providing a comprehensive analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/needle-in-a-video-haystack-a-scalable</guid>
    </item>
    <item>
      <title>Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?</title>
      <link>https://paperswithcode.com/paper/living-in-the-moment-can-large-language</link>
      <description><![CDATA[Temporal reasoning is fundamental for large language models (LLMs) to comprehend the world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/living-in-the-moment-can-large-language</guid>
    </item>
    <item>
      <title>Interpreting the Weight Space of Customized Diffusion Models</title>
      <link>https://paperswithcode.com/paper/interpreting-the-weight-space-of-customized</link>
      <description><![CDATA[First, as each point in the space corresponds to an identity, sampling a set of weights from it results in a model encoding a novel identity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpreting-the-weight-space-of-customized</guid>
    </item>
    <item>
      <title>Investigating the translation capabilities of Large Language Models trained on parallel data only</title>
      <link>https://paperswithcode.com/paper/investigating-the-translation-capabilities-of</link>
      <description><![CDATA[In recent years, Large Language Models (LLMs) have demonstrated exceptional proficiency across a broad spectrum of Natural Language Processing (NLP) tasks, including Machine Translation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/investigating-the-translation-capabilities-of</guid>
    </item>
    <item>
      <title>Explore the Limits of Omni-modal Pretraining at Scale</title>
      <link>https://paperswithcode.com/paper/explore-the-limits-of-omni-modal-pretraining</link>
      <description><![CDATA[We propose to build omni-modal intelligence, which is capable of understanding any modality and learning universal representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explore-the-limits-of-omni-modal-pretraining</guid>
    </item>
    <item>
      <title>SciKnowEval: Evaluating Multi-level Scientific Knowledge of Large Language Models</title>
      <link>https://paperswithcode.com/paper/sciknoweval-evaluating-multi-level-scientific</link>
      <description><![CDATA[The burgeoning utilization of Large Language Models (LLMs) in scientific research necessitates advanced benchmarks capable of evaluating their understanding and application of scientific knowledge comprehensively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sciknoweval-evaluating-multi-level-scientific</guid>
    </item>
    <item>
      <title>OmniTokenizer: A Joint Image-Video Tokenizer for Visual Generation</title>
      <link>https://paperswithcode.com/paper/omnitokenizer-a-joint-image-video-tokenizer</link>
      <description><![CDATA[To exploit the complementary nature of image and video data, we further propose a progressive training strategy, where OmniTokenizer is first trained on image data on a fixed resolution to develop the spatial encoding capacity and then jointly trained on image and video data on multiple resolutions to learn the temporal dynamics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnitokenizer-a-joint-image-video-tokenizer</guid>
    </item>
    <item>
      <title>Pareto Front-Diverse Batch Multi-Objective Bayesian Optimization</title>
      <link>https://paperswithcode.com/paper/pareto-front-diverse-batch-multi-objective</link>
      <description><![CDATA[We solve a cheap MOO problem by assigning the selected acquisition function for each expensive objective function to obtain a candidate set of inputs for evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pareto-front-diverse-batch-multi-objective</guid>
    </item>
    <item>
      <title>Understanding Jailbreak Success: A Study of Latent Space Dynamics in Large Language Models</title>
      <link>https://paperswithcode.com/paper/understanding-jailbreak-success-a-study-of</link>
      <description><![CDATA[Conversational Large Language Models are trained to refuse to answer harmful questions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-jailbreak-success-a-study-of</guid>
    </item>
    <item>
      <title>Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging Co-Attention Cues in Multitask Learning</title>
      <link>https://paperswithcode.com/paper/exploring-multilingual-unseen-speaker-emotion</link>
      <description><![CDATA[Advent of modern deep learning techniques has given rise to advancements in the field of Speech Emotion Recognition (SER).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-multilingual-unseen-speaker-emotion</guid>
    </item>
    <item>
      <title>Data Attribution for Text-to-Image Models by Unlearning Synthesized Images</title>
      <link>https://paperswithcode.com/paper/data-attribution-for-text-to-image-models-by</link>
      <description><![CDATA[The goal of data attribution for text-to-image models is to identify the training images that most influence the generation of a new image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-attribution-for-text-to-image-models-by</guid>
    </item>
    <item>
      <title>Multiple Prior Representation Learning for Self-Supervised Monocular Depth Estimation via Hybrid Transformer</title>
      <link>https://paperswithcode.com/paper/multiple-prior-representation-learning-for</link>
      <description><![CDATA[To address these challenges, we introduce a novel self-supervised monocular depth estimation model that leverages multiple priors to bolster representation capabilities across spatial, context, and semantic dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiple-prior-representation-learning-for</guid>
    </item>
    <item>
      <title>Towards Vision-Language Geo-Foundation Model: A Survey</title>
      <link>https://paperswithcode.com/paper/towards-vision-language-geo-foundation-model</link>
      <description><![CDATA[Vision-Language Foundation Models (VLFMs) have made remarkable progress on various multimodal tasks, such as image captioning, image-text retrieval, visual question answering, and visual grounding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-vision-language-geo-foundation-model</guid>
    </item>
    <item>
      <title>EgoExo-Fitness: Towards Egocentric and Exocentric Full-Body Action Understanding</title>
      <link>https://paperswithcode.com/paper/egoexo-fitness-towards-egocentric-and</link>
      <description><![CDATA[To facilitate research on egocentric and exocentric full-body action understanding, we construct benchmarks on a suite of tasks (i. e., action classification, action localization, cross-view sequence verification, cross-view skill determination, and a newly proposed task of guidance-based execution verification), together with detailed analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/egoexo-fitness-towards-egocentric-and</guid>
    </item>
    <item>
      <title>BTS: Building Timeseries Dataset: Empowering Large-Scale Building Analytics</title>
      <link>https://paperswithcode.com/paper/bts-building-timeseries-dataset-empowering</link>
      <description><![CDATA[Buildings play a crucial role in human well-being, influencing occupant comfort, health, and safety.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bts-building-timeseries-dataset-empowering</guid>
    </item>
    <item>
      <title>Navigating the Shadows: Unveiling Effective Disturbances for Modern AI Content Detectors</title>
      <link>https://paperswithcode.com/paper/navigating-the-shadows-unveiling-effective</link>
      <description><![CDATA[Furthermore, through adversarial learning experiments, we investigate the impact of perturbation data augmentation on the robustness of AI-text detectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/navigating-the-shadows-unveiling-effective</guid>
    </item>
    <item>
      <title>Reinforcement Learning to Disentangle Multiqubit Quantum States from Partial Observations</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-to-disentangle</link>
      <description><![CDATA[We present a deep reinforcement learning (RL) approach to constructing short disentangling circuits for arbitrary 4-, 5-, and 6-qubit states using an actor-critic algorithm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-to-disentangle</guid>
    </item>
    <item>
      <title>Accurate Explanation Model for Image Classifiers using Class Association Embedding</title>
      <link>https://paperswithcode.com/paper/accurate-explanation-model-for-image</link>
      <description><![CDATA[Recombining the individual code of a given sample with altered class-associated code leads to a synthetic real-looking sample with preserved individual characters but modified class-associated features and possibly flipped class assignments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accurate-explanation-model-for-image</guid>
    </item>
    <item>
      <title>Enhancing End-to-End Autonomous Driving with Latent World Model</title>
      <link>https://paperswithcode.com/paper/enhancing-end-to-end-autonomous-driving-with</link>
      <description><![CDATA[Specifically, our framework \textbf{LAW} uses a LAtent World model to predict future latent features based on the predicted ego actions and the latent feature of the current frame.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-end-to-end-autonomous-driving-with</guid>
    </item>
  </channel>
</rss>
