<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 27 Mar 2024 21:06:46 +0000</lastBuildDate>
    <item>
      <title>Are Compressed Language Models Less Subgroup Robust?</title>
      <link>https://paperswithcode.com/paper/are-compressed-language-models-less-subgroup</link>
      <description><![CDATA[To reduce the inference cost of large language models, model compression is increasingly used to create smaller scalable models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/are-compressed-language-models-less-subgroup</guid>
    </item>
    <item>
      <title>Learning to Visually Localize Sound Sources from Mixtures without Prior Source Knowledge</title>
      <link>https://paperswithcode.com/paper/learning-to-visually-localize-sound-sources</link>
      <description><![CDATA[In this paper, to overcome this limitation, we present a novel multi-sound source localization method that can perform localization without prior knowledge of the number of sound sources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-visually-localize-sound-sources</guid>
    </item>
    <item>
      <title>MESIA: Understanding and Leveraging Supplementary Nature of Method-level Comments for Automatic Comment Generation</title>
      <link>https://paperswithcode.com/paper/mesia-understanding-and-leveraging</link>
      <description><![CDATA[In this paper, we raise the awareness of the supplementary nature of method-level comments and propose a new metric named MESIA (Mean Supplementary Information Amount) to assess the extent of supplementary information that a code comment can provide.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mesia-understanding-and-leveraging</guid>
    </item>
    <item>
      <title>PlainMamba: Improving Non-Hierarchical Mamba in Visual Recognition</title>
      <link>https://paperswithcode.com/paper/plainmamba-improving-non-hierarchical-mamba</link>
      <description><![CDATA[In this paper, we further adapt the selective scanning process of Mamba to the visual domain, enhancing its ability to learn features from two-dimensional images by (i) a continuous 2D scanning process that improves spatial continuity by ensuring adjacency of tokens in the scanning sequence, and (ii) direction-aware updating which enables the model to discern the spatial relations of tokens by encoding directional information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plainmamba-improving-non-hierarchical-mamba</guid>
    </item>
    <item>
      <title>Efficient Image Pre-Training with Siamese Cropped Masked Autoencoders</title>
      <link>https://paperswithcode.com/paper/efficient-image-pre-training-with-siamese</link>
      <description><![CDATA[In particular, SiamMAE recently introduced a Siamese network, training a shared-weight encoder from two frames of a video with a high asymmetric masking ratio (95%).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-image-pre-training-with-siamese</guid>
    </item>
    <item>
      <title>Empowering Data Mesh with Federated Learning</title>
      <link>https://paperswithcode.com/paper/empowering-data-mesh-with-federated-learning</link>
      <description><![CDATA[To the best of our knowledge, this is the first open-source applied work that represents a critical advancement toward the integration of federated learning methods into the Data Mesh paradigm, underscoring the promising prospects for privacy-preserving and decentralized data analysis strategies within Data Mesh architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/empowering-data-mesh-with-federated-learning</guid>
    </item>
    <item>
      <title>LASIL: Learner-Aware Supervised Imitation Learning For Long-term Microscopic Traffic Simulation</title>
      <link>https://paperswithcode.com/paper/lasil-learner-aware-supervised-imitation</link>
      <description><![CDATA[Due to the covariate shift issue, existing imitation learning-based simulators often fail to generate stable long-term simulations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lasil-learner-aware-supervised-imitation</guid>
    </item>
    <item>
      <title>ILLUMINER: Instruction-tuned Large Language Models as Few-shot Intent Classifier and Slot Filler</title>
      <link>https://paperswithcode.com/paper/illuminer-instruction-tuned-large-language</link>
      <description><![CDATA[State-of-the-art intent classification (IC) and slot filling (SF) methods often rely on data-intensive deep learning models, limiting their practicality for industry applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/illuminer-instruction-tuned-large-language</guid>
    </item>
    <item>
      <title>Activity-Biometrics: Person Identification from Daily Activities</title>
      <link>https://paperswithcode.com/paper/activity-biometrics-person-identification</link>
      <description><![CDATA[Furthermore, we extensively compare ABNet with existing works in person identification and demonstrate its effectiveness for activity-based biometrics across all five datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/activity-biometrics-person-identification</guid>
    </item>
    <item>
      <title>SGHormer: An Energy-Saving Graph Transformer Driven by Spikes</title>
      <link>https://paperswithcode.com/paper/sghormer-an-energy-saving-graph-transformer</link>
      <description><![CDATA[However, the costs behind outstanding performances of GTs are higher energy consumption and computational overhead.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sghormer-an-energy-saving-graph-transformer</guid>
    </item>
    <item>
      <title>KDMCSE: Knowledge Distillation Multimodal Sentence Embeddings with Adaptive Angular margin Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/kdmcse-knowledge-distillation-multimodal</link>
      <description><![CDATA[Previous work on multimodal sentence embedding has proposed multimodal contrastive learning and achieved promising results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kdmcse-knowledge-distillation-multimodal</guid>
    </item>
    <item>
      <title>Intrinsic Subgraph Generation for Interpretable Graph based Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/intrinsic-subgraph-generation-for</link>
      <description><![CDATA[In this work, we introduce an interpretable approach for graph-based VQA and demonstrate competitive performance on the GQA dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intrinsic-subgraph-generation-for</guid>
    </item>
    <item>
      <title>A Gaze-grounded Visual Question Answering Dataset for Clarifying Ambiguous Japanese Questions</title>
      <link>https://paperswithcode.com/paper/a-gaze-grounded-visual-question-answering</link>
      <description><![CDATA[Such ambiguities in questions are often clarified by the contexts in conversational situations, such as joint attention with a user or user gaze information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-gaze-grounded-visual-question-answering</guid>
    </item>
    <item>
      <title>MIND Your Language: A Multilingual Dataset for Cross-lingual News Recommendation</title>
      <link>https://paperswithcode.com/paper/mind-your-language-a-multilingual-dataset-for</link>
      <description><![CDATA[Our findings reveal that (i) current NNRs, even when based on a multilingual language model, suffer from substantial performance losses under ZS-XLT and that (ii) inclusion of target-language data in FS-XLT training has limited benefits, particularly when combined with a bilingual news consumption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mind-your-language-a-multilingual-dataset-for</guid>
    </item>
    <item>
      <title>PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models</title>
      <link>https://paperswithcode.com/paper/pctoolkit-a-unified-plug-and-play-prompt</link>
      <description><![CDATA[Prompt compression is an innovative method for efficiently condensing input prompts while preserving essential information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pctoolkit-a-unified-plug-and-play-prompt</guid>
    </item>
    <item>
      <title>S+t-SNE - Bringing dimensionality reduction to data streams</title>
      <link>https://paperswithcode.com/paper/s-t-sne-bringing-dimensionality-reduction-to</link>
      <description><![CDATA[We present S+t-SNE, an adaptation of the t-SNE algorithm designed to handle infinite data streams.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s-t-sne-bringing-dimensionality-reduction-to</guid>
    </item>
    <item>
      <title>Language Models are Free Boosters for Biomedical Imaging Tasks</title>
      <link>https://paperswithcode.com/paper/language-models-are-free-boosters-for</link>
      <description><![CDATA[In this study, we uncover the unexpected efficacy of residual-based large language models (LLMs) as part of encoders for biomedical imaging tasks, a domain traditionally devoid of language or textual data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-are-free-boosters-for</guid>
    </item>
    <item>
      <title>Can multiple-choice questions really be useful in detecting the abilities of LLMs?</title>
      <link>https://paperswithcode.com/paper/can-multiple-choice-questions-really-be</link>
      <description><![CDATA[Additionally, we propose two methods to quantify the consistency and confidence of LLMs' output, which can be generalized to other QA evaluation benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-multiple-choice-questions-really-be</guid>
    </item>
    <item>
      <title>Neural Multimodal Topic Modeling: A Comprehensive Evaluation</title>
      <link>https://paperswithcode.com/paper/neural-multimodal-topic-modeling-a</link>
      <description><![CDATA[This paper presents the first systematic and comprehensive evaluation of multimodal topic modeling of documents containing both text and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-multimodal-topic-modeling-a</guid>
    </item>
    <item>
      <title>Efficient Video Object Segmentation via Modulated Cross-Attention Memory</title>
      <link>https://paperswithcode.com/paper/efficient-video-object-segmentation-via-1</link>
      <description><![CDATA[Recently, transformer-based approaches have shown promising results for semi-supervised video object segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-video-object-segmentation-via-1</guid>
    </item>
    <item>
      <title>Bridging Textual and Tabular Worlds for Fact Verification: A Lightweight, Attention-Based Model</title>
      <link>https://paperswithcode.com/paper/bridging-textual-and-tabular-worlds-for-fact</link>
      <description><![CDATA[FEVEROUS is a benchmark and research initiative focused on fact extraction and verification tasks involving unstructured text and structured tabular data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridging-textual-and-tabular-worlds-for-fact</guid>
    </item>
    <item>
      <title>HILL: Hierarchy-aware Information Lossless Contrastive Learning for Hierarchical Text Classification</title>
      <link>https://paperswithcode.com/paper/hill-hierarchy-aware-information-lossless</link>
      <description><![CDATA[Existing self-supervised methods in natural language processing (NLP), especially hierarchical text classification (HTC), mainly focus on self-supervised contrastive learning, extremely relying on human-designed augmentation rules to generate contrastive samples, which can potentially corrupt or distort the original information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hill-hierarchy-aware-information-lossless</guid>
    </item>
    <item>
      <title>Scenario-Based Curriculum Generation for Multi-Agent Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/scenario-based-curriculum-generation-for</link>
      <description><![CDATA[Especially in real-world application domains, such as autonomous driving, auto-curriculum generation is considered vital for obtaining robust and general policies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scenario-based-curriculum-generation-for</guid>
    </item>
    <item>
      <title>OmniVid: A Generative Framework for Universal Video Understanding</title>
      <link>https://paperswithcode.com/paper/omnivid-a-generative-framework-for-universal</link>
      <description><![CDATA[The core of video understanding tasks, such as recognition, captioning, and tracking, is to automatically detect objects or actions in a video and analyze their temporal evolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnivid-a-generative-framework-for-universal</guid>
    </item>
    <item>
      <title>Robust and Scalable Model Editing for Large Language Models</title>
      <link>https://paperswithcode.com/paper/robust-and-scalable-model-editing-for-large</link>
      <description><![CDATA[Large language models (LLMs) can make predictions using parametric knowledge--knowledge encoded in the model weights--or contextual knowledge--knowledge presented in the context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-and-scalable-model-editing-for-large</guid>
    </item>
    <item>
      <title>REFeREE: A REference-FREE Model-Based Metric for Text Simplification</title>
      <link>https://paperswithcode.com/paper/referee-a-reference-free-model-based-metric</link>
      <description><![CDATA[Text simplification lacks a universal standard of quality, and annotated reference simplifications are scarce and costly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/referee-a-reference-free-model-based-metric</guid>
    </item>
    <item>
      <title>Noise2Noise Denoising of CRISM Hyperspectral Data</title>
      <link>https://paperswithcode.com/paper/noise2noise-denoising-of-crism-hyperspectral</link>
      <description><![CDATA[Hyperspectral data acquired by the Compact Reconnaissance Imaging Spectrometer for Mars (CRISM) have allowed for unparalleled mapping of the surface mineralogy of Mars.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/noise2noise-denoising-of-crism-hyperspectral</guid>
    </item>
    <item>
      <title>Deepfake Generation and Detection: A Benchmark and Survey</title>
      <link>https://paperswithcode.com/paper/deepfake-generation-and-detection-a-benchmark</link>
      <description><![CDATA[In addition to the advancements in deepfake generation, corresponding detection technologies need to continuously evolve to regulate the potential misuse of deepfakes, such as for privacy invasion and phishing attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepfake-generation-and-detection-a-benchmark</guid>
    </item>
    <item>
      <title>A foundation model utilizing chest CT volumes and radiology reports for supervised-level zero-shot detection of abnormalities</title>
      <link>https://paperswithcode.com/paper/a-foundation-model-utilizing-chest-ct-volumes</link>
      <description><![CDATA[A major challenge in computational research in 3D medical imaging is the lack of comprehensive datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-foundation-model-utilizing-chest-ct-volumes</guid>
    </item>
    <item>
      <title>An Empirical Study of Training ID-Agnostic Multi-modal Sequential Recommenders</title>
      <link>https://paperswithcode.com/paper/an-empirical-study-of-training-id-agnostic</link>
      <description><![CDATA[Sequential Recommendation (SR) aims to predict future user-item interactions based on historical interactions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-empirical-study-of-training-id-agnostic</guid>
    </item>
    <item>
      <title>Learning the Optimal Power Flow: Environment Design Matters</title>
      <link>https://paperswithcode.com/paper/learning-the-optimal-power-flow-environment</link>
      <description><![CDATA[Further, we derive some first recommendations regarding the choice of these design decisions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-the-optimal-power-flow-environment</guid>
    </item>
    <item>
      <title>Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/dual-memory-networks-a-versatile-adaptation</link>
      <description><![CDATA[In this paper, we introduce a versatile adaptation approach that can effectively work under all three settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-memory-networks-a-versatile-adaptation</guid>
    </item>
    <item>
      <title>TWOLAR: a TWO-step LLM-Augmented distillation method for passage Reranking</title>
      <link>https://paperswithcode.com/paper/twolar-a-two-step-llm-augmented-distillation</link>
      <description><![CDATA[In this paper, we present TWOLAR: a two-stage pipeline for passage reranking based on the distillation of knowledge from Large Language Models (LLM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/twolar-a-two-step-llm-augmented-distillation</guid>
    </item>
    <item>
      <title>Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/physical-3d-adversarial-attacks-against</link>
      <description><![CDATA[Deep learning-based monocular depth estimation (MDE), extensively applied in autonomous driving, is known to be vulnerable to adversarial attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physical-3d-adversarial-attacks-against</guid>
    </item>
    <item>
      <title>Using Stratified Sampling to Improve LIME Image Explanations</title>
      <link>https://paperswithcode.com/paper/using-stratified-sampling-to-improve-lime</link>
      <description><![CDATA[We investigate the use of a stratified sampling approach for LIME Image, a popular model-agnostic explainable AI method for computer vision tasks, in order to reduce the artifacts generated by typical Monte Carlo sampling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/using-stratified-sampling-to-improve-lime</guid>
    </item>
    <item>
      <title>CoDA: Instructive Chain-of-Domain Adaptation with Severity-Aware Visual Prompt Tuning</title>
      <link>https://paperswithcode.com/paper/coda-instructive-chain-of-domain-adaptation</link>
      <description><![CDATA[SAVPT features a novel metric Severity that divides all adverse scene images into low-severity and high-severity images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coda-instructive-chain-of-domain-adaptation</guid>
    </item>
    <item>
      <title>EulerFormer: Sequential User Behavior Modeling with Complex Vector Attention</title>
      <link>https://paperswithcode.com/paper/eulerformer-sequential-user-behavior-modeling</link>
      <description><![CDATA[The core of transformer architecture lies in the self-attention mechanism, which computes the pairwise attention scores in a sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eulerformer-sequential-user-behavior-modeling</guid>
    </item>
    <item>
      <title>Provably Secure Disambiguating Neural Linguistic Steganography</title>
      <link>https://paperswithcode.com/paper/provably-secure-disambiguating-neural</link>
      <description><![CDATA[SyncPool does not change the size of the candidate pool or the distribution of tokens and thus is applicable to provably secure language steganography methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/provably-secure-disambiguating-neural</guid>
    </item>
    <item>
      <title>ChatGPT Rates Natural Language Explanation Quality Like Humans: But on Which Scales?</title>
      <link>https://paperswithcode.com/paper/chatgpt-rates-natural-language-explanation</link>
      <description><![CDATA[Our results show that ChatGPT aligns better with humans in more coarse-grained scales.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatgpt-rates-natural-language-explanation</guid>
    </item>
    <item>
      <title>Denoising Table-Text Retrieval for Open-Domain Question Answering</title>
      <link>https://paperswithcode.com/paper/denoising-table-text-retrieval-for-open</link>
      <description><![CDATA[Previous studies in table-text open-domain question answering have two common challenges: firstly, their retrievers can be affected by false-positive labels in training datasets; secondly, they may struggle to provide appropriate evidence for questions that require reasoning across the table.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/denoising-table-text-retrieval-for-open</guid>
    </item>
    <item>
      <title>ArabicaQA: A Comprehensive Dataset for Arabic Question Answering</title>
      <link>https://paperswithcode.com/paper/arabicaqa-a-comprehensive-dataset-for-arabic</link>
      <description><![CDATA[In conclusion, ArabicaQA, AraDPR, and the benchmarking of LLMs in Arabic question answering offer significant advancements in the field of Arabic NLP.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/arabicaqa-a-comprehensive-dataset-for-arabic</guid>
    </item>
    <item>
      <title>ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages</title>
      <link>https://paperswithcode.com/paper/chroniclingamericaqa-a-large-scale-question</link>
      <description><![CDATA[Therefore, to enable realistic testing of QA models, our dataset can be used in three different ways: answering questions from raw and noisy content, answering questions from cleaner, corrected version of the content, as well as answering questions from scanned images of newspaper pages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chroniclingamericaqa-a-large-scale-question</guid>
    </item>
    <item>
      <title>Groupwise Query Specialization and Quality-Aware Multi-Assignment for Transformer-based Visual Relationship Detection</title>
      <link>https://paperswithcode.com/paper/groupwise-query-specialization-and-quality</link>
      <description><![CDATA[Groupwise Query Specialization trains a specialized query by dividing queries and relations into disjoint groups and directing a query in a specific query group solely toward relations in the corresponding relation group.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/groupwise-query-specialization-and-quality</guid>
    </item>
    <item>
      <title>DS-AL: A Dual-Stream Analytic Learning for Exemplar-Free Class-Incremental Learning</title>
      <link>https://paperswithcode.com/paper/ds-al-a-dual-stream-analytic-learning-for</link>
      <description><![CDATA[The compensation stream is governed by a Dual-Activation Compensation (DAC) module.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ds-al-a-dual-stream-analytic-learning-for</guid>
    </item>
    <item>
      <title>Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance</title>
      <link>https://paperswithcode.com/paper/self-rectifying-diffusion-sampling-with</link>
      <description><![CDATA[These techniques are often not applicable in unconditional generation or in various downstream tasks such as image restoration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-rectifying-diffusion-sampling-with</guid>
    </item>
    <item>
      <title>Building Bridges across Spatial and Temporal Resolutions: Reference-Based Super-Resolution via Change Priors and Conditional Diffusion Model</title>
      <link>https://paperswithcode.com/paper/building-bridges-across-spatial-and-temporal</link>
      <description><![CDATA[Specifically, we inject the priors into the denoising model to improve the utilization of reference information in unchanged areas and regulate the reconstruction of semantically relevant content in changed areas.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/building-bridges-across-spatial-and-temporal</guid>
    </item>
    <item>
      <title>Sharing the Cost of Success: A Game for Evaluating and Learning Collaborative Multi-Agent Instruction Giving and Following Policies</title>
      <link>https://paperswithcode.com/paper/sharing-the-cost-of-success-a-game-for</link>
      <description><![CDATA[In collaborative goal-oriented settings, the participants are not only interested in achieving a successful outcome, but do also implicitly negotiate the effort they put into the interaction (by adapting to each other).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sharing-the-cost-of-success-a-game-for</guid>
    </item>
    <item>
      <title>JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset</title>
      <link>https://paperswithcode.com/paper/jmultiwoz-a-large-scale-japanese-multi-domain</link>
      <description><![CDATA[In this study, towards the advancement of research and development of task-oriented dialogue systems in Japanese, we constructed JMultiWOZ, the first Japanese language large-scale multi-domain task-oriented dialogue dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jmultiwoz-a-large-scale-japanese-multi-domain</guid>
    </item>
    <item>
      <title>AID: Attention Interpolation of Text-to-Image Diffusion</title>
      <link>https://paperswithcode.com/paper/aid-attention-interpolation-of-text-to-image</link>
      <description><![CDATA[To that end, we introduce a novel training-free technique named Attention Interpolation via Diffusion (AID).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aid-attention-interpolation-of-text-to-image</guid>
    </item>
    <item>
      <title>Task-Oriented Paraphrase Analytics</title>
      <link>https://paperswithcode.com/paper/task-oriented-paraphrase-analytics</link>
      <description><![CDATA[Since paraphrasing is an ill-defined task, the term "paraphrasing" covers text transformation tasks with different characteristics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/task-oriented-paraphrase-analytics</guid>
    </item>
  </channel>
</rss>
