<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Nov 2023 09:11:59 +0000</lastBuildDate>
    <item>
      <title>A 3D generative model of pathological multi-modal MR images and segmentations</title>
      <link>https://paperswithcode.com/paper/a-3d-generative-model-of-pathological-multi</link>
      <description><![CDATA[The proposed joint imaging-segmentation generative model is shown to generate high-fidelity synthetic images and associated segmentations, with the ability to combine pathologies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-3d-generative-model-of-pathological-multi</guid>
    </item>
    <item>
      <title>Data Factors for Better Compositional Generalization</title>
      <link>https://paperswithcode.com/paper/data-factors-for-better-compositional</link>
      <description><![CDATA[However, in contrast to this poor performance, state-of-the-art models trained on larger and more general datasets show better generalization ability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-factors-for-better-compositional</guid>
    </item>
    <item>
      <title>Massive Editing for Large Language Models via Meta Learning</title>
      <link>https://paperswithcode.com/paper/massive-editing-for-large-language-models-via</link>
      <description><![CDATA[While large language models (LLMs) have enabled learning knowledge from the pre-training corpora, the acquired knowledge may be fundamentally incorrect or outdated over time, which necessitates rectifying the knowledge of the language model (LM) after the training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/massive-editing-for-large-language-models-via</guid>
    </item>
    <item>
      <title>SEMQA: Semi-Extractive Multi-Source Question Answering</title>
      <link>https://paperswithcode.com/paper/semqa-semi-extractive-multi-source-question</link>
      <description><![CDATA[Experimenting with several LLMs in various settings, we find this task to be surprisingly challenging, demonstrating the importance of QuoteSum for developing and studying such consolidation capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semqa-semi-extractive-multi-source-question</guid>
    </item>
    <item>
      <title>Image-Based Virtual Try-On: A Survey</title>
      <link>https://paperswithcode.com/paper/image-based-virtual-try-on-a-survey</link>
      <description><![CDATA[In addition to quantitative and qualitative evaluation of current open-source methods, we also utilize ControlNet to fine-tune a recent large image generation model (PBE) to show future potentials of large-scale models on image-based virtual try-on task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/image-based-virtual-try-on-a-survey</guid>
    </item>
    <item>
      <title>Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs</title>
      <link>https://paperswithcode.com/paper/bias-runs-deep-implicit-reasoning-biases-in</link>
      <description><![CDATA[These can be observed as abstentions in the model responses, e. g., 'As a Black person, I am unable to answer this question as it requires math knowledge', and generally result in a substantial drop in performance on reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bias-runs-deep-implicit-reasoning-biases-in</guid>
    </item>
    <item>
      <title>Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection</title>
      <link>https://paperswithcode.com/paper/army-of-thieves-enhancing-black-box-model</link>
      <description><![CDATA[In this work, we explore the usage of an ensemble of deep learning models as our thief model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/army-of-thieves-enhancing-black-box-model</guid>
    </item>
    <item>
      <title>A Comprehensive Summarization and Evaluation of Feature Refinement Modules for CTR Prediction</title>
      <link>https://paperswithcode.com/paper/a-comprehensive-summarization-and-evaluation</link>
      <description><![CDATA[In addition, we present a new architecture of assigning independent FR modules to separate sub-networks for parallel CTR models, as opposed to the conventional method of inserting a shared FR module on top of the embedding layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comprehensive-summarization-and-evaluation</guid>
    </item>
    <item>
      <title>Byzantine-Tolerant Methods for Distributed Variational Inequalities</title>
      <link>https://paperswithcode.com/paper/byzantine-tolerant-methods-for-distributed</link>
      <description><![CDATA[Robustness to Byzantine attacks is a necessity for various distributed training scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/byzantine-tolerant-methods-for-distributed</guid>
    </item>
    <item>
      <title>A Hierarchical Spatial Transformer for Massive Point Samples in Continuous Space</title>
      <link>https://paperswithcode.com/paper/a-hierarchical-spatial-transformer-for</link>
      <description><![CDATA[However, designing a transformer for massive spatial points is non-trivial due to several challenges, including implicit long-range and multi-scale dependency on irregular points in continuous space, a non-uniform point distribution, the potential high computational costs of calculating all-pair attention across massive points, and the risks of over-confident predictions due to varying point density.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-hierarchical-spatial-transformer-for</guid>
    </item>
    <item>
      <title>Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability</title>
      <link>https://paperswithcode.com/paper/recursion-in-recursion-two-level-nested</link>
      <description><![CDATA[For the inner recursion, we choose Beam Tree RvNNs (BT-RvNN).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recursion-in-recursion-two-level-nested</guid>
    </item>
    <item>
      <title>AI-accelerated Discovery of Altermagnetic Materials</title>
      <link>https://paperswithcode.com/paper/ai-accelerated-discovery-of-altermagnetic</link>
      <description><![CDATA[Altermagnetism, a new magnetic phase, has been theoretically proposed and experimentally verified to be distinct from ferromagnetism and antiferromagnetism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ai-accelerated-discovery-of-altermagnetic</guid>
    </item>
    <item>
      <title>Rethinking Event-based Human Pose Estimation with 3D Event Representations</title>
      <link>https://paperswithcode.com/paper/rethinking-event-based-human-pose-estimation</link>
      <description><![CDATA[To address this issue and to unlock the 3D potential of event information, we introduce two 3D event representations: the Rasterized Event Point Cloud (RasEPC) and the Decoupled Event Voxel (DEV).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-event-based-human-pose-estimation</guid>
    </item>
    <item>
      <title>Training CLIP models on Data from Scientific Papers</title>
      <link>https://paperswithcode.com/paper/training-clip-models-on-data-from-scientific</link>
      <description><![CDATA[Contrastive Language-Image Pretraining (CLIP) models are able to capture the semantic relationship of images and texts and have enabled a wide range of applications, from image retrieval to classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-clip-models-on-data-from-scientific</guid>
    </item>
    <item>
      <title>How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure</title>
      <link>https://paperswithcode.com/paper/how-abstract-is-linguistic-generalization-in</link>
      <description><![CDATA[We find that LLMs perform well in generalizing the distribution of a novel noun argument between related contexts that were seen during pre-training (e. g., the active object and passive subject of the verb spray), succeeding by making use of the semantically-organized structure of the embedding space for word embeddings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-abstract-is-linguistic-generalization-in</guid>
    </item>
    <item>
      <title>Using large language models to study human memory for meaningful narratives</title>
      <link>https://paperswithcode.com/paper/using-large-language-models-to-study-human</link>
      <description><![CDATA[One of the most impressive achievements of the AI revolution is the development of large language models that can generate meaningful text and respond to instructions in plain English with no additional training necessary.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/using-large-language-models-to-study-human</guid>
    </item>
    <item>
      <title>VET: Visual Error Tomography for Point Cloud Completion and High-Quality Neural Rendering</title>
      <link>https://paperswithcode.com/paper/vet-visual-error-tomography-for-point-cloud</link>
      <description><![CDATA[In our results, we show that our approach can improve the quality of a point cloud obtained by structure from motion and thus increase novel view synthesis quality significantly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vet-visual-error-tomography-for-point-cloud</guid>
    </item>
    <item>
      <title>Learning Linear Gaussian Polytree Models with Interventions</title>
      <link>https://paperswithcode.com/paper/learning-linear-gaussian-polytree-models-with</link>
      <description><![CDATA[We present a consistent and highly scalable local approach to learn the causal structure of a linear Gaussian polytree using data from interventional experiments with known intervention targets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-linear-gaussian-polytree-models-with</guid>
    </item>
    <item>
      <title>Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models</title>
      <link>https://paperswithcode.com/paper/beyond-size-how-gradients-shape-pruning</link>
      <description><![CDATA[Prior approaches such as Weights Magnitude, SparseGPT, and Wanda, either concentrated solely on weights or integrated weights with activations for sparsity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-size-how-gradients-shape-pruning</guid>
    </item>
    <item>
      <title>MixTEA: Semi-supervised Entity Alignment with Mixture Teaching</title>
      <link>https://paperswithcode.com/paper/mixtea-semi-supervised-entity-alignment-with</link>
      <description><![CDATA[More importantly, in pseudo mapping learning, we propose a bi-directional voting (BDV) strategy that fuses the alignment decisions in different directions to estimate the uncertainty via the joint matching confidence score.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixtea-semi-supervised-entity-alignment-with</guid>
    </item>
    <item>
      <title>Robust and Communication-Efficient Federated Domain Adaptation via Random Features</title>
      <link>https://paperswithcode.com/paper/robust-and-communication-efficient-federated-1</link>
      <description><![CDATA[As a result, there is a growing trend to leverage federated learning (FL) techniques to train large ML models in a distributed and collaborative manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-and-communication-efficient-federated-1</guid>
    </item>
    <item>
      <title>Identifying Semantic Component for Robust Molecular Property Prediction</title>
      <link>https://paperswithcode.com/paper/identifying-semantic-component-for-robust</link>
      <description><![CDATA[Specifically, we first formulate the data generation process from the atom level to the molecular level, where the latent space is split into SI substructures, SR substructures, and SR atom variables.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/identifying-semantic-component-for-robust</guid>
    </item>
    <item>
      <title>Improving Pacing in Long-Form Story Planning</title>
      <link>https://paperswithcode.com/paper/improving-pacing-in-long-form-story-planning</link>
      <description><![CDATA[Existing LLM-based systems for writing long-form stories or story outlines frequently suffer from unnatural pacing, whether glossing over important events or over-elaborating on insignificant details, resulting in a jarring experience for the reader.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-pacing-in-long-form-story-planning</guid>
    </item>
    <item>
      <title>GCS-ICHNet: Assessment of Intracerebral Hemorrhage Prognosis using Self-Attention with Domain Knowledge Integration</title>
      <link>https://paperswithcode.com/paper/gcs-ichnet-assessment-of-intracerebral</link>
      <description><![CDATA[Intracerebral Hemorrhage (ICH) is a severe condition resulting from damaged brain blood vessel ruptures, often leading to complications and fatalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gcs-ichnet-assessment-of-intracerebral</guid>
    </item>
    <item>
      <title>Lidar Annotation Is All You Need</title>
      <link>https://paperswithcode.com/paper/lidar-annotation-is-all-you-need</link>
      <description><![CDATA[One of the fundamental tasks in computer vision is semantic image segmentation, which is vital for precise object delineation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lidar-annotation-is-all-you-need</guid>
    </item>
    <item>
      <title>RDGCN: Reinforced Dependency Graph Convolutional Network for Aspect-based Sentiment Analysis</title>
      <link>https://paperswithcode.com/paper/rdgcn-reinforced-dependency-graph</link>
      <description><![CDATA[Aspect-based sentiment analysis (ABSA) is dedicated to forecasting the sentiment polarity of aspect terms within sentences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rdgcn-reinforced-dependency-graph</guid>
    </item>
    <item>
      <title>On Characterizing the Evolution of Embedding Space of Neural Networks using Algebraic Topology</title>
      <link>https://paperswithcode.com/paper/on-characterizing-the-evolution-of-embedding</link>
      <description><![CDATA[We study how the topology of feature embedding space changes as it passes through the layers of a well-trained deep neural network (DNN) through Betti numbers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-characterizing-the-evolution-of-embedding</guid>
    </item>
    <item>
      <title>Self-Supervised Learning for Visual Relationship Detection through Masked Bounding Box Reconstruction</title>
      <link>https://paperswithcode.com/paper/self-supervised-learning-for-visual</link>
      <description><![CDATA[We present a novel self-supervised approach for representation learning, particularly for the task of Visual Relationship Detection (VRD).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-learning-for-visual</guid>
    </item>
    <item>
      <title>DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of mixture-of-datasets</title>
      <link>https://paperswithcode.com/paper/damex-dataset-aware-mixture-of-experts-for</link>
      <description><![CDATA[Construction of a universal detector poses a crucial question: How can we most effectively train a model on a large mixture of datasets?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damex-dataset-aware-mixture-of-experts-for</guid>
    </item>
    <item>
      <title>SODAWideNet -- Salient Object Detection with an Attention augmented Wide Encoder Decoder network without ImageNet pre-training</title>
      <link>https://paperswithcode.com/paper/sodawidenet-salient-object-detection-with-an</link>
      <description><![CDATA[To achieve a shallower network, we increase the receptive field from the beginning of the network using a combination of dilated convolutions and self-attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sodawidenet-salient-object-detection-with-an</guid>
    </item>
    <item>
      <title>Hierarchically Gated Recurrent Neural Network for Sequence Modeling</title>
      <link>https://paperswithcode.com/paper/hierarchically-gated-recurrent-neural-network</link>
      <description><![CDATA[Transformers have surpassed RNNs in popularity due to their superior abilities in parallel training and long-term dependency modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchically-gated-recurrent-neural-network</guid>
    </item>
    <item>
      <title>Towards Deeper, Lighter and Interpretable Cross Network for CTR Prediction</title>
      <link>https://paperswithcode.com/paper/towards-deeper-lighter-and-interpretable-1</link>
      <description><![CDATA[It is crucial to effectively model feature interactions to improve the prediction performance of CTR models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-deeper-lighter-and-interpretable-1</guid>
    </item>
    <item>
      <title>Cross-Silo Federated Learning Across Divergent Domains with Iterative Parameter Alignment</title>
      <link>https://paperswithcode.com/paper/cross-silo-federated-learning-across</link>
      <description><![CDATA[Learning from the collective knowledge of data dispersed across private sources can provide neural networks with enhanced generalization capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-silo-federated-learning-across</guid>
    </item>
    <item>
      <title>CAIS-DMA: A Decision-Making Assistant for Collaborative AI Systems</title>
      <link>https://paperswithcode.com/paper/cais-dma-a-decision-making-assistant-for</link>
      <description><![CDATA[This paper introduces a new methodology to automatically support the decision-making process in CAIS when the system experiences performance degradation after a disruptive event.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cais-dma-a-decision-making-assistant-for</guid>
    </item>
    <item>
      <title>Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic Representations</title>
      <link>https://paperswithcode.com/paper/sub-sentence-encoder-contrastive-learning-of</link>
      <description><![CDATA[We introduce sub-sentence encoder, a contrastively-learned contextual embedding model for fine-grained semantic representation of text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sub-sentence-encoder-contrastive-learning-of</guid>
    </item>
    <item>
      <title>JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models</title>
      <link>https://paperswithcode.com/paper/jaspice-automatic-evaluation-metric-using</link>
      <description><![CDATA[Image captioning studies heavily rely on automatic evaluation metrics such as BLEU and METEOR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jaspice-automatic-evaluation-metric-using</guid>
    </item>
    <item>
      <title>Multilingual Mathematical Autoformalization</title>
      <link>https://paperswithcode.com/paper/multilingual-mathematical-autoformalization</link>
      <description><![CDATA[In this work, we create $\texttt{MMA}$, a large, flexible, multilingual, and multi-domain dataset of informal-formal pairs, by using a language model to translate in the reverse direction, that is, from formal mathematical statements into corresponding informal ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multilingual-mathematical-autoformalization</guid>
    </item>
    <item>
      <title>Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning</title>
      <link>https://paperswithcode.com/paper/unified-low-resource-sequence-labeling-by</link>
      <description><![CDATA[Unfortunately, this requires formatting them into specialized augmented format unknown to the base pretrained language model (PLMs) necessitating finetuning to the target format.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-low-resource-sequence-labeling-by</guid>
    </item>
    <item>
      <title>SeRO: Self-Supervised Reinforcement Learning for Recovery from Out-of-Distribution Situations</title>
      <link>https://paperswithcode.com/paper/sero-self-supervised-reinforcement-learning</link>
      <description><![CDATA[Moreover, we show that our method can retrain the agent to recover from OOD situations even when in-distribution states are difficult to visit through exploration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sero-self-supervised-reinforcement-learning</guid>
    </item>
    <item>
      <title>A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis</title>
      <link>https://paperswithcode.com/paper/a-simple-interpretable-transformer-for-fine</link>
      <description><![CDATA[Unlike mainstream classifiers that wait until the last fully-connected layer to incorporate class information to make predictions, we investigate a proactive approach, asking each class to search for itself in an image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-simple-interpretable-transformer-for-fine</guid>
    </item>
    <item>
      <title>Do LLMs exhibit human-like response biases? A case study in survey design</title>
      <link>https://paperswithcode.com/paper/do-llms-exhibit-human-like-response-biases-a</link>
      <description><![CDATA[In this work, we use survey design as a case study, where human response biases caused by permutations in wordings of ``prompts'' have been extensively studied.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-llms-exhibit-human-like-response-biases-a</guid>
    </item>
    <item>
      <title>Restoration of Analog Videos Using Swin-UNet</title>
      <link>https://paperswithcode.com/paper/restoration-of-analog-videos-using-swin-unet</link>
      <description><![CDATA[In this paper, we present a system to restore analog videos of historical archives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/restoration-of-analog-videos-using-swin-unet</guid>
    </item>
    <item>
      <title>JPAVE: A Generation and Classification-based Model for Joint Product Attribute Prediction and Value Extraction</title>
      <link>https://paperswithcode.com/paper/jpave-a-generation-and-classification-based</link>
      <description><![CDATA[Furthermore, the copy mechanism in value generator and the value attention module in value classifier help our model address the data discrepancy issue by only focusing on the relevant part of input text and ignoring other information which causes the discrepancy issue such as sentence structure in the text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jpave-a-generation-and-classification-based</guid>
    </item>
    <item>
      <title>Holistic Evaluation of Text-To-Image Models</title>
      <link>https://paperswithcode.com/paper/holistic-evaluation-of-text-to-image-models</link>
      <description><![CDATA[The stunning qualitative improvement of recent text-to-image models has led to their widespread attention and adoption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/holistic-evaluation-of-text-to-image-models</guid>
    </item>
    <item>
      <title>Uncovering Causal Variables in Transformers using Circuit Probing</title>
      <link>https://paperswithcode.com/paper/uncovering-causal-variables-in-transformers</link>
      <description><![CDATA[We apply this method to models trained on simple arithmetic tasks, demonstrating its effectiveness at (1) deciphering the algorithms that models have learned, (2) revealing modular structure within a model, and (3) tracking the development of circuits over training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncovering-causal-variables-in-transformers</guid>
    </item>
    <item>
      <title>Black-Box Prompt Optimization: Aligning Large Language Models without Model Training</title>
      <link>https://paperswithcode.com/paper/black-box-prompt-optimization-aligning-large</link>
      <description><![CDATA[However, these models are often not well aligned with human intents, which calls for additional treatments on them, that is, the alignment problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/black-box-prompt-optimization-aligning-large</guid>
    </item>
    <item>
      <title>Video Instance Matting</title>
      <link>https://paperswithcode.com/paper/video-instance-matting</link>
      <description><![CDATA[To remedy this deficiency, we propose Video Instance Matting~(VIM), that is, estimating alpha mattes of each instance at each frame of a video sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-instance-matting</guid>
    </item>
    <item>
      <title>Conversations in Galician: a Large Language Model for an Underrepresented Language</title>
      <link>https://paperswithcode.com/paper/conversations-in-galician-a-large-language</link>
      <description><![CDATA[Additionally, as a demonstration of the dataset utility, we fine-tuned LLaMA-7B to comprehend and respond in Galician, a language not originally supported by the model, by following the Alpaca format.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conversations-in-galician-a-large-language</guid>
    </item>
    <item>
      <title>ETDPC: A Multimodality Framework for Classifying Pages in Electronic Theses and Dissertations</title>
      <link>https://paperswithcode.com/paper/etdpc-a-multimodality-framework-for</link>
      <description><![CDATA[To overcome the challenge of imbalanced labeled samples, we augmented data for minority categories and employed a hierarchical classifier.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/etdpc-a-multimodality-framework-for</guid>
    </item>
    <item>
      <title>Cup Curriculum: Curriculum Learning on Model Capacity</title>
      <link>https://paperswithcode.com/paper/cup-curriculum-curriculum-learning-on-model</link>
      <description><![CDATA[Curriculum learning (CL) aims to increase the performance of a learner on a given task by applying a specialized learning strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cup-curriculum-curriculum-learning-on-model</guid>
    </item>
  </channel>
</rss>
