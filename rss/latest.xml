<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 17 Oct 2024 09:16:28 +0000</lastBuildDate>
    <item>
      <title>PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking</title>
      <link>https://paperswithcode.com/paper/preflexor-preference-based-recursive-language</link>
      <description><![CDATA[We propose a recursive learning approach that engages the model in multi-step reasoning, revisiting, and refining intermediate steps before producing a final output in training and inference phases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/preflexor-preference-based-recursive-language</guid>
    </item>
    <item>
      <title>Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective</title>
      <link>https://paperswithcode.com/paper/stabilize-the-latent-space-for-image</link>
      <description><![CDATA[Furthermore, we propose a simple but effective discrete image tokenizer to stabilize the latent space for image generative modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stabilize-the-latent-space-for-image</guid>
    </item>
    <item>
      <title>HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts</title>
      <link>https://paperswithcode.com/paper/henry-a-multi-agent-system-framework-for</link>
      <description><![CDATA[This project, named HEnRY, aims to introduce a Multi-Agent System (MAS) into Intesa Sanpaolo.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/henry-a-multi-agent-system-framework-for</guid>
    </item>
    <item>
      <title>Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization</title>
      <link>https://paperswithcode.com/paper/embedding-an-ethical-mind-aligning-text-to</link>
      <description><![CDATA[To optimize the value encoder, we also develop a framework to automatically construct a text-image preference dataset of 86k (prompt, aligned image, violating image, value principle) samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embedding-an-ethical-mind-aligning-text-to</guid>
    </item>
    <item>
      <title>Self-adaptive Multimodal Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/self-adaptive-multimodal-retrieval-augmented</link>
      <description><![CDATA[Traditional Retrieval-Augmented Generation (RAG) methods are limited by their reliance on a fixed number of retrieved documents, often resulting in incomplete or noisy information that undermines task performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-adaptive-multimodal-retrieval-augmented</guid>
    </item>
    <item>
      <title>Safety Filtering While Training: Improving the Performance and Sample Efficiency of Reinforcement Learning Agents</title>
      <link>https://paperswithcode.com/paper/safety-filtering-while-training-improving-the</link>
      <description><![CDATA[In experiments, we show that the proposed training approaches require significantly fewer environment interactions and improve performance by up to 20% compared to standard RL training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safety-filtering-while-training-improving-the</guid>
    </item>
    <item>
      <title>On the potential of Optimal Transport in Geospatial Data Science</title>
      <link>https://paperswithcode.com/paper/on-the-potential-of-optimal-transport-in</link>
      <description><![CDATA[We put forward Optimal Transport (OT) as a spatial evaluation metric and loss function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-potential-of-optimal-transport-in</guid>
    </item>
    <item>
      <title>Improving Long-Text Alignment for Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/improving-long-text-alignment-for-text-to</link>
      <description><![CDATA[To tackle these issues, we propose LongAlign, which includes a segment-level encoding method for processing long texts and a decomposed preference optimization method for effective alignment training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-long-text-alignment-for-text-to</guid>
    </item>
    <item>
      <title>MCTBench: Multimodal Cognition towards Text-Rich Visual Scenes Benchmark</title>
      <link>https://paperswithcode.com/paper/mctbench-multimodal-cognition-towards-text</link>
      <description><![CDATA[The comprehension of text-rich visual scenes has become a focal point for evaluating Multi-modal Large Language Models (MLLMs) due to their widespread applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mctbench-multimodal-cognition-towards-text</guid>
    </item>
    <item>
      <title>Benchmarking Data Efficiency in $Î”$-ML and Multifidelity Models for Quantum Chemistry</title>
      <link>https://paperswithcode.com/paper/benchmarking-data-efficiency-in-d-ml-and</link>
      <description><![CDATA[Increased work in reducing the cost of generating training data resulted in the development of $\Delta$-ML and multifidelity machine learning methods which use data at more than one QC level of accuracy, or fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-data-efficiency-in-d-ml-and</guid>
    </item>
    <item>
      <title>Conditional Density Estimation with Histogram Trees</title>
      <link>https://paperswithcode.com/paper/conditional-density-estimation-with-histogram</link>
      <description><![CDATA[Our experiments demonstrate that, in comparison to existing interpretable CDE methods, CDTrees are both more accurate (as measured by the log-loss) and more robust against irrelevant features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conditional-density-estimation-with-histogram</guid>
    </item>
    <item>
      <title>Zero-shot Model-based Reinforcement Learning using Large Language Models</title>
      <link>https://paperswithcode.com/paper/zero-shot-model-based-reinforcement-learning</link>
      <description><![CDATA[The emerging zero-shot capabilities of Large Language Models (LLMs) have led to their applications in areas extending well beyond natural language processing tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-model-based-reinforcement-learning</guid>
    </item>
    <item>
      <title>Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/automatically-generating-visual-hallucination</link>
      <description><![CDATA[Our theoretical analysis shows that symmetric accuracy is an unbiased evaluation metric that remains unaffected by the imbalance of VH testing cases with varying answers when an MLLM is randomly guessing the answers, whereas traditional accuracy is prone to such imbalance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automatically-generating-visual-hallucination</guid>
    </item>
    <item>
      <title>Eliciting Textual Descriptions from Representations of Continuous Prompts</title>
      <link>https://paperswithcode.com/paper/eliciting-textual-descriptions-from</link>
      <description><![CDATA[Continuous prompts, or "soft prompts", are a widely-adopted parameter-efficient tuning strategy for large language models, but are often less favorable due to their opaque nature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eliciting-textual-descriptions-from</guid>
    </item>
    <item>
      <title>Bayesian Experimental Design via Contrastive Diffusions</title>
      <link>https://paperswithcode.com/paper/bayesian-experimental-design-via-contrastive</link>
      <description><![CDATA[In this work, we introduce an {\it expected posterior} distribution with cost-effective sampling properties and provide a tractable access to the EIG contrast maximization via a new EIG gradient expression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bayesian-experimental-design-via-contrastive</guid>
    </item>
    <item>
      <title>Spatio-Temporal Distortion Aware Omnidirectional Video Super-Resolution</title>
      <link>https://paperswithcode.com/paper/spatio-temporal-distortion-aware</link>
      <description><![CDATA[Omnidirectional video (ODV) can provide an immersive experience and is widely utilized in the field of virtual reality and augmented reality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatio-temporal-distortion-aware</guid>
    </item>
    <item>
      <title>RATE: Score Reward Models with Imperfect Rewrites of Rewrites</title>
      <link>https://paperswithcode.com/paper/rate-score-reward-models-with-imperfect</link>
      <description><![CDATA[In this paper, we develop an evaluation method, RATE (Rewrite-based Attribute Treatment Estimators), that allows us to measure the causal effect of a given attribute of a response (e. g., length) on the reward assigned to that response.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rate-score-reward-models-with-imperfect</guid>
    </item>
    <item>
      <title>Visual-Geometric Collaborative Guidance for Affordance Learning</title>
      <link>https://paperswithcode.com/paper/visual-geometric-collaborative-guidance-for</link>
      <description><![CDATA[Perceiving potential ``action possibilities'' (\ie, affordance) regions of images and learning interactive functionalities of objects from human demonstration is a challenging task due to the diversity of human-object interactions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-geometric-collaborative-guidance-for</guid>
    </item>
    <item>
      <title>Breaking Modality Gap in RGBT Tracking: Coupled Knowledge Distillation</title>
      <link>https://paperswithcode.com/paper/breaking-modality-gap-in-rgbt-tracking</link>
      <description><![CDATA[To handle this issue, we take original RGB and TIR networks as the teachers, and distill their content knowledge into two student networks respectively by the style-content orthogonal feature decoupling scheme.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/breaking-modality-gap-in-rgbt-tracking</guid>
    </item>
    <item>
      <title>MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation</title>
      <link>https://paperswithcode.com/paper/mllm-can-see-dynamic-correction-decoding-for</link>
      <description><![CDATA[Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mllm-can-see-dynamic-correction-decoding-for</guid>
    </item>
    <item>
      <title>Efficiera Residual Networks: Hardware-Friendly Fully Binary Weight with 2-bit Activation Model Achieves Practical ImageNet Accuracy</title>
      <link>https://paperswithcode.com/paper/efficiera-residual-networks-hardware-friendly</link>
      <description><![CDATA[The edge-device environment imposes severe resource limitations, encompassing computation costs, hardware resource usage, and energy consumption for deploying deep neural network models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiera-residual-networks-hardware-friendly</guid>
    </item>
    <item>
      <title>DeltaDock: A Unified Framework for Accurate, Efficient, and Physically Reliable Molecular Docking</title>
      <link>https://paperswithcode.com/paper/deltadock-a-unified-framework-for-accurate</link>
      <description><![CDATA[Despite these advancements, current methods are often tailored for specific docking settings, and limitations such as the neglect of protein side-chain structures, difficulties in handling large binding pockets, and challenges in predicting physically valid structures exist.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deltadock-a-unified-framework-for-accurate</guid>
    </item>
    <item>
      <title>Overcoming Domain Limitations in Open-vocabulary Segmentation</title>
      <link>https://paperswithcode.com/paper/overcoming-domain-limitations-in-open</link>
      <description><![CDATA[Extensive experiments demonstrate that this approach allows OVS models to adapt to new domains while maintaining performance on the previous training dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/overcoming-domain-limitations-in-open</guid>
    </item>
    <item>
      <title>RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation</title>
      <link>https://paperswithcode.com/paper/rclicks-realistic-click-simulation-for</link>
      <description><![CDATA[According to our benchmark, in real-world usage interactive segmentation models may perform worse than it has been reported in the baseline benchmark, and most of the methods are not robust.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rclicks-realistic-click-simulation-for</guid>
    </item>
    <item>
      <title>DreamSteerer: Enhancing Source Image Conditioned Editability using Personalized Diffusion Models</title>
      <link>https://paperswithcode.com/paper/dreamsteerer-enhancing-source-image</link>
      <description><![CDATA[To address this, a straightforward solution is to incorporate a personalized diffusion model with a text-driven editing framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamsteerer-enhancing-source-image</guid>
    </item>
    <item>
      <title>Leaving the barn door open for Clever Hans: Simple features predict LLM benchmark answers</title>
      <link>https://paperswithcode.com/paper/leaving-the-barn-door-open-for-clever-hans</link>
      <description><![CDATA[In this work, we investigate the extent to which simple $n$-grams extracted from benchmark instances can be combined to predict labels in modern multiple-choice benchmarks designed for LLMs, and whether LLMs might be using such $n$-gram patterns to solve these benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leaving-the-barn-door-open-for-clever-hans</guid>
    </item>
    <item>
      <title>Language Models Encode Numbers Using Digit Representations in Base 10</title>
      <link>https://paperswithcode.com/paper/language-models-encode-numbers-using-digit</link>
      <description><![CDATA[Large language models (LLMs) frequently make errors when handling even simple numerical problems, such as comparing two small numbers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-encode-numbers-using-digit</guid>
    </item>
    <item>
      <title>MoH: Multi-Head Attention as Mixture-of-Head Attention</title>
      <link>https://paperswithcode.com/paper/moh-multi-head-attention-as-mixture-of-head</link>
      <description><![CDATA[We show that multi-head attention can be expressed in the summation form.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moh-multi-head-attention-as-mixture-of-head</guid>
    </item>
    <item>
      <title>GS^3: Efficient Relighting with Triple Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/gs-3-efficient-relighting-with-triple</link>
      <description><![CDATA[We present a spatial and angular Gaussian based representation and a triple splatting process, for real-time, high-quality novel lighting-and-view synthesis from multi-view point-lit input images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gs-3-efficient-relighting-with-triple</guid>
    </item>
    <item>
      <title>Subspace Optimization for Large Language Models with Convergence Guarantees</title>
      <link>https://paperswithcode.com/paper/subspace-optimization-for-large-language</link>
      <description><![CDATA[Subspace optimization algorithms, with GaLore (Zhao et al., 2024) as a representative method, have gained popularity for pre-training or fine-tuning large language models (LLMs) due to their memory efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/subspace-optimization-for-large-language</guid>
    </item>
    <item>
      <title>Unveiling the Mystery of Visual Attributes of Concrete and Abstract Concepts: Variability, Nearest Neighbors, and Challenging Categories</title>
      <link>https://paperswithcode.com/paper/unveiling-the-mystery-of-visual-attributes-of</link>
      <description><![CDATA[The visual representation of a concept varies significantly depending on its meaning and the context where it occurs; this poses multiple challenges both for vision and multimodal models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unveiling-the-mystery-of-visual-attributes-of</guid>
    </item>
    <item>
      <title>ECGN: A Cluster-Aware Approach to Graph Neural Networks for Imbalanced Classification</title>
      <link>https://paperswithcode.com/paper/ecgn-a-cluster-aware-approach-to-graph-neural</link>
      <description><![CDATA[We propose the Enhanced Cluster-aware Graph Network (ECGN), a novel method that addresses these issues by integrating cluster-specific training with synthetic node generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ecgn-a-cluster-aware-approach-to-graph-neural</guid>
    </item>
    <item>
      <title>Deep unrolled primal dual network for TOF-PET list-mode image reconstruction</title>
      <link>https://paperswithcode.com/paper/deep-unrolled-primal-dual-network-for-tof-pet</link>
      <description><![CDATA[In this study, we propose a deep unrolled primal dual network for TOF-PET list-mode reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-unrolled-primal-dual-network-for-tof-pet</guid>
    </item>
    <item>
      <title>Time-Series Foundation Model for Value-at-Risk</title>
      <link>https://paperswithcode.com/paper/time-series-foundation-model-for-value-at</link>
      <description><![CDATA[This study is the first to explore the application of a time-series foundation model for VaR estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/time-series-foundation-model-for-value-at</guid>
    </item>
    <item>
      <title>PaSTe: Improving the Efficiency of Visual Anomaly Detection at the Edge</title>
      <link>https://paperswithcode.com/paper/paste-improving-the-efficiency-of-visual</link>
      <description><![CDATA[Visual Anomaly Detection (VAD) has gained significant research attention for its ability to identify anomalous images and pinpoint the specific areas responsible for the anomaly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paste-improving-the-efficiency-of-visual</guid>
    </item>
    <item>
      <title>MANet: Fine-Tuning Segment Anything Model for Multimodal Remote Sensing Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/manet-fine-tuning-segment-anything-model-for</link>
      <description><![CDATA[Building upon recent advancements in vision foundation models, particularly the Segment Anything Model (SAM), this study introduces a novel Multimodal Adapter-based Network (MANet) for multimodal remote sensing semantic segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/manet-fine-tuning-segment-anything-model-for</guid>
    </item>
    <item>
      <title>Error Diffusion: Post Training Quantization with Block-Scaled Number Formats for Neural Networks</title>
      <link>https://paperswithcode.com/paper/error-diffusion-post-training-quantization</link>
      <description><![CDATA[Quantization reduces the model's hardware costs, such as data movement, storage, and operations like multiply and addition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/error-diffusion-post-training-quantization</guid>
    </item>
    <item>
      <title>Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models</title>
      <link>https://paperswithcode.com/paper/layer-wise-importance-matters-less-memory-for</link>
      <description><![CDATA[Extensive experiments on a range of LLMs, PEFTs, and downstream tasks substantiate the effectiveness of our proposed method, showcasing IST's capacity to enhance existing layer-based PEFT methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/layer-wise-importance-matters-less-memory-for</guid>
    </item>
    <item>
      <title>Process Reward Model with Q-Value Rankings</title>
      <link>https://paperswithcode.com/paper/process-reward-model-with-q-value-rankings</link>
      <description><![CDATA[PQM optimizes Q-value rankings based on a novel comparative loss function, enhancing the model's ability to capture the intricate dynamics among sequential decisions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/process-reward-model-with-q-value-rankings</guid>
    </item>
    <item>
      <title>CVCP-Fusion: On Implicit Depth Estimation for 3D Bounding Box Prediction</title>
      <link>https://paperswithcode.com/paper/cvcp-fusion-on-implicit-depth-estimation-for</link>
      <description><![CDATA[In this paper we propose Cross-View Center Point-Fusion, a state-of-the-art model to perform 3D object detection by combining camera and LiDAR-derived features in the BEV space to preserve semantic density from the camera stream while incorporating spacial data from the LiDAR stream.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cvcp-fusion-on-implicit-depth-estimation-for</guid>
    </item>
    <item>
      <title>It Takes Two to Tango: Directly Optimizing for Constrained Synthesizability in Generative Molecular Design</title>
      <link>https://paperswithcode.com/paper/it-takes-two-to-tango-directly-optimizing-for</link>
      <description><![CDATA[Our framework is the first generative approach to tackle constrained synthesizability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/it-takes-two-to-tango-directly-optimizing-for</guid>
    </item>
    <item>
      <title>Do LLMs Have the Generalization Ability in Conducting Causal Inference?</title>
      <link>https://paperswithcode.com/paper/do-llms-have-the-generalization-ability-in</link>
      <description><![CDATA[In this paper, we selected four tasks: Causal Path Discovery (CP), Backdoor Adjustment (BA), Factual Inference (FI), and Counterfactual Inference (CI) as representatives of causal inference tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-llms-have-the-generalization-ability-in</guid>
    </item>
    <item>
      <title>On-the-fly Modulation for Balanced Multimodal Learning</title>
      <link>https://paperswithcode.com/paper/on-the-fly-modulation-for-balanced-multimodal</link>
      <description><![CDATA[Then, On-the-fly Prediction Modulation (OPM) and On-the-fly Gradient Modulation (OGM) strategies are proposed to modulate the optimization of each modality, by monitoring the discriminative discrepancy between modalities during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-fly-modulation-for-balanced-multimodal</guid>
    </item>
    <item>
      <title>Contrastive learning of cell state dynamics in response to perturbations</title>
      <link>https://paperswithcode.com/paper/contrastive-learning-of-cell-state-dynamics</link>
      <description><![CDATA[We illustrate the features and applications of DynaCLR with the following experiments: analyzing the kinetics of viral infection in human cells, detecting transient changes in cell morphology due to cell division, and mapping the dynamics of organelles due to viral infection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-learning-of-cell-state-dynamics</guid>
    </item>
    <item>
      <title>Efficient, Accurate and Stable Gradients for Neural ODEs</title>
      <link>https://paperswithcode.com/paper/efficient-accurate-and-stable-gradients-for</link>
      <description><![CDATA[In this work, we present a class of algebraically reversible solvers that are both high-order and numerically stable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-accurate-and-stable-gradients-for</guid>
    </item>
    <item>
      <title>ChatHouseDiffusion: Prompt-Guided Generation and Editing of Floor Plans</title>
      <link>https://paperswithcode.com/paper/chathousediffusion-prompt-guided-generation</link>
      <description><![CDATA[The generation and editing of floor plans are critical in architectural planning, requiring a high degree of flexibility and efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chathousediffusion-prompt-guided-generation</guid>
    </item>
    <item>
      <title>MMFuser: Multimodal Multi-Layer Feature Fuser for Fine-Grained Vision-Language Understanding</title>
      <link>https://paperswithcode.com/paper/mmfuser-multimodal-multi-layer-feature-fuser</link>
      <description><![CDATA[To address this issue, we propose \modelname, a simple yet effective multi-layer feature fuser that efficiently integrates deep and shallow features from Vision Transformers (ViTs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmfuser-multimodal-multi-layer-feature-fuser</guid>
    </item>
    <item>
      <title>Personas with Attitudes: Controlling LLMs for Diverse Data Annotation</title>
      <link>https://paperswithcode.com/paper/personas-with-attitudes-controlling-llms-for</link>
      <description><![CDATA[We present a novel approach for enhancing diversity and control in data annotation tasks by personalizing large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personas-with-attitudes-controlling-llms-for</guid>
    </item>
    <item>
      <title>Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs</title>
      <link>https://paperswithcode.com/paper/difficult-task-yes-but-simple-task-no</link>
      <description><![CDATA[Multimodal Large Language Models (MLLMs) demonstrate a strong understanding of the real world and can even handle complex tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/difficult-task-yes-but-simple-task-no</guid>
    </item>
    <item>
      <title>LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/llm-mixer-multiscale-mixing-in-llms-for-time</link>
      <description><![CDATA[Time series forecasting remains a challenging task, particularly in the context of complex multiscale temporal patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-mixer-multiscale-mixing-in-llms-for-time</guid>
    </item>
  </channel>
</rss>
