<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 06 Jan 2025 09:17:00 +0000</lastBuildDate>
    <item>
      <title>JoyGen: Audio-Driven 3D Depth-Aware Talking-Face Video Editing</title>
      <link>https://paperswithcode.com/paper/joygen-audio-driven-3d-depth-aware-talking</link>
      <description><![CDATA[Significant progress has been made in talking-face video generation research; however, precise lip-audio synchronization and high visual quality remain challenging in editing lip shapes based on input audio.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/joygen-audio-driven-3d-depth-aware-talking</guid>
    </item>
    <item>
      <title>A Multi-task Supervised Compression Model for Split Computing</title>
      <link>https://paperswithcode.com/paper/a-multi-task-supervised-compression-model-for</link>
      <description><![CDATA[Split computing ($\neq$ split learning) is a promising approach to deep learning models for resource-constrained edge computing systems, where weak sensor (mobile) devices are wirelessly connected to stronger edge servers through channels with limited communication capacity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-multi-task-supervised-compression-model-for</guid>
    </item>
    <item>
      <title>Bridging Simplicity and Sophistication using GLinear: A Novel Architecture for Enhanced Time Series Prediction</title>
      <link>https://paperswithcode.com/paper/bridging-simplicity-and-sophistication-using-1</link>
      <description><![CDATA[A performance comparison with state-of-the-art linear architectures (such as NLinear, DLinear, and RLinear) and transformer-based time series predictor (Autoformer) shows that the GLinear, despite being parametrically efficient, significantly outperforms the existing architectures in most cases of multivariate TSF.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridging-simplicity-and-sophistication-using-1</guid>
    </item>
    <item>
      <title>HybridTrack: A Hybrid Approach for Robust Multi-Object Tracking</title>
      <link>https://paperswithcode.com/paper/hybridtrack-a-hybrid-approach-for-robust</link>
      <description><![CDATA[The evolution of Advanced Driver Assistance Systems (ADAS) has increased the need for robust and generalizable algorithms for multi-object tracking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hybridtrack-a-hybrid-approach-for-robust</guid>
    </item>
    <item>
      <title>SVFR: A Unified Framework for Generalized Video Face Restoration</title>
      <link>https://paperswithcode.com/paper/svfr-a-unified-framework-for-generalized</link>
      <description><![CDATA[In this paper, we propose a novel approach for the Generalized Video Face Restoration (GVFR) task, which integrates video BFR, inpainting, and colorization tasks that we empirically show to benefit each other.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/svfr-a-unified-framework-for-generalized</guid>
    </item>
    <item>
      <title>KaLM-Embedding: Superior Training Data Brings A Stronger Embedding Model</title>
      <link>https://paperswithcode.com/paper/kalm-embedding-superior-training-data-brings</link>
      <description><![CDATA[As retrieval-augmented generation prevails in large language models, embedding models are becoming increasingly crucial.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kalm-embedding-superior-training-data-brings</guid>
    </item>
    <item>
      <title>MuQ: Self-Supervised Music Representation Learning with Mel Residual Vector Quantization</title>
      <link>https://paperswithcode.com/paper/muq-self-supervised-music-representation</link>
      <description><![CDATA[In this paper, we propose a self-supervised music representation learning model for music understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/muq-self-supervised-music-representation</guid>
    </item>
    <item>
      <title>Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/reconstruction-vs-generation-taming-1</link>
      <description><![CDATA[The integrated system achieves state-of-the-art (SOTA) performance on ImageNet 256x256 generation with an FID score of 1. 35 while demonstrating remarkable training efficiency by reaching an FID score of 2. 11 in just 64 epochs--representing an over 21 times convergence speedup compared to the original DiT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reconstruction-vs-generation-taming-1</guid>
    </item>
    <item>
      <title>Conditional Consistency Guided Image Translation and Enhancement</title>
      <link>https://paperswithcode.com/paper/conditional-consistency-guided-image</link>
      <description><![CDATA[Consistency models have emerged as a promising alternative to diffusion models, offering high-quality generative capabilities through single-step sample generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conditional-consistency-guided-image</guid>
    </item>
    <item>
      <title>FlashInfer: Efficient and Customizable Attention Engine for LLM Inference Serving</title>
      <link>https://paperswithcode.com/paper/flashinfer-efficient-and-customizable</link>
      <description><![CDATA[We present FlashInfer: a customizable and efficient attention engine for LLM serving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flashinfer-efficient-and-customizable</guid>
    </item>
    <item>
      <title>TrustRAG: Enhancing Robustness and Trustworthiness in RAG</title>
      <link>https://paperswithcode.com/paper/trustrag-enhancing-robustness-and</link>
      <description><![CDATA[Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by integrating external knowledge sources, enabling more accurate and contextually relevant responses tailored to user queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trustrag-enhancing-robustness-and</guid>
    </item>
    <item>
      <title>2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining</title>
      <link>https://paperswithcode.com/paper/2-5-years-in-class-a-multimodal-textbook-for</link>
      <description><![CDATA[Compared to its counterparts, our video-centric textbook offers more coherent context, richer knowledge, and better image-text alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2-5-years-in-class-a-multimodal-textbook-for</guid>
    </item>
    <item>
      <title>VoiceRestore: Flow-Matching Transformers for Speech Recording Quality Restoration</title>
      <link>https://paperswithcode.com/paper/voicerestore-flow-matching-transformers-for-1</link>
      <description><![CDATA[We present VoiceRestore, a novel approach to restoring the quality of speech recordings using flow-matching Transformers trained in a self-supervised manner on synthetic data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/voicerestore-flow-matching-transformers-for-1</guid>
    </item>
    <item>
      <title>FGAseg: Fine-Grained Pixel-Text Alignment for Open-Vocabulary Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/fgaseg-fine-grained-pixel-text-alignment-for</link>
      <description><![CDATA[The core of FGAseg is a Pixel-Level Alignment module that employs a cross-modal attention mechanism and a text-pixel alignment loss to refine the coarse-grained alignment from CLIP, achieving finer-grained pixel-text semantic alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fgaseg-fine-grained-pixel-text-alignment-for</guid>
    </item>
    <item>
      <title>Cached Adaptive Token Merging: Dynamic Token Reduction and Redundant Computation Elimination in Diffusion Model</title>
      <link>https://paperswithcode.com/paper/cached-adaptive-token-merging-dynamic-token</link>
      <description><![CDATA[Diffusion models have emerged as a promising approach for generating high-quality, high-dimensional images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cached-adaptive-token-merging-dynamic-token</guid>
    </item>
    <item>
      <title>Population Aware Diffusion for Time Series Generation</title>
      <link>https://paperswithcode.com/paper/population-aware-diffusion-for-time-series</link>
      <description><![CDATA[We propose Population-aware Diffusion for Time Series (PaD-TS), a new TS generation model that better preserves the population-level properties.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/population-aware-diffusion-for-time-series</guid>
    </item>
    <item>
      <title>OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning</title>
      <link>https://paperswithcode.com/paper/ocrbench-v2-an-improved-benchmark-for</link>
      <description><![CDATA[Scoring the Optical Character Recognition (OCR) capabilities of Large Multimodal Models (LMMs) has witnessed growing interest recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ocrbench-v2-an-improved-benchmark-for</guid>
    </item>
    <item>
      <title>Exploiting Boundary Loss for the Hierarchical Panoptic Segmentation of Plants and Leaves</title>
      <link>https://paperswithcode.com/paper/exploiting-boundary-loss-for-the-hierarchical</link>
      <description><![CDATA[Precision agriculture leverages data and machine learning so that farmers can monitor their crops and target interventions precisely.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploiting-boundary-loss-for-the-hierarchical</guid>
    </item>
    <item>
      <title>Superposition in Transformers: A Novel Way of Building Mixture of Experts</title>
      <link>https://paperswithcode.com/paper/superposition-in-transformers-a-novel-way-of</link>
      <description><![CDATA[Catastrophic forgetting remains a major challenge when adapting large language models (LLMs) to new tasks or domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/superposition-in-transformers-a-novel-way-of</guid>
    </item>
    <item>
      <title>MapEval: A Map-Based Evaluation of Geo-Spatial Reasoning in Foundation Models</title>
      <link>https://paperswithcode.com/paper/mapeval-a-map-based-evaluation-of-geo-spatial</link>
      <description><![CDATA[To bridge this gap, we introduce MapEval, a benchmark designed to assess diverse and complex map-based user queries with geo-spatial reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mapeval-a-map-based-evaluation-of-geo-spatial</guid>
    </item>
    <item>
      <title>HisynSeg: Weakly-Supervised Histopathological Image Segmentation via Image-Mixing Synthesis and Consistency Regularization</title>
      <link>https://paperswithcode.com/paper/hisynseg-weakly-supervised-histopathological</link>
      <description><![CDATA[In order to further avoid the model overfitting to the occasional synthesis artifacts, we additionally propose a novel self-supervised consistency regularization, which enables the real images without segmentation masks to supervise the training of the segmentation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hisynseg-weakly-supervised-histopathological</guid>
    </item>
    <item>
      <title>A novel deep learning approach for facial emotion recognition: application to detecting emotional responses in elderly individuals with Alzheimerâ€™s disease</title>
      <link>https://paperswithcode.com/paper/a-novel-deep-learning-approach-for-facial</link>
      <description><![CDATA[Facial expressions are a critical form of nonverbal communication, conveying a wide range of emotions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-novel-deep-learning-approach-for-facial</guid>
    </item>
    <item>
      <title>Sample Correlation for Fingerprinting Deep Face Recognition</title>
      <link>https://paperswithcode.com/paper/sample-correlation-for-fingerprinting-deep</link>
      <description><![CDATA[Face recognition has witnessed remarkable advancements in recent years, thanks to the development of deep learning techniques. However, an off-the-shelf face recognition model as a commercial service could be stolen by model stealing attacks, posing great threats to the rights of the model owner. Model fingerprinting, as a model stealing detection method, aims to verify whether a suspect model is stolen from the victim model, gaining more and more attention nowadays. Previous methods always utilize transferable adversarial examples as the model fingerprint, but this method is known to be sensitive to adversarial defense and transfer learning techniques. To address this issue, we consider the pairwise relationship between samples instead and propose a novel yet simple model stealing detection method based on SAmple Correlation (SAC). Specifically, we present SAC-JC that selects JPEG compressed samples as model inputs and calculates the correlation matrix among their model outputs. Extensive results validate that SAC successfully defends against various model stealing attacks in deep face recognition, encompassing face verification and face emotion recognition, exhibiting the highest performance in terms of AUC, p-value and F1 score. Furthermore, we extend our evaluation of SAC-JC to object recognition datasets including Tiny-ImageNet and CIFAR10, which also demonstrates the superior performance of SAC-JC to previous methods. The code will be available at \url{https://github. com/guanjiyang/SAC_JC}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sample-correlation-for-fingerprinting-deep</guid>
    </item>
    <item>
      <title>Frequency-Masked Embedding Inference: A Non-Contrastive Approach for Time Series Representation Learning</title>
      <link>https://paperswithcode.com/paper/frequency-masked-embedding-inference-a-non</link>
      <description><![CDATA[To fundamentally overcome the limitations of contrastive learning, this paper introduces Frequency-masked Embedding Inference (FEI), a novel non-contrastive method that completely eliminates the need for positive and negative samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/frequency-masked-embedding-inference-a-non</guid>
    </item>
    <item>
      <title>ReFlow6D: Refraction-Guided Transparent Object 6D Pose Estimation via Intermediate Representation Learning</title>
      <link>https://paperswithcode.com/paper/reflow6d-refraction-guided-transparent-object</link>
      <description><![CDATA[To solve this, we present ReFlow6D, a novel method for transparent object 6D pose estimation that harnesses the refractive-intermediate representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reflow6d-refraction-guided-transparent-object</guid>
    </item>
    <item>
      <title>TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization</title>
      <link>https://paperswithcode.com/paper/tangoflux-super-fast-and-faithful-text-to</link>
      <description><![CDATA[We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44. 1kHz audio in just 3. 7 seconds on a single A40 GPU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tangoflux-super-fast-and-faithful-text-to</guid>
    </item>
    <item>
      <title>GASLITEing the Retrieval: Exploring Vulnerabilities in Dense Embedding-based Search</title>
      <link>https://paperswithcode.com/paper/gasliteing-the-retrieval-exploring</link>
      <description><![CDATA[Particularly, adversaries using GASLITE require minimal effort to manipulate search results$\unicode{x2013}$by injecting a negligible amount of adversarial passages ($\leq$0. 0001% of the corpus), they could make them visible in the top-10 results for 61-100% of unseen concept-specific queries against most evaluated models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gasliteing-the-retrieval-exploring</guid>
    </item>
    <item>
      <title>Quantum Diffusion Model for Quark and Gluon Jet Generation</title>
      <link>https://paperswithcode.com/paper/quantum-diffusion-model-for-quark-and-gluon</link>
      <description><![CDATA[Diffusion models have demonstrated remarkable success in image generation, but they are computationally intensive and time-consuming to train.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quantum-diffusion-model-for-quark-and-gluon</guid>
    </item>
    <item>
      <title>Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense</title>
      <link>https://paperswithcode.com/paper/toward-intelligent-and-secure-cloud-large</link>
      <description><![CDATA[The rapid evolution of cloud computing technologies and the increasing number of cloud applications have provided a large number of benefits in daily lives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toward-intelligent-and-secure-cloud-large</guid>
    </item>
    <item>
      <title>Mind the truncation gap: challenges of learning on dynamic graphs with recurrent architectures</title>
      <link>https://paperswithcode.com/paper/mind-the-truncation-gap-challenges-of</link>
      <description><![CDATA[In this work, we demonstrate that this truncation can limit the learning of dependencies beyond a single hop, resulting in reduced performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mind-the-truncation-gap-challenges-of</guid>
    </item>
    <item>
      <title>Towards Identity-Aware Cross-Modal Retrieval: a Dataset and a Baseline</title>
      <link>https://paperswithcode.com/paper/towards-identity-aware-cross-modal-retrieval</link>
      <description><![CDATA[Recent advancements in deep learning have significantly enhanced content-based retrieval methods, notably through models like CLIP that map images and texts into a shared embedding space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-identity-aware-cross-modal-retrieval</guid>
    </item>
    <item>
      <title>Generalizing in Net-Zero Microgrids: A Study with Federated PPO and TRPO</title>
      <link>https://paperswithcode.com/paper/generalizing-in-net-zero-microgrids-a-study</link>
      <description><![CDATA[This work addresses the challenge of optimal energy management in microgrids through a collaborative and privacy-preserving framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizing-in-net-zero-microgrids-a-study</guid>
    </item>
    <item>
      <title>YOLO-UniOW: Efficient Universal Open-World Object Detection</title>
      <link>https://paperswithcode.com/paper/yolo-uniow-efficient-universal-open-world</link>
      <description><![CDATA[In this work, we introduce Universal Open-World Object Detection (Uni-OWD), a new paradigm that unifies open-vocabulary and open-world object detection tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-uniow-efficient-universal-open-world</guid>
    </item>
    <item>
      <title>Visual Style Prompt Learning Using Diffusion Models for Blind Face Restoration</title>
      <link>https://paperswithcode.com/paper/visual-style-prompt-learning-using-diffusion</link>
      <description><![CDATA[Blind face restoration aims to recover high-quality facial images from various unidentified sources of degradation, posing significant challenges due to the minimal information retrievable from the degraded images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-style-prompt-learning-using-diffusion</guid>
    </item>
    <item>
      <title>HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation</title>
      <link>https://paperswithcode.com/paper/humaneval-pro-and-mbpp-pro-evaluating-large</link>
      <description><![CDATA[First, we propose a general recipe for generating more challenging versions of existing benchmarks, resulting in three new benchmarks: HumanEval Pro, MBPP Pro, and BigCodeBench-Lite Pro, specifically designed to assess LLMs on self-invoking code generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/humaneval-pro-and-mbpp-pro-evaluating-large</guid>
    </item>
    <item>
      <title>On Parallel External-Memory Bidirectional Search</title>
      <link>https://paperswithcode.com/paper/on-parallel-external-memory-bidirectional</link>
      <description><![CDATA[Parallelization and External Memory (PEM) techniques have significantly enhanced the capabilities of search algorithms when solving large-scale problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-parallel-external-memory-bidirectional</guid>
    </item>
    <item>
      <title>Length-Aware DETR for Robust Moment Retrieval</title>
      <link>https://paperswithcode.com/paper/length-aware-detr-for-robust-moment-retrieval</link>
      <description><![CDATA[Video Moment Retrieval (MR) aims to localize moments within a video based on a given natural language query.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/length-aware-detr-for-robust-moment-retrieval</guid>
    </item>
    <item>
      <title>Causal Hangover Effects</title>
      <link>https://paperswithcode.com/paper/causal-hangover-effects</link>
      <description><![CDATA[We are interested to see if teams exhibit a decline in performance the day following a game in a city with active nightlife; we call this a "hangover effect".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causal-hangover-effects</guid>
    </item>
    <item>
      <title>A Tale of Two Imperatives: Privacy and Explainability</title>
      <link>https://paperswithcode.com/paper/a-tale-of-two-imperatives-privacy-and</link>
      <description><![CDATA[Deep learning's preponderance across scientific domains has reshaped high-stakes decision-making, making it essential to follow rigorous operational frameworks that include both Right-to-Privacy (RTP) and Right-to-Explanation (RTE).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-tale-of-two-imperatives-privacy-and</guid>
    </item>
    <item>
      <title>Hierarchical Banzhaf Interaction for General Video-Language Representation Learning</title>
      <link>https://paperswithcode.com/paper/hierarchical-banzhaf-interaction-for-general</link>
      <description><![CDATA[As an important subfield, video-language representation learning focuses on learning representations using global semantic interactions between pre-defined video-text pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-banzhaf-interaction-for-general</guid>
    </item>
    <item>
      <title>LEASE: Offline Preference-based Reinforcement Learning with High Sample Efficiency</title>
      <link>https://paperswithcode.com/paper/lease-offline-preference-based-reinforcement</link>
      <description><![CDATA[Considering the pretrained reward model may generate incorrect labels for unlabeled data, we design an uncertainty-aware mechanism to ensure the performance of reward model, where only high confidence and low variance data are selected.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lease-offline-preference-based-reinforcement</guid>
    </item>
    <item>
      <title>Attributing Culture-Conditioned Generations to Pretraining Corpora</title>
      <link>https://paperswithcode.com/paper/attributing-culture-conditioned-generations</link>
      <description><![CDATA[Using MEMOed on culture-conditioned generations about food and clothing for 110 cultures, we find that high-frequency cultures in pretraining data yield more generations with memorized symbols, while some low-frequency cultures produce none.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attributing-culture-conditioned-generations</guid>
    </item>
    <item>
      <title>Edicho: Consistent Image Editing in the Wild</title>
      <link>https://paperswithcode.com/paper/edicho-consistent-image-editing-in-the-wild</link>
      <description><![CDATA[As a verified need, consistent editing across in-the-wild images remains a technical challenge arising from various unmanageable factors, like object poses, lighting conditions, and photography environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edicho-consistent-image-editing-in-the-wild</guid>
    </item>
    <item>
      <title>Are Vision-Language Models Truly Understanding Multi-vision Sensor?</title>
      <link>https://paperswithcode.com/paper/are-vision-language-models-truly</link>
      <description><![CDATA[Moreover, we introduce Diverse Negative Attributes (DNA) optimization to enable VLMs to perform deep reasoning on multi-vision sensor tasks, helping to bridge the core information gap between images and sensor data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/are-vision-language-models-truly</guid>
    </item>
    <item>
      <title>Training Software Engineering Agents and Verifiers with SWE-Gym</title>
      <link>https://paperswithcode.com/paper/training-software-engineering-agents-and</link>
      <description><![CDATA[When combined with our fine-tuned SWE agents, we achieve 32. 0% and 26. 0% on SWE-Bench Verified and Lite, respectively, reflecting a new state-of-the-art for open-weight SWE agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-software-engineering-agents-and</guid>
    </item>
    <item>
      <title>TiGDistill-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning Distillation</title>
      <link>https://paperswithcode.com/paper/tigdistill-bev-multi-view-bev-3d-object</link>
      <description><![CDATA[Researchers have consistently aimed to leverage LiDAR's precise spatial information to enhance camera-based detectors through methods like depth supervision and bird-eye-view (BEV) feature distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tigdistill-bev-multi-view-bev-3d-object</guid>
    </item>
    <item>
      <title>M$^3$oralBench: A MultiModal Moral Benchmark for LVLMs</title>
      <link>https://paperswithcode.com/paper/m-3-oralbench-a-multimodal-moral-benchmark</link>
      <description><![CDATA[To bridge this gap, we introduce M$^3$oralBench, the first MultiModal Moral Benchmark for LVLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/m-3-oralbench-a-multimodal-moral-benchmark</guid>
    </item>
    <item>
      <title>A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications</title>
      <link>https://paperswithcode.com/paper/a-standardized-framework-for-sensor-placement</link>
      <description><![CDATA[The proliferation of wearable sensors and monitoring technologies has created an urgent need for standardized sensor placement protocols.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-standardized-framework-for-sensor-placement</guid>
    </item>
    <item>
      <title>Distributed Mixture-of-Agents for Edge Inference with Large Language Models</title>
      <link>https://paperswithcode.com/paper/distributed-mixture-of-agents-for-edge</link>
      <description><![CDATA[Further, we demonstrate through experiments, leveraging open-source LLMs for the implementation of distributed MoA, that certain MoA configurations produce higher-quality responses compared to others, as evaluated on AlpacaEval 2. 0 benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distributed-mixture-of-agents-for-edge</guid>
    </item>
    <item>
      <title>MapQaTor: A System for Efficient Annotation of Map Query Datasets</title>
      <link>https://paperswithcode.com/paper/mapqator-a-system-for-efficient-annotation-of</link>
      <description><![CDATA[Mapping and navigation services like Google Maps, Apple Maps, Openstreet Maps, are essential for accessing various location-based data, yet they often struggle to handle natural language geospatial queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mapqator-a-system-for-efficient-annotation-of</guid>
    </item>
  </channel>
</rss>
