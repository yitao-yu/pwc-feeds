<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 19 Feb 2024 21:07:27 +0000</lastBuildDate>
    <item>
      <title>3D Diffuser Actor: Policy Diffusion with 3D Scene Representations</title>
      <link>https://paperswithcode.com/paper/3d-diffuser-actor-policy-diffusion-with-3d</link>
      <description><![CDATA[We marry diffusion policies and 3D scene representations for robot manipulation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-diffuser-actor-policy-diffusion-with-3d</guid>
    </item>
    <item>
      <title>DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows</title>
      <link>https://paperswithcode.com/paper/datadreamer-a-tool-for-synthetic-data</link>
      <description><![CDATA[The rapid rise to prominence of these models and these unique challenges has had immediate adverse impacts on open science and on the reproducibility of work that uses them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datadreamer-a-tool-for-synthetic-data</guid>
    </item>
    <item>
      <title>Pushing the Limits of Zero-shot End-to-End Speech Translation</title>
      <link>https://paperswithcode.com/paper/pushing-the-limits-of-zero-shot-end-to-end</link>
      <description><![CDATA[The speech encoder seamlessly integrates with the MT model at inference, enabling direct translation from speech to text, across all languages supported by the MT model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pushing-the-limits-of-zero-shot-end-to-end</guid>
    </item>
    <item>
      <title>Performance Gaps in Multi-view Clustering under the Nested Matrix-Tensor Model</title>
      <link>https://paperswithcode.com/paper/performance-gaps-in-multi-view-clustering</link>
      <description><![CDATA[We study the estimation of a planted signal hidden in a recently introduced nested matrix-tensor model, which is an extension of the classical spiked rank-one tensor model, motivated by multi-view clustering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/performance-gaps-in-multi-view-clustering</guid>
    </item>
    <item>
      <title>Do Llamas Work in English? On the Latent Language of Multilingual Transformers</title>
      <link>https://paperswithcode.com/paper/do-llamas-work-in-english-on-the-latent</link>
      <description><![CDATA[Tracking intermediate embeddings through their high-dimensional space reveals three distinct phases, whereby intermediate embeddings (1) start far away from output token embeddings; (2) already allow for decoding a semantically correct next token in the middle layers, but give higher probability to its version in English than in the input language; (3) finally move into an input-language-specific region of the embedding space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-llamas-work-in-english-on-the-latent</guid>
    </item>
    <item>
      <title>BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation</title>
      <link>https://paperswithcode.com/paper/bitdistiller-unleashing-the-potential-of-sub</link>
      <description><![CDATA[The upscaling of Large Language Models (LLMs) has yielded impressive advances in natural language processing, yet it also poses significant deployment challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bitdistiller-unleashing-the-potential-of-sub</guid>
    </item>
    <item>
      <title>Linear Transformers with Learnable Kernel Functions are Better In-Context Models</title>
      <link>https://paperswithcode.com/paper/linear-transformers-with-learnable-kernel</link>
      <description><![CDATA[Advancing the frontier of subquadratic architectures for Language Models (LMs) is crucial in the rapidly evolving field of natural language processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linear-transformers-with-learnable-kernel</guid>
    </item>
    <item>
      <title>Fitness-based Linkage Learning and Maximum-Clique Conditional Linkage Modelling for Gray-box Optimization with RV-GOMEA</title>
      <link>https://paperswithcode.com/paper/fitness-based-linkage-learning-and-maximum</link>
      <description><![CDATA[In addition, we propose a new way to model overlapping dependencies in conditional linkage models to maximize the joint sampling of fully interdependent groups of variables.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fitness-based-linkage-learning-and-maximum</guid>
    </item>
    <item>
      <title>Personalised Drug Identifier for Cancer Treatment with Transformers using Auxiliary Information</title>
      <link>https://paperswithcode.com/paper/personalised-drug-identifier-for-cancer</link>
      <description><![CDATA[Cancer remains a global challenge due to its growing clinical and economic burden.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalised-drug-identifier-for-cancer</guid>
    </item>
    <item>
      <title>Interpreting CLIP with Sparse Linear Concept Embeddings (SpLiCE)</title>
      <link>https://paperswithcode.com/paper/interpreting-clip-with-sparse-linear-concept</link>
      <description><![CDATA[CLIP embeddings have demonstrated remarkable performance across a wide range of computer vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpreting-clip-with-sparse-linear-concept</guid>
    </item>
    <item>
      <title>Stochastic Localization via Iterative Posterior Sampling</title>
      <link>https://paperswithcode.com/paper/stochastic-localization-via-iterative</link>
      <description><![CDATA[Building upon score-based learning, new interest in stochastic localization techniques has recently emerged.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stochastic-localization-via-iterative</guid>
    </item>
    <item>
      <title>Theoretical Understanding of Learning from Adversarial Perturbations</title>
      <link>https://paperswithcode.com/paper/theoretical-understanding-of-learning-from</link>
      <description><![CDATA[In this study, we provide a theoretical framework for understanding learning from perturbations using a one-hidden-layer network trained on mutually orthogonal samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/theoretical-understanding-of-learning-from</guid>
    </item>
    <item>
      <title>Compact and De-biased Negative Instance Embedding for Multi-Instance Learning on Whole-Slide Image Classification</title>
      <link>https://paperswithcode.com/paper/compact-and-de-biased-negative-instance</link>
      <description><![CDATA[Using this free annotation, we introduce a semi-supervision signal to de-bias the inter-slide variability and to capture the common factors of variation within normal patches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compact-and-de-biased-negative-instance</guid>
    </item>
    <item>
      <title>CodaMal: Contrastive Domain Adaptation for Malaria Detection in Low-Cost Microscopes</title>
      <link>https://paperswithcode.com/paper/codamal-contrastive-domain-adaptation-for</link>
      <description><![CDATA[Annotating images from LCM significantly increases the burden on medical experts compared to annotating images from high-cost microscopes (HCM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codamal-contrastive-domain-adaptation-for</guid>
    </item>
    <item>
      <title>Smaller Language Models are capable of selecting Instruction-Tuning Training Data for Larger Language Models</title>
      <link>https://paperswithcode.com/paper/smaller-language-models-are-capable-of</link>
      <description><![CDATA[In this paper, we introduce a novel training data selection based on the learning percentage of the samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smaller-language-models-are-capable-of</guid>
    </item>
    <item>
      <title>Steering Conversational Large Language Models for Long Emotional Support Conversations</title>
      <link>https://paperswithcode.com/paper/steering-conversational-large-language-models</link>
      <description><![CDATA[In this study, we address the challenge of consistently following emotional support strategies in long conversations by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/steering-conversational-large-language-models</guid>
    </item>
    <item>
      <title>FedKit: Enabling Cross-Platform Federated Learning for Android and iOS</title>
      <link>https://paperswithcode.com/paper/fedkit-enabling-cross-platform-federated</link>
      <description><![CDATA[We present FedKit, a federated learning (FL) system tailored for cross-platform FL research on Android and iOS devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedkit-enabling-cross-platform-federated</guid>
    </item>
    <item>
      <title>Genome-AC-GAN: Enhancing Synthetic Genotype Generation through Auxiliary Classification</title>
      <link>https://paperswithcode.com/paper/genome-ac-gan-enhancing-synthetic-genotype</link>
      <description><![CDATA[We conducted experiments to evaluate the performance of the Genome-AC-GAN and compare the AGs it generates with real genomic data as well as with AGs generated by previously published methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/genome-ac-gan-enhancing-synthetic-genotype</guid>
    </item>
    <item>
      <title>Towards Cohesion-Fairness Harmony: Contrastive Regularization in Individual Fair Graph Clustering</title>
      <link>https://paperswithcode.com/paper/towards-cohesion-fairness-harmony-contrastive</link>
      <description><![CDATA[Conventional fair graph clustering methods face two primary challenges: i) They prioritize balanced clusters at the expense of cluster cohesion by imposing rigid constraints, ii) Existing methods of both individual and group-level fairness in graph partitioning mostly rely on eigen decompositions and thus, generally lack interpretability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-cohesion-fairness-harmony-contrastive</guid>
    </item>
    <item>
      <title>Modelling crypto markets by multi-agent reinforcement learning</title>
      <link>https://paperswithcode.com/paper/modelling-crypto-markets-by-multi-agent</link>
      <description><![CDATA[Building on a previous foundation work (Lussange et al. 2020), this study introduces a multi-agent reinforcement learning (MARL) model simulating crypto markets, which is calibrated to the Binance's daily closing prices of $153$ cryptocurrencies that were continuously traded between 2018 and 2022.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/modelling-crypto-markets-by-multi-agent</guid>
    </item>
    <item>
      <title>ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages</title>
      <link>https://paperswithcode.com/paper/toolsword-unveiling-safety-issues-of-large</link>
      <description><![CDATA[Tool learning is widely acknowledged as a foundational approach or deploying large language models (LLMs) in real-world scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toolsword-unveiling-safety-issues-of-large</guid>
    </item>
    <item>
      <title>Training Class-Imbalanced Diffusion Model Via Overlap Optimization</title>
      <link>https://paperswithcode.com/paper/training-class-imbalanced-diffusion-model-via</link>
      <description><![CDATA[To address the observed appearance overlap between synthesized images of rare classes and tail classes, we propose a method based on contrastive learning to minimize the overlap between distributions of synthetic images for different classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-class-imbalanced-diffusion-model-via</guid>
    </item>
    <item>
      <title>FairSync: Ensuring Amortized Group Exposure in Distributed Recommendation Retrieval</title>
      <link>https://paperswithcode.com/paper/fairsync-ensuring-amortized-group-exposure-in</link>
      <description><![CDATA[Specifically, FairSync resolves the issue by moving it to the dual space, where a central node aggregates historical fairness data into a vector and distributes it to all servers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fairsync-ensuring-amortized-group-exposure-in</guid>
    </item>
    <item>
      <title>LSRFormer: Efficient Transformer Supply Convolutional Neural Networks with Global Information for Aerial Image Segmentation</title>
      <link>https://paperswithcode.com/paper/https-ieeexplore-ieee-org-document-10438484</link>
      <description><![CDATA[Convolutional Neural Networks (CNNs) can capture local context information well but cannot model the global dependencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/https-ieeexplore-ieee-org-document-10438484</guid>
    </item>
    <item>
      <title>BlackJAX: Composable Bayesian inference in JAX</title>
      <link>https://paperswithcode.com/paper/blackjax-composable-bayesian-inference-in-jax</link>
      <description><![CDATA[BlackJAX is a library implementing sampling and variational inference algorithms commonly used in Bayesian computation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blackjax-composable-bayesian-inference-in-jax</guid>
    </item>
    <item>
      <title>Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/weak-mamba-unet-visual-mamba-makes-cnn-and</link>
      <description><![CDATA[Medical image segmentation is increasingly reliant on deep learning techniques, yet the promising performance often come with high annotation costs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/weak-mamba-unet-visual-mamba-makes-cnn-and</guid>
    </item>
    <item>
      <title>Conformalized Credal Set Predictors</title>
      <link>https://paperswithcode.com/paper/conformalized-credal-set-predictors</link>
      <description><![CDATA[Credal sets are sets of probability distributions that are considered as candidates for an imprecisely known ground-truth distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conformalized-credal-set-predictors</guid>
    </item>
    <item>
      <title>STF: Spatio-Temporal Fusion Module for Improving Video Object Detection</title>
      <link>https://paperswithcode.com/paper/stf-spatio-temporal-fusion-module-for</link>
      <description><![CDATA[The objective of our work is to leverage this complementary information to improve detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stf-spatio-temporal-fusion-module-for</guid>
    </item>
    <item>
      <title>Let's Learn Step by Step: Enhancing In-Context Learning Ability with Curriculum Learning</title>
      <link>https://paperswithcode.com/paper/let-s-learn-step-by-step-enhancing-in-context</link>
      <description><![CDATA[We advocate the few-shot in-context curriculum learning (ICCL), a simple but effective demonstration ordering method for ICL, which implies gradually increasing the complexity of prompt demonstrations during the inference process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-s-learn-step-by-step-enhancing-in-context</guid>
    </item>
    <item>
      <title>DE-COP: Detecting Copyrighted Content in Language Models Training Data</title>
      <link>https://paperswithcode.com/paper/de-cop-detecting-copyrighted-content-in</link>
      <description><![CDATA[We are motivated by the premise that a language model is likely to identify verbatim excerpts from its training text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/de-cop-detecting-copyrighted-content-in</guid>
    </item>
    <item>
      <title>Repurposing Coal Power Plants into Thermal Energy Storage for Supporting Zero-carbon Data Centers</title>
      <link>https://paperswithcode.com/paper/repurposing-coal-power-plants-into-thermal</link>
      <description><![CDATA[Coal power plants will need to be phased out and face stranded asset risks under the net-zero energy system transition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repurposing-coal-power-plants-into-thermal</guid>
    </item>
    <item>
      <title>A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents</title>
      <link>https://paperswithcode.com/paper/a-trembling-house-of-cards-mapping</link>
      <description><![CDATA[There is a surprisingly large gap between the speed and scale of their development and deployment and our understanding of their safety risks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-trembling-house-of-cards-mapping</guid>
    </item>
    <item>
      <title>Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning</title>
      <link>https://paperswithcode.com/paper/selective-reflection-tuning-student-selected</link>
      <description><![CDATA[Instruction tuning is critical to large language models (LLMs) for achieving better instruction following and task adaptation capabilities but its success heavily relies on the training data quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/selective-reflection-tuning-student-selected</guid>
    </item>
    <item>
      <title>Textual Localization: Decomposing Multi-concept Images for Subject-Driven Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/textual-localization-decomposing-multi</link>
      <description><![CDATA[Subject-driven text-to-image diffusion models empower users to tailor the model to new concepts absent in the pre-training dataset using a few sample images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textual-localization-decomposing-multi</guid>
    </item>
    <item>
      <title>Unlocking Structure Measuring: Introducing PDD, an Automatic Metric for Positional Discourse Coherence</title>
      <link>https://paperswithcode.com/paper/unlocking-structure-measuring-introducing-pdd</link>
      <description><![CDATA[Recent large language models (LLMs) have shown remarkable performance in aligning generated text with user intentions across various tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlocking-structure-measuring-introducing-pdd</guid>
    </item>
    <item>
      <title>ControlLM: Crafting Diverse Personalities for Language Models</title>
      <link>https://paperswithcode.com/paper/controllm-crafting-diverse-personalities-for</link>
      <description><![CDATA[This heightens the need to control model behaviors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controllm-crafting-diverse-personalities-for</guid>
    </item>
    <item>
      <title>Criterion collapse and loss distribution control</title>
      <link>https://paperswithcode.com/paper/criterion-collapse-and-loss-distribution</link>
      <description><![CDATA[In this work, we consider the notion of "criterion collapse," in which optimization of one metric implies optimality in another, with a particular focus on conditions for collapse into error probability minimizers under a wide variety of learning criteria, ranging from DRO and OCE risks (CVaR, tilted ERM) to non-monotonic criteria underlying recent ascent-descent algorithms explored in the literature (Flooding, SoftAD).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/criterion-collapse-and-loss-distribution</guid>
    </item>
    <item>
      <title>TIAViz: A Browser-based Visualization Tool for Computational Pathology Models</title>
      <link>https://paperswithcode.com/paper/tiaviz-a-browser-based-visualization-tool-for</link>
      <description><![CDATA[Throughout the development of a machine learning (ML) model in digital pathology, it is crucial to have flexible, openly available tools to visualize models, from their outputs and predictions to the underlying annotations and images used to train or test a model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tiaviz-a-browser-based-visualization-tool-for</guid>
    </item>
    <item>
      <title>Visually Dehallucinative Instruction Generation: Know What You Don't Know</title>
      <link>https://paperswithcode.com/paper/visually-dehallucinative-instruction-1</link>
      <description><![CDATA["When did the emperor Napoleon invented iPhone?"]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visually-dehallucinative-instruction-1</guid>
    </item>
    <item>
      <title>TEXTRON: Weakly Supervised Multilingual Text Detection through Data Programming</title>
      <link>https://paperswithcode.com/paper/textron-weakly-supervised-multilingual-text-1</link>
      <description><![CDATA[In order to solve this problem, we propose TEXTRON, a Data Programming-based approach, where users can plug various text detection methods into a weak supervision-based learning framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textron-weakly-supervised-multilingual-text-1</guid>
    </item>
    <item>
      <title>GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving</title>
      <link>https://paperswithcode.com/paper/geoeval-benchmark-for-evaluating-llms-and</link>
      <description><![CDATA[Yet, their proficiency in tackling geometry math problems, which necessitates an integrated understanding of both textual and visual information, has not been thoroughly evaluated.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geoeval-benchmark-for-evaluating-llms-and</guid>
    </item>
    <item>
      <title>OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset</title>
      <link>https://paperswithcode.com/paper/openmathinstruct-1-a-1-8-million-math</link>
      <description><![CDATA[Building on the recent progress in open-source LLMs, our proposed prompting novelty, and some brute-force scaling, we construct OpenMathInstruct-1, a math instruction tuning dataset with 1. 8M problem-solution pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openmathinstruct-1-a-1-8-million-math</guid>
    </item>
    <item>
      <title>Generative Representational Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/generative-representational-instruction</link>
      <description><![CDATA[Notably, we find that GRIT matches training on only generative or embedding data, thus we can unify both at no performance loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-representational-instruction</guid>
    </item>
    <item>
      <title>Best Arm Identification for Prompt Learning under a Limited Budget</title>
      <link>https://paperswithcode.com/paper/best-arm-identification-for-prompt-learning</link>
      <description><![CDATA[Based on this connection, a general framework TRIPLE (besT aRm Identification for Prompt LEarning) is proposed to harness the power of BAI-FB in prompt learning systematically.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/best-arm-identification-for-prompt-learning</guid>
    </item>
    <item>
      <title>Uncertainty Decomposition and Quantification for In-Context Learning of Large Language Models</title>
      <link>https://paperswithcode.com/paper/uncertainty-decomposition-and-quantification</link>
      <description><![CDATA[Existing works have been devoted to quantifying the uncertainty in LLM's response, but they often overlook the complex nature of LLMs and the uniqueness of in-context learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncertainty-decomposition-and-quantification</guid>
    </item>
    <item>
      <title>QUICK: Quantization-aware Interleaving and Conflict-free Kernel for efficient LLM inference</title>
      <link>https://paperswithcode.com/paper/quick-quantization-aware-interleaving-and</link>
      <description><![CDATA[We introduce QUICK, a group of novel optimized CUDA kernels for the efficient inference of quantized Large Language Models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quick-quantization-aware-interleaving-and</guid>
    </item>
    <item>
      <title>FedLion: Faster Adaptive Federated Optimization with Fewer Communication</title>
      <link>https://paperswithcode.com/paper/fedlion-faster-adaptive-federated</link>
      <description><![CDATA[In Federated Learning (FL), a framework to train machine learning models across distributed data, well-known algorithms like FedAvg tend to have slow convergence rates, resulting in high communication costs during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedlion-faster-adaptive-federated</guid>
    </item>
    <item>
      <title>Recovering the Pre-Fine-Tuning Weights of Generative Models</title>
      <link>https://paperswithcode.com/paper/recovering-the-pre-fine-tuning-weights-of</link>
      <description><![CDATA[The dominant paradigm in generative modeling consists of two steps: i) pre-training on a large-scale but unsafe dataset, ii) aligning the pre-trained model with human values via fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recovering-the-pre-fine-tuning-weights-of</guid>
    </item>
    <item>
      <title>X-maps: Direct Depth Lookup for Event-based Structured Light Systems</title>
      <link>https://paperswithcode.com/paper/x-maps-direct-depth-lookup-for-event-based-1</link>
      <description><![CDATA[We present a new approach to direct depth estimation for Spatial Augmented Reality (SAR) applications using event cameras.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-maps-direct-depth-lookup-for-event-based-1</guid>
    </item>
    <item>
      <title>COVIDHealth: A Benchmark Twitter Dataset and Machine Learning based Web Application for Classifying COVID-19 Discussions</title>
      <link>https://paperswithcode.com/paper/covidhealth-a-benchmark-twitter-dataset-and</link>
      <description><![CDATA[In this study, our primary objective is to develop a machine learning-based web application for automatically classifying COVID-19-related discussions on social media.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/covidhealth-a-benchmark-twitter-dataset-and</guid>
    </item>
  </channel>
</rss>
