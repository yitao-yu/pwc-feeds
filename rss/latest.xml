<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 26 Apr 2024 21:06:51 +0000</lastBuildDate>
    <item>
      <title>PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning</title>
      <link>https://paperswithcode.com/paper/pllava-parameter-free-llava-extension-from</link>
      <description><![CDATA[PLLaVA achieves new state-of-the-art performance on modern benchmark datasets for both video question-answer and captioning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pllava-parameter-free-llava-extension-from</guid>
    </item>
    <item>
      <title>How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites</title>
      <link>https://paperswithcode.com/paper/how-far-are-we-to-gpt-4v-closing-the-gap-to</link>
      <description><![CDATA[Compared to both open-source and proprietary models, InternVL 1. 5 shows competitive performance, achieving state-of-the-art results in 8 of 18 benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-far-are-we-to-gpt-4v-closing-the-gap-to</guid>
    </item>
    <item>
      <title>TinyChart: Efficient Chart Understanding with Visual Token Merging and Program-of-Thoughts Learning</title>
      <link>https://paperswithcode.com/paper/tinychart-efficient-chart-understanding-with</link>
      <description><![CDATA[Charts are important for presenting and explaining complex data relationships.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tinychart-efficient-chart-understanding-with</guid>
    </item>
    <item>
      <title>OmniSearchSage: Multi-Task Multi-Entity Embeddings for Pinterest Search</title>
      <link>https://paperswithcode.com/paper/omnisearchsage-multi-task-multi-entity</link>
      <description><![CDATA[In this paper, we present OmniSearchSage, a versatile and scalable system for understanding search queries, pins, and products for Pinterest search.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnisearchsage-multi-task-multi-entity</guid>
    </item>
    <item>
      <title>Interpreting Answers to Yes-No Questions in Dialogues from Multiple Domains</title>
      <link>https://paperswithcode.com/paper/interpreting-answers-to-yes-no-questions-in-1</link>
      <description><![CDATA[People often answer yes-no questions without explicitly saying yes, no, or similar polar keywords.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpreting-answers-to-yes-no-questions-in-1</guid>
    </item>
    <item>
      <title>Vision-based robot manipulation of transparent liquid containers in a laboratory setting</title>
      <link>https://paperswithcode.com/paper/vision-based-robot-manipulation-of</link>
      <description><![CDATA[Laboratory processes involving small volumes of solutions and active ingredients are often performed manually due to challenges in automation, such as high initial costs, semi-structured environments and protocol variability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-based-robot-manipulation-of</guid>
    </item>
    <item>
      <title>A Multi-objective Optimization Benchmark Test Suite for Real-time Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/a-multi-objective-optimization-benchmark-test</link>
      <description><![CDATA[To bridge the gap, we introduce a tailored streamline to transform the task of HW-NAS for real-time semantic segmentation into standard MOPs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-multi-objective-optimization-benchmark-test</guid>
    </item>
    <item>
      <title>AAPL: Adding Attributes to Prompt Learning for Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/aapl-adding-attributes-to-prompt-learning-for</link>
      <description><![CDATA[Through our experiments, we have identified important issues in CoOp and CoCoOp: the context learned through traditional image augmentation is biased toward seen classes, negatively impacting generalization to unseen classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aapl-adding-attributes-to-prompt-learning-for</guid>
    </item>
    <item>
      <title>SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension</title>
      <link>https://paperswithcode.com/paper/seed-bench-2-plus-benchmarking-multimodal</link>
      <description><![CDATA[We hope that our work can serve as a valuable addition to existing MLLM benchmarks, providing insightful observations and inspiring further research in the area of text-rich visual comprehension with MLLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seed-bench-2-plus-benchmarking-multimodal</guid>
    </item>
    <item>
      <title>List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs</title>
      <link>https://paperswithcode.com/paper/list-items-one-by-one-a-new-data-source-and</link>
      <description><![CDATA[Set-of-Mark (SoM) Prompting unleashes the visual grounding capability of GPT-4V, by enabling the model to associate visual objects with tags inserted on the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/list-items-one-by-one-a-new-data-source-and</guid>
    </item>
    <item>
      <title>Multimodal Information Interaction for Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/multimodal-information-interaction-for</link>
      <description><![CDATA[To address this issue, we introduce an innovative Multimodal Information Cross Transformer (MicFormer), which employs a dual-stream architecture to simultaneously extract features from each modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-information-interaction-for</guid>
    </item>
    <item>
      <title>Latent Modulated Function for Computational Optimal Continuous Image Representation</title>
      <link>https://paperswithcode.com/paper/latent-modulated-function-for-computational</link>
      <description><![CDATA[To tackle this problem, we propose a novel Latent Modulated Function (LMF), which decouples the HR-HD decoding process into shared latent decoding in LR-HD space and independent rendering in HR Low-Dimensional (LD) space, thereby realizing the first computational optimal paradigm of continuous image representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-modulated-function-for-computational</guid>
    </item>
    <item>
      <title>Deep learning-based blind image super-resolution with iterative kernel reconstruction and noise estimation</title>
      <link>https://paperswithcode.com/paper/deep-learning-based-blind-image-super</link>
      <description><![CDATA[Yet, there is a gap in the literature to provide a well-generalized deep learning-based solution that performs well on images with unknown and highly complex degradations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-learning-based-blind-image-super</guid>
    </item>
    <item>
      <title>3D Face Modeling via Weakly-supervised Disentanglement Network joint Identity-consistency Prior</title>
      <link>https://paperswithcode.com/paper/3d-face-modeling-via-weakly-supervised</link>
      <description><![CDATA[Generative 3D face models featuring disentangled controlling factors hold immense potential for diverse applications in computer vision and computer graphics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-face-modeling-via-weakly-supervised</guid>
    </item>
    <item>
      <title>TokenHMR: Advancing Human Mesh Recovery with a Tokenized Pose Representation</title>
      <link>https://paperswithcode.com/paper/tokenhmr-advancing-human-mesh-recovery-with-a</link>
      <description><![CDATA[We address the problem of regressing 3D human pose and shape from a single image, with a focus on 3D accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tokenhmr-advancing-human-mesh-recovery-with-a</guid>
    </item>
    <item>
      <title>PAD: Patch-Agnostic Defense against Adversarial Patch Attacks</title>
      <link>https://paperswithcode.com/paper/pad-patch-agnostic-defense-against</link>
      <description><![CDATA[Adversarial patch attacks present a significant threat to real-world object detectors due to their practical feasibility.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pad-patch-agnostic-defense-against</guid>
    </item>
    <item>
      <title>ConsistentID: Portrait Generation with Multimodal Fine-Grained Identity Preserving</title>
      <link>https://paperswithcode.com/paper/consistentid-portrait-generation-with</link>
      <description><![CDATA[ConsistentID comprises two key components: a multimodal facial prompt generator that combines facial features, corresponding facial descriptions and the overall facial context to enhance precision in facial details, and an ID-preservation network optimized through the facial attention localization strategy, aimed at preserving ID consistency in facial regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/consistentid-portrait-generation-with</guid>
    </item>
    <item>
      <title>DAVE -- A Detect-and-Verify Paradigm for Low-Shot Counting</title>
      <link>https://paperswithcode.com/paper/dave-a-detect-and-verify-paradigm-for-low</link>
      <description><![CDATA[DAVE outperforms the top density-based counters by ~20% in the total count MAE, it outperforms the most recent detection-based counter by ~20% in detection quality and sets a new state-of-the-art in zero-shot as well as text-prompt-based counting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dave-a-detect-and-verify-paradigm-for-low</guid>
    </item>
    <item>
      <title>ReZero: Boosting MCTS-based Algorithms by Just-in-Time and Speedy Reanalyze</title>
      <link>https://paperswithcode.com/paper/rezero-boosting-mcts-based-algorithms-by-just</link>
      <description><![CDATA[MCTS-based algorithms, such as MuZero and its derivatives, have achieved widespread success in various decision-making domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rezero-boosting-mcts-based-algorithms-by-just</guid>
    </item>
    <item>
      <title>EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/emovit-revolutionizing-emotion-insights-with</link>
      <description><![CDATA[Visual Instruction Tuning represents a novel learning paradigm involving the fine-tuning of pre-trained language models using task-specific instructions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emovit-revolutionizing-emotion-insights-with</guid>
    </item>
    <item>
      <title>SFMViT: SlowFast Meet ViT in Chaotic World</title>
      <link>https://paperswithcode.com/paper/sfmvit-slowfast-meet-vit-in-chaotic-world</link>
      <description><![CDATA[The task of spatiotemporal action localization in chaotic scenes is a challenging task toward advanced video understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sfmvit-slowfast-meet-vit-in-chaotic-world</guid>
    </item>
    <item>
      <title>Training-Free Unsupervised Prompt for Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/training-free-unsupervised-prompt-for-vision</link>
      <description><![CDATA[In light of this, we propose Training-Free Unsupervised Prompts (TFUP), which maximally preserves the inherent representation capabilities and enhances them with a residual connection to similarity-based prediction probabilities in a training-free and labeling-free manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-free-unsupervised-prompt-for-vision</guid>
    </item>
    <item>
      <title>Boosting Unsupervised Semantic Segmentation with Principal Mask Proposals</title>
      <link>https://paperswithcode.com/paper/boosting-unsupervised-semantic-segmentation</link>
      <description><![CDATA[Unsupervised semantic segmentation aims to automatically partition images into semantically meaningful regions by identifying global categories within an image corpus without any form of annotation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-unsupervised-semantic-segmentation</guid>
    </item>
    <item>
      <title>WorldValuesBench: A Large-Scale Benchmark Dataset for Multi-Cultural Value Awareness of Language Models</title>
      <link>https://paperswithcode.com/paper/worldvaluesbench-a-large-scale-benchmark</link>
      <description><![CDATA[The awareness of multi-cultural human values is critical to the ability of language models (LMs) to generate safe and personalized responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/worldvaluesbench-a-large-scale-benchmark</guid>
    </item>
    <item>
      <title>Learning Visuotactile Skills with Two Multifingered Hands</title>
      <link>https://paperswithcode.com/paper/learning-visuotactile-skills-with-two</link>
      <description><![CDATA[Two significant challenges exist: the lack of an affordable and accessible teleoperation system suitable for a dual-arm setup with multifingered hands, and the scarcity of multifingered hand hardware equipped with touch sensing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-visuotactile-skills-with-two</guid>
    </item>
    <item>
      <title>ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling</title>
      <link>https://paperswithcode.com/paper/probgate-at-ehrsql-2024-enhancing-sql-query</link>
      <description><![CDATA[Recently, deep learning-based language models have significantly enhanced text-to-SQL tasks, with promising applications in retrieving patient records within the medical domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probgate-at-ehrsql-2024-enhancing-sql-query</guid>
    </item>
    <item>
      <title>Commonsense Prototype for Outdoor Unsupervised 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/commonsense-prototype-for-outdoor</link>
      <description><![CDATA[The prevalent approaches of unsupervised 3D object detection follow cluster-based pseudo-label generation and iterative self-training processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/commonsense-prototype-for-outdoor</guid>
    </item>
    <item>
      <title>SwarmRL: Building the Future of Smart Active Systems</title>
      <link>https://paperswithcode.com/paper/swarmrl-building-the-future-of-smart-active</link>
      <description><![CDATA[This work introduces SwarmRL, a Python package designed to study intelligent active particles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/swarmrl-building-the-future-of-smart-active</guid>
    </item>
    <item>
      <title>Lost in Recursion: Mining Rich Event Semantics in Knowledge Graphs</title>
      <link>https://paperswithcode.com/paper/lost-in-recursion-mining-rich-event-semantics</link>
      <description><![CDATA[In this paper, we show how narratives concerning complex events can be constructed and utilized.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lost-in-recursion-mining-rich-event-semantics</guid>
    </item>
    <item>
      <title>History repeats itself: A Baseline for Temporal Knowledge Graph Forecasting</title>
      <link>https://paperswithcode.com/paper/history-repeats-itself-a-baseline-for</link>
      <description><![CDATA[Temporal Knowledge Graph (TKG) Forecasting aims at predicting links in Knowledge Graphs for future timesteps based on a history of Knowledge Graphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/history-repeats-itself-a-baseline-for</guid>
    </item>
    <item>
      <title>Efficient Solution of Point-Line Absolute Pose</title>
      <link>https://paperswithcode.com/paper/efficient-solution-of-point-line-absolute</link>
      <description><![CDATA[We revisit certain problems of pose estimation based on 3D--2D correspondences between features which may be points or lines.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-solution-of-point-line-absolute</guid>
    </item>
    <item>
      <title>Cross-sensor super-resolution of irregularly sampled Sentinel-2 time series</title>
      <link>https://paperswithcode.com/paper/cross-sensor-super-resolution-of-irregularly</link>
      <description><![CDATA[Satellite imaging generally presents a trade-off between the frequency of acquisitions and the spatial resolution of the images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-sensor-super-resolution-of-irregularly</guid>
    </item>
    <item>
      <title>Efficient Higher-order Convolution for Small Kernels in Deep Learning</title>
      <link>https://paperswithcode.com/paper/efficient-higher-order-convolution-for-small</link>
      <description><![CDATA[Conceptional convolution, a linear filter, is the essential component of DCNNs while nonlinear convolution is generally implemented as higher-order Volterra filters, However, for Volterra filtering, significant memory and computational costs pose a primary limitation for its widespread application in DCNN applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-higher-order-convolution-for-small</guid>
    </item>
    <item>
      <title>CoCoG: Controllable Visual Stimuli Generation based on Human Concept Representations</title>
      <link>https://paperswithcode.com/paper/cocog-controllable-visual-stimuli-generation</link>
      <description><![CDATA[Generating visual stimuli with controlling concepts is the key.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cocog-controllable-visual-stimuli-generation</guid>
    </item>
    <item>
      <title>Make Your LLM Fully Utilize the Context</title>
      <link>https://paperswithcode.com/paper/make-your-llm-fully-utilize-the-context</link>
      <description><![CDATA[While many contemporary large language models (LLMs) can process lengthy input, they still struggle to fully utilize information within the long context, known as the lost-in-the-middle challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/make-your-llm-fully-utilize-the-context</guid>
    </item>
    <item>
      <title>Multi-Scale Representations by Varying Window Attention for Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/multi-scale-representations-by-varying-window</link>
      <description><![CDATA[VWA leverages the local window attention (LWA) and disentangles LWA into the query window and context window, allowing the context's scale to vary for the query to learn representations at multiple scales.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-representations-by-varying-window</guid>
    </item>
    <item>
      <title>PILA: A Historical-Linguistic Dataset of Proto-Italic and Latin</title>
      <link>https://paperswithcode.com/paper/pila-a-historical-linguistic-dataset-of-proto</link>
      <description><![CDATA[To assist historical linguists in the study of Italic sound change, we introduce the Proto-Italic to Latin (PILA) dataset, which consists of roughly 3, 000 pairs of forms from Proto-Italic and Latin.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pila-a-historical-linguistic-dataset-of-proto</guid>
    </item>
    <item>
      <title>Self-Balanced R-CNN for Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/self-balanced-r-cnn-for-instance-segmentation</link>
      <description><![CDATA[Current state-of-the-art two-stage models on instance segmentation task suffer from several types of imbalances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-balanced-r-cnn-for-instance-segmentation</guid>
    </item>
    <item>
      <title>Continual Learning of Large Language Models: A Comprehensive Survey</title>
      <link>https://paperswithcode.com/paper/continual-learning-of-large-language-models-a</link>
      <description><![CDATA[In this survey, we provide a comprehensive overview of the current research progress on LLMs within the context of CL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/continual-learning-of-large-language-models-a</guid>
    </item>
    <item>
      <title>Asking and Answering Questions to Extract Event-Argument Structures</title>
      <link>https://paperswithcode.com/paper/asking-and-answering-questions-to-extract</link>
      <description><![CDATA[Transformer-based questions are generated using large language models trained to formulate questions based on a passage and the expected answer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asking-and-answering-questions-to-extract</guid>
    </item>
    <item>
      <title>LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications</title>
      <link>https://paperswithcode.com/paper/llm-based-section-identifiers-excel-on-open</link>
      <description><![CDATA[Electronic health records (EHR) even though a boon for healthcare practitioners, are growing convoluted and longer every day.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-based-section-identifiers-excel-on-open</guid>
    </item>
    <item>
      <title>Reinforcement Learning with Generative Models for Compact Support Sets</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-with-generative-models</link>
      <description><![CDATA[In this work, we propose a framework utilizing reinforcement learning as a control for foundation models, allowing for the granular generation of small, focused synthetic support sets to augment the performance of neural network models on real data classification tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-with-generative-models</guid>
    </item>
    <item>
      <title>Multi-scale HSV Color Feature Embedding for High-fidelity NIR-to-RGB Spectrum Translation</title>
      <link>https://paperswithcode.com/paper/multi-scale-hsv-color-feature-embedding-for</link>
      <description><![CDATA[The NIR-to-RGB spectral domain translation is a formidable task due to the inherent spectral mapping ambiguities within NIR inputs and RGB outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-hsv-color-feature-embedding-for</guid>
    </item>
    <item>
      <title>Vision Transformer-based Adversarial Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/vision-transformer-based-adversarial-domain</link>
      <description><![CDATA[Unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-transformer-based-adversarial-domain</guid>
    </item>
    <item>
      <title>Power Failure Cascade Prediction using Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/power-failure-cascade-prediction-using-graph</link>
      <description><![CDATA[We consider the problem of predicting power failure cascades due to branch failures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/power-failure-cascade-prediction-using-graph</guid>
    </item>
    <item>
      <title>FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search</title>
      <link>https://paperswithcode.com/paper/fr-nas-forward-and-reverse-graph-predictor</link>
      <description><![CDATA[Additionally, we incorporate a customized training loss within the GNN predictor to ensure efficient utilization of both types of representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fr-nas-forward-and-reverse-graph-predictor</guid>
    </item>
    <item>
      <title>Exploring LLM Prompting Strategies for Joint Essay Scoring and Feedback Generation</title>
      <link>https://paperswithcode.com/paper/exploring-llm-prompting-strategies-for-joint</link>
      <description><![CDATA[We evaluate both the AES performance that LLMs can achieve with prompting only and the helpfulness of the generated essay feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-llm-prompting-strategies-for-joint</guid>
    </item>
    <item>
      <title>ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction</title>
      <link>https://paperswithcode.com/paper/implicitave-an-open-source-dataset-and</link>
      <description><![CDATA[To address these limitations, we present ImplicitAVE, the first, publicly available multimodal dataset for implicit attribute value extraction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implicitave-an-open-source-dataset-and</guid>
    </item>
    <item>
      <title>Where to Mask: Structure-Guided Masking for Graph Masked Autoencoders</title>
      <link>https://paperswithcode.com/paper/where-to-mask-structure-guided-masking-for</link>
      <description><![CDATA[To this end, we introduce a novel structure-guided masking strategy (i. e., StructMAE), designed to refine the existing GMAE models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/where-to-mask-structure-guided-masking-for</guid>
    </item>
    <item>
      <title>Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges</title>
      <link>https://paperswithcode.com/paper/mamba-360-survey-of-state-space-models-as</link>
      <description><![CDATA[This survey also highlights diverse applications of SSMs across domains such as vision, video, audio, speech, language (especially long sequence modeling), medical (including genomics), chemical (like drug design), recommendation systems, and time series analysis, including tabular data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mamba-360-survey-of-state-space-models-as</guid>
    </item>
  </channel>
</rss>
