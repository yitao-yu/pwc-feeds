<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 18 Aug 2023 21:05:25 +0000</lastBuildDate>
    <item>
      <title>Endogenous Macrodynamics in Algorithmic Recourse</title>
      <link>https://paperswithcode.com/paper/endogenous-macrodynamics-in-algorithmic</link>
      <description><![CDATA[Existing work on Counterfactual Explanations (CE) and Algorithmic Recourse (AR) has largely focused on single individuals in a static environment: given some estimated model, the goal is to find valid counterfactuals for an individual instance that fulfill various desiderata.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/endogenous-macrodynamics-in-algorithmic</guid>
    </item>
    <item>
      <title>Safety Filter Design for Neural Network Systems via Convex Optimization</title>
      <link>https://paperswithcode.com/paper/safety-filter-design-for-neural-network</link>
      <description><![CDATA[With the increase in data availability, it has been widely demonstrated that neural networks (NN) can capture complex system dynamics precisely in a data-driven manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safety-filter-design-for-neural-network</guid>
    </item>
    <item>
      <title>RSpell: Retrieval-augmented Framework for Domain Adaptive Chinese Spelling Check</title>
      <link>https://paperswithcode.com/paper/rspell-retrieval-augmented-framework-for</link>
      <description><![CDATA[In this paper, we propose a retrieval-augmented spelling check framework called RSpell, which searches corresponding domain terms and incorporates them into CSC models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rspell-retrieval-augmented-framework-for</guid>
    </item>
    <item>
      <title>Benchmarking Neural Network Generalization for Grammar Induction</title>
      <link>https://paperswithcode.com/paper/benchmarking-neural-network-generalization</link>
      <description><![CDATA[How well do neural networks generalize?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-neural-network-generalization</guid>
    </item>
    <item>
      <title>MDDial: A Multi-turn Differential Diagnosis Dialogue Dataset with Reliability Evaluation</title>
      <link>https://paperswithcode.com/paper/mddial-a-multi-turn-differential-diagnosis</link>
      <description><![CDATA[We introduce a unified score for the ADD system that takes into account the interplay between symptoms and diagnosis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mddial-a-multi-turn-differential-diagnosis</guid>
    </item>
    <item>
      <title>Characteristics of networks generated by kernel growing neural gas</title>
      <link>https://paperswithcode.com/paper/characteristics-of-networks-generated-by</link>
      <description><![CDATA[This research aims to develop kernel GNG, a kernelized version of the growing neural gas (GNG) algorithm, and to investigate the features of the networks generated by the kernel GNG.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/characteristics-of-networks-generated-by</guid>
    </item>
    <item>
      <title>Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater</title>
      <link>https://paperswithcode.com/paper/autoencoding-a-soft-touch-to-learn-grasping</link>
      <description><![CDATA[Robots play a critical role as the physical agent of human operators in exploring the ocean.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoencoding-a-soft-touch-to-learn-grasping</guid>
    </item>
    <item>
      <title>Independent Distribution Regularization for Private Graph Embedding</title>
      <link>https://paperswithcode.com/paper/independent-distribution-regularization-for</link>
      <description><![CDATA[Additionally, we introduce a novel regularization to enforce the independence of the encoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/independent-distribution-regularization-for</guid>
    </item>
    <item>
      <title>AdaBrowse: Adaptive Video Browser for Efficient Continuous Sign Language Recognition</title>
      <link>https://paperswithcode.com/paper/adabrowse-adaptive-video-browser-for</link>
      <description><![CDATA[Then these features are fed into a policy network to intelligently select a subsequence to process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adabrowse-adaptive-video-browser-for</guid>
    </item>
    <item>
      <title>Denoising Diffusion Probabilistic Model for Retinal Image Generation and Segmentation</title>
      <link>https://paperswithcode.com/paper/denoising-diffusion-probabilistic-model-for</link>
      <description><![CDATA[We developed a Retinal Trees (ReTree) dataset consisting of retinal images, corresponding vessel trees, and a segmentation network based on DDPM trained with images from the ReTree dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/denoising-diffusion-probabilistic-model-for</guid>
    </item>
    <item>
      <title>Inherent Redundancy in Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/inherent-redundancy-in-spiking-neural</link>
      <description><![CDATA[In this work, we pose and focus on three key questions regarding the inherent redundancy in SNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inherent-redundancy-in-spiking-neural</guid>
    </item>
    <item>
      <title>Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness</title>
      <link>https://paperswithcode.com/paper/expressivity-of-graph-neural-networks-through</link>
      <description><![CDATA[We perform the first adversarial robustness study into Graph Neural Networks (GNNs) that are provably more powerful than traditional Message Passing Neural Networks (MPNNs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/expressivity-of-graph-neural-networks-through</guid>
    </item>
    <item>
      <title>Detoxify Language Model Step-by-Step</title>
      <link>https://paperswithcode.com/paper/detoxify-language-model-step-by-step</link>
      <description><![CDATA[Detoxification for LLMs is challenging since it requires models to avoid generating harmful content while maintaining the generation capability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detoxify-language-model-step-by-step</guid>
    </item>
    <item>
      <title>Membrane Potential Batch Normalization for Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/membrane-potential-batch-normalization-for</link>
      <description><![CDATA[All these BNs are suggested to be used after the convolution layer as usually doing in CNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/membrane-potential-batch-normalization-for</guid>
    </item>
    <item>
      <title>DeDoDe: Detect, Don't Describe -- Describe, Don't Detect for Local Feature Matching</title>
      <link>https://paperswithcode.com/paper/dedode-detect-don-t-describe-describe-don-t</link>
      <description><![CDATA[To train a descriptor, we maximize the mutual nearest neighbour objective over the keypoints with a separate network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dedode-detect-don-t-describe-describe-don-t</guid>
    </item>
    <item>
      <title>Unsupervised Domain Adaptive Detection with Network Stability Analysis</title>
      <link>https://paperswithcode.com/paper/unsupervised-domain-adaptive-detection-with</link>
      <description><![CDATA[In this work, drawing inspiration from the concept of stability from the control theory that a robust system requires to remain consistent both externally and internally regardless of disturbances, we propose a novel framework that achieves unsupervised domain adaptive detection through stability analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-domain-adaptive-detection-with</guid>
    </item>
    <item>
      <title>Likelihood-Based Text-to-Image Evaluation with Patch-Level Perceptual and Semantic Credit Assignment</title>
      <link>https://paperswithcode.com/paper/likelihood-based-text-to-image-evaluation</link>
      <description><![CDATA[In this paper, we propose to evaluate text-to-image generation performance by directly estimating the likelihood of the generated images using a pre-trained likelihood-based text-to-image generative model, i. e., a higher likelihood indicates better perceptual quality and better text-image alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/likelihood-based-text-to-image-evaluation</guid>
    </item>
    <item>
      <title>Self-Reference Deep Adaptive Curve Estimation for Low-Light Image Enhancement</title>
      <link>https://paperswithcode.com/paper/self-reference-deep-adaptive-curve-estimation</link>
      <description><![CDATA[In this paper, we propose a 2-stage low-light image enhancement method called Self-Reference Deep Adaptive Curve Estimation (Self-DACE).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-reference-deep-adaptive-curve-estimation</guid>
    </item>
    <item>
      <title>MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions</title>
      <link>https://paperswithcode.com/paper/mevis-a-large-scale-benchmark-for-video</link>
      <description><![CDATA[To investigate the feasibility of using motion expressions to ground and segment objects in videos, we propose a large-scale dataset called MeViS, which contains numerous motion expressions to indicate target objects in complex environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mevis-a-large-scale-benchmark-for-video</guid>
    </item>
    <item>
      <title>KernelWarehouse: Towards Parameter-Efficient Dynamic Convolution</title>
      <link>https://paperswithcode.com/paper/kernelwarehouse-towards-parameter-efficient</link>
      <description><![CDATA[Dynamic convolution learns a linear mixture of $n$ static kernels weighted with their sample-dependent attentions, demonstrating superior performance compared to normal convolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kernelwarehouse-towards-parameter-efficient</guid>
    </item>
    <item>
      <title>Diagnosing Human-object Interaction Detectors</title>
      <link>https://paperswithcode.com/paper/diagnosing-human-object-interaction-detectors</link>
      <description><![CDATA[Although we have witnessed significant progress in human-object interaction (HOI) detection with increasingly high mAP (mean Average Precision), a single mAP score is too concise to obtain an informative summary of a model's performance and to understand why one approach is better than another.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diagnosing-human-object-interaction-detectors</guid>
    </item>
    <item>
      <title>Ref-DVGO: Reflection-Aware Direct Voxel Grid Optimization for an Improved Quality-Efficiency Trade-Off in Reflective Scene Reconstructio</title>
      <link>https://paperswithcode.com/paper/ref-dvgo-reflection-aware-direct-voxel-grid</link>
      <description><![CDATA[To this end, we investigate an implicit-explicit approach based on conventional volume rendering to enhance the reconstruction quality and accelerate the training and rendering processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ref-dvgo-reflection-aware-direct-voxel-grid</guid>
    </item>
    <item>
      <title>Pro-Cap: Leveraging a Frozen Vision-Language Model for Hateful Meme Detection</title>
      <link>https://paperswithcode.com/paper/pro-cap-leveraging-a-frozen-vision-language</link>
      <description><![CDATA[Specifically, we prompt a frozen PVLM by asking hateful content-related questions and use the answers as image captions (which we call Pro-Cap), so that the captions contain information critical for hateful content detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pro-cap-leveraging-a-frozen-vision-language</guid>
    </item>
    <item>
      <title>GPA-3D: Geometry-aware Prototype Alignment for Unsupervised Domain Adaptive 3D Object Detection from Point Clouds</title>
      <link>https://paperswithcode.com/paper/gpa-3d-geometry-aware-prototype-alignment-for</link>
      <description><![CDATA[LiDAR-based 3D detection has made great progress in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpa-3d-geometry-aware-prototype-alignment-for</guid>
    </item>
    <item>
      <title>Uncovering User Interest from Biased and Noised Watch Time in Video Recommendation</title>
      <link>https://paperswithcode.com/paper/uncovering-user-interest-from-biased-and</link>
      <description><![CDATA[In the video recommendation, watch time is commonly adopted as an indicator of user interest.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncovering-user-interest-from-biased-and</guid>
    </item>
    <item>
      <title>PDPK: A Framework to Synthesise Process Data and Corresponding Procedural Knowledge for Manufacturing</title>
      <link>https://paperswithcode.com/paper/pdpk-a-framework-to-synthesise-process-data</link>
      <description><![CDATA[To the best of our knowledge, no real-world datasets containing process data and corresponding procedural knowledge are publicly available, possibly due to corporate apprehensions regarding the loss of knowledge advances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pdpk-a-framework-to-synthesise-process-data</guid>
    </item>
    <item>
      <title>ALIP: Adaptive Language-Image Pre-training with Synthetic Caption</title>
      <link>https://paperswithcode.com/paper/alip-adaptive-language-image-pre-training</link>
      <description><![CDATA[However, the presence of intrinsic noise and unmatched image-text pairs in web data can potentially affect the performance of representation learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alip-adaptive-language-image-pre-training</guid>
    </item>
    <item>
      <title>Integrating Visual and Semantic Similarity Using Hierarchies for Image Retrieval</title>
      <link>https://paperswithcode.com/paper/integrating-visual-and-semantic-similarity</link>
      <description><![CDATA[Most of the research in content-based image retrieval (CBIR) focus on developing robust feature representations that can effectively retrieve instances from a database of images that are visually similar to a query.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/integrating-visual-and-semantic-similarity</guid>
    </item>
    <item>
      <title>An Expert's Guide to Training Physics-informed Neural Networks</title>
      <link>https://paperswithcode.com/paper/an-expert-s-guide-to-training-physics</link>
      <description><![CDATA[Physics-informed neural networks (PINNs) have been popularized as a deep learning framework that can seamlessly synthesize observational data and partial differential equation (PDE) constraints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-expert-s-guide-to-training-physics</guid>
    </item>
    <item>
      <title>Explainable Multi-View Deep Networks Methodology for Experimental Physics</title>
      <link>https://paperswithcode.com/paper/explainable-multi-view-deep-networks</link>
      <description><![CDATA[In this paper, we suggest different multi-view architectures for the vision domain, each suited to another problem, and we also present a methodology for explaining these models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explainable-multi-view-deep-networks</guid>
    </item>
    <item>
      <title>S-Mixup: Structural Mixup for Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/s-mixup-structural-mixup-for-graph-neural</link>
      <description><![CDATA[Existing studies for applying the mixup technique on graphs mainly focus on graph classification tasks, while the research in node classification is still under-explored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s-mixup-structural-mixup-for-graph-neural</guid>
    </item>
    <item>
      <title>Probabilistic Phase Labeling and Lattice Refinement for Autonomous Material Research</title>
      <link>https://paperswithcode.com/paper/probabilistic-phase-labeling-and-lattice</link>
      <description><![CDATA[X-ray diffraction (XRD) is an essential technique to determine a material's crystal structure in high-throughput experimentation, and has recently been incorporated in artificially intelligent agents in autonomous scientific discovery processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/probabilistic-phase-labeling-and-lattice</guid>
    </item>
    <item>
      <title>Boosting Multi-modal Model Performance with Adaptive Gradient Modulation</title>
      <link>https://paperswithcode.com/paper/boosting-multi-modal-model-performance-with</link>
      <description><![CDATA[In addition, we find that the jointly trained model typically has a preferred modality on which the competition is weaker than other modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-multi-modal-model-performance-with</guid>
    </item>
    <item>
      <title>Do We Fully Understand Students' Knowledge States? Identifying and Mitigating Answer Bias in Knowledge Tracing</title>
      <link>https://paperswithcode.com/paper/do-we-fully-understand-students-knowledge</link>
      <description><![CDATA[Existing models tend to memorize the answer bias as a shortcut for achieving high prediction performance in KT, thereby failing to fully understand students' knowledge states.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-we-fully-understand-students-knowledge</guid>
    </item>
    <item>
      <title>Better Zero-Shot Reasoning with Role-Play Prompting</title>
      <link>https://paperswithcode.com/paper/better-zero-shot-reasoning-with-role-play</link>
      <description><![CDATA[This highlights its potential to augment the reasoning capabilities of LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/better-zero-shot-reasoning-with-role-play</guid>
    </item>
    <item>
      <title>EduSAT: A Pedagogical Tool for Theory and Applications of Boolean Satisfiability</title>
      <link>https://paperswithcode.com/paper/edusat-a-pedagogical-tool-for-theory-and</link>
      <description><![CDATA[Boolean Satisfiability (SAT) and Satisfiability Modulo Theories (SMT) are widely used in automated verification, but there is a lack of interactive tools designed for educational purposes in this field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edusat-a-pedagogical-tool-for-theory-and</guid>
    </item>
    <item>
      <title>Towards Temporal Edge Regression: A Case Study on Agriculture Trade Between Nations</title>
      <link>https://paperswithcode.com/paper/towards-temporal-edge-regression-a-case-study</link>
      <description><![CDATA[In this paper, we explore the application of GNNs to edge regression tasks in both static and dynamic settings, focusing on predicting food and agriculture trade values between nations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-temporal-edge-regression-a-case-study</guid>
    </item>
    <item>
      <title>CoDeF: Content Deformation Fields for Temporally Consistent Video Processing</title>
      <link>https://paperswithcode.com/paper/codef-content-deformation-fields-for</link>
      <description><![CDATA[We present the content deformation field CoDeF as a new type of video representation, which consists of a canonical content field aggregating the static contents in the entire video and a temporal deformation field recording the transformations from the canonical image (i. e., rendered from the canonical content field) to each individual frame along the time axis. Given a target video, these two fields are jointly optimized to reconstruct it through a carefully tailored rendering pipeline. We advisedly introduce some regularizations into the optimization process, urging the canonical content field to inherit semantics (e. g., the object shape) from the video. With such a design, CoDeF naturally supports lifting image algorithms for video processing, in the sense that one can apply an image algorithm to the canonical image and effortlessly propagate the outcomes to the entire video with the aid of the temporal deformation field. We experimentally show that CoDeF is able to lift image-to-image translation to video-to-video translation and lift keypoint detection to keypoint tracking without any training. More importantly, thanks to our lifting strategy that deploys the algorithms on only one image, we achieve superior cross-frame consistency in processed videos compared to existing video-to-video translation approaches, and even manage to track non-rigid objects like water and smog. Project page can be found at https://qiuyu96. github. io/CoDeF/.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codef-content-deformation-fields-for</guid>
    </item>
    <item>
      <title>Dyadic Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/dyadic-reinforcement-learning</link>
      <description><![CDATA[This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dyadic-reinforcement-learning</guid>
    </item>
    <item>
      <title>APACE: AlphaFold2 and advanced computing as a service for accelerated discovery in biophysics</title>
      <link>https://paperswithcode.com/paper/apace-alphafold2-and-advanced-computing-as-a</link>
      <description><![CDATA[The prediction of protein 3D structure from amino acid sequence is a computational grand challenge in biophysics, and plays a key role in robust protein structure prediction algorithms, from drug discovery to genome interpretation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/apace-alphafold2-and-advanced-computing-as-a</guid>
    </item>
    <item>
      <title>Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT</title>
      <link>https://paperswithcode.com/paper/synthesizing-political-zero-shot-relation</link>
      <description><![CDATA[Recent supervised models for event coding vastly outperform pattern-matching methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synthesizing-political-zero-shot-relation</guid>
    </item>
    <item>
      <title>SGDiff: A Style Guided Diffusion Model for Fashion Synthesis</title>
      <link>https://paperswithcode.com/paper/sgdiff-a-style-guided-diffusion-model-for</link>
      <description><![CDATA[This paper reports on the development of \textbf{a novel style guided diffusion model (SGDiff)} which overcomes certain weaknesses inherent in existing models for image synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sgdiff-a-style-guided-diffusion-model-for</guid>
    </item>
    <item>
      <title>DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models</title>
      <link>https://paperswithcode.com/paper/diffguard-semantic-mismatch-guided-out-of</link>
      <description><![CDATA[There is a recent work that directly applies it to OOD detection, which employs a conditional Generative Adversarial Network (cGAN) to enlarge semantic mismatch in the image space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffguard-semantic-mismatch-guided-out-of</guid>
    </item>
    <item>
      <title>Rapid model-guided design of organ-scale synthetic vasculature for biomanufacturing</title>
      <link>https://paperswithcode.com/paper/rapid-model-guided-design-of-organ-scale</link>
      <description><![CDATA[We demonstrate rapid generation, simulation, and 3D printing of synthetic vasculature in complex geometries, from small tissue constructs to organ scale networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rapid-model-guided-design-of-organ-scale</guid>
    </item>
    <item>
      <title>Fast Machine Unlearning Without Retraining Through Selective Synaptic Dampening</title>
      <link>https://paperswithcode.com/paper/fast-machine-unlearning-without-retraining</link>
      <description><![CDATA[We present Selective Synaptic Dampening (SSD), a novel two-step, post hoc, retrain-free approach to machine unlearning which is fast, performant, and does not require long-term storage of the training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-machine-unlearning-without-retraining</guid>
    </item>
    <item>
      <title>Benchmarking Scalable Epistemic Uncertainty Quantification in Organ Segmentation</title>
      <link>https://paperswithcode.com/paper/benchmarking-scalable-epistemic-uncertainty</link>
      <description><![CDATA[Deep learning based methods for automatic organ segmentation have shown promise in aiding diagnosis and treatment planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-scalable-epistemic-uncertainty</guid>
    </item>
    <item>
      <title>Helping Hands: An Object-Aware Ego-Centric Video Recognition Model</title>
      <link>https://paperswithcode.com/paper/helping-hands-an-object-aware-ego-centric</link>
      <description><![CDATA[We demonstrate the performance of the object-aware representations learnt by our model, by: (i) evaluating it for strong transfer, i. e. through zero-shot testing, on a number of downstream video-text retrieval and classification benchmarks; and (ii) by using the representations learned as input for long-term video understanding tasks (e. g. Episodic Memory in Ego4D).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/helping-hands-an-object-aware-ego-centric</guid>
    </item>
    <item>
      <title>ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces</title>
      <link>https://paperswithcode.com/paper/objectsdf-improved-object-compositional</link>
      <description><![CDATA[Unlike traditional multi-view stereo approaches, the neural implicit surface-based methods leverage neural networks to represent 3D scenes as signed distance functions (SDFs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/objectsdf-improved-object-compositional</guid>
    </item>
    <item>
      <title>UniTR: A Unified and Efficient Multi-Modal Transformer for Bird's-Eye-View Representation</title>
      <link>https://paperswithcode.com/paper/unitr-a-unified-and-efficient-multi-modal</link>
      <description><![CDATA[Jointly processing information from multiple sensors is crucial to achieving accurate and robust perception for reliable autonomous driving systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unitr-a-unified-and-efficient-multi-modal</guid>
    </item>
    <item>
      <title>Memory-and-Anticipation Transformer for Online Action Understanding</title>
      <link>https://paperswithcode.com/paper/memory-and-anticipation-transformer-for</link>
      <description><![CDATA[Based on this idea, we present Memory-and-Anticipation Transformer (MAT), a memory-anticipation-based approach, to address the online action detection and anticipation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memory-and-anticipation-transformer-for</guid>
    </item>
  </channel>
</rss>
