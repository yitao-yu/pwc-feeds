<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 03 Sep 2024 09:15:43 +0000</lastBuildDate>
    <item>
      <title>Sparse Uncertainty-Informed Sampling from Federated Streaming Data</title>
      <link>https://paperswithcode.com/paper/sparse-uncertainty-informed-sampling-from</link>
      <description><![CDATA[We present a numerically robust, computationally efficient approach for non-I. I. D.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparse-uncertainty-informed-sampling-from</guid>
    </item>
    <item>
      <title>Self-supervised Anomaly Detection Pretraining Enhances Long-tail ECG Diagnosis</title>
      <link>https://paperswithcode.com/paper/self-supervised-anomaly-detection-pretraining</link>
      <description><![CDATA[Current computer-aided ECG diagnostic systems struggle with the underdetection of rare but critical cardiac anomalies due to the imbalanced nature of ECG datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-anomaly-detection-pretraining</guid>
    </item>
    <item>
      <title>Efficient Camera Exposure Control for Visual Odometry via Deep Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/efficient-camera-exposure-control-for-visual</link>
      <description><![CDATA[The stability of visual odometry (VO) systems is undermined by degraded image quality, especially in environments with significant illumination changes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-camera-exposure-control-for-visual</guid>
    </item>
    <item>
      <title>MemLong: Memory-Augmented Retrieval for Long Text Modeling</title>
      <link>https://paperswithcode.com/paper/memlong-memory-augmented-retrieval-for-long</link>
      <description><![CDATA[This work introduces MemLong: Memory-Augmented Retrieval for Long Text Generation, a method designed to enhance the capabilities of long-context language modeling by utilizing an external retriever for historical information retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memlong-memory-augmented-retrieval-for-long</guid>
    </item>
    <item>
      <title>Fairness-Aware Estimation of Graphical Models</title>
      <link>https://paperswithcode.com/paper/fairness-aware-estimation-of-graphical-models</link>
      <description><![CDATA[This paper examines the issue of fairness in the estimation of graphical models (GMs), particularly Gaussian, Covariance, and Ising models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fairness-aware-estimation-of-graphical-models</guid>
    </item>
    <item>
      <title>Categorical data clustering: 25 years beyond K-modes</title>
      <link>https://paperswithcode.com/paper/categorical-data-clustering-25-years-beyond-k</link>
      <description><![CDATA[The clustering of categorical data is a common and important task in computer science, offering profound implications across a spectrum of applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/categorical-data-clustering-25-years-beyond-k</guid>
    </item>
    <item>
      <title>Towards Hyper-parameter-free Federated Learning</title>
      <link>https://paperswithcode.com/paper/towards-hyper-parameter-free-federated</link>
      <description><![CDATA[The adaptive synchronization techniques in federated learning (FL) for scaled global model updates show superior performance over the vanilla federated averaging (FedAvg) scheme.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-hyper-parameter-free-federated</guid>
    </item>
    <item>
      <title>MoRe Fine-Tuning with 10x Fewer Parameters</title>
      <link>https://paperswithcode.com/paper/more-fine-tuning-with-10x-fewer-parameters</link>
      <description><![CDATA[Parameter-efficient fine-tuning (PEFT) techniques have unlocked the potential to cheaply and easily specialize large pretrained models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/more-fine-tuning-with-10x-fewer-parameters</guid>
    </item>
    <item>
      <title>Look, Compare, Decide: Alleviating Hallucination in Large Vision-Language Models via Multi-View Multi-Path Reasoning</title>
      <link>https://paperswithcode.com/paper/look-compare-decide-alleviating-hallucination</link>
      <description><![CDATA[By fully grasping the information in the image and carefully considering the certainty of the potential answers when decoding, our MVP can effectively reduce hallucinations in LVLMs. The extensive experiments verify that our proposed MVP significantly mitigates the hallucination problem across four well-known LVLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/look-compare-decide-alleviating-hallucination</guid>
    </item>
    <item>
      <title>VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time Series Forecasters</title>
      <link>https://paperswithcode.com/paper/visionts-visual-masked-autoencoders-are-free</link>
      <description><![CDATA[Surprisingly, without further adaptation in the time-series domain, the proposed VisionTS could achieve superior zero-shot forecasting performance compared to existing TSF foundation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visionts-visual-masked-autoencoders-are-free</guid>
    </item>
    <item>
      <title>How Knowledge Distillation Mitigates the Synthetic Gap in Fair Face Recognition</title>
      <link>https://paperswithcode.com/paper/how-knowledge-distillation-mitigates-the</link>
      <description><![CDATA[Leveraging the capabilities of Knowledge Distillation (KD) strategies, we devise a strategy to fight the recent retraction of face recognition datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-knowledge-distillation-mitigates-the</guid>
    </item>
    <item>
      <title>Abstracted Gaussian Prototypes for One-Shot Concept Learning</title>
      <link>https://paperswithcode.com/paper/abstracted-gaussian-prototypes-for-one-shot</link>
      <description><![CDATA[We introduce a cluster-based generative image segmentation framework to encode higher-level representations of visual concepts based on one-shot learning inspired by the Omniglot Challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/abstracted-gaussian-prototypes-for-one-shot</guid>
    </item>
    <item>
      <title>Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis</title>
      <link>https://paperswithcode.com/paper/identifying-and-clustering-counter</link>
      <description><![CDATA[The accuracy of the observed strength relations in these games is comparable to traditional pairwise win value predictions, while also offering a more manageable complexity for analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/identifying-and-clustering-counter</guid>
    </item>
    <item>
      <title>From Text to Emotion: Unveiling the Emotion Annotation Capabilities of LLMs</title>
      <link>https://paperswithcode.com/paper/from-text-to-emotion-unveiling-the-emotion</link>
      <description><![CDATA[Training emotion recognition models has relied heavily on human annotated data, which present diversity, quality, and cost challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-text-to-emotion-unveiling-the-emotion</guid>
    </item>
    <item>
      <title>Investigating Neuron Ablation in Attention Heads: The Case for Peak Activation Centering</title>
      <link>https://paperswithcode.com/paper/investigating-neuron-ablation-in-attention</link>
      <description><![CDATA[The use of transformer-based models is growing rapidly throughout society.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/investigating-neuron-ablation-in-attention</guid>
    </item>
    <item>
      <title>Flow Matching for Optimal Reaction Coordinates of Biomolecular System</title>
      <link>https://paperswithcode.com/paper/flow-matching-for-optimal-reaction</link>
      <description><![CDATA[We present Flow Matching for Reaction Coordinates (FMRC), a novel deep learning algorithm designed to identify optimal reaction coordinates (RC) in biomolecular reversible dynamics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flow-matching-for-optimal-reaction</guid>
    </item>
    <item>
      <title>HiTSR: A Hierarchical Transformer for Reference-based Super-Resolution</title>
      <link>https://paperswithcode.com/paper/hitsr-a-hierarchical-transformer-for</link>
      <description><![CDATA[In this paper, we propose HiTSR, a hierarchical transformer model for reference-based image super-resolution, which enhances low-resolution input images by learning matching correspondences from high-resolution reference images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hitsr-a-hierarchical-transformer-for</guid>
    </item>
    <item>
      <title>Assessing Generative Language Models in Classification Tasks: Performance and Self-Evaluation Capabilities in the Environmental and Climate Change Domain</title>
      <link>https://paperswithcode.com/paper/assessing-generative-language-models-in</link>
      <description><![CDATA[Our findings reveal that while BERT-based models generally outperform both the LLMs and SLM, the performance of the large generative models is still noteworthy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/assessing-generative-language-models-in</guid>
    </item>
    <item>
      <title>Learning Multi-Target TDOA Features for Sound Event Localization and Detection</title>
      <link>https://paperswithcode.com/paper/learning-multi-target-tdoa-features-for-sound</link>
      <description><![CDATA[Sound event localization and detection (SELD) systems using audio recordings from a microphone array rely on spatial cues for determining the location of sound events.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-multi-target-tdoa-features-for-sound</guid>
    </item>
    <item>
      <title>AdaptVision: Dynamic Input Scaling in MLLMs for Versatile Scene Understanding</title>
      <link>https://paperswithcode.com/paper/adaptvision-dynamic-input-scaling-in-mllms</link>
      <description><![CDATA[We hypothesize that the requisite number of visual tokens for the model is contingent upon both the resolution and content of the input image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptvision-dynamic-input-scaling-in-mllms</guid>
    </item>
    <item>
      <title>Controllable Edge-Type-Specific Interpretation in Multi-Relational Graph Neural Networks for Drug Response Prediction</title>
      <link>https://paperswithcode.com/paper/controllable-edge-type-specific</link>
      <description><![CDATA[Graph Neural Networks have been widely applied in critical decision-making areas that demand interpretable predictions, leading to the flourishing development of interpretability algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controllable-edge-type-specific</guid>
    </item>
    <item>
      <title>Short-term Wind Speed Forecasting for Power Integration in Smart Grids based on Hybrid LSSVM-SVMD Method</title>
      <link>https://paperswithcode.com/paper/short-term-wind-speed-forecasting-for-power</link>
      <description><![CDATA[Finally, the performance of the proposed model was compared against state-of-the-art benchmark models for forecasting wind speed using two separate data sets collected from a local wind farm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/short-term-wind-speed-forecasting-for-power</guid>
    </item>
    <item>
      <title>Generative AI Enables Medical Image Segmentation in Ultra Low-Data Regimes</title>
      <link>https://paperswithcode.com/paper/generative-ai-enables-medical-image</link>
      <description><![CDATA[While deep learning has excelled in automating this task, a major hurdle is the need for numerous annotated segmentation masks, which are resource-intensive to produce due to the required expertise and time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-ai-enables-medical-image</guid>
    </item>
    <item>
      <title>Traffic expertise meets residual RL: Knowledge-informed model-based residual reinforcement learning for CAV trajectory control</title>
      <link>https://paperswithcode.com/paper/traffic-expertise-meets-residual-rl-knowledge</link>
      <description><![CDATA[Model-based reinforcement learning (RL) is anticipated to exhibit higher sample efficiency compared to model-free RL by utilizing a virtual environment model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/traffic-expertise-meets-residual-rl-knowledge</guid>
    </item>
    <item>
      <title>FissionVAE: Federated Non-IID Image Generation with Latent Space and Decoder Decomposition</title>
      <link>https://paperswithcode.com/paper/fissionvae-federated-non-iid-image-generation</link>
      <description><![CDATA[In this paper, we address the challenges of non-IID (independently and identically distributed) data environments featuring multiple groups of images of different types.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fissionvae-federated-non-iid-image-generation</guid>
    </item>
    <item>
      <title>UTrack: Multi-Object Tracking with Uncertain Detections</title>
      <link>https://paperswithcode.com/paper/utrack-multi-object-tracking-with-uncertain</link>
      <description><![CDATA[The tracking-by-detection paradigm is the mainstream in multi-object tracking, associating tracks to the predictions of an object detector.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/utrack-multi-object-tracking-with-uncertain</guid>
    </item>
    <item>
      <title>Transient Fault Tolerant Semantic Segmentation for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/transient-fault-tolerant-semantic</link>
      <description><![CDATA[Deep learning models are crucial for autonomous vehicle perception, but their reliability is challenged by algorithmic limitations and hardware faults.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transient-fault-tolerant-semantic</guid>
    </item>
    <item>
      <title>Geometry of Lightning Self-Attention: Identifiability and Dimension</title>
      <link>https://paperswithcode.com/paper/geometry-of-lightning-self-attention</link>
      <description><![CDATA[We consider function spaces defined by self-attention networks without normalization, and theoretically analyze their geometry.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geometry-of-lightning-self-attention</guid>
    </item>
    <item>
      <title>rerankers: A Lightweight Python Library to Unify Ranking Methods</title>
      <link>https://paperswithcode.com/paper/rerankers-a-lightweight-python-library-to</link>
      <description><![CDATA[This paper presents rerankers, a Python library which provides an easy-to-use interface to the most commonly used re-ranking approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rerankers-a-lightweight-python-library-to</guid>
    </item>
    <item>
      <title>Not All Videos Become Outdated: Short-Video Recommendation by Learning to Deconfound Release Interval Bias</title>
      <link>https://paperswithcode.com/paper/not-all-videos-become-outdated-short-video</link>
      <description><![CDATA[Our analysis, based on a causal graph modeling short-video recommendation, suggests that the release interval serves as a confounder, establishing a backdoor path between users and videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/not-all-videos-become-outdated-short-video</guid>
    </item>
    <item>
      <title>Contrastive Learning with Synthetic Positives</title>
      <link>https://paperswithcode.com/paper/contrastive-learning-with-synthetic-positives</link>
      <description><![CDATA[In this paper, we introduce a novel approach called Contrastive Learning with Synthetic Positives (CLSP) that utilizes synthetic images, generated by an unconditional diffusion model, as the additional positives to help the model learn from diverse positives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-learning-with-synthetic-positives</guid>
    </item>
    <item>
      <title>SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic CheckLists</title>
      <link>https://paperswithcode.com/paper/syntheval-hybrid-behavioral-testing-of-nlp</link>
      <description><![CDATA[In this work, we propose SYNTHEVAL, a hybrid behavioral testing framework that leverages large language models (LLMs) to generate a wide range of test types for a comprehensive evaluation of NLP models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/syntheval-hybrid-behavioral-testing-of-nlp</guid>
    </item>
    <item>
      <title>Stochastic Layer-Wise Shuffle: A Good Practice to Improve Vision Mamba Training</title>
      <link>https://paperswithcode.com/paper/stochastic-layer-wise-shuffle-a-good-practice</link>
      <description><![CDATA[Recent Vision Mamba models not only have much lower complexity for processing higher resolution images and longer videos but also the competitive performance with Vision Transformers (ViTs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stochastic-layer-wise-shuffle-a-good-practice</guid>
    </item>
    <item>
      <title>Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer</title>
      <link>https://paperswithcode.com/paper/training-ultra-long-context-language-model</link>
      <description><![CDATA[Large Language Models (LLMs) with long context capabilities are integral to complex tasks in natural language processing and computational biology, such as text generation and protein sequence analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-ultra-long-context-language-model</guid>
    </item>
    <item>
      <title>Evaluating Reliability in Medical DNNs: A Critical Analysis of Feature and Confidence-Based OOD Detection</title>
      <link>https://paperswithcode.com/paper/evaluating-reliability-in-medical-dnns-a</link>
      <description><![CDATA[Reliable use of deep neural networks (DNNs) for medical image analysis requires methods to identify inputs that differ significantly from the training data, called out-of-distribution (OOD), to prevent erroneous predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-reliability-in-medical-dnns-a</guid>
    </item>
    <item>
      <title>Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model</title>
      <link>https://paperswithcode.com/paper/codec-does-matter-exploring-the-semantic</link>
      <description><![CDATA[By enhancing the semantic ability of the codec, X-Codec significantly reduces WER in speech synthesis tasks and extends these benefits to non-speech applications, including music and sound generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codec-does-matter-exploring-the-semantic</guid>
    </item>
    <item>
      <title>Bridging Domain Knowledge and Process Discovery Using Large Language Models</title>
      <link>https://paperswithcode.com/paper/bridging-domain-knowledge-and-process</link>
      <description><![CDATA[Discovering good process models is essential for different process analysis tasks such as conformance checking and process improvements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridging-domain-knowledge-and-process</guid>
    </item>
    <item>
      <title>Fair Best Arm Identification with Fixed Confidence</title>
      <link>https://paperswithcode.com/paper/fair-best-arm-identification-with-fixed</link>
      <description><![CDATA[For this setting, we establish an instance-specific sample complexity lower bound and analyze the \textit{price of fairness}, quantifying how fairness impacts sample complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fair-best-arm-identification-with-fixed</guid>
    </item>
    <item>
      <title>Bridging Episodes and Semantics: A Novel Framework for Long-Form Video Understanding</title>
      <link>https://paperswithcode.com/paper/bridging-episodes-and-semantics-a-novel</link>
      <description><![CDATA[While existing research often treats long-form videos as extended short videos, we propose a novel approach that more accurately reflects human cognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridging-episodes-and-semantics-a-novel</guid>
    </item>
    <item>
      <title>LAR-IQA: A Lightweight, Accurate, and Robust No-Reference Image Quality Assessment Model</title>
      <link>https://paperswithcode.com/paper/lar-iqa-a-lightweight-accurate-and-robust-no</link>
      <description><![CDATA[Recent advancements in the field of No-Reference Image Quality Assessment (NR-IQA) using deep learning techniques demonstrate high performance across multiple open-source datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lar-iqa-a-lightweight-accurate-and-robust-no</guid>
    </item>
    <item>
      <title>A Tighter Convergence Proof of Reverse Experience Replay</title>
      <link>https://paperswithcode.com/paper/a-tighter-convergence-proof-of-reverse</link>
      <description><![CDATA[In reinforcement learning, Reverse Experience Replay (RER) is a recently proposed algorithm that attains better sample complexity than the classic experience replay method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-tighter-convergence-proof-of-reverse</guid>
    </item>
    <item>
      <title>Generalizing Deepfake Video Detection with Plug-and-Play: Video-Level Blending and Spatiotemporal Adapter Tuning</title>
      <link>https://paperswithcode.com/paper/generalizing-deepfake-video-detection-with</link>
      <description><![CDATA[Second, we carefully design a lightweight Spatiotemporal Adapter (StA) to equip a pretrained image model (both ViTs and CNNs) with the ability to capture both spatial and temporal features jointly and efficiently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalizing-deepfake-video-detection-with</guid>
    </item>
    <item>
      <title>Spiking Diffusion Models</title>
      <link>https://paperswithcode.com/paper/spiking-diffusion-models</link>
      <description><![CDATA[Recent years have witnessed Spiking Neural Networks (SNNs) gaining attention for their ultra-low energy consumption and high biological plausibility compared with traditional Artificial Neural Networks (ANNs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spiking-diffusion-models</guid>
    </item>
    <item>
      <title>A high-order focus interaction model and oral ulcer dataset for oral ulcer segmentation</title>
      <link>https://paperswithcode.com/paper/a-high-order-focus-interaction-model-and-oral</link>
      <description><![CDATA[Therefore to address this challenge, in this paper a multi-tasking oral ulcer dataset (Autooral) containing two major tasks of lesion segmentation and classification is proposed and made publicly available.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-high-order-focus-interaction-model-and-oral</guid>
    </item>
    <item>
      <title>Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks</title>
      <link>https://paperswithcode.com/paper/dissecting-out-of-distribution-detection-and</link>
      <description><![CDATA[Detecting test-time distribution shift has emerged as a key capability for safely deployed machine learning models, with the question being tackled under various guises in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dissecting-out-of-distribution-detection-and</guid>
    </item>
    <item>
      <title>Eigen-Cluster VIS: Improving Weakly-supervised Video Instance Segmentation by Leveraging Spatio-temporal Consistency</title>
      <link>https://paperswithcode.com/paper/eigen-cluster-vis-improving-weakly-supervised</link>
      <description><![CDATA[This method is based on two key innovations: a Temporal Eigenvalue Loss (TEL) and a clip-level Quality Cluster Coefficient (QCC).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eigen-cluster-vis-improving-weakly-supervised</guid>
    </item>
    <item>
      <title>Longitudinal Modularity, a Modularity for Link Streams</title>
      <link>https://paperswithcode.com/paper/longitudinal-modularity-a-modularity-for-link</link>
      <description><![CDATA[Temporal networks are commonly used to model real-life phenomena.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longitudinal-modularity-a-modularity-for-link</guid>
    </item>
    <item>
      <title>LLaVA-Chef: A Multi-modal Generative Model for Food Recipes</title>
      <link>https://paperswithcode.com/paper/llava-chef-a-multi-modal-generative-model-for</link>
      <description><![CDATA[This work evaluates existing LLMs for recipe generation and proposes LLaVA-Chef, a novel model trained on a curated dataset of diverse recipe prompts in a multi-stage approach.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llava-chef-a-multi-modal-generative-model-for</guid>
    </item>
    <item>
      <title>CogVLM2: Visual Language Models for Image and Video Understanding</title>
      <link>https://paperswithcode.com/paper/cogvlm2-visual-language-models-for-image-and</link>
      <description><![CDATA[Beginning with VisualGLM and CogVLM, we are continuously exploring VLMs in pursuit of enhanced vision-language fusion, efficient higher-resolution architecture, and broader modalities and applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cogvlm2-visual-language-models-for-image-and</guid>
    </item>
    <item>
      <title>Training-free Video Temporal Grounding using Large-scale Pre-trained Models</title>
      <link>https://paperswithcode.com/paper/training-free-video-temporal-grounding-using</link>
      <description><![CDATA[In this paper, we propose a Training-Free Video Temporal Grounding (TFVTG) approach that leverages the ability of pre-trained large models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-free-video-temporal-grounding-using</guid>
    </item>
  </channel>
</rss>
