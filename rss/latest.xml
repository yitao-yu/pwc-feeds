<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 10 Jul 2024 21:07:34 +0000</lastBuildDate>
    <item>
      <title>Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence</title>
      <link>https://paperswithcode.com/paper/internet-of-agents-weaving-a-web-of</link>
      <description><![CDATA[The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internet-of-agents-weaving-a-web-of</guid>
    </item>
    <item>
      <title>AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/anytasktune-advanced-domain-specific</link>
      <description><![CDATA[Our findings demonstrate that models fine-tuned using the \textbf{Task-Fine-Tune} methodology not only achieve superior performance on these specific tasks but also significantly outperform models with higher general capabilities in their respective domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anytasktune-advanced-domain-specific</guid>
    </item>
    <item>
      <title>Tailored Design of Audio-Visual Speech Recognition Models using Branchformers</title>
      <link>https://paperswithcode.com/paper/tailored-design-of-audio-visual-speech</link>
      <description><![CDATA[Our proposed method constitutes, to the best of our knowledge, the first attempt to harness the flexibility and interpretability offered by encoder architectures, such as the Branchformer, in the design of parameter-efficient AVSR systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tailored-design-of-audio-visual-speech</guid>
    </item>
    <item>
      <title>TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis</title>
      <link>https://paperswithcode.com/paper/te-ssl-time-and-event-aware-self-supervised</link>
      <description><![CDATA[Alzheimer's Dementia (AD) represents one of the most pressing challenges in the field of neurodegenerative disorders, with its progression analysis being crucial for understanding disease dynamics and developing targeted interventions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/te-ssl-time-and-event-aware-self-supervised</guid>
    </item>
    <item>
      <title>ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction</title>
      <link>https://paperswithcode.com/paper/conceptexpress-harnessing-diffusion-models</link>
      <description><![CDATA[To achieve this, we present ConceptExpress that tackles UCE by unleashing the inherent capabilities of pretrained diffusion models in two aspects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conceptexpress-harnessing-diffusion-models</guid>
    </item>
    <item>
      <title>Composable Interventions for Language Models</title>
      <link>https://paperswithcode.com/paper/composable-interventions-for-language-models</link>
      <description><![CDATA[Test-time interventions for language models can enhance factual accuracy, mitigate harmful outputs, and improve model efficiency without costly retraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/composable-interventions-for-language-models</guid>
    </item>
    <item>
      <title>CoLA: Conditional Dropout and Language-driven Robust Dual-modal Salient Object Detection</title>
      <link>https://paperswithcode.com/paper/cola-conditional-dropout-and-language-driven</link>
      <description><![CDATA[However, in dual-modal salient object detection (SOD) model, the robustness against noisy inputs and modality missing is crucial but rarely studied.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cola-conditional-dropout-and-language-driven</guid>
    </item>
    <item>
      <title>Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization</title>
      <link>https://paperswithcode.com/paper/exploring-scalability-of-self-training-for</link>
      <description><![CDATA[First, a class-agnostic action localizer is trained on a human-labeled TAL dataset and used to generate pseudo-labels for unlabeled videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-scalability-of-self-training-for</guid>
    </item>
    <item>
      <title>Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective</title>
      <link>https://paperswithcode.com/paper/robust-neural-information-retrieval-an</link>
      <description><![CDATA[Recent advances in neural information retrieval (IR) models have significantly enhanced their effectiveness over various IR tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-neural-information-retrieval-an</guid>
    </item>
    <item>
      <title>HumanRefiner: Benchmarking Abnormal Human Generation and Refining with Coarse-to-fine Pose-Reversible Guidance</title>
      <link>https://paperswithcode.com/paper/humanrefiner-benchmarking-abnormal-human</link>
      <description><![CDATA[To address this issue, we introduce AbHuman, the first large-scale synthesized human benchmark focusing on anatomical anomalies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/humanrefiner-benchmarking-abnormal-human</guid>
    </item>
    <item>
      <title>Virtual Personas for Language Models via an Anthology of Backstories</title>
      <link>https://paperswithcode.com/paper/virtual-personas-for-language-models-via-an</link>
      <description><![CDATA[Large language models (LLMs) are trained from vast repositories of text authored by millions of distinct authors, reflecting an enormous diversity of human traits.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/virtual-personas-for-language-models-via-an</guid>
    </item>
    <item>
      <title>Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model</title>
      <link>https://paperswithcode.com/paper/multimodal-self-instruct-synthetic-abstract</link>
      <description><![CDATA[In light of this, we design a multi-modal self-instruct, utilizing large language models and their code capabilities to synthesize massive abstract images and visual reasoning instructions across daily scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-self-instruct-synthetic-abstract</guid>
    </item>
    <item>
      <title>Cue Point Estimation using Object Detection</title>
      <link>https://paperswithcode.com/paper/cue-point-estimation-using-object-detection</link>
      <description><![CDATA[Cue points indicate possible temporal boundaries in a transition between two pieces of music in DJ mixing and constitute a crucial element in autonomous DJ systems as well as for live mixing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cue-point-estimation-using-object-detection</guid>
    </item>
    <item>
      <title>FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation</title>
      <link>https://paperswithcode.com/paper/fbi-llm-scaling-up-fully-binarized-llms-from</link>
      <description><![CDATA[This work presents a Fully BInarized Large Language Model (FBI-LLM), demonstrating for the first time how to train a large-scale binary language model from scratch (not the partial binary or ternary LLM like BitNet b1. 58) to match the performance of its full-precision counterparts (e. g., FP16 or BF16) in transformer-based LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fbi-llm-scaling-up-fully-binarized-llms-from</guid>
    </item>
    <item>
      <title>Metron: Holistic Performance Evaluation Framework for LLM Inference Systems</title>
      <link>https://paperswithcode.com/paper/metron-holistic-performance-evaluation</link>
      <description><![CDATA[However, these metrics fail to fully capture the nuances of LLM inference, leading to an incomplete assessment of user-facing performance crucial for real-time applications such as chat and translation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metron-holistic-performance-evaluation</guid>
    </item>
    <item>
      <title>TVR-Ranking: A Dataset for Ranked Video Moment Retrieval with Imprecise Queries</title>
      <link>https://paperswithcode.com/paper/tvr-ranking-a-dataset-for-ranked-video-moment</link>
      <description><![CDATA[To facilitate research in RVMR, we develop the TVR-Ranking dataset, based on the raw videos and existing moment annotations provided in the TVR dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tvr-ranking-a-dataset-for-ranked-video-moment</guid>
    </item>
    <item>
      <title>Variational Zero-shot Multispectral Pansharpening</title>
      <link>https://paperswithcode.com/paper/variational-zero-shot-multispectral</link>
      <description><![CDATA[The most challenging issue for this task is that only the to-be-fused LRMS and PAN are available, and the existing deep learning-based methods are unsuitable since they rely on many training pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/variational-zero-shot-multispectral</guid>
    </item>
    <item>
      <title>Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI</title>
      <link>https://paperswithcode.com/paper/aligning-cyber-space-with-physical-world-a</link>
      <description><![CDATA[In this survey, we give a comprehensive exploration of the latest advancements in Embodied AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-cyber-space-with-physical-world-a</guid>
    </item>
    <item>
      <title>Dynamic Correlation Learning and Regularization for Multi-Label Confidence Calibration</title>
      <link>https://paperswithcode.com/paper/dynamic-correlation-learning-and</link>
      <description><![CDATA[To overcome these limitations, we propose the Dynamic Correlation Learning and Regularization (DCLR) algorithm, which leverages multi-grained semantic correlations to better model semantic confusion for adaptive regularization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-correlation-learning-and</guid>
    </item>
    <item>
      <title>Can Learned Optimization Make Reinforcement Learning Less Difficult?</title>
      <link>https://paperswithcode.com/paper/can-learned-optimization-make-reinforcement</link>
      <description><![CDATA[While reinforcement learning (RL) holds great potential for decision making in the real world, it suffers from a number of unique difficulties which often need specific consideration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-learned-optimization-make-reinforcement</guid>
    </item>
    <item>
      <title>TeVAE: A Variational Autoencoder Approach for Discrete Online Anomaly Detection in Variable-state Multivariate Time-series Data</title>
      <link>https://paperswithcode.com/paper/tevae-a-variational-autoencoder-approach-for</link>
      <description><![CDATA[To address this, we propose a temporal variational autoencoder (TeVAE) that can detect anomalies with minimal false positives when trained on unlabelled data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tevae-a-variational-autoencoder-approach-for</guid>
    </item>
    <item>
      <title>Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps</title>
      <link>https://paperswithcode.com/paper/lookback-lens-detecting-and-mitigating</link>
      <description><![CDATA[We find that a linear classifier based on these lookback ratio features is as effective as a richer detector that utilizes the entire hidden states of an LLM or a text-based entailment model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lookback-lens-detecting-and-mitigating</guid>
    </item>
    <item>
      <title>Economic span selection of bridge based on deep reinforcement learning</title>
      <link>https://paperswithcode.com/paper/economic-span-selection-of-bridge-based-on</link>
      <description><![CDATA[Deep Q-network algorithm is used to select economic span of bridge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/economic-span-selection-of-bridge-based-on</guid>
    </item>
    <item>
      <title>Preference-Guided Reinforcement Learning for Efficient Exploration</title>
      <link>https://paperswithcode.com/paper/preference-guided-reinforcement-learning-for</link>
      <description><![CDATA[To tackle this issue, we introduce LOPE: Learning Online with trajectory Preference guidancE, an end-to-end preference-guided RL framework that enhances exploration efficiency in hard-exploration tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/preference-guided-reinforcement-learning-for</guid>
    </item>
    <item>
      <title>MoSt-DSA: Modeling Motion and Structural Interactions for Direct Multi-Frame Interpolation in DSA Images</title>
      <link>https://paperswithcode.com/paper/most-dsa-modeling-motion-and-structural</link>
      <description><![CDATA[Artificial intelligence has become a crucial tool for medical image analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/most-dsa-modeling-motion-and-structural</guid>
    </item>
    <item>
      <title>Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models</title>
      <link>https://paperswithcode.com/paper/hypothetical-minds-scaffolding-theory-of-mind</link>
      <description><![CDATA[Multi-agent reinforcement learning (MARL) methods struggle with the non-stationarity of multi-agent systems and fail to adaptively learn online when tested with novel agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hypothetical-minds-scaffolding-theory-of-mind</guid>
    </item>
    <item>
      <title>STORYSUMM: Evaluating Faithfulness in Story Summarization</title>
      <link>https://paperswithcode.com/paper/storysumm-evaluating-faithfulness-in-story</link>
      <description><![CDATA[Human evaluation has been the gold standard for checking faithfulness in abstractive summarization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/storysumm-evaluating-faithfulness-in-story</guid>
    </item>
    <item>
      <title>Safe-Embed: Unveiling the Safety-Critical Knowledge of Sentence Encoders</title>
      <link>https://paperswithcode.com/paper/safe-embed-unveiling-the-safety-critical</link>
      <description><![CDATA[This paper investigates the potential of sentence encoders to distinguish safe from unsafe prompts, and the ability to classify various unsafe prompts according to a safety taxonomy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/safe-embed-unveiling-the-safety-critical</guid>
    </item>
    <item>
      <title>Graph Neural Networks and Deep Reinforcement Learning Based Resource Allocation for V2X Communications</title>
      <link>https://paperswithcode.com/paper/graph-neural-networks-and-deep-reinforcement</link>
      <description><![CDATA[In the rapidly evolving landscape of Internet of Vehicles (IoV) technology, Cellular Vehicle-to-Everything (C-V2X) communication has attracted much attention due to its superior performance in coverage, latency, and throughput.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-neural-networks-and-deep-reinforcement</guid>
    </item>
    <item>
      <title>Powerful and Flexible: Personalized Text-to-Image Generation via Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/powerful-and-flexible-personalized-text-to</link>
      <description><![CDATA[Personalized text-to-image models allow users to generate varied styles of images (specified with a sentence) for an object (specified with a set of reference images).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/powerful-and-flexible-personalized-text-to</guid>
    </item>
    <item>
      <title>LuSNAR:A Lunar Segmentation, Navigation and Reconstruction Dataset based on Muti-sensor for Autonomous Exploration</title>
      <link>https://paperswithcode.com/paper/lusnar-a-lunar-segmentation-navigation-and</link>
      <description><![CDATA[The experiment results prove that the dataset proposed in this paper can be used for ground verification of tasks such as autonomous environment perception and navigation, and provides a lunar benchmark dataset for testing the accessibility of algorithm metrics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lusnar-a-lunar-segmentation-navigation-and</guid>
    </item>
    <item>
      <title>Listen and Speak Fairly: A Study on Semantic Gender Bias in Speech Integrated Large Language Models</title>
      <link>https://paperswithcode.com/paper/listen-and-speak-fairly-a-study-on-semantic</link>
      <description><![CDATA[Speech Integrated Large Language Models (SILLMs) combine large language models with speech perception to perform diverse tasks, such as emotion recognition to speaker verification, demonstrating universal audio understanding capability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/listen-and-speak-fairly-a-study-on-semantic</guid>
    </item>
    <item>
      <title>Fine-Tuning Linear Layers Only Is a Simple yet Effective Way for Task Arithmetic</title>
      <link>https://paperswithcode.com/paper/fine-tuning-linear-layers-only-is-a-simple</link>
      <description><![CDATA[To further understand how our method improves the disentanglement of task arithmetic, we present a comprehensive study of task arithmetic by differentiating the role of representation model and task-specific model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-linear-layers-only-is-a-simple</guid>
    </item>
    <item>
      <title>General and Task-Oriented Video Segmentation</title>
      <link>https://paperswithcode.com/paper/general-and-task-oriented-video-segmentation</link>
      <description><![CDATA[We present GvSeg, a general video segmentation framework for addressing four different video segmentation tasks (i. e., instance, semantic, panoptic, and exemplar-guided) while maintaining an identical architectural design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/general-and-task-oriented-video-segmentation</guid>
    </item>
    <item>
      <title>VideoEval: Comprehensive Benchmark Suite for Low-Cost Evaluation of Video Foundation Model</title>
      <link>https://paperswithcode.com/paper/videoeval-comprehensive-benchmark-suite-for</link>
      <description><![CDATA[With the growth of high-quality data and advancement in visual pre-training paradigms, Video Foundation Models (VFMs) have made significant progress recently, demonstrating their remarkable performance on traditional video understanding benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videoeval-comprehensive-benchmark-suite-for</guid>
    </item>
    <item>
      <title>BEVWorld: A Multimodal World Model for Autonomous Driving via Unified BEV Latent Space</title>
      <link>https://paperswithcode.com/paper/bevworld-a-multimodal-world-model-for</link>
      <description><![CDATA[The world model consists of two parts: the multi-modal tokenizer and the latent BEV sequence diffusion model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bevworld-a-multimodal-world-model-for</guid>
    </item>
    <item>
      <title>One system for learning and remembering episodes and rules</title>
      <link>https://paperswithcode.com/paper/one-system-for-learning-and-remembering</link>
      <description><![CDATA[Humans can learn individual episodes and generalizable rules and also successfully retain both kinds of acquired knowledge over time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-system-for-learning-and-remembering</guid>
    </item>
    <item>
      <title>From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty</title>
      <link>https://paperswithcode.com/paper/from-loops-to-oops-fallback-behaviors-of</link>
      <description><![CDATA[Our experiments reveal a clear and consistent ordering of fallback behaviors, across all these axes: the more advanced an LLM is (i. e., trained on more tokens, has more parameters, or instruction-tuned), its fallback behavior shifts from sequence repetitions, to degenerate text, and then to hallucinations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-loops-to-oops-fallback-behaviors-of</guid>
    </item>
    <item>
      <title>LDGCN: An Edge-End Lightweight Dual GCN Based on Single-Channel EEG for Driver Drowsiness Monitoring</title>
      <link>https://paperswithcode.com/paper/ldgcn-an-edge-end-lightweight-dual-gcn-based</link>
      <description><![CDATA[However, the existing single-channel EEG adjacency graph construction process lacks interpretability, which hinders the ability of GCNs to effectively extract adjacency graph features, thus affecting the performance of drowsiness monitoring.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ldgcn-an-edge-end-lightweight-dual-gcn-based</guid>
    </item>
    <item>
      <title>4D Contrastive Superflows are Dense 3D Representation Learners</title>
      <link>https://paperswithcode.com/paper/4d-contrastive-superflows-are-dense-3d</link>
      <description><![CDATA[In the realm of autonomous driving, accurate 3D perception is the foundation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/4d-contrastive-superflows-are-dense-3d</guid>
    </item>
    <item>
      <title>3D Vision and Language Pretraining with Large-Scale Synthetic Data</title>
      <link>https://paperswithcode.com/paper/3d-vision-and-language-pretraining-with-large</link>
      <description><![CDATA[3D Vision-Language Pre-training (3D-VLP) aims to provide a pre-train model which can bridge 3D scenes with natural language, which is an important technique for embodied intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-vision-and-language-pretraining-with-large</guid>
    </item>
    <item>
      <title>InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct</title>
      <link>https://paperswithcode.com/paper/inversecoder-unleashing-the-power-of</link>
      <description><![CDATA[Recent advancements in open-source code large language models (LLMs) have demonstrated remarkable coding abilities by fine-tuning on the data generated from powerful closed-source LLMs such as GPT-3. 5 and GPT-4 for instruction tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inversecoder-unleashing-the-power-of</guid>
    </item>
    <item>
      <title>RHRSegNet: Relighting High-Resolution Night-Time Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/rhrsegnet-relighting-high-resolution-night</link>
      <description><![CDATA[Our model then feeds the lightened scene feature maps into a high-resolution network for scene segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rhrsegnet-relighting-high-resolution-night</guid>
    </item>
    <item>
      <title>Stranger Danger! Identifying and Avoiding Unpredictable Pedestrians in RL-based Social Robot Navigation</title>
      <link>https://paperswithcode.com/paper/stranger-danger-identifying-and-avoiding</link>
      <description><![CDATA[Reinforcement learning (RL) methods for social robot navigation show great success navigating robots through large crowds of people, but the performance of these learning-based methods tends to degrade in particularly challenging or unfamiliar situations due to the models' dependency on representative training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stranger-danger-identifying-and-avoiding</guid>
    </item>
    <item>
      <title>Cyber Physical Games</title>
      <link>https://paperswithcode.com/paper/cyber-physical-games</link>
      <description><![CDATA[We describe a formulation of multi-agents operating within a Cyber-Physical System, resulting in collaborative or adversarial games.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cyber-physical-games</guid>
    </item>
    <item>
      <title>Fast and Continual Knowledge Graph Embedding via Incremental LoRA</title>
      <link>https://paperswithcode.com/paper/fast-and-continual-knowledge-graph-embedding</link>
      <description><![CDATA[To address this issue, we propose a fast CKGE framework (\model), incorporating an incremental low-rank adapter (\mec) mechanism to efficiently acquire new knowledge while preserving old knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-and-continual-knowledge-graph-embedding</guid>
    </item>
    <item>
      <title>iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement</title>
      <link>https://paperswithcode.com/paper/illm-tsc-integration-reinforcement-learning</link>
      <description><![CDATA[However, the existing RL-based TSC system often overlooks imperfect observations caused by degraded communication, such as packet loss, delays, and noise, as well as rare real-life events not included in the reward function, such as unconsidered emergency vehicles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/illm-tsc-integration-reinforcement-learning</guid>
    </item>
    <item>
      <title>WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/wsi-vqa-interpreting-whole-slide-images-by</link>
      <description><![CDATA[Abundant experience is required for pathologists to achieve accurate and reliable diagnostic results of whole slide images (WSI).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wsi-vqa-interpreting-whole-slide-images-by</guid>
    </item>
    <item>
      <title>LGRNet: Local-Global Reciprocal Network for Uterine Fibroid Segmentation in Ultrasound Videos</title>
      <link>https://paperswithcode.com/paper/lgrnet-local-global-reciprocal-network-for</link>
      <description><![CDATA[To this end, we collect and annotate the first ultrasound video dataset with 100 videos for uterine fibroid segmentation (UFUV).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lgrnet-local-global-reciprocal-network-for</guid>
    </item>
    <item>
      <title>Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision</title>
      <link>https://paperswithcode.com/paper/video-star-self-training-enables-video</link>
      <description><![CDATA[The performance of Large Vision Language Models (LVLMs) is dependent on the size and quality of their training datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-star-self-training-enables-video</guid>
    </item>
  </channel>
</rss>
