<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 15 Oct 2024 09:16:31 +0000</lastBuildDate>
    <item>
      <title>Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks</title>
      <link>https://paperswithcode.com/paper/improve-meta-learning-for-few-shot-text</link>
      <description><![CDATA[Meta-learning has emerged as a prominent technology for few-shot text classification and has achieved promising performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improve-meta-learning-for-few-shot-text</guid>
    </item>
    <item>
      <title>Fine-grained Abnormality Prompt Learning for Zero-shot Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/fine-grained-abnormality-prompt-learning-for</link>
      <description><![CDATA[To this end, we introduce a novel compound abnormality prompting module in FAPrompt to learn a set of complementary, decomposed abnormality prompts, where each abnormality prompt is formed by a compound of shared normal tokens and a few learnable abnormal tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-grained-abnormality-prompt-learning-for</guid>
    </item>
    <item>
      <title>LVD-2M: A Long-take Video Dataset with Temporally Dense Captions</title>
      <link>https://paperswithcode.com/paper/lvd-2m-a-long-take-video-dataset-with</link>
      <description><![CDATA[The efficacy of video generation models heavily depends on the quality of their training datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lvd-2m-a-long-take-video-dataset-with</guid>
    </item>
    <item>
      <title>EasyRAG: Efficient Retrieval-Augmented Generation Framework for Network Automated Operations</title>
      <link>https://paperswithcode.com/paper/easyrag-efficient-retrieval-augmented</link>
      <description><![CDATA[This paper presents EasyRAG, a simple, lightweight, and efficient retrieval-augmented generation framework for network automated operations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyrag-efficient-retrieval-augmented</guid>
    </item>
    <item>
      <title>Capture Artifacts via Progressive Disentangling and Purifying Blended Identities for Deepfake Detection</title>
      <link>https://paperswithcode.com/paper/capture-artifacts-via-progressive</link>
      <description><![CDATA[To address these issues, a Deepfake detection method based on progressive disentangling and purifying blended identities is innovatively proposed in this paper.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/capture-artifacts-via-progressive</guid>
    </item>
    <item>
      <title>How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective</title>
      <link>https://paperswithcode.com/paper/how-to-leverage-demonstration-data-in</link>
      <description><![CDATA[This paper introduces a novel generalized self-imitation learning ($\textbf{GSIL}$) framework, which effectively and efficiently aligns large language models with offline demonstration data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-to-leverage-demonstration-data-in</guid>
    </item>
    <item>
      <title>Out-of-Bounding-Box Triggers: A Stealthy Approach to Cheat Object Detectors</title>
      <link>https://paperswithcode.com/paper/out-of-bounding-box-triggers-a-stealthy</link>
      <description><![CDATA[In recent years, the study of adversarial robustness in object detection systems, particularly those based on deep neural networks (DNNs), has become a pivotal area of research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/out-of-bounding-box-triggers-a-stealthy</guid>
    </item>
    <item>
      <title>MagicEraser: Erasing Any Objects via Semantics-Aware Control</title>
      <link>https://paperswithcode.com/paper/magiceraser-erasing-any-objects-via-semantics</link>
      <description><![CDATA[However, the object erasure task, which is in increasing demand, aims to erase objects and generate harmonious background.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magiceraser-erasing-any-objects-via-semantics</guid>
    </item>
    <item>
      <title>GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs</title>
      <link>https://paperswithcode.com/paper/graphclip-enhancing-transferability-in-graph</link>
      <description><![CDATA[In this work, we propose the GraphCLIP framework to address these challenges by learning graph foundation models with strong cross-domain zero/few-shot transferability through a self-supervised contrastive graph-summary pretraining method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphclip-enhancing-transferability-in-graph</guid>
    </item>
    <item>
      <title>Queueing Matching Bandits with Preference Feedback</title>
      <link>https://paperswithcode.com/paper/queueing-matching-bandits-with-preference</link>
      <description><![CDATA[In this study, we consider multi-class multi-server asymmetric queueing systems consisting of $N$ queues on one side and $K$ servers on the other side, where jobs randomly arrive in queues at each time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/queueing-matching-bandits-with-preference</guid>
    </item>
    <item>
      <title>MAIR: A Massive Benchmark for Evaluating Instructed Retrieval</title>
      <link>https://paperswithcode.com/paper/mair-a-massive-benchmark-for-evaluating</link>
      <description><![CDATA[Recent information retrieval (IR) models are pre-trained and instruction-tuned on massive datasets and tasks, enabling them to perform well on a wide range of tasks and potentially generalize to unseen tasks with instructions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mair-a-massive-benchmark-for-evaluating</guid>
    </item>
    <item>
      <title>AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality</title>
      <link>https://paperswithcode.com/paper/alphalora-assigning-lora-experts-based-on</link>
      <description><![CDATA[However, inspired by the observed redundancy in traditional MoE structures, previous studies identify similar redundancy among LoRA experts within the MoE architecture, highlighting the necessity for non-uniform allocation of LoRA experts across different layers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alphalora-assigning-lora-experts-based-on</guid>
    </item>
    <item>
      <title>Towards Calibrated Losses for Adversarial Robust Reject Option Classification</title>
      <link>https://paperswithcode.com/paper/towards-calibrated-losses-for-adversarial</link>
      <description><![CDATA[This paper aims to characterize and design surrogates calibrated in "Adversarial Robust Reject Option" setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-calibrated-losses-for-adversarial</guid>
    </item>
    <item>
      <title>$Î±$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs</title>
      <link>https://paperswithcode.com/paper/a-dpo-adaptive-reward-margin-is-what-direct</link>
      <description><![CDATA[Aligning large language models (LLMs) with human values and intentions is crucial for their utility, honesty, and safety.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-dpo-adaptive-reward-margin-is-what-direct</guid>
    </item>
    <item>
      <title>Divide, Reweight, and Conquer: A Logit Arithmetic Approach for In-Context Learning</title>
      <link>https://paperswithcode.com/paper/divide-reweight-and-conquer-a-logit</link>
      <description><![CDATA[In-Context Learning (ICL) emerges as a key feature for Large Language Models (LLMs), allowing them to adapt to new tasks by leveraging task-specific examples without updating model parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/divide-reweight-and-conquer-a-logit</guid>
    </item>
    <item>
      <title>Ensemble of ConvNeXt V2 and MaxViT for Long-Tailed CXR Classification with View-Based Aggregation</title>
      <link>https://paperswithcode.com/paper/ensemble-of-convnext-v2-and-maxvit-for-long</link>
      <description><![CDATA[Through experiments, we demonstrate the advantages of our approach in improving both detection accuracy and the handling of the long-tailed distribution in CXR findings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ensemble-of-convnext-v2-and-maxvit-for-long</guid>
    </item>
    <item>
      <title>Transparent Networks for Multivariate Time Series</title>
      <link>https://paperswithcode.com/paper/transparent-networks-for-multivariate-time</link>
      <description><![CDATA[Transparent models, which are machine learning models that produce inherently interpretable predictions, are receiving significant attention in high-stakes domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transparent-networks-for-multivariate-time</guid>
    </item>
    <item>
      <title>DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads</title>
      <link>https://paperswithcode.com/paper/duoattention-efficient-long-context-llm</link>
      <description><![CDATA[Based on this insight, we introduce DuoAttention, a framework that only applies a full KV cache to retrieval heads while using a light-weight, constant-length KV cache for streaming heads, which reduces both LLM's decoding and pre-filling memory and latency without compromising its long-context abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/duoattention-efficient-long-context-llm</guid>
    </item>
    <item>
      <title>Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs</title>
      <link>https://paperswithcode.com/paper/free-video-llm-prompt-guided-visual</link>
      <description><![CDATA[Conversely, training-free approaches offer a more efficient alternative by adapting pre-trained image-LLMs models for video tasks without additional training, but they face inference efficiency bottlenecks due to the large number of visual tokens generated from video frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/free-video-llm-prompt-guided-visual</guid>
    </item>
    <item>
      <title>Local and Global Decoding in Text Generation</title>
      <link>https://paperswithcode.com/paper/local-and-global-decoding-in-text-generation</link>
      <description><![CDATA[Traditional methods, such as top-$k$ and top-$\pi$, apply local normalisation to the model's output distribution, which can distort it.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/local-and-global-decoding-in-text-generation</guid>
    </item>
    <item>
      <title>Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance</title>
      <link>https://paperswithcode.com/paper/context-parametric-inversion-why-instruction</link>
      <description><![CDATA[However, even state-of-the-art models often struggle to follow the instruction, especially when the input context is not aligned with the model's parametric knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-parametric-inversion-why-instruction</guid>
    </item>
    <item>
      <title>Edge Unlearning is Not "on Edge"! An Adaptive Exact Unlearning System on Resource-Constrained Devices</title>
      <link>https://paperswithcode.com/paper/edge-unlearning-is-not-on-edge-an-adaptive</link>
      <description><![CDATA[Another approach, exact unlearning, tackles this issue by discarding the data and retraining the model from scratch, but at the cost of considerable computational and memory resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edge-unlearning-is-not-on-edge-an-adaptive</guid>
    </item>
    <item>
      <title>Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes</title>
      <link>https://paperswithcode.com/paper/sitcom-crafter-a-plot-driven-human-motion</link>
      <description><![CDATA[Recent advancements in human motion synthesis have focused on specific types of motions, such as human-scene interaction, locomotion or human-human interaction, however, there is a lack of a unified system capable of generating a diverse combination of motion types.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sitcom-crafter-a-plot-driven-human-motion</guid>
    </item>
    <item>
      <title>HART: Efficient Visual Generation with Hybrid Autoregressive Transformer</title>
      <link>https://paperswithcode.com/paper/hart-efficient-visual-generation-with-hybrid</link>
      <description><![CDATA[To address these challenges, we present the hybrid tokenizer, which decomposes the continuous latents from the autoencoder into two components: discrete tokens representing the big picture and continuous tokens representing the residual components that cannot be represented by the discrete tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hart-efficient-visual-generation-with-hybrid</guid>
    </item>
    <item>
      <title>LiveXiv -- A Multi-Modal Live Benchmark Based on Arxiv Papers Content</title>
      <link>https://paperswithcode.com/paper/livexiv-a-multi-modal-live-benchmark-based-on</link>
      <description><![CDATA[Moreover, we introduce an efficient evaluation approach that estimates the performance of all models on the evolving benchmark using evaluations of only a subset of models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/livexiv-a-multi-modal-live-benchmark-based-on</guid>
    </item>
    <item>
      <title>Revisiting and Benchmarking Graph Autoencoders: A Contrastive Learning Perspective</title>
      <link>https://paperswithcode.com/paper/revisiting-and-benchmarking-graph</link>
      <description><![CDATA[Graph autoencoders (GAEs) are self-supervised learning models that can learn meaningful representations of graph-structured data by reconstructing the input graph from a low-dimensional latent space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-and-benchmarking-graph</guid>
    </item>
    <item>
      <title>QueST: Querying Functional and Structural Niches on Spatial Transcriptomics Data via Contrastive Subgraph Embedding</title>
      <link>https://paperswithcode.com/paper/quest-querying-functional-and-structural</link>
      <description><![CDATA[To address this gap, we introduce QueST, a novel niche representation learning model designed for querying spatial niches across multiple samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quest-querying-functional-and-structural</guid>
    </item>
    <item>
      <title>ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection</title>
      <link>https://paperswithcode.com/paper/rosar-an-adversarial-re-training-framework</link>
      <description><![CDATA[This paper introduces ROSAR, a novel framework enhancing the robustness of deep learning object detection models tailored for side-scan sonar (SSS) images, generated by autonomous underwater vehicles using sonar sensors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rosar-an-adversarial-re-training-framework</guid>
    </item>
    <item>
      <title>Self-Assessed Generation: Trustworthy Label Generation for Optical Flow and Stereo Matching in Real-world</title>
      <link>https://paperswithcode.com/paper/self-assessed-generation-trustworthy-label</link>
      <description><![CDATA[A significant challenge facing current optical flow and stereo methods is the difficulty in generalizing them well to the real world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-assessed-generation-trustworthy-label</guid>
    </item>
    <item>
      <title>TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control</title>
      <link>https://paperswithcode.com/paper/textctrl-diffusion-based-scene-text-editing</link>
      <description><![CDATA[Centred on content modification and style preservation, Scene Text Editing (STE) remains a challenging task despite considerable progress in text-to-image synthesis and text-driven image manipulation recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textctrl-diffusion-based-scene-text-editing</guid>
    </item>
    <item>
      <title>A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration</title>
      <link>https://paperswithcode.com/paper/a-consistency-aware-spot-guided-transformer</link>
      <description><![CDATA[Deep learning-based feature matching has shown great superiority for point cloud registration in the absence of pose priors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-consistency-aware-spot-guided-transformer</guid>
    </item>
    <item>
      <title>Denial-of-Service Poisoning Attacks against Large Language Models</title>
      <link>https://paperswithcode.com/paper/denial-of-service-poisoning-attacks-against</link>
      <description><![CDATA[To overcome this limitation, we propose poisoning-based DoS (P-DoS) attacks for LLMs, demonstrating that injecting a single poisoned sample designed for DoS purposes can break the output length limit.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/denial-of-service-poisoning-attacks-against</guid>
    </item>
    <item>
      <title>Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings</title>
      <link>https://paperswithcode.com/paper/adversarially-robust-out-of-distribution</link>
      <description><![CDATA[By incorporating a tailored loss function, we apply Lyapunov stability theory to ensure that both in-distribution (ID) and OOD data converge to stable equilibrium points within the dynamical system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarially-robust-out-of-distribution</guid>
    </item>
    <item>
      <title>SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing</title>
      <link>https://paperswithcode.com/paper/sensorbench-benchmarking-llms-in-coding-based</link>
      <description><![CDATA[Effective processing, interpretation, and management of sensor data have emerged as a critical component of cyber-physical systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sensorbench-benchmarking-llms-in-coding-based</guid>
    </item>
    <item>
      <title>Is Structure Dependence Shaped for Efficient Communication?: A Case Study on Coordination</title>
      <link>https://paperswithcode.com/paper/is-structure-dependence-shaped-for-efficient</link>
      <description><![CDATA[The results demonstrate that the language with the structure-dependent reduction operation is significantly more communicatively efficient than the counterfactual languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-structure-dependence-shaped-for-efficient</guid>
    </item>
    <item>
      <title>SAMPa: Sharpness-aware Minimization Parallelized</title>
      <link>https://paperswithcode.com/paper/sampa-sharpness-aware-minimization</link>
      <description><![CDATA[Sharpness-aware minimization (SAM) has been shown to improve the generalization of neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sampa-sharpness-aware-minimization</guid>
    </item>
    <item>
      <title>Domain-Conditioned Transformer for Fully Test-time Adaptation</title>
      <link>https://paperswithcode.com/paper/domain-conditioned-transformer-for-fully-test</link>
      <description><![CDATA[We observe that, when applying a transformer network model into a new domain, the self-attention profiles of image samples in the target domain deviate significantly from those in the source domain, which results in large performance degradation during domain changes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-conditioned-transformer-for-fully-test</guid>
    </item>
    <item>
      <title>V2M: Visual 2-Dimensional Mamba for Image Representation Learning</title>
      <link>https://paperswithcode.com/paper/v2m-visual-2-dimensional-mamba-for-image</link>
      <description><![CDATA[Mamba has garnered widespread attention due to its flexible design and efficient hardware performance to process 1D sequences based on the state space model (SSM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/v2m-visual-2-dimensional-mamba-for-image</guid>
    </item>
    <item>
      <title>TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE</title>
      <link>https://paperswithcode.com/paper/tabcf-counterfactual-explanations-for-tabular</link>
      <description><![CDATA[In the field of Explainable AI (XAI), counterfactual (CF) explanations are one prominent method to interpret a black-box model by suggesting changes to the input that would alter a prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tabcf-counterfactual-explanations-for-tabular</guid>
    </item>
    <item>
      <title>XAI-based Feature Selection for Improved Network Intrusion Detection Systems</title>
      <link>https://paperswithcode.com/paper/xai-based-feature-selection-for-improved</link>
      <description><![CDATA[Explainability and evaluation of AI models are crucial parts of the security of modern intrusion detection systems (IDS) in the network security field, yet they are lacking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xai-based-feature-selection-for-improved</guid>
    </item>
    <item>
      <title>The Epochal Sawtooth Effect: Unveiling Training Loss Oscillations in Adam and Other Optimizers</title>
      <link>https://paperswithcode.com/paper/the-epochal-sawtooth-effect-unveiling</link>
      <description><![CDATA[In this paper, we identify and analyze a recurring training loss pattern, which we term the \textit{Epochal Sawtooth Effect (ESE)}, commonly observed during training with adaptive gradient-based optimizers, particularly Adam optimizer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-epochal-sawtooth-effect-unveiling</guid>
    </item>
    <item>
      <title>Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective</title>
      <link>https://paperswithcode.com/paper/evaluating-semantic-variation-in-text-to</link>
      <description><![CDATA[We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations, a factor previously overlooked by a focus on textual encoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-semantic-variation-in-text-to</guid>
    </item>
    <item>
      <title>The Implicit Bias of Structured State Space Models Can Be Poisoned With Clean Labels</title>
      <link>https://paperswithcode.com/paper/the-implicit-bias-of-structured-state-space</link>
      <description><![CDATA[Prior work argued that the implicit bias of SSMs leads to generalization in a setting where data is generated by a low dimensional teacher.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-implicit-bias-of-structured-state-space</guid>
    </item>
    <item>
      <title>Locking Down the Finetuned LLMs Safety</title>
      <link>https://paperswithcode.com/paper/locking-down-the-finetuned-llms-safety</link>
      <description><![CDATA[SafetyLock leverages our discovery that fine-tuned models retain similar safety-related activation representations to their base models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/locking-down-the-finetuned-llms-safety</guid>
    </item>
    <item>
      <title>On Information-Theoretic Measures of Predictive Uncertainty</title>
      <link>https://paperswithcode.com/paper/on-information-theoretic-measures-of</link>
      <description><![CDATA[Reliable estimation of predictive uncertainty is crucial for machine learning applications, particularly in high-stakes scenarios where hedging against risks is essential.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-information-theoretic-measures-of</guid>
    </item>
    <item>
      <title>Exploiting Local Features and Range Images for Small Data Real-Time Point Cloud Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/exploiting-local-features-and-range-images</link>
      <description><![CDATA[Semantic segmentation of point clouds is an essential task for understanding the environment in autonomous driving and robotics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploiting-local-features-and-range-images</guid>
    </item>
    <item>
      <title>Disentangling Hate Across Target Identities</title>
      <link>https://paperswithcode.com/paper/disentangling-hate-across-target-identities</link>
      <description><![CDATA[Experiments on popular industrial and academic models demonstrate that HS detectors assign a higher hatefulness score merely based on the mention of specific target identities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disentangling-hate-across-target-identities</guid>
    </item>
    <item>
      <title>Artificial Intelligence-Based Triaging of Cutaneous Melanocytic Lesions</title>
      <link>https://paperswithcode.com/paper/artificial-intelligence-based-triaging-of</link>
      <description><![CDATA[The AI model reached an AUROC of 0. 966 (95% CI, 0. 960-0. 972) and an AUPRC of 0. 857 (95% CI, 0. 836-0. 877) on the in-distribution test set, and an AUROC of 0. 899 (95% CI, 0. 860-0. 934) and an AUPRC of 0. 498 (95% CI, 0. 360-0. 639) on the out-of-distribution test set.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/artificial-intelligence-based-triaging-of</guid>
    </item>
    <item>
      <title>When Attention Sink Emerges in Language Models: An Empirical View</title>
      <link>https://paperswithcode.com/paper/when-attention-sink-emerges-in-language</link>
      <description><![CDATA[In this work, we first demonstrate that attention sinks exist universally in LMs with various inputs, even in small models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-attention-sink-emerges-in-language</guid>
    </item>
    <item>
      <title>Replay-and-Forget-Free Graph Class-Incremental Learning: A Task Profiling and Prompting Approach</title>
      <link>https://paperswithcode.com/paper/replay-and-forget-free-graph-class</link>
      <description><![CDATA[Graph CIL (GCIL) follows the same setting but needs to deal with graph tasks (e. g., node classification in a graph).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/replay-and-forget-free-graph-class</guid>
    </item>
  </channel>
</rss>
