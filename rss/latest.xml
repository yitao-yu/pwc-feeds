<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 05 Dec 2023 21:06:56 +0000</lastBuildDate>
    <item>
      <title>The Self-Loop Paradox: Investigating the Impact of Self-Loops on Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/the-self-loop-paradox-investigating-the</link>
      <description><![CDATA[In this work, we counter this intuition and show that for certain GNN architectures, the information a node gains from itself can be smaller in graphs with self-loops compared to the same graphs without.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-self-loop-paradox-investigating-the</guid>
    </item>
    <item>
      <title>Unsupervised Anomaly Detection using Aggregated Normative Diffusion</title>
      <link>https://paperswithcode.com/paper/unsupervised-anomaly-detection-using</link>
      <description><![CDATA[Early detection of anomalies in medical images such as brain MRI is highly relevant for diagnosis and treatment of many conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-anomaly-detection-using</guid>
    </item>
    <item>
      <title>A Challenging Multimodal Video Summary: Simultaneously Extracting and Generating Keyframe-Caption Pairs from Video</title>
      <link>https://paperswithcode.com/paper/a-challenging-multimodal-video-summary</link>
      <description><![CDATA[This paper proposes a practical multimodal video summarization task setting and a dataset to train and evaluate the task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-challenging-multimodal-video-summary</guid>
    </item>
    <item>
      <title>AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for Preconditioning Matrix</title>
      <link>https://paperswithcode.com/paper/agd-an-auto-switchable-optimizer-using-1</link>
      <description><![CDATA[Additionally, we introduce an auto-switching function that enables the preconditioning matrix to switch dynamically between Stochastic Gradient Descent (SGD) and the adaptive optimizer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agd-an-auto-switchable-optimizer-using-1</guid>
    </item>
    <item>
      <title>Explaining with Contrastive Phrasal Highlighting: A Case Study in Assisting Humans to Detect Translation Differences</title>
      <link>https://paperswithcode.com/paper/explaining-with-contrastive-phrasal</link>
      <description><![CDATA[Explainable NLP techniques primarily explain by answering "Which tokens in the input are responsible for this prediction?''.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explaining-with-contrastive-phrasal</guid>
    </item>
    <item>
      <title>xNeuSM: Explainable Neural Subgraph Matching with Graph Learnable Multi-hop Attention Networks</title>
      <link>https://paperswithcode.com/paper/xneusm-explainable-neural-subgraph-matching</link>
      <description><![CDATA[Subgraph matching is a challenging problem with a wide range of applications in database systems, biochemistry, and cognitive science.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xneusm-explainable-neural-subgraph-matching</guid>
    </item>
    <item>
      <title>UniGS: Unified Representation for Image Generation and Segmentation</title>
      <link>https://paperswithcode.com/paper/unigs-unified-representation-for-image</link>
      <description><![CDATA[On the other hand, the progressive dichotomy module can efficiently decode the synthesized colormap to high-quality entity-level masks in a depth-first binary search without knowing the cluster numbers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unigs-unified-representation-for-image</guid>
    </item>
    <item>
      <title>Steerers: A framework for rotation equivariant keypoint descriptors</title>
      <link>https://paperswithcode.com/paper/steerers-a-framework-for-rotation-equivariant</link>
      <description><![CDATA[Image keypoint descriptions that are discriminative and matchable over large changes in viewpoint are vital for 3D reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/steerers-a-framework-for-rotation-equivariant</guid>
    </item>
    <item>
      <title>DUCK: Distance-based Unlearning via Centroid Kinematics</title>
      <link>https://paperswithcode.com/paper/duck-distance-based-unlearning-via-centroid</link>
      <description><![CDATA[Machine Unlearning is rising as a new field, driven by the pressing necessity of ensuring privacy in modern artificial intelligence models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/duck-distance-based-unlearning-via-centroid</guid>
    </item>
    <item>
      <title>Prompting Disentangled Embeddings for Knowledge Graph Completion with Pre-trained Language Model</title>
      <link>https://paperswithcode.com/paper/prompting-disentangled-embeddings-for</link>
      <description><![CDATA[Accordingly, we propose a new KGC method named PDKGC with two prompts -- a hard task prompt which is to adapt the KGC task to the PLM pre-training task of token prediction, and a disentangled structure prompt which learns disentangled graph representation so as to enable the PLM to combine more relevant structure knowledge with the text information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompting-disentangled-embeddings-for</guid>
    </item>
    <item>
      <title>Adversarial Medical Image with Hierarchical Feature Hiding</title>
      <link>https://paperswithcode.com/paper/adversarial-medical-image-with-hierarchical</link>
      <description><![CDATA[Interestingly, this vulnerability is a double-edged sword, which can be exploited to hide AEs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-medical-image-with-hierarchical</guid>
    </item>
    <item>
      <title>Action Inference by Maximising Evidence: Zero-Shot Imitation from Observation with World Models</title>
      <link>https://paperswithcode.com/paper/action-inference-by-maximising-evidence-zero-1</link>
      <description><![CDATA[Our method is "zero-shot" in the sense that it does not require further training for the world model or online interactions with the environment after given the demonstration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/action-inference-by-maximising-evidence-zero-1</guid>
    </item>
    <item>
      <title>Correlation and Unintended Biases on Univariate and Multivariate Decision Trees</title>
      <link>https://paperswithcode.com/paper/correlation-and-unintended-biases-on</link>
      <description><![CDATA[Decision Trees are accessible, interpretable, and well-performing classification models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/correlation-and-unintended-biases-on</guid>
    </item>
    <item>
      <title>Dynamic Erasing Network Based on Multi-Scale Temporal Features for Weakly Supervised Video Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/dynamic-erasing-network-based-on-multi-scale</link>
      <description><![CDATA[To address these limitations, we propose a Dynamic Erasing Network (DE-Net) for weakly supervised video anomaly detection, which learns multi-scale temporal features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-erasing-network-based-on-multi-scale</guid>
    </item>
    <item>
      <title>SRSNetwork: Siamese Reconstruction-Segmentation Networks based on Dynamic-Parameter Convolution</title>
      <link>https://paperswithcode.com/paper/srsnetwork-siamese-reconstruction</link>
      <description><![CDATA[In this paper, we present a high-performance deep neural network for weak target image segmentation, including medical image segmentation and infrared image segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/srsnetwork-siamese-reconstruction</guid>
    </item>
    <item>
      <title>Hulk: A Universal Knowledge Translator for Human-Centric Tasks</title>
      <link>https://paperswithcode.com/paper/hulk-a-universal-knowledge-translator-for</link>
      <description><![CDATA[Human-centric perception tasks, e. g., human mesh recovery, pedestrian detection, skeleton-based action recognition, and pose estimation, have wide industrial applications, such as metaverse and sports analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hulk-a-universal-knowledge-translator-for</guid>
    </item>
    <item>
      <title>Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication</title>
      <link>https://paperswithcode.com/paper/exchange-of-thought-enhancing-large-language</link>
      <description><![CDATA[Large Language Models (LLMs) have recently made significant strides in complex reasoning tasks through the Chain-of-Thought technique.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exchange-of-thought-enhancing-large-language</guid>
    </item>
    <item>
      <title>Tree of Attacks: Jailbreaking Black-Box LLMs Automatically</title>
      <link>https://paperswithcode.com/paper/tree-of-attacks-jailbreaking-black-box-llms</link>
      <description><![CDATA[In this work, we present Tree of Attacks with Pruning (TAP), an automated method for generating jailbreaks that only requires black-box access to the target LLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tree-of-attacks-jailbreaking-black-box-llms</guid>
    </item>
    <item>
      <title>Energy-based Potential Games for Joint Motion Forecasting and Control</title>
      <link>https://paperswithcode.com/paper/energy-based-potential-games-for-joint-motion</link>
      <description><![CDATA[This work uses game theory as a mathematical framework to address interaction modeling in multi-agent motion forecasting and control.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/energy-based-potential-games-for-joint-motion</guid>
    </item>
    <item>
      <title>Language-only Efficient Training of Zero-shot Composed Image Retrieval</title>
      <link>https://paperswithcode.com/paper/language-only-efficient-training-of-zero-shot</link>
      <description><![CDATA[Our LinCIR (Language-only training for CIR) can be trained only with text datasets by a novel self-supervision named self-masking projection (SMP).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-only-efficient-training-of-zero-shot</guid>
    </item>
    <item>
      <title>StableVITON: Learning Semantic Correspondence with Latent Diffusion Model for Virtual Try-On</title>
      <link>https://paperswithcode.com/paper/stableviton-learning-semantic-correspondence</link>
      <description><![CDATA[Given a clothing image and a person image, an image-based virtual try-on aims to generate a customized image that appears natural and accurately reflects the characteristics of the clothing image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stableviton-learning-semantic-correspondence</guid>
    </item>
    <item>
      <title>Rejuvenating image-GPT as Strong Visual Representation Learners</title>
      <link>https://paperswithcode.com/paper/rejuvenating-image-gpt-as-strong-visual</link>
      <description><![CDATA[This paper enhances image-GPT (iGPT), one of the pioneering works that introduce autoregressive pretraining to predict next pixels for visual representation learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rejuvenating-image-gpt-as-strong-visual</guid>
    </item>
    <item>
      <title>Aligning and Prompting Everything All at Once for Universal Visual Perception</title>
      <link>https://paperswithcode.com/paper/aligning-and-prompting-everything-all-at-once</link>
      <description><![CDATA[However, predominant paradigms, driven by casting instance-level tasks as an object-word alignment, bring heavy cross-modality interaction, which is not effective in prompting object detection and visual grounding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-and-prompting-everything-all-at-once</guid>
    </item>
    <item>
      <title>OCGEC: One-class Graph Embedding Classification for DNN Backdoor Detection</title>
      <link>https://paperswithcode.com/paper/ocgec-one-class-graph-embedding</link>
      <description><![CDATA[We then pre-train a generative self-supervised graph autoencoder (GAE) to better learn the features of benign models in order to detect backdoor models without knowing the attack strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ocgec-one-class-graph-embedding</guid>
    </item>
    <item>
      <title>MobileUtr: Revisiting the relationship between light-weight CNN and Transformer for efficient medical image segmentation</title>
      <link>https://paperswithcode.com/paper/mobileutr-revisiting-the-relationship-between</link>
      <description><![CDATA[This work revisits the relationship between CNNs and Transformers in lightweight universal networks for medical image segmentation, aiming to integrate the advantages of both worlds at the infrastructure design level.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobileutr-revisiting-the-relationship-between</guid>
    </item>
    <item>
      <title>Mitigating Fine-Grained Hallucination by Fine-Tuning Large Vision-Language Models with Caption Rewrites</title>
      <link>https://paperswithcode.com/paper/mitigating-fine-grained-hallucination-by-fine</link>
      <description><![CDATA[The fine-grained object attributes and behaviors non-existent in the image may still be generated but not measured by the current evaluation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mitigating-fine-grained-hallucination-by-fine</guid>
    </item>
    <item>
      <title>Guarding Barlow Twins Against Overfitting with Mixed Samples</title>
      <link>https://paperswithcode.com/paper/guarding-barlow-twins-against-overfitting</link>
      <description><![CDATA[Self-supervised Learning (SSL) aims to learn transferable feature representations for downstream applications without relying on labeled data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/guarding-barlow-twins-against-overfitting</guid>
    </item>
    <item>
      <title>Towards Learning a Generalist Model for Embodied Navigation</title>
      <link>https://paperswithcode.com/paper/towards-learning-a-generalist-model-for</link>
      <description><![CDATA[We conduct extensive experiments to evaluate the performance and generalizability of our model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-learning-a-generalist-model-for</guid>
    </item>
    <item>
      <title>Learning Efficient Unsupervised Satellite Image-based Building Damage Detection</title>
      <link>https://paperswithcode.com/paper/learning-efficient-unsupervised-satellite</link>
      <description><![CDATA[Existing Building Damage Detection (BDD) methods always require labour-intensive pixel-level annotations of buildings and their conditions, hence largely limiting their applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-efficient-unsupervised-satellite</guid>
    </item>
    <item>
      <title>Open-DDVM: A Reproduction and Extension of Diffusion Model for Optical Flow Estimation</title>
      <link>https://paperswithcode.com/paper/open-ddvm-a-reproduction-and-extension-of</link>
      <description><![CDATA[Recently, Google proposes DDVM which for the first time demonstrates that a general diffusion model for image-to-image translation task works impressively well on optical flow estimation task without any specific designs like RAFT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-ddvm-a-reproduction-and-extension-of</guid>
    </item>
    <item>
      <title>Characterizing Large Language Model Geometry Solves Toxicity Detection and Generation</title>
      <link>https://paperswithcode.com/paper/characterizing-large-language-model-geometry</link>
      <description><![CDATA[We obtain in closed form (i) the intrinsic dimension in which the Multi-Head Attention embeddings are constrained to exist and (ii) the partition and per-region affine mappings of the per-layer feedforward networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/characterizing-large-language-model-geometry</guid>
    </item>
    <item>
      <title>Adaptive Confidence Threshold for ByteTrack in Multi-Object Tracking</title>
      <link>https://paperswithcode.com/paper/adaptive-confidence-threshold-for-bytetrack</link>
      <description><![CDATA[ByteTrack, a simple tracking algorithm, enables the simultaneous tracking of multiple objects by strategically incorporating detections with a low confidence threshold.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-confidence-threshold-for-bytetrack</guid>
    </item>
    <item>
      <title>Likelihood-Aware Semantic Alignment for Full-Spectrum Out-of-Distribution Detection</title>
      <link>https://paperswithcode.com/paper/likelihood-aware-semantic-alignment-for-full</link>
      <description><![CDATA[Full-spectrum out-of-distribution (F-OOD) detection aims to accurately recognize in-distribution (ID) samples while encountering semantic and covariate shifts simultaneously.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/likelihood-aware-semantic-alignment-for-full</guid>
    </item>
    <item>
      <title>Mathematical Supplement for the $\texttt{gsplat}$ Library</title>
      <link>https://paperswithcode.com/paper/mathematical-supplement-for-the-texttt-gsplat</link>
      <description><![CDATA[This report provides the mathematical details of the gsplat library, a modular toolbox for efficient differentiable Gaussian splatting, as proposed by Kerbl et al.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mathematical-supplement-for-the-texttt-gsplat</guid>
    </item>
    <item>
      <title>Bootstrapping SparseFormers from Vision Foundation Models</title>
      <link>https://paperswithcode.com/paper/bootstrapping-sparseformers-from-vision</link>
      <description><![CDATA[In this paper, we propose to bootstrap SparseFormers from ViT-based vision foundation models in a simple and efficient way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bootstrapping-sparseformers-from-vision</guid>
    </item>
    <item>
      <title>DiffiT: Diffusion Vision Transformers for Image Generation</title>
      <link>https://paperswithcode.com/paper/diffit-diffusion-vision-transformers-for</link>
      <description><![CDATA[We also introduce latent DiffiT which consists of transformer model with the proposed self-attention layers, for high-resolution image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffit-diffusion-vision-transformers-for</guid>
    </item>
    <item>
      <title>Exploring the Viability of Synthetic Audio Data for Audio-Based Dialogue State Tracking</title>
      <link>https://paperswithcode.com/paper/exploring-the-viability-of-synthetic-audio</link>
      <description><![CDATA[We address this by investigating synthetic audio data for audio-based DST.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-viability-of-synthetic-audio</guid>
    </item>
    <item>
      <title>Magicoder: Source Code Is All You Need</title>
      <link>https://paperswithcode.com/paper/magicoder-source-code-is-all-you-need</link>
      <description><![CDATA[Magicoder models are trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets to generate high-quality instruction data for code.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magicoder-source-code-is-all-you-need</guid>
    </item>
    <item>
      <title>Exploring Multi-Modal Fusion for Image Manipulation Detection and Localization</title>
      <link>https://paperswithcode.com/paper/exploring-multi-modal-fusion-for-image</link>
      <description><![CDATA[Recent image manipulation localization and detection techniques usually leverage forensic artifacts and traces that are produced by a noise-sensitive filter, such as SRM and Bayar convolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-multi-modal-fusion-for-image</guid>
    </item>
    <item>
      <title>How to Configure Good In-Context Sequence for Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/how-to-configure-good-in-context-sequence-for</link>
      <description><![CDATA[Inspired by the success of Large Language Models in dealing with new tasks via In-Context Learning (ICL) in NLP, researchers have also developed Large Vision-Language Models (LVLMs) with ICL capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-to-configure-good-in-context-sequence-for</guid>
    </item>
    <item>
      <title>Good Questions Help Zero-Shot Image Reasoning</title>
      <link>https://paperswithcode.com/paper/good-questions-help-zero-shot-image-reasoning</link>
      <description><![CDATA[QVix enables a wider exploration of visual scenes, improving the LVLMs' reasoning accuracy and depth in tasks such as visual question answering and visual entailment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/good-questions-help-zero-shot-image-reasoning</guid>
    </item>
    <item>
      <title>Rethinking Urban Mobility Prediction: A Super-Multivariate Time Series Forecasting Approach</title>
      <link>https://paperswithcode.com/paper/rethinking-urban-mobility-prediction-a-super</link>
      <description><![CDATA[To address this challenge, we present the Super-Multivariate Urban Mobility Transformer (SUMformer), which utilizes a specially designed attention mechanism to calculate temporal and cross-variable correlations and reduce computational costs stemming from a large number of time series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-urban-mobility-prediction-a-super</guid>
    </item>
    <item>
      <title>Distilled Self-Critique of LLMs with Synthetic Data: a Bayesian Perspective</title>
      <link>https://paperswithcode.com/paper/distilled-self-critique-of-llms-with</link>
      <description><![CDATA[This paper proposes an interpretation of RLAIF as Bayesian inference by introducing distilled Self-Critique (dSC), which refines the outputs of a LLM through a Gibbs sampler that is later distilled into a fine-tuned model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distilled-self-critique-of-llms-with</guid>
    </item>
    <item>
      <title>Object Recognition as Next Token Prediction</title>
      <link>https://paperswithcode.com/paper/object-recognition-as-next-token-prediction</link>
      <description><![CDATA[We present an approach to pose object recognition as next token prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/object-recognition-as-next-token-prediction</guid>
    </item>
    <item>
      <title>Deeper into Self-Supervised Monocular Indoor Depth Estimation</title>
      <link>https://paperswithcode.com/paper/deeper-into-self-supervised-monocular-indoor</link>
      <description><![CDATA[One is the large areas of low-texture regions and the other is the complex ego-motion on indoor training datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deeper-into-self-supervised-monocular-indoor</guid>
    </item>
    <item>
      <title>Unlocking the Potential of Federated Learning: The Symphony of Dataset Distillation via Deep Generative Latents</title>
      <link>https://paperswithcode.com/paper/unlocking-the-potential-of-federated-learning-1</link>
      <description><![CDATA[This process allows local devices to train smaller surrogate models while enabling the training of a larger global model on the server, effectively minimizing resource utilization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlocking-the-potential-of-federated-learning-1</guid>
    </item>
    <item>
      <title>Enhancing and Adapting in the Clinic: Source-free Unsupervised Domain Adaptation for Medical Image Enhancement</title>
      <link>https://paperswithcode.com/paper/enhancing-and-adapting-in-the-clinic-source</link>
      <description><![CDATA[Additionally, a pseudo-label picker is developed to boost the knowledge distillation of enhancement tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-and-adapting-in-the-clinic-source</guid>
    </item>
    <item>
      <title>D$^2$ST-Adapter: Disentangled-and-Deformable Spatio-Temporal Adapter for Few-shot Action Recognition</title>
      <link>https://paperswithcode.com/paper/d-2-st-adapter-disentangled-and-deformable</link>
      <description><![CDATA[Adapting large pre-trained image models to few-shot action recognition has proven to be an effective and efficient strategy for learning robust feature extractors, which is essential for few-shot learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/d-2-st-adapter-disentangled-and-deformable</guid>
    </item>
    <item>
      <title>BenchMARL: Benchmarking Multi-Agent Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/benchmarl-benchmarking-multi-agent</link>
      <description><![CDATA[The field of Multi-Agent Reinforcement Learning (MARL) is currently facing a reproducibility crisis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarl-benchmarking-multi-agent</guid>
    </item>
    <item>
      <title>Brain Decodes Deep Nets</title>
      <link>https://paperswithcode.com/paper/brain-decodes-deep-nets</link>
      <description><![CDATA[This mapping method, FactorTopy, is plug-and-play for any deep-network; with it, one can paint a picture of the network onto the brain (literally!).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/brain-decodes-deep-nets</guid>
    </item>
  </channel>
</rss>
