<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 13 Oct 2023 09:12:17 +0000</lastBuildDate>
    <item>
      <title>UniPose: Detecting Any Keypoints</title>
      <link>https://paperswithcode.com/paper/unipose-detecting-any-keypoints</link>
      <description><![CDATA[This work proposes a unified framework called UniPose to detect keypoints of any articulated (e. g., human and animal), rigid, and soft objects via visual or textual prompts for fine-grained vision understanding and manipulation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unipose-detecting-any-keypoints</guid>
    </item>
    <item>
      <title>DUSA: Decoupled Unsupervised Sim2Real Adaptation for Vehicle-to-Everything Collaborative Perception</title>
      <link>https://paperswithcode.com/paper/dusa-decoupled-unsupervised-sim2real</link>
      <description><![CDATA[To take full advantage of simulated data, we present a new unsupervised sim2real domain adaptation method for V2X collaborative detection named Decoupled Unsupervised Sim2Real Adaptation (DUSA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dusa-decoupled-unsupervised-sim2real</guid>
    </item>
    <item>
      <title>QASiNa: Religious Domain Question Answering using Sirah Nabawiyah</title>
      <link>https://paperswithcode.com/paper/qasina-religious-domain-question-answering</link>
      <description><![CDATA[This concludes Chat GPT is unsuitable for question answering task in religious domain especially for Islamic religion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qasina-religious-domain-question-answering</guid>
    </item>
    <item>
      <title>LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios</title>
      <link>https://paperswithcode.com/paper/lightzero-a-unified-benchmark-for-monte-carlo</link>
      <description><![CDATA[Building agents based on tree-search planning capabilities with learned models has achieved remarkable success in classic decision-making problems, such as Go and Atari.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightzero-a-unified-benchmark-for-monte-carlo</guid>
    </item>
    <item>
      <title>EC-Depth: Exploring the consistency of self-supervised monocular depth estimation under challenging scenes</title>
      <link>https://paperswithcode.com/paper/ec-depth-exploring-the-consistency-of-self</link>
      <description><![CDATA[Self-supervised monocular depth estimation holds significant importance in the fields of autonomous driving and robotics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ec-depth-exploring-the-consistency-of-self</guid>
    </item>
    <item>
      <title>Model-Agnostic Covariate-Assisted Inference on Partially Identified Causal Effects</title>
      <link>https://paperswithcode.com/paper/model-agnostic-covariate-assisted-inference</link>
      <description><![CDATA[Finally, we propose an efficient computational framework, enabling implementation on many practical problems in causal inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/model-agnostic-covariate-assisted-inference</guid>
    </item>
    <item>
      <title>MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/metabox-a-benchmark-platform-for-meta-black</link>
      <description><![CDATA[To fill this gap, we introduce MetaBox, the first benchmark platform expressly tailored for developing and evaluating MetaBBO-RL methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metabox-a-benchmark-platform-for-meta-black</guid>
    </item>
    <item>
      <title>Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning</title>
      <link>https://paperswithcode.com/paper/not-all-demonstration-examples-are-equally</link>
      <description><![CDATA[To assess the quality of weights in the absence of additional validation data, we design a masked self-prediction (MSP) score that exhibits a strong correlation with the final ICL performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/not-all-demonstration-examples-are-equally</guid>
    </item>
    <item>
      <title>Extensions of Heterogeneity in Integration and Prediction (HIP) with R Shiny Application</title>
      <link>https://paperswithcode.com/paper/extensions-of-heterogeneity-in-integration</link>
      <description><![CDATA[Multiple data views measured on the same set of participants is becoming more common and has the potential to deepen our understanding of many complex diseases by analyzing these different views simultaneously.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extensions-of-heterogeneity-in-integration</guid>
    </item>
    <item>
      <title>PonderV2: Pave the Way for 3D Foundataion Model with A Universal Pre-training Paradigm</title>
      <link>https://paperswithcode.com/paper/ponderv2-pave-the-way-for-3d-foundataion</link>
      <description><![CDATA[In this paper, we introduce a comprehensive 3D pre-training framework designed to facilitate the acquisition of efficient 3D representations, thereby establishing a pathway to 3D foundational models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ponderv2-pave-the-way-for-3d-foundataion</guid>
    </item>
    <item>
      <title>XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation</title>
      <link>https://paperswithcode.com/paper/ximagenet-12-an-explainable-ai-benchmark</link>
      <description><![CDATA[The lack of standardized robustness metrics and the widespread reliance on numerous unrelated benchmark datasets for testing have created a gap between academically validated robust models and their often problematic practical adoption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ximagenet-12-an-explainable-ai-benchmark</guid>
    </item>
    <item>
      <title>Linear Latent World Models in Simple Transformers: A Case Study on Othello-GPT</title>
      <link>https://paperswithcode.com/paper/linear-latent-world-models-in-simple</link>
      <description><![CDATA[Foundation models exhibit significant capabilities in decision-making and logical deductions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linear-latent-world-models-in-simple</guid>
    </item>
    <item>
      <title>Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue</title>
      <link>https://paperswithcode.com/paper/well-begun-is-half-done-generator-agnostic</link>
      <description><![CDATA[Accurate knowledge selection is critical in knowledge-grounded dialogue systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/well-begun-is-half-done-generator-agnostic</guid>
    </item>
    <item>
      <title>LLM4Vis: Explainable Visualization Recommendation using ChatGPT</title>
      <link>https://paperswithcode.com/paper/llm4vis-explainable-visualization</link>
      <description><![CDATA[To obtain demonstration examples with high-quality explanations, we propose a new explanation generation bootstrapping to iteratively refine generated explanations by considering the previous generation and template-based hint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm4vis-explainable-visualization</guid>
    </item>
    <item>
      <title>RobustGEC: Robust Grammatical Error Correction Against Subtle Context Perturbation</title>
      <link>https://paperswithcode.com/paper/robustgec-robust-grammatical-error-correction</link>
      <description><![CDATA[In this paper, we introduce RobustGEC, a benchmark designed to evaluate the context robustness of GEC systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robustgec-robust-grammatical-error-correction</guid>
    </item>
    <item>
      <title>An Empirical Study of Instruction-tuning Large Language Models in Chinese</title>
      <link>https://paperswithcode.com/paper/an-empirical-study-of-instruction-tuning</link>
      <description><![CDATA[This paper will release a powerful Chinese LLMs that is comparable to ChatGLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-empirical-study-of-instruction-tuning</guid>
    </item>
    <item>
      <title>PHALM: Building a Knowledge Graph from Scratch by Prompting Humans and a Language Model</title>
      <link>https://paperswithcode.com/paper/phalm-building-a-knowledge-graph-from-scratch</link>
      <description><![CDATA[In this paper, we propose PHALM, a method of building a knowledge graph from scratch, by prompting both crowdworkers and a large language model (LLM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phalm-building-a-knowledge-graph-from-scratch</guid>
    </item>
    <item>
      <title>Retrieve Anything To Augment Large Language Models</title>
      <link>https://paperswithcode.com/paper/retrieve-anything-to-augment-large-language</link>
      <description><![CDATA[On one hand, the general-purpose retrievers are not properly optimized for the retrieval augmentation of LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retrieve-anything-to-augment-large-language</guid>
    </item>
    <item>
      <title>Functional Generalized Canonical Correlation Analysis for studying multiple longitudinal variables</title>
      <link>https://paperswithcode.com/paper/functional-generalized-canonical-correlation</link>
      <description><![CDATA[In this paper, we introduce Functional Generalized Canonical Correlation Analysis (FGCCA), a new framework for exploring associations between multiple random processes observed jointly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/functional-generalized-canonical-correlation</guid>
    </item>
    <item>
      <title>A Unified Remote Sensing Anomaly Detector Across Modalities and Scenes via Deviation Relationship Learning</title>
      <link>https://paperswithcode.com/paper/a-unified-remote-sensing-anomaly-detector</link>
      <description><![CDATA[Firstly, we reformulate the anomaly detection task as an undirected bilayer graph based on the deviation relationship, where the anomaly score is modeled as the conditional probability, given the pattern of the background and normal objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-unified-remote-sensing-anomaly-detector</guid>
    </item>
    <item>
      <title>AE-smnsMLC: Multi-Label Classification with Semantic Matching and Negative Label Sampling for Product Attribute Value Extraction</title>
      <link>https://paperswithcode.com/paper/ae-smnsmlc-multi-label-classification-with</link>
      <description><![CDATA[In this paper, we reformulate this task as a multi-label classification task that can be applied for real-world scenario in which only annotation of attribute values is available to train models (i. e., annotation of positional information of attribute values is not available).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ae-smnsmlc-multi-label-classification-with</guid>
    </item>
    <item>
      <title>Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models</title>
      <link>https://paperswithcode.com/paper/mini-dalle3-interactive-text-to-image-by</link>
      <description><![CDATA[The revolution of artificial intelligence content generation has been rapidly accelerated with the booming text-to-image (T2I) diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mini-dalle3-interactive-text-to-image-by</guid>
    </item>
    <item>
      <title>Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity</title>
      <link>https://paperswithcode.com/paper/survey-on-factuality-in-large-language-models</link>
      <description><![CDATA[This survey addresses the crucial issue of factuality in Large Language Models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/survey-on-factuality-in-large-language-models</guid>
    </item>
    <item>
      <title>Learning a Reward Function for User-Preferred Appliance Scheduling</title>
      <link>https://paperswithcode.com/paper/learning-a-reward-function-for-user-preferred</link>
      <description><![CDATA[Accelerated development of demand response service provision by the residential sector is crucial for reducing carbon-emissions in the power sector.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-a-reward-function-for-user-preferred</guid>
    </item>
    <item>
      <title>GMOCAT: A Graph-Enhanced Multi-Objective Method for Computerized Adaptive Testing</title>
      <link>https://paperswithcode.com/paper/gmocat-a-graph-enhanced-multi-objective</link>
      <description><![CDATA[Besides, the students' response records contain valuable relational information between questions and knowledge concepts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gmocat-a-graph-enhanced-multi-objective</guid>
    </item>
    <item>
      <title>BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations</title>
      <link>https://paperswithcode.com/paper/biot5-enriching-cross-modal-integration-in</link>
      <description><![CDATA[Recent advancements in biological research leverage the integration of molecules, proteins, and natural language to enhance drug discovery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biot5-enriching-cross-modal-integration-in</guid>
    </item>
    <item>
      <title>QACHECK: A Demonstration System for Question-Guided Multi-Hop Fact-Checking</title>
      <link>https://paperswithcode.com/paper/qacheck-a-demonstration-system-for-question</link>
      <description><![CDATA[Fact-checking real-world claims often requires complex, multi-step reasoning due to the absence of direct evidence to support or refute them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qacheck-a-demonstration-system-for-question</guid>
    </item>
    <item>
      <title>Dual Radar: A Multi-modal Dataset with Dual 4D Radar for Autononous Driving</title>
      <link>https://paperswithcode.com/paper/dual-radar-a-multi-modal-dataset-with-dual-4d</link>
      <description><![CDATA[Compared with commonly used 3D radars, latest 4D radars have precise vertical resolution and higher point cloud density, making it a highly promising sensor for autonomous driving in complex environmental perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-radar-a-multi-modal-dataset-with-dual-4d</guid>
    </item>
    <item>
      <title>A Discrepancy Aware Framework for Robust Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/a-discrepancy-aware-framework-for-robust</link>
      <description><![CDATA[To alleviate this issue, we present a Discrepancy Aware Framework (DAF), which demonstrates robust performance consistently with simple and cheap strategies across different anomaly detection benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-discrepancy-aware-framework-for-robust</guid>
    </item>
    <item>
      <title>Uncovering Hidden Connections: Iterative Tracking and Reasoning for Video-grounded Dialog</title>
      <link>https://paperswithcode.com/paper/uncovering-hidden-connections-iterative</link>
      <description><![CDATA[In response to this gap, we present an iterative tracking and reasoning strategy that amalgamates a textual encoder, a visual encoder, and a generator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncovering-hidden-connections-iterative</guid>
    </item>
    <item>
      <title>How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances</title>
      <link>https://paperswithcode.com/paper/how-do-large-language-models-capture-the-ever</link>
      <description><![CDATA[Although large language models (LLMs) are impressive in solving various tasks, they can quickly be outdated after deployment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-do-large-language-models-capture-the-ever</guid>
    </item>
    <item>
      <title>Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation</title>
      <link>https://paperswithcode.com/paper/target-oriented-proactive-dialogue-systems</link>
      <description><![CDATA[Target-oriented dialogue systems, designed to proactively steer conversations toward predefined targets or accomplish specific system-side goals, are an exciting area in conversational AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/target-oriented-proactive-dialogue-systems</guid>
    </item>
    <item>
      <title>Explainable Image Similarity: Integrating Siamese Networks and Grad-CAM</title>
      <link>https://paperswithcode.com/paper/explainable-image-similarity-integrating</link>
      <description><![CDATA[In this paper, we propose the concept of explainable image similarity, where the goal is the development of an approach, which is capable of providing similarity scores along with visual factual and counterfactual explanations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explainable-image-similarity-integrating</guid>
    </item>
    <item>
      <title>Adapting the adapters for code-switching in multilingual ASR</title>
      <link>https://paperswithcode.com/paper/adapting-the-adapters-for-code-switching-in</link>
      <description><![CDATA[Recently, large pre-trained multilingual speech models have shown potential in scaling Automatic Speech Recognition (ASR) to many low-resource languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adapting-the-adapters-for-code-switching-in</guid>
    </item>
    <item>
      <title>PHYDI: Initializing Parameterized Hypercomplex Neural Networks as Identity Functions</title>
      <link>https://paperswithcode.com/paper/phydi-initializing-parameterized-hypercomplex</link>
      <description><![CDATA[Neural models based on hypercomplex algebra systems are growing and prolificating for a plethora of applications, ranging from computer vision to natural language processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phydi-initializing-parameterized-hypercomplex</guid>
    </item>
    <item>
      <title>Guided Attention for Interpretable Motion Captioning</title>
      <link>https://paperswithcode.com/paper/guided-attention-for-interpretable-motion</link>
      <description><![CDATA[While much effort has been invested in generating human motion from text, relatively few studies have been dedicated to the reverse direction, that is, generating text from motion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/guided-attention-for-interpretable-motion</guid>
    </item>
    <item>
      <title>ADASR: An Adversarial Auto-Augmentation Framework for Hyperspectral and Multispectral Data Fusion</title>
      <link>https://paperswithcode.com/paper/adasr-an-adversarial-auto-augmentation</link>
      <description><![CDATA[Deep learning-based hyperspectral image (HSI) super-resolution, which aims to generate high spatial resolution HSI (HR-HSI) by fusing hyperspectral image (HSI) and multispectral image (MSI) with deep neural networks (DNNs), has attracted lots of attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adasr-an-adversarial-auto-augmentation</guid>
    </item>
    <item>
      <title>Uni-paint: A Unified Framework for Multimodal Image Inpainting with Pretrained Diffusion Model</title>
      <link>https://paperswithcode.com/paper/uni-paint-a-unified-framework-for-multimodal</link>
      <description><![CDATA[Recently, text-to-image denoising diffusion probabilistic models (DDPMs) have demonstrated impressive image generation capabilities and have also been successfully applied to image inpainting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uni-paint-a-unified-framework-for-multimodal</guid>
    </item>
    <item>
      <title>Kernel Cox partially linear regression: building predictive models for cancer patients' survival</title>
      <link>https://paperswithcode.com/paper/kernel-cox-partially-linear-regression</link>
      <description><![CDATA[To accurately predict clinical outcomes, it is vital to build an accurate predictive model that relates patients' molecular profiles with patients' survival.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kernel-cox-partially-linear-regression</guid>
    </item>
    <item>
      <title>PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/pad-a-dataset-and-benchmark-for-pose-agnostic</link>
      <description><![CDATA[Furthermore, we provide an open-source benchmark library, including dataset and baseline methods that cover 8 anomaly detection paradigms, to facilitate future research and application in this domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pad-a-dataset-and-benchmark-for-pose-agnostic</guid>
    </item>
    <item>
      <title>Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models</title>
      <link>https://paperswithcode.com/paper/found-in-the-middle-permutation-self</link>
      <description><![CDATA[Large language models (LLMs) exhibit positional bias in how they use context, which especially complicates listwise ranking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/found-in-the-middle-permutation-self</guid>
    </item>
    <item>
      <title>DASpeech: Directed Acyclic Transformer for Fast and High-quality Speech-to-Speech Translation</title>
      <link>https://paperswithcode.com/paper/daspeech-directed-acyclic-transformer-for</link>
      <description><![CDATA[However, due to the presence of linguistic and acoustic diversity, the target speech follows a complex multimodal distribution, posing challenges to achieving both high-quality translations and fast decoding speeds for S2ST models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/daspeech-directed-acyclic-transformer-for</guid>
    </item>
    <item>
      <title>Ferret: Refer and Ground Anything Anywhere at Any Granularity</title>
      <link>https://paperswithcode.com/paper/ferret-refer-and-ground-anything-anywhere-at</link>
      <description><![CDATA[We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ferret-refer-and-ground-anything-anywhere-at</guid>
    </item>
    <item>
      <title>Self-supervised Representation Learning From Random Data Projectors</title>
      <link>https://paperswithcode.com/paper/self-supervised-representation-learning-from-6</link>
      <description><![CDATA[Self-supervised representation learning~(SSRL) has advanced considerably by exploiting the transformation invariance assumption under artificially designed data augmentations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-representation-learning-from-6</guid>
    </item>
    <item>
      <title>ChatGPT for Computational Topology</title>
      <link>https://paperswithcode.com/paper/chatgpt-for-computational-topology</link>
      <description><![CDATA[This work serves as an initial step towards effectively transforming pure mathematical theories into practical computational tools, with the ultimate goal of enabling real applications across diverse fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatgpt-for-computational-topology</guid>
    </item>
    <item>
      <title>Deep Learning for blind spectral unmixing of LULC classes with MODIS multispectral time series and ancillary data</title>
      <link>https://paperswithcode.com/paper/deep-learning-for-blind-spectral-unmixing-of</link>
      <description><![CDATA[To our knowledge, here we provide the first study on BSU of LULC classes using multispectral time series data with DL models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-learning-for-blind-spectral-unmixing-of</guid>
    </item>
    <item>
      <title>Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality</title>
      <link>https://paperswithcode.com/paper/hierarchical-decomposition-of-prompt-based</link>
      <description><![CDATA[Following these empirical and theoretical insights, we propose Hierarchical Decomposition (HiDe-)Prompt, an innovative approach that explicitly optimizes the hierarchical components with an ensemble of task-specific prompts and statistics of both uninstructed and instructed representations, further with the coordination of a contrastive regularization strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-decomposition-of-prompt-based</guid>
    </item>
    <item>
      <title>Score Regularized Policy Optimization through Diffusion Behavior</title>
      <link>https://paperswithcode.com/paper/score-regularized-policy-optimization-through</link>
      <description><![CDATA[Recent developments in offline reinforcement learning have uncovered the immense potential of diffusion modeling, which excels at representing heterogeneous behavior policies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/score-regularized-policy-optimization-through</guid>
    </item>
    <item>
      <title>NeuroInspect: Interpretable Neuron-based Debugging Framework through Class-conditional Visualizations</title>
      <link>https://paperswithcode.com/paper/neuroinspect-interpretable-neuron-based</link>
      <description><![CDATA[We validate the effectiveness of our framework by addressing false correlations and improving inferences for classes with the worst performance in real-world settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuroinspect-interpretable-neuron-based</guid>
    </item>
    <item>
      <title>Validating Synthetic Usage Data in Living Lab Environments</title>
      <link>https://paperswithcode.com/paper/validating-synthetic-usage-data-in-living-lab</link>
      <description><![CDATA[Our setup is entirely open, and we share the code to reproduce the experiments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/validating-synthetic-usage-data-in-living-lab</guid>
    </item>
  </channel>
</rss>
