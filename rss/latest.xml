<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 12 Nov 2024 21:08:33 +0000</lastBuildDate>
    <item>
      <title>Retrieval or Global Context Understanding? On Many-Shot In-Context Learning for Long-Context Evaluation</title>
      <link>https://paperswithcode.com/paper/retrieval-or-global-context-understanding-on</link>
      <description><![CDATA[We find that classification and summarization tasks show notable performance improvements with additional demonstrations, while translation and reasoning tasks do not exhibit clear trends.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retrieval-or-global-context-understanding-on</guid>
    </item>
    <item>
      <title>Variational Graph Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/variational-graph-contrastive-learning</link>
      <description><![CDATA[Our approach introduces a subgraph Gaussian embedding module, which adaptively maps subgraphs to a structured Gaussian space, ensuring the preservation of graph characteristics while controlling the distribution of generated subgraphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/variational-graph-contrastive-learning</guid>
    </item>
    <item>
      <title>UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction</title>
      <link>https://paperswithcode.com/paper/unihr-hierarchical-representation-learning</link>
      <description><![CDATA[Experimental results across 7 datasets from 3 types of KGs demonstrate that our UniHR outperforms baselines designed for one specific kind of KG, indicating strong generalization capability of HiDR form and the effectiveness of HiSL module.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unihr-hierarchical-representation-learning</guid>
    </item>
    <item>
      <title>Benchmarking LLMs' Judgments with No Gold Standard</title>
      <link>https://paperswithcode.com/paper/benchmarking-llms-judgments-with-no-gold</link>
      <description><![CDATA[We also present GRE-bench (Generating Review Evaluation Benchmark) which evaluates LLMs based on how well they can generate high-quality peer reviews for academic research papers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-llms-judgments-with-no-gold</guid>
    </item>
    <item>
      <title>United Domain Cognition Network for Salient Object Detection in Optical Remote Sensing Images</title>
      <link>https://paperswithcode.com/paper/united-domain-cognition-network-for-salient</link>
      <description><![CDATA[Technically, we first design a frequency-spatial domain transformer block that mutually amalgamates the complementary local spatial and global frequency features to strength the capability of initial input features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/united-domain-cognition-network-for-salient</guid>
    </item>
    <item>
      <title>Model Fusion through Bayesian Optimization in Language Model Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/model-fusion-through-bayesian-optimization-in</link>
      <description><![CDATA[Building on this observation, we introduce a novel model fusion technique that optimizes both the desired metric and loss through multi-objective Bayesian optimization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/model-fusion-through-bayesian-optimization-in</guid>
    </item>
    <item>
      <title>Neuromodulated Meta-Learning</title>
      <link>https://paperswithcode.com/paper/neuromodulated-meta-learning</link>
      <description><![CDATA[To investigate the role of flexible network structure (FNS) in meta-learning, we conduct extensive empirical and theoretical analyses, finding that model performance is tied to structure, with no universally optimal pattern across tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuromodulated-meta-learning</guid>
    </item>
    <item>
      <title>Training Neural Networks as Recognizers of Formal Languages</title>
      <link>https://paperswithcode.com/paper/training-neural-networks-as-recognizers-of</link>
      <description><![CDATA[We provide results on a variety of languages across the Chomsky hierarchy for three neural architectures: a simple RNN, an LSTM, and a causally-masked transformer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-neural-networks-as-recognizers-of</guid>
    </item>
    <item>
      <title>Transformer verbatim in-context retrieval across time and scale</title>
      <link>https://paperswithcode.com/paper/transformer-verbatim-in-context-retrieval</link>
      <description><![CDATA[We further found that the development of verbatim in-context retrieval is positively correlated with the learning of zero-shot benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-verbatim-in-context-retrieval</guid>
    </item>
    <item>
      <title>Decoding Visual Experience and Mapping Semantics through Whole-Brain Analysis Using fMRI Foundation Models</title>
      <link>https://paperswithcode.com/paper/decoding-visual-experience-and-mapping</link>
      <description><![CDATA[Neural decoding, the process of understanding how brain activity corresponds to different stimuli, has been a primary objective in cognitive sciences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decoding-visual-experience-and-mapping</guid>
    </item>
    <item>
      <title>Renaissance: Investigating the Pretraining of Vision-Language Encoders</title>
      <link>https://paperswithcode.com/paper/renaissance-investigating-the-pretraining-of</link>
      <description><![CDATA[In this paper we seek to answer several questions related to the pretraining of vision-language encoders through meta-analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/renaissance-investigating-the-pretraining-of</guid>
    </item>
    <item>
      <title>ScaleKD: Strong Vision Transformers Could Be Excellent Teachers</title>
      <link>https://paperswithcode.com/paper/scalekd-strong-vision-transformers-could-be</link>
      <description><![CDATA[The student backbones trained by our method transfer well on downstream MS-COCO and ADE20K datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalekd-strong-vision-transformers-could-be</guid>
    </item>
    <item>
      <title>Revisiting Ensembling in One-Shot Federated Learning</title>
      <link>https://paperswithcode.com/paper/revisiting-ensembling-in-one-shot-federated</link>
      <description><![CDATA[One-shot federated learning (OFL) trades the iterative exchange of models between clients and the server with a single round of communication, thereby saving substantially on communication costs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-ensembling-in-one-shot-federated</guid>
    </item>
    <item>
      <title>SCAR: Sparse Conditioned Autoencoders for Concept Detection and Steering in LLMs</title>
      <link>https://paperswithcode.com/paper/scar-sparse-conditioned-autoencoders-for</link>
      <description><![CDATA[Large Language Models (LLMs) have demonstrated remarkable capabilities in generating human-like text, but their output may not be aligned with the user or even produce harmful content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scar-sparse-conditioned-autoencoders-for</guid>
    </item>
    <item>
      <title>Counterfactual Generation from Language Models</title>
      <link>https://paperswithcode.com/paper/counterfactual-generation-from-language</link>
      <description><![CDATA[Understanding and manipulating the causal generation mechanisms in language models is essential for controlling their behavior.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-generation-from-language</guid>
    </item>
    <item>
      <title>Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching</title>
      <link>https://paperswithcode.com/paper/non-adversarial-inverse-reinforcement</link>
      <description><![CDATA[In inverse reinforcement learning (IRL), an agent seeks to replicate expert demonstrations through interactions with the environment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/non-adversarial-inverse-reinforcement</guid>
    </item>
    <item>
      <title>StoryTeller: Improving Long Video Description through Global Audio-Visual Character Identification</title>
      <link>https://paperswithcode.com/paper/storyteller-improving-long-video-description</link>
      <description><![CDATA[We propose StoryTeller, a system for generating dense descriptions of long videos, incorporating both low-level visual concepts and high-level plot information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/storyteller-improving-long-video-description</guid>
    </item>
    <item>
      <title>An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning</title>
      <link>https://paperswithcode.com/paper/an-efficient-memory-module-for-graph-few-shot</link>
      <description><![CDATA[Knowledge is then distilled back into the GNN through a Graph Knowledge Distillation Module, preserving the model's memory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-efficient-memory-module-for-graph-few-shot</guid>
    </item>
    <item>
      <title>Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training</title>
      <link>https://paperswithcode.com/paper/zeroth-order-adaptive-neuron-alignment-based</link>
      <description><![CDATA[Hence, we propose \textsc{NeuroAl}, a \emph{top-up} algorithm that can be used on top of any given pruning algorithm for LLMs, that modifies the block-wise and row-wise sparsity ratios to maximize the \emph{neuron alignment} among activations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zeroth-order-adaptive-neuron-alignment-based</guid>
    </item>
    <item>
      <title>ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis</title>
      <link>https://paperswithcode.com/paper/enat-rethinking-spatial-temporal-interactions</link>
      <description><![CDATA[At the spatial level, we disentangle the computations of visible and mask tokens by encoding visible tokens independently, while decoding mask tokens conditioned on the fully encoded visible tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enat-rethinking-spatial-temporal-interactions</guid>
    </item>
    <item>
      <title>SAMPart3D: Segment Any Part in 3D Objects</title>
      <link>https://paperswithcode.com/paper/sampart3d-segment-any-part-in-3d-objects</link>
      <description><![CDATA[For flexibility, we distill scale-conditioned part-aware 3D features for 3D part segmentation at multiple granularities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sampart3d-segment-any-part-in-3d-objects</guid>
    </item>
    <item>
      <title>Understanding Scaling Laws with Statistical and Approximation Theory for Transformer Neural Networks on Intrinsically Low-dimensional Data</title>
      <link>https://paperswithcode.com/paper/understanding-scaling-laws-with-statistical</link>
      <description><![CDATA[Our theory predicts a power law between the generalization error and both the training data size and the network size for transformers, where the power depends on the intrinsic dimension $d$ of the training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-scaling-laws-with-statistical</guid>
    </item>
    <item>
      <title>'Explaining RL Decisions with Trajectories': A Reproducibility Study</title>
      <link>https://paperswithcode.com/paper/explaining-rl-decisions-with-trajectories-a</link>
      <description><![CDATA[This work investigates the reproducibility of the paper 'Explaining RL decisions with trajectories'.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explaining-rl-decisions-with-trajectories-a</guid>
    </item>
    <item>
      <title>AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant</title>
      <link>https://paperswithcode.com/paper/assistrag-boosting-the-potential-of-large</link>
      <description><![CDATA[The emergence of Large Language Models (LLMs) has significantly advanced natural language processing, but these models often generate factually incorrect information, known as "hallucination".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/assistrag-boosting-the-potential-of-large</guid>
    </item>
    <item>
      <title>Fast and Efficient Transformer-based Method for Bird's Eye View Instance Prediction</title>
      <link>https://paperswithcode.com/paper/fast-and-efficient-transformer-based-method</link>
      <description><![CDATA[Accurate object detection and prediction are critical to ensure the safety and efficiency of self-driving architectures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-and-efficient-transformer-based-method</guid>
    </item>
    <item>
      <title>Large-scale moral machine experiment on large language models</title>
      <link>https://paperswithcode.com/paper/large-scale-moral-machine-experiment-on-large</link>
      <description><![CDATA[Here, we evaluate moral judgments across 51 different LLMs, including multiple versions of proprietary models (GPT, Claude, Gemini) and open-source alternatives (Llama, Gemma), to assess their alignment with human moral preferences in autonomous driving scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-scale-moral-machine-experiment-on-large</guid>
    </item>
    <item>
      <title>White-Box Diffusion Transformer for single-cell RNA-seq generation</title>
      <link>https://paperswithcode.com/paper/white-box-diffusion-transformer-for-single</link>
      <description><![CDATA[Our White-Box Diffusion Transformer combines the generative capabilities of Diffusion model with the mathematical interpretability of White-Box transformer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/white-box-diffusion-transformer-for-single</guid>
    </item>
    <item>
      <title>The Super Weight in Large Language Models</title>
      <link>https://paperswithcode.com/paper/the-super-weight-in-large-language-models</link>
      <description><![CDATA[For weight quantization, we similarly find that by preserving the super weight and clipping other weight outliers, round-to-nearest quantization can scale to much larger block sizes than previously considered.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-super-weight-in-large-language-models</guid>
    </item>
    <item>
      <title>Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis</title>
      <link>https://paperswithcode.com/paper/token-merging-for-training-free-semantic</link>
      <description><![CDATA[In this paper, we define semantic binding as the task of associating a given object with its attribute, termed attribute binding, or linking it to other related sub-objects, referred to as object binding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/token-merging-for-training-free-semantic</guid>
    </item>
    <item>
      <title>ConvMixFormer- A Resource-efficient Convolution Mixer for Transformer-based Dynamic Hand Gesture Recognition</title>
      <link>https://paperswithcode.com/paper/convmixformer-a-resource-efficient</link>
      <description><![CDATA[We have considered this drawback of the transformer and designed a resource-efficient model that replaces the self-attention in the transformer with the simple convolutional layer-based token mixer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/convmixformer-a-resource-efficient</guid>
    </item>
    <item>
      <title>Spatially Constrained Transformer with Efficient Global Relation Modelling for Spatio-Temporal Prediction</title>
      <link>https://paperswithcode.com/paper/spatially-constrained-transformer-with</link>
      <description><![CDATA[To address this limitation, we propose ST-SampleNet, a novel transformer-based architecture that combines CNNs with self-attention mechanisms to capture both local and global relations effectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatially-constrained-transformer-with</guid>
    </item>
    <item>
      <title>Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI</title>
      <link>https://paperswithcode.com/paper/gaussian-process-emulators-for-few-shot</link>
      <description><![CDATA[Segmentation of cardiac magnetic resonance images (MRI) is crucial for the analysis and assessment of cardiac function, helping to diagnose and treat various cardiovascular diseases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaussian-process-emulators-for-few-shot</guid>
    </item>
    <item>
      <title>Increasing Rosacea Awareness Among Population Using Deep Learning and Statistical Approaches</title>
      <link>https://paperswithcode.com/paper/increasing-rosacea-awareness-among-population</link>
      <description><![CDATA[To increase rosacea awareness, automatic rosacea detection methods using deep learning and explainable statistical approaches are presented in this paper.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/increasing-rosacea-awareness-among-population</guid>
    </item>
    <item>
      <title>Scaling Mesh Generation via Compressive Tokenization</title>
      <link>https://paperswithcode.com/paper/scaling-mesh-generation-via-compressive</link>
      <description><![CDATA[We propose a compressive yet effective mesh representation, Blocked and Patchified Tokenization (BPT), facilitating the generation of meshes exceeding 8k faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-mesh-generation-via-compressive</guid>
    </item>
    <item>
      <title>DLCR: A Generative Data Expansion Framework via Diffusion for Clothes-Changing Person Re-ID</title>
      <link>https://paperswithcode.com/paper/dlcr-a-generative-data-expansion-framework</link>
      <description><![CDATA[To address this issue we propose DLCR, a novel data expansion framework that leverages pre-trained diffusion and large language models (LLMs) to accurately generate diverse images of individuals in varied attire.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dlcr-a-generative-data-expansion-framework</guid>
    </item>
    <item>
      <title>Structuring the Processing Frameworks for Data Stream Evaluation and Application</title>
      <link>https://paperswithcode.com/paper/structuring-the-processing-frameworks-for</link>
      <description><![CDATA[The following work addresses the problem of frameworks for data stream processing that can be used to evaluate the solutions in an environment that resembles real-world applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structuring-the-processing-frameworks-for</guid>
    </item>
    <item>
      <title>Model Editing for LLMs4Code: How Far are We?</title>
      <link>https://paperswithcode.com/paper/model-editing-for-llms4code-how-far-are-we</link>
      <description><![CDATA[Despite that, a comprehensive study that thoroughly compares and analyzes the performance of the state-of-the-art model editing techniques for adapting the knowledge within LLMs4Code across various code-related tasks is notably absent.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/model-editing-for-llms4code-how-far-are-we</guid>
    </item>
    <item>
      <title>Continual Memorization of Factoids in Large Language Models</title>
      <link>https://paperswithcode.com/paper/continual-memorization-of-factoids-in-large</link>
      <description><![CDATA[REMIX prevents forgetting by mixing generic data sampled from pretraining corpora or even randomly generated word sequences during each stage, despite being unrelated to the memorized factoids in the first stage.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/continual-memorization-of-factoids-in-large</guid>
    </item>
    <item>
      <title>More Expressive Attention with Negative Weights</title>
      <link>https://paperswithcode.com/paper/more-expressive-attention-with-negative</link>
      <description><![CDATA[We propose a novel attention mechanism, named Cog Attention, that enables attention weights to be negative for enhanced expressiveness, which stems from two key factors: (1) Cog Attention can shift the token deletion and copying function from a static OV matrix to dynamic QK inner products, with the OV matrix now focusing more on refinement or modification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/more-expressive-attention-with-negative</guid>
    </item>
    <item>
      <title>Enhancing Robot Assistive Behaviour with Reinforcement Learning and Theory of Mind</title>
      <link>https://paperswithcode.com/paper/enhancing-robot-assistive-behaviour-with</link>
      <description><![CDATA[The adaptation to users' preferences and the ability to infer and interpret humans' beliefs and intents, which is known as the Theory of Mind (ToM), are two crucial aspects for achieving effective human-robot collaboration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-robot-assistive-behaviour-with</guid>
    </item>
    <item>
      <title>Does This Summary Answer My Question? Modeling Query-Focused Summary Readers with Rational Speech Acts</title>
      <link>https://paperswithcode.com/paper/does-this-summary-answer-my-question-modeling</link>
      <description><![CDATA[Query-focused summarization (QFS) is the task of generating a summary in response to a user-written query.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/does-this-summary-answer-my-question-modeling</guid>
    </item>
    <item>
      <title>SAN: Structure-Aware Network for Complex and Long-tailed Chinese Text Recognition</title>
      <link>https://paperswithcode.com/paper/san-structure-aware-network-for-complex-and</link>
      <description><![CDATA[Hence in this work, we propose a structure-aware network utilizing the hierarchical composition information to improve the recognition performance of complex characters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/san-structure-aware-network-for-complex-and</guid>
    </item>
    <item>
      <title>SEM-Net: Efficient Pixel Modelling for image inpainting with Spatially Enhanced SSM</title>
      <link>https://paperswithcode.com/paper/sem-net-efficient-pixel-modelling-for-image</link>
      <description><![CDATA[Image inpainting aims to repair a partially damaged image based on the information from known regions of the images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sem-net-efficient-pixel-modelling-for-image</guid>
    </item>
    <item>
      <title>Reinforcement learning for Quantum Tiq-Taq-Toe</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-for-quantum-tiq-taq</link>
      <description><![CDATA[Quantum Tiq-Taq-Toe is a well-known benchmark and playground for both quantum computing and machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-for-quantum-tiq-taq</guid>
    </item>
    <item>
      <title>Fitting Multiple Machine Learning Models with Performance Based Clustering</title>
      <link>https://paperswithcode.com/paper/fitting-multiple-machine-learning-models-with</link>
      <description><![CDATA[Traditional machine learning approaches assume that data comes from a single generating mechanism, which may not hold for most real life data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fitting-multiple-machine-learning-models-with</guid>
    </item>
    <item>
      <title>Offline Handwritten Signature Verification Using a Stream-Based Approach</title>
      <link>https://paperswithcode.com/paper/offline-handwritten-signature-verification-1</link>
      <description><![CDATA[Handwritten Signature Verification (HSV) systems distinguish between genuine and forged signatures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/offline-handwritten-signature-verification-1</guid>
    </item>
    <item>
      <title>Optimized Inference for 1.58-bit LLMs: A Time and Memory-Efficient Algorithm for Binary and Ternary Matrix Multiplication</title>
      <link>https://paperswithcode.com/paper/optimized-inference-for-1-58-bit-llms-a-time</link>
      <description><![CDATA[To address these challenges and make LLMs more accessible and cost-effective, in this paper, we propose algorithms to improve the inference time and memory efficiency of 1. 58-bit LLMs with ternary weight matrices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimized-inference-for-1-58-bit-llms-a-time</guid>
    </item>
    <item>
      <title>UniGAD: Unifying Multi-level Graph Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/unigad-unifying-multi-level-graph-anomaly</link>
      <description><![CDATA[Existing methods generally focus on a single graph object type (node, edge, graph, etc.)]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unigad-unifying-multi-level-graph-anomaly</guid>
    </item>
    <item>
      <title>CityGuessr: City-Level Video Geo-Localization on a Global Scale</title>
      <link>https://paperswithcode.com/paper/cityguessr-city-level-video-geo-localization</link>
      <description><![CDATA[Hence, we propose a novel problem of worldwide video geolocalization with the objective of hierarchically predicting the correct city, state/province, country, and continent, given a video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cityguessr-city-level-video-geo-localization</guid>
    </item>
    <item>
      <title>PRISM: Privacy-preserving Inter-Site MRI Harmonization via Disentangled Representation Learning</title>
      <link>https://paperswithcode.com/paper/prism-privacy-preserving-inter-site-mri</link>
      <description><![CDATA[Multi-site MRI studies often suffer from site-specific variations arising from differences in methodology, hardware, and acquisition protocols, thereby compromising accuracy and reliability in clinical AI/ML tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prism-privacy-preserving-inter-site-mri</guid>
    </item>
  </channel>
</rss>
