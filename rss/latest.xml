<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 28 Aug 2023 21:06:14 +0000</lastBuildDate>
    <item>
      <title>GEMTrans: A General, Echocardiography-based, Multi-Level Transformer Framework for Cardiovascular Diagnosis</title>
      <link>https://paperswithcode.com/paper/gemtrans-a-general-echocardiography-based</link>
      <description><![CDATA[Due to inter-observer variability in echo-based diagnosis, which arises from the variability in echo image acquisition and the interpretation of echo images based on clinical experience, vision-based machine learning (ML) methods have gained popularity to act as secondary layers of verification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gemtrans-a-general-echocardiography-based</guid>
    </item>
    <item>
      <title>STRIDE: Street View-based Environmental Feature Detection and Pedestrian Collision Prediction</title>
      <link>https://paperswithcode.com/paper/stride-street-view-based-environmental</link>
      <description><![CDATA[This paper introduces a novel benchmark to study the impact and relationship of built environment elements on pedestrian collision prediction, intending to enhance environmental awareness in autonomous driving systems to prevent pedestrian injuries actively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stride-street-view-based-environmental</guid>
    </item>
    <item>
      <title>ReST: A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera Multi-Object Tracking</title>
      <link>https://paperswithcode.com/paper/rest-a-reconfigurable-spatial-temporal-graph</link>
      <description><![CDATA[Experimental results show that the proposed graph model is able to extract more discriminating features for object tracking, and our model achieves state-of-the-art performance on several public datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rest-a-reconfigurable-spatial-temporal-graph</guid>
    </item>
    <item>
      <title>Prompting Visual-Language Models for Dynamic Facial Expression Recognition</title>
      <link>https://paperswithcode.com/paper/prompting-visual-language-models-for-dynamic</link>
      <description><![CDATA[For the visual part, based on the CLIP image encoder, a temporal model consisting of several Transformer encoders is introduced for extracting temporal facial expression features, and the final feature embedding is obtained as a learnable "class" token.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompting-visual-language-models-for-dynamic</guid>
    </item>
    <item>
      <title>ARTIST: ARTificial Intelligence for Simplified Text</title>
      <link>https://paperswithcode.com/paper/artist-artificial-intelligence-for-simplified</link>
      <description><![CDATA[Complex text is a major barrier for many citizens when accessing public information and knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/artist-artificial-intelligence-for-simplified</guid>
    </item>
    <item>
      <title>Ngambay-French Neural Machine Translation (sba-Fr)</title>
      <link>https://paperswithcode.com/paper/ngambay-french-neural-machine-translation-sba</link>
      <description><![CDATA[However, a guided approach for data gathering can produce bitext data for many Chadian language translation pairs with well-known languages that have ample data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ngambay-french-neural-machine-translation-sba</guid>
    </item>
    <item>
      <title>IOMatch: Simplifying Open-Set Semi-Supervised Learning with Joint Inliers and Outliers Utilization</title>
      <link>https://paperswithcode.com/paper/iomatch-simplifying-open-set-semi-supervised</link>
      <description><![CDATA[Semi-supervised learning (SSL) aims to leverage massive unlabeled data when labels are expensive to obtain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/iomatch-simplifying-open-set-semi-supervised</guid>
    </item>
    <item>
      <title>LLM2KB: Constructing Knowledge Bases using instruction tuned context aware Large Language Models</title>
      <link>https://paperswithcode.com/paper/llm2kb-constructing-knowledge-bases-using</link>
      <description><![CDATA[Our paper proposes LLM2KB, a system for constructing knowledge bases using large language models, with a focus on the Llama 2 architecture and the Wikipedia dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm2kb-constructing-knowledge-bases-using</guid>
    </item>
    <item>
      <title>Gotta match 'em all: Solution diversification in graph matching matched filters</title>
      <link>https://paperswithcode.com/paper/gotta-match-em-all-solution-diversification</link>
      <description><![CDATA[We present a novel approach for finding multiple noisily embedded template graphs in a very large background graph.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gotta-match-em-all-solution-diversification</guid>
    </item>
    <item>
      <title>Training normalizing flows with computationally intensive target probability distributions</title>
      <link>https://paperswithcode.com/paper/training-normalizing-flows-with</link>
      <description><![CDATA[The common loss function's gradient estimator based on the "reparametrization trick" requires the calculation of the derivative of the action with respect to the fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-normalizing-flows-with</guid>
    </item>
    <item>
      <title>Unpaired Multi-domain Attribute Translation of 3D Facial Shapes with a Square and Symmetric Geometric Map</title>
      <link>https://paperswithcode.com/paper/unpaired-multi-domain-attribute-translation</link>
      <description><![CDATA[We propose a learning framework for 3D facial attribute translation to relieve these limitations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unpaired-multi-domain-attribute-translation</guid>
    </item>
    <item>
      <title>Relighting Neural Radiance Fields with Shadow and Highlight Hints</title>
      <link>https://paperswithcode.com/paper/relighting-neural-radiance-fields-with-shadow</link>
      <description><![CDATA[This paper presents a novel neural implicit radiance representation for free viewpoint relighting from a small set of unstructured photographs of an object lit by a moving point light source different from the view position.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relighting-neural-radiance-fields-with-shadow</guid>
    </item>
    <item>
      <title>Eventful Transformers: Leveraging Temporal Redundancy in Vision Transformers</title>
      <link>https://paperswithcode.com/paper/eventful-transformers-leveraging-temporal</link>
      <description><![CDATA[In this work, we exploit temporal redundancy between subsequent inputs to reduce the cost of Transformers for video processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eventful-transformers-leveraging-temporal</guid>
    </item>
    <item>
      <title>Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs</title>
      <link>https://paperswithcode.com/paper/do-not-answer-a-dataset-for-evaluating</link>
      <description><![CDATA[With the rapid evolution of large language models (LLMs), new and hard-to-predict harmful capabilities are emerging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-not-answer-a-dataset-for-evaluating</guid>
    </item>
    <item>
      <title>Assessing Keyness using Permutation Tests</title>
      <link>https://paperswithcode.com/paper/assessing-keyness-using-permutation-tests</link>
      <description><![CDATA[We propose a resampling-based approach for assessing keyness in corpus linguistics based on suggestions by Gries (2006, 2022).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/assessing-keyness-using-permutation-tests</guid>
    </item>
    <item>
      <title>In-context learning for model-free system identification</title>
      <link>https://paperswithcode.com/paper/in-context-learning-for-model-free-system</link>
      <description><![CDATA[Yet, is it also possible to understand the intricacies of dynamical systems not solely from their input/output patterns, but by observing the behavior of other systems within the same class?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/in-context-learning-for-model-free-system</guid>
    </item>
    <item>
      <title>TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs</title>
      <link>https://paperswithcode.com/paper/tpugraphs-a-performance-prediction-dataset-on</link>
      <description><![CDATA[TpuGraphs provides 25x more graphs than the largest graph property prediction dataset (with comparable graph sizes), and 770x larger graphs on average compared to existing performance prediction datasets on machine learning programs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tpugraphs-a-performance-prediction-dataset-on</guid>
    </item>
    <item>
      <title>Unsupervised Domain Adaptation for Anatomical Landmark Detection</title>
      <link>https://paperswithcode.com/paper/unsupervised-domain-adaptation-for-anatomical</link>
      <description><![CDATA[The framework leverages self-training and domain adversarial learning to address the domain gap during adaptation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-domain-adaptation-for-anatomical</guid>
    </item>
    <item>
      <title>Unlocking Fine-Grained Details with Wavelet-based High-Frequency Enhancement in Transformers</title>
      <link>https://paperswithcode.com/paper/unlocking-fine-grained-details-with-wavelet</link>
      <description><![CDATA[Furthermore, to intensify the importance of the boundary information, we impose an additional attention map by creating a Gaussian pyramid on top of the HF components.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlocking-fine-grained-details-with-wavelet</guid>
    </item>
    <item>
      <title>TriGait: Aligning and Fusing Skeleton and Silhouette Gait Data via a Tri-Branch Network</title>
      <link>https://paperswithcode.com/paper/trigait-aligning-and-fusing-skeleton-and</link>
      <description><![CDATA[To fully exploit the complementary nature of the two modalities, a novel triple branch gait recognition framework, TriGait, is proposed in this paper.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trigait-aligning-and-fusing-skeleton-and</guid>
    </item>
    <item>
      <title>SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research</title>
      <link>https://paperswithcode.com/paper/scieval-a-multi-level-large-language-model</link>
      <description><![CDATA[This design suffers from data leakage problem and lacks the evaluation of subjective Q/A ability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scieval-a-multi-level-large-language-model</guid>
    </item>
    <item>
      <title>MultiCapCLIP: Auto-Encoding Prompts for Zero-Shot Multilingual Visual Captioning</title>
      <link>https://paperswithcode.com/paper/multicapclip-auto-encoding-prompts-for-zero</link>
      <description><![CDATA[To deal with the label shortage problem, we present a simple yet effective zero-shot approach MultiCapCLIP that can generate visual captions for different scenarios and languages without any labeled vision-caption pairs of downstream datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multicapclip-auto-encoding-prompts-for-zero</guid>
    </item>
    <item>
      <title>Nougat: Neural Optical Understanding for Academic Documents</title>
      <link>https://paperswithcode.com/paper/nougat-neural-optical-understanding-for</link>
      <description><![CDATA[Scientific knowledge is predominantly stored in books and scientific journals, often in the form of PDFs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nougat-neural-optical-understanding-for</guid>
    </item>
    <item>
      <title>Optimizing Group-Fair Plackett-Luce Ranking Models for Relevance and Ex-Post Fairness</title>
      <link>https://paperswithcode.com/paper/optimizing-group-fair-plackett-luce-ranking</link>
      <description><![CDATA[Previous works have proposed efficient algorithms to train stochastic ranking models that achieve fairness of exposure to the groups ex-ante (or, in expectation), which may not guarantee representation fairness to the groups ex-post, that is, after realizing a ranking from the stochastic ranking model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimizing-group-fair-plackett-luce-ranking</guid>
    </item>
    <item>
      <title>Integrating Boxes and Masks: A Multi-Object Framework for Unified Visual Tracking and Segmentation</title>
      <link>https://paperswithcode.com/paper/integrating-boxes-and-masks-a-multi-object</link>
      <description><![CDATA[Tracking any given object(s) spatially and temporally is a common purpose in Visual Object Tracking (VOT) and Video Object Segmentation (VOS).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/integrating-boxes-and-masks-a-multi-object</guid>
    </item>
    <item>
      <title>OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/omniquant-omnidirectionally-calibrated</link>
      <description><![CDATA[To tackle this issue, we introduce an Omnidirectionally calibrated Quantization (OmniQuant) technique for LLMs, which achieves good performance in diverse quantization settings while maintaining the computational efficiency of PTQ by efficiently optimizing various quantization parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omniquant-omnidirectionally-calibrated</guid>
    </item>
    <item>
      <title>MatchXML: An Efficient Text-label Matching Framework for Extreme Multi-label Text Classification</title>
      <link>https://paperswithcode.com/paper/matchxml-an-efficient-text-label-matching</link>
      <description><![CDATA[We then extract the dense text representations from the fine-tuned Transformer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/matchxml-an-efficient-text-label-matching</guid>
    </item>
    <item>
      <title>SoTaNa: The Open-Source Software Development Assistant</title>
      <link>https://paperswithcode.com/paper/sotana-the-open-source-software-development</link>
      <description><![CDATA[To meet the demands of this dynamic field, there is a growing need for an effective software development assistant.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sotana-the-open-source-software-development</guid>
    </item>
    <item>
      <title>NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes</title>
      <link>https://paperswithcode.com/paper/neo-360-neural-fields-for-sparse-view</link>
      <description><![CDATA[NeO 360's representation allows us to learn from a large collection of unbounded 3D scenes while offering generalizability to new views and novel scenes from as few as a single image during inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neo-360-neural-fields-for-sparse-view</guid>
    </item>
    <item>
      <title>Large Language Models Vote: Prompting for Rare Disease Identification</title>
      <link>https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</link>
      <description><![CDATA[The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</guid>
    </item>
    <item>
      <title>Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities</title>
      <link>https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</link>
      <description><![CDATA[We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</guid>
    </item>
    <item>
      <title>Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?</title>
      <link>https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</link>
      <description><![CDATA[The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</guid>
    </item>
    <item>
      <title>Causal Parrots: Large Language Models May Talk Causality But Are Not Causal</title>
      <link>https://paperswithcode.com/paper/causal-parrots-large-language-models-may-talk</link>
      <description><![CDATA[We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causal-parrots-large-language-models-may-talk</guid>
    </item>
    <item>
      <title>FastSurfer-HypVINN: Automated sub-segmentation of the hypothalamus and adjacent structures on high-resolutional brain MRI</title>
      <link>https://paperswithcode.com/paper/fastsurfer-hypvinn-automated-sub-segmentation</link>
      <description><![CDATA[The hypothalamus plays a crucial role in the regulation of a broad range of physiological, behavioural, and cognitive functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fastsurfer-hypvinn-automated-sub-segmentation</guid>
    </item>
    <item>
      <title>StreamMapNet: Streaming Mapping Network for Vectorized Online HD Map Construction</title>
      <link>https://paperswithcode.com/paper/streammapnet-streaming-mapping-network-for</link>
      <description><![CDATA[High-Definition (HD) maps are essential for the safety of autonomous driving systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streammapnet-streaming-mapping-network-for</guid>
    </item>
    <item>
      <title>Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines</title>
      <link>https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</link>
      <description><![CDATA[This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</guid>
    </item>
    <item>
      <title>LISTER: Neighbor Decoding for Length-Insensitive Scene Text Recognition</title>
      <link>https://paperswithcode.com/paper/lister-neighbor-decoding-for-length</link>
      <description><![CDATA[The diversity in length constitutes a significant characteristic of text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lister-neighbor-decoding-for-length</guid>
    </item>
    <item>
      <title>Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers</title>
      <link>https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</link>
      <description><![CDATA[Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</guid>
    </item>
    <item>
      <title>Improving Translation Faithfulness of Large Language Models via Augmenting Instructions</title>
      <link>https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</link>
      <description><![CDATA[The experimental results demonstrate significant improvements in translation performance with SWIE based on BLOOMZ-3b, particularly in zero-shot and long text translations due to reduced instruction forgetting risk.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</guid>
    </item>
    <item>
      <title>PoseSync: Robust pose based video synchronization</title>
      <link>https://paperswithcode.com/paper/posesync-robust-pose-based-video</link>
      <description><![CDATA[Pose based video sychronization can have applications in multiple domains such as gameplay performance evaluation, choreography or guiding athletes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posesync-robust-pose-based-video</guid>
    </item>
    <item>
      <title>Sentence Embedding Models for Ancient Greek Using Multilingual Knowledge Distillation</title>
      <link>https://paperswithcode.com/paper/sentence-embedding-models-for-ancient-greek</link>
      <description><![CDATA[In this work, we use a multilingual knowledge distillation approach to train BERT models to produce sentence embeddings for Ancient Greek text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sentence-embedding-models-for-ancient-greek</guid>
    </item>
    <item>
      <title>Perspective-aware Convolution for Monocular 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</link>
      <description><![CDATA[Monocular 3D object detection is a crucial and challenging task for autonomous driving vehicle, while it uses only a single camera image to infer 3D objects in the scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</guid>
    </item>
    <item>
      <title>Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]</title>
      <link>https://paperswithcode.com/paper/unified-data-management-and-comprehensive</link>
      <description><![CDATA[The field of urban spatial-temporal prediction is advancing rapidly with the development of deep learning techniques and the availability of large-scale datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-data-management-and-comprehensive</guid>
    </item>
    <item>
      <title>Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis</title>
      <link>https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</link>
      <description><![CDATA[The model pretrained on large-scale rs-fMRI data has been released to the public.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</guid>
    </item>
    <item>
      <title>Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods</title>
      <link>https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</link>
      <description><![CDATA[We introduce an open-source GitHub repository containing comprehensive benchmarks for a wide range of machine scheduling problems, including Job Shop Scheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling (FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent Setup Times (FJSP-SDST), and the online FJSP (with online job arrivals).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</guid>
    </item>
    <item>
      <title>CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias</title>
      <link>https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</link>
      <description><![CDATA[To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</guid>
    </item>
    <item>
      <title>Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</link>
      <description><![CDATA[The challenges of this task lie in the complexity of the scenes, the unique features of anime style, and the lack of high-quality datasets to bridge the domain gap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</guid>
    </item>
    <item>
      <title>Single-shot Bayesian approximation for neural networks</title>
      <link>https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</link>
      <description><![CDATA[We demonstrate that our single-shot MC dropout approximation resembles the point estimate and the uncertainty estimate of the predictive distribution that is achieved with an MC approach, while being fast enough for real-time deployments of BNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</guid>
    </item>
    <item>
      <title>Masked Autoencoders are Efficient Class Incremental Learners</title>
      <link>https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</link>
      <description><![CDATA[Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</guid>
    </item>
    <item>
      <title>Grounded Entity-Landmark Adaptive Pre-training for Vision-and-Language Navigation</title>
      <link>https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</link>
      <description><![CDATA[To address this problem, we propose a novel Grounded Entity-Landmark Adaptive (GELA) pre-training paradigm for VLN tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</guid>
    </item>
  </channel>
</rss>
