<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 14 Oct 2023 09:10:34 +0000</lastBuildDate>
    <item>
      <title>Towards Robust Multi-Modal Reasoning via Model Selection</title>
      <link>https://paperswithcode.com/paper/towards-robust-multi-modal-reasoning-via</link>
      <description><![CDATA[The reasoning capabilities of LLM (Large Language Model) are widely acknowledged in recent research, inspiring studies on tool learning and autonomous agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-multi-modal-reasoning-via</guid>
    </item>
    <item>
      <title>Jailbreaking Black Box Large Language Models in Twenty Queries</title>
      <link>https://paperswithcode.com/paper/jailbreaking-black-box-large-language-models</link>
      <description><![CDATA[PAIR -- which is inspired by social engineering attacks -- uses an attacker LLM to automatically generate jailbreaks for a separate targeted LLM without human intervention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jailbreaking-black-box-large-language-models</guid>
    </item>
    <item>
      <title>Expanding the Vocabulary of BERT for Knowledge Base Construction</title>
      <link>https://paperswithcode.com/paper/expanding-the-vocabulary-of-bert-for</link>
      <description><![CDATA[To address this, we present Vocabulary Expandable BERT for knowledge base construction, which expand the language model's vocabulary while preserving semantic embeddings for newly added words.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/expanding-the-vocabulary-of-bert-for</guid>
    </item>
    <item>
      <title>SimCKP: Simple Contrastive Learning of Keyphrase Representations</title>
      <link>https://paperswithcode.com/paper/simckp-simple-contrastive-learning-of</link>
      <description><![CDATA[Keyphrase generation (KG) aims to generate a set of summarizing words or phrases given a source document, while keyphrase extraction (KE) aims to identify them from the text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simckp-simple-contrastive-learning-of</guid>
    </item>
    <item>
      <title>TriRE: A Multi-Mechanism Learning Paradigm for Continual Knowledge Retention and Promotion</title>
      <link>https://paperswithcode.com/paper/trire-a-multi-mechanism-learning-paradigm-for</link>
      <description><![CDATA[Continual learning (CL) has remained a persistent challenge for deep neural networks due to catastrophic forgetting (CF) of previously learned tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trire-a-multi-mechanism-learning-paradigm-for</guid>
    </item>
    <item>
      <title>MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/metabox-a-benchmark-platform-for-meta-black</link>
      <description><![CDATA[To fill this gap, we introduce MetaBox, the first benchmark platform expressly tailored for developing and evaluating MetaBBO-RL methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metabox-a-benchmark-platform-for-meta-black</guid>
    </item>
    <item>
      <title>Offline Retraining for Online RL: Decoupled Policy Learning to Mitigate Exploration Bias</title>
      <link>https://paperswithcode.com/paper/offline-retraining-for-online-rl-decoupled</link>
      <description><![CDATA[Can we leverage offline RL to recover better policies from online interaction?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/offline-retraining-for-online-rl-decoupled</guid>
    </item>
    <item>
      <title>AutoVP: An Automated Visual Prompting Framework and Benchmark</title>
      <link>https://paperswithcode.com/paper/autovp-an-automated-visual-prompting</link>
      <description><![CDATA[To bridge this gap, we propose AutoVP, an end-to-end expandable framework for automating VP design choices, along with 12 downstream image-classification tasks that can serve as a holistic VP-performance benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autovp-an-automated-visual-prompting</guid>
    </item>
    <item>
      <title>UniPAD: A Universal Pre-training Paradigm for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/unipad-a-universal-pre-training-paradigm-for</link>
      <description><![CDATA[In the context of autonomous driving, the significance of effective feature learning is widely acknowledged.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unipad-a-universal-pre-training-paradigm-for</guid>
    </item>
    <item>
      <title>Unsupervised Learning of Object-Centric Embeddings for Cell Instance Segmentation in Microscopy Images</title>
      <link>https://paperswithcode.com/paper/unsupervised-learning-of-object-centric-1</link>
      <description><![CDATA[Here, we show theoretically that, under assumptions commonly found in microscopy images, OCEs can be learnt through a self-supervised task that predicts the spatial offset between image patches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-learning-of-object-centric-1</guid>
    </item>
    <item>
      <title>Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/visual-data-type-understanding-does-not</link>
      <description><![CDATA[This finding points to a blind spot in current frontier VLMs: they excel in recognizing semantic content but fail to acquire an understanding of visual \textit{data-types} through scaling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-data-type-understanding-does-not</guid>
    </item>
    <item>
      <title>Defending Our Privacy With Backdoors</title>
      <link>https://paperswithcode.com/paper/defending-our-privacy-with-backdoors</link>
      <description><![CDATA[Our approach provides not only a new "dual-use" perspective on backdoor attacks, but also presents a promising avenue to enhance the privacy of individuals within models trained on uncurated web-scraped data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/defending-our-privacy-with-backdoors</guid>
    </item>
    <item>
      <title>Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization</title>
      <link>https://paperswithcode.com/paper/improving-fast-minimum-norm-attacks-with</link>
      <description><![CDATA[Evaluating the adversarial robustness of machine learning models using gradient-based attacks is challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-fast-minimum-norm-attacks-with</guid>
    </item>
    <item>
      <title>PonderV2: Pave the Way for 3D Foundataion Model with A Universal Pre-training Paradigm</title>
      <link>https://paperswithcode.com/paper/ponderv2-pave-the-way-for-3d-foundataion</link>
      <description><![CDATA[In this paper, we introduce a comprehensive 3D pre-training framework designed to facilitate the acquisition of efficient 3D representations, thereby establishing a pathway to 3D foundational models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ponderv2-pave-the-way-for-3d-foundataion</guid>
    </item>
    <item>
      <title>DualAug: Exploiting Additional Heavy Augmentation with OOD Data Rejection</title>
      <link>https://paperswithcode.com/paper/dualaug-exploiting-additional-heavy</link>
      <description><![CDATA[Most existing data augmentation methods tend to find a compromise in augmenting the data, \textit{i. e.}, increasing the amplitude of augmentation carefully to avoid degrading some data too much and doing harm to the model performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dualaug-exploiting-additional-heavy</guid>
    </item>
    <item>
      <title>Generalized Logit Adjustment: Calibrating Fine-tuned Models by Removing Label Bias in Foundation Models</title>
      <link>https://paperswithcode.com/paper/generalized-logit-adjustment-calibrating-fine</link>
      <description><![CDATA[In this study, we systematically examine the biases in foundation models and demonstrate the efficacy of our proposed Generalized Logit Adjustment (GLA) method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-logit-adjustment-calibrating-fine</guid>
    </item>
    <item>
      <title>X-HRNet: Towards Lightweight Human Pose Estimation with Spatially Unidimensional Self-Attention</title>
      <link>https://paperswithcode.com/paper/x-hrnet-towards-lightweight-human-pose</link>
      <description><![CDATA[Inspired by this observation, we introduce a lightweight and powerful alternative, Spatially Unidimensional Self-Attention (SUSA), to the pointwise (1x1) convolution that is the main computational bottleneck in the depthwise separable 3c3 convolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-hrnet-towards-lightweight-human-pose</guid>
    </item>
    <item>
      <title>Can We Edit Multimodal Large Language Models?</title>
      <link>https://paperswithcode.com/paper/can-we-edit-multimodal-large-language-models</link>
      <description><![CDATA[In this paper, we focus on editing Multimodal Large Language Models (MLLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-we-edit-multimodal-large-language-models</guid>
    </item>
    <item>
      <title>Distilling from Vision-Language Models for Improved OOD Generalization in Vision Tasks</title>
      <link>https://paperswithcode.com/paper/distilling-from-vision-language-models-for</link>
      <description><![CDATA[The client aims to minimize inference cost by distilling the VLM to a student model using the limited available task-specific data, and further deploying this student model in the downstream application.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distilling-from-vision-language-models-for</guid>
    </item>
    <item>
      <title>DUSA: Decoupled Unsupervised Sim2Real Adaptation for Vehicle-to-Everything Collaborative Perception</title>
      <link>https://paperswithcode.com/paper/dusa-decoupled-unsupervised-sim2real</link>
      <description><![CDATA[To take full advantage of simulated data, we present a new unsupervised sim2real domain adaptation method for V2X collaborative detection named Decoupled Unsupervised Sim2Real Adaptation (DUSA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dusa-decoupled-unsupervised-sim2real</guid>
    </item>
    <item>
      <title>LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios</title>
      <link>https://paperswithcode.com/paper/lightzero-a-unified-benchmark-for-monte-carlo</link>
      <description><![CDATA[Building agents based on tree-search planning capabilities with learned models has achieved remarkable success in classic decision-making problems, such as Go and Atari.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightzero-a-unified-benchmark-for-monte-carlo</guid>
    </item>
    <item>
      <title>Multimodal Variational Auto-encoder based Audio-Visual Segmentation</title>
      <link>https://paperswithcode.com/paper/multimodal-variational-auto-encoder-based-1</link>
      <description><![CDATA[To achieve this, our ECMVAE factorizes the representations of each modality with a modality-shared representation and a modality-specific representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-variational-auto-encoder-based-1</guid>
    </item>
    <item>
      <title>EC-Depth: Exploring the consistency of self-supervised monocular depth estimation under challenging scenes</title>
      <link>https://paperswithcode.com/paper/ec-depth-exploring-the-consistency-of-self</link>
      <description><![CDATA[Self-supervised monocular depth estimation holds significant importance in the fields of autonomous driving and robotics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ec-depth-exploring-the-consistency-of-self</guid>
    </item>
    <item>
      <title>QASiNa: Religious Domain Question Answering using Sirah Nabawiyah</title>
      <link>https://paperswithcode.com/paper/qasina-religious-domain-question-answering</link>
      <description><![CDATA[This concludes Chat GPT is unsuitable for question answering task in religious domain especially for Islamic religion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qasina-religious-domain-question-answering</guid>
    </item>
    <item>
      <title>UniPose: Detecting Any Keypoints</title>
      <link>https://paperswithcode.com/paper/unipose-detecting-any-keypoints</link>
      <description><![CDATA[This work proposes a unified framework called UniPose to detect keypoints of any articulated (e. g., human and animal), rigid, and soft objects via visual or textual prompts for fine-grained vision understanding and manipulation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unipose-detecting-any-keypoints</guid>
    </item>
    <item>
      <title>Extensions of Heterogeneity in Integration and Prediction (HIP) with R Shiny Application</title>
      <link>https://paperswithcode.com/paper/extensions-of-heterogeneity-in-integration</link>
      <description><![CDATA[Multiple data views measured on the same set of participants is becoming more common and has the potential to deepen our understanding of many complex diseases by analyzing these different views simultaneously.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extensions-of-heterogeneity-in-integration</guid>
    </item>
    <item>
      <title>HoneyBee: Progressive Instruction Finetuning of Large Language Models for Materials Science</title>
      <link>https://paperswithcode.com/paper/honeybee-progressive-instruction-finetuning</link>
      <description><![CDATA[We propose an instruction-based process for trustworthy data curation in materials science (MatSci-Instruct), which we then apply to finetune a LLaMa-based language model targeted for materials science (HoneyBee).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/honeybee-progressive-instruction-finetuning</guid>
    </item>
    <item>
      <title>Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale Generalization</title>
      <link>https://paperswithcode.com/paper/neural-combinatorial-optimization-with-heavy</link>
      <description><![CDATA[Neural combinatorial optimization (NCO) is a promising learning-based approach for solving challenging combinatorial optimization problems without specialized algorithm design by experts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-combinatorial-optimization-with-heavy</guid>
    </item>
    <item>
      <title>Semantic-Forward Relaying: A Novel Framework Towards 6G Cooperative Communications</title>
      <link>https://paperswithcode.com/paper/semantic-forward-relaying-a-novel-framework</link>
      <description><![CDATA[This letter proposes a novel relaying framework, semantic-forward (SF), for cooperative communications towards the sixth-generation (6G) wireless networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-forward-relaying-a-novel-framework</guid>
    </item>
    <item>
      <title>Infinite Width Graph Neural Networks for Node Regression/ Classification</title>
      <link>https://paperswithcode.com/paper/infinite-width-graph-neural-networks-for-node</link>
      <description><![CDATA[This work analyzes Graph Neural Networks, a generalization of Fully-Connected Deep Neural Nets on Graph structured data, when their width, that is the number of nodes in each fullyconnected layer is increasing to infinity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infinite-width-graph-neural-networks-for-node</guid>
    </item>
    <item>
      <title>GraphextQA: A Benchmark for Evaluating Graph-Enhanced Large Language Models</title>
      <link>https://paperswithcode.com/paper/graphextqa-a-benchmark-for-evaluating-graph</link>
      <description><![CDATA[The proposed dataset is designed to evaluate graph-language models' ability to understand graphs and make use of it for answer generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphextqa-a-benchmark-for-evaluating-graph</guid>
    </item>
    <item>
      <title>Who Said That? Benchmarking Social Media AI Detection</title>
      <link>https://paperswithcode.com/paper/who-said-that-benchmarking-social-media-ai</link>
      <description><![CDATA[Addressing these challenges, this paper introduces SAID (Social media AI Detection), a novel benchmark developed to assess AI-text detection models' capabilities in real social media platforms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/who-said-that-benchmarking-social-media-ai</guid>
    </item>
    <item>
      <title>Language Models are Universal Embedders</title>
      <link>https://paperswithcode.com/paper/language-models-are-universal-embedders</link>
      <description><![CDATA[As such cases span from English to other natural or programming languages, from retrieval to classification and beyond, it is desirable to build a unified embedding model rather than dedicated ones for each scenario.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-are-universal-embedders</guid>
    </item>
    <item>
      <title>Visual Question Generation in Bengali</title>
      <link>https://paperswithcode.com/paper/visual-question-generation-in-bengali</link>
      <description><![CDATA[Our quantitative and qualitative results establish the first state of the art models for VQG task in Bengali and demonstrate that our models are capable of generating grammatically correct and relevant questions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-question-generation-in-bengali</guid>
    </item>
    <item>
      <title>Impact of multi-armed bandit strategies on deep recurrent reinforcement learning</title>
      <link>https://paperswithcode.com/paper/impact-of-multi-armed-bandit-strategies-on</link>
      <description><![CDATA[We aim to show that adaptive stochastic methods for exploration better approximate the trade-off between exploration and exploitation as, in general, Softmax and Max-Boltzmann strategies are able to outperform epsilon-greedy techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/impact-of-multi-armed-bandit-strategies-on</guid>
    </item>
    <item>
      <title>Exploring the Relationship Between Model Architecture and In-Context Learning Ability</title>
      <link>https://paperswithcode.com/paper/exploring-the-relationship-between-model</link>
      <description><![CDATA[What is the relationship between model architecture and the ability to perform in-context learning?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-relationship-between-model</guid>
    </item>
    <item>
      <title>Counterfactual Explanations for Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/counterfactual-explanations-for-time-series</link>
      <description><![CDATA[In this paper, we formulate the novel problem of counterfactual generation for time series forecasting, and propose an algorithm, called ForecastCF, that solves the problem by applying gradient-based perturbations to the original time series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-explanations-for-time-series</guid>
    </item>
    <item>
      <title>ZEST: Attention-based Zero-Shot Learning for Unseen IoT Device Classification</title>
      <link>https://paperswithcode.com/paper/zest-attention-based-zero-shot-learning-for</link>
      <description><![CDATA[Recent research works have proposed machine learning models for classifying IoT devices connected to a network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zest-attention-based-zero-shot-learning-for</guid>
    </item>
    <item>
      <title>Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement</title>
      <link>https://paperswithcode.com/paper/phenomenal-yet-puzzling-testing-inductive</link>
      <description><![CDATA[Iterative hypothesis refinement employs a three-step process: proposing, selecting, and refining hypotheses in the form of textual rules.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phenomenal-yet-puzzling-testing-inductive</guid>
    </item>
    <item>
      <title>Context Compression for Auto-regressive Transformers with Sentinel Tokens</title>
      <link>https://paperswithcode.com/paper/context-compression-for-auto-regressive</link>
      <description><![CDATA[The quadratic complexity of the attention module makes it gradually become the bulk of compute in Transformer-based LLMs during generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-compression-for-auto-regressive</guid>
    </item>
    <item>
      <title>Incorporating Domain Knowledge Graph into Multimodal Movie Genre Classification with Self-Supervised Attention and Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/incorporating-domain-knowledge-graph-into</link>
      <description><![CDATA[Firstly we retrieve the relevant embedding from the knowledge graph by utilizing group relations in metadata and then integrate it with other modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/incorporating-domain-knowledge-graph-into</guid>
    </item>
    <item>
      <title>Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for Sentence Simplification</title>
      <link>https://paperswithcode.com/paper/simplicity-level-estimate-sle-a-learned</link>
      <description><![CDATA[Automatic evaluation for sentence simplification remains a challenging problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simplicity-level-estimate-sle-a-learned</guid>
    </item>
    <item>
      <title>Model-Agnostic Covariate-Assisted Inference on Partially Identified Causal Effects</title>
      <link>https://paperswithcode.com/paper/model-agnostic-covariate-assisted-inference</link>
      <description><![CDATA[Finally, we propose an efficient computational framework, enabling implementation on many practical problems in causal inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/model-agnostic-covariate-assisted-inference</guid>
    </item>
    <item>
      <title>Rethinking Negative Pairs in Code Search</title>
      <link>https://paperswithcode.com/paper/rethinking-negative-pairs-in-code-search</link>
      <description><![CDATA[In our proposed loss function, we apply three methods to estimate the weights of negative pairs and show that the vanilla InfoNCE loss is a special case of Soft-InfoNCE.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-negative-pairs-in-code-search</guid>
    </item>
    <item>
      <title>XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation</title>
      <link>https://paperswithcode.com/paper/ximagenet-12-an-explainable-ai-benchmark</link>
      <description><![CDATA[The lack of standardized robustness metrics and the widespread reliance on numerous unrelated benchmark datasets for testing have created a gap between academically validated robust models and their often problematic practical adoption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ximagenet-12-an-explainable-ai-benchmark</guid>
    </item>
    <item>
      <title>Prometheus: Inducing Fine-grained Evaluation Capability in Language Models</title>
      <link>https://paperswithcode.com/paper/prometheus-inducing-fine-grained-evaluation</link>
      <description><![CDATA[We first construct the Feedback Collection, a new dataset that consists of 1K fine-grained score rubrics, 20K instructions, and 100K responses and language feedback generated by GPT-4.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prometheus-inducing-fine-grained-evaluation</guid>
    </item>
    <item>
      <title>CleftGAN: Adapting A Style-Based Generative Adversarial Network To Create Images Depicting Cleft Lip Deformity</title>
      <link>https://paperswithcode.com/paper/cleftgan-adapting-a-style-based-generative</link>
      <description><![CDATA[We undertook a transfer learning protocol testing different versions of StyleGAN-ADA (a generative adversarial network image generator incorporating adaptive data augmentation (ADA)) as the base model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cleftgan-adapting-a-style-based-generative</guid>
    </item>
    <item>
      <title>Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning</title>
      <link>https://paperswithcode.com/paper/not-all-demonstration-examples-are-equally</link>
      <description><![CDATA[To assess the quality of weights in the absence of additional validation data, we design a masked self-prediction (MSP) score that exhibits a strong correlation with the final ICL performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/not-all-demonstration-examples-are-equally</guid>
    </item>
    <item>
      <title>Beyond Sharing Weights in Decoupling Feature Learning Network for UAV RGB-Infrared Vehicle Re-Identification</title>
      <link>https://paperswithcode.com/paper/beyond-sharing-weights-in-decoupling-feature</link>
      <description><![CDATA[Moreover, to meet cross-modality discrepancy and orientation discrepancy challenges, we present a hybrid weights decoupling network (HWDNet) to learn the shared discriminative orientation-invariant features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-sharing-weights-in-decoupling-feature</guid>
    </item>
    <item>
      <title>From Large Language Models to Knowledge Graphs for Biomarker Discovery in Cancer</title>
      <link>https://paperswithcode.com/paper/from-large-language-models-to-knowledge</link>
      <description><![CDATA[The KG is then enriched by harmonizing the ONO, controlled vocabularies, and additional biomedical concepts from scientific articles by employing BioBERT- and SciBERT-based information extraction (IE) methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-large-language-models-to-knowledge</guid>
    </item>
  </channel>
</rss>
