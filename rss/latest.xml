<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 23 Oct 2023 09:12:51 +0000</lastBuildDate>
    <item>
      <title>Is Weakly-supervised Action Segmentation Ready For Human-Robot Interaction? No, Let's Improve It With Action-union Learning</title>
      <link>https://paperswithcode.com/paper/is-weakly-supervised-action-segmentation</link>
      <description><![CDATA[To alleviate this issue, we proposed a novel learning pattern in our training stage, which maximizes the probability of action union of surrounding timestamps for unlabeled frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-weakly-supervised-action-segmentation</guid>
    </item>
    <item>
      <title>SplitGNN: Spectral Graph Neural Network for Fraud Detection against Heterophily</title>
      <link>https://paperswithcode.com/paper/splitgnn-spectral-graph-neural-network-for</link>
      <description><![CDATA[However, researches on addressing the heterophily problem in the spectral domain are still limited due to a lack of understanding of spectral energy distribution in graphs with heterophily.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/splitgnn-spectral-graph-neural-network-for</guid>
    </item>
    <item>
      <title>ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction</title>
      <link>https://paperswithcode.com/paper/relm-leveraging-language-models-for-enhanced</link>
      <description><![CDATA[Predicting chemical reactions, a fundamental challenge in chemistry, involves forecasting the resulting products from a given reaction process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relm-leveraging-language-models-for-enhanced</guid>
    </item>
    <item>
      <title>Calibrating Neural Simulation-Based Inference with Differentiable Coverage Probability</title>
      <link>https://paperswithcode.com/paper/calibrating-neural-simulation-based-inference</link>
      <description><![CDATA[Bayesian inference allows expressing the uncertainty of posterior belief under a probabilistic model given prior information and the likelihood of the evidence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/calibrating-neural-simulation-based-inference</guid>
    </item>
    <item>
      <title>ScaleLong: Towards More Stable Training of Diffusion Model via Scaling Network Long Skip Connection</title>
      <link>https://paperswithcode.com/paper/scalelong-towards-more-stable-training-of</link>
      <description><![CDATA[Besides, we also observe the theoretical benefits of the LSC coefficient scaling of UNet in the stableness of hidden features and gradient and also robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalelong-towards-more-stable-training-of</guid>
    </item>
    <item>
      <title>Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning</title>
      <link>https://paperswithcode.com/paper/self-prompted-chain-of-thought-on-large</link>
      <description><![CDATA[To further extend this task, we officially introduce open-domain multi-hop reasoning (ODMR) by answering multi-hop questions with explicit reasoning steps in open-domain setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-prompted-chain-of-thought-on-large</guid>
    </item>
    <item>
      <title>Improving Cross-Lingual Transfer through Subtree-Aware Word Reordering</title>
      <link>https://paperswithcode.com/paper/improving-cross-lingual-transfer-through</link>
      <description><![CDATA[Despite the impressive growth of the abilities of multilingual language models, such as XLM-R and mT5, it has been shown that they still face difficulties when tackling typologically-distant languages, particularly in the low-resource setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-cross-lingual-transfer-through</guid>
    </item>
    <item>
      <title>Explaining Interactions Between Text Spans</title>
      <link>https://paperswithcode.com/paper/explaining-interactions-between-text-spans</link>
      <description><![CDATA[Reasoning over spans of tokens from different parts of the input is essential for natural language understanding (NLU) tasks such as fact-checking (FC), machine reading comprehension (MRC) or natural language inference (NLI).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explaining-interactions-between-text-spans</guid>
    </item>
    <item>
      <title>Towards Understanding Sycophancy in Language Models</title>
      <link>https://paperswithcode.com/paper/towards-understanding-sycophancy-in-language</link>
      <description><![CDATA[However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-understanding-sycophancy-in-language</guid>
    </item>
    <item>
      <title>Unraveling the Enigma of Double Descent: An In-depth Analysis through the Lens of Learned Feature Space</title>
      <link>https://paperswithcode.com/paper/unraveling-the-enigma-of-double-descent-an-in</link>
      <description><![CDATA[Double descent presents a counter-intuitive aspect within the machine learning domain, and researchers have observed its manifestation in various models and tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unraveling-the-enigma-of-double-descent-an-in</guid>
    </item>
    <item>
      <title>CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages</title>
      <link>https://paperswithcode.com/paper/capivara-cost-efficient-approach-for</link>
      <description><![CDATA[This work introduces CAPIVARA, a cost-efficient framework designed to enhance the performance of multilingual CLIP models in low-resource languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/capivara-cost-efficient-approach-for</guid>
    </item>
    <item>
      <title>Tuna: Instruction Tuning using Feedback from Large Language Models</title>
      <link>https://paperswithcode.com/paper/tuna-instruction-tuning-using-feedback-from</link>
      <description><![CDATA[Furthermore, we apply probabilistic ranking and contextual ranking sequentially to the instruction-tuned LLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tuna-instruction-tuning-using-feedback-from</guid>
    </item>
    <item>
      <title>NurViD: A Large Expert-Level Video Database for Nursing Procedure Activity Understanding</title>
      <link>https://paperswithcode.com/paper/nurvid-a-large-expert-level-video-database</link>
      <description><![CDATA[The existing video datasets pose several limitations: 1) these datasets are small-scale in size to support comprehensive investigations of nursing activity; 2) they primarily focus on single procedures, lacking expert-level annotations for various nursing procedures and action steps; and 3) they lack temporally localized annotations, which prevents the effective localization of targeted actions within longer video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nurvid-a-large-expert-level-video-database</guid>
    </item>
    <item>
      <title>Bridging Information-Theoretic and Geometric Compression in Language Models</title>
      <link>https://paperswithcode.com/paper/bridging-information-theoretic-and-geometric</link>
      <description><![CDATA[For a language model (LM) to faithfully model human language, it must compress vast, potentially infinite information into relatively few dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridging-information-theoretic-and-geometric</guid>
    </item>
    <item>
      <title>Towards General Error Diagnosis via Behavioral Testing in Machine Translation</title>
      <link>https://paperswithcode.com/paper/towards-general-error-diagnosis-via</link>
      <description><![CDATA[Behavioral testing offers a crucial means of diagnosing linguistic errors and assessing capabilities of NLP models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-general-error-diagnosis-via</guid>
    </item>
    <item>
      <title>Information Value: Measuring Utterance Predictability as Distance from Plausible Alternatives</title>
      <link>https://paperswithcode.com/paper/information-value-measuring-utterance</link>
      <description><![CDATA[We present information value, a measure which quantifies the predictability of an utterance relative to a set of plausible alternatives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/information-value-measuring-utterance</guid>
    </item>
    <item>
      <title>Beyond Hard Samples: Robust and Effective Grammatical Error Correction with Cycle Self-Augmenting</title>
      <link>https://paperswithcode.com/paper/beyond-hard-samples-robust-and-effective</link>
      <description><![CDATA[By leveraging the augmenting data from the GEC models themselves in the post-training process and introducing regularization data for cycle training, our proposed method can effectively improve the model robustness of well-trained GEC models with only a few more training epochs as an extra cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-hard-samples-robust-and-effective</guid>
    </item>
    <item>
      <title>POSQA: Probe the World Models of LLMs with Size Comparisons</title>
      <link>https://paperswithcode.com/paper/posqa-probe-the-world-models-of-llms-with</link>
      <description><![CDATA[Embodied language comprehension emphasizes that language understanding is not solely a matter of mental processing in the brain but also involves interactions with the physical and social environment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posqa-probe-the-world-models-of-llms-with</guid>
    </item>
    <item>
      <title>Arabic Dialect Identification under Scrutiny: Limitations of Single-label Classification</title>
      <link>https://paperswithcode.com/paper/arabic-dialect-identification-under-scrutiny</link>
      <description><![CDATA[Automatic Arabic Dialect Identification (ADI) of text has gained great popularity since it was introduced in the early 2010s.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/arabic-dialect-identification-under-scrutiny</guid>
    </item>
    <item>
      <title>MarineGPT: Unlocking Secrets of Ocean to the Public</title>
      <link>https://paperswithcode.com/paper/marinegpt-unlocking-secrets-of-ocean-to-the</link>
      <description><![CDATA[Large language models (LLMs), such as ChatGPT/GPT-4, have proven to be powerful tools in promoting the user experience as an AI assistant.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/marinegpt-unlocking-secrets-of-ocean-to-the</guid>
    </item>
    <item>
      <title>Benchmarking and Improving Text-to-SQL Generation under Ambiguity</title>
      <link>https://paperswithcode.com/paper/benchmarking-and-improving-text-to-sql</link>
      <description><![CDATA[Research in Text-to-SQL conversion has been largely benchmarked against datasets where each text query corresponds to one correct SQL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-and-improving-text-to-sql</guid>
    </item>
    <item>
      <title>On Synthetic Data for Back Translation</title>
      <link>https://paperswithcode.com/paper/on-synthetic-data-for-back-translation-2</link>
      <description><![CDATA[Back translation (BT) is one of the most significant technologies in NMT research fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-synthetic-data-for-back-translation-2</guid>
    </item>
    <item>
      <title>A Diachronic Perspective on User Trust in AI under Uncertainty</title>
      <link>https://paperswithcode.com/paper/a-diachronic-perspective-on-user-trust-in-ai</link>
      <description><![CDATA[In a human-AI collaboration, users build a mental model of the AI system based on its reliability and how it presents its decision, e. g. its presentation of system confidence and an explanation of the output.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-diachronic-perspective-on-user-trust-in-ai</guid>
    </item>
    <item>
      <title>Improving Question Generation with Multi-level Content Planning</title>
      <link>https://paperswithcode.com/paper/improving-question-generation-with-multi</link>
      <description><![CDATA[Previous studies have suggested that key phrase selection is essential for question generation (QG), yet it is still challenging to connect such disjointed phrases into meaningful questions, particularly for long context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-question-generation-with-multi</guid>
    </item>
    <item>
      <title>StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models</title>
      <link>https://paperswithcode.com/paper/stereomap-quantifying-the-awareness-of-human</link>
      <description><![CDATA[Based on the SCM theory, StereoMap maps LLMs' perceptions of social groups (defined by socio-demographic features) using the dimensions of Warmth and Competence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stereomap-quantifying-the-awareness-of-human</guid>
    </item>
    <item>
      <title>BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues</title>
      <link>https://paperswithcode.com/paper/botchat-evaluating-llms-capabilities-of</link>
      <description><![CDATA[In contrast, other LLMs struggle to generate multi-turn dialogues of satisfactory quality due to poor instruction-following capability, tendency to generate lengthy utterances, or limited general capability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/botchat-evaluating-llms-capabilities-of</guid>
    </item>
    <item>
      <title>Coarse-to-Fine Dual Encoders are Better Frame Identification Learners</title>
      <link>https://paperswithcode.com/paper/coarse-to-fine-dual-encoders-are-better-frame</link>
      <description><![CDATA[Recent researches measure the similarity or matching score between targets and candidate frames by modeling frame definitions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coarse-to-fine-dual-encoders-are-better-frame</guid>
    </item>
    <item>
      <title>FLEE-GNN: A Federated Learning System for Edge-Enhanced Graph Neural Network in Analyzing Geospatial Resilience of Multicommodity Food Flows</title>
      <link>https://paperswithcode.com/paper/flee-gnn-a-federated-learning-system-for-edge</link>
      <description><![CDATA[This paper proposes FLEE-GNN, a novel Federated Learning System for Edge-Enhanced Graph Neural Network, designed to overcome these challenges and enhance the analysis of geospatial resilience of multicommodity food flow network, which is one type of spatial networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flee-gnn-a-federated-learning-system-for-edge</guid>
    </item>
    <item>
      <title>Unified Pretraining for Recommendation via Task Hypergraphs</title>
      <link>https://paperswithcode.com/paper/unified-pretraining-for-recommendation-via</link>
      <description><![CDATA[On the other hand, pretraining and finetuning on the same dataset leads to a high risk of overfitting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-pretraining-for-recommendation-via</guid>
    </item>
    <item>
      <title>CylinderTag: An Accurate and Flexible Marker for Cylinder-Shape Objects Pose Estimation Based on Projective Invariants</title>
      <link>https://paperswithcode.com/paper/cylindertag-an-accurate-and-flexible-marker</link>
      <description><![CDATA[Experimental results demonstrate that the CylinderTag is a highly promising visual marker for use on cylindrical-like surfaces, thus offering important guidance for future research on high-precision visual localization of cylinder-shaped objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cylindertag-an-accurate-and-flexible-marker</guid>
    </item>
    <item>
      <title>DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model Statistics</title>
      <link>https://paperswithcode.com/paper/dpm-solver-v3-improved-diffusion-ode-solver</link>
      <description><![CDATA[In this work, we propose a novel formulation towards the optimal parameterization during sampling that minimizes the first-order discretization error of the ODE solution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dpm-solver-v3-improved-diffusion-ode-solver</guid>
    </item>
    <item>
      <title>Zone Evaluation: Revealing Spatial Bias in Object Detection</title>
      <link>https://paperswithcode.com/paper/zone-evaluation-revealing-spatial-bias-in</link>
      <description><![CDATA[A fundamental limitation of object detectors is that they suffer from "spatial bias", and in particular perform less satisfactorily when detecting objects near image borders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zone-evaluation-revealing-spatial-bias-in</guid>
    </item>
    <item>
      <title>What you see is what you get: Experience ranking with deep neural dataset-to-dataset similarity for topological localisation</title>
      <link>https://paperswithcode.com/paper/what-you-see-is-what-you-get-experience</link>
      <description><![CDATA[In the case of localisation, important dataset differences impacting performance are modes of appearance change, including weather, lighting, and season.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-you-see-is-what-you-get-experience</guid>
    </item>
    <item>
      <title>Optimizing Retrieval-augmented Reader Models via Token Elimination</title>
      <link>https://paperswithcode.com/paper/optimizing-retrieval-augmented-reader-models</link>
      <description><![CDATA[Fusion-in-Decoder (FiD) is an effective retrieval-augmented language model applied across a variety of open-domain tasks, such as question answering, fact checking, etc.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimizing-retrieval-augmented-reader-models</guid>
    </item>
    <item>
      <title>Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models</title>
      <link>https://paperswithcode.com/paper/let-s-synthesize-step-by-step-iterative</link>
      <description><![CDATA[*Data Synthesis* is a promising way to train a small model with very little labeled data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-s-synthesize-step-by-step-iterative</guid>
    </item>
    <item>
      <title>Automatic Unit Test Data Generation and Actor-Critic Reinforcement Learning for Code Synthesis</title>
      <link>https://paperswithcode.com/paper/automatic-unit-test-data-generation-and-actor</link>
      <description><![CDATA[The advent of large pre-trained language models in the domain of Code Synthesis has shown remarkable performance on various benchmarks, treating the problem of Code Generation in a fashion similar to Natural Language Generation, trained with a Language Modelling (LM) objective.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automatic-unit-test-data-generation-and-actor</guid>
    </item>
    <item>
      <title>EarlyBird: Early-Fusion for Multi-View Tracking in the Bird's Eye View</title>
      <link>https://paperswithcode.com/paper/earlybird-early-fusion-for-multi-view</link>
      <description><![CDATA[Most current approaches in multi-view tracking perform the detection and tracking task in each view and use graph-based approaches to perform the association of the pedestrian across each view.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/earlybird-early-fusion-for-multi-view</guid>
    </item>
    <item>
      <title>Contrastive Prefence Learning: Learning from Human Feedback without RL</title>
      <link>https://paperswithcode.com/paper/contrastive-prefence-learning-learning-from</link>
      <description><![CDATA[Thus, learning a reward function from feedback is not only based on a flawed assumption of human preference, but also leads to unwieldy optimization challenges that stem from policy gradients or bootstrapping in the RL phase.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-prefence-learning-learning-from</guid>
    </item>
    <item>
      <title>SALMONN: Towards Generic Hearing Abilities for Large Language Models</title>
      <link>https://paperswithcode.com/paper/salmonn-towards-generic-hearing-abilities-for</link>
      <description><![CDATA[Hearing is arguably an essential ability of artificial intelligence (AI) agents in the physical world, which refers to the perception and understanding of general auditory information consisting of at least three types of sounds: speech, audio events, and music.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/salmonn-towards-generic-hearing-abilities-for</guid>
    </item>
    <item>
      <title>Skin Lesion Segmentation Improved by Transformer-based Networks with Inter-scale Dependency Modeling</title>
      <link>https://paperswithcode.com/paper/skin-lesion-segmentation-improved-by</link>
      <description><![CDATA[As a result, we propose a U-shaped hierarchical Transformer-based structure for skin lesion segmentation and an Inter-scale Context Fusion (ISCF) method that uses attention correlations in each stage of the encoder to adaptively combine the contexts from each stage to mitigate semantic gaps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/skin-lesion-segmentation-improved-by</guid>
    </item>
    <item>
      <title>MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark</title>
      <link>https://paperswithcode.com/paper/multitude-large-scale-multilingual-machine</link>
      <description><![CDATA[There is a lack of research into capabilities of recent LLMs to generate convincing text in languages other than English and into performance of detectors of machine-generated text in multilingual settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multitude-large-scale-multilingual-machine</guid>
    </item>
    <item>
      <title>MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model</title>
      <link>https://paperswithcode.com/paper/moqagpt-zero-shot-multi-modal-open-domain</link>
      <description><![CDATA[To enable LLMs to tackle the task in a zero-shot manner, we introduce MoqaGPT, a straightforward and flexible framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moqagpt-zero-shot-multi-modal-open-domain</guid>
    </item>
    <item>
      <title>Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking</title>
      <link>https://paperswithcode.com/paper/open-source-large-language-models-are-strong</link>
      <description><![CDATA[In the field of information retrieval, Query Likelihood Models (QLMs) rank documents based on the probability of generating the query given the content of a document.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-source-large-language-models-are-strong</guid>
    </item>
    <item>
      <title>A Quality-based Syntactic Template Retriever for Syntactically-controlled Paraphrase Generation</title>
      <link>https://paperswithcode.com/paper/a-quality-based-syntactic-template-retriever</link>
      <description><![CDATA[Furthermore, for situations requiring multiple paraphrases for each source sentence, we design a Diverse Templates Search (DTS) algorithm, which can enhance the diversity between paraphrases without sacrificing quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-quality-based-syntactic-template-retriever</guid>
    </item>
    <item>
      <title>Deep Reinforcement Learning-based Intelligent Traffic Signal Controls with Optimized CO2 emissions</title>
      <link>https://paperswithcode.com/paper/deep-reinforcement-learning-based-intelligent-2</link>
      <description><![CDATA[Nowadays, transportation networks face the challenge of sub-optimal control policies that can have adverse effects on human health, the environment, and contribute to traffic congestion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-reinforcement-learning-based-intelligent-2</guid>
    </item>
    <item>
      <title>Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding</title>
      <link>https://paperswithcode.com/paper/uncertainty-aware-parameter-efficient-self</link>
      <description><![CDATA[The recent success of large pre-trained language models (PLMs) heavily hinges on massive labeled data, which typically produces inferior performance in low-resource scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncertainty-aware-parameter-efficient-self</guid>
    </item>
    <item>
      <title>PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models</title>
      <link>https://paperswithcode.com/paper/poisonprompt-backdoor-attack-on-prompt-based</link>
      <description><![CDATA[Prompts have significantly improved the performance of pretrained Large Language Models (LLMs) on various downstream tasks recently, making them increasingly indispensable for a diverse range of LLM application scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poisonprompt-backdoor-attack-on-prompt-based</guid>
    </item>
    <item>
      <title>AgentTuning: Enabling Generalized Agent Abilities for LLMs</title>
      <link>https://paperswithcode.com/paper/agenttuning-enabling-generalized-agent</link>
      <description><![CDATA[Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of LLMs themselves without compromising their general abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agenttuning-enabling-generalized-agent</guid>
    </item>
    <item>
      <title>MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models</title>
      <link>https://paperswithcode.com/paper/maf-multi-aspect-feedback-for-improving</link>
      <description><![CDATA[Language Models (LMs) have shown impressive performance in various natural language tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maf-multi-aspect-feedback-for-improving</guid>
    </item>
    <item>
      <title>Do Language Models Learn about Legal Entity Types during Pretraining?</title>
      <link>https://paperswithcode.com/paper/do-language-models-learn-about-legal-entity</link>
      <description><![CDATA[Language Models (LMs) have proven their ability to acquire diverse linguistic knowledge during the pretraining phase, potentially serving as a valuable source of incidental supervision for downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-language-models-learn-about-legal-entity</guid>
    </item>
  </channel>
</rss>
