<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 03 Nov 2024 09:15:18 +0000</lastBuildDate>
    <item>
      <title>Enhancing Chess Reinforcement Learning with Graph Representation</title>
      <link>https://paperswithcode.com/paper/enhancing-chess-reinforcement-learning-with</link>
      <description><![CDATA[Our experiments, performed on smaller networks than the initial AlphaZero paper, show that this new architecture outperforms previous architectures with a similar number of parameters, being able to increase playing strength an order of magnitude faster.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-chess-reinforcement-learning-with</guid>
    </item>
    <item>
      <title>Reasons and Solutions for the Decline in Model Performance after Editing</title>
      <link>https://paperswithcode.com/paper/reasons-and-solutions-for-the-decline-in</link>
      <description><![CDATA[In order to investigate the reasons for the performance decline of the edited model and optimize the editing method, this work explores the underlying reasons from both data and model perspectives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reasons-and-solutions-for-the-decline-in</guid>
    </item>
    <item>
      <title>DiffBatt: A Diffusion Model for Battery Degradation Prediction and Synthesis</title>
      <link>https://paperswithcode.com/paper/diffbatt-a-diffusion-model-for-battery</link>
      <description><![CDATA[To address this challenge, we introduce a novel general-purpose model for battery degradation prediction and synthesis, DiffBatt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffbatt-a-diffusion-model-for-battery</guid>
    </item>
    <item>
      <title>Quantum Deep Equilibrium Models</title>
      <link>https://paperswithcode.com/paper/quantum-deep-equilibrium-models</link>
      <description><![CDATA[In this work, we present Quantum Deep Equilibrium Models (QDEQs): a training paradigm that learns parameters of a quantum machine learning model given by a PQC using DEQs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quantum-deep-equilibrium-models</guid>
    </item>
    <item>
      <title>GlotCC: An Open Broad-Coverage CommonCrawl Corpus and Pipeline for Minority Languages</title>
      <link>https://paperswithcode.com/paper/glotcc-an-open-broad-coverage-commoncrawl</link>
      <description><![CDATA[The need for large text corpora has increased with the advent of pretrained language models and, in particular, the discovery of scaling laws for these models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glotcc-an-open-broad-coverage-commoncrawl</guid>
    </item>
    <item>
      <title>Dynamical similarity analysis uniquely captures how computations develop in RNNs</title>
      <link>https://paperswithcode.com/paper/dynamical-similarity-analysis-uniquely</link>
      <description><![CDATA[Overall, we develop test cases that showcase how DSA's enhanced ability to detect dynamical motifs makes it highly effective for identifying ongoing computations in RNNs and revealing how networks learn tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamical-similarity-analysis-uniquely</guid>
    </item>
    <item>
      <title>DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion</title>
      <link>https://paperswithcode.com/paper/diffpano-scalable-and-consistent-text-to</link>
      <description><![CDATA[Then, we propose a novel text-driven panoramic generation framework, termed DiffPano, to achieve scalable, consistent, and diverse panoramic scene generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffpano-scalable-and-consistent-text-to</guid>
    </item>
    <item>
      <title>Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure</title>
      <link>https://paperswithcode.com/paper/understanding-generalizability-of-diffusion</link>
      <description><![CDATA[This discovery leads us to investigate the linear counterparts of the nonlinear diffusion models, which are a series of linear models trained to match the function mappings of the nonlinear diffusion denoisers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-generalizability-of-diffusion</guid>
    </item>
    <item>
      <title>GPT or BERT: why not both?</title>
      <link>https://paperswithcode.com/paper/gpt-or-bert-why-not-both</link>
      <description><![CDATA[This hybrid training objective results in a model that combines the strengths of both modeling paradigms within a single transformer stack: GPT-BERT can be transparently used like any standard causal or masked language model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-or-bert-why-not-both</guid>
    </item>
    <item>
      <title>A Non-Monolithic Policy Approach of Offline-to-Online Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/a-non-monolithic-policy-approach-of-offline</link>
      <description><![CDATA[An existing approach, Policy Expansion (PEX), utilizes a policy set composed of both policies without modifying the offline policy for exploration and learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-non-monolithic-policy-approach-of-offline</guid>
    </item>
    <item>
      <title>COSNet: A Novel Semantic Segmentation Network using Enhanced Boundaries in Cluttered Scenes</title>
      <link>https://paperswithcode.com/paper/cosnet-a-novel-semantic-segmentation-network</link>
      <description><![CDATA[Automated waste recycling aims to efficiently separate the recyclable objects from the waste by employing vision-based systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cosnet-a-novel-semantic-segmentation-network</guid>
    </item>
    <item>
      <title>Hamiltonian Monte Carlo Inference of Marginalized Linear Mixed-Effects Models</title>
      <link>https://paperswithcode.com/paper/hamiltonian-monte-carlo-inference-of</link>
      <description><![CDATA[A naive approach introduces cubic time operations within an inference algorithm like HMC, but we reduce the running time to linear using fast linear algebra techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hamiltonian-monte-carlo-inference-of</guid>
    </item>
    <item>
      <title>Show Me What and Where has Changed? Question Answering and Grounding for Remote Sensing Change Detection</title>
      <link>https://paperswithcode.com/paper/show-me-what-and-where-has-changed-question</link>
      <description><![CDATA[Remote sensing change detection aims to perceive changes occurring on the Earth's surface from remote sensing data in different periods, and feed these changes back to humans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/show-me-what-and-where-has-changed-question</guid>
    </item>
    <item>
      <title>Conformal prediction of circular data</title>
      <link>https://paperswithcode.com/paper/conformal-prediction-of-circular-data</link>
      <description><![CDATA[Split conformal prediction techniques are applied to regression problems with circular responses by introducing a suitable conformity score, leading to prediction sets with adaptive arc length and finite-sample coverage guarantees for any circular predictive model under exchangeable data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conformal-prediction-of-circular-data</guid>
    </item>
    <item>
      <title>AllClear: A Comprehensive Dataset and Benchmark for Cloud Removal in Satellite Imagery</title>
      <link>https://paperswithcode.com/paper/allclear-a-comprehensive-dataset-and</link>
      <description><![CDATA[Clouds in satellite imagery pose a significant challenge for downstream applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/allclear-a-comprehensive-dataset-and</guid>
    </item>
    <item>
      <title>Exploring Consistency in Graph Representations:from Graph Kernels to Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/exploring-consistency-in-graph</link>
      <description><![CDATA[Inspired by these findings, we conjecture that the consistency in the similarities of graph representations across GNN layers is crucial in capturing relational structures and enhancing graph classification performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-consistency-in-graph</guid>
    </item>
    <item>
      <title>What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective</title>
      <link>https://paperswithcode.com/paper/what-happened-in-llms-layers-when-trained-for</link>
      <description><![CDATA[We are specifically interested in how fast vs. slow thinking affects the layer-wise gradients, given the recent popularity of training LLMs on reasoning paths such as chain-of-thoughts (CoT) and process rewards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-happened-in-llms-layers-when-trained-for</guid>
    </item>
    <item>
      <title>Graph Learning for Numeric Planning</title>
      <link>https://paperswithcode.com/paper/graph-learning-for-numeric-planning</link>
      <description><![CDATA[Graph learning is naturally well suited for use in symbolic, object-centric planning due to its ability to exploit relational structures exhibited in planning domains and to take as input planning instances with arbitrary numbers of objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-learning-for-numeric-planning</guid>
    </item>
    <item>
      <title>EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching</title>
      <link>https://paperswithcode.com/paper/edt-an-efficient-diffusion-transformer</link>
      <description><![CDATA[Transformer-based Diffusion Probabilistic Models (DPMs) have shown more potential than CNN-based DPMs, yet their extensive computational requirements hinder widespread practical applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edt-an-efficient-diffusion-transformer</guid>
    </item>
    <item>
      <title>Zonal RL-RRT: Integrated RL-RRT Path Planning with Collision Probability and Zone Connectivity</title>
      <link>https://paperswithcode.com/paper/zonal-rl-rrt-integrated-rl-rrt-path-planning</link>
      <description><![CDATA[Path planning in high-dimensional spaces poses significant challenges, particularly in achieving both time efficiency and a fair success rate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zonal-rl-rrt-integrated-rl-rrt-path-planning</guid>
    </item>
    <item>
      <title>Approaches to human activity recognition via passive radar</title>
      <link>https://paperswithcode.com/paper/approaches-to-human-activity-recognition-via</link>
      <description><![CDATA[The thesis explores novel methods for Human Activity Recognition (HAR) using passive radar with a focus on non-intrusive Wi-Fi Channel State Information (CSI) data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/approaches-to-human-activity-recognition-via</guid>
    </item>
    <item>
      <title>RA-PbRL: Provably Efficient Risk-Aware Preference-Based Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/ra-pbrl-provably-efficient-risk-aware</link>
      <description><![CDATA[To address this, we explore and prove the applicability of two risk-aware objectives to PbRL: nested and static quantile risk objectives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ra-pbrl-provably-efficient-risk-aware</guid>
    </item>
    <item>
      <title>End-to-End Ontology Learning with Large Language Models</title>
      <link>https://paperswithcode.com/paper/end-to-end-ontology-learning-with-large</link>
      <description><![CDATA[Ontologies are useful for automatic machine processing of domain knowledge as they represent it in a structured format.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/end-to-end-ontology-learning-with-large</guid>
    </item>
    <item>
      <title>Wide Two-Layer Networks can Learn from Adversarial Perturbations</title>
      <link>https://paperswithcode.com/paper/wide-two-layer-networks-can-learn-from</link>
      <description><![CDATA[This hypothesis is supported by the success of perturbation learning, where classifiers trained solely on adversarial examples and the corresponding incorrect labels generalize well to correctly labeled test data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wide-two-layer-networks-can-learn-from</guid>
    </item>
    <item>
      <title>CaAdam: Improving Adam optimizer using connection aware methods</title>
      <link>https://paperswithcode.com/paper/caadam-improving-adam-optimizer-using</link>
      <description><![CDATA[We introduce a new method inspired by Adam that enhances convergence speed and achieves better loss function minima.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/caadam-improving-adam-optimizer-using</guid>
    </item>
    <item>
      <title>Diffusion Twigs with Loop Guidance for Conditional Graph Generation</title>
      <link>https://paperswithcode.com/paper/diffusion-twigs-with-loop-guidance-for</link>
      <description><![CDATA[We introduce a novel score-based diffusion framework named Twigs that incorporates multiple co-evolving flows for enriching conditional generation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-twigs-with-loop-guidance-for</guid>
    </item>
    <item>
      <title>No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images</title>
      <link>https://paperswithcode.com/paper/no-pose-no-problem-surprisingly-simple-3d</link>
      <description><![CDATA[We utilize the reconstructed 3D Gaussians for novel view synthesis and pose estimation tasks and propose a two-stage coarse-to-fine pipeline for accurate pose estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/no-pose-no-problem-surprisingly-simple-3d</guid>
    </item>
    <item>
      <title>CALE: Continuous Arcade Learning Environment</title>
      <link>https://paperswithcode.com/paper/cale-continuous-arcade-learning-environment</link>
      <description><![CDATA[We introduce the Continuous Arcade Learning Environment (CALE), an extension of the well-known Arcade Learning Environment (ALE) [Bellemare et al., 2013].]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cale-continuous-arcade-learning-environment</guid>
    </item>
    <item>
      <title>Neural Model Checking</title>
      <link>https://paperswithcode.com/paper/neural-model-checking</link>
      <description><![CDATA[Our new approach combines machine learning and symbolic reasoning by using neural networks as formal proof certificates for linear temporal logic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-model-checking</guid>
    </item>
    <item>
      <title>ImOV3D: Learning Open-Vocabulary Point Clouds 3D Object Detection from Only 2D Images</title>
      <link>https://paperswithcode.com/paper/imov3d-learning-open-vocabulary-point-clouds</link>
      <description><![CDATA[To address this challenge, we propose a novel framework ImOV3D to leverage pseudo multimodal representation containing both images and point clouds (PC) to close the modality gap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imov3d-learning-open-vocabulary-point-clouds</guid>
    </item>
    <item>
      <title>Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?</title>
      <link>https://paperswithcode.com/paper/can-language-models-perform-robust-reasoning</link>
      <description><![CDATA[Here, we propose the method of contrastive denoising with noisy chain-of-thought (CD-CoT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-language-models-perform-robust-reasoning</guid>
    </item>
    <item>
      <title>Chasing Better Deep Image Priors between Over- and Under-parameterization</title>
      <link>https://paperswithcode.com/paper/chasing-better-deep-image-priors-between-over</link>
      <description><![CDATA[Besides, we also extend LIP to compressive sensing image reconstruction, where a pre-trained GAN generator is used as the prior (in contrast to untrained DIP or deep decoder), and confirm its validity in this setting too.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chasing-better-deep-image-priors-between-over</guid>
    </item>
    <item>
      <title>What is Wrong with Perplexity for Long-context Language Modeling?</title>
      <link>https://paperswithcode.com/paper/what-is-wrong-with-perplexity-for-long</link>
      <description><![CDATA[To address this, we propose \textbf{LongPPL}, a novel metric that focuses on key tokens by employing a long-short context contrastive method to identify them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-is-wrong-with-perplexity-for-long</guid>
    </item>
    <item>
      <title>Enhancing Motion in Text-to-Video Generation with Decomposed Encoding and Conditioning</title>
      <link>https://paperswithcode.com/paper/enhancing-motion-in-text-to-video-generation</link>
      <description><![CDATA[This issue stems from the internal biases in text encoding, which overlooks motions, and inadequate conditioning mechanisms in T2V generation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-motion-in-text-to-video-generation</guid>
    </item>
    <item>
      <title>Parameter choices in HaarPSI for IQA with medical images</title>
      <link>https://paperswithcode.com/paper/parameter-choices-in-haarpsi-for-iqa-with</link>
      <description><![CDATA[We observe that they are more sensitive to the parameter choices than the employed natural images, and on the other hand both medical data sets lead to similar parameter values when optimized.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parameter-choices-in-haarpsi-for-iqa-with</guid>
    </item>
    <item>
      <title>Bayesian-guided Label Mapping for Visual Reprogramming</title>
      <link>https://paperswithcode.com/paper/bayesian-guided-label-mapping-for-visual</link>
      <description><![CDATA[When adapting the output interface, label mapping methods transform the pretrained labels to downstream labels by establishing a gradient-free one-to-one correspondence between the two sets of labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bayesian-guided-label-mapping-for-visual</guid>
    </item>
    <item>
      <title>TabM: Advancing Tabular Deep Learning with Parameter-Efficient Ensembling</title>
      <link>https://paperswithcode.com/paper/tabm-advancing-tabular-deep-learning-with</link>
      <description><![CDATA[Deep learning architectures for supervised learning on tabular data range from simple multilayer perceptrons (MLP) to sophisticated Transformers and retrieval-augmented methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tabm-advancing-tabular-deep-learning-with</guid>
    </item>
    <item>
      <title>On Positional Bias of Faithfulness for Long-form Summarization</title>
      <link>https://paperswithcode.com/paper/on-positional-bias-of-faithfulness-for-long</link>
      <description><![CDATA[Large Language Models (LLMs) often exhibit positional bias in long-context settings, under-attending to information in the middle of inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-positional-bias-of-faithfulness-for-long</guid>
    </item>
    <item>
      <title>Rethinking Inverse Reinforcement Learning: from Data Alignment to Task Alignment</title>
      <link>https://paperswithcode.com/paper/rethinking-inverse-reinforcement-learning</link>
      <description><![CDATA[Many imitation learning (IL) algorithms use inverse reinforcement learning (IRL) to infer a reward function that aligns with the demonstration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-inverse-reinforcement-learning</guid>
    </item>
    <item>
      <title>Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model</title>
      <link>https://paperswithcode.com/paper/text-difuse-an-interactive-multi-modal-image</link>
      <description><![CDATA[Second, by embedding the combination of the text and zero-shot location model into the diffusion fusion process, a text-controlled fusion re-modulation strategy is developed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-difuse-an-interactive-multi-modal-image</guid>
    </item>
    <item>
      <title>Disentangling Interactions and Dependencies in Feature Attribution</title>
      <link>https://paperswithcode.com/paper/disentangling-interactions-and-dependencies</link>
      <description><![CDATA[In this work, we derive DIP, a new mathematical decomposition of individual feature importance scores that disentangles three components: the standalone contribution and the contributions stemming from interactions and dependencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disentangling-interactions-and-dependencies</guid>
    </item>
    <item>
      <title>Disentangling Interpretable Factors with Supervised Independent Subspace Principal Component Analysis</title>
      <link>https://paperswithcode.com/paper/disentangling-interpretable-factors-with</link>
      <description><![CDATA[The success of machine learning models relies heavily on effectively representing high-dimensional data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disentangling-interpretable-factors-with</guid>
    </item>
    <item>
      <title>Beyond Content Relevance: Evaluating Instruction Following in Retrieval Models</title>
      <link>https://paperswithcode.com/paper/beyond-content-relevance-evaluating</link>
      <description><![CDATA[Instruction-following capabilities in large language models (LLMs) have significantly progressed, enabling more complex user interactions through detailed prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-content-relevance-evaluating</guid>
    </item>
    <item>
      <title>DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios</title>
      <link>https://paperswithcode.com/paper/detectrl-benchmarking-llm-generated-text</link>
      <description><![CDATA[More importantly, we analyzed the potential impact of writing styles, model types, attack methods, the text lengths, and real-world human writing factors on different types of detectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detectrl-benchmarking-llm-generated-text</guid>
    </item>
    <item>
      <title>Failure Modes of LLMs for Causal Reasoning on Narratives</title>
      <link>https://paperswithcode.com/paper/failure-modes-of-llms-for-causal-reasoning-on</link>
      <description><![CDATA[We find that even state-of-the-art language models rely on unreliable shortcuts, both in terms of the narrative presentation and their parametric knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/failure-modes-of-llms-for-causal-reasoning-on</guid>
    </item>
    <item>
      <title>Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing</title>
      <link>https://paperswithcode.com/paper/leveraging-large-language-models-for-code</link>
      <description><![CDATA[The emergence of foundational models and generative artificial intelligence (GenAI) is poised to transform productivity in scientific computing, especially in code development, refactoring, and translating from one programming language to another.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-large-language-models-for-code</guid>
    </item>
    <item>
      <title>Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs</title>
      <link>https://paperswithcode.com/paper/plan-on-graph-self-correcting-adaptive</link>
      <description><![CDATA[To address these limitations, we propose a novel self-correcting adaptive planning paradigm for KG-augmented LLM named Plan-on-Graph (PoG), which first decomposes the question into several sub-objectives and then repeats the process of adaptively exploring reasoning paths, updating memory, and reflecting on the need to self-correct erroneous reasoning paths until arriving at the answer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plan-on-graph-self-correcting-adaptive</guid>
    </item>
    <item>
      <title>EZ-HOI: VLM Adaptation via Guided Prompt Learning for Zero-Shot HOI Detection</title>
      <link>https://paperswithcode.com/paper/ez-hoi-vlm-adaptation-via-guided-prompt</link>
      <description><![CDATA[However, fine-tuning on task-specific datasets often leads to overfitting to seen classes and suboptimal performance on unseen classes, due to the absence of unseen class labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ez-hoi-vlm-adaptation-via-guided-prompt</guid>
    </item>
    <item>
      <title>Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-gradients-as-vitamin</link>
      <description><![CDATA[As suggested by our analysis, in our experiments, we hence find that simply adding TD3 gradients to the finetuning process of ODT effectively improves the online finetuning performance of ODT, especially if ODT is pretrained with low-reward offline data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-gradients-as-vitamin</guid>
    </item>
    <item>
      <title>Instruction-Tuning Llama-3-8B Excels in City-Scale Mobility Prediction</title>
      <link>https://paperswithcode.com/paper/instruction-tuning-llama-3-8b-excels-in-city</link>
      <description><![CDATA[Human mobility prediction plays a critical role in applications such as disaster response, urban planning, and epidemic forecasting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instruction-tuning-llama-3-8b-excels-in-city</guid>
    </item>
  </channel>
</rss>
