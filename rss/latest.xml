<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 09 Jul 2024 09:14:20 +0000</lastBuildDate>
    <item>
      <title>Stranger Danger! Identifying and Avoiding Unpredictable Pedestrians in RL-based Social Robot Navigation</title>
      <link>https://paperswithcode.com/paper/stranger-danger-identifying-and-avoiding</link>
      <description><![CDATA[Reinforcement learning (RL) methods for social robot navigation show great success navigating robots through large crowds of people, but the performance of these learning-based methods tends to degrade in particularly challenging or unfamiliar situations due to the models' dependency on representative training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stranger-danger-identifying-and-avoiding</guid>
    </item>
    <item>
      <title>Fast and Continual Knowledge Graph Embedding via Incremental LoRA</title>
      <link>https://paperswithcode.com/paper/fast-and-continual-knowledge-graph-embedding</link>
      <description><![CDATA[To address this issue, we propose a fast CKGE framework (\model), incorporating an incremental low-rank adapter (\mec) mechanism to efficiently acquire new knowledge while preserving old knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-and-continual-knowledge-graph-embedding</guid>
    </item>
    <item>
      <title>WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering</title>
      <link>https://paperswithcode.com/paper/wsi-vqa-interpreting-whole-slide-images-by</link>
      <description><![CDATA[Abundant experience is required for pathologists to achieve accurate and reliable diagnostic results of whole slide images (WSI).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wsi-vqa-interpreting-whole-slide-images-by</guid>
    </item>
    <item>
      <title>iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement</title>
      <link>https://paperswithcode.com/paper/illm-tsc-integration-reinforcement-learning</link>
      <description><![CDATA[However, the existing RL-based TSC system often overlooks imperfect observations caused by degraded communication, such as packet loss, delays, and noise, as well as rare real-life events not included in the reward function, such as unconsidered emergency vehicles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/illm-tsc-integration-reinforcement-learning</guid>
    </item>
    <item>
      <title>LGRNet: Local-Global Reciprocal Network for Uterine Fibroid Segmentation in Ultrasound Videos</title>
      <link>https://paperswithcode.com/paper/lgrnet-local-global-reciprocal-network-for</link>
      <description><![CDATA[To this end, we collect and annotate the first ultrasound video dataset with 100 videos for uterine fibroid segmentation (UFUV).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lgrnet-local-global-reciprocal-network-for</guid>
    </item>
    <item>
      <title>AdaPI: Facilitating DNN Model Adaptivity for Efficient Private Inference in Edge Computing</title>
      <link>https://paperswithcode.com/paper/adapi-facilitating-dnn-model-adaptivity-for</link>
      <description><![CDATA[Private inference (PI) has emerged as a promising solution to execute computations on encrypted data, safeguarding user privacy and model parameters in edge computing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adapi-facilitating-dnn-model-adaptivity-for</guid>
    </item>
    <item>
      <title>From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty</title>
      <link>https://paperswithcode.com/paper/from-loops-to-oops-fallback-behaviors-of</link>
      <description><![CDATA[Our experiments reveal a clear and consistent ordering of fallback behaviors, across all these axes: the more advanced an LLM is (i. e., trained on more tokens, has more parameters, or instruction-tuned), its fallback behavior shifts from sequence repetitions, to degenerate text, and then to hallucinations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-loops-to-oops-fallback-behaviors-of</guid>
    </item>
    <item>
      <title>4D Contrastive Superflows are Dense 3D Representation Learners</title>
      <link>https://paperswithcode.com/paper/4d-contrastive-superflows-are-dense-3d</link>
      <description><![CDATA[In the realm of autonomous driving, accurate 3D perception is the foundation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/4d-contrastive-superflows-are-dense-3d</guid>
    </item>
    <item>
      <title>LDGCN: An Edge-End Lightweight Dual GCN Based on Single-Channel EEG for Driver Drowsiness Monitoring</title>
      <link>https://paperswithcode.com/paper/ldgcn-an-edge-end-lightweight-dual-gcn-based</link>
      <description><![CDATA[However, the existing single-channel EEG adjacency graph construction process lacks interpretability, which hinders the ability of GCNs to effectively extract adjacency graph features, thus affecting the performance of drowsiness monitoring.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ldgcn-an-edge-end-lightweight-dual-gcn-based</guid>
    </item>
    <item>
      <title>MTL-Split: Multi-Task Learning for Edge Devices using Split Computing</title>
      <link>https://paperswithcode.com/paper/mtl-split-multi-task-learning-for-edge</link>
      <description><![CDATA[However, how to partition such a multi-tasking DNN to be deployed within a SC framework has not been sufficiently studied.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mtl-split-multi-task-learning-for-edge</guid>
    </item>
    <item>
      <title>Gait Patterns as Biomarkers: A Video-Based Approach for Classifying Scoliosis</title>
      <link>https://paperswithcode.com/paper/gait-patterns-as-biomarkers-a-video-based</link>
      <description><![CDATA[Scoliosis poses significant diagnostic challenges, particularly in adolescents, where early detection is crucial for effective treatment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gait-patterns-as-biomarkers-a-video-based</guid>
    </item>
    <item>
      <title>Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation</title>
      <link>https://paperswithcode.com/paper/sub-sa-strengthen-in-context-learning-via</link>
      <description><![CDATA[In Sub-SA, we design a submodular function that facilitates effective subset selection for annotation and demonstrates the characteristics of monotonically and submodularity from the theoretical perspective.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sub-sa-strengthen-in-context-learning-via</guid>
    </item>
    <item>
      <title>BEVWorld: A Multimodal World Model for Autonomous Driving via Unified BEV Latent Space</title>
      <link>https://paperswithcode.com/paper/bevworld-a-multimodal-world-model-for</link>
      <description><![CDATA[The world model consists of two parts: the multi-modal tokenizer and the latent BEV sequence diffusion model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bevworld-a-multimodal-world-model-for</guid>
    </item>
    <item>
      <title>Fostering Trust and Quantifying Value of AI and ML</title>
      <link>https://paperswithcode.com/paper/fostering-trust-and-quantifying-value-of-ai</link>
      <description><![CDATA[Producing ever more trustworthy machine learning inferences is a path to increase the value of products (i. e., increased trust in the results) and to engage in conversations with users to gather feedback to improve products.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fostering-trust-and-quantifying-value-of-ai</guid>
    </item>
    <item>
      <title>Focus on the Whole Character: Discriminative Character Modeling for Scene Text Recognition</title>
      <link>https://paperswithcode.com/paper/focus-on-the-whole-character-discriminative</link>
      <description><![CDATA[To address the above issues, we propose a novel method that enriches the character features to enhance the discriminability of characters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/focus-on-the-whole-character-discriminative</guid>
    </item>
    <item>
      <title>SLIM: Spuriousness Mitigation with Minimal Human Annotations</title>
      <link>https://paperswithcode.com/paper/slim-spuriousness-mitigation-with-minimal</link>
      <description><![CDATA[Recent studies highlight that deep learning models often learn spurious features mistakenly linked to labels, compromising their reliability in real-world scenarios where such correlations do not hold.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/slim-spuriousness-mitigation-with-minimal</guid>
    </item>
    <item>
      <title>LLMBox: A Comprehensive Library for Large Language Models</title>
      <link>https://paperswithcode.com/paper/llmbox-a-comprehensive-library-for-large</link>
      <description><![CDATA[To facilitate the research on large language models (LLMs), this paper presents a comprehensive and unified library, LLMBox, to ease the development, use, and evaluation of LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llmbox-a-comprehensive-library-for-large</guid>
    </item>
    <item>
      <title>Meme Analysis using LLM-based Contextual Information and U-net Encapsulated Transformer</title>
      <link>https://paperswithcode.com/paper/meme-analysis-using-llm-based-contextual</link>
      <description><![CDATA[A meme is social media content with which the creator tries to convey a certain idea in public via the internet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meme-analysis-using-llm-based-contextual</guid>
    </item>
    <item>
      <title>Mamba-FSCIL: Dynamic Adaptation with Selective State Space Model for Few-Shot Class-Incremental Learning</title>
      <link>https://paperswithcode.com/paper/mamba-fscil-dynamic-adaptation-with-selective</link>
      <description><![CDATA[The dual design enables the model to maintain the robust features of base classes, while adaptively learning distinctive feature shifts for novel classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mamba-fscil-dynamic-adaptation-with-selective</guid>
    </item>
    <item>
      <title>Nonrigid Reconstruction of Freehand Ultrasound without a Tracker</title>
      <link>https://paperswithcode.com/paper/nonrigid-reconstruction-of-freehand</link>
      <description><![CDATA[Motivated by a) the observed nonrigid deformation due to soft tissue motion during scanning, and b) the highly sensitive prediction of rigid transformation, this study investigates the methods and their benefits in predicting nonrigid transformations for reconstructing 3D US.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nonrigid-reconstruction-of-freehand</guid>
    </item>
    <item>
      <title>Pan-denoising: Guided Hyperspectral Image Denoising via Weighted Represent Coefficient Total Variation</title>
      <link>https://paperswithcode.com/paper/pan-denoising-guided-hyperspectral-image</link>
      <description><![CDATA[This paper introduces a novel paradigm for hyperspectral image (HSI) denoising, which is termed \textit{pan-denoising}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pan-denoising-guided-hyperspectral-image</guid>
    </item>
    <item>
      <title>HPFF: Hierarchical Locally Supervised Learning with Patch Feature Fusion</title>
      <link>https://paperswithcode.com/paper/hpff-hierarchical-locally-supervised-learning</link>
      <description><![CDATA[To overcome these limitations, we propose a novel model called HPFF that performs hierarchical locally supervised learning and patch-level feature computation on the auxiliary networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hpff-hierarchical-locally-supervised-learning</guid>
    </item>
    <item>
      <title>RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features</title>
      <link>https://paperswithcode.com/paper/radiomicsfill-mammo-synthetic-mammogram-mass</link>
      <description><![CDATA[This approach also allows for the incorporation of essential clinical variables, such as BI-RADS and breast density, alongside radiomics features as conditions for mass generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/radiomicsfill-mammo-synthetic-mammogram-mass</guid>
    </item>
    <item>
      <title>Transfer Learning with Self-Supervised Vision Transformers for Snake Identification</title>
      <link>https://paperswithcode.com/paper/transfer-learning-with-self-supervised-vision</link>
      <description><![CDATA[We present our approach for the SnakeCLEF 2024 competition to predict snake species from images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transfer-learning-with-self-supervised-vision</guid>
    </item>
    <item>
      <title>OSN: Infinite Representations of Dynamic 3D Scenes from Monocular Videos</title>
      <link>https://paperswithcode.com/paper/osn-infinite-representations-of-dynamic-3d</link>
      <description><![CDATA[It has long been challenging to recover the underlying dynamic 3D scene representations from a monocular RGB video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/osn-infinite-representations-of-dynamic-3d</guid>
    </item>
    <item>
      <title>How DNNs break the Curse of Dimensionality: Compositionality and Symmetry Learning</title>
      <link>https://paperswithcode.com/paper/how-dnns-break-the-curse-of-dimensionality</link>
      <description><![CDATA[We show that deep neural networks (DNNs) can efficiently learn any composition of functions with bounded $F_{1}$-norm, which allows DNNs to break the curse of dimensionality in ways that shallow networks cannot.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-dnns-break-the-curse-of-dimensionality</guid>
    </item>
    <item>
      <title>AID-AppEAL: Automatic Image Dataset and Algorithm for Content Appeal Enhancement and Assessment Labeling</title>
      <link>https://paperswithcode.com/paper/aid-appeal-automatic-image-dataset-and</link>
      <description><![CDATA[We propose Image Content Appeal Assessment (ICAA), a novel metric that quantifies the level of positive interest an image's content generates for viewers, such as the appeal of food in a photograph.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aid-appeal-automatic-image-dataset-and</guid>
    </item>
    <item>
      <title>Short-term Object Interaction Anticipation with Disentangled Object Detection @ Ego4D Short Term Object Interaction Anticipation Challenge</title>
      <link>https://paperswithcode.com/paper/short-term-object-interaction-anticipation</link>
      <description><![CDATA[Short-term object interaction anticipation is an important task in egocentric video analysis, including precise predictions of future interactions and their timings as well as the categories and positions of the involved active objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/short-term-object-interaction-anticipation</guid>
    </item>
    <item>
      <title>OpenCIL: Benchmarking Out-of-Distribution Detection in Class-Incremental Learning</title>
      <link>https://paperswithcode.com/paper/opencil-benchmarking-out-of-distribution</link>
      <description><![CDATA[Class incremental learning (CIL) aims to learn a model that can not only incrementally accommodate new classes, but also maintain the learned knowledge of old classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/opencil-benchmarking-out-of-distribution</guid>
    </item>
    <item>
      <title>KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions</title>
      <link>https://paperswithcode.com/paper/kg-fpq-evaluating-factuality-hallucination-in</link>
      <description><![CDATA[Recent studies have demonstrated that large language models (LLMs) are susceptible to being misled by false premise questions (FPQs), leading to errors in factual knowledge, know as factuality hallucination.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kg-fpq-evaluating-factuality-hallucination-in</guid>
    </item>
    <item>
      <title>FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging</title>
      <link>https://paperswithcode.com/paper/fedmrl-data-heterogeneity-aware-federated</link>
      <description><![CDATA[We assess our approach using two publicly available real-world medical datasets, and the results demonstrate that FedMRL significantly outperforms state-of-the-art techniques, showing its efficacy in addressing data heterogeneity in federated learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedmrl-data-heterogeneity-aware-federated</guid>
    </item>
    <item>
      <title>Momentum Auxiliary Network for Supervised Local Learning</title>
      <link>https://paperswithcode.com/paper/momentum-auxiliary-network-for-supervised</link>
      <description><![CDATA[Supervised local learning, which segments the network into multiple local blocks updated by independent auxiliary networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/momentum-auxiliary-network-for-supervised</guid>
    </item>
    <item>
      <title>C2C: Component-to-Composition Learning for Zero-Shot Compositional Action Recognition</title>
      <link>https://paperswithcode.com/paper/c2c-component-to-composition-learning-for</link>
      <description><![CDATA[For evaluating the task, we construct a new benchmark, Something-composition (Sth-com), based on the widely used Something-Something V2 dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/c2c-component-to-composition-learning-for</guid>
    </item>
    <item>
      <title>Structural Generalization in Autonomous Cyber Incident Response with Message-Passing Neural Networks and Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/structural-generalization-in-autonomous-cyber</link>
      <description><![CDATA[We believe that agents for automated incident response based on machine learning need to handle changes in network structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structural-generalization-in-autonomous-cyber</guid>
    </item>
    <item>
      <title>The Dynamic Net Architecture: Learning Robust and Holistic Visual Representations Through Self-Organizing Networks</title>
      <link>https://paperswithcode.com/paper/the-dynamic-net-architecture-learning-robust</link>
      <description><![CDATA[We present a novel intelligent-system architecture called "Dynamic Net Architecture" (DNA) that relies on recurrence-stabilized networks and discuss it in application to vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-dynamic-net-architecture-learning-robust</guid>
    </item>
    <item>
      <title>Fine-Grained Multi-View Hand Reconstruction Using Inverse Rendering</title>
      <link>https://paperswithcode.com/paper/fine-grained-multi-view-hand-reconstruction</link>
      <description><![CDATA[Reconstructing high-fidelity hand models with intricate textures plays a crucial role in enhancing human-object interaction and advancing real-world applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-grained-multi-view-hand-reconstruction</guid>
    </item>
    <item>
      <title>Minutes to Seconds: Speeded-up DDPM-based Image Inpainting with Coarse-to-Fine Sampling</title>
      <link>https://paperswithcode.com/paper/minutes-to-seconds-speeded-up-ddpm-based</link>
      <description><![CDATA[Second, we introduce a skip-step sampling scheme of Denoising Diffusion Implicit Models (DDIM) for the denoising process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minutes-to-seconds-speeded-up-ddpm-based</guid>
    </item>
    <item>
      <title>Wavelet Convolutions for Large Receptive Fields</title>
      <link>https://paperswithcode.com/paper/wavelet-convolutions-for-large-receptive</link>
      <description><![CDATA[In recent years, there have been attempts to increase the kernel size of Convolutional Neural Nets (CNNs) to mimic the global receptive field of Vision Transformers' (ViTs) self-attention blocks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wavelet-convolutions-for-large-receptive</guid>
    </item>
    <item>
      <title>ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation</title>
      <link>https://paperswithcode.com/paper/anole-an-open-autoregressive-native-large</link>
      <description><![CDATA[Previous open-source large multimodal models (LMMs) have faced several limitations: (1) they often lack native integration, requiring adapters to align visual representations with pre-trained large language models (LLMs); (2) many are restricted to single-modal generation; (3) while some support multimodal generation, they rely on separate diffusion models for visual modeling and generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anole-an-open-autoregressive-native-large</guid>
    </item>
    <item>
      <title>PerlDiff: Controllable Street View Synthesis Using Perspective-Layout Diffusion Models</title>
      <link>https://paperswithcode.com/paper/perldiff-controllable-street-view-synthesis</link>
      <description><![CDATA[In this paper, we explore the integration of controlling information and introduce PerlDiff (Perspective-Layout Diffusion Models), a method for effective street view image generation that fully leverages perspective 3D geometric information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perldiff-controllable-street-view-synthesis</guid>
    </item>
    <item>
      <title>LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages</title>
      <link>https://paperswithcode.com/paper/llamax-scaling-linguistic-horizons-of-llm-by</link>
      <description><![CDATA[To address this, we dedicate 35, 000 A100-SXM4-80GB GPU hours in conducting extensive multilingual continual pre-training on the LLaMA series models, enabling translation support across more than 100 languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llamax-scaling-linguistic-horizons-of-llm-by</guid>
    </item>
    <item>
      <title>Mind the Interference: Retaining Pre-trained Knowledge in Parameter Efficient Continual Learning of Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/mind-the-interference-retaining-pre-trained</link>
      <description><![CDATA[To address this problem efficiently, we propose the Distribution-aware Interference-free Knowledge Integration (DIKI) framework, retaining pre-trained knowledge of VLMs from a perspective of avoiding information interference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mind-the-interference-retaining-pre-trained</guid>
    </item>
    <item>
      <title>See Further for Parameter Efficient Fine-tuning by Standing on the Shoulders of Decomposition</title>
      <link>https://paperswithcode.com/paper/see-further-for-parameter-efficient-fine</link>
      <description><![CDATA[The rapid expansion of large foundation models within the pre-training and fine-tuning framework has underscored that larger models often yield better results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/see-further-for-parameter-efficient-fine</guid>
    </item>
    <item>
      <title>Language Models Encode Collaborative Signals in Recommendation</title>
      <link>https://paperswithcode.com/paper/language-models-encode-collaborative-signals</link>
      <description><![CDATA[Recent studies empirically indicate that language models (LMs) encode rich world knowledge beyond mere semantics, attracting significant attention across various fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-encode-collaborative-signals</guid>
    </item>
    <item>
      <title>SCIPaD: Incorporating Spatial Clues into Unsupervised Pose-Depth Joint Learning</title>
      <link>https://paperswithcode.com/paper/scipad-incorporating-spatial-clues-into</link>
      <description><![CDATA[Specifically, a confidence-aware feature flow estimator is proposed to acquire 2D feature positional translations and their associated confidence levels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scipad-incorporating-spatial-clues-into</guid>
    </item>
    <item>
      <title>ElecBench: a Power Dispatch Evaluation Benchmark for Large Language Models</title>
      <link>https://paperswithcode.com/paper/elecbench-a-power-dispatch-evaluation</link>
      <description><![CDATA[In response to the urgent demand for grid stability and the complex challenges posed by renewable energy integration and electricity market dynamics, the power sector increasingly seeks innovative technological solutions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elecbench-a-power-dispatch-evaluation</guid>
    </item>
    <item>
      <title>HyperKAN: Kolmogorov-Arnold Networks make Hyperspectral Image Classificators Smarter</title>
      <link>https://paperswithcode.com/paper/hyperkan-kolmogorov-arnold-networks-make</link>
      <description><![CDATA[We modified seven different neural network architectures for hyperspectral image classification and observed a substantial improvement in the classification accuracy across all the networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyperkan-kolmogorov-arnold-networks-make</guid>
    </item>
    <item>
      <title>P2P: Part-to-Part Motion Cues Guide a Strong Tracking Framework for LiDAR Point Clouds</title>
      <link>https://paperswithcode.com/paper/p2p-part-to-part-motion-cues-guide-a-strong</link>
      <description><![CDATA[Moreover, under the same point-based representation, P2P-point outperforms the previous motion tracker M$^2$Track by \textbf{3. 3\%} and \textbf{6. 7\%} on the KITTI and NuScenes, while running at a considerably high speed of \textbf{107 Fps} on a single RTX3090 GPU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/p2p-part-to-part-motion-cues-guide-a-strong</guid>
    </item>
    <item>
      <title>Diffusion as Sound Propagation: Physics-inspired Model for Ultrasound Image Generation</title>
      <link>https://paperswithcode.com/paper/diffusion-as-sound-propagation-physics</link>
      <description><![CDATA[However, when it comes to ultrasound (US) imaging, the authenticity of generated data often diminishes due to the oversight of ultrasound physics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-as-sound-propagation-physics</guid>
    </item>
    <item>
      <title>SmurfCat at PAN 2024 TextDetox: Alignment of Multilingual Transformers for Text Detoxification</title>
      <link>https://paperswithcode.com/paper/smurfcat-at-pan-2024-textdetox-alignment-of</link>
      <description><![CDATA[This paper presents a solution for the Multilingual Text Detoxification task in the PAN-2024 competition of the SmurfCat team.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smurfcat-at-pan-2024-textdetox-alignment-of</guid>
    </item>
  </channel>
</rss>
