<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 08 Jan 2024 09:13:08 +0000</lastBuildDate>
    <item>
      <title>Unsupervised hard Negative Augmentation for contrastive learning</title>
      <link>https://paperswithcode.com/paper/unsupervised-hard-negative-augmentation-for</link>
      <description><![CDATA[We present Unsupervised hard Negative Augmentation (UNA), a method that generates synthetic negative instances based on the term frequency-inverse document frequency (TF-IDF) retrieval model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-hard-negative-augmentation-for</guid>
    </item>
    <item>
      <title>Location Aware Modular Biencoder for Tourism Question Answering</title>
      <link>https://paperswithcode.com/paper/location-aware-modular-biencoder-for-tourism</link>
      <description><![CDATA[To overcome this, we propose treating the QA task as a dense vector retrieval problem, where we encode questions and POIs separately and retrieve the most relevant POIs for a question by utilizing embedding space similarity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/location-aware-modular-biencoder-for-tourism</guid>
    </item>
    <item>
      <title>GridFormer: Point-Grid Transformer for Surface Reconstruction</title>
      <link>https://paperswithcode.com/paper/gridformer-point-grid-transformer-for-surface</link>
      <description><![CDATA[Our method maximizes the spatial expressiveness of grid features and maintains computational efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gridformer-point-grid-transformer-for-surface</guid>
    </item>
    <item>
      <title>Simulation-Based Inference with Quantile Regression</title>
      <link>https://paperswithcode.com/paper/simulation-based-inference-with-quantile</link>
      <description><![CDATA[We present Neural Quantile Estimation (NQE), a novel Simulation-Based Inference (SBI) method based on conditional quantile regression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simulation-based-inference-with-quantile</guid>
    </item>
    <item>
      <title>An Open and Comprehensive Pipeline for Unified Object Grounding and Detection</title>
      <link>https://paperswithcode.com/paper/an-open-and-comprehensive-pipeline-for</link>
      <description><![CDATA[Grounding-DINO is a state-of-the-art open-set detection model that tackles multiple vision tasks including Open-Vocabulary Detection (OVD), Phrase Grounding (PG), and Referring Expression Comprehension (REC).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-open-and-comprehensive-pipeline-for</guid>
    </item>
    <item>
      <title>Textron: Weakly Supervised Multilingual Text Detection Through Data Programming</title>
      <link>https://paperswithcode.com/paper/textron-weakly-supervised-multilingual-text</link>
      <description><![CDATA[In order to solve this problem, we propose TEXTRON, a Data Programming-based approach, where users can plug various text detection methods into a weak supervision-based learning framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textron-weakly-supervised-multilingual-text</guid>
    </item>
    <item>
      <title>TinyLlama: An Open-Source Small Language Model</title>
      <link>https://paperswithcode.com/paper/tinyllama-an-open-source-small-language-model</link>
      <description><![CDATA[We present TinyLlama, a compact 1. 1B language model pretrained on around 1 trillion tokens for approximately 3 epochs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tinyllama-an-open-source-small-language-model</guid>
    </item>
    <item>
      <title>DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models</title>
      <link>https://paperswithcode.com/paper/dcr-consistency-divide-conquer-reasoning-for</link>
      <description><![CDATA[Evaluating the quality and variability of text generated by Large Language Models (LLMs) poses a significant, yet unresolved research challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dcr-consistency-divide-conquer-reasoning-for</guid>
    </item>
    <item>
      <title>TR-DETR: Task-Reciprocal Transformer for Joint Moment Retrieval and Highlight Detection</title>
      <link>https://paperswithcode.com/paper/tr-detr-task-reciprocal-transformer-for-joint</link>
      <description><![CDATA[Finally, a task cooperation module is constructed to refine the retrieval pipeline and the highlight score prediction process by utilizing the reciprocity between MR and HD.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tr-detr-task-reciprocal-transformer-for-joint</guid>
    </item>
    <item>
      <title>Reassessing the Exon-Foldon correspondence using Frustration Analysis</title>
      <link>https://paperswithcode.com/paper/reassessing-the-exon-foldon-correspondence</link>
      <description><![CDATA[Protein folding and evolution are intimately linked phenomena.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reassessing-the-exon-foldon-correspondence</guid>
    </item>
    <item>
      <title>BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model</title>
      <link>https://paperswithcode.com/paper/ba-sam-scalable-bias-mode-attention-mask-for</link>
      <description><![CDATA[In this paper, we reformulate this issue as a length extrapolation problem, where token sequence length varies while maintaining a consistent patch size for images of different sizes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ba-sam-scalable-bias-mode-attention-mask-for</guid>
    </item>
    <item>
      <title>LLaMA Pro: Progressive LLaMA with Block Expansion</title>
      <link>https://paperswithcode.com/paper/llama-pro-progressive-llama-with-block</link>
      <description><![CDATA[Humans generally acquire new skills without compromising the old; however, the opposite holds for Large Language Models (LLMs), e. g., from LLaMA to CodeLLaMA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-pro-progressive-llama-with-block</guid>
    </item>
    <item>
      <title>Distillation-based fabric anomaly detection</title>
      <link>https://paperswithcode.com/paper/distillation-based-fabric-anomaly-detection</link>
      <description><![CDATA[Given the extensive variability in colors, textures, and defect types, fabric defect detection poses a complex and challenging problem in the field of patterned textures inspection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distillation-based-fabric-anomaly-detection</guid>
    </item>
    <item>
      <title>Leveraging SAM for Single-Source Domain Generalization in Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/leveraging-sam-for-single-source-domain</link>
      <description><![CDATA[Domain Generalization (DG) aims to reduce domain shifts between domains to achieve promising performance on the unseen target domain, which has been widely practiced in medical image segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-sam-for-single-source-domain</guid>
    </item>
    <item>
      <title>Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket</title>
      <link>https://paperswithcode.com/paper/spikformer-v2-join-the-high-accuracy-club-on</link>
      <description><![CDATA[To the best of our knowledge, this is the first time that the SNN achieves 80+% accuracy on ImageNet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spikformer-v2-join-the-high-accuracy-club-on</guid>
    </item>
    <item>
      <title>DiffusionEdge: Diffusion Probabilistic Model for Crisp Edge Detection</title>
      <link>https://paperswithcode.com/paper/diffusionedge-diffusion-probabilistic-model</link>
      <description><![CDATA[With the recent success of the diffusion probabilistic model (DPM), we found it is especially suitable for accurate and crisp edge detection since the denoising process is directly applied to the original image size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusionedge-diffusion-probabilistic-model</guid>
    </item>
    <item>
      <title>View-based Explanations for Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/view-based-explanations-for-graph-neural</link>
      <description><![CDATA[We propose GVEX, a novel paradigm that generates Graph Views for EXplanation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/view-based-explanations-for-graph-neural</guid>
    </item>
    <item>
      <title>A Robust Quantile Huber Loss With Interpretable Parameter Adjustment In Distributional Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/a-robust-quantile-huber-loss-with</link>
      <description><![CDATA[Distributional Reinforcement Learning (RL) estimates return distribution mainly by learning quantile values via minimizing the quantile Huber loss function, entailing a threshold parameter often selected heuristically or via hyperparameter search, which may not generalize well and can be suboptimal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-robust-quantile-huber-loss-with</guid>
    </item>
    <item>
      <title>Explore Human Parsing Modality for Action Recognition</title>
      <link>https://paperswithcode.com/paper/explore-human-parsing-modality-for-action-1</link>
      <description><![CDATA[Multimodal-based action recognition methods have achieved high success using pose and RGB modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explore-human-parsing-modality-for-action-1</guid>
    </item>
    <item>
      <title>ClassWise-SAM-Adapter: Parameter Efficient Fine-tuning Adapts Segment Anything to SAR Domain for Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/classwise-sam-adapter-parameter-efficient</link>
      <description><![CDATA[Compared to conventional state-of-the-art semantic segmentation algorithms by extensive experiments, CWSAM showcases enhanced performance with fewer computing resources, highlighting the potential of leveraging foundational models like SAM for specific downstream tasks in the SAR domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/classwise-sam-adapter-parameter-efficient</guid>
    </item>
    <item>
      <title>Graph Neural Networks for Tabular Data Learning: A Survey with Taxonomy and Directions</title>
      <link>https://paperswithcode.com/paper/graph-neural-networks-for-tabular-data</link>
      <description><![CDATA[In this survey, we dive into Tabular Data Learning (TDL) using Graph Neural Networks (GNNs), a domain where deep learning-based approaches have increasingly shown superior performance in both classification and regression tasks compared to traditional methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-neural-networks-for-tabular-data</guid>
    </item>
    <item>
      <title>Learning to Prompt with Text Only Supervision for Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/learning-to-prompt-with-text-only-supervision</link>
      <description><![CDATA[While effective, most of these works require labeled data which is not practical, and often struggle to generalize towards new datasets due to over-fitting on the source data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-prompt-with-text-only-supervision</guid>
    </item>
    <item>
      <title>Unified Diffusion-Based Rigid and Non-Rigid Editing with Text and Image Guidance</title>
      <link>https://paperswithcode.com/paper/unified-diffusion-based-rigid-and-non-rigid</link>
      <description><![CDATA[Existing text-to-image editing methods tend to excel either in rigid or non-rigid editing but encounter challenges when combining both, resulting in misaligned outputs with the provided text prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-diffusion-based-rigid-and-non-rigid</guid>
    </item>
    <item>
      <title>ChartAssisstant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/chartassisstant-a-universal-chart-multimodal</link>
      <description><![CDATA[Charts play a vital role in data visualization, understanding data patterns, and informed decision-making.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chartassisstant-a-universal-chart-multimodal</guid>
    </item>
    <item>
      <title>Generating synthetic data for neural operators</title>
      <link>https://paperswithcode.com/paper/generating-synthetic-data-for-neural</link>
      <description><![CDATA[In this paper, we propose a new approach to generating synthetic functional training data that does not require solving a PDE numerically.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-synthetic-data-for-neural</guid>
    </item>
    <item>
      <title>GUESS:GradUally Enriching SyntheSis for Text-Driven Human Motion Generation</title>
      <link>https://paperswithcode.com/paper/guess-gradually-enriching-synthesis-for-text</link>
      <description><![CDATA[The whole text-driven human motion synthesis problem is then divided into multiple abstraction levels and solved with a multi-stage generation framework with a cascaded latent diffusion model: an initial generator first generates the coarsest human motion guess from a given text description; then, a series of successive generators gradually enrich the motion details based on the textual description and the previous synthesized results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/guess-gradually-enriching-synthesis-for-text</guid>
    </item>
    <item>
      <title>Linguistic Profiling of Deepfakes: An Open Database for Next-Generation Deepfake Detection</title>
      <link>https://paperswithcode.com/paper/linguistic-profiling-of-deepfakes-an-open</link>
      <description><![CDATA[The two distinguished features enable DFLIP-3K to develop a benchmark that promotes progress in linguistic profiling of deepfakes, which includes three sub-tasks namely deepfake detection, model identification, and prompt prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linguistic-profiling-of-deepfakes-an-open</guid>
    </item>
    <item>
      <title>LLaVA-$φ$: Efficient Multi-Modal Assistant with Small Language Model</title>
      <link>https://paperswithcode.com/paper/llava-ph-efficient-multi-modal-assistant-with</link>
      <description><![CDATA[In this paper, we introduce LLaVA-$\phi$ (LLaVA-Phi), an efficient multi-modal assistant that harnesses the power of the recently advanced small language model, Phi-2, to facilitate multi-modal dialogues.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llava-ph-efficient-multi-modal-assistant-with</guid>
    </item>
    <item>
      <title>Policy-regularized Offline Multi-objective Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/policy-regularized-offline-multi-objective</link>
      <description><![CDATA[In this paper, we aim to utilize only offline trajectory data to train a policy for multi-objective RL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/policy-regularized-offline-multi-objective</guid>
    </item>
    <item>
      <title>FairGridSearch: A Framework to Compare Fairness-Enhancing Models</title>
      <link>https://paperswithcode.com/paper/fairgridsearch-a-framework-to-compare</link>
      <description><![CDATA[While there are various bias mitigation methods and base estimators in the literature, selecting the optimal model for a specific application remains challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fairgridsearch-a-framework-to-compare</guid>
    </item>
    <item>
      <title>Task Oriented Dialogue as a Catalyst for Self-Supervised Automatic Speech Recognition</title>
      <link>https://paperswithcode.com/paper/task-oriented-dialogue-as-a-catalyst-for-self</link>
      <description><![CDATA[We demonstrate that our CLC family of approaches can improve the performance of ASR models on OD3, a new public large-scale semi-synthetic meta-dataset of audio task-oriented dialogues, by up to 19. 2%.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/task-oriented-dialogue-as-a-catalyst-for-self</guid>
    </item>
    <item>
      <title>Mining Fine-Grained Image-Text Alignment for Zero-Shot Captioning via Text-Only Training</title>
      <link>https://paperswithcode.com/paper/mining-fine-grained-image-text-alignment-for</link>
      <description><![CDATA[Firstly, we observe that the CLIP's visual feature of image subregions can achieve closer proximity to the paired caption due to the inherent information loss in text descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mining-fine-grained-image-text-alignment-for</guid>
    </item>
    <item>
      <title>Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes</title>
      <link>https://paperswithcode.com/paper/act-as-you-learn-adaptive-decision-making-in</link>
      <description><![CDATA[However, existing approaches for decision-making in NSMDPs have two major shortcomings: first, they assume that the updated environmental dynamics at the current time are known (although future dynamics can change); and second, planning is largely pessimistic, i. e., the agent acts ``safely'' to account for the non-stationary evolution of the environment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/act-as-you-learn-adaptive-decision-making-in</guid>
    </item>
    <item>
      <title>STAF: 3D Human Mesh Recovery from Video with Spatio-Temporal Alignment Fusion</title>
      <link>https://paperswithcode.com/paper/staf-3d-human-mesh-recovery-from-video-with</link>
      <description><![CDATA[This method can remarkably improve the smoothness of recovery results from video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/staf-3d-human-mesh-recovery-from-video-with</guid>
    </item>
    <item>
      <title>Investigating the Suitability of Concept Drift Detection for Detecting Leakages in Water Distribution Networks</title>
      <link>https://paperswithcode.com/paper/investigating-the-suitability-of-concept</link>
      <description><![CDATA[In this work, we explore the potential of model-loss-based and distribution-based drift detection methods to tackle leakage detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/investigating-the-suitability-of-concept</guid>
    </item>
    <item>
      <title>S$^{2}$-DMs:Skip-Step Diffusion Models</title>
      <link>https://paperswithcode.com/paper/s-2-dms-skip-step-diffusion-models</link>
      <description><![CDATA[On the CIFAR10 dataset, models trained using our algorithm showed an improvement of 3. 27% to 14. 06% over models trained with traditional methods across various sampling algorithms (DDIMs, PNDMs, DEIS) and different numbers of sampling steps (10, 20, ..., 1000).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s-2-dms-skip-step-diffusion-models</guid>
    </item>
    <item>
      <title>GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning</title>
      <link>https://paperswithcode.com/paper/gps-ssl-guided-positive-sampling-to-inject</link>
      <description><![CDATA[Any prior knowledge can now be embedded into that metric space independently from the employed DA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gps-ssl-guided-positive-sampling-to-inject</guid>
    </item>
    <item>
      <title>From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations</title>
      <link>https://paperswithcode.com/paper/from-audio-to-photoreal-embodiment</link>
      <description><![CDATA[We present a framework for generating full-bodied photorealistic avatars that gesture according to the conversational dynamics of a dyadic interaction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-audio-to-photoreal-embodiment</guid>
    </item>
    <item>
      <title>Context-Guided Spatio-Temporal Video Grounding</title>
      <link>https://paperswithcode.com/paper/context-guided-spatio-temporal-video</link>
      <description><![CDATA[The key of CG-STVG lies in two specially designed modules, including instance context generation (ICG), which focuses on discovering visual context information (in both appearance and motion) of the instance, and instance context refinement (ICR), which aims to improve the instance context from ICG by eliminating irrelevant or even harmful information from the context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-guided-spatio-temporal-video</guid>
    </item>
    <item>
      <title>CRA-PCN: Point Cloud Completion with Intra- and Inter-level Cross-Resolution Transformers</title>
      <link>https://paperswithcode.com/paper/cra-pcn-point-cloud-completion-with-intra-and</link>
      <description><![CDATA[Point cloud completion is an indispensable task for recovering complete point clouds due to incompleteness caused by occlusion, limited sensor resolution, etc.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cra-pcn-point-cloud-completion-with-intra-and</guid>
    </item>
    <item>
      <title>Graph Neural Networks for Surfactant Multi-Property Prediction</title>
      <link>https://paperswithcode.com/paper/graph-neural-networks-for-surfactant-multi</link>
      <description><![CDATA[A key factor in the predictive ability of QSPR and GNN models is the data available for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-neural-networks-for-surfactant-multi</guid>
    </item>
    <item>
      <title>Poisoning Attacks against Recommender Systems: A Survey</title>
      <link>https://paperswithcode.com/paper/poisoning-attacks-against-recommender-systems</link>
      <description><![CDATA[This survey paper provides a systematic and up-to-date review of the research landscape on Poisoning Attacks against Recommendation (PAR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poisoning-attacks-against-recommender-systems</guid>
    </item>
    <item>
      <title>Context-Aware Interaction Network for RGB-T Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/context-aware-interaction-network-for-rgb-t</link>
      <description><![CDATA[Specifically, we propose a Context-Aware Complementary Reasoning (CACR) module aimed at establishing the complementary relationship between multimodal features with the long-term context in both spatial and channel dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/context-aware-interaction-network-for-rgb-t</guid>
    </item>
    <item>
      <title>aMUSEd: An Open MUSE Reproduction</title>
      <link>https://paperswithcode.com/paper/amused-an-open-muse-reproduction</link>
      <description><![CDATA[We present aMUSEd, an open-source, lightweight masked image model (MIM) for text-to-image generation based on MUSE.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/amused-an-open-muse-reproduction</guid>
    </item>
    <item>
      <title>Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction</title>
      <link>https://paperswithcode.com/paper/prototypical-information-bottlenecking-and</link>
      <description><![CDATA[Despite advantages of multimodal learning for cancer survival prediction, massive redundancy in multimodal data prevents it from extracting discriminative and compact information: (1) An extensive amount of intra-modal task-unrelated information blurs discriminability, especially for gigapixel whole slide images (WSIs) with many patches in pathology and thousands of pathways in genomic data, leading to an ``intra-modal redundancy" issue.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prototypical-information-bottlenecking-and</guid>
    </item>
    <item>
      <title>ODTrack: Online Dense Temporal Token Learning for Visual Tracking</title>
      <link>https://paperswithcode.com/paper/odtrack-online-dense-temporal-token-learning</link>
      <description><![CDATA[To alleviate the above problem, we propose a simple, flexible and effective video-level tracking pipeline, named \textbf{ODTrack}, which densely associates the contextual relationships of video frames in an online token propagation manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/odtrack-online-dense-temporal-token-learning</guid>
    </item>
    <item>
      <title>Boosting of Implicit Neural Representation-based Image Denoiser</title>
      <link>https://paperswithcode.com/paper/boosting-of-implicit-neural-representation</link>
      <description><![CDATA[Implicit Neural Representation (INR) has emerged as an effective method for unsupervised image denoising.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-of-implicit-neural-representation</guid>
    </item>
    <item>
      <title>Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication</title>
      <link>https://paperswithcode.com/paper/large-language-model-capabilities-in</link>
      <description><![CDATA[We achieve F1 scores of 0. 50 for ASA Physical Status Classification, 0. 81 for ICU admission, and 0. 86 for hospital mortality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-model-capabilities-in</guid>
    </item>
    <item>
      <title>Concurrent Brainstorming &amp; Hypothesis Satisfying: An Iterative Framework for Enhanced Retrieval-Augmented Generation (R2CBR3H-SR)</title>
      <link>https://paperswithcode.com/paper/concurrent-brainstorming-hypothesis</link>
      <description><![CDATA[Addressing the complexity of comprehensive information retrieval, this study introduces an innovative, iterative retrieval-augmented generation system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/concurrent-brainstorming-hypothesis</guid>
    </item>
    <item>
      <title>A First Look at Information Highlighting in Stack Overflow Answers</title>
      <link>https://paperswithcode.com/paper/a-first-look-at-information-highlighting-in</link>
      <description><![CDATA[For training recommendation models, we choose CNN and BERT models for each type of formatting (i. e., Bold, Italic, Code, and Heading) using the information highlighting dataset we collected from SO answers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-first-look-at-information-highlighting-in</guid>
    </item>
  </channel>
</rss>
