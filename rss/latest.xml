<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 15 Aug 2023 21:06:23 +0000</lastBuildDate>
    <item>
      <title>Complete Instances Mining for Weakly Supervised Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/complete-instances-mining-for-weakly</link>
      <description><![CDATA[To address this problem, we propose a novel approach for WSIS that focuses on the online refinement of complete instances through the use of MaskIoU heads to predict the integrity scores of proposals and a Complete Instances Mining (CIM) strategy to explicitly model the redundant segmentation problem and generate refined pseudo labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/complete-instances-mining-for-weakly</guid>
    </item>
    <item>
      <title>AudioFormer: Audio Transformer learns audio feature representations from discrete acoustic codes</title>
      <link>https://paperswithcode.com/paper/audioformer-audio-transformer-learns-audio</link>
      <description><![CDATA[This method enables the learning of joint representations among multiple discrete acoustic codes within the same audio input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audioformer-audio-transformer-learns-audio</guid>
    </item>
    <item>
      <title>Semantic-aware Network for Aerial-to-Ground Image Synthesis</title>
      <link>https://paperswithcode.com/paper/semantic-aware-network-for-aerial-to-ground</link>
      <description><![CDATA[Aerial-to-ground image synthesis is an emerging and challenging problem that aims to synthesize a ground image from an aerial image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-aware-network-for-aerial-to-ground</guid>
    </item>
    <item>
      <title>Contrastive Bi-Projector for Unsupervised Domain Adaption</title>
      <link>https://paperswithcode.com/paper/contrastive-bi-projector-for-unsupervised</link>
      <description><![CDATA[The GS scheme can be exploited to tackle the unstable problem of the CD loss because training the CBPUDA requires using contrastive learning and adversarial learning at the same time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-bi-projector-for-unsupervised</guid>
    </item>
    <item>
      <title>Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes</title>
      <link>https://paperswithcode.com/paper/radiomics-informed-deep-learning-for</link>
      <description><![CDATA[Furthermore, we ensure complementary information is learned by deep and radiomic features by designing a novel feature de-correlation loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/radiomics-informed-deep-learning-for</guid>
    </item>
    <item>
      <title>Knowing Where to Focus: Event-aware Transformer for Video Grounding</title>
      <link>https://paperswithcode.com/paper/knowing-where-to-focus-event-aware</link>
      <description><![CDATA[Recent DETR-based video grounding models have made the model directly predict moment timestamps without any hand-crafted components, such as a pre-defined proposal or non-maximum suppression, by learning moment queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/knowing-where-to-focus-event-aware</guid>
    </item>
    <item>
      <title>Jurassic World Remake: Bringing Ancient Fossils Back to Life via Zero-Shot Long Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/jurassic-world-remake-bringing-ancient</link>
      <description><![CDATA[In this work, we use text-guided latent diffusion models for zero-shot image-to-image translation (I2I) across large domain gaps (longI2I), where large amounts of new visual features and new geometry need to be generated to enter the target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jurassic-world-remake-bringing-ancient</guid>
    </item>
    <item>
      <title>Robustness Stress Testing in Medical Image Classification</title>
      <link>https://paperswithcode.com/paper/robustness-stress-testing-in-medical-image</link>
      <description><![CDATA[We conclude that progressive stress testing is a viable and important tool and should become standard practice in the clinical validation of image-based disease detection models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robustness-stress-testing-in-medical-image</guid>
    </item>
    <item>
      <title>Neural radiance fields in the industrial and robotics domain: applications, research opportunities and use cases</title>
      <link>https://paperswithcode.com/paper/neural-radiance-fields-in-the-industrial-and</link>
      <description><![CDATA[We also present a series of proof-of-concept experiments that demonstrate the potential of NeRFs in the industrial domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-radiance-fields-in-the-industrial-and</guid>
    </item>
    <item>
      <title>Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking</title>
      <link>https://paperswithcode.com/paper/exploring-lightweight-hierarchical-vision</link>
      <description><![CDATA[The Bridge Module incorporates the high-level information of deep features into the shallow large-resolution features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-lightweight-hierarchical-vision</guid>
    </item>
    <item>
      <title>Platypus: Quick, Cheap, and Powerful Refinement of LLMs</title>
      <link>https://paperswithcode.com/paper/platypus-quick-cheap-and-powerful-refinement</link>
      <description><![CDATA[We present $\textbf{Platypus}$, a family of fine-tuned and merged Large Language Models (LLMs) that achieves the strongest performance and currently stands at first place in HuggingFace's Open LLM Leaderboard as of the release date of this work.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/platypus-quick-cheap-and-powerful-refinement</guid>
    </item>
    <item>
      <title>Robustified ANNs Reveal Wormholes Between Human Category Percepts</title>
      <link>https://paperswithcode.com/paper/robustified-anns-reveal-wormholes-between</link>
      <description><![CDATA[Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations -- and locally stable in general -- this argues that ANNs are incomplete scientific models of human visual perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robustified-anns-reveal-wormholes-between</guid>
    </item>
    <item>
      <title>FocusFlow: Boosting Key-Points Optical Flow Estimation for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/focusflow-boosting-key-points-optical-flow</link>
      <description><![CDATA[Based on the modeling method, we present FocusFlow, a framework consisting of 1) a mix loss function combined with a classic photometric loss function and our proposed Conditional Point Control Loss (CPCL) function for diverse point-wise supervision; 2) a conditioned controlling model which substitutes the conventional feature encoder by our proposed Condition Control Encoder (CCE).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/focusflow-boosting-key-points-optical-flow</guid>
    </item>
    <item>
      <title>Generative Interpretation</title>
      <link>https://paperswithcode.com/paper/generative-interpretation</link>
      <description><![CDATA[We introduce generative interpretation, a new approach to estimating contractual meaning using large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-interpretation</guid>
    </item>
    <item>
      <title>Group Pose: A Simple Baseline for End-to-End Multi-person Pose Estimation</title>
      <link>https://paperswithcode.com/paper/group-pose-a-simple-baseline-for-end-to-end</link>
      <description><![CDATA[State-of-the-art solutions adopt the DETR-like framework, and mainly develop the complex decoder, e. g., regarding pose estimation as keypoint box detection and combining with human detection in ED-Pose, hierarchically predicting with pose decoder and joint (keypoint) decoder in PETR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/group-pose-a-simple-baseline-for-end-to-end</guid>
    </item>
    <item>
      <title>ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate</title>
      <link>https://paperswithcode.com/paper/chateval-towards-better-llm-based-evaluators</link>
      <description><![CDATA[Text evaluation has historically posed significant challenges, often demanding substantial labor and time cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chateval-towards-better-llm-based-evaluators</guid>
    </item>
    <item>
      <title>Hierarchy Flow For High-Fidelity Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/hierarchy-flow-for-high-fidelity-image-to</link>
      <description><![CDATA[In this work, we propose Hierarchy Flow, a novel flow-based model to achieve better content preservation during translation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchy-flow-for-high-fidelity-image-to</guid>
    </item>
    <item>
      <title>AutoSeqRec: Autoencoder for Efficient Sequential Recommendation</title>
      <link>https://paperswithcode.com/paper/autoseqrec-autoencoder-for-efficient</link>
      <description><![CDATA[Sequential recommendation demonstrates the capability to recommend items by modeling the sequential behavior of users.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoseqrec-autoencoder-for-efficient</guid>
    </item>
    <item>
      <title>Large Language Models for Information Retrieval: A Survey</title>
      <link>https://paperswithcode.com/paper/large-language-models-for-information</link>
      <description><![CDATA[This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-for-information</guid>
    </item>
    <item>
      <title>CTP: Towards Vision-Language Continual Pretraining via Compatible Momentum Contrast and Topology Preservation</title>
      <link>https://paperswithcode.com/paper/ctp-towards-vision-language-continual</link>
      <description><![CDATA[Regarding the growing nature of real-world data, such an offline training paradigm on ever-expanding data is unsustainable, because models lack the continual learning ability to accumulate knowledge constantly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ctp-towards-vision-language-continual</guid>
    </item>
    <item>
      <title>#InsTag: Instruction Tagging for Diversity and Complexity Analysis</title>
      <link>https://paperswithcode.com/paper/instag-instruction-tagging-for-diversity-and</link>
      <description><![CDATA[Based on this observation, we propose a data selector based on InsTag to select 6K diverse and complex samples from open-source datasets and fine-tune models on InsTag-selected data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instag-instruction-tagging-for-diversity-and</guid>
    </item>
    <item>
      <title>gSASRec: Reducing Overconfidence in Sequential Recommendation Trained with Negative Sampling</title>
      <link>https://paperswithcode.com/paper/gsasrec-reducing-overconfidence-in-sequential</link>
      <description><![CDATA[A large catalogue size is one of the central challenges in training recommendation models: a large number of items makes them memory and computationally inefficient to compute scores for all items during training, forcing these models to deploy negative sampling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gsasrec-reducing-overconfidence-in-sequential</guid>
    </item>
    <item>
      <title>CBA: Improving Online Continual Learning via Continual Bias Adaptor</title>
      <link>https://paperswithcode.com/paper/cba-improving-online-continual-learning-via</link>
      <description><![CDATA[Online continual learning (CL) aims to learn new knowledge and consolidate previously learned knowledge from non-stationary data streams.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cba-improving-online-continual-learning-via</guid>
    </item>
    <item>
      <title>LCE -- An Augmented Combination of Bagging and Boosting in Python</title>
      <link>https://paperswithcode.com/paper/lce-an-augmented-combination-of-bagging-and</link>
      <description><![CDATA[lcensemble is a high-performing, scalable and user-friendly Python package for the general tasks of classification and regression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lce-an-augmented-combination-of-bagging-and</guid>
    </item>
    <item>
      <title>OpenGCD: Assisting Open World Recognition with Generalized Category Discovery</title>
      <link>https://paperswithcode.com/paper/opengcd-assisting-open-world-recognition-with</link>
      <description><![CDATA[To bridge this gap, we propose OpenGCD that combines three key ideas to solve the above problems sequentially: (a) We score the origin of instances (unknown or specifically known) based on the uncertainty of the classifier's prediction; (b) For the first time, we introduce generalized category discovery (GCD) techniques in OWR to assist humans in grouping unlabeled data; (c) For the smooth execution of IL and GCD, we retain an equal number of informative exemplars for each class with diversity as the goal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/opengcd-assisting-open-world-recognition-with</guid>
    </item>
    <item>
      <title>Large-kernel Attention for Efficient and Robust Brain Lesion Segmentation</title>
      <link>https://paperswithcode.com/paper/large-kernel-attention-for-efficient-and</link>
      <description><![CDATA[Vision transformers are effective deep learning models for vision tasks, including medical image segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-kernel-attention-for-efficient-and</guid>
    </item>
    <item>
      <title>A One Stop 3D Target Reconstruction and multilevel Segmentation Method</title>
      <link>https://paperswithcode.com/paper/a-one-stop-3d-target-reconstruction-and</link>
      <description><![CDATA[We extend object tracking and 3D reconstruction algorithms to support continuous segmentation labels to leverage the advances in the 2D image segmentation, especially the Segment-Anything Model (SAM) which uses the pretrained neural network without additional training for new scenes, for 3D object segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-one-stop-3d-target-reconstruction-and</guid>
    </item>
    <item>
      <title>OctoPack: Instruction Tuning Code Large Language Models</title>
      <link>https://paperswithcode.com/paper/octopack-instruction-tuning-code-large</link>
      <description><![CDATA[We benchmark CommitPack against other natural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B parameter StarCoder model, and achieve state-of-the-art performance among models not trained on OpenAI outputs, on the HumanEval Python benchmark (46. 2% pass@1).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/octopack-instruction-tuning-code-large</guid>
    </item>
    <item>
      <title>Explaining Black-Box Models through Counterfactuals</title>
      <link>https://paperswithcode.com/paper/explaining-black-box-models-through</link>
      <description><![CDATA[We present CounterfactualExplanations. jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explaining-black-box-models-through</guid>
    </item>
    <item>
      <title>AdvCLIP: Downstream-agnostic Adversarial Examples in Multimodal Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/advclip-downstream-agnostic-adversarial</link>
      <description><![CDATA[In this work, we propose AdvCLIP, the first attack framework for generating downstream-agnostic adversarial examples based on cross-modal pre-trained encoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advclip-downstream-agnostic-adversarial</guid>
    </item>
    <item>
      <title>Aesthetics of Sanskrit Poetry from the Perspective of Computational Linguistics: A Case Study Analysis on Siksastaka</title>
      <link>https://paperswithcode.com/paper/aesthetics-of-sanskrit-poetry-from-the</link>
      <description><![CDATA[We provide a deep analysis of Siksastaka, a Sanskrit poem, from the perspective of 6 prominent kavyashastra schools, to illustrate the proposed framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aesthetics-of-sanskrit-poetry-from-the</guid>
    </item>
    <item>
      <title>Color-NeuS: Reconstructing Neural Implicit Surfaces with Color</title>
      <link>https://paperswithcode.com/paper/color-neus-reconstructing-neural-implicit</link>
      <description><![CDATA[Mesh is extracted from the signed distance function (SDF) network for the surface, and color for each surface vertex is drawn from the global color network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/color-neus-reconstructing-neural-implicit</guid>
    </item>
    <item>
      <title>EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language Models</title>
      <link>https://paperswithcode.com/paper/easyedit-an-easy-to-use-knowledge-editing</link>
      <description><![CDATA[Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy issues, which means they are unaware of unseen events or generate text with incorrect facts owing to the outdated/noisy data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyedit-an-easy-to-use-knowledge-editing</guid>
    </item>
    <item>
      <title>Global Features are All You Need for Image Retrieval and Reranking</title>
      <link>https://paperswithcode.com/paper/global-features-are-all-you-need-for-image</link>
      <description><![CDATA[We, for the first time, propose an image retrieval paradigm leveraging global feature only to enable accurate and lightweight image retrieval for both coarse retrieval and reranking, thus the name - SuperGlobal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/global-features-are-all-you-need-for-image</guid>
    </item>
    <item>
      <title>UniWorld: Autonomous Driving Pre-training via World Models</title>
      <link>https://paperswithcode.com/paper/uniworld-autonomous-driving-pre-training-via</link>
      <description><![CDATA[In this paper, we draw inspiration from Alberto Elfes' pioneering work in 1989, where he introduced the concept of the occupancy grid as World Models for robots.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uniworld-autonomous-driving-pre-training-via</guid>
    </item>
    <item>
      <title>MixBCT: Towards Self-Adapting Backward-Compatible Training</title>
      <link>https://paperswithcode.com/paper/mixbct-towards-self-adapting-backward</link>
      <description><![CDATA[As a solution, backward-compatible training can be employed to avoid the necessity of updating old retrieval datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixbct-towards-self-adapting-backward</guid>
    </item>
    <item>
      <title>Temporal Sentence Grounding in Streaming Videos</title>
      <link>https://paperswithcode.com/paper/temporal-sentence-grounding-in-streaming</link>
      <description><![CDATA[The goal of TSGSV is to evaluate the relevance between a video stream and a given sentence query.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-sentence-grounding-in-streaming</guid>
    </item>
    <item>
      <title>Distance Matters For Improving Performance Estimation Under Covariate Shift</title>
      <link>https://paperswithcode.com/paper/distance-matters-for-improving-performance</link>
      <description><![CDATA[In this work, we show that taking into account distances of test samples to their expected training distribution can significantly improve performance estimation under covariate shift.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distance-matters-for-improving-performance</guid>
    </item>
    <item>
      <title>HyperSparse Neural Networks: Shifting Exploration to Exploitation through Adaptive Regularization</title>
      <link>https://paperswithcode.com/paper/hypersparse-neural-networks-shifting</link>
      <description><![CDATA[Sparse neural networks are a key factor in developing resource-efficient machine learning applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hypersparse-neural-networks-shifting</guid>
    </item>
    <item>
      <title>TextDiff: Mask-Guided Residual Diffusion Models for Scene Text Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/textdiff-mask-guided-residual-diffusion</link>
      <description><![CDATA[Moreover, our proposed MRD module is plug-and-play that effectively sharpens the text edges produced by SOTA methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textdiff-mask-guided-residual-diffusion</guid>
    </item>
    <item>
      <title>FastLLVE: Real-Time Low-Light Video Enhancement with Intensity-Aware Lookup Table</title>
      <link>https://paperswithcode.com/paper/fastllve-real-time-low-light-video</link>
      <description><![CDATA[Experimental results on benchmark datasets demonstrate that our method achieves the State-Of-The-Art (SOTA) performance in terms of both image quality and inter-frame brightness consistency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fastllve-real-time-low-light-video</guid>
    </item>
    <item>
      <title>Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training</title>
      <link>https://paperswithcode.com/paper/estimator-meets-equilibrium-perspective-a</link>
      <description><![CDATA[The pioneering work BinaryConnect uses Straight Through Estimator (STE) to mimic the gradients of the sign function, but it also causes the crucial inconsistency problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/estimator-meets-equilibrium-perspective-a</guid>
    </item>
    <item>
      <title>Target before Shooting: Accurate Anomaly Detection and Localization under One Millisecond via Cascade Patch Retrieval</title>
      <link>https://paperswithcode.com/paper/target-before-shooting-accurate-anomaly</link>
      <description><![CDATA[In this framework, the anomaly detection problem is solved via a cascade patch retrieval procedure that retrieves the nearest neighbors for each test image patch in a coarse-to-fine fashion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/target-before-shooting-accurate-anomaly</guid>
    </item>
    <item>
      <title>Influence Function Based Second-Order Channel Pruning-Evaluating True Loss Changes For Pruning Is Possible Without Retraining</title>
      <link>https://paperswithcode.com/paper/influence-function-based-second-order-channel</link>
      <description><![CDATA[It motivates us to develop a technique to evaluate true loss changes without retraining, with which channels to prune can be selected more reliably and confidently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/influence-function-based-second-order-channel</guid>
    </item>
    <item>
      <title>Shrinking Class Space for Enhanced Certainty in Semi-Supervised Learning</title>
      <link>https://paperswithcode.com/paper/shrinking-class-space-for-enhanced-certainty</link>
      <description><![CDATA[To mitigate potentially incorrect pseudo labels, recent frameworks mostly set a fixed confidence threshold to discard uncertain samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shrinking-class-space-for-enhanced-certainty</guid>
    </item>
    <item>
      <title>Condition-Adaptive Graph Convolution Learning for Skeleton-Based Gait Recognition</title>
      <link>https://paperswithcode.com/paper/condition-adaptive-graph-convolution-learning</link>
      <description><![CDATA[Graph convolutional networks have been widely applied in skeleton-based gait recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/condition-adaptive-graph-convolution-learning</guid>
    </item>
    <item>
      <title>Self-supervised Noise2noise Method Utilizing Corrupted Images with a Modular Network for LDCT Denoising</title>
      <link>https://paperswithcode.com/paper/self-supervised-noise2noise-method-utilizing</link>
      <description><![CDATA[Note that we use LDCT images based on the noisy-as-clean strategy for corruption instead of NDCT images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-noise2noise-method-utilizing</guid>
    </item>
    <item>
      <title>Isomer: Isomerous Transformer for Zero-shot Video Object Segmentation</title>
      <link>https://paperswithcode.com/paper/isomer-isomerous-transformer-for-zero-shot</link>
      <description><![CDATA[Recent leading zero-shot video object segmentation (ZVOS) works devote to integrating appearance and motion information by elaborately designing feature fusion modules and identically applying them in multiple feature stages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/isomer-isomerous-transformer-for-zero-shot</guid>
    </item>
    <item>
      <title>A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations</title>
      <link>https://paperswithcode.com/paper/a-survey-on-deep-neural-network-pruning</link>
      <description><![CDATA[Modern deep neural networks, particularly recent large language models, come with massive model sizes that require significant computational and storage resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-deep-neural-network-pruning</guid>
    </item>
    <item>
      <title>Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches</title>
      <link>https://paperswithcode.com/paper/unsupervised-image-denoising-in-real-world</link>
      <description><![CDATA[Although unsupervised approaches based on generative adversarial networks offer a promising solution for denoising without paired datasets, they are difficult in surpassing the performance limitations of conventional GAN-based unsupervised frameworks without significantly modifying existing structures or increasing the computational complexity of denoisers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-image-denoising-in-real-world</guid>
    </item>
  </channel>
</rss>
