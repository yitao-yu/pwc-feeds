<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 26 Feb 2024 09:13:05 +0000</lastBuildDate>
    <item>
      <title>Distributionally Robust Off-Dynamics Reinforcement Learning: Provable Efficiency with Linear Function Approximation</title>
      <link>https://paperswithcode.com/paper/distributionally-robust-off-dynamics</link>
      <description><![CDATA[We provide the first study on online DRMDPs with function approximation for off-dynamics RL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distributionally-robust-off-dynamics</guid>
    </item>
    <item>
      <title>Infusing Hierarchical Guidance into Prompt Tuning: A Parameter-Efficient Framework for Multi-level Implicit Discourse Relation Recognition</title>
      <link>https://paperswithcode.com/paper/infusing-hierarchical-guidance-into-prompt</link>
      <description><![CDATA[First, we leverage parameter-efficient prompt tuning to drive the inputted arguments to match the pre-trained space and realize the approximation with few parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infusing-hierarchical-guidance-into-prompt</guid>
    </item>
    <item>
      <title>NeuralThink: Algorithm Synthesis that Extrapolates in General Tasks</title>
      <link>https://paperswithcode.com/paper/neuralthink-algorithm-synthesis-that</link>
      <description><![CDATA[To address this gap, we propose NeuralThink, a new recurrent architecture that can consistently extrapolate to both symmetrical and asymmetrical tasks, where the dimensionality of the input and output are different.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuralthink-algorithm-synthesis-that</guid>
    </item>
    <item>
      <title>MSPipe: Efficient Temporal GNN Training via Staleness-aware Pipeline</title>
      <link>https://paperswithcode.com/paper/mspipe-efficient-temporal-gnn-training-via</link>
      <description><![CDATA[However, the iterative reading and updating process of the memory module in MTGNNs to obtain up-to-date information needs to follow the temporal dependencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mspipe-efficient-temporal-gnn-training-via</guid>
    </item>
    <item>
      <title>EMIFF: Enhanced Multi-scale Image Feature Fusion for Vehicle-Infrastructure Cooperative 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/emiff-enhanced-multi-scale-image-feature</link>
      <description><![CDATA[In autonomous driving, cooperative perception makes use of multi-view cameras from both vehicles and infrastructure, providing a global vantage point with rich semantic context of road conditions beyond a single vehicle viewpoint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emiff-enhanced-multi-scale-image-feature</guid>
    </item>
    <item>
      <title>Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing</title>
      <link>https://paperswithcode.com/paper/where-visual-speech-meets-language-vsp-llm</link>
      <description><![CDATA[In visual speech processing, context modeling capability is one of the most important requirements due to the ambiguous nature of lip movements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/where-visual-speech-meets-language-vsp-llm</guid>
    </item>
    <item>
      <title>Explorations of Self-Repair in Language Models</title>
      <link>https://paperswithcode.com/paper/explorations-of-self-repair-in-language</link>
      <description><![CDATA[Prior interpretability research studying narrow distributions has preliminarily identified self-repair, a phenomena where if components in large language models are ablated, later components will change their behavior to compensate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explorations-of-self-repair-in-language</guid>
    </item>
    <item>
      <title>ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models against Stochastic Perturbation</title>
      <link>https://paperswithcode.com/paper/protip-probabilistic-robustness-verification</link>
      <description><![CDATA[Text-to-Image (T2I) Diffusion Models (DMs) have shown impressive abilities in generating high-quality images based on simple text descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/protip-probabilistic-robustness-verification</guid>
    </item>
    <item>
      <title>GraphEdit: Large Language Models for Graph Structure Learning</title>
      <link>https://paperswithcode.com/paper/graphedit-large-language-models-for-graph</link>
      <description><![CDATA[Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphedit-large-language-models-for-graph</guid>
    </item>
    <item>
      <title>Optimal Transport for Structure Learning Under Missing Data</title>
      <link>https://paperswithcode.com/paper/optimal-transport-for-structure-learning</link>
      <description><![CDATA[Merely filling in missing values with existing imputation methods and subsequently applying structure learning on the complete data is empirical shown to be sub-optimal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimal-transport-for-structure-learning</guid>
    </item>
    <item>
      <title>PUAD: Frustratingly Simple Method for Robust Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/puad-frustratingly-simple-method-for-robust</link>
      <description><![CDATA[However, we argue that logical anomalies, such as the wrong number of objects, can not be well-represented by the spatial feature maps and require an alternative approach.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/puad-frustratingly-simple-method-for-robust</guid>
    </item>
    <item>
      <title>Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting</title>
      <link>https://paperswithcode.com/paper/enhancing-one-shot-federated-learning-through</link>
      <description><![CDATA[These hard samples are then employed to promote the quality of the ensemble model by adjusting the ensembling weights for each client model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-one-shot-federated-learning-through</guid>
    </item>
    <item>
      <title>Chitchat as Interference: Adding User Backstories to Task-Oriented Dialogues</title>
      <link>https://paperswithcode.com/paper/chitchat-as-interference-adding-user</link>
      <description><![CDATA[During task-oriented dialogues (TODs), human users naturally introduce chitchat that is beyond the immediate scope of the task, interfering with the flow of the conversation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chitchat-as-interference-adding-user</guid>
    </item>
    <item>
      <title>AttributionBench: How Hard is Automatic Attribution Evaluation?</title>
      <link>https://paperswithcode.com/paper/attributionbench-how-hard-is-automatic</link>
      <description><![CDATA[Modern generative search engines enhance the reliability of large language model (LLM) responses by providing cited evidence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attributionbench-how-hard-is-automatic</guid>
    </item>
    <item>
      <title>A Data-Centric Approach To Generate Faithful and High Quality Patient Summaries with Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-data-centric-approach-to-generate-faithful</link>
      <description><![CDATA[In this work, we investigate the potential of large language models to generate patient summaries based on doctors' notes and study the effect of training data on the faithfulness and quality of the generated summaries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-data-centric-approach-to-generate-faithful</guid>
    </item>
    <item>
      <title>Multi-Agent Collaboration Framework for Recommender Systems</title>
      <link>https://paperswithcode.com/paper/multi-agent-collaboration-framework-for</link>
      <description><![CDATA[LLM-based agents have gained considerable attention for their decision-making skills and ability to handle complex tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-agent-collaboration-framework-for</guid>
    </item>
    <item>
      <title>Grasp, See and Place: Efficient Unknown Object Rearrangement with Policy Structure Prior</title>
      <link>https://paperswithcode.com/paper/grasp-see-and-place-efficient-unknown-object</link>
      <description><![CDATA[For the inner loop, we learn an active seeing policy for self-confident object matching to improve the perception of place.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grasp-see-and-place-efficient-unknown-object</guid>
    </item>
    <item>
      <title>On the Multi-turn Instruction Following for Conversational Web Agents</title>
      <link>https://paperswithcode.com/paper/on-the-multi-turn-instruction-following-for</link>
      <description><![CDATA[Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-multi-turn-instruction-following-for</guid>
    </item>
    <item>
      <title>Transformers are Expressive, But Are They Expressive Enough for Regression?</title>
      <link>https://paperswithcode.com/paper/transformers-are-expressive-but-are-they</link>
      <description><![CDATA[Expressivity of a neural network is the class of functions it can approximate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformers-are-expressive-but-are-they</guid>
    </item>
    <item>
      <title>On the Duality Between Sharpness-Aware Minimization and Adversarial Training</title>
      <link>https://paperswithcode.com/paper/on-the-duality-between-sharpness-aware</link>
      <description><![CDATA[Instead of perturbing the samples, Sharpness-Aware Minimization (SAM) perturbs the model weights during training to find a more flat loss landscape and improve generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-duality-between-sharpness-aware</guid>
    </item>
    <item>
      <title>Let's Rectify Step by Step: Improving Aspect-based Sentiment Analysis with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/let-s-rectify-step-by-step-improving-aspect</link>
      <description><![CDATA[Aspect-Based Sentiment Analysis (ABSA) stands as a crucial task in predicting the sentiment polarity associated with identified aspects within text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-s-rectify-step-by-step-improving-aspect</guid>
    </item>
    <item>
      <title>MemoryPrompt: A Light Wrapper to Improve Context Tracking in Pre-trained Language Models</title>
      <link>https://paperswithcode.com/paper/memoryprompt-a-light-wrapper-to-improve</link>
      <description><![CDATA[Transformer-based language models (LMs) track contextual information through large, hard-coded input windows.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memoryprompt-a-light-wrapper-to-improve</guid>
    </item>
    <item>
      <title>Counterfactual Generation with Identifiability Guarantees</title>
      <link>https://paperswithcode.com/paper/counterfactual-generation-with-1</link>
      <description><![CDATA[In this work, we tackle the domain-varying dependence between the content and the style variables inherent in the counterfactual generation task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-generation-with-1</guid>
    </item>
    <item>
      <title>Leveraging Domain Knowledge for Efficient Reward Modelling in RLHF: A Case-Study in E-Commerce Opinion Summarization</title>
      <link>https://paperswithcode.com/paper/leveraging-domain-knowledge-for-efficient</link>
      <description><![CDATA[While this strategy has proven to be effective, the training methodology requires a lot of human preference annotation (usually of the order of tens of thousands) to train {$\varphi$}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-domain-knowledge-for-efficient</guid>
    </item>
    <item>
      <title>EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems</title>
      <link>https://paperswithcode.com/paper/easyrl4rec-a-user-friendly-code-library-for</link>
      <description><![CDATA[Reinforcement Learning (RL)-Based Recommender Systems (RSs) are increasingly recognized for their ability to improve long-term user engagement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyrl4rec-a-user-friendly-code-library-for</guid>
    </item>
    <item>
      <title>Spatially-Aware Transformer Memory for Embodied Agents</title>
      <link>https://paperswithcode.com/paper/spatially-aware-transformer-memory-for</link>
      <description><![CDATA[Adopting this approach, we demonstrate that memory utilization efficiency can be improved, leading to enhanced accuracy in various place-centric downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatially-aware-transformer-memory-for</guid>
    </item>
    <item>
      <title>Machine Unlearning of Pre-trained Large Language Models</title>
      <link>https://paperswithcode.com/paper/machine-unlearning-of-pre-trained-large</link>
      <description><![CDATA[This study investigates the concept of the `right to be forgotten' within the context of large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/machine-unlearning-of-pre-trained-large</guid>
    </item>
    <item>
      <title>Hierarchical Invariance for Robust and Interpretable Vision Tasks at Larger Scales</title>
      <link>https://paperswithcode.com/paper/hierarchical-invariance-for-robust-and</link>
      <description><![CDATA[Developing robust and interpretable vision systems is a crucial step towards trustworthy artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchical-invariance-for-robust-and</guid>
    </item>
    <item>
      <title>GPT-HateCheck: Can LLMs Write Better Functional Tests for Hate Speech Detection?</title>
      <link>https://paperswithcode.com/paper/gpt-hatecheck-can-llms-write-better</link>
      <description><![CDATA[A recent proposal in this direction is HateCheck, a suite for testing fine-grained model functionalities on synthesized data generated using templates of the kind "You are just a [slur] to me."]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-hatecheck-can-llms-write-better</guid>
    </item>
    <item>
      <title>Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition</title>
      <link>https://paperswithcode.com/paper/gen4gen-generative-data-pipeline-for</link>
      <description><![CDATA[First, current personalization techniques fail to reliably extend to multiple concepts -- we hypothesize this to be due to the mismatch between complex scenes and simple text descriptions in the pre-training dataset (e. g., LAION).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gen4gen-generative-data-pipeline-for</guid>
    </item>
    <item>
      <title>ChildAugment: Data Augmentation Methods for Zero-Resource Children's Speaker Verification</title>
      <link>https://paperswithcode.com/paper/childaugment-data-augmentation-methods-for</link>
      <description><![CDATA[One promising approach is to align vocal-tract parameters between adults and children through children-specific data augmentation, referred here to as ChildAugment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/childaugment-data-augmentation-methods-for</guid>
    </item>
    <item>
      <title>Repetition Improves Language Model Embeddings</title>
      <link>https://paperswithcode.com/paper/repetition-improves-language-model-embeddings</link>
      <description><![CDATA[In this work, we address an architectural limitation of autoregressive models: token embeddings cannot contain information from tokens that appear later in the input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repetition-improves-language-model-embeddings</guid>
    </item>
    <item>
      <title>Farsight: Fostering Responsible AI Awareness During AI Application Prototyping</title>
      <link>https://paperswithcode.com/paper/farsight-fostering-responsible-ai-awareness</link>
      <description><![CDATA[To address this, we present Farsight, a novel in situ interactive tool that helps people identify potential harms from the AI applications they are prototyping.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/farsight-fostering-responsible-ai-awareness</guid>
    </item>
    <item>
      <title>Less is More: Mitigating Multimodal Hallucination from an EOS Decision Perspective</title>
      <link>https://paperswithcode.com/paper/less-is-more-mitigating-multimodal</link>
      <description><![CDATA[In this paper, we explore a new angle of this issue: overly detailed training data hinders the model's ability to timely terminate generation, leading to continued outputs beyond visual perception limits.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-is-more-mitigating-multimodal</guid>
    </item>
    <item>
      <title>Transformable Gaussian Reward Function for Socially-Aware Navigation with Deep Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/transformable-gaussian-reward-function-for</link>
      <description><![CDATA[Although reinforcement learning technique has fostered the advancement of socially aware navigation, defining appropriate reward functions, especially in congested environments, has posed a significant challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformable-gaussian-reward-function-for</guid>
    </item>
    <item>
      <title>INSTRAUG: Automatic Instruction Augmentation for Multimodal Instruction Fine-tuning</title>
      <link>https://paperswithcode.com/paper/instraug-automatic-instruction-augmentation</link>
      <description><![CDATA[Fine-tuning large language models (LLMs) on multi-task instruction-following data has been proven to be a powerful learning paradigm for improving their zero-shot capabilities on new tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instraug-automatic-instruction-augmentation</guid>
    </item>
    <item>
      <title>NeRF-Det++: Incorporating Semantic Cues and Perspective-aware Depth Supervision for Indoor Multi-View 3D Detection</title>
      <link>https://paperswithcode.com/paper/nerf-det-incorporating-semantic-cues-and</link>
      <description><![CDATA[We project the freely available 3D segmentation annotations onto the 2D plane and leverage the corresponding 2D semantic maps as the supervision signal, significantly enhancing the semantic awareness of multi-view detectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nerf-det-incorporating-semantic-cues-and</guid>
    </item>
    <item>
      <title>Self-supervised Visualisation of Medical Image Datasets</title>
      <link>https://paperswithcode.com/paper/self-supervised-visualisation-of-medical</link>
      <description><![CDATA[Self-supervised learning methods based on data augmentations, such as SimCLR, BYOL, or DINO, allow obtaining semantically meaningful representations of image datasets and are widely used prior to supervised fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-visualisation-of-medical</guid>
    </item>
    <item>
      <title>Federated Learning on Transcriptomic Data: Model Quality and Performance Trade-Offs</title>
      <link>https://paperswithcode.com/paper/federated-learning-on-transcriptomic-data</link>
      <description><![CDATA[However, our experiments confirm that both frameworks can readily build models on transcriptomic data, without transferring personal raw data to a third party with abundant computational resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/federated-learning-on-transcriptomic-data</guid>
    </item>
    <item>
      <title>GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion</title>
      <link>https://paperswithcode.com/paper/geneoh-diffusion-towards-generalizable-hand</link>
      <description><![CDATA[We tackle those challenges through a novel approach, GeneOH Diffusion, incorporating two key designs: an innovative contact-centric HOI representation named GeneOH and a new domain-generalizable denoising scheme.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geneoh-diffusion-towards-generalizable-hand</guid>
    </item>
    <item>
      <title>Subobject-level Image Tokenization</title>
      <link>https://paperswithcode.com/paper/subobject-level-image-tokenization</link>
      <description><![CDATA[Transformer-based vision models typically tokenize images into fixed-size square patches as input units, which lacks the adaptability to image content and overlooks the inherent pixel grouping structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/subobject-level-image-tokenization</guid>
    </item>
    <item>
      <title>PALO: A Polyglot Large Multimodal Model for 5B People</title>
      <link>https://paperswithcode.com/paper/palo-a-polyglot-large-multimodal-model-for-5b</link>
      <description><![CDATA[\textsc{Palo} offers visual reasoning capabilities in 10 major languages, including English, Chinese, Hindi, Spanish, French, Arabic, Bengali, Russian, Urdu, and Japanese, that span a total of $\sim$5B people (65\% of the world population).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/palo-a-polyglot-large-multimodal-model-for-5b</guid>
    </item>
    <item>
      <title>On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe</title>
      <link>https://paperswithcode.com/paper/on-the-tip-of-the-tongue-analyzing-conceptual</link>
      <description><![CDATA[Here we re-purpose the reverse dictionary task as a case study to probe LLMs' capacity for conceptual inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-tip-of-the-tongue-analyzing-conceptual</guid>
    </item>
    <item>
      <title>Data Science with LLMs and Interpretable Models</title>
      <link>https://paperswithcode.com/paper/data-science-with-llms-and-interpretable</link>
      <description><![CDATA[Recent years have seen important advances in the building of interpretable models, machine learning models that are designed to be easily understood by humans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-science-with-llms-and-interpretable</guid>
    </item>
    <item>
      <title>latrend: A Framework for Clustering Longitudinal Data</title>
      <link>https://paperswithcode.com/paper/latrend-a-framework-for-clustering</link>
      <description><![CDATA[We introduce the R package "latrend" as a framework for the unified application of methods for longitudinal clustering, enabling comparisons between methods with minimal coding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latrend-a-framework-for-clustering</guid>
    </item>
    <item>
      <title>EE3P: Event-based Estimation of Periodic Phenomena Properties</title>
      <link>https://paperswithcode.com/paper/ee3p-event-based-estimation-of-periodic</link>
      <description><![CDATA[We introduce a novel method for measuring properties of periodic phenomena with an event camera, a device asynchronously reporting brightness changes at independently operating pixels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ee3p-event-based-estimation-of-periodic</guid>
    </item>
    <item>
      <title>Take the Bull by the Horns: Hard Sample-Reweighted Continual Training Improves LLM Generalization</title>
      <link>https://paperswithcode.com/paper/take-the-bull-by-the-horns-hard-sample</link>
      <description><![CDATA[Our study starts from an empirical strategy for the light continual training of LLMs using their original pre-training data sets, with a specific focus on selective retention of samples that incur moderately high losses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/take-the-bull-by-the-horns-hard-sample</guid>
    </item>
    <item>
      <title>ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models</title>
      <link>https://paperswithcode.com/paper/conceptmath-a-bilingual-concept-wise</link>
      <description><![CDATA[This paper introduces ConceptMath, a bilingual (English and Chinese), fine-grained benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conceptmath-a-bilingual-concept-wise</guid>
    </item>
    <item>
      <title>CommVQA: Situating Visual Question Answering in Communicative Contexts</title>
      <link>https://paperswithcode.com/paper/commvqa-situating-visual-question-answering</link>
      <description><![CDATA[Current visual question answering (VQA) models tend to be trained and evaluated on image-question pairs in isolation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/commvqa-situating-visual-question-answering</guid>
    </item>
    <item>
      <title>INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models</title>
      <link>https://paperswithcode.com/paper/instructir-a-benchmark-for-instruction</link>
      <description><![CDATA[Enhancing the capability of retrievers to understand intentions and preferences of users, akin to language model instructions, has the potential to yield more aligned search targets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructir-a-benchmark-for-instruction</guid>
    </item>
  </channel>
</rss>
