<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 12 Jul 2024 21:08:45 +0000</lastBuildDate>
    <item>
      <title>Transductive Active Learning with Application to Safe Bayesian Optimization</title>
      <link>https://paperswithcode.com/paper/transductive-active-learning-with-application</link>
      <description><![CDATA[We analyze Safe BO under the lens of a generalization of active learning with concrete prediction targets where sampling is restricted to an accessible region of the domain, while prediction targets may lie outside this region.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transductive-active-learning-with-application</guid>
    </item>
    <item>
      <title>RTMW: Real-Time Multi-Person 2D and 3D Whole-body Pose Estimation</title>
      <link>https://paperswithcode.com/paper/rtmw-real-time-multi-person-2d-and-3d-whole</link>
      <description><![CDATA[In this work, we present RTMW (Real-Time Multi-person Whole-body pose estimation models), a series of high-performance models for 2D/3D whole-body pose estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rtmw-real-time-multi-person-2d-and-3d-whole</guid>
    </item>
    <item>
      <title>Multimodal contrastive learning for spatial gene expression prediction using histology images</title>
      <link>https://paperswithcode.com/paper/multimodal-contrastive-learning-for-spatial</link>
      <description><![CDATA[In this paper, we propose \textbf{mclSTExp}, a multimodal contrastive learning with Transformer and Densenet-121 encoder for Spatial Transcriptomics Expression prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-contrastive-learning-for-spatial</guid>
    </item>
    <item>
      <title>Gradient Boosting Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/gradient-boosting-reinforcement-learning</link>
      <description><![CDATA[GBRL expands the toolkit for RL practitioners, demonstrating the viability and promise of GBT within the RL paradigm, particularly in domains characterized by structured or categorical features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gradient-boosting-reinforcement-learning</guid>
    </item>
    <item>
      <title>DSCENet: Dynamic Screening and Clinical-Enhanced Multimodal Fusion for MPNs Subtype Classification</title>
      <link>https://paperswithcode.com/paper/dscenet-dynamic-screening-and-clinical</link>
      <description><![CDATA[(1) A dynamic screening module is proposed to flexibly adapt the feature learning of local patches, reducing the interference of irrelevant features and enhancing their diagnostic representativeness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dscenet-dynamic-screening-and-clinical</guid>
    </item>
    <item>
      <title>Chromosomal Structural Abnormality Diagnosis by Homologous Similarity</title>
      <link>https://paperswithcode.com/paper/chromosomal-structural-abnormality-diagnosis</link>
      <description><![CDATA[Pathogenic chromosome abnormalities are very common among the general population.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chromosomal-structural-abnormality-diagnosis</guid>
    </item>
    <item>
      <title>Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation</title>
      <link>https://paperswithcode.com/paper/natural-language-is-not-enough-benchmarking</link>
      <description><![CDATA[Natural language interfaces have exhibited considerable potential in the automation of Verilog generation derived from high-level specifications through the utilization of large language models, garnering significant attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/natural-language-is-not-enough-benchmarking</guid>
    </item>
    <item>
      <title>eyeballvul: a future-proof benchmark for vulnerability detection in the wild</title>
      <link>https://paperswithcode.com/paper/eyeballvul-a-future-proof-benchmark-for</link>
      <description><![CDATA[The benchmark consists of a list of revisions in different repositories, each associated with the list of known vulnerabilities present at that revision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eyeballvul-a-future-proof-benchmark-for</guid>
    </item>
    <item>
      <title>Latent Spaces Enable Transformer-Based Dose Prediction in Complex Radiotherapy Plans</title>
      <link>https://paperswithcode.com/paper/latent-spaces-enable-transformer-based-dose</link>
      <description><![CDATA[Evidence is accumulating in favour of using stereotactic ablative body radiotherapy (SABR) to treat multiple cancer lesions in the lung.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-spaces-enable-transformer-based-dose</guid>
    </item>
    <item>
      <title>MeshAvatar: Learning High-quality Triangular Human Avatars from Multi-view Videos</title>
      <link>https://paperswithcode.com/paper/meshavatar-learning-high-quality-triangular</link>
      <description><![CDATA[We present a novel pipeline for learning high-quality triangular human avatars from multi-view videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meshavatar-learning-high-quality-triangular</guid>
    </item>
    <item>
      <title>CAR-MFL: Cross-Modal Augmentation by Retrieval for Multimodal Federated Learning with Missing Modalities</title>
      <link>https://paperswithcode.com/paper/car-mfl-cross-modal-augmentation-by-retrieval</link>
      <description><![CDATA[Toward this, we propose a novel method for multimodal federated learning with missing modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/car-mfl-cross-modal-augmentation-by-retrieval</guid>
    </item>
    <item>
      <title>Adversarial-MidiBERT: Symbolic Music Understanding Model Based on Unbias Pre-training and Mask Fine-tuning</title>
      <link>https://paperswithcode.com/paper/adversarial-midibert-symbolic-music</link>
      <description><![CDATA[Recently, pre-trained language models have been widely adopted in SMU because the symbolic music shares a huge similarity with natural language, and the pre-trained manner also helps make full use of limited music data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-midibert-symbolic-music</guid>
    </item>
    <item>
      <title>Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models</title>
      <link>https://paperswithcode.com/paper/establishing-rigorous-and-cost-effective</link>
      <description><![CDATA[We envision DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and transformative evaluation methodologies for AI models in clinical practice, offering a preclinical-like setting mirroring conventional medicine, and reshaping development paradigms in a cost-effective and fast-iterative manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/establishing-rigorous-and-cost-effective</guid>
    </item>
    <item>
      <title>Enriching Information and Preserving Semantic Consistency in Expanding Curvilinear Object Segmentation Datasets</title>
      <link>https://paperswithcode.com/paper/enriching-information-and-preserving-semantic</link>
      <description><![CDATA[To address these challenges, this paper introduces a novel approach for expanding curvilinear object segmentation datasets, focusing on enhancing the informativeness of generated data and the consistency between semantic maps and generated images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enriching-information-and-preserving-semantic</guid>
    </item>
    <item>
      <title>GTA: A Benchmark for General Tool Agents</title>
      <link>https://paperswithcode.com/paper/gta-a-benchmark-for-general-tool-agents</link>
      <description><![CDATA[This poses a challenge to LLMs' tool-use capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gta-a-benchmark-for-general-tool-agents</guid>
    </item>
    <item>
      <title>DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception</title>
      <link>https://paperswithcode.com/paper/densefusion-1m-merging-vision-experts-for</link>
      <description><![CDATA[To facilitate the cutting-edge research of MLLMs on comprehensive vision perception, we thereby propose Perceptual Fusion, using a low-budget but highly effective caption engine for complete and accurate image descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/densefusion-1m-merging-vision-experts-for</guid>
    </item>
    <item>
      <title>ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions</title>
      <link>https://paperswithcode.com/paper/elasticast-an-audio-spectrogram-transformer</link>
      <description><![CDATA[Transformer-based models, such as the Audio Spectrogram Transformers (AST), also inherit the fixed-size input paradigm from CNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elasticast-an-audio-spectrogram-transformer</guid>
    </item>
    <item>
      <title>An Economic Framework for 6-DoF Grasp Detection</title>
      <link>https://paperswithcode.com/paper/an-economic-framework-for-6-dof-grasp</link>
      <description><![CDATA[In this work, we propose an economic framework for 6-DoF grasp detection, aiming to economize the resource cost in training and meanwhile maintain effective grasp performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-economic-framework-for-6-dof-grasp</guid>
    </item>
    <item>
      <title>Joint Optimization of Age of Information and Energy Consumption in NR-V2X System based on Deep Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/joint-optimization-of-age-of-information-and</link>
      <description><![CDATA[To address this, 3GPP has developed Vehicle-to-Everything (V2X) specifications based on 5G New Radio (NR) technology, where Mode 2 Side-Link (SL) communication resembles Mode 4 in LTE-V2X, allowing direct communication between vehicles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/joint-optimization-of-age-of-information-and</guid>
    </item>
    <item>
      <title>Hardware Neural Control of CartPole and F1TENTH Race Car</title>
      <link>https://paperswithcode.com/paper/hardware-neural-control-of-cartpole-and</link>
      <description><![CDATA[We demonstrate kHz control rates for a physical cartpole and offloading control to the FPGA hardware on the F1TENTH car.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hardware-neural-control-of-cartpole-and</guid>
    </item>
    <item>
      <title>WayveScenes101: A Dataset and Benchmark for Novel View Synthesis in Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/wayvescenes101-a-dataset-and-benchmark-for</link>
      <description><![CDATA[We present WayveScenes101, a dataset designed to help the community advance the state of the art in novel view synthesis that focuses on challenging driving scenes containing many dynamic and deformable elements with changing geometry and texture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wayvescenes101-a-dataset-and-benchmark-for</guid>
    </item>
    <item>
      <title>SEED-Story: Multimodal Long Story Generation with Large Language Model</title>
      <link>https://paperswithcode.com/paper/seed-story-multimodal-long-story-generation</link>
      <description><![CDATA[We further propose multimodal attention sink mechanism to enable the generation of stories with up to 25 sequences (only 10 for training) in a highly efficient autoregressive manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seed-story-multimodal-long-story-generation</guid>
    </item>
    <item>
      <title>VideoMamba: Spatio-Temporal Selective State Space Model</title>
      <link>https://paperswithcode.com/paper/videomamba-spatio-temporal-selective-state</link>
      <description><![CDATA[We introduce VideoMamba, a novel adaptation of the pure Mamba architecture, specifically designed for video recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videomamba-spatio-temporal-selective-state</guid>
    </item>
    <item>
      <title>Video Diffusion Alignment via Reward Gradients</title>
      <link>https://paperswithcode.com/paper/video-diffusion-alignment-via-reward</link>
      <description><![CDATA[We show that backpropagating gradients from these reward models to a video diffusion model can allow for compute and sample efficient alignment of the video diffusion model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-diffusion-alignment-via-reward</guid>
    </item>
    <item>
      <title>Approaching Outside: Scaling Unsupervised 3D Object Detection from 2D Scene</title>
      <link>https://paperswithcode.com/paper/approaching-outside-scaling-unsupervised-3d</link>
      <description><![CDATA[In this paper, we are among the early attempts to integrate LiDAR data with 2D images for unsupervised 3D detection and introduce a new method, dubbed LiDAR-2D Self-paced Learning (LiSe).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/approaching-outside-scaling-unsupervised-3d</guid>
    </item>
    <item>
      <title>SRPose: Two-view Relative Pose Estimation with Sparse Keypoints</title>
      <link>https://paperswithcode.com/paper/srpose-two-view-relative-pose-estimation-with</link>
      <description><![CDATA[Two-view pose estimation is essential for map-free visual relocalization and object pose tracking tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/srpose-two-view-relative-pose-estimation-with</guid>
    </item>
    <item>
      <title>Exemplar-free Continual Representation Learning via Learnable Drift Compensation</title>
      <link>https://paperswithcode.com/paper/exemplar-free-continual-representation</link>
      <description><![CDATA[Prototype-based approaches, when continually updated, face the critical issue of semantic drift due to which the old class prototypes drift to different positions in the new feature space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exemplar-free-continual-representation</guid>
    </item>
    <item>
      <title>SCPNet: Unsupervised Cross-modal Homography Estimation via Intra-modal Self-supervised Learning</title>
      <link>https://paperswithcode.com/paper/scpnet-unsupervised-cross-modal-homography</link>
      <description><![CDATA[The correlation-based homography estimation network and the consistent feature map projection are combined to form the learnable architecture of SCPNet, boosting the unsupervised learning framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scpnet-unsupervised-cross-modal-homography</guid>
    </item>
    <item>
      <title>Transformer Circuit Faithfulness Metrics are not Robust</title>
      <link>https://paperswithcode.com/paper/transformer-circuit-faithfulness-metrics-are</link>
      <description><![CDATA[Prior work has attempted to measure circuit 'faithfulness' -- the degree to which the circuit replicates the performance of the full model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-circuit-faithfulness-metrics-are</guid>
    </item>
    <item>
      <title>Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter</title>
      <link>https://paperswithcode.com/paper/urban-waterlogging-detection-a-challenging</link>
      <description><![CDATA[Urban waterlogging poses a major risk to public safety and infrastructure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/urban-waterlogging-detection-a-challenging</guid>
    </item>
    <item>
      <title>The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective</title>
      <link>https://paperswithcode.com/paper/the-synergy-between-data-and-multi-modal</link>
      <description><![CDATA[As LLMs and MLLMs rely on vast amounts of model parameters and data to achieve emergent capabilities, the importance of data is receiving increasingly widespread attention and recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-synergy-between-data-and-multi-modal</guid>
    </item>
    <item>
      <title>stEnTrans: Transformer-based deep learning for spatial transcriptomics enhancement</title>
      <link>https://paperswithcode.com/paper/stentrans-transformer-based-deep-learning-for</link>
      <description><![CDATA[The spatial location of cells within tissues and organs is crucial for the manifestation of their specific functions. Spatial transcriptomics technology enables comprehensive measurement of the gene expression patterns in tissues while retaining spatial information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stentrans-transformer-based-deep-learning-for</guid>
    </item>
    <item>
      <title>AddressCLIP: Empowering Vision-Language Models for City-wide Image Address Localization</title>
      <link>https://paperswithcode.com/paper/addressclip-empowering-vision-language-models</link>
      <description><![CDATA[In this study, we introduce a new problem raised by social media and photojournalism, named Image Address Localization (IAL), which aims to predict the readable textual address where an image was taken.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/addressclip-empowering-vision-language-models</guid>
    </item>
    <item>
      <title>Enhancing Thermal Infrared Tracking with Natural Language Modeling and Coordinate Sequence Generation</title>
      <link>https://paperswithcode.com/paper/enhancing-thermal-infrared-tracking-with</link>
      <description><![CDATA[In this paper, to address these issues, we apply natural language modeling to TIR tracking and propose a novel model called NLMTrack, which enhances the utilization of coordinate and temporal information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-thermal-infrared-tracking-with</guid>
    </item>
    <item>
      <title>BiasPruner: Debiased Continual Learning for Medical Image Classification</title>
      <link>https://paperswithcode.com/paper/biaspruner-debiased-continual-learning-for</link>
      <description><![CDATA[Utilizing a new bias score that measures the contribution of each unit in the network to learning spurious features, BiasPruner prunes those units with the highest bias scores to form a debiased subnetwork preserved for a given task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biaspruner-debiased-continual-learning-for</guid>
    </item>
    <item>
      <title>Knowledge distillation to effectively attain both region-of-interest and global semantics from an image where multiple objects appear</title>
      <link>https://paperswithcode.com/paper/knowledge-distillation-to-effectively-attain</link>
      <description><![CDATA[The images in which only the ROI was preserved were fed as inputs to fine-tune various off-the-shelf models that encoded their own inductive biases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/knowledge-distillation-to-effectively-attain</guid>
    </item>
    <item>
      <title>MAVIS: Mathematical Visual Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/mavis-mathematical-visual-instruction-tuning</link>
      <description><![CDATA[We identify three key areas within MLLMs that need to be improved: visual encoding of math diagrams, diagram-language alignment, and mathematical reasoning skills.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mavis-mathematical-visual-instruction-tuning</guid>
    </item>
    <item>
      <title>Histopathological Image Classification with Cell Morphology Aware Deep Neural Networks</title>
      <link>https://paperswithcode.com/paper/histopathological-image-classification-with</link>
      <description><![CDATA[To deal with this problem, we propose a novel DeepCMorph model pre-trained to learn cell morphology and identify a large number of different cancer types.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/histopathological-image-classification-with</guid>
    </item>
    <item>
      <title>SR-Mamba: Effective Surgical Phase Recognition with State Space Model</title>
      <link>https://paperswithcode.com/paper/sr-mamba-effective-surgical-phase-recognition</link>
      <description><![CDATA[Inspired by the recent success of Mamba, a state space model with linear scalability in sequence length, this paper presents SR-Mamba, a novel attention-free model specifically tailored to meet the challenges of surgical phase recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sr-mamba-effective-surgical-phase-recognition</guid>
    </item>
    <item>
      <title>A Comprehensive Survey on Human Video Generation: Challenges, Methods, and Insights</title>
      <link>https://paperswithcode.com/paper/a-comprehensive-survey-on-human-video</link>
      <description><![CDATA[The goal of this survey is to offer the research community a clear and holistic view of the advancements in human video generation, highlighting the milestones achieved and the challenges that lie ahead.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comprehensive-survey-on-human-video</guid>
    </item>
    <item>
      <title>Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion</title>
      <link>https://paperswithcode.com/paper/vox-populi-vox-ai-using-language-models-to</link>
      <description><![CDATA[The recent development of large language models (LLMs) has spurred discussions about whether LLM-generated "synthetic samples" could complement or replace traditional surveys, considering their training data potentially reflects attitudes and behaviors prevalent in the population.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vox-populi-vox-ai-using-language-models-to</guid>
    </item>
    <item>
      <title>Prediction Exposes Your Face: Black-box Model Inversion via Prediction Alignment</title>
      <link>https://paperswithcode.com/paper/prediction-exposes-your-face-black-box-model</link>
      <description><![CDATA[Model inversion (MI) attack reconstructs the private training data of a target model given its output, posing a significant threat to deep learning models and data privacy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prediction-exposes-your-face-black-box-model</guid>
    </item>
    <item>
      <title>$β$-DPO: Direct Preference Optimization with Dynamic $β$</title>
      <link>https://paperswithcode.com/paper/b-dpo-direct-preference-optimization-with</link>
      <description><![CDATA[Direct Preference Optimization (DPO) has emerged as a compelling approach for training Large Language Models (LLMs) to adhere to human preferences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/b-dpo-direct-preference-optimization-with</guid>
    </item>
    <item>
      <title>Learning Localization of Body and Finger Animation Skeleton Joints on Three-Dimensional Models of Human Bodies</title>
      <link>https://paperswithcode.com/paper/learning-localization-of-body-and-finger</link>
      <description><![CDATA[Given only a list of point coordinates and normal vector estimates as input, a dynamic graph convolutional neural network is used to predict the coefficients of the convex combinations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-localization-of-body-and-finger</guid>
    </item>
    <item>
      <title>Multi-modal Crowd Counting via a Broker Modality</title>
      <link>https://paperswithcode.com/paper/multi-modal-crowd-counting-via-a-broker</link>
      <description><![CDATA[Multi-modal crowd counting involves estimating crowd density from both visual and thermal/depth images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-modal-crowd-counting-via-a-broker</guid>
    </item>
    <item>
      <title>ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/vitime-a-visual-intelligence-based-foundation</link>
      <description><![CDATA[The success of large pretrained models in natural language processing (NLP) and computer vision (CV) has opened new avenues for constructing foundation models for time series forecasting (TSF).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vitime-a-visual-intelligence-based-foundation</guid>
    </item>
    <item>
      <title>H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper</title>
      <link>https://paperswithcode.com/paper/h-fcbformer-hierarchical-fully-convolutional</link>
      <description><![CDATA[The most common method for occlusal contact detection is articulating paper.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h-fcbformer-hierarchical-fully-convolutional</guid>
    </item>
    <item>
      <title>Flow4D: Leveraging 4D Voxel Network for LiDAR Scene Flow Estimation</title>
      <link>https://paperswithcode.com/paper/flow4d-leveraging-4d-voxel-network-for-lidar</link>
      <description><![CDATA[In addition, Flow4D further improves performance by using five frames to take advantage of richer temporal information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flow4d-leveraging-4d-voxel-network-for-lidar</guid>
    </item>
    <item>
      <title>FALFormer: Feature-aware Landmarks self-attention for Whole-slide Image Classification</title>
      <link>https://paperswithcode.com/paper/falformer-feature-aware-landmarks-self</link>
      <description><![CDATA[Herein, we propose an efficient and effective slide-level classification model, named as FALFormer, that can process a WSI as a whole so as to fully exploit the relationship among the entire patches and to improve the classification performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/falformer-feature-aware-landmarks-self</guid>
    </item>
    <item>
      <title>Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard</title>
      <link>https://paperswithcode.com/paper/evaluating-large-language-models-with-grid</link>
      <description><![CDATA[We introduce a novel and extensible benchmark for large language models (LLMs) through grid-based games such as Tic-Tac-Toe, Connect Four, and Gomoku.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-large-language-models-with-grid</guid>
    </item>
  </channel>
</rss>
