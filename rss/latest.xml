<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 25 Aug 2023 21:05:19 +0000</lastBuildDate>
    <item>
      <title>Fast Adversarial Training with Smooth Convergence</title>
      <link>https://paperswithcode.com/paper/fast-adversarial-training-with-smooth</link>
      <description><![CDATA[To address this, we analyze the training process of prior FAT work and observe that catastrophic overfitting is accompanied by the appearance of loss convergence outliers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-adversarial-training-with-smooth</guid>
    </item>
    <item>
      <title>Perspective-aware Convolution for Monocular 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</link>
      <description><![CDATA[Monocular 3D object detection is a crucial and challenging task for autonomous driving vehicle, while it uses only a single camera image to infer 3D objects in the scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perspective-aware-convolution-for-monocular</guid>
    </item>
    <item>
      <title>American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers</title>
      <link>https://paperswithcode.com/paper/american-stories-a-large-scale-structured</link>
      <description><![CDATA[The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/american-stories-a-large-scale-structured</guid>
    </item>
    <item>
      <title>Improving Translation Faithfulness of Large Language Models via Augmenting Instructions</title>
      <link>https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</link>
      <description><![CDATA[The experimental results demonstrate significant improvements in translation performance with SWIE based on BLOOMZ-3b, particularly in zero-shot and long text translations due to reduced instruction forgetting risk.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-translation-faithfulness-of-large</guid>
    </item>
    <item>
      <title>kTrans: Knowledge-Aware Transformer for Binary Code Embedding</title>
      <link>https://paperswithcode.com/paper/ktrans-knowledge-aware-transformer-for-binary</link>
      <description><![CDATA[By feeding explicit knowledge as additional inputs to the Transformer, and fusing implicit knowledge with a novel pre-training task, kTrans provides a new perspective to incorporating domain knowledge into a Transformer framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ktrans-knowledge-aware-transformer-for-binary</guid>
    </item>
    <item>
      <title>Single-shot Bayesian approximation for neural networks</title>
      <link>https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</link>
      <description><![CDATA[We demonstrate that our single-shot MC dropout approximation resembles the point estimate and the uncertainty estimate of the predictive distribution that is achieved with an MC approach, while being fast enough for real-time deployments of BNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/single-shot-bayesian-approximation-for-neural</guid>
    </item>
    <item>
      <title>Motion In-Betweening with Phase Manifolds</title>
      <link>https://paperswithcode.com/paper/motion-in-betweening-with-phase-manifolds</link>
      <description><![CDATA[This paper introduces a novel data-driven motion in-betweening system to reach target poses of characters by making use of phases variables learned by a Periodic Autoencoder.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motion-in-betweening-with-phase-manifolds</guid>
    </item>
    <item>
      <title>On Popularity Bias of Multimodal-aware Recommender Systems: a Modalities-driven Analysis</title>
      <link>https://paperswithcode.com/paper/on-popularity-bias-of-multimodal-aware</link>
      <description><![CDATA[Multimodal-aware recommender systems (MRSs) exploit multimodal content (e. g., product images or descriptions) as items' side information to improve recommendation accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-popularity-bias-of-multimodal-aware</guid>
    </item>
    <item>
      <title>Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</link>
      <description><![CDATA[The challenges of this task lie in the complexity of the scenes, the unique features of anime style, and the lack of high-quality datasets to bridge the domain gap.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scenimefy-learning-to-craft-anime-scene-via</guid>
    </item>
    <item>
      <title>Evolutionary Dynamic Optimization Laboratory: A MATLAB Optimization Platform for Education and Experimentation in Dynamic Environments</title>
      <link>https://paperswithcode.com/paper/evolutionary-dynamic-optimization-laboratory</link>
      <description><![CDATA[In this paper, to assist researchers in performing experiments and comparing their algorithms against several EDOAs, we develop an open-source MATLAB platform for EDOAs, called Evolutionary Dynamic Optimization LABoratory (EDOLAB).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evolutionary-dynamic-optimization-laboratory</guid>
    </item>
    <item>
      <title>DD-GCN: Directed Diffusion Graph Convolutional Network for Skeleton-based Human Action Recognition</title>
      <link>https://paperswithcode.com/paper/dd-gcn-directed-diffusion-graph-convolutional</link>
      <description><![CDATA[Graph Convolutional Networks (GCNs) have been widely used in skeleton-based human action recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dd-gcn-directed-diffusion-graph-convolutional</guid>
    </item>
    <item>
      <title>Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?</title>
      <link>https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</link>
      <description><![CDATA[The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-linguistic-knowledge-improve-multimodal</guid>
    </item>
    <item>
      <title>Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers</title>
      <link>https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</link>
      <description><![CDATA[Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-look-into-the-sun-adversarial</guid>
    </item>
    <item>
      <title>BridgeData V2: A Dataset for Robot Learning at Scale</title>
      <link>https://paperswithcode.com/paper/bridgedata-v2-a-dataset-for-robot-learning-at</link>
      <description><![CDATA[By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bridgedata-v2-a-dataset-for-robot-learning-at</guid>
    </item>
    <item>
      <title>Mutual-Guided Dynamic Network for Image Fusion</title>
      <link>https://paperswithcode.com/paper/mutual-guided-dynamic-network-for-image</link>
      <description><![CDATA[Image fusion aims to generate a high-quality image from multiple images captured under varying conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mutual-guided-dynamic-network-for-image</guid>
    </item>
    <item>
      <title>Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]</title>
      <link>https://paperswithcode.com/paper/unified-data-management-and-comprehensive</link>
      <description><![CDATA[The field of urban spatial-temporal prediction is advancing rapidly with the development of deep learning techniques and the availability of large-scale datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-data-management-and-comprehensive</guid>
    </item>
    <item>
      <title>Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis</title>
      <link>https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</link>
      <description><![CDATA[The model pretrained on large-scale rs-fMRI data has been released to the public.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/source-free-collaborative-domain-adaptation</guid>
    </item>
    <item>
      <title>CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias</title>
      <link>https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</link>
      <description><![CDATA[To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/calm-a-multi-task-benchmark-for-comprehensive</guid>
    </item>
    <item>
      <title>Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines</title>
      <link>https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</link>
      <description><![CDATA[This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-hungarian-text-processing-with</guid>
    </item>
    <item>
      <title>Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints</title>
      <link>https://paperswithcode.com/paper/master-slave-deep-architecture-for-top-k</link>
      <description><![CDATA[We propose a novel master-slave architecture to solve the top-$K$ combinatorial multi-armed bandits problem with non-linear bandit feedback and diversity constraints, which, to the best of our knowledge, is the first combinatorial bandits setting considering diversity constraints under bandit feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/master-slave-deep-architecture-for-top-k</guid>
    </item>
    <item>
      <title>Attention-Based Acoustic Feature Fusion Network for Depression Detection</title>
      <link>https://paperswithcode.com/paper/attention-based-acoustic-feature-fusion</link>
      <description><![CDATA[To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-based-acoustic-feature-fusion</guid>
    </item>
    <item>
      <title>NOVA: NOvel View Augmentation for Neural Composition of Dynamic Objects</title>
      <link>https://paperswithcode.com/paper/nova-novel-view-augmentation-for-neural</link>
      <description><![CDATA[We propose a novel-view augmentation (NOVA) strategy to train NeRFs for photo-realistic 3D composition of dynamic objects in a static scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nova-novel-view-augmentation-for-neural</guid>
    </item>
    <item>
      <title>HuBo-VLM: Unified Vision-Language Model designed for HUman roBOt interaction tasks</title>
      <link>https://paperswithcode.com/paper/hubo-vlm-unified-vision-language-model</link>
      <description><![CDATA[Human robot interaction is an exciting task, which aimed to guide robots following instructions from human.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hubo-vlm-unified-vision-language-model</guid>
    </item>
    <item>
      <title>Large Language Models Vote: Prompting for Rare Disease Identification</title>
      <link>https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</link>
      <description><![CDATA[The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-vote-prompting-for-rare</guid>
    </item>
    <item>
      <title>Less is More: Towards Efficient Few-shot 3D Semantic Segmentation via Training-free Networks</title>
      <link>https://paperswithcode.com/paper/less-is-more-towards-efficient-few-shot-3d</link>
      <description><![CDATA[However, the prior pre-training stage not only introduces excessive time overhead, but also incurs a significant domain gap on `unseen' classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-is-more-towards-efficient-few-shot-3d</guid>
    </item>
    <item>
      <title>REB: Reducing Biases in Representation for Industrial Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/reb-reducing-biases-in-representation-for</link>
      <description><![CDATA[Additionally, we propose a local density KNN (LDKNN) to reduce the local density bias and obtain effective anomaly detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reb-reducing-biases-in-representation-for</guid>
    </item>
    <item>
      <title>Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods</title>
      <link>https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</link>
      <description><![CDATA[We introduce an open-source GitHub repository containing comprehensive benchmarks for a wide range of machine scheduling problems, including Job Shop Scheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling (FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent Setup Times (FJSP-SDST), and the online FJSP (with online job arrivals).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/job-shop-scheduling-benchmark-environments</guid>
    </item>
    <item>
      <title>Match-And-Deform: Time Series Domain Adaptation through Optimal Transport and Temporal Alignment</title>
      <link>https://paperswithcode.com/paper/match-and-deform-time-series-domain</link>
      <description><![CDATA[While large volumes of unlabeled data are usually available, associated labels are often scarce.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/match-and-deform-time-series-domain</guid>
    </item>
    <item>
      <title>Ground-to-Aerial Person Search: Benchmark Dataset and Approach</title>
      <link>https://paperswithcode.com/paper/ground-to-aerial-person-search-benchmark</link>
      <description><![CDATA[In this work, we construct a large-scale dataset for Ground-to-Aerial Person Search, named G2APS, which contains 31, 770 images of 260, 559 annotated bounding boxes for 2, 644 identities appearing in both of the UAVs and ground surveillance cameras.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ground-to-aerial-person-search-benchmark</guid>
    </item>
    <item>
      <title>Robotic Scene Segmentation with Memory Network for Runtime Surgical Context Inference</title>
      <link>https://paperswithcode.com/paper/robotic-scene-segmentation-with-memory</link>
      <description><![CDATA[However, runtime context inference is challenging since it requires timely and accurate detection of the interactions among the tools and objects in the surgical scene based on the segmentation of video data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robotic-scene-segmentation-with-memory</guid>
    </item>
    <item>
      <title>Dense Text-to-Image Generation with Attention Modulation</title>
      <link>https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</link>
      <description><![CDATA[To address this, we propose DenseDiffusion, a training-free method that adapts a pre-trained text-to-image model to handle such dense captions while offering control over the scene layout.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</guid>
    </item>
    <item>
      <title>HR-Pro: Point-supervised Temporal Action Localization via Hierarchical Reliability Propagation</title>
      <link>https://paperswithcode.com/paper/hr-pro-point-supervised-temporal-action</link>
      <description><![CDATA[For snippet-level learning, we introduce an online-updated memory to store reliable snippet prototypes for each class.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hr-pro-point-supervised-temporal-action</guid>
    </item>
    <item>
      <title>Masked Autoencoders are Efficient Class Incremental Learners</title>
      <link>https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</link>
      <description><![CDATA[Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masked-autoencoders-are-efficient-class</guid>
    </item>
    <item>
      <title>Laying foundations to quantify the "Effort of Reproducibility"</title>
      <link>https://paperswithcode.com/paper/laying-foundations-to-quantify-the-effort-of</link>
      <description><![CDATA[Why are some research studies easy to reproduce while others are difficult?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/laying-foundations-to-quantify-the-effort-of</guid>
    </item>
    <item>
      <title>Learning Heavily-Degraded Prior for Underwater Object Detection</title>
      <link>https://paperswithcode.com/paper/learning-heavily-degraded-prior-for</link>
      <description><![CDATA[Therefore, we propose a residual feature transference module (RFTM) to learn a mapping between deep representations of the heavily degraded patches of DFUI- and underwater- images, and make the mapping as a heavily degraded prior (HDP) for underwater detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-heavily-degraded-prior-for</guid>
    </item>
    <item>
      <title>Implicit Obstacle Map-driven Indoor Navigation Model for Robust Obstacle Avoidance</title>
      <link>https://paperswithcode.com/paper/implicit-obstacle-map-driven-indoor</link>
      <description><![CDATA[Robust obstacle avoidance is one of the critical steps for successful goal-driven indoor navigation tasks. Due to the obstacle missing in the visual image and the possible missed detection issue, visual image-based obstacle avoidance techniques still suffer from unsatisfactory robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implicit-obstacle-map-driven-indoor</guid>
    </item>
    <item>
      <title>Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities</title>
      <link>https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</link>
      <description><![CDATA[We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</guid>
    </item>
    <item>
      <title>Grounded Entity-Landmark Adaptive Pre-training for Vision-and-Language Navigation</title>
      <link>https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</link>
      <description><![CDATA[To address this problem, we propose a novel Grounded Entity-Landmark Adaptive (GELA) pre-training paradigm for VLN tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grounded-entity-landmark-adaptive-pre</guid>
    </item>
    <item>
      <title>Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges</title>
      <link>https://paperswithcode.com/paper/deploying-deep-reinforcement-learning-systems</link>
      <description><![CDATA[In this paper, we propose an empirical study on Stack Overflow (SO), the most popular Q&A forum for developers, to uncover and understand the challenges practitioners faced when deploying DRL systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deploying-deep-reinforcement-learning-systems</guid>
    </item>
    <item>
      <title>TAI-GAN: Temporally and Anatomically Informed GAN for early-to-late frame conversion in dynamic cardiac PET motion correction</title>
      <link>https://paperswithcode.com/paper/tai-gan-temporally-and-anatomically-informed</link>
      <description><![CDATA[The rapid tracer kinetics of rubidium-82 ($^{82}$Rb) and high variation of cross-frame distribution in dynamic cardiac positron emission tomography (PET) raise significant challenges for inter-frame motion correction, particularly for the early frames where conventional intensity-based image registration techniques are not applicable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tai-gan-temporally-and-anatomically-informed</guid>
    </item>
    <item>
      <title>SPPNet: A Single-Point Prompt Network for Nuclei Image Segmentation</title>
      <link>https://paperswithcode.com/paper/sppnet-a-single-point-prompt-network-for</link>
      <description><![CDATA[Compared to the segment anything model, SPPNet shows roughly 20 times faster inference, with 1/70 parameters and computational cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sppnet-a-single-point-prompt-network-for</guid>
    </item>
    <item>
      <title>Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning</title>
      <link>https://paperswithcode.com/paper/diffusion-language-models-can-perform-many</link>
      <description><![CDATA[We then reprogram pretrained masked language models into diffusion language models via diffusive adaptation, wherein task-specific finetuning and instruction finetuning are explored to unlock their versatility in solving general language tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-language-models-can-perform-many</guid>
    </item>
    <item>
      <title>Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages</title>
      <link>https://paperswithcode.com/paper/large-multilingual-models-pivot-zero-shot</link>
      <description><![CDATA[Building a competitive counterpart in other languages is highly challenging due to the low-resource nature of non-English multimodal data (i. e., lack of large-scale, high-quality image-text data).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-multilingual-models-pivot-zero-shot</guid>
    </item>
    <item>
      <title>Manipulating Embeddings of Stable Diffusion Prompts</title>
      <link>https://paperswithcode.com/paper/manipulating-embeddings-of-stable-diffusion</link>
      <description><![CDATA[(3) Changing the embedding of the prompt to include information that the user has seen in a particular seed but finds difficult to describe in the prompt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/manipulating-embeddings-of-stable-diffusion</guid>
    </item>
    <item>
      <title>Multi-Modal Multi-Task (3MT) Road Segmentation</title>
      <link>https://paperswithcode.com/paper/multi-modal-multi-task-3mt-road-segmentation</link>
      <description><![CDATA[The inference times obtained in all experiments are very promising for real-time experiments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-modal-multi-task-3mt-road-segmentation</guid>
    </item>
    <item>
      <title>MolGrapher: Graph-based Visual Recognition of Chemical Structures</title>
      <link>https://paperswithcode.com/paper/molgrapher-graph-based-visual-recognition-of</link>
      <description><![CDATA[In addition, we introduce a large-scale benchmark of annotated real molecule images, USPTO-30K, to spur research on this critical topic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/molgrapher-graph-based-visual-recognition-of</guid>
    </item>
    <item>
      <title>SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets</title>
      <link>https://paperswithcode.com/paper/summit-source-free-adaptation-of-uni-modal</link>
      <description><![CDATA[In this work, we relax both of these assumptions by addressing the problem of adapting a set of models trained independently on uni-modal data to a target domain consisting of unlabeled multi-modal data, without having access to the original source dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/summit-source-free-adaptation-of-uni-modal</guid>
    </item>
    <item>
      <title>Head-Tail Cooperative Learning Network for Unbiased Scene Graph Generation</title>
      <link>https://paperswithcode.com/paper/head-tail-cooperative-learning-network-for</link>
      <description><![CDATA[We also propose a self-supervised learning approach to enhance the prediction ability of the tail-prefer feature representation branch by constraining tail-prefer predicate features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/head-tail-cooperative-learning-network-for</guid>
    </item>
    <item>
      <title>Instruction Position Matters in Sequence Generation with Large Language Models</title>
      <link>https://paperswithcode.com/paper/instruction-position-matters-in-sequence</link>
      <description><![CDATA[Large language models (LLMs) are capable of performing conditional sequence generation tasks, such as translation or summarization, through instruction fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instruction-position-matters-in-sequence</guid>
    </item>
    <item>
      <title>DR-Tune: Improving Fine-tuning of Pretrained Visual Models by Distribution Regularization with Semantic Calibration</title>
      <link>https://paperswithcode.com/paper/dr-tune-improving-fine-tuning-of-pretrained</link>
      <description><![CDATA[Furthermore, to alleviate the interference by semantic drift, we develop the semantic calibration (SC) module to align the global shape and class centers of the pretrained and downstream feature distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dr-tune-improving-fine-tuning-of-pretrained</guid>
    </item>
  </channel>
</rss>
