<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 02 Mar 2024 21:05:42 +0000</lastBuildDate>
    <item>
      <title>Dual-domain strip attention for image restoration</title>
      <link>https://paperswithcode.com/paper/dual-domain-strip-attention-for-image</link>
      <description><![CDATA[In this paper, we develop a dual-domain strip attention mechanism for image restoration by enhancing representation learning, which consists of spatial and frequency strip attention units.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-domain-strip-attention-for-image</guid>
    </item>
    <item>
      <title>BigGait: Learning Gait Representation You Want by Large Vision Models</title>
      <link>https://paperswithcode.com/paper/biggait-learning-gait-representation-you-want</link>
      <description><![CDATA[Gait recognition stands as one of the most pivotal remote identification technologies and progressively expands across research and industrial communities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biggait-learning-gait-representation-you-want</guid>
    </item>
    <item>
      <title>Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes</title>
      <link>https://paperswithcode.com/paper/degradation-modeling-and-prognostic-analysis</link>
      <description><![CDATA[Then, using these degradation trajectories, we develop a time series-based clustering method to identify the training units' failure modes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/degradation-modeling-and-prognostic-analysis</guid>
    </item>
    <item>
      <title>Automated segmentation of lesions and organs at risk on [68Ga]Ga-PSMA-11 PET/CT images using self-supervised learning with Swin UNETR</title>
      <link>https://paperswithcode.com/paper/automated-segmentation-of-lesions-and-organs</link>
      <description><![CDATA[Prostate-specific membrane antigen (PSMA) PET/CT imaging is widely used for quantitative image analysis, especially in radioligand therapy (RLT) for metastatic castration-resistant prostate cancer (mCRPC).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automated-segmentation-of-lesions-and-organs</guid>
    </item>
    <item>
      <title>CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition</title>
      <link>https://paperswithcode.com/paper/cricavpr-cross-image-correlation-aware</link>
      <description><![CDATA[To further facilitate the robustness, we propose a multi-scale convolution-enhanced adaptation method to adapt pre-trained visual foundation models to the VPR task, which introduces the multi-scale local information to further enhance the cross-image correlation-aware representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cricavpr-cross-image-correlation-aware</guid>
    </item>
    <item>
      <title>Utilizing Local Hierarchy with Adversarial Training for Hierarchical Text Classification</title>
      <link>https://paperswithcode.com/paper/utilizing-local-hierarchy-with-adversarial</link>
      <description><![CDATA[Hierarchical text classification (HTC) is a challenging subtask of multi-label classification due to its complex taxonomic structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/utilizing-local-hierarchy-with-adversarial</guid>
    </item>
    <item>
      <title>Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction</title>
      <link>https://paperswithcode.com/paper/fine-structure-aware-sampling-a-new-sampling</link>
      <description><![CDATA[Lastly, to further improve the training process, FSS proposes a mesh thickness loss signal for pixel-aligned implicit models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-structure-aware-sampling-a-new-sampling</guid>
    </item>
    <item>
      <title>AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging</title>
      <link>https://paperswithcode.com/paper/adamergex-cross-lingual-transfer-with-large</link>
      <description><![CDATA[In this paper, we acknowledge the mutual reliance between task ability and language ability and direct our attention toward the gap between the target language and the source language on tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adamergex-cross-lingual-transfer-with-large</guid>
    </item>
    <item>
      <title>Aligning Knowledge Graph with Visual Perception for Object-goal Navigation</title>
      <link>https://paperswithcode.com/paper/aligning-knowledge-graph-with-visual</link>
      <description><![CDATA[Object-goal navigation is a challenging task that requires guiding an agent to specific objects based on first-person visual observations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-knowledge-graph-with-visual</guid>
    </item>
    <item>
      <title>Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap</title>
      <link>https://paperswithcode.com/paper/functional-benchmarks-for-robust-evaluation</link>
      <description><![CDATA[Models that solve a reasoning test should exhibit no difference in performance over the static version of a problem compared to a snapshot of the functional variant.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/functional-benchmarks-for-robust-evaluation</guid>
    </item>
    <item>
      <title>PEM: Prototype-based Efficient MaskFormer for Image Segmentation</title>
      <link>https://paperswithcode.com/paper/pem-prototype-based-efficient-maskformer-for</link>
      <description><![CDATA[To fill this gap, we propose Prototype-based Efficient MaskFormer (PEM), an efficient transformer-based architecture that can operate in multiple segmentation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pem-prototype-based-efficient-maskformer-for</guid>
    </item>
    <item>
      <title>Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models</title>
      <link>https://paperswithcode.com/paper/towards-tracing-trustworthiness-dynamics</link>
      <description><![CDATA[This research provides an initial exploration of trustworthiness modeling during LLM pre-training, seeking to unveil new insights and spur further developments in the field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-tracing-trustworthiness-dynamics</guid>
    </item>
    <item>
      <title>MENTOR: Multi-level Self-supervised Learning for Multimodal Recommendation</title>
      <link>https://paperswithcode.com/paper/mentor-multi-level-self-supervised-learning</link>
      <description><![CDATA[It utilizes multimodal information to alleviate the data sparsity problem in recommendation systems, thus improving recommendation accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mentor-multi-level-self-supervised-learning</guid>
    </item>
    <item>
      <title>GDCNet: Calibrationless geometric distortion correction of echo planar imaging data using deep learning</title>
      <link>https://paperswithcode.com/paper/gdcnet-calibrationless-geometric-distortion</link>
      <description><![CDATA[Traditional methods leverage a field map or voxel displacement map for distortion correction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gdcnet-calibrationless-geometric-distortion</guid>
    </item>
    <item>
      <title>Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark</title>
      <link>https://paperswithcode.com/paper/let-llms-take-on-the-latest-challenges-a</link>
      <description><![CDATA[To promote the improvement of Chinese LLMs' ability to answer dynamic questions, in this paper, we introduce CDQA, a Chinese Dynamic QA benchmark containing question-answer pairs related to the latest news on the Chinese Internet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-llms-take-on-the-latest-challenges-a</guid>
    </item>
    <item>
      <title>Trained Random Forests Completely Reveal your Dataset</title>
      <link>https://paperswithcode.com/paper/trained-random-forests-completely-reveal-your</link>
      <description><![CDATA[Even with bootstrap aggregation, the majority of the data can also be reconstructed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trained-random-forests-completely-reveal-your</guid>
    </item>
    <item>
      <title>Curiosity-driven Red-teaming for Large Language Models</title>
      <link>https://paperswithcode.com/paper/curiosity-driven-red-teaming-for-large</link>
      <description><![CDATA[To probe when an LLM generates unwanted content, the current paradigm is to recruit a \textit{red team} of human testers to design input prompts (i. e., test cases) that elicit undesirable responses from LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/curiosity-driven-red-teaming-for-large</guid>
    </item>
    <item>
      <title>Retrieval-Augmented Generation for AI-Generated Content: A Survey</title>
      <link>https://paperswithcode.com/paper/retrieval-augmented-generation-for-ai</link>
      <description><![CDATA[Furthermore, we introduce the benchmarks for RAG, discuss the limitations of current RAG systems, and suggest potential directions for future research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retrieval-augmented-generation-for-ai</guid>
    </item>
    <item>
      <title>FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning</title>
      <link>https://paperswithcode.com/paper/flexllm-a-system-for-co-serving-large</link>
      <description><![CDATA[This is because existing systems cannot handle workloads that include a mix of inference and PEFT finetuning requests.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flexllm-a-system-for-co-serving-large</guid>
    </item>
    <item>
      <title>Uncertainty-Based Extensible Codebook for Discrete Federated Learning in Heterogeneous Data Silos</title>
      <link>https://paperswithcode.com/paper/uncertainty-based-extensible-codebook-for</link>
      <description><![CDATA[Federated learning (FL), aimed at leveraging vast distributed datasets, confronts a crucial challenge: the heterogeneity of data across different silos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncertainty-based-extensible-codebook-for</guid>
    </item>
    <item>
      <title>CAMixerSR: Only Details Need More "Attention"</title>
      <link>https://paperswithcode.com/paper/camixersr-only-details-need-more-attention</link>
      <description><![CDATA[To satisfy the rapidly increasing demands on the large image (2K-8K) super-resolution (SR), prevailing methods follow two independent tracks: 1) accelerate existing networks by content-aware routing, and 2) design better super-resolution networks via token mixer refining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camixersr-only-details-need-more-attention</guid>
    </item>
    <item>
      <title>Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks</title>
      <link>https://paperswithcode.com/paper/benchmarking-uncertainty-disentanglement</link>
      <description><![CDATA[Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-uncertainty-disentanglement</guid>
    </item>
    <item>
      <title>Variable-Rate Learned Image Compression with Multi-Objective Optimization and Quantization-Reconstruction Offsets</title>
      <link>https://paperswithcode.com/paper/variable-rate-learned-image-compression-with</link>
      <description><![CDATA[Third, variable rate quantization is used also for the hyper latent.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/variable-rate-learned-image-compression-with</guid>
    </item>
    <item>
      <title>Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook</title>
      <link>https://paperswithcode.com/paper/deep-learning-for-cross-domain-data-fusion-in</link>
      <description><![CDATA[As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e. g., geographical, traffic, social media, and environmental data) and modalities (e. g., spatio-temporal, visual, and textual modalities).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-learning-for-cross-domain-data-fusion-in</guid>
    </item>
    <item>
      <title>Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/loss-aware-curriculum-learning-for</link>
      <description><![CDATA[Heterogeneous Graph Neural Networks (HGNNs) are a class of deep learning models designed specifically for heterogeneous graphs, which are graphs that contain different types of nodes and edges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/loss-aware-curriculum-learning-for</guid>
    </item>
    <item>
      <title>VEC-SBM: Optimal Community Detection with Vectorial Edges Covariates</title>
      <link>https://paperswithcode.com/paper/vec-sbm-optimal-community-detection-with</link>
      <description><![CDATA[Social networks are often associated with rich side information, such as texts and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vec-sbm-optimal-community-detection-with</guid>
    </item>
    <item>
      <title>Gradient Alignment for Cross-Domain Face Anti-Spoofing</title>
      <link>https://paperswithcode.com/paper/gradient-alignment-for-cross-domain-face-anti</link>
      <description><![CDATA[Recent advancements in domain generalization (DG) for face anti-spoofing (FAS) have garnered considerable attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gradient-alignment-for-cross-domain-face-anti</guid>
    </item>
    <item>
      <title>Optimal ANN-SNN Conversion with Group Neurons</title>
      <link>https://paperswithcode.com/paper/optimal-ann-snn-conversion-with-group-neurons</link>
      <description><![CDATA[For instance, while converting artificial neural networks (ANNs) to SNNs circumvents the need for direct training of SNNs, it encounters issues related to conversion errors and high inference time delays.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimal-ann-snn-conversion-with-group-neurons</guid>
    </item>
    <item>
      <title>Principal Component Analysis as a Sanity Check for Bayesian Phylolinguistic Reconstruction</title>
      <link>https://paperswithcode.com/paper/principal-component-analysis-as-a-sanity</link>
      <description><![CDATA[Bayesian approaches to reconstructing the evolutionary history of languages rely on the tree model, which assumes that these languages descended from a common ancestor and underwent modifications over time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/principal-component-analysis-as-a-sanity</guid>
    </item>
    <item>
      <title>Deep Learning for 3D Human Pose Estimation and Mesh Recovery: A Survey</title>
      <link>https://paperswithcode.com/paper/deep-learning-for-3d-human-pose-estimation</link>
      <description><![CDATA[To the best of our knowledge, this survey is arguably the first to comprehensively cover deep learning methods for 3D human pose estimation, including both single-person and multi-person approaches, as well as human mesh recovery, encompassing methods based on explicit models and implicit representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-learning-for-3d-human-pose-estimation</guid>
    </item>
    <item>
      <title>GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers</title>
      <link>https://paperswithcode.com/paper/gsm-plus-a-comprehensive-benchmark-for</link>
      <description><![CDATA[Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gsm-plus-a-comprehensive-benchmark-for</guid>
    </item>
    <item>
      <title>Listening to the Noise: Blind Denoising with Gibbs Diffusion</title>
      <link>https://paperswithcode.com/paper/listening-to-the-noise-blind-denoising-with</link>
      <description><![CDATA[Assuming arbitrary parametric Gaussian noise, we develop a Gibbs algorithm that alternates sampling steps from a conditional diffusion model trained to map the signal prior to the family of noise distributions, and a Monte Carlo sampler to infer the noise parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/listening-to-the-noise-blind-denoising-with</guid>
    </item>
    <item>
      <title>DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models</title>
      <link>https://paperswithcode.com/paper/distrifusion-distributed-parallel-inference</link>
      <description><![CDATA[To overcome this dilemma, we observe the high similarity between the input from adjacent diffusion steps and propose displaced patch parallelism, which takes advantage of the sequential nature of the diffusion process by reusing the pre-computed feature maps from the previous timestep to provide context for the current step.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distrifusion-distributed-parallel-inference</guid>
    </item>
    <item>
      <title>Training Generative Image Super-Resolution Models by Wavelet-Domain Losses Enables Better Control of Artifacts</title>
      <link>https://paperswithcode.com/paper/training-generative-image-super-resolution</link>
      <description><![CDATA[Although some recent works focused on the differentiation of details and artifacts, this is a very challenging problem and a satisfactory solution is yet to be found.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-generative-image-super-resolution</guid>
    </item>
    <item>
      <title>A SAM-guided Two-stream Lightweight Model for Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/a-sam-guided-two-stream-lightweight-model-for</link>
      <description><![CDATA[In this paper, considering these two critical factors, we propose a SAM-guided Two-stream Lightweight Model for unsupervised anomaly detection (STLM) that not only aligns with the two practical application requirements but also harnesses the robust generalization capabilities of SAM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-sam-guided-two-stream-lightweight-model-for</guid>
    </item>
    <item>
      <title>ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL</title>
      <link>https://paperswithcode.com/paper/archer-training-language-model-agents-via</link>
      <description><![CDATA[In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e. g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/archer-training-language-model-agents-via</guid>
    </item>
    <item>
      <title>Aligning Language Models for Versatile Text-based Item Retrieval</title>
      <link>https://paperswithcode.com/paper/aligning-language-models-for-versatile-text</link>
      <description><![CDATA[Our empirical studies demonstrate that fine-tuning embedding models on the dataset leads to remarkable improvements in a variety of retrieval tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-language-models-for-versatile-text</guid>
    </item>
    <item>
      <title>Reducing Hallucinations in Entity Abstract Summarization with Facts-Template Decomposition</title>
      <link>https://paperswithcode.com/paper/reducing-hallucinations-in-entity-abstract</link>
      <description><![CDATA[Entity abstract summarization aims to generate a coherent description of a given entity based on a set of relevant Internet documents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reducing-hallucinations-in-entity-abstract</guid>
    </item>
    <item>
      <title>Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing</title>
      <link>https://paperswithcode.com/paper/suppress-and-rebalance-towards-generalized</link>
      <description><![CDATA[Face Anti-Spoofing (FAS) is crucial for securing face recognition systems against presentation attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/suppress-and-rebalance-towards-generalized</guid>
    </item>
    <item>
      <title>DeepEraser: Deep Iterative Context Mining for Generic Text Eraser</title>
      <link>https://paperswithcode.com/paper/deeperaser-deep-iterative-context-mining-for</link>
      <description><![CDATA[In this work, we present DeepEraser, an effective deep network for generic text removal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deeperaser-deep-iterative-context-mining-for</guid>
    </item>
    <item>
      <title>Accelerating materials discovery for polymer solar cells: Data-driven insights enabled by natural language processing</title>
      <link>https://paperswithcode.com/paper/accelerating-materials-discovery-for-polymer</link>
      <description><![CDATA[We present a natural language processing pipeline that was used to extract polymer solar cell property data from the literature and simulate various active learning strategies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-materials-discovery-for-polymer</guid>
    </item>
    <item>
      <title>Spyx: A Library for Just-In-Time Compiled Optimization of Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/spyx-a-library-for-just-in-time-compiled</link>
      <description><![CDATA[As the role of artificial intelligence becomes increasingly pivotal in modern society, the efficient training and deployment of deep neural networks have emerged as critical areas of focus.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spyx-a-library-for-just-in-time-compiled</guid>
    </item>
    <item>
      <title>One model to use them all: Training a segmentation model with complementary datasets</title>
      <link>https://paperswithcode.com/paper/one-model-to-use-them-all-training-a</link>
      <description><![CDATA[In this work, we propose a method to combine multiple partially annotated datasets, which provide complementary annotations, into one model, enabling better scene segmentation and the use of multiple readily available datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-model-to-use-them-all-training-a</guid>
    </item>
    <item>
      <title>A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/a-cognitive-based-trajectory-prediction</link>
      <description><![CDATA[In autonomous vehicle (AV) technology, the ability to accurately predict the movements of surrounding vehicles is paramount for ensuring safety and operational efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-cognitive-based-trajectory-prediction</guid>
    </item>
    <item>
      <title>WDM: 3D Wavelet Diffusion Models for High-Resolution Medical Image Synthesis</title>
      <link>https://paperswithcode.com/paper/wdm-3d-wavelet-diffusion-models-for-high</link>
      <description><![CDATA[Due to the three-dimensional nature of CT- or MR-scans, generative modeling of medical images is a particularly challenging task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wdm-3d-wavelet-diffusion-models-for-high</guid>
    </item>
    <item>
      <title>Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning</title>
      <link>https://paperswithcode.com/paper/analyzing-and-reducing-catastrophic</link>
      <description><![CDATA[Through extensive experiments, we uncover the mode connectivity phenomenon in the LLMs continual learning scenario and find that it can strike a balance between plasticity and stability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/analyzing-and-reducing-catastrophic</guid>
    </item>
    <item>
      <title>DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly</title>
      <link>https://paperswithcode.com/paper/diffassemble-a-unified-graph-diffusion-model</link>
      <description><![CDATA[Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffassemble-a-unified-graph-diffusion-model</guid>
    </item>
    <item>
      <title>Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress</title>
      <link>https://paperswithcode.com/paper/lifelong-benchmarks-efficient-model</link>
      <description><![CDATA[However, with repeated testing, the risk of overfitting grows as algorithms over-exploit benchmark idiosyncrasies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lifelong-benchmarks-efficient-model</guid>
    </item>
    <item>
      <title>Theoretically Achieving Continuous Representation of Oriented Bounding Boxes</title>
      <link>https://paperswithcode.com/paper/theoretically-achieving-continuous</link>
      <description><![CDATA[Considerable efforts have been devoted to Oriented Object Detection (OOD).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/theoretically-achieving-continuous</guid>
    </item>
    <item>
      <title>Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models</title>
      <link>https://paperswithcode.com/paper/token-specific-watermarking-with-enhanced</link>
      <description><![CDATA[Large language models generate high-quality responses with potential misinformation, underscoring the need for regulation by distinguishing AI-generated and human-written texts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/token-specific-watermarking-with-enhanced</guid>
    </item>
  </channel>
</rss>
