<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 16 Apr 2023 21:06:02 +0000</lastBuildDate>
    <item>
      <title>STU-Net: Scalable and Transferable Medical Image Segmentation Models Empowered by Large-Scale Supervised Pre-training</title>
      <link>https://paperswithcode.com/paper/stu-net-scalable-and-transferable-medical</link>
      <description><![CDATA[However, the state-of-the-art models for medical image segmentation are still small-scale, with their parameters only in the tens of millions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stu-net-scalable-and-transferable-medical</guid>
    </item>
    <item>
      <title>AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models</title>
      <link>https://paperswithcode.com/paper/agieval-a-human-centric-benchmark-for</link>
      <description><![CDATA[Impressively, GPT-4 surpasses average human performance on SAT, LSAT, and math competitions, attaining a 95% accuracy rate on the SAT Math test and a 92. 5% accuracy on the English test of the Chinese national college entrance exam.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agieval-a-human-centric-benchmark-for</guid>
    </item>
    <item>
      <title>Segment Everything Everywhere All at Once</title>
      <link>https://paperswithcode.com/paper/segment-everything-everywhere-all-at-once</link>
      <description><![CDATA[Inspired by the development of prompt-based universal interfaces for LLMs, this paper presents SEEM, a promptable, interactive model for Segmenting Everything Everywhere all at once in an image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-everything-everywhere-all-at-once</guid>
    </item>
    <item>
      <title>Towards hypergraph cognitive networks as feature-rich models of knowledge</title>
      <link>https://paperswithcode.com/paper/towards-hypergraph-cognitive-networks-as</link>
      <description><![CDATA[Semantic networks provide a useful tool to understand how related concepts are retrieved from memory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-hypergraph-cognitive-networks-as</guid>
    </item>
    <item>
      <title>Neural State-Space Models: Empirical Evaluation of Uncertainty Quantification</title>
      <link>https://paperswithcode.com/paper/neural-state-space-models-empirical</link>
      <description><![CDATA[Effective quantification of uncertainty is an essential and still missing step towards a greater adoption of deep-learning approaches in different applications, including mission-critical ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-state-space-models-empirical</guid>
    </item>
    <item>
      <title>Priors for symbolic regression</title>
      <link>https://paperswithcode.com/paper/priors-for-symbolic-regression</link>
      <description><![CDATA[In this paper we develop methods to incorporate detailed prior information on both functions and their parameters into SR. Our prior on the structure of a function is based on a $n$-gram language model, which is sensitive to the arrangement of operators relative to one another in addition to the frequency of occurrence of each operator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/priors-for-symbolic-regression</guid>
    </item>
    <item>
      <title>Canonical and Noncanonical Hamiltonian Operator Inference</title>
      <link>https://paperswithcode.com/paper/canonical-and-noncanonical-hamiltonian</link>
      <description><![CDATA[A method for the nonintrusive and structure-preserving model reduction of canonical and noncanonical Hamiltonian systems is presented.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/canonical-and-noncanonical-hamiltonian</guid>
    </item>
    <item>
      <title>Revisiting the thorny issue of missing values in single-cell proteomics</title>
      <link>https://paperswithcode.com/paper/revisiting-the-thorny-issue-of-missing-values</link>
      <description><![CDATA[While the field is still actively debating on the best practices, the challenge increased with the emergence of mass spectrometry-based single-cell proteomics and the dramatic increase in missing values.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-the-thorny-issue-of-missing-values</guid>
    </item>
    <item>
      <title>You are here! Finding position and orientation on a 2D map from a single image: The Flatlandia localization problem and dataset</title>
      <link>https://paperswithcode.com/paper/you-are-here-finding-position-and-orientation</link>
      <description><![CDATA[We introduce Flatlandia, a novel problem for visual localization of an image from object detections composed of two specific tasks: i) Coarse Map Localization: localizing a single image observing a set of objects in respect to a 2D map of object landmarks; ii) Fine-grained 3DoF Localization: estimating latitude, longitude, and orientation of the image within a 2D map.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/you-are-here-finding-position-and-orientation</guid>
    </item>
    <item>
      <title>Remote Sensing Change Detection With Transformers Trained from Scratch</title>
      <link>https://paperswithcode.com/paper/remote-sensing-change-detection-with</link>
      <description><![CDATA[Current transformer-based change detection (CD) approaches either employ a pre-trained model trained on large-scale image classification ImageNet dataset or rely on first pre-training on another CD dataset and then fine-tuning on the target benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/remote-sensing-change-detection-with</guid>
    </item>
    <item>
      <title>DDT: Dual-branch Deformable Transformer for Image Denoising</title>
      <link>https://paperswithcode.com/paper/ddt-dual-branch-deformable-transformer-for</link>
      <description><![CDATA[Transformer is beneficial for image denoising tasks since it can model long-range dependencies to overcome the limitations presented by inductive convolutional biases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ddt-dual-branch-deformable-transformer-for</guid>
    </item>
    <item>
      <title>VISION DIFFMASK: Faithful Interpretation of Vision Transformers with Differentiable Patch Masking</title>
      <link>https://paperswithcode.com/paper/vision-diffmask-faithful-interpretation-of</link>
      <description><![CDATA[The lack of interpretability of the Vision Transformer may hinder its use in critical real-world applications despite its effectiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-diffmask-faithful-interpretation-of</guid>
    </item>
    <item>
      <title>Exploring the State of the Art in Legal QA Systems</title>
      <link>https://paperswithcode.com/paper/exploring-the-state-of-the-art-in-legal-qa</link>
      <description><![CDATA[At this time, there is a lack of surveys that discuss legal question answering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-state-of-the-art-in-legal-qa</guid>
    </item>
    <item>
      <title>Leveraging triplet loss for unsupervised action segmentation</title>
      <link>https://paperswithcode.com/paper/leveraging-triplet-loss-for-unsupervised</link>
      <description><![CDATA[In this paper, we propose a novel fully unsupervised framework that learns action representations suitable for the action segmentation task from the single input video itself, without requiring any training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-triplet-loss-for-unsupervised</guid>
    </item>
    <item>
      <title>RoboBEV: Towards Robust Bird's Eye View Perception under Corruptions</title>
      <link>https://paperswithcode.com/paper/robobev-towards-robust-bird-s-eye-view</link>
      <description><![CDATA[Our experiments further demonstrate that pre-training and depth-free BEV transformation has the potential to enhance out-of-distribution robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robobev-towards-robust-bird-s-eye-view</guid>
    </item>
    <item>
      <title>Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance</title>
      <link>https://paperswithcode.com/paper/evaluating-the-robustness-of-interpretability</link>
      <description><![CDATA[Through this rigorous formalism, we derive (1) two metrics to measure the robustness of any interpretability method with respect to the model symmetry group; (2) theoretical robustness guarantees for some popular interpretability methods and (3) a systematic approach to increase the invariance of any interpretability method with respect to a symmetry group.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-the-robustness-of-interpretability</guid>
    </item>
    <item>
      <title>LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model</title>
      <link>https://paperswithcode.com/paper/lasuie-unifying-information-extraction-with</link>
      <description><![CDATA[Universally modeling all typical information extraction tasks (UIE) with one generative language model (GLM) has revealed great potential by the latest study, where various IE predictions are unified into a linearized hierarchical expression under a GLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lasuie-unifying-information-extraction-with</guid>
    </item>
    <item>
      <title>CoSDA: Continual Source-Free Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/cosda-continual-source-free-domain-adaptation</link>
      <description><![CDATA[Recently, SFDA has gained popularity due to the need to protect the data privacy of the source domain, but it suffers from catastrophic forgetting on the source domain due to the lack of data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cosda-continual-source-free-domain-adaptation</guid>
    </item>
    <item>
      <title>Modeling Cell Size Distribution with Heterogeneous Flux Balance Analysis</title>
      <link>https://paperswithcode.com/paper/modeling-cell-size-distribution-with</link>
      <description><![CDATA[Hereto, a mathematical description of the concept of balanced growth in terms of cell mass distribution is presented.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/modeling-cell-size-distribution-with</guid>
    </item>
    <item>
      <title>Boosting Convolutional Neural Networks with Middle Spectrum Grouped Convolution</title>
      <link>https://paperswithcode.com/paper/boosting-convolutional-neural-networks-with</link>
      <description><![CDATA[This paper proposes a novel module called middle spectrum grouped convolution (MSGC) for efficient deep convolutional neural networks (DCNNs) with the mechanism of grouped convolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-convolutional-neural-networks-with</guid>
    </item>
    <item>
      <title>Noisy Correspondence Learning with Meta Similarity Correction</title>
      <link>https://paperswithcode.com/paper/noisy-correspondence-learning-with-meta</link>
      <description><![CDATA[Despite the success of multimodal learning in cross-modal retrieval task, the remarkable progress relies on the correct correspondence among multimedia data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/noisy-correspondence-learning-with-meta</guid>
    </item>
    <item>
      <title>Robust Multiview Multimodal Driver Monitoring System Using Masked Multi-Head Self-Attention</title>
      <link>https://paperswithcode.com/paper/robust-multiview-multimodal-driver-monitoring</link>
      <description><![CDATA[Driver Monitoring Systems (DMSs) are crucial for safe hand-over actions in Level-2+ self-driving vehicles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-multiview-multimodal-driver-monitoring</guid>
    </item>
    <item>
      <title>Physics-informed radial basis network (PIRBN): A local approximation neural network for solving nonlinear PDEs</title>
      <link>https://paperswithcode.com/paper/physics-informed-radial-basis-network-pirbn-a</link>
      <description><![CDATA[Our recent intensive study has found that physics-informed neural networks (PINN) tend to be local approximators after training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physics-informed-radial-basis-network-pirbn-a</guid>
    </item>
    <item>
      <title>Learning Accurate Performance Predictors for Ultrafast Automated Model Compression</title>
      <link>https://paperswithcode.com/paper/learning-accurate-performance-predictors-for</link>
      <description><![CDATA[On the contrary, we obtain the optimal efficient networks by directly optimizing the compression policy with an accurate performance predictor, where the ultrafast automated model compression for various computational cost constraint is achieved without complex compression policy search and evaluation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-accurate-performance-predictors-for</guid>
    </item>
    <item>
      <title>Zoom-VQA: Patches, Frames and Clips Integration for Video Quality Assessment</title>
      <link>https://paperswithcode.com/paper/zoom-vqa-patches-frames-and-clips-integration</link>
      <description><![CDATA[Video quality assessment (VQA) aims to simulate the human perception of video quality, which is influenced by factors ranging from low-level color and texture details to high-level semantic content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zoom-vqa-patches-frames-and-clips-integration</guid>
    </item>
    <item>
      <title>Transfer Knowledge from Head to Tail: Uncertainty Calibration under Long-tailed Distribution</title>
      <link>https://paperswithcode.com/paper/transfer-knowledge-from-head-to-tail</link>
      <description><![CDATA[We adaptively transfer knowledge from head classes to get the target probability density of tail classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transfer-knowledge-from-head-to-tail</guid>
    </item>
    <item>
      <title>RadarGNN: Transformation Invariant Graph Neural Network for Radar-based Perception</title>
      <link>https://paperswithcode.com/paper/radargnn-transformation-invariant-graph</link>
      <description><![CDATA[However, the sparsity of radar point clouds and the poor data availability remain challenging for current perception methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/radargnn-transformation-invariant-graph</guid>
    </item>
    <item>
      <title>Sign Language Translation from Instructional Videos</title>
      <link>https://paperswithcode.com/paper/sign-language-translation-from-instructional</link>
      <description><![CDATA[We report a result of 8. 03 on the BLEU score, and publish the first open-source implementation of its kind to promote further advances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sign-language-translation-from-instructional</guid>
    </item>
    <item>
      <title>Neuromorphic Event-based Facial Expression Recognition</title>
      <link>https://paperswithcode.com/paper/neuromorphic-event-based-facial-expression</link>
      <description><![CDATA[Recently, event cameras have shown large applicability in several computer vision fields especially concerning tasks that require high temporal resolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuromorphic-event-based-facial-expression</guid>
    </item>
    <item>
      <title>Multi-kernel Correntropy-based Orientation Estimation of IMUs: Gradient Descent Methods</title>
      <link>https://paperswithcode.com/paper/multi-kernel-correntropy-based-orientation</link>
      <description><![CDATA[We evaluate the effectiveness of our proposed methods by comparing them with existing algorithms in various situations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-kernel-correntropy-based-orientation</guid>
    </item>
    <item>
      <title>A Learnheuristic Approach to A Constrained Multi-Objective Portfolio Optimisation Problem</title>
      <link>https://paperswithcode.com/paper/a-learnheuristic-approach-to-a-constrained</link>
      <description><![CDATA[The results of this study show that, despite taking significantly longer to run to completion, the learnheuristic algorithms outperform the baseline algorithms in terms of hypervolume and rate of convergence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-learnheuristic-approach-to-a-constrained</guid>
    </item>
    <item>
      <title>Improving Segmentation of Objects with Varying Sizes in Biomedical Images using Instance-wise and Center-of-Instance Segmentation Loss Function</title>
      <link>https://paperswithcode.com/paper/improving-segmentation-of-objects-with</link>
      <description><![CDATA[In this paper, we propose a novel two-component loss for biomedical image segmentation tasks called the Instance-wise and Center-of-Instance (ICI) loss, a loss function that addresses the instance imbalance problem commonly encountered when using pixel-wise loss functions such as the Dice loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-segmentation-of-objects-with</guid>
    </item>
    <item>
      <title>MProtoNet: A Case-Based Interpretable Model for Brain Tumor Classification with 3D Multi-parametric Magnetic Resonance Imaging</title>
      <link>https://paperswithcode.com/paper/mprotonet-a-case-based-interpretable-model</link>
      <description><![CDATA[Recent applications of deep convolutional neural networks in medical imaging raise concerns about their interpretability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mprotonet-a-case-based-interpretable-model</guid>
    </item>
    <item>
      <title>Generating Aligned Pseudo-Supervision from Non-Aligned Data for Image Restoration in Under-Display Camera</title>
      <link>https://paperswithcode.com/paper/generating-aligned-pseudo-supervision-from</link>
      <description><![CDATA[Due to the difficulty in collecting large-scale and perfectly aligned paired training data for Under-Display Camera (UDC) image restoration, previous methods resort to monitor-based image systems or simulation-based methods, sacrificing the realness of the data and introducing domain gaps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-aligned-pseudo-supervision-from</guid>
    </item>
    <item>
      <title>Hard Patches Mining for Masked Image Modeling</title>
      <link>https://paperswithcode.com/paper/hard-patches-mining-for-masked-image-modeling</link>
      <description><![CDATA[We observe that the reconstruction loss can naturally be the metric of the difficulty of the pre-training task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hard-patches-mining-for-masked-image-modeling</guid>
    </item>
    <item>
      <title>Boosted Prompt Ensembles for Large Language Models</title>
      <link>https://paperswithcode.com/paper/boosted-prompt-ensembles-for-large-language</link>
      <description><![CDATA[Methods such as chain-of-thought prompting and self-consistency have pushed the frontier of language model reasoning performance with no additional training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosted-prompt-ensembles-for-large-language</guid>
    </item>
    <item>
      <title>TopTrack: Tracking Objects By Their Top</title>
      <link>https://paperswithcode.com/paper/toptrack-tracking-objects-by-their-top</link>
      <description><![CDATA[We propose TopTrack, a joint detection-and-tracking method that uses the top of the object as a keypoint for detection instead of the center because it is more often visible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toptrack-tracking-objects-by-their-top</guid>
    </item>
    <item>
      <title>CLIP-Guided Vision-Language Pre-training for Question Answering in 3D Scenes</title>
      <link>https://paperswithcode.com/paper/clip-guided-vision-language-pre-training-for</link>
      <description><![CDATA[Training models to apply linguistic knowledge and visual concepts from 2D images to 3D world understanding is a promising direction that researchers have only recently started to explore.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clip-guided-vision-language-pre-training-for</guid>
    </item>
    <item>
      <title>CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks</title>
      <link>https://paperswithcode.com/paper/clip-surgery-for-better-explainability-with</link>
      <description><![CDATA[Contrastive Language-Image Pre-training (CLIP) is a powerful multimodal large vision model that has demonstrated significant benefits for downstream tasks, including many zero-shot learning and text-guided vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clip-surgery-for-better-explainability-with</guid>
    </item>
    <item>
      <title>Towards Evaluating Explanations of Vision Transformers for Medical Imaging</title>
      <link>https://paperswithcode.com/paper/towards-evaluating-explanations-of-vision</link>
      <description><![CDATA[Our findings provide insights into the applicability of ViT explanations in medical imaging and highlight the importance of using appropriate evaluation criteria for comparing them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-evaluating-explanations-of-vision</guid>
    </item>
    <item>
      <title>$E(3) \times SO(3)$-Equivariant Networks for Spherical Deconvolution in Diffusion MRI</title>
      <link>https://paperswithcode.com/paper/e-3-times-so-3-equivariant-networks-for</link>
      <description><![CDATA[We present Roto-Translation Equivariant Spherical Deconvolution (RT-ESD), an $E(3)\times SO(3)$ equivariant framework for sparse deconvolution of volumes where each voxel contains a spherical signal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/e-3-times-so-3-equivariant-networks-for</guid>
    </item>
    <item>
      <title>Label-Free Concept Bottleneck Models</title>
      <link>https://paperswithcode.com/paper/label-free-concept-bottleneck-models</link>
      <description><![CDATA[Concept bottleneck models (CBM) are a popular way of creating more interpretable neural networks by having hidden layer neurons correspond to human-understandable concepts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/label-free-concept-bottleneck-models</guid>
    </item>
    <item>
      <title>Factorized Inverse Path Tracing for Efficient and Accurate Material-Lighting Estimation</title>
      <link>https://paperswithcode.com/paper/factorized-inverse-path-tracing-for-efficient</link>
      <description><![CDATA[Inverse path tracing has recently been applied to joint material and lighting estimation, given geometry and multi-view HDR observations of an indoor scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/factorized-inverse-path-tracing-for-efficient</guid>
    </item>
    <item>
      <title>Best Practices for 2-Body Pose Forecasting</title>
      <link>https://paperswithcode.com/paper/best-practices-for-2-body-pose-forecasting</link>
      <description><![CDATA[The task of collaborative human pose forecasting stands for predicting the future poses of multiple interacting people, given those in previous frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/best-practices-for-2-body-pose-forecasting</guid>
    </item>
    <item>
      <title>ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/imagereward-learning-and-evaluating-human</link>
      <description><![CDATA[We present ImageReward -- the first general-purpose text-to-image human preference reward model -- to address various prevalent issues in generative models and align them with human values and preferences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imagereward-learning-and-evaluating-human</guid>
    </item>
    <item>
      <title>DynamicDet: A Unified Dynamic Architecture for Object Detection</title>
      <link>https://paperswithcode.com/paper/dynamicdet-a-unified-dynamic-architecture-for</link>
      <description><![CDATA[We also present a novel optimization strategy with an exiting criterion based on the detection losses for our dynamic detectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamicdet-a-unified-dynamic-architecture-for</guid>
    </item>
    <item>
      <title>Unicom: Universal and Compact Representation Learning for Image Retrieval</title>
      <link>https://paperswithcode.com/paper/unicom-universal-and-compact-representation</link>
      <description><![CDATA[To further enhance the low-dimensional feature representation, we randomly select partial feature dimensions when calculating the similarities between embeddings and class-wise prototypes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unicom-universal-and-compact-representation</guid>
    </item>
    <item>
      <title>An Image Quality Assessment Dataset for Portraits</title>
      <link>https://paperswithcode.com/paper/an-image-quality-assessment-dataset-for</link>
      <description><![CDATA[This costly procedure can be partially replaced by automated learning-based methods for image quality assessment (IQA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-image-quality-assessment-dataset-for</guid>
    </item>
    <item>
      <title>InterGen: Diffusion-based Multi-human Motion Generation under Complex Interactions</title>
      <link>https://paperswithcode.com/paper/intergen-diffusion-based-multi-human-motion</link>
      <description><![CDATA[Then, we propose a novel representation for motion input in our interaction diffusion model, which explicitly formulates the global relations between the two performers in the world frame.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intergen-diffusion-based-multi-human-motion</guid>
    </item>
    <item>
      <title>Precise localization of corneal reflections in eye images using deep learning trained on synthetic data</title>
      <link>https://paperswithcode.com/paper/precise-localization-of-corneal-reflections</link>
      <description><![CDATA[Our method outperformed state-of-the-art algorithmic methods on real eye images with a 35% reduction in terms of spatial precision, and performed on par with state-of-the-art on simulated images in terms of spatial accuracy. We conclude that our method provides a precise method for CR center localization and provides a solution to the data availability problem which is one of the important common roadblocks in the development of deep learning models for gaze estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/precise-localization-of-corneal-reflections</guid>
    </item>
  </channel>
</rss>
