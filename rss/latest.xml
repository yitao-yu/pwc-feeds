<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 26 Jul 2022 21:07:36 +0000</lastBuildDate>
    <item>
      <title>Improving Pseudo Labels With Intra-Class Similarity for Unsupervised Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/improving-pseudo-labels-with-intra-class</link>
      <description><![CDATA[In this paper, we propose a novel approach to improve the accuracy of the pseudo labels in the target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-pseudo-labels-with-intra-class</guid>
    </item>
    <item>
      <title>CelebV-HQ: A Large-Scale Video Facial Attributes Dataset</title>
      <link>https://paperswithcode.com/paper/celebv-hq-a-large-scale-video-facial</link>
      <description><![CDATA[Large-scale datasets have played indispensable roles in the recent success of face generation/editing and significantly facilitated the advances of emerging research fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/celebv-hq-a-large-scale-video-facial</guid>
    </item>
    <item>
      <title>What is Healthy? Generative Counterfactual Diffusion for Lesion Localization</title>
      <link>https://paperswithcode.com/paper/what-is-healthy-generative-counterfactual</link>
      <description><![CDATA[This requires training with healthy and unhealthy data in DPMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-is-healthy-generative-counterfactual</guid>
    </item>
    <item>
      <title>Developing Optimal Causal Cyber-Defence Agents via Cyber Security Simulation</title>
      <link>https://paperswithcode.com/paper/developing-optimal-causal-cyber-defence</link>
      <description><![CDATA[In this paper we explore cyber security defence, through the unification of a novel cyber security simulator with models for (causal) decision-making through optimisation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/developing-optimal-causal-cyber-defence</guid>
    </item>
    <item>
      <title>Lifelong Machine Learning of Functionally Compositional Structures</title>
      <link>https://paperswithcode.com/paper/lifelong-machine-learning-of-functionally</link>
      <description><![CDATA[Supervised learning evaluations found that 1) compositional models improve lifelong learning of diverse tasks, 2) the multi-stage process permits lifelong learning of compositional knowledge, and 3) the components learned by the framework represent self-contained and reusable functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lifelong-machine-learning-of-functionally</guid>
    </item>
    <item>
      <title>Dive into Big Model Training</title>
      <link>https://paperswithcode.com/paper/dive-into-big-model-training</link>
      <description><![CDATA[We summarize the existing training methodologies into three main categories: training parallelism, memory-saving technologies, and model sparsity design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dive-into-big-model-training</guid>
    </item>
    <item>
      <title>MAPIE: an open-source library for distribution-free uncertainty quantification</title>
      <link>https://paperswithcode.com/paper/mapie-an-open-source-library-for-distribution</link>
      <description><![CDATA[Estimating uncertainties associated with the predictions of Machine Learning (ML) models is of crucial importance to assess their robustness and predictive power.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mapie-an-open-source-library-for-distribution</guid>
    </item>
    <item>
      <title>TreeSketchNet: From Sketch To 3D Tree Parameters Generation</title>
      <link>https://paperswithcode.com/paper/treesketchnet-from-sketch-to-3d-tree</link>
      <description><![CDATA[Our approach is based on a well-defined Deep Neural Network (DNN) architecture, we called TreeSketchNet (TSN), based on convolutions and able to generate Weber and Penn parameters that can be interpreted by the modelling software to generate a 3D model of a tree starting from a simple sketch.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/treesketchnet-from-sketch-to-3d-tree</guid>
    </item>
    <item>
      <title>Self-Distilled Vision Transformer for Domain Generalization</title>
      <link>https://paperswithcode.com/paper/self-distilled-vision-transformer-for-domain</link>
      <description><![CDATA[In recent past, several domain generalization (DG) methods have been proposed, showing encouraging performance, however, almost all of them build on convolutional neural networks (CNNs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-distilled-vision-transformer-for-domain</guid>
    </item>
    <item>
      <title>Differential testing for machine learning: an analysis for classification algorithms beyond deep learning</title>
      <link>https://paperswithcode.com/paper/differential-testing-for-machine-learning-an</link>
      <description><![CDATA[The execution of the feasible tests revealed that there is a large amount of deviations for the scores and classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/differential-testing-for-machine-learning-an</guid>
    </item>
    <item>
      <title>GNN Transformation Framework for Improving Efficiency and Scalability</title>
      <link>https://paperswithcode.com/paper/gnn-transformation-framework-for-improving</link>
      <description><![CDATA[We propose a framework that automatically transforms non-scalable GNNs into precomputation-based GNNs which are efficient and scalable for large-scale graphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gnn-transformation-framework-for-improving</guid>
    </item>
    <item>
      <title>Improving Adversarial Robustness via Mutual Information Estimation</title>
      <link>https://paperswithcode.com/paper/improving-adversarial-robustness-via-mutual</link>
      <description><![CDATA[To alleviate this negative effect, in this paper, we investigate the dependence between outputs of the target model and input adversarial samples from the perspective of information theory, and propose an adversarial defense method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-adversarial-robustness-via-mutual</guid>
    </item>
    <item>
      <title>SecretGen: Privacy Recovery on Pre-Trained Models via Distribution Discrimination</title>
      <link>https://paperswithcode.com/paper/secretgen-privacy-recovery-on-pre-trained</link>
      <description><![CDATA[We first explore different statistical information which can discriminate the private training distribution from other distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/secretgen-privacy-recovery-on-pre-trained</guid>
    </item>
    <item>
      <title>Calibrated One-class Classification for Unsupervised Time Series Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/calibrated-one-class-classification-for</link>
      <description><![CDATA[Our one-class classifier is calibrated in two ways: (1) by adaptively penalizing uncertain predictions, which helps eliminate the impact of anomaly contamination while accentuating the predictions that the one-class model is confident in, and (2) by discriminating the normal samples from native anomaly examples that are generated to simulate genuine time series abnormal behaviors on the basis of original data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/calibrated-one-class-classification-for</guid>
    </item>
    <item>
      <title>Equivariance and Invariance Inductive Bias for Learning from Insufficient Data</title>
      <link>https://paperswithcode.com/paper/equivariance-and-invariance-inductive-bias</link>
      <description><![CDATA[We are interested in learning robust models from insufficient data, without the need for any externally pre-trained checkpoints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/equivariance-and-invariance-inductive-bias</guid>
    </item>
    <item>
      <title>OpenRAN Gym: AI/ML Development, Data Collection, and Testing for O-RAN on PAWR Platforms</title>
      <link>https://paperswithcode.com/paper/openran-gym-ai-ml-development-data-collection</link>
      <description><![CDATA[In this paper we present OpenRAN Gym, a unified, open, and O-RAN-compliant experimental toolbox for data collection, design, prototyping and testing of end-to-end data-driven control solutions for next generation Open RAN systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openran-gym-ai-ml-development-data-collection</guid>
    </item>
    <item>
      <title>A Confident Deep Learning loss function for one-step Conformal Prediction approximation</title>
      <link>https://paperswithcode.com/paper/a-confident-deep-learning-loss-function-for</link>
      <description><![CDATA[Deep Learning predictions with measurable confidence are increasingly desirable for real-world problems, especially in high-risk settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-confident-deep-learning-loss-function-for</guid>
    </item>
    <item>
      <title>Generative Subgraph Contrast for Self-Supervised Graph Representation Learning</title>
      <link>https://paperswithcode.com/paper/generative-subgraph-contrast-for-self</link>
      <description><![CDATA[To this end, in this paper, we propose a novel adaptive subgraph generation based contrastive learning framework for efficient and robust self-supervised graph representation learning, and the optimal transport distance is utilized as the similarity metric between the subgraphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-subgraph-contrast-for-self</guid>
    </item>
    <item>
      <title>C3-SL: Circular Convolution-Based Batch-Wise Compression for Communication-Efficient Split Learning</title>
      <link>https://paperswithcode.com/paper/c3-sl-circular-convolution-based-batch-wise</link>
      <description><![CDATA[Based on the simulation results on CIFAR-10 and CIFAR-100, our method achieves a 16x compression ratio with negligible accuracy drops compared with the vanilla SL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/c3-sl-circular-convolution-based-batch-wise</guid>
    </item>
    <item>
      <title>Post-processing Networks: Method for Optimizing Pipeline Task-oriented Dialogue Systems using Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/post-processing-networks-method-for</link>
      <description><![CDATA[Many studies have proposed methods for optimizing the dialogue performance of an entire pipeline task-oriented dialogue system by jointly training modules in the system using reinforcement learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/post-processing-networks-method-for</guid>
    </item>
    <item>
      <title>Cost Volume Pyramid Network with Multi-strategies Range Searching for Multi-view Stereo</title>
      <link>https://paperswithcode.com/paper/cost-volume-pyramid-network-with-multi</link>
      <description><![CDATA[Multi-view stereo is an important research task in computer vision while still keeping challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cost-volume-pyramid-network-with-multi</guid>
    </item>
    <item>
      <title>MedML: Fusing Medical Knowledge and Machine Learning Models for Early Pediatric COVID-19 Hospitalization and Severity Prediction</title>
      <link>https://paperswithcode.com/paper/medml-fusing-medical-knowledge-and-machine</link>
      <description><![CDATA[We respond to the national Pediatric COVID-19 data challenge with a novel machine learning model, MedML.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medml-fusing-medical-knowledge-and-machine</guid>
    </item>
    <item>
      <title>Black-box Few-shot Knowledge Distillation</title>
      <link>https://paperswithcode.com/paper/black-box-few-shot-knowledge-distillation</link>
      <description><![CDATA[Traditional KD methods require lots of labeled training samples and a white-box teacher (parameters are accessible) to train a good student.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/black-box-few-shot-knowledge-distillation</guid>
    </item>
    <item>
      <title>Advancing Semi-Supervised Task Oriented Dialog Systems by JSA Learning of Discrete Latent Variable Models</title>
      <link>https://paperswithcode.com/paper/advancing-semi-supervised-task-oriented</link>
      <description><![CDATA[In this paper, we propose to apply JSA to semi-supervised learning of the latent state TOD models, which is referred to as JSA-TOD.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-semi-supervised-task-oriented</guid>
    </item>
    <item>
      <title>Domain Adaptive Person Search</title>
      <link>https://paperswithcode.com/paper/domain-adaptive-person-search</link>
      <description><![CDATA[In this paper, we take a further step and present Domain Adaptive Person Search (DAPS), which aims to generalize the model from a labeled source domain to the unlabeled target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-adaptive-person-search</guid>
    </item>
    <item>
      <title>Dynamic Channel Selection in Self-Supervised Learning</title>
      <link>https://paperswithcode.com/paper/dynamic-channel-selection-in-self-supervised</link>
      <description><![CDATA[Currently, convnets pre-trained with self-supervision have obtained comparable performance on downstream tasks in comparison to their supervised counterparts in computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-channel-selection-in-self-supervised</guid>
    </item>
    <item>
      <title>Active Learning Strategies for Weakly-supervised Object Detection</title>
      <link>https://paperswithcode.com/paper/active-learning-strategies-for-weakly</link>
      <description><![CDATA[On COCO, using on average 10 fully-annotated images per class, or equivalently 1% of the training set, BiB also reduces the performance gap (in AP) between the weakly-supervised detector and the fully-supervised Fast RCNN by over 70%, showing a good trade-off between performance and data efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/active-learning-strategies-for-weakly</guid>
    </item>
    <item>
      <title>Deep Laparoscopic Stereo Matching with Transformers</title>
      <link>https://paperswithcode.com/paper/deep-laparoscopic-stereo-matching-with</link>
      <description><![CDATA[The self-attention mechanism, successfully employed with the transformer structure is shown promise in many computer vision tasks including image recognition, and object detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-laparoscopic-stereo-matching-with</guid>
    </item>
    <item>
      <title>Domain Decorrelation with Potential Energy Ranking</title>
      <link>https://paperswithcode.com/paper/domain-decorrelation-with-potential-energy</link>
      <description><![CDATA[PoER helps the neural networks to capture label-related features which contain the domain information first in shallow layers and then distills the label-discriminative representations out progressively, enforcing the neural networks to be aware of the characteristic of objects and background which is vital to the generation of domain-invariant features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-decorrelation-with-potential-energy</guid>
    </item>
    <item>
      <title>Reference-based Image Super-Resolution with Deformable Attention Transformer</title>
      <link>https://paperswithcode.com/paper/reference-based-image-super-resolution-with</link>
      <description><![CDATA[Reference-based image super-resolution (RefSR) aims to exploit auxiliary reference (Ref) images to super-resolve low-resolution (LR) images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reference-based-image-super-resolution-with</guid>
    </item>
    <item>
      <title>Domain-invariant Feature Exploration for Domain Generalization</title>
      <link>https://paperswithcode.com/paper/domain-invariant-feature-exploration-for</link>
      <description><![CDATA[Internal invariance means that the features can be learned with a single domain and the features capture intrinsic semantics of data, i. e., the property within a domain, which is agnostic to other domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-invariant-feature-exploration-for</guid>
    </item>
    <item>
      <title>Behind Every Domain There is a Shift: Adapting Distortion-aware Vision Transformers for Panoramic Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/behind-every-domain-there-is-a-shift-adapting</link>
      <description><![CDATA[Panoramic segmentation is under-explored due to two critical challenges: (1) image distortions and object deformations on panoramas; (2) lack of annotations for training panoramic segmenters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/behind-every-domain-there-is-a-shift-adapting</guid>
    </item>
    <item>
      <title>Patchwork++: Fast and Robust Ground Segmentation Solving Partial Under-Segmentation Using 3D Point Cloud</title>
      <link>https://paperswithcode.com/paper/patchwork-fast-and-robust-ground-segmentation</link>
      <description><![CDATA[Moreover, even if the parameters are well adjusted, a partial under-segmentation problem can still emerge, which implies ground segmentation failures in some regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/patchwork-fast-and-robust-ground-segmentation</guid>
    </item>
    <item>
      <title>RA-Depth: Resolution Adaptive Self-Supervised Monocular Depth Estimation</title>
      <link>https://paperswithcode.com/paper/ra-depth-resolution-adaptive-self-supervised</link>
      <description><![CDATA[In this paper, we propose a resolution adaptive self-supervised monocular depth estimation method (RA-Depth) by learning the scale invariance of the scene depth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ra-depth-resolution-adaptive-self-supervised</guid>
    </item>
    <item>
      <title>On Mitigating Hard Clusters for Face Clustering</title>
      <link>https://paperswithcode.com/paper/on-mitigating-hard-clusters-for-face</link>
      <description><![CDATA[Face clustering is a promising way to scale up face recognition systems using large-scale unlabeled face images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-mitigating-hard-clusters-for-face</guid>
    </item>
    <item>
      <title>ArtFID: Quantitative Evaluation of Neural Style Transfer</title>
      <link>https://paperswithcode.com/paper/artfid-quantitative-evaluation-of-neural</link>
      <description><![CDATA[The field of neural style transfer has experienced a surge of research exploring different avenues ranging from optimization-based approaches and feed-forward models to meta-learning methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/artfid-quantitative-evaluation-of-neural</guid>
    </item>
    <item>
      <title>Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection</title>
      <link>https://paperswithcode.com/paper/revisiting-ap-loss-for-dense-object-detection-1</link>
      <description><![CDATA[However, a deep understanding of how AP loss affects the detector from a pairwise ranking perspective has not yet been developed. In this work, we revisit the average precision (AP)loss and reveal that the crucial element is that of selecting the ranking pairs between positive and negative samples. Based on this observation, we propose two strategies to improve the AP loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-ap-loss-for-dense-object-detection-1</guid>
    </item>
    <item>
      <title>Intention-Conditioned Long-Term Human Egocentric Action Forecasting @ EGO4D Challenge 2022</title>
      <link>https://paperswithcode.com/paper/intention-conditioned-long-term-human</link>
      <description><![CDATA[Our framework first extracts two level of human information over the N observed videos human actions through a Hierarchical Multi-task MLP Mixer (H3M).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intention-conditioned-long-term-human</guid>
    </item>
    <item>
      <title>W2N:Switching From Weak Supervision to Noisy Supervision for Object Detection</title>
      <link>https://paperswithcode.com/paper/w2n-switching-from-weak-supervision-to-noisy</link>
      <description><![CDATA[Generally, with given pseudo ground-truths generated from the well-trained WSOD network, we propose a two-module iterative training algorithm to refine pseudo labels and supervise better object detector progressively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/w2n-switching-from-weak-supervision-to-noisy</guid>
    </item>
    <item>
      <title>Explored An Effective Methodology for Fine-Grained Snake Recognition</title>
      <link>https://paperswithcode.com/paper/explored-an-effective-methodology-for-fine</link>
      <description><![CDATA[Then, in order to take full advantage of unlabeled datasets, we use self-supervised learning and supervised learning joint training to provide pre-trained model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explored-an-effective-methodology-for-fine</guid>
    </item>
    <item>
      <title>PatchRD: Detail-Preserving Shape Completion by Learning Patch Retrieval and Deformation</title>
      <link>https://paperswithcode.com/paper/patchrd-detail-preserving-shape-completion-by</link>
      <description><![CDATA[Our key insight is to copy and deform patches from the partial input to complete missing regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/patchrd-detail-preserving-shape-completion-by</guid>
    </item>
    <item>
      <title>PCA: Semi-supervised Segmentation with Patch Confidence Adversarial Training</title>
      <link>https://paperswithcode.com/paper/pca-semi-supervised-segmentation-with-patch</link>
      <description><![CDATA[Unlike most existing semi-supervised learning methods, adversarial training based methods distinguish samples from different sources by learning the data distribution of the segmentation map, leading the segmenter to generate more accurate predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pca-semi-supervised-segmentation-with-patch</guid>
    </item>
    <item>
      <title>Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment Analysis</title>
      <link>https://paperswithcode.com/paper/counterfactual-reasoning-for-out-of</link>
      <description><![CDATA[Inspired by this, we devise a model-agnostic counterfactual framework for multimodal sentiment analysis, which captures the direct effect of textual modality via an extra text model and estimates the indirect one by a multimodal model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-reasoning-for-out-of</guid>
    </item>
    <item>
      <title>Weakly-Supervised Temporal Action Detection for Fine-Grained Videos with Hierarchical Atomic Actions</title>
      <link>https://paperswithcode.com/paper/weakly-supervised-temporal-action-detection</link>
      <description><![CDATA[Action understanding has evolved into the era of fine granularity, as most human behaviors in real life have only minor differences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/weakly-supervised-temporal-action-detection</guid>
    </item>
    <item>
      <title>SimAM: A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</title>
      <link>https://paperswithcode.com/paper/simam-a-simple-parameter-free-attention</link>
      <description><![CDATA[Another advantage of the module is that most of the operators are selected based on the solution to the defined energy function, avoiding too many efforts for structure tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simam-a-simple-parameter-free-attention</guid>
    </item>
    <item>
      <title>Kernel Relative-prototype Spectral Filtering for Few-shot Learning</title>
      <link>https://paperswithcode.com/paper/kernel-relative-prototype-spectral-filtering</link>
      <description><![CDATA[In this paper, we propose a framework of spectral filtering (shrinkage) for measuring the difference between query samples and prototypes, or namely the relative prototypes, in a reproducing kernel Hilbert space (RKHS).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kernel-relative-prototype-spectral-filtering</guid>
    </item>
    <item>
      <title>No More Fine-Tuning? An Experimental Evaluation of Prompt Tuning in Code Intelligence</title>
      <link>https://paperswithcode.com/paper/no-more-fine-tuning-an-experimental</link>
      <description><![CDATA[Besides, the performance of fine-tuning strongly relies on the amount of downstream data, while in practice, the scenarios with scarce data are common.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/no-more-fine-tuning-an-experimental</guid>
    </item>
    <item>
      <title>Object State Change Classification in Egocentric Videos using the Divided Space-Time Attention Mechanism</title>
      <link>https://paperswithcode.com/paper/object-state-change-classification-in</link>
      <description><![CDATA[This report describes our submission called "TarHeels" for the Ego4D: Object State Change Classification Challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/object-state-change-classification-in</guid>
    </item>
    <item>
      <title>Learnable Privacy-Preserving Anonymization for Pedestrian Images</title>
      <link>https://paperswithcode.com/paper/learnable-privacy-preserving-anonymization</link>
      <description><![CDATA[We further propose a progressive training strategy to improve the performance, which iteratively upgrades the initial anonymization supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learnable-privacy-preserving-anonymization</guid>
    </item>
    <item>
      <title>CODiT: Conformal Out-of-Distribution Detection in Time-Series Data</title>
      <link>https://paperswithcode.com/paper/codit-conformal-out-of-distribution-detection</link>
      <description><![CDATA[Machine learning models are prone to making incorrect predictions on inputs that are far from the training distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codit-conformal-out-of-distribution-detection</guid>
    </item>
  </channel>
</rss>
