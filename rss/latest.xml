<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 18 Oct 2024 09:16:45 +0000</lastBuildDate>
    <item>
      <title>Fairness-Enhancing Ensemble Classification in Water Distribution Networks</title>
      <link>https://paperswithcode.com/paper/fairness-enhancing-ensemble-classification-in</link>
      <description><![CDATA[As relevant examples such as the future criminal detection software [1] show, fairness of AI-based and social domain affecting decision support tools constitutes an important area of research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fairness-enhancing-ensemble-classification-in</guid>
    </item>
    <item>
      <title>UniG: Modelling Unitary 3D Gaussians for View-consistent 3D Reconstruction</title>
      <link>https://paperswithcode.com/paper/unig-modelling-unitary-3d-gaussians-for-view</link>
      <description><![CDATA[In this work, we present UniG, a view-consistent 3D reconstruction and novel view synthesis model that generates a high-fidelity representation of 3D Gaussians from sparse images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unig-modelling-unitary-3d-gaussians-for-view</guid>
    </item>
    <item>
      <title>GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning</title>
      <link>https://paperswithcode.com/paper/gder-safeguarding-efficiency-balancing-and</link>
      <description><![CDATA[Training high-quality deep models necessitates vast amounts of data, resulting in overwhelming computational and memory demands.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gder-safeguarding-efficiency-balancing-and</guid>
    </item>
    <item>
      <title>LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/loldu-low-rank-adaptation-via-lower-diag</link>
      <description><![CDATA[However, LoRA utilize random initialization and optimization of low-rank matrices to approximate updated weights, which can result in suboptimal convergence and an accuracy gap compared to full fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/loldu-low-rank-adaptation-via-lower-diag</guid>
    </item>
    <item>
      <title>SiamSeg: Self-Training with Contrastive Learning for Unsupervised Domain Adaptation in Remote Sensing</title>
      <link>https://paperswithcode.com/paper/siamseg-self-training-with-contrastive</link>
      <description><![CDATA[Semantic segmentation of remote sensing (RS) images is a challenging task with significant potential across various applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/siamseg-self-training-with-contrastive</guid>
    </item>
    <item>
      <title>SAda-Net: A Self-Supervised Adaptive Stereo Estimation CNN For Remote Sensing Image Data</title>
      <link>https://paperswithcode.com/paper/sada-net-a-self-supervised-adaptive-stereo</link>
      <description><![CDATA[Stereo estimation has made many advancements in recent years with the introduction of deep-learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sada-net-a-self-supervised-adaptive-stereo</guid>
    </item>
    <item>
      <title>Starbucks: Improved Training for 2D Matryoshka Embeddings</title>
      <link>https://paperswithcode.com/paper/starbucks-improved-training-for-2d-matryoshka</link>
      <description><![CDATA[Effective approaches that can scale embedding model depth (i. e. layers) and embedding size allow for the creation of models that are highly scalable across different computational resources and task requirements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/starbucks-improved-training-for-2d-matryoshka</guid>
    </item>
    <item>
      <title>Performance of Gaussian Mixture Model Classifiers on Embedded Feature Spaces</title>
      <link>https://paperswithcode.com/paper/performance-of-gaussian-mixture-model</link>
      <description><![CDATA[Our first contribution is to investigate GMM based classification performance taking advantage of the embedded spaces CLIP and ImageBind.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/performance-of-gaussian-mixture-model</guid>
    </item>
    <item>
      <title>CLaMP 2: Multimodal Music Information Retrieval Across 101 Languages Using Large Language Models</title>
      <link>https://paperswithcode.com/paper/clamp-2-multimodal-music-information</link>
      <description><![CDATA[Challenges in managing linguistic diversity and integrating various musical modalities are faced by current music information retrieval systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clamp-2-multimodal-music-information</guid>
    </item>
    <item>
      <title>UniDrive: Towards Universal Driving Perception Across Camera Configurations</title>
      <link>https://paperswithcode.com/paper/unidrive-towards-universal-driving-perception</link>
      <description><![CDATA[We further propose a virtual configuration optimization method by minimizing the expected projection error between original cameras and virtual cameras.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unidrive-towards-universal-driving-perception</guid>
    </item>
    <item>
      <title>Data Defenses Against Large Language Models</title>
      <link>https://paperswithcode.com/paper/data-defenses-against-large-language-models</link>
      <description><![CDATA[Large language models excel at performing inference over text to extract information, summarize information, or generate additional text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-defenses-against-large-language-models</guid>
    </item>
    <item>
      <title>A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks</title>
      <link>https://paperswithcode.com/paper/a-new-approach-for-fine-tuning-sentence</link>
      <description><![CDATA[One of the most accurate approaches for out-of-scope (OOS) rejection is to combine it with the task of intent classification on in-scope queries, and to use methods based on the similarity of embeddings produced by transformer-based sentence encoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-new-approach-for-fine-tuning-sentence</guid>
    </item>
    <item>
      <title>RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards</title>
      <link>https://paperswithcode.com/paper/rag-ddr-optimizing-retrieval-augmented</link>
      <description><![CDATA[Our experiments on various knowledge-intensive tasks demonstrate that DDR significantly outperforms the SFT method, particularly for LLMs with smaller-scale parameters that depend more on the retrieved knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rag-ddr-optimizing-retrieval-augmented</guid>
    </item>
    <item>
      <title>A Pattern to Align Them All: Integrating Different Modalities to Define Multi-Modal Entities</title>
      <link>https://paperswithcode.com/paper/a-pattern-to-align-them-all-integrating</link>
      <description><![CDATA[The ability to reason with and integrate different sensory inputs is the foundation underpinning human intelligence and it is the reason for the growing interest in modelling multi-modal information within Knowledge Graphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-pattern-to-align-them-all-integrating</guid>
    </item>
    <item>
      <title>Estimating the Probabilities of Rare Outputs in Language Models</title>
      <link>https://paperswithcode.com/paper/estimating-the-probabilities-of-rare-outputs</link>
      <description><![CDATA[We consider the problem of low probability estimation: given a machine learning model and a formally-specified input distribution, how can we estimate the probability of a binary property of the model's output, even when that probability is too small to estimate by random sampling?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/estimating-the-probabilities-of-rare-outputs</guid>
    </item>
    <item>
      <title>Diffusing States and Matching Scores: A New Framework for Imitation Learning</title>
      <link>https://paperswithcode.com/paper/diffusing-states-and-matching-scores-a-new</link>
      <description><![CDATA[Adversarial Imitation Learning is traditionally framed as a two-player zero-sum game between a learner and an adversarially chosen cost function, and can therefore be thought of as the sequential generalization of a Generative Adversarial Network (GAN).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusing-states-and-matching-scores-a-new</guid>
    </item>
    <item>
      <title>PUMA: Empowering Unified MLLM with Multi-granular Visual Generation</title>
      <link>https://paperswithcode.com/paper/puma-empowering-unified-mllm-with-multi</link>
      <description><![CDATA[This work represents a significant step towards a truly unified MLLM capable of adapting to the granularity demands of various visual tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/puma-empowering-unified-mllm-with-multi</guid>
    </item>
    <item>
      <title>Cliqueformer: Model-Based Optimization with Structured Transformers</title>
      <link>https://paperswithcode.com/paper/cliqueformer-model-based-optimization-with</link>
      <description><![CDATA[Expressive large-scale neural networks enable training powerful models for prediction tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cliqueformer-model-based-optimization-with</guid>
    </item>
    <item>
      <title>MedINST: Meta Dataset of Biomedical Instructions</title>
      <link>https://paperswithcode.com/paper/medinst-meta-dataset-of-biomedical</link>
      <description><![CDATA[The integration of large language model (LLM) techniques in the field of medical analysis has brought about significant advancements, yet the scarcity of large, diverse, and well-annotated datasets remains a major challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medinst-meta-dataset-of-biomedical</guid>
    </item>
    <item>
      <title>aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Completion</title>
      <link>https://paperswithcode.com/paper/aixcoder-7b-a-lightweight-and-effective-large</link>
      <description><![CDATA[In this paper, we propose a lightweight and effective LLM for code completion named aiXcoder-7B.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aixcoder-7b-a-lightweight-and-effective-large</guid>
    </item>
    <item>
      <title>Learning Graph Quantized Tokenizers for Transformers</title>
      <link>https://paperswithcode.com/paper/learning-graph-quantized-tokenizers-for</link>
      <description><![CDATA[Transformers serve as the backbone architectures of Foundational Models, where a domain-specific tokenizer helps them adapt to various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-graph-quantized-tokenizers-for</guid>
    </item>
    <item>
      <title>Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning</title>
      <link>https://paperswithcode.com/paper/deep-generative-models-unveil-patterns-in</link>
      <description><![CDATA[Deep generative models have significantly advanced medical imaging analysis by enhancing dataset size and quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-generative-models-unveil-patterns-in</guid>
    </item>
    <item>
      <title>Looking Inward: Language Models Can Learn About Themselves by Introspection</title>
      <link>https://paperswithcode.com/paper/looking-inward-language-models-can-learn</link>
      <description><![CDATA[We study introspection by finetuning LLMs to predict properties of their own behavior in hypothetical scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/looking-inward-language-models-can-learn</guid>
    </item>
    <item>
      <title>Efficient Function Placement in Virtual Networks: An Online Learning Approach</title>
      <link>https://paperswithcode.com/paper/efficient-function-placement-in-virtual</link>
      <description><![CDATA[We propose a model for the virtual function placement problem and several novel algorithms using ideas based on multi-armed bandits.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-function-placement-in-virtual</guid>
    </item>
    <item>
      <title>VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding</title>
      <link>https://paperswithcode.com/paper/vlm-grounder-a-vlm-agent-for-zero-shot-3d</link>
      <description><![CDATA[3D visual grounding is crucial for robots, requiring integration of natural language and 3D scene understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vlm-grounder-a-vlm-agent-for-zero-shot-3d</guid>
    </item>
    <item>
      <title>Unlocking the Capabilities of Masked Generative Models for Image Synthesis via Self-Guidance</title>
      <link>https://paperswithcode.com/paper/unlocking-the-capabilities-of-masked</link>
      <description><![CDATA[A key factor in the performance of continuous diffusion models stems from the guidance methods, which enhance the sample quality at the expense of diversity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlocking-the-capabilities-of-masked</guid>
    </item>
    <item>
      <title>Enhanced Prompt-leveraged Weakly Supervised Cancer Segmentation based on Segment Anything</title>
      <link>https://paperswithcode.com/paper/enhanced-prompt-leveraged-weakly-supervised</link>
      <description><![CDATA[To demonstrate the superiority of the proposed method, experimental studies are conducted on histopathological breast cancer datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhanced-prompt-leveraged-weakly-supervised</guid>
    </item>
    <item>
      <title>EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning</title>
      <link>https://paperswithcode.com/paper/eh-mam-easy-to-hard-masked-acoustic-modeling</link>
      <description><![CDATA[In this paper, we present EH-MAM (Easy-to-Hard adaptive Masked Acoustic Modeling), a novel self-supervised learning approach for speech representation learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eh-mam-easy-to-hard-masked-acoustic-modeling</guid>
    </item>
    <item>
      <title>An Evolved Universal Transformer Memory</title>
      <link>https://paperswithcode.com/paper/an-evolved-universal-transformer-memory</link>
      <description><![CDATA[Prior methods propose to offset the escalating costs of modern foundation models by dropping specific parts of their contexts with hand-designed rules, while attempting to preserve their original performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-evolved-universal-transformer-memory</guid>
    </item>
    <item>
      <title>Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations</title>
      <link>https://paperswithcode.com/paper/measuring-free-form-decision-making</link>
      <description><![CDATA[We find that inconsistency due to semantically equivalent prompt variations can exceed response inconsistency from temperature sampling for most studied models across different levels of ablations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/measuring-free-form-decision-making</guid>
    </item>
    <item>
      <title>Novelty-based Sample Reuse for Continuous Robotics Control</title>
      <link>https://paperswithcode.com/paper/novelty-based-sample-reuse-for-continuous</link>
      <description><![CDATA[In reinforcement learning, agents collect state information and rewards through environmental interactions, essential for policy refinement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/novelty-based-sample-reuse-for-continuous</guid>
    </item>
    <item>
      <title>ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization</title>
      <link>https://paperswithcode.com/paper/orchid-a-chinese-debate-corpus-for-target</link>
      <description><![CDATA[Dialogue agents have been receiving increasing attention for years, and this trend has been further boosted by the recent progress of large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/orchid-a-chinese-debate-corpus-for-target</guid>
    </item>
    <item>
      <title>A Little Human Data Goes A Long Way</title>
      <link>https://paperswithcode.com/paper/a-little-human-data-goes-a-long-way</link>
      <description><![CDATA[Faced with an expensive human annotation process, creators of NLP systems increasingly turn to synthetic data generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-little-human-data-goes-a-long-way</guid>
    </item>
    <item>
      <title>D-FINE: Redefine Regression Task in DETRs as Fine-grained Distribution Refinement</title>
      <link>https://paperswithcode.com/paper/d-fine-redefine-regression-task-in-detrs-as</link>
      <description><![CDATA[When pretrained on Objects365, D-FINE-L / X attains 57. 1% / 59. 3% AP, surpassing all existing real-time detectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/d-fine-redefine-regression-task-in-detrs-as</guid>
    </item>
    <item>
      <title>DepthSplat: Connecting Gaussian Splatting and Depth</title>
      <link>https://paperswithcode.com/paper/depthsplat-connecting-gaussian-splatting-and</link>
      <description><![CDATA[Gaussian splatting and single/multi-view depth estimation are typically studied in isolation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depthsplat-connecting-gaussian-splatting-and</guid>
    </item>
    <item>
      <title>Can MLLMs Understand the Deep Implication Behind Chinese Images?</title>
      <link>https://paperswithcode.com/paper/can-mllms-understand-the-deep-implication</link>
      <description><![CDATA[To fill the gap, we introduce the **C**hinese **I**mage **I**mplication understanding **Bench**mark, **CII-Bench**, which aims to assess the higher-order perception and understanding capabilities of MLLMs for Chinese images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-mllms-understand-the-deep-implication</guid>
    </item>
    <item>
      <title>BenTo: Benchmark Task Reduction with In-Context Transferability</title>
      <link>https://paperswithcode.com/paper/bento-benchmark-task-reduction-with-in</link>
      <description><![CDATA[Evaluating large language models (LLMs) is costly: it requires the generation and examination of LLM outputs on a large-scale benchmark of various tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bento-benchmark-task-reduction-with-in</guid>
    </item>
    <item>
      <title>LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch</title>
      <link>https://paperswithcode.com/paper/llmopt-learning-to-define-and-solve-general</link>
      <description><![CDATA[Namely, the accuracy of most current LLM-based methods and the generality of optimization problem types that they can model are still limited.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llmopt-learning-to-define-and-solve-general</guid>
    </item>
    <item>
      <title>Hybrid bundle-adjusting 3D Gaussians for view consistent rendering with pose optimization</title>
      <link>https://paperswithcode.com/paper/hybrid-bundle-adjusting-3d-gaussians-for-view</link>
      <description><![CDATA[Novel view synthesis has made significant progress in the field of 3D computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hybrid-bundle-adjusting-3d-gaussians-for-view</guid>
    </item>
    <item>
      <title>A Comparative Study on Reasoning Patterns of OpenAI's o1 Model</title>
      <link>https://paperswithcode.com/paper/a-comparative-study-on-reasoning-patterns-of</link>
      <description><![CDATA[In our work, to investigate the reasoning patterns of o1, we compare o1 with existing Test-time Compute methods (BoN, Step-wise BoN, Agent Workflow, and Self-Refine) by using OpenAI's GPT-4o as a backbone on general reasoning benchmarks in three domains (i. e., math, coding, commonsense reasoning).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparative-study-on-reasoning-patterns-of</guid>
    </item>
    <item>
      <title>Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design</title>
      <link>https://paperswithcode.com/paper/fine-tuning-discrete-diffusion-models-via</link>
      <description><![CDATA[Finally, we demonstrate the effectiveness of DRAKES in generating DNA and protein sequences that optimize enhancer activity and protein stability, respectively, important tasks for gene therapies and protein-based therapeutics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-discrete-diffusion-models-via</guid>
    </item>
    <item>
      <title>ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization</title>
      <link>https://paperswithcode.com/paper/orso-accelerating-reward-design-via-online</link>
      <description><![CDATA[Reward shaping is a critical component in reinforcement learning (RL), particularly for complex tasks where sparse rewards can hinder learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/orso-accelerating-reward-design-via-online</guid>
    </item>
    <item>
      <title>CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models</title>
      <link>https://paperswithcode.com/paper/ccup-a-controllable-synthetic-data-generation</link>
      <description><![CDATA[Cloth-changing person re-identification (CC-ReID), also known as Long-Term Person Re-Identification (LT-ReID) is a critical and challenging research topic in computer vision that has recently garnered significant attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ccup-a-controllable-synthetic-data-generation</guid>
    </item>
    <item>
      <title>Boosting Imperceptibility of Stable Diffusion-based Adversarial Examples Generation with Momentum</title>
      <link>https://paperswithcode.com/paper/boosting-imperceptibility-of-stable-diffusion</link>
      <description><![CDATA[We propose a novel framework, Stable Diffusion-based Momentum Integrated Adversarial Examples (SD-MIAE), for generating adversarial examples that can effectively mislead neural network classifiers while maintaining visual imperceptibility and preserving the semantic similarity to the original class label.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/boosting-imperceptibility-of-stable-diffusion</guid>
    </item>
    <item>
      <title>signwriting-evaluation: Effective Sign Language Evaluation via SignWriting</title>
      <link>https://paperswithcode.com/paper/signwriting-evaluation-effective-sign</link>
      <description><![CDATA[The lack of automatic evaluation metrics tailored for SignWriting presents a significant obstacle in developing effective transcription and translation models for signed languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/signwriting-evaluation-effective-sign</guid>
    </item>
    <item>
      <title>Balancing Label Quantity and Quality for Scalable Elicitation</title>
      <link>https://paperswithcode.com/paper/balancing-label-quantity-and-quality-for</link>
      <description><![CDATA[Scalable oversight studies methods of training and evaluating AI systems in domains where human judgement is unreliable or expensive, such as scientific research and software engineering in complex codebases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/balancing-label-quantity-and-quality-for</guid>
    </item>
    <item>
      <title>Fast Estimation of Partial Dependence Functions using Trees</title>
      <link>https://paperswithcode.com/paper/fast-estimation-of-partial-dependence</link>
      <description><![CDATA[By estimating PD functions for arbitrary feature subsets, \texttt{FastPD} can be used to extract PD-based interpretations such as SHAP, PD plots and higher order interaction effects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-estimation-of-partial-dependence</guid>
    </item>
    <item>
      <title>MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems</title>
      <link>https://paperswithcode.com/paper/mirage-bench-automatic-multilingual-benchmark</link>
      <description><![CDATA[In our work, we benchmark 19 diverse multilingual-focused LLMs, and achieve a high correlation (Kendall Tau ($\tau$) = 0. 909) using our surrogate judge learned using heuristic features with pairwise evaluations and between GPT-4o as a teacher on the MIRAGE-Bench leaderboard using the Bradley-Terry framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mirage-bench-automatic-multilingual-benchmark</guid>
    </item>
    <item>
      <title>Preference Diffusion for Recommendation</title>
      <link>https://paperswithcode.com/paper/preference-diffusion-for-recommendation</link>
      <description><![CDATA[Recommender systems predict personalized item rankings based on user preference distributions derived from historical behavior data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/preference-diffusion-for-recommendation</guid>
    </item>
    <item>
      <title>DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation</title>
      <link>https://paperswithcode.com/paper/dawn-dynamic-frame-avatar-with-non</link>
      <description><![CDATA[To address these challenges, we present DAWN (Dynamic frame Avatar With Non-autoregressive diffusion), a framework that enables all-at-once generation of dynamic-length video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dawn-dynamic-frame-avatar-with-non</guid>
    </item>
  </channel>
</rss>
