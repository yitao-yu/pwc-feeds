<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Latest (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 14 Mar 2023 09:14:53 +0000</lastBuildDate>
    <item>
      <title>Vessel-Promoted OCT to OCTA Image Translation by Heuristic Contextual Constraints</title>
      <link>https://paperswithcode.com/paper/vessel-promoted-oct-to-octa-image-translation</link>
      <description><![CDATA[In this paper, we propose a novel framework, TransPro, that translates 3D Optical Coherence Tomography (OCT) images into exclusive 3D OCTA images using an image translation pattern.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vessel-promoted-oct-to-octa-image-translation</guid>
    </item>
    <item>
      <title>Validation of uncertainty quantification metrics: a primer</title>
      <link>https://paperswithcode.com/paper/validation-of-uncertainty-quantification</link>
      <description><![CDATA[The practice of uncertainty quantification (UQ) validation, notably in machine learning for the physico-chemical sciences, rests on several graphical methods (scattering plots, calibration curves, reliability diagrams and confidence curves) which explore complementary aspects of calibration, without covering all the desirable ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/validation-of-uncertainty-quantification</guid>
    </item>
    <item>
      <title>OverlapNetVLAD: A Coarse-to-Fine Framework for LiDAR-based Place Recognition</title>
      <link>https://paperswithcode.com/paper/overlapnetvlad-a-coarse-to-fine-framework-for</link>
      <description><![CDATA[Place recognition is a challenging yet crucial task in robotics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/overlapnetvlad-a-coarse-to-fine-framework-for</guid>
    </item>
    <item>
      <title>Uni-RXN: An Unified Framework that Bridge the Gap between Chemical Reaction Pretraining and Conditional Molecule Generation</title>
      <link>https://paperswithcode.com/paper/uni-rxn-an-unified-framework-that-bridge-the</link>
      <description><![CDATA[Chemical reactions are the fundamental building blocks of drug design and organic chemistry research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uni-rxn-an-unified-framework-that-bridge-the</guid>
    </item>
    <item>
      <title>Upcycling Models under Domain and Category Shift</title>
      <link>https://paperswithcode.com/paper/upcycling-models-under-domain-and-category</link>
      <description><![CDATA[We examine the superiority of our GLC on multiple benchmarks with different category shift scenarios, including partial-set, open-set, and open-partial-set DA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/upcycling-models-under-domain-and-category</guid>
    </item>
    <item>
      <title>One-Shot Segmentation of Novel White Matter Tracts via Extensive Data Augmentation</title>
      <link>https://paperswithcode.com/paper/one-shot-segmentation-of-novel-white-matter</link>
      <description><![CDATA[However, accurate segmentation of novel WM tracts can still be challenging in the one-shot setting, where only one scan is annotated for the novel WM tracts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-shot-segmentation-of-novel-white-matter</guid>
    </item>
    <item>
      <title>Kernel Density Bayesian Inverse Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/kernel-density-bayesian-inverse-reinforcement</link>
      <description><![CDATA[Inverse reinforcement learning~(IRL) is a powerful framework to infer an agent's reward function by observing its behavior, but IRL algorithms that learn point estimates of the reward function can be misleading because there may be several functions that describe an agent's behavior equally well.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kernel-density-bayesian-inverse-reinforcement</guid>
    </item>
    <item>
      <title>TriDet: Temporal Action Detection with Relative Boundary Modeling</title>
      <link>https://paperswithcode.com/paper/tridet-temporal-action-detection-with</link>
      <description><![CDATA[In this paper, we present a one-stage framework TriDet for temporal action detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tridet-temporal-action-detection-with</guid>
    </item>
    <item>
      <title>High-throughput Generative Inference of Large Language Models with a Single GPU</title>
      <link>https://paperswithcode.com/paper/high-throughput-generative-inference-of-large</link>
      <description><![CDATA[As a result, when running OPT-175B on a single 16GB GPU, FlexGen achieves significantly higher throughput compared to state-of-the-art offloading systems, reaching a generation throughput of 1 token/s for the first time with an effective batch size of 144.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-throughput-generative-inference-of-large</guid>
    </item>
    <item>
      <title>Contextually-rich human affect perception using multimodal scene information</title>
      <link>https://paperswithcode.com/paper/contextually-rich-human-affect-perception</link>
      <description><![CDATA[The process of human affect understanding involves the ability to infer person specific emotional states from various sources including images, speech, and language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contextually-rich-human-affect-perception</guid>
    </item>
    <item>
      <title>OTOV2: Automatic, Generic, User-Friendly</title>
      <link>https://paperswithcode.com/paper/otov2-automatic-generic-user-friendly</link>
      <description><![CDATA[We propose the second generation of Only-Train-Once (OTOv2), which first automatically trains and compresses a general DNN only once from scratch to produce a more compact model with competitive performance without fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/otov2-automatic-generic-user-friendly</guid>
    </item>
    <item>
      <title>AGTGAN: Unpaired Image Translation for Photographic Ancient Character Generation</title>
      <link>https://paperswithcode.com/paper/agtgan-unpaired-image-translation-for</link>
      <description><![CDATA[We evaluate our approach on the photographic ancient character datasets, e. g., OBC306 and CSDD.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agtgan-unpaired-image-translation-for</guid>
    </item>
    <item>
      <title>TranSG: Transformer-Based Skeleton Graph Prototype Contrastive Learning with Structure-Trajectory Prompted Reconstruction for Person Re-Identification</title>
      <link>https://paperswithcode.com/paper/transg-transformer-based-skeleton-graph</link>
      <description><![CDATA[Then, we propose the Graph Prototype Contrastive learning (GPC) to mine the most typical graph features (graph prototypes) of each identity, and contrast the inherent similarity between graph representations and different prototypes from both skeleton and sequence levels to learn discriminative graph representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transg-transformer-based-skeleton-graph</guid>
    </item>
    <item>
      <title>Super-Resolution Information Enhancement For Crowd Counting</title>
      <link>https://paperswithcode.com/paper/super-resolution-information-enhancement-for</link>
      <description><![CDATA[As the proposed method requires SR labels, we further propose a Super-Resolution Crowd Counting dataset (SR-Crowd).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/super-resolution-information-enhancement-for</guid>
    </item>
    <item>
      <title>Learning Distortion Invariant Representation for Image Restoration from A Causality Perspective</title>
      <link>https://paperswithcode.com/paper/learning-distortion-invariant-representation</link>
      <description><![CDATA[In this paper, we are the first to propose a novel training strategy for image restoration from the causality perspective, to improve the generalization ability of DNNs for unknown degradations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-distortion-invariant-representation</guid>
    </item>
    <item>
      <title>FireRisk: A Remote Sensing Dataset for Fire Risk Assessment with Benchmarks Using Supervised and Self-supervised Learning</title>
      <link>https://paperswithcode.com/paper/firerisk-a-remote-sensing-dataset-for-fire</link>
      <description><![CDATA[Inspired by the abundance of publicly available remote sensing projects and the burgeoning development of deep learning in computer vision, our research focuses on assessing fire risk using remote sensing imagery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/firerisk-a-remote-sensing-dataset-for-fire</guid>
    </item>
    <item>
      <title>Adaptive Data-Free Quantization</title>
      <link>https://paperswithcode.com/paper/adaptive-data-free-quantization</link>
      <description><![CDATA[how to generate the samples with large adaptability to improve Q's generalization?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptive-data-free-quantization</guid>
    </item>
    <item>
      <title>CrossFormer++: A Versatile Vision Transformer Hinging on Cross-scale Attention</title>
      <link>https://paperswithcode.com/paper/crossformer-a-versatile-vision-transformer-1</link>
      <description><![CDATA[On the one hand, CEL blends each token with multiple patches of different scales, providing the self-attention module itself with cross-scale features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/crossformer-a-versatile-vision-transformer-1</guid>
    </item>
    <item>
      <title>Progressive Open Space Expansion for Open-Set Model Attribution</title>
      <link>https://paperswithcode.com/paper/progressive-open-space-expansion-for-open-set</link>
      <description><![CDATA[In this study, we focus on a challenging task, namely Open-Set Model Attribution (OSMA), to simultaneously attribute images to known models and identify those from unknown ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progressive-open-space-expansion-for-open-set</guid>
    </item>
    <item>
      <title>ST360IQ: No-Reference Omnidirectional Image Quality Assessment with Spherical Vision Transformers</title>
      <link>https://paperswithcode.com/paper/st360iq-no-reference-omnidirectional-image</link>
      <description><![CDATA[As their popularity has increased dramatically in recent years, evaluating the quality of 360 images has become a problem of interest since it provides insights for capturing, transmitting, and consuming this new media.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/st360iq-no-reference-omnidirectional-image</guid>
    </item>
    <item>
      <title>Erasing Concepts from Diffusion Models</title>
      <link>https://paperswithcode.com/paper/erasing-concepts-from-diffusion-models</link>
      <description><![CDATA[We propose a fine-tuning method that can erase a visual concept from a pre-trained diffusion model, given only the name of the style and using negative guidance as a teacher.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/erasing-concepts-from-diffusion-models</guid>
    </item>
    <item>
      <title>Improving Mutual Information Estimation with Annealed and Energy-Based Bounds</title>
      <link>https://paperswithcode.com/paper/improving-mutual-information-estimation-with-1</link>
      <description><![CDATA[Since accurate estimation of MI without density information requires a sample size exponential in the true MI, we assume either a single marginal or the full joint density information is known.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-mutual-information-estimation-with-1</guid>
    </item>
    <item>
      <title>Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need</title>
      <link>https://paperswithcode.com/paper/revisiting-class-incremental-learning-with</link>
      <description><![CDATA[ADAM is a general framework that can be orthogonally combined with any parameter-efficient tuning method, which holds the advantages of PTM's generalizability and adapted model's adaptivity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-class-incremental-learning-with</guid>
    </item>
    <item>
      <title>Transformer Encoder with Multiscale Deep Learning for Pain Classification Using Physiological Signals</title>
      <link>https://paperswithcode.com/paper/transformer-encoder-with-multiscale-deep</link>
      <description><![CDATA[These results confirm that our approach can be utilized for automated classification of pain intensity using physiological signals to improve pain management and treatment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-encoder-with-multiscale-deep</guid>
    </item>
    <item>
      <title>Predicting Density of States via Multi-modal Transformer</title>
      <link>https://paperswithcode.com/paper/predicting-density-of-states-via-multi-modal</link>
      <description><![CDATA[The density of states (DOS) is a spectral property of materials, which provides fundamental insights on various characteristics of materials.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/predicting-density-of-states-via-multi-modal</guid>
    </item>
    <item>
      <title>Backdoor Defense via Deconfounded Representation Learning</title>
      <link>https://paperswithcode.com/paper/backdoor-defense-via-deconfounded</link>
      <description><![CDATA[The other clean model dedicates to capturing the desired causal effects by minimizing the mutual information with the confounding representations from the backdoored model and employing a sample-wise re-weighting scheme.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/backdoor-defense-via-deconfounded</guid>
    </item>
    <item>
      <title>Label Information Bottleneck for Label Enhancement</title>
      <link>https://paperswithcode.com/paper/label-information-bottleneck-for-label</link>
      <description><![CDATA[In this work, we focus on the challenging problem of Label Enhancement (LE), which aims to exactly recover label distributions from logical labels, and present a novel Label Information Bottleneck (LIB) method for LE.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/label-information-bottleneck-for-label</guid>
    </item>
    <item>
      <title>Physics-driven machine learning models coupling PyTorch and Firedrake</title>
      <link>https://paperswithcode.com/paper/physics-driven-machine-learning-models</link>
      <description><![CDATA[Partial differential equations (PDEs) are central to describing and modelling complex physical systems that arise in many disciplines across science and engineering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physics-driven-machine-learning-models</guid>
    </item>
    <item>
      <title>CoGANPPIS: Coevolution-enhanced Global Attention Neural Network for Protein-Protein Interaction Site Prediction</title>
      <link>https://paperswithcode.com/paper/coganppis-coevolution-enhanced-global</link>
      <description><![CDATA[It utilizes three layers in parallel for feature extraction: (1) Local-level representation aggregation layer, which aggregates the neighboring residues' features; (2) Global-level representation learning layer, which employs a novel coevolution-enhanced global attention mechanism to allocate attention weights to all the residues on the same protein sequences; (3) Coevolutionary information learning layer, which applies CNN & pooling to coevolutionary information to obtain the coevolutionary profile representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/coganppis-coevolution-enhanced-global</guid>
    </item>
    <item>
      <title>A Human Subject Study of Named Entity Recognition (NER) in Conversational Music Recommendation Queries</title>
      <link>https://paperswithcode.com/paper/a-human-subject-study-of-named-entity</link>
      <description><![CDATA[We conducted a human subject study of named entity recognition on a noisy corpus of conversational music recommendation queries, with many irregular and novel named entities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-human-subject-study-of-named-entity</guid>
    </item>
    <item>
      <title>Reference-Guided Large-Scale Face Inpainting with Identity and Texture Control</title>
      <link>https://paperswithcode.com/paper/reference-guided-large-scale-face-inpainting</link>
      <description><![CDATA[To introduce strong control for face inpainting, we propose a novel reference-guided face inpainting method that fills the large-scale missing region with identity and texture control guided by a reference face image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reference-guided-large-scale-face-inpainting</guid>
    </item>
    <item>
      <title>PoseExaminer: Automated Testing of Out-of-Distribution Robustness in Human Pose and Shape Estimation</title>
      <link>https://paperswithcode.com/paper/poseexaminer-automated-testing-of-out-of</link>
      <description><![CDATA[We introduce a learning-based testing method, termed PoseExaminer, that automatically diagnoses HPS algorithms by searching over the parameter space of human pose images to find the failure modes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poseexaminer-automated-testing-of-out-of</guid>
    </item>
    <item>
      <title>Efficient Semantic Segmentation by Altering Resolutions for Compressed Videos</title>
      <link>https://paperswithcode.com/paper/efficient-semantic-segmentation-by-altering</link>
      <description><![CDATA[In this paper, we propose an altering resolution framework called AR-Seg for compressed videos to achieve efficient VSS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-semantic-segmentation-by-altering</guid>
    </item>
    <item>
      <title>DINO-MC: Self-supervised Contrastive Learning for Remote Sensing Imagery with Multi-sized Local Crops</title>
      <link>https://paperswithcode.com/paper/dino-mc-self-supervised-contrastive-learning</link>
      <description><![CDATA[Due to the costly nature of remote sensing image labeling and the large volume of available unlabeled imagery, self-supervised methods that can learn feature representations without manual annotation have received great attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dino-mc-self-supervised-contrastive-learning</guid>
    </item>
    <item>
      <title>Color Mismatches in Stereoscopic Video: Real-World Dataset and Deep Correction Method</title>
      <link>https://paperswithcode.com/paper/color-mismatches-in-stereoscopic-video-real</link>
      <description><![CDATA[We propose a real-world dataset of stereoscopic videos for color-mismatch correction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/color-mismatches-in-stereoscopic-video-real</guid>
    </item>
    <item>
      <title>Ensemble Learning of Myocardial Displacements for Myocardial Infarction Detection in Echocardiography</title>
      <link>https://paperswithcode.com/paper/ensemble-learning-of-myocardial-displacements</link>
      <description><![CDATA[The proposed approach demonstrated excellent performance in detecting MI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ensemble-learning-of-myocardial-displacements</guid>
    </item>
    <item>
      <title>Proactive Prioritization of App Issues via Contrastive Learning</title>
      <link>https://paperswithcode.com/paper/proactive-prioritization-of-app-issues-via</link>
      <description><![CDATA[Phase one adapts the pre-trained T5 model to the user reviews data in a self-supervised fashion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proactive-prioritization-of-app-issues-via</guid>
    </item>
    <item>
      <title>MWE as WSD: Solving Multiword Expression Identification with Word Sense Disambiguation</title>
      <link>https://paperswithcode.com/paper/mwe-as-wsd-solving-multiword-expression</link>
      <description><![CDATA[Recent work in word sense disambiguation (WSD) utilizes encodings of the sense gloss (definition text), in addition to the input words and context, to improve performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mwe-as-wsd-solving-multiword-expression</guid>
    </item>
    <item>
      <title>Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive Machine Translation</title>
      <link>https://paperswithcode.com/paper/fuzzy-alignments-in-directed-acyclic-graph</link>
      <description><![CDATA[Non-autoregressive translation (NAT) reduces the decoding latency but suffers from performance degradation due to the multi-modality problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fuzzy-alignments-in-directed-acyclic-graph</guid>
    </item>
    <item>
      <title>AidUI: Toward Automated Recognition of Dark Patterns in User Interfaces</title>
      <link>https://paperswithcode.com/paper/aidui-toward-automated-recognition-of-dark</link>
      <description><![CDATA[To evaluate our approach, we have constructed ContextDP, the current largest dataset of fully-localized UI dark patterns that spans 175 mobile and 83 web UI screenshots containing 301 dark pattern instances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aidui-toward-automated-recognition-of-dark</guid>
    </item>
    <item>
      <title>Universal Instance Perception as Object Discovery and Retrieval</title>
      <link>https://paperswithcode.com/paper/universal-instance-perception-as-object</link>
      <description><![CDATA[All instance perception tasks aim at finding certain objects specified by some queries such as category names, language expressions, and target annotations, but this complete field has been split into multiple independent subtasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-instance-perception-as-object</guid>
    </item>
    <item>
      <title>Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search</title>
      <link>https://paperswithcode.com/paper/large-language-models-know-your-contextual</link>
      <description><![CDATA[In this paper, we present a prompting framework called LLMCS that leverages large language models, such as code-davinci-002 of GPT-3, to perform few-shot conversational query rewriting for conversational search.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-know-your-contextual</guid>
    </item>
    <item>
      <title>ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions</title>
      <link>https://paperswithcode.com/paper/chatgpt-asks-blip-2-answers-automatic</link>
      <description><![CDATA[By keeping acquiring new visual information from BLIP-2's answers, ChatCaptioner is able to generate more enriched image descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatgpt-asks-blip-2-answers-automatic</guid>
    </item>
    <item>
      <title>P-MMF: Provider Max-min Fairness Re-ranking in Recommender System</title>
      <link>https://paperswithcode.com/paper/p-mmf-provider-max-min-fairness-re-ranking-in</link>
      <description><![CDATA[In this paper, we proposed an online re-ranking model named Provider Max-min Fairness Re-ranking (P-MMF) to tackle the problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/p-mmf-provider-max-min-fairness-re-ranking-in</guid>
    </item>
    <item>
      <title>SSGD: A smartphone screen glass dataset for defect detection</title>
      <link>https://paperswithcode.com/paper/ssgd-a-smartphone-screen-glass-dataset-for</link>
      <description><![CDATA[Interactive devices with touch screen have become commonly used in various aspects of daily life, which raises the demand for high production quality of touch screen glass.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ssgd-a-smartphone-screen-glass-dataset-for</guid>
    </item>
    <item>
      <title>Informative regularization for a multi-layer perceptron RR Lyrae classifier under data shift</title>
      <link>https://paperswithcode.com/paper/informative-regularization-for-a-multi-layer</link>
      <description><![CDATA[Consequently, we propose a scalable and easily adaptable approach based on an informative regularization and an ad-hoc training procedure to mitigate the shift problem during the training of a multi-layer perceptron for RR Lyrae classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/informative-regularization-for-a-multi-layer</guid>
    </item>
    <item>
      <title>Schema Inference for Interpretable Image Classification</title>
      <link>https://paperswithcode.com/paper/schema-inference-for-interpretable-image</link>
      <description><![CDATA[In this paper, we study a novel inference paradigm, termed as schema inference, that learns to deductively infer the explainable predictions by rebuilding the prior deep neural network (DNN) forwarding scheme, guided by the prevalent philosophical cognitive concept of schema.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/schema-inference-for-interpretable-image</guid>
    </item>
    <item>
      <title>Compressed Heterogeneous Graph for Abstractive Multi-Document Summarization</title>
      <link>https://paperswithcode.com/paper/compressed-heterogeneous-graph-for</link>
      <description><![CDATA[We propose HGSUM, an MDS model that extends an encoder-decoder architecture, to incorporate a heterogeneous graph to represent different semantic units (e. g., words and sentences) of the documents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compressed-heterogeneous-graph-for</guid>
    </item>
    <item>
      <title>One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale</title>
      <link>https://paperswithcode.com/paper/one-transformer-fits-all-distributions-in</link>
      <description><![CDATA[Inspired by the unified view, UniDiffuser learns all distributions simultaneously with a minimal modification to the original diffusion model -- perturbs data in all modalities instead of a single modality, inputs individual timesteps in different modalities, and predicts the noise of all modalities instead of a single modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-transformer-fits-all-distributions-in</guid>
    </item>
    <item>
      <title>Predictive Experience Replay for Continual Visual Control and Forecasting</title>
      <link>https://paperswithcode.com/paper/predictive-experience-replay-for-continual</link>
      <description><![CDATA[In this paper, we present a new continual learning approach for visual dynamics modeling and explore its efficacy in visual control and forecasting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/predictive-experience-replay-for-continual</guid>
    </item>
  </channel>
</rss>
