<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 28 Jan 2023 21:05:57 +0000</lastBuildDate>
    <item>
      <title>Cut and Learn for Unsupervised Object Detection and Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/cut-and-learn-for-unsupervised-object</link>
      <description><![CDATA[We propose Cut-and-LEaRn (CutLER), a simple approach for training unsupervised object detection and segmentation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cut-and-learn-for-unsupervised-object</guid>
    </item>
    <item>
      <title>InstructPix2Pix: Learning to Follow Image Editing Instructions</title>
      <link>https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</link>
      <description><![CDATA[We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</guid>
    </item>
    <item>
      <title>StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis</title>
      <link>https://paperswithcode.com/paper/stylegan-t-unlocking-the-power-of-gans-for</link>
      <description><![CDATA[Text-to-image synthesis has recently seen significant progress thanks to large pretrained language models, large-scale training data, and the introduction of scalable model families such as diffusion and autoregressive models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stylegan-t-unlocking-the-power-of-gans-for</guid>
    </item>
    <item>
      <title>Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP</title>
      <link>https://paperswithcode.com/paper/demonstrate-search-predict-composing</link>
      <description><![CDATA[Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demonstrate-search-predict-composing</guid>
    </item>
    <item>
      <title>Generating Sequences With Recurrent Neural Networks</title>
      <link>https://paperswithcode.com/paper/generating-sequences-with-recurrent-neural</link>
      <description><![CDATA[This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-sequences-with-recurrent-neural</guid>
    </item>
    <item>
      <title>Hungry Hungry Hippos: Towards Language Modeling with State Space Models</title>
      <link>https://paperswithcode.com/paper/hungry-hungry-hippos-towards-language</link>
      <description><![CDATA[First, we use synthetic language modeling tasks to understand the gap between SSMs and attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hungry-hungry-hippos-towards-language</guid>
    </item>
    <item>
      <title>Fine-Tuning Language Models from Human Preferences</title>
      <link>https://paperswithcode.com/paper/fine-tuning-language-models-from-human</link>
      <description><![CDATA[Most work on reward learning has used simulated environments, but complex information about values is often expressed in natural language, and we believe reward learning for language is a key to making RL practical and safe for real-world tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-language-models-from-human</guid>
    </item>
    <item>
      <title>Learning the Beauty in Songs: Neural Singing Voice Beautifier</title>
      <link>https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</link>
      <description><![CDATA[Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</guid>
    </item>
    <item>
      <title>K-Planes: Explicit Radiance Fields in Space, Time, and Appearance</title>
      <link>https://paperswithcode.com/paper/k-planes-explicit-radiance-fields-in-space</link>
      <description><![CDATA[We introduce k-planes, a white-box model for radiance fields in arbitrary dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/k-planes-explicit-radiance-fields-in-space</guid>
    </item>
    <item>
      <title>VIBUS: Data-efficient 3D Scene Parsing with VIewpoint Bottleneck and Uncertainty-Spectrum Modeling</title>
      <link>https://paperswithcode.com/paper/vibus-data-efficient-3d-scene-parsing-with</link>
      <description><![CDATA[In the first stage, we perform self-supervised representation learning on unlabeled points with the proposed Viewpoint Bottleneck loss function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vibus-data-efficient-3d-scene-parsing-with</guid>
    </item>
    <item>
      <title>SNAKE: Shape-aware Neural 3D Keypoint Field</title>
      <link>https://paperswithcode.com/paper/snake-shape-aware-neural-3d-keypoint-field</link>
      <description><![CDATA[Detecting 3D keypoints from point clouds is important for shape reconstruction, while this work investigates the dual question: can shape reconstruction benefit 3D keypoint detection?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/snake-shape-aware-neural-3d-keypoint-field</guid>
    </item>
    <item>
      <title>OCR-free Document Understanding Transformer</title>
      <link>https://paperswithcode.com/paper/donut-document-understanding-transformer</link>
      <description><![CDATA[Current Visual Document Understanding (VDU) methods outsource the task of reading text to off-the-shelf Optical Character Recognition (OCR) engines and focus on the understanding task with the OCR outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/donut-document-understanding-transformer</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>Text2LIVE: Text-Driven Layered Image and Video Editing</title>
      <link>https://paperswithcode.com/paper/text2live-text-driven-layered-image-and-video</link>
      <description><![CDATA[Given an input image or video and a target text prompt, our goal is to edit the appearance of existing objects (e. g., object's texture) or augment the scene with visual effects (e. g., smoke, fire) in a semantically meaningful manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2live-text-driven-layered-image-and-video</guid>
    </item>
    <item>
      <title>Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling</title>
      <link>https://paperswithcode.com/paper/designing-bert-for-convolutional-networks</link>
      <description><![CDATA[This is the first use of sparse convolution for 2D masked modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/designing-bert-for-convolutional-networks</guid>
    </item>
    <item>
      <title>Multi-scale Multi-band DenseNets for Audio Source Separation</title>
      <link>https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</link>
      <description><![CDATA[This paper deals with the problem of audio source separation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</guid>
    </item>
    <item>
      <title>BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining</title>
      <link>https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</link>
      <description><![CDATA[Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</guid>
    </item>
    <item>
      <title>Salesforce CausalAI Library: A Fast and Scalable Framework for Causal Analysis of Time Series and Tabular Data</title>
      <link>https://paperswithcode.com/paper/salesforce-causalai-library-a-fast-and</link>
      <description><![CDATA[We introduce the Salesforce CausalAI Library, an open-source library for causal analysis using observational data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/salesforce-causalai-library-a-fast-and</guid>
    </item>
    <item>
      <title>Planar Object Tracking via Weighted Optical Flow</title>
      <link>https://paperswithcode.com/paper/planar-object-tracking-via-weighted-optical</link>
      <description><![CDATA[We propose WOFT -- a novel method for planar object tracking that estimates a full 8 degrees-of-freedom pose, i. e. the homography w. r. t.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/planar-object-tracking-via-weighted-optical</guid>
    </item>
  </channel>
</rss>
