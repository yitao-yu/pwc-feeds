<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 01 Mar 2024 09:14:11 +0000</lastBuildDate>
    <item>
      <title>YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information</title>
      <link>https://paperswithcode.com/paper/yolov9-learning-what-you-want-to-learn-using</link>
      <description><![CDATA[It can be used to obtain complete information, so that train-from-scratch models can achieve better results than state-of-the-art models pre-trained using large datasets, the comparison results are shown in Figure 1.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov9-learning-what-you-want-to-learn-using</guid>
    </item>
    <item>
      <title>Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing</title>
      <link>https://paperswithcode.com/paper/where-visual-speech-meets-language-vsp-llm</link>
      <description><![CDATA[In visual speech processing, context modeling capability is one of the most important requirements due to the ambiguous nature of lip movements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/where-visual-speech-meets-language-vsp-llm</guid>
    </item>
    <item>
      <title>Intent-based Prompt Calibration: Enhancing prompt optimization with synthetic boundary cases</title>
      <link>https://paperswithcode.com/paper/intent-based-prompt-calibration-enhancing</link>
      <description><![CDATA[Recent studies have demonstrated the capabilities of LLMs to automatically conduct prompt engineering by employing a meta-prompt that incorporates the outcomes of the last trials and proposes an improved prompt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intent-based-prompt-calibration-enhancing</guid>
    </item>
    <item>
      <title>UFO: A UI-Focused Agent for Windows OS Interaction</title>
      <link>https://paperswithcode.com/paper/ufo-a-ui-focused-agent-for-windows-os</link>
      <description><![CDATA[We introduce UFO, an innovative UI-Focused agent to fulfill user requests tailored to applications on Windows OS, harnessing the capabilities of GPT-Vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ufo-a-ui-focused-agent-for-windows-os</guid>
    </item>
    <item>
      <title>Neural Network Diffusion</title>
      <link>https://paperswithcode.com/paper/neural-network-diffusion</link>
      <description><![CDATA[The autoencoder extracts latent representations of a subset of the trained network parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-network-diffusion</guid>
    </item>
    <item>
      <title>Scalable Diffusion Models with Transformers</title>
      <link>https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</link>
      <description><![CDATA[We explore a new class of diffusion models based on the transformer architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</guid>
    </item>
    <item>
      <title>Vectorized and performance-portable Quicksort</title>
      <link>https://paperswithcode.com/paper/vectorized-and-performance-portable-quicksort</link>
      <description><![CDATA[Recent works showed that implementations of Quicksort using vector CPU instructions can outperform the non-vectorized algorithms in widespread use.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vectorized-and-performance-portable-quicksort</guid>
    </item>
    <item>
      <title>Cleaner Pretraining Corpus Curation with Neural Web Scraping</title>
      <link>https://paperswithcode.com/paper/cleaner-pretraining-corpus-curation-with</link>
      <description><![CDATA[The web contains large-scale, diverse, and abundant information to satisfy the information-seeking needs of humans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cleaner-pretraining-corpus-curation-with</guid>
    </item>
    <item>
      <title>AlphaFold Meets Flow Matching for Generating Protein Ensembles</title>
      <link>https://paperswithcode.com/paper/alphafold-meets-flow-matching-for-generating</link>
      <description><![CDATA[When trained and evaluated on the PDB, our method provides a superior combination of precision and diversity compared to AlphaFold with MSA subsampling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alphafold-meets-flow-matching-for-generating</guid>
    </item>
    <item>
      <title>World Model on Million-Length Video And Language With RingAttention</title>
      <link>https://paperswithcode.com/paper/world-model-on-million-length-video-and</link>
      <description><![CDATA[This work paves the way for training on massive datasets of long video and language to develop understanding of both human knowledge and the multimodal world, and broader capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/world-model-on-million-length-video-and</guid>
    </item>
    <item>
      <title>TinyLLaVA: A Framework of Small-scale Large Multimodal Models</title>
      <link>https://paperswithcode.com/paper/tinyllava-a-framework-of-small-scale-large</link>
      <description><![CDATA[We present the TinyLLaVA framework that provides a unified perspective in designing and analyzing the small-scale Large Multimodal Models (LMMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tinyllava-a-framework-of-small-scale-large</guid>
    </item>
    <item>
      <title>Repetition Improves Language Model Embeddings</title>
      <link>https://paperswithcode.com/paper/repetition-improves-language-model-embeddings</link>
      <description><![CDATA[In this work, we address an architectural limitation of autoregressive models: token embeddings cannot contain information from tokens that appear later in the input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repetition-improves-language-model-embeddings</guid>
    </item>
    <item>
      <title>Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition</title>
      <link>https://paperswithcode.com/paper/gen4gen-generative-data-pipeline-for</link>
      <description><![CDATA[First, current personalization techniques fail to reliably extend to multiple concepts -- we hypothesize this to be due to the mismatch between complex scenes and simple text descriptions in the pre-training dataset (e. g., LAION).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gen4gen-generative-data-pipeline-for</guid>
    </item>
    <item>
      <title>Large Language Models for Data Annotation: A Survey</title>
      <link>https://paperswithcode.com/paper/large-language-models-for-data-annotation-a</link>
      <description><![CDATA[Furthermore, the paper includes an in-depth taxonomy of methodologies employing LLMs for data annotation, a comprehensive review of learning strategies for models incorporating LLM-generated annotations, and a detailed discussion on primary challenges and limitations associated with using LLMs for data annotation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-for-data-annotation-a</guid>
    </item>
    <item>
      <title>YOLO-World: Real-Time Open-Vocabulary Object Detection</title>
      <link>https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</link>
      <description><![CDATA[The You Only Look Once (YOLO) series of detectors have established themselves as efficient and practical tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</guid>
    </item>
    <item>
      <title>Towards Building Multilingual Language Model for Medicine</title>
      <link>https://paperswithcode.com/paper/towards-building-multilingual-language-model</link>
      <description><![CDATA[In this paper, we aim to develop an open-source, multilingual language model for medicine, that the benefits a wider, linguistically diverse audience from different regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-building-multilingual-language-model</guid>
    </item>
    <item>
      <title>Differential Diffusion: Giving Each Pixel Its Strength</title>
      <link>https://paperswithcode.com/paper/differential-diffusion-giving-each-pixel-its</link>
      <description><![CDATA[While current techniques enable user control over the degree of change in an image edit, the controllability is limited to global changes over an entire edited region.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/differential-diffusion-giving-each-pixel-its</guid>
    </item>
    <item>
      <title>T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching</title>
      <link>https://paperswithcode.com/paper/t-stitch-accelerating-sampling-in-pre-trained</link>
      <description><![CDATA[Sampling from diffusion probabilistic models (DPMs) is often expensive for high-quality image generation and typically requires many steps with a large model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t-stitch-accelerating-sampling-in-pre-trained</guid>
    </item>
    <item>
      <title>OS-Copilot: Towards Generalist Computer Agents with Self-Improvement</title>
      <link>https://paperswithcode.com/paper/os-copilot-towards-generalist-computer-agents</link>
      <description><![CDATA[Autonomous interaction with the computer has been a longstanding challenge with great potential, and the recent proliferation of large language models (LLMs) has markedly accelerated progress in building digital agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/os-copilot-towards-generalist-computer-agents</guid>
    </item>
    <item>
      <title>FiT: Flexible Vision Transformer for Diffusion Model</title>
      <link>https://paperswithcode.com/paper/fit-flexible-vision-transformer-for-diffusion</link>
      <description><![CDATA[Nature is infinitely resolution-free.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fit-flexible-vision-transformer-for-diffusion</guid>
    </item>
  </channel>
</rss>
