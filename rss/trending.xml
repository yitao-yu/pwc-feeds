<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 13 Feb 2025 09:16:19 +0000</lastBuildDate>
    <item>
      <title>s1: Simple test-time scaling</title>
      <link>https://paperswithcode.com/paper/s1-simple-test-time-scaling</link>
      <description><![CDATA[After supervised finetuning the Qwen2. 5-32B-Instruct language model on s1K and equipping it with budget forcing, our model s1-32B exceeds o1-preview on competition math questions by up to 27% (MATH and AIME24).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s1-simple-test-time-scaling</guid>
    </item>
    <item>
      <title>Data Formulator 2: Iteratively Creating Rich Visualizations with AI</title>
      <link>https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</link>
      <description><![CDATA[To create rich visualizations, data analysts often need to iterate back and forth among data processing and chart specification to achieve their goals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</guid>
    </item>
    <item>
      <title>LLM4Decompile: Decompiling Binary Code with Large Language Models</title>
      <link>https://paperswithcode.com/paper/llm4decompile-decompiling-binary-code-with</link>
      <description><![CDATA[Decompilation aims to convert binary code to high-level source code, but traditional tools like Ghidra often produce results that are difficult to read and execute.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm4decompile-decompiling-binary-code-with</guid>
    </item>
    <item>
      <title>Cut Your Losses in Large-Vocabulary Language Models</title>
      <link>https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</link>
      <description><![CDATA[We implement a custom kernel that performs the matrix multiplications and the log-sum-exp reduction over the vocabulary in flash memory, making global memory consumption for the cross-entropy computation negligible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</guid>
    </item>
    <item>
      <title>DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</link>
      <description><![CDATA[We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</guid>
    </item>
    <item>
      <title>Flaming-hot Initiation with Regular Execution Sampling for Large Language Models</title>
      <link>https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</link>
      <description><![CDATA[Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</guid>
    </item>
    <item>
      <title>rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking</title>
      <link>https://paperswithcode.com/paper/rstar-math-small-llms-can-master-math</link>
      <description><![CDATA[We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rstar-math-small-llms-can-master-math</guid>
    </item>
    <item>
      <title>Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback</title>
      <link>https://paperswithcode.com/paper/align-anything-training-all-modality-models</link>
      <description><![CDATA[In this work, we make the first attempt to fine-tune all-modality models (i. e. input and output with any modality, also named any-to-any models) using human preference data across all modalities (including text, image, audio, and video), ensuring its behavior aligns with human intentions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/align-anything-training-all-modality-models</guid>
    </item>
    <item>
      <title>FireRedASR: Open-Source Industrial-Grade Mandarin Speech Recognition Models from Encoder-Decoder to LLM Integration</title>
      <link>https://paperswithcode.com/paper/fireredasr-open-source-industrial-grade</link>
      <description><![CDATA[We present FireRedASR, a family of large-scale automatic speech recognition (ASR) models for Mandarin, designed to meet diverse requirements in superior performance and optimal efficiency across various applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fireredasr-open-source-industrial-grade</guid>
    </item>
    <item>
      <title>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</link>
      <description><![CDATA[We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</guid>
    </item>
    <item>
      <title>PARTNR: A Benchmark for Planning and Reasoning in Embodied Multi-agent Tasks</title>
      <link>https://paperswithcode.com/paper/partnr-a-benchmark-for-planning-and-reasoning</link>
      <description><![CDATA[We present a benchmark for Planning And Reasoning Tasks in humaN-Robot collaboration (PARTNR) designed to study human-robot coordination in household activities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/partnr-a-benchmark-for-planning-and-reasoning</guid>
    </item>
    <item>
      <title>Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step</title>
      <link>https://paperswithcode.com/paper/can-we-generate-images-with-cot-let-s-verify</link>
      <description><![CDATA[We hope our study provides unique insights and paves a new path for integrating CoT reasoning with autoregressive image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-we-generate-images-with-cot-let-s-verify</guid>
    </item>
    <item>
      <title>IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems</title>
      <link>https://paperswithcode.com/paper/intellagent-a-multi-agent-framework-for</link>
      <description><![CDATA[IntellAgent represents a paradigm shift in evaluating conversational AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intellagent-a-multi-agent-framework-for</guid>
    </item>
    <item>
      <title>DeepSeek-V3 Technical Report</title>
      <link>https://paperswithcode.com/paper/deepseek-v3-technical-report</link>
      <description><![CDATA[We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-v3-technical-report</guid>
    </item>
    <item>
      <title>ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills</title>
      <link>https://paperswithcode.com/paper/asap-aligning-simulation-and-real-world</link>
      <description><![CDATA[In the second stage, we deploy the policies in the real world and collect real-world data to train a delta (residual) action model that compensates for the dynamics mismatch.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asap-aligning-simulation-and-real-world</guid>
    </item>
    <item>
      <title>SGLang: Efficient Execution of Structured Language Model Programs</title>
      <link>https://paperswithcode.com/paper/efficiently-programming-large-language-models</link>
      <description><![CDATA[SGLang consists of a frontend language and a runtime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiently-programming-large-language-models</guid>
    </item>
    <item>
      <title>Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search</title>
      <link>https://paperswithcode.com/paper/mulberry-empowering-mllm-with-o1-like</link>
      <description><![CDATA[Using CoMCTS, we construct Mulberry-260k, a multimodal dataset with a tree of rich, explicit and well-defined reasoning nodes for each question.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mulberry-empowering-mllm-with-o1-like</guid>
    </item>
    <item>
      <title>Bilateral Reference for High-Resolution Dichotomous Image Segmentation</title>
      <link>https://paperswithcode.com/paper/bilateral-reference-for-high-resolution</link>
      <description><![CDATA[It comprises two essential components: the localization module (LM) and the reconstruction module (RM) with our proposed bilateral reference (BiRef).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bilateral-reference-for-high-resolution</guid>
    </item>
    <item>
      <title>REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models</title>
      <link>https://paperswithcode.com/paper/reinforce-a-simple-and-efficient-approach-for</link>
      <description><![CDATA[Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical approach for aligning large language models with human preferences, witnessing rapid algorithmic evolution through methods such as Proximal Policy Optimization (PPO), Direct Preference Optimization (DPO), REINFORCE Leave One-Out (RLOO), ReMax, and Group Relative Policy Optimization (GRPO).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforce-a-simple-and-efficient-approach-for</guid>
    </item>
    <item>
      <title>Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO</title>
      <link>https://paperswithcode.com/paper/implementation-matters-in-deep-policy</link>
      <description><![CDATA[We study the roots of algorithmic progress in deep policy gradient algorithms through a case study on two popular algorithms: Proximal Policy Optimization (PPO) and Trust Region Policy Optimization (TRPO).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implementation-matters-in-deep-policy</guid>
    </item>
  </channel>
</rss>
