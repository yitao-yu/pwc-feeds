<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 29 Mar 2025 21:08:24 +0000</lastBuildDate>
    <item>
      <title>InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity</title>
      <link>https://paperswithcode.com/paper/infiniteyou-flexible-photo-recrafting-while</link>
      <description><![CDATA[Achieving flexible and high-fidelity identity-preserved image generation remains formidable, particularly with advanced Diffusion Transformers (DiTs) like FLUX.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infiniteyou-flexible-photo-recrafting-while</guid>
    </item>
    <item>
      <title>VGGT: Visual Geometry Grounded Transformer</title>
      <link>https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</link>
      <description><![CDATA[We present VGGT, a feed-forward neural network that directly infers all key 3D attributes of a scene, including camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</guid>
    </item>
    <item>
      <title>ImageNet Classification with Deep Convolutional Neural Networks</title>
      <link>https://paperswithcode.com/paper/imagenet-classification-with-deep</link>
      <description><![CDATA[We trained a large, deep convolutional neural network to classify the 1. 3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imagenet-classification-with-deep</guid>
    </item>
    <item>
      <title>LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds</title>
      <link>https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</link>
      <description><![CDATA[Animatable 3D human reconstruction from a single image is a challenging problem due to the ambiguity in decoupling geometry, appearance, and deformation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</guid>
    </item>
    <item>
      <title>Long-Context Autoregressive Video Modeling with Next-Frame Prediction</title>
      <link>https://paperswithcode.com/paper/long-context-autoregressive-video-modeling-1</link>
      <description><![CDATA[Existing RoPE lacks effective temporal decay for remote context and fails to extrapolate well to long video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/long-context-autoregressive-video-modeling-1</guid>
    </item>
    <item>
      <title>KBLaM: Knowledge Base augmented Language Model</title>
      <link>https://paperswithcode.com/paper/kblam-knowledge-base-augmented-language-model</link>
      <description><![CDATA[In this paper, we propose Knowledge Base augmented Language Model (KBLaM), a new method for augmenting Large Language Models (LLMs) with external knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kblam-knowledge-base-augmented-language-model</guid>
    </item>
    <item>
      <title>Fin-R1: A Large Language Model for Financial Reasoning through Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/fin-r1-a-large-language-model-for-financial</link>
      <description><![CDATA[Reasoning large language models are rapidly evolving across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fin-r1-a-large-language-model-for-financial</guid>
    </item>
    <item>
      <title>UniK3D: Universal Camera Monocular 3D Estimation</title>
      <link>https://paperswithcode.com/paper/unik3d-universal-camera-monocular-3d</link>
      <description><![CDATA[Monocular 3D estimation is crucial for visual perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unik3d-universal-camera-monocular-3d</guid>
    </item>
    <item>
      <title>Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens</title>
      <link>https://paperswithcode.com/paper/2503-01710</link>
      <description><![CDATA[Recent advancements in large language models (LLMs) have driven significant progress in zero-shot text-to-speech (TTS) synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2503-01710</guid>
    </item>
    <item>
      <title>UI-TARS: Pioneering Automated GUI Interaction with Native Agents</title>
      <link>https://paperswithcode.com/paper/ui-tars-pioneering-automated-gui-interaction</link>
      <description><![CDATA[This paper introduces UI-TARS, a native GUI agent model that solely perceives the screenshots as input and performs human-like interactions (e. g., keyboard and mouse operations).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ui-tars-pioneering-automated-gui-interaction</guid>
    </item>
    <item>
      <title>Zep: A Temporal Knowledge Graph Architecture for Agent Memory</title>
      <link>https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</link>
      <description><![CDATA[We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</guid>
    </item>
    <item>
      <title>Cube: A Roblox View of 3D Intelligence</title>
      <link>https://paperswithcode.com/paper/cube-a-roblox-view-of-3d-intelligence</link>
      <description><![CDATA[We show how our tokenization scheme can be used in applications for text-to-shape generation, shape-to-text generation and text-to-scene generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cube-a-roblox-view-of-3d-intelligence</guid>
    </item>
    <item>
      <title>Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-for-reasoning-in-small</link>
      <description><![CDATA[Enhancing the reasoning capabilities of large language models (LLMs) typically relies on massive computational resources and extensive datasets, limiting accessibility for resource-constrained settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-for-reasoning-in-small</guid>
    </item>
    <item>
      <title>Sonata: Self-Supervised Learning of Reliable Point Representations</title>
      <link>https://paperswithcode.com/paper/sonata-self-supervised-learning-of-reliable</link>
      <description><![CDATA[In this paper, we question whether we have a reliable self-supervised point cloud model that can be used for diverse 3D tasks via simple linear probing, even with limited data and minimal computation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sonata-self-supervised-learning-of-reliable</guid>
    </item>
    <item>
      <title>Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models</title>
      <link>https://paperswithcode.com/paper/stop-overthinking-a-survey-on-efficient</link>
      <description><![CDATA[Large Language Models (LLMs) have demonstrated remarkable capabilities in complex tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stop-overthinking-a-survey-on-efficient</guid>
    </item>
    <item>
      <title>Multimodal Chain-of-Thought Reasoning: A Comprehensive Survey</title>
      <link>https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-a</link>
      <description><![CDATA[By extending the advantage of chain-of-thought (CoT) reasoning in human-like step-by-step processes to multimodal contexts, multimodal CoT (MCoT) reasoning has recently garnered significant research attention, especially in the integration with multimodal large language models (MLLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-a</guid>
    </item>
    <item>
      <title>CFG-Zero*: Improved Classifier-Free Guidance for Flow Matching Models</title>
      <link>https://paperswithcode.com/paper/cfg-zero-improved-classifier-free-guidance</link>
      <description><![CDATA[Classifier-Free Guidance (CFG) is a widely adopted technique in diffusion/flow models to improve image fidelity and controllability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cfg-zero-improved-classifier-free-guidance</guid>
    </item>
    <item>
      <title>Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning</title>
      <link>https://paperswithcode.com/paper/cosmos-reason1-from-physical-common-sense-to</link>
      <description><![CDATA[We begin by defining key capabilities for Physical AI reasoning, with a focus on physical common sense and embodied reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cosmos-reason1-from-physical-common-sense-to</guid>
    </item>
    <item>
      <title>PhysTwin: Physics-Informed Reconstruction and Simulation of Deformable Objects from Videos</title>
      <link>https://paperswithcode.com/paper/phystwin-physics-informed-reconstruction-and</link>
      <description><![CDATA[Creating a physical digital twin of a real-world object has immense potential in robotics, content creation, and XR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phystwin-physics-informed-reconstruction-and</guid>
    </item>
    <item>
      <title>beeFormer: Bridging the Gap Between Semantic and Interaction Similarity in Recommender Systems</title>
      <link>https://paperswithcode.com/paper/beeformer-bridging-the-gap-between-semantic</link>
      <description><![CDATA[In this paper, we propose beeFormer, a framework for training sentence Transformer models with interaction data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beeformer-bridging-the-gap-between-semantic</guid>
    </item>
  </channel>
</rss>
