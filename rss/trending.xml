<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 18 Apr 2025 21:09:28 +0000</lastBuildDate>
    <item>
      <title>Less-to-More Generalization: Unlocking More Controllability by In-Context Generation</title>
      <link>https://paperswithcode.com/paper/less-to-more-generalization-unlocking-more</link>
      <description><![CDATA[In this study, we propose a highly-consistent data synthesis pipeline to tackle this challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-to-more-generalization-unlocking-more</guid>
    </item>
    <item>
      <title>REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/repa-e-unlocking-vae-for-end-to-end-tuning</link>
      <description><![CDATA[We show that while diffusion loss is ineffective, end-to-end training can be unlocked through the representation-alignment (REPA) loss -- allowing both VAE and diffusion model to be jointly tuned during the training process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repa-e-unlocking-vae-for-end-to-end-tuning</guid>
    </item>
    <item>
      <title>Liquid: Language Models are Scalable Multi-modal Generators</title>
      <link>https://paperswithcode.com/paper/liquid-language-models-are-scalable-multi</link>
      <description><![CDATA[We present Liquid, an auto-regressive generation paradigm that seamlessly integrates visual comprehension and generation by tokenizing images into discrete codes and learning these code embeddings alongside text tokens within a shared feature space for both vision and language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/liquid-language-models-are-scalable-multi</guid>
    </item>
    <item>
      <title>Kimi-VL Technical Report</title>
      <link>https://paperswithcode.com/paper/kimi-vl-technical-report</link>
      <description><![CDATA[We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE) vision-language model (VLM) that offers advanced multimodal reasoning, long-context understanding, and strong agent capabilities - all while activating only 2. 8B parameters in its language decoder (Kimi-VL-A3B).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kimi-vl-technical-report</guid>
    </item>
    <item>
      <title>Advanced Video Inpainting Using Optical Flow-Guided Efficient Diffusion</title>
      <link>https://paperswithcode.com/paper/advanced-video-inpainting-using-optical-flow</link>
      <description><![CDATA[Specifically, FloED employs a dual-branch architecture, where a flow branch first restores corrupted flow and a multi-scale flow adapter provides motion guidance to the main inpainting branch.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advanced-video-inpainting-using-optical-flow</guid>
    </item>
    <item>
      <title>NdLinear Is All You Need for Representation Learning</title>
      <link>https://paperswithcode.com/paper/ndlinear-is-all-you-need-for-representation</link>
      <description><![CDATA[We propose NdLinear as a drop-in replacement for standard linear layers -- marking an important step toward next-generation neural architectures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ndlinear-is-all-you-need-for-representation</guid>
    </item>
    <item>
      <title>The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search</title>
      <link>https://paperswithcode.com/paper/the-ai-scientist-v2-workshop-level-automated</link>
      <description><![CDATA[AI is increasingly playing a pivotal role in transforming how scientific discoveries are made.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-ai-scientist-v2-workshop-level-automated</guid>
    </item>
    <item>
      <title>OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape Generation</title>
      <link>https://paperswithcode.com/paper/octgpt-octree-based-multiscale-autoregressive</link>
      <description><![CDATA[In this paper, we introduce OctGPT, a novel multiscale autoregressive model for 3D shape generation that dramatically improves the efficiency and performance of prior 3D autoregressive approaches, while rivaling or surpassing state-of-the-art diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/octgpt-octree-based-multiscale-autoregressive</guid>
    </item>
    <item>
      <title>VSLAM-LAB: A Comprehensive Framework for Visual SLAM Methods and Datasets</title>
      <link>https://paperswithcode.com/paper/vslam-lab-a-comprehensive-framework-for</link>
      <description><![CDATA[Visual Simultaneous Localization and Mapping (VSLAM) research faces significant challenges due to fragmented toolchains, complex system configurations, and inconsistent evaluation methodologies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vslam-lab-a-comprehensive-framework-for</guid>
    </item>
    <item>
      <title>Genius: A Generalizable and Purely Unsupervised Self-Training Framework For Advanced Reasoning</title>
      <link>https://paperswithcode.com/paper/genius-a-generalizable-and-purely</link>
      <description><![CDATA[This motivates us to enhance LLM reasoning without the need for external supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/genius-a-generalizable-and-purely</guid>
    </item>
    <item>
      <title>TorchFX: A modern approach to Audio DSP with PyTorch and GPU acceleration</title>
      <link>https://paperswithcode.com/paper/torchfx-a-modern-approach-to-audio-dsp-with</link>
      <description><![CDATA[In response, we introduce TorchFX: a GPU-accelerated Python library for DSP, specifically engineered to facilitate sophisticated audio signal processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchfx-a-modern-approach-to-audio-dsp-with</guid>
    </item>
    <item>
      <title>IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System</title>
      <link>https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</link>
      <description><![CDATA[Recently, large language model (LLM) based text-to-speech (TTS) systems have gradually become the mainstream in the industry due to their high naturalness and powerful zero-shot voice cloning capabilities. Here, we introduce the IndexTTS system, which is mainly based on the XTTS and Tortoise model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</guid>
    </item>
    <item>
      <title>Zep: A Temporal Knowledge Graph Architecture for Agent Memory</title>
      <link>https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</link>
      <description><![CDATA[We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</guid>
    </item>
    <item>
      <title>PixelFlow: Pixel-Space Generative Models with Flow</title>
      <link>https://paperswithcode.com/paper/pixelflow-pixel-space-generative-models-with</link>
      <description><![CDATA[We present PixelFlow, a family of image generation models that operate directly in the raw pixel space, in contrast to the predominant latent-space models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pixelflow-pixel-space-generative-models-with</guid>
    </item>
    <item>
      <title>LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds</title>
      <link>https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</link>
      <description><![CDATA[Animatable 3D human reconstruction from a single image is a challenging problem due to the ambiguity in decoupling geometry, appearance, and deformation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</guid>
    </item>
    <item>
      <title>MonSter: Marry Monodepth to Stereo Unleashes Power</title>
      <link>https://paperswithcode.com/paper/monster-marry-monodepth-to-stereo-unleashes</link>
      <description><![CDATA[The refined monodepth is in turn guides stereo effectively at ill-posed regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monster-marry-monodepth-to-stereo-unleashes</guid>
    </item>
    <item>
      <title>3DGUT: Enabling Distorted Cameras and Secondary Rays in Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/3dgut-enabling-distorted-cameras-and</link>
      <description><![CDATA[3D Gaussian Splatting (3DGS) enables efficient reconstruction and high-fidelity real-time rendering of complex scenes on consumer hardware.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dgut-enabling-distorted-cameras-and</guid>
    </item>
    <item>
      <title>InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity</title>
      <link>https://paperswithcode.com/paper/infiniteyou-flexible-photo-recrafting-while</link>
      <description><![CDATA[Achieving flexible and high-fidelity identity-preserved image generation remains formidable, particularly with advanced Diffusion Transformers (DiTs) like FLUX.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infiniteyou-flexible-photo-recrafting-while</guid>
    </item>
    <item>
      <title>Affordable AI Assistants with Knowledge Graph of Thoughts</title>
      <link>https://paperswithcode.com/paper/affordable-ai-assistants-with-knowledge-graph</link>
      <description><![CDATA[Such structured representation of task-relevant knowledge enables low-cost models to solve complex tasks effectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/affordable-ai-assistants-with-knowledge-graph</guid>
    </item>
    <item>
      <title>VGGT: Visual Geometry Grounded Transformer</title>
      <link>https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</link>
      <description><![CDATA[We present VGGT, a feed-forward neural network that directly infers all key 3D attributes of a scene, including camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</guid>
    </item>
  </channel>
</rss>
