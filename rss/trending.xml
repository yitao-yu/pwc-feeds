<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 06 Jun 2024 21:08:38 +0000</lastBuildDate>
    <item>
      <title>LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images</title>
      <link>https://paperswithcode.com/paper/llava-uhd-an-lmm-perceiving-any-aspect-ratio</link>
      <description><![CDATA[To address the challenges, we present LLaVA-UHD, a large multimodal model that can efficiently perceive images in any aspect ratio and high resolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llava-uhd-an-lmm-perceiving-any-aspect-ratio</guid>
    </item>
    <item>
      <title>AutoCoder: Enhancing Code Large Language Model with \textsc{AIEV-Instruct}</title>
      <link>https://paperswithcode.com/paper/autocoder-enhancing-code-large-language-model</link>
      <description><![CDATA[We introduce AutoCoder, the first Large Language Model to surpass GPT-4 Turbo (April 2024) and GPT-4o in pass@1 on the Human Eval benchmark test ($\mathbf{90. 9\%}$ vs. $\mathbf{90. 2\%}$).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autocoder-enhancing-code-large-language-model</guid>
    </item>
    <item>
      <title>Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments</title>
      <link>https://paperswithcode.com/paper/orbit-a-unified-simulation-framework-for</link>
      <description><![CDATA[We present Orbit, a unified and modular framework for robot learning powered by NVIDIA Isaac Sim.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/orbit-a-unified-simulation-framework-for</guid>
    </item>
    <item>
      <title>$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/textit-s-3-gaussian-self-supervised-street</link>
      <description><![CDATA[Photorealistic 3D reconstruction of street scenes is a critical technique for developing real-world simulators for autonomous driving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textit-s-3-gaussian-self-supervised-street</guid>
    </item>
    <item>
      <title>EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture</title>
      <link>https://paperswithcode.com/paper/easyanimate-a-high-performance-long-video</link>
      <description><![CDATA[The motion module can be adapted to various DiT baseline methods to generate video with different styles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyanimate-a-high-performance-long-video</guid>
    </item>
    <item>
      <title>Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</title>
      <link>https://paperswithcode.com/paper/switch-transformers-scaling-to-trillion</link>
      <description><![CDATA[We design models based off T5-Base and T5-Large to obtain up to 7x increases in pre-training speed with the same computational resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/switch-transformers-scaling-to-trillion</guid>
    </item>
    <item>
      <title>MeshXL: Neural Coordinate Field for Generative 3D Foundation Models</title>
      <link>https://paperswithcode.com/paper/meshxl-neural-coordinate-field-for-generative</link>
      <description><![CDATA[The polygon mesh representation of 3D data exhibits great flexibility, fast rendering speed, and storage efficiency, which is widely preferred in various applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meshxl-neural-coordinate-field-for-generative</guid>
    </item>
    <item>
      <title>DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ</title>
      <link>https://paperswithcode.com/paper/detikzify-synthesizing-graphics-programs-for</link>
      <description><![CDATA[Creating high-quality scientific figures can be time-consuming and challenging, even though sketching ideas on paper is relatively easy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detikzify-synthesizing-graphics-programs-for</guid>
    </item>
    <item>
      <title>MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model</title>
      <link>https://paperswithcode.com/paper/mofa-video-controllable-image-animation-via</link>
      <description><![CDATA[We present MOFA-Video, an advanced controllable image animation method that generates video from the given image using various additional controllable signals (such as human landmarks reference, manual trajectories, and another even provided video) or their combinations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mofa-video-controllable-image-animation-via</guid>
    </item>
    <item>
      <title>The Road Less Scheduled</title>
      <link>https://paperswithcode.com/paper/the-road-less-scheduled</link>
      <description><![CDATA[Existing learning rate schedules that do not require specification of the optimization stopping step T are greatly out-performed by learning rate schedules that depend on T. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-road-less-scheduled</guid>
    </item>
    <item>
      <title>MegActor: Harness the Power of Raw Video for Vivid Portrait Animation</title>
      <link>https://paperswithcode.com/paper/megactor-harness-the-power-of-raw-video-for</link>
      <description><![CDATA[Despite raw driving videos contain richer information on facial expressions than intermediate representations such as landmarks in the field of portrait animation, they are seldom the subject of research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/megactor-harness-the-power-of-raw-video-for</guid>
    </item>
    <item>
      <title>Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head</title>
      <link>https://paperswithcode.com/paper/real-time-transformer-based-open-vocabulary</link>
      <description><![CDATA[End-to-end transformer-based detectors (DETRs) have shown exceptional performance in both closed-set and open-vocabulary object detection (OVD) tasks through the integration of language modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-transformer-based-open-vocabulary</guid>
    </item>
    <item>
      <title>CV-VAE: A Compatible Video VAE for Latent Generative Video Models</title>
      <link>https://paperswithcode.com/paper/cv-vae-a-compatible-video-vae-for-latent</link>
      <description><![CDATA[Moreover, since current diffusion-based approaches are often implemented using pre-trained text-to-image (T2I) models, directly training a video VAE without considering the compatibility with existing T2I models will result in a latent space gap between them, which will take huge computational resources for training to bridge the gap even with the T2I models as initialization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cv-vae-a-compatible-video-vae-for-latent</guid>
    </item>
    <item>
      <title>How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites</title>
      <link>https://paperswithcode.com/paper/how-far-are-we-to-gpt-4v-closing-the-gap-to</link>
      <description><![CDATA[Compared to both open-source and proprietary models, InternVL 1. 5 shows competitive performance, achieving state-of-the-art results in 8 of 18 benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-far-are-we-to-gpt-4v-closing-the-gap-to</guid>
    </item>
    <item>
      <title>ZeroSmooth: Training-free Diffuser Adaptation for High Frame Rate Video Generation</title>
      <link>https://paperswithcode.com/paper/zerosmooth-training-free-diffuser-adaptation</link>
      <description><![CDATA[Previous methods promote the frame rate by either training a video interpolation model in pixel space as a postprocessing stage or training an interpolation model in latent space for a specific base video model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zerosmooth-training-free-diffuser-adaptation</guid>
    </item>
    <item>
      <title>Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras</title>
      <link>https://paperswithcode.com/paper/photo-slam-real-time-simultaneous</link>
      <description><![CDATA[In addition to actively densifying hyper primitives based on geometric features, we further introduce a Gaussian-Pyramid-based training method to progressively learn multi-level features, enhancing photorealistic mapping performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photo-slam-real-time-simultaneous</guid>
    </item>
    <item>
      <title>On the Origin of Llamas: Model Tree Heritage Recovery</title>
      <link>https://paperswithcode.com/paper/on-the-origin-of-llamas-model-tree-heritage</link>
      <description><![CDATA[However, this information is underutilized as the weights are uninterpretable, and publicly available models are disorganized.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-origin-of-llamas-model-tree-heritage</guid>
    </item>
    <item>
      <title>FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models</title>
      <link>https://paperswithcode.com/paper/finrobot-an-open-source-ai-agent-platform-for</link>
      <description><![CDATA[As financial institutions and professionals increasingly incorporate Large Language Models (LLMs) into their workflows, substantial barriers, including proprietary data and specialized knowledge, persist between the finance sector and the AI community.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finrobot-an-open-source-ai-agent-platform-for</guid>
    </item>
    <item>
      <title>YOLOv10: Real-Time End-to-End Object Detection</title>
      <link>https://paperswithcode.com/paper/yolov10-real-time-end-to-end-object-detection</link>
      <description><![CDATA[In this work, we aim to further advance the performance-efficiency boundary of YOLOs from both the post-processing and model architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov10-real-time-end-to-end-object-detection</guid>
    </item>
    <item>
      <title>HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models</title>
      <link>https://paperswithcode.com/paper/hipporag-neurobiologically-inspired-long-term</link>
      <description><![CDATA[In order to thrive in hostile and ever-changing natural environments, mammalian brains evolved to store large amounts of knowledge about the world and continually integrate new information while avoiding catastrophic forgetting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hipporag-neurobiologically-inspired-long-term</guid>
    </item>
  </channel>
</rss>
