<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 13 Aug 2023 09:10:10 +0000</lastBuildDate>
    <item>
      <title>Generative Agents: Interactive Simulacra of Human Behavior</title>
      <link>https://paperswithcode.com/paper/generative-agents-interactive-simulacra-of</link>
      <description><![CDATA[Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-agents-interactive-simulacra-of</guid>
    </item>
    <item>
      <title>Revisiting the Minimalist Approach to Offline Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/revisiting-the-minimalist-approach-to-offline</link>
      <description><![CDATA[In this work, we aim to bridge this gap by conducting a retrospective analysis of recent works in offline RL and propose ReBRAC, a minimalistic algorithm that integrates such design elements built on top of the TD3+BC method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-the-minimalist-approach-to-offline</guid>
    </item>
    <item>
      <title>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</title>
      <link>https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</link>
      <description><![CDATA[Recently, remarkable progress has been made in automated task-solving through the use of multi-agent driven by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</guid>
    </item>
    <item>
      <title>Separate Anything You Describe</title>
      <link>https://paperswithcode.com/paper/separate-anything-you-describe</link>
      <description><![CDATA[In this work, we introduce AudioSep, a foundation model for open-domain audio source separation with natural language queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/separate-anything-you-describe</guid>
    </item>
    <item>
      <title>AgentBench: Evaluating LLMs as Agents</title>
      <link>https://paperswithcode.com/paper/agentbench-evaluating-llms-as-agents</link>
      <description><![CDATA[Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentbench-evaluating-llms-as-agents</guid>
    </item>
    <item>
      <title>ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</title>
      <link>https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</link>
      <description><![CDATA[We first present ToolBench, an instruction-tuning dataset for tool use, which is created automatically using ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</guid>
    </item>
    <item>
      <title>LISA: Reasoning Segmentation via Large Language Model</title>
      <link>https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</link>
      <description><![CDATA[In this work, we propose a new segmentation task -- reasoning segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</guid>
    </item>
    <item>
      <title>PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning</title>
      <link>https://paperswithcode.com/paper/pug-photorealistic-and-semantically</link>
      <description><![CDATA[Synthetic image datasets offer unmatched advantages for designing and evaluating deep neural networks: they make it possible to (i) render as many data samples as needed, (ii) precisely control each scene and yield granular ground truth labels (and captions), (iii) precisely control distribution shifts between training and testing to isolate variables of interest for sound experimentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pug-photorealistic-and-semantically</guid>
    </item>
    <item>
      <title>SynJax: Structured Probability Distributions for JAX</title>
      <link>https://paperswithcode.com/paper/synjax-structured-probability-distributions</link>
      <description><![CDATA[The models that explicitly account for structured objects, such as trees and segmentations, did not benefit equally because they require custom algorithms that are difficult to implement in a vectorized form.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synjax-structured-probability-distributions</guid>
    </item>
    <item>
      <title>Effective Whole-body Pose Estimation with Two-stages Distillation</title>
      <link>https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</link>
      <description><![CDATA[Different from the previous self-knowledge distillation, this stage finetunes the student's head with only 20% training time as a plug-and-play training strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</guid>
    </item>
    <item>
      <title>Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising</title>
      <link>https://paperswithcode.com/paper/lighting-every-darkness-in-two-pairs-a</link>
      <description><![CDATA[Calibration-based methods have dominated RAW image denoising under extremely low-light environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lighting-every-darkness-in-two-pairs-a</guid>
    </item>
    <item>
      <title>Shepherd: A Critic for Language Model Generation</title>
      <link>https://paperswithcode.com/paper/shepherd-a-critic-for-language-model</link>
      <description><![CDATA[As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shepherd-a-critic-for-language-model</guid>
    </item>
    <item>
      <title>Empowering Vision-Language Models to Follow Interleaved Vision-Language Instructions</title>
      <link>https://paperswithcode.com/paper/empowering-vision-language-models-to-follow</link>
      <description><![CDATA[To address this issue, we propose a generic and lightweight controllable knowledge re-injection module, which utilizes the sophisticated reasoning ability of LLMs to control the VPG to conditionally extract instruction-specific visual information and re-inject it into the LLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/empowering-vision-language-models-to-follow</guid>
    </item>
    <item>
      <title>Simple synthetic data reduces sycophancy in large language models</title>
      <link>https://paperswithcode.com/paper/simple-synthetic-data-reduces-sycophancy-in</link>
      <description><![CDATA[Adding these data in a lightweight finetuning step can significantly reduce sycophantic behavior on held-out prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simple-synthetic-data-reduces-sycophancy-in</guid>
    </item>
    <item>
      <title>Fine-Tuning Language Models from Human Preferences</title>
      <link>https://paperswithcode.com/paper/fine-tuning-language-models-from-human</link>
      <description><![CDATA[Most work on reward learning has used simulated environments, but complex information about values is often expressed in natural language, and we believe reward learning for language is a key to making RL practical and safe for real-world tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-language-models-from-human</guid>
    </item>
    <item>
      <title>SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative AI Tool</title>
      <link>https://paperswithcode.com/paper/simplyretrieve-a-private-and-lightweight</link>
      <description><![CDATA[Large Language Model (LLM) based Generative AI systems have seen significant progress in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simplyretrieve-a-private-and-lightweight</guid>
    </item>
    <item>
      <title>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</title>
      <link>https://paperswithcode.com/paper/direct-preference-optimization-your-language</link>
      <description><![CDATA[However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct-preference-optimization-your-language</guid>
    </item>
    <item>
      <title>LightGlue: Local Feature Matching at Light Speed</title>
      <link>https://paperswithcode.com/paper/lightglue-local-feature-matching-at-light</link>
      <description><![CDATA[We introduce LightGlue, a deep neural network that learns to match local features across images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightglue-local-feature-matching-at-light</guid>
    </item>
    <item>
      <title>Dual Aggregation Transformer for Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/dual-aggregation-transformer-for-image-super</link>
      <description><![CDATA[Based on the above idea, we propose a novel Transformer model, Dual Aggregation Transformer (DAT), for image SR. Our DAT aggregates features across spatial and channel dimensions, in the inter-block and intra-block dual manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-aggregation-transformer-for-image-super</guid>
    </item>
    <item>
      <title>PAL: Program-aided Language Models</title>
      <link>https://paperswithcode.com/paper/pal-program-aided-language-models</link>
      <description><![CDATA[Much of this success can be attributed to prompting methods such as "chain-of-thought'', which employ LLMs for both understanding the problem description by decomposing it into steps, as well as solving each step of the problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pal-program-aided-language-models</guid>
    </item>
  </channel>
</rss>
