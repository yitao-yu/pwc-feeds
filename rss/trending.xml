<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 14 Apr 2023 09:12:07 +0000</lastBuildDate>
    <item>
      <title>Consistency Models</title>
      <link>https://paperswithcode.com/paper/consistency-models</link>
      <description><![CDATA[To overcome this limitation, we propose consistency models, a new family of generative models that achieve high sample quality without adversarial training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/consistency-models</guid>
    </item>
    <item>
      <title>Segment Anything</title>
      <link>https://paperswithcode.com/paper/segment-anything</link>
      <description><![CDATA[We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-anything</guid>
    </item>
    <item>
      <title>OpenAGI: When LLM Meets Domain Experts</title>
      <link>https://paperswithcode.com/paper/openagi-when-llm-meets-domain-experts</link>
      <description><![CDATA[Thus, the LLM is responsible for synthesizing various external models for solving complex tasks, while RLTF provides feedback to improve its task-solving ability, enabling a feedback loop for self-improving AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openagi-when-llm-meets-domain-experts</guid>
    </item>
    <item>
      <title>Instruction Tuning with GPT-4</title>
      <link>https://paperswithcode.com/paper/instruction-tuning-with-gpt-4</link>
      <description><![CDATA[Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instruction-tuning-with-gpt-4</guid>
    </item>
    <item>
      <title>Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases</title>
      <link>https://paperswithcode.com/paper/understanding-int4-quantization-for</link>
      <description><![CDATA[Improving the deployment efficiency of transformer-based language models has been challenging given their high computation and memory cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-int4-quantization-for</guid>
    </item>
    <item>
      <title>SegGPT: Segmenting Everything In Context</title>
      <link>https://paperswithcode.com/paper/seggpt-segmenting-everything-in-context</link>
      <description><![CDATA[We unify various segmentation tasks into a generalist in-context learning framework that accommodates different kinds of segmentation data by transforming them into the same format of images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seggpt-segmenting-everything-in-context</guid>
    </item>
    <item>
      <title>SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation</title>
      <link>https://paperswithcode.com/paper/sadtalker-learning-realistic-3d-motion</link>
      <description><![CDATA[We present SadTalker, which generates 3D motion coefficients (head pose, expression) of the 3DMM from audio and implicitly modulates a novel 3D-aware face render for talking head generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sadtalker-learning-realistic-3d-motion</guid>
    </item>
    <item>
      <title>RRHF: Rank Responses to Align Language Models with Human Feedback without tears</title>
      <link>https://paperswithcode.com/paper/rrhf-rank-responses-to-align-language-models</link>
      <description><![CDATA[Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment of large language models with human preferences, significantly enhancing the quality of interactions between humans and these models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rrhf-rank-responses-to-align-language-models</guid>
    </item>
    <item>
      <title>HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace</title>
      <link>https://paperswithcode.com/paper/hugginggpt-solving-ai-tasks-with-chatgpt-and</link>
      <description><![CDATA[Solving complicated AI tasks with different domains and modalities is a key step toward advanced artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hugginggpt-solving-ai-tasks-with-chatgpt-and</guid>
    </item>
    <item>
      <title>Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition</title>
      <link>https://paperswithcode.com/paper/prompt-pre-training-with-twenty-thousand</link>
      <description><![CDATA[This work proposes POMP, a prompt pre-training method for vision-language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-pre-training-with-twenty-thousand</guid>
    </item>
    <item>
      <title>OccFormer: Dual-path Transformer for Vision-based 3D Semantic Occupancy Prediction</title>
      <link>https://paperswithcode.com/paper/occformer-dual-path-transformer-for-vision</link>
      <description><![CDATA[The vision-based perception for autonomous driving has undergone a transformation from the bird-eye-view (BEV) representations to the 3D semantic occupancy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/occformer-dual-path-transformer-for-vision</guid>
    </item>
    <item>
      <title>GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</title>
      <link>https://paperswithcode.com/paper/gptq-accurate-post-training-quantization-for</link>
      <description><![CDATA[In this paper, we address this challenge, and propose GPTQ, a new one-shot weight quantization method based on approximate second-order information, that is both highly-accurate and highly-efficient.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gptq-accurate-post-training-quantization-for</guid>
    </item>
    <item>
      <title>Self-Instruct: Aligning Language Model with Self Generated Instructions</title>
      <link>https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</link>
      <description><![CDATA[Applying our method to vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT_001, which is trained with private user data and human annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</guid>
    </item>
    <item>
      <title>A Survey of Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-of-large-language-models</link>
      <description><![CDATA[To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-large-language-models</guid>
    </item>
    <item>
      <title>Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases</title>
      <link>https://paperswithcode.com/paper/exploring-the-impact-of-instruction-data</link>
      <description><![CDATA[However current research rarely studies the impact of different amounts of instruction data on model performance, especially in the real-world use cases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-impact-of-instruction-data</guid>
    </item>
    <item>
      <title>CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society</title>
      <link>https://paperswithcode.com/paper/camel-communicative-agents-for-mind</link>
      <description><![CDATA[To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camel-communicative-agents-for-mind</guid>
    </item>
    <item>
      <title>Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data</title>
      <link>https://paperswithcode.com/paper/baize-an-open-source-chat-model-with</link>
      <description><![CDATA[The Baize models and data are released for research purposes only at https://github. com/project-baize/baize.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/baize-an-open-source-chat-model-with</guid>
    </item>
    <item>
      <title>LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention</title>
      <link>https://paperswithcode.com/paper/llama-adapter-efficient-fine-tuning-of</link>
      <description><![CDATA[We present LLaMA-Adapter, a lightweight adaption method to efficiently fine-tune LLaMA into an instruction-following model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-adapter-efficient-fine-tuning-of</guid>
    </item>
    <item>
      <title>PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models</title>
      <link>https://paperswithcode.com/paper/pair-diffusion-object-level-image-editing</link>
      <description><![CDATA[Nevertheless, most of them lack fine-grained control over the properties of the different objects present in the image, i. e. object-level image editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pair-diffusion-object-level-image-editing</guid>
    </item>
    <item>
      <title>Training language models to follow instructions with human feedback</title>
      <link>https://paperswithcode.com/paper/training-language-models-to-follow</link>
      <description><![CDATA[In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-language-models-to-follow</guid>
    </item>
  </channel>
</rss>
