<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 20 Apr 2025 21:08:46 +0000</lastBuildDate>
    <item>
      <title>UniAnimate-DiT: Human Image Animation with Large-Scale Video Diffusion Transformer</title>
      <link>https://paperswithcode.com/paper/unianimate-dit-human-image-animation-with</link>
      <description><![CDATA[Furthermore, we adopt a simple concatenation operation to integrate the reference appearance into the model and incorporate the pose information of the reference image for enhanced pose alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unianimate-dit-human-image-animation-with</guid>
    </item>
    <item>
      <title>PRIMA.CPP: Speeding Up 70B-Scale LLM Inference on Low-Resource Everyday Home Clusters</title>
      <link>https://paperswithcode.com/paper/prima-cpp-speeding-up-70b-scale-llm-inference</link>
      <description><![CDATA[Emergency of DeepSeek R1 and QwQ 32B have broken through performance barriers for running frontier large language models (LLMs) on home devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prima-cpp-speeding-up-70b-scale-llm-inference</guid>
    </item>
    <item>
      <title>REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/repa-e-unlocking-vae-for-end-to-end-tuning</link>
      <description><![CDATA[We show that while diffusion loss is ineffective, end-to-end training can be unlocked through the representation-alignment (REPA) loss -- allowing both VAE and diffusion model to be jointly tuned during the training process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repa-e-unlocking-vae-for-end-to-end-tuning</guid>
    </item>
    <item>
      <title>Liquid: Language Models are Scalable Multi-modal Generators</title>
      <link>https://paperswithcode.com/paper/liquid-language-models-are-scalable-multi</link>
      <description><![CDATA[We present Liquid, an auto-regressive generation paradigm that seamlessly integrates visual comprehension and generation by tokenizing images into discrete codes and learning these code embeddings alongside text tokens within a shared feature space for both vision and language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/liquid-language-models-are-scalable-multi</guid>
    </item>
    <item>
      <title>Advanced Video Inpainting Using Optical Flow-Guided Efficient Diffusion</title>
      <link>https://paperswithcode.com/paper/advanced-video-inpainting-using-optical-flow</link>
      <description><![CDATA[Specifically, FloED employs a dual-branch architecture, where a flow branch first restores corrupted flow and a multi-scale flow adapter provides motion guidance to the main inpainting branch.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advanced-video-inpainting-using-optical-flow</guid>
    </item>
    <item>
      <title>Bitnet.cpp: Efficient Edge Inference for Ternary LLMs</title>
      <link>https://paperswithcode.com/paper/bitnet-cpp-efficient-edge-inference-for</link>
      <description><![CDATA[The advent of 1-bit large language models (LLMs), led by BitNet b1. 58, has spurred interest in ternary LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bitnet-cpp-efficient-edge-inference-for</guid>
    </item>
    <item>
      <title>The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search</title>
      <link>https://paperswithcode.com/paper/the-ai-scientist-v2-workshop-level-automated</link>
      <description><![CDATA[AI is increasingly playing a pivotal role in transforming how scientific discoveries are made.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-ai-scientist-v2-workshop-level-automated</guid>
    </item>
    <item>
      <title>UniK3D: Universal Camera Monocular 3D Estimation</title>
      <link>https://paperswithcode.com/paper/unik3d-universal-camera-monocular-3d</link>
      <description><![CDATA[Monocular 3D estimation is crucial for visual perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unik3d-universal-camera-monocular-3d</guid>
    </item>
    <item>
      <title>UI-TARS: Pioneering Automated GUI Interaction with Native Agents</title>
      <link>https://paperswithcode.com/paper/ui-tars-pioneering-automated-gui-interaction</link>
      <description><![CDATA[This paper introduces UI-TARS, a native GUI agent model that solely perceives the screenshots as input and performs human-like interactions (e. g., keyboard and mouse operations).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ui-tars-pioneering-automated-gui-interaction</guid>
    </item>
    <item>
      <title>BIP3D: Bridging 2D Images and 3D Perception for Embodied Intelligence</title>
      <link>https://paperswithcode.com/paper/bip3d-bridging-2d-images-and-3d-perception</link>
      <description><![CDATA[In embodied intelligence systems, a key component is 3D perception algorithm, which enables agents to understand their surrounding environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bip3d-bridging-2d-images-and-3d-perception</guid>
    </item>
    <item>
      <title>NdLinear Is All You Need for Representation Learning</title>
      <link>https://paperswithcode.com/paper/ndlinear-is-all-you-need-for-representation</link>
      <description><![CDATA[We propose NdLinear as a drop-in replacement for standard linear layers -- marking an important step toward next-generation neural architectures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ndlinear-is-all-you-need-for-representation</guid>
    </item>
    <item>
      <title>Less-to-More Generalization: Unlocking More Controllability by In-Context Generation</title>
      <link>https://paperswithcode.com/paper/less-to-more-generalization-unlocking-more</link>
      <description><![CDATA[In this study, we propose a highly-consistent data synthesis pipeline to tackle this challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-to-more-generalization-unlocking-more</guid>
    </item>
    <item>
      <title>LocoMuJoCo: A Comprehensive Imitation Learning Benchmark for Locomotion</title>
      <link>https://paperswithcode.com/paper/locomujoco-a-comprehensive-imitation-learning</link>
      <description><![CDATA[Imitation Learning (IL) holds great promise for enabling agile locomotion in embodied agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/locomujoco-a-comprehensive-imitation-learning</guid>
    </item>
    <item>
      <title>IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System</title>
      <link>https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</link>
      <description><![CDATA[Recently, large language model (LLM) based text-to-speech (TTS) systems have gradually become the mainstream in the industry due to their high naturalness and powerful zero-shot voice cloning capabilities. Here, we introduce the IndexTTS system, which is mainly based on the XTTS and Tortoise model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</guid>
    </item>
    <item>
      <title>Affordable AI Assistants with Knowledge Graph of Thoughts</title>
      <link>https://paperswithcode.com/paper/affordable-ai-assistants-with-knowledge-graph</link>
      <description><![CDATA[Such structured representation of task-relevant knowledge enables low-cost models to solve complex tasks effectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/affordable-ai-assistants-with-knowledge-graph</guid>
    </item>
    <item>
      <title>MonSter: Marry Monodepth to Stereo Unleashes Power</title>
      <link>https://paperswithcode.com/paper/monster-marry-monodepth-to-stereo-unleashes</link>
      <description><![CDATA[The refined monodepth is in turn guides stereo effectively at ill-posed regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monster-marry-monodepth-to-stereo-unleashes</guid>
    </item>
    <item>
      <title>VSLAM-LAB: A Comprehensive Framework for Visual SLAM Methods and Datasets</title>
      <link>https://paperswithcode.com/paper/vslam-lab-a-comprehensive-framework-for</link>
      <description><![CDATA[Visual Simultaneous Localization and Mapping (VSLAM) research faces significant challenges due to fragmented toolchains, complex system configurations, and inconsistent evaluation methodologies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vslam-lab-a-comprehensive-framework-for</guid>
    </item>
    <item>
      <title>OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape Generation</title>
      <link>https://paperswithcode.com/paper/octgpt-octree-based-multiscale-autoregressive</link>
      <description><![CDATA[In this paper, we introduce OctGPT, a novel multiscale autoregressive model for 3D shape generation that dramatically improves the efficiency and performance of prior 3D autoregressive approaches, while rivaling or surpassing state-of-the-art diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/octgpt-octree-based-multiscale-autoregressive</guid>
    </item>
    <item>
      <title>DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning</title>
      <link>https://paperswithcode.com/paper/deepmath-103k-a-large-scale-challenging</link>
      <description><![CDATA[The capacity for complex mathematical reasoning is a key benchmark for artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepmath-103k-a-large-scale-challenging</guid>
    </item>
    <item>
      <title>A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce</title>
      <link>https://paperswithcode.com/paper/a-minimalist-approach-to-llm-reasoning-from</link>
      <description><![CDATA[In this work, we revisit GRPO from a reinforce-like algorithm perspective and analyze its core components.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-minimalist-approach-to-llm-reasoning-from</guid>
    </item>
  </channel>
</rss>
