<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 06 Aug 2024 21:08:07 +0000</lastBuildDate>
    <item>
      <title>MindSearch: Mimicking Human Minds Elicits Deep AI Searcher</title>
      <link>https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</link>
      <description><![CDATA[Inspired by the cognitive process when humans solve these problems, we introduce MindSearch to mimic the human minds in web information seeking and integration, which can be instantiated by a simple yet effective LLM-based multi-agent framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</guid>
    </item>
    <item>
      <title>FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs</title>
      <link>https://paperswithcode.com/paper/funaudiollm-voice-understanding-and</link>
      <description><![CDATA[This report introduces FunAudioLLM, a model family designed to enhance natural voice interactions between humans and large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/funaudiollm-voice-understanding-and</guid>
    </item>
    <item>
      <title>Arbitrary-Scale Video Super-Resolution with Structural and Textural Priors</title>
      <link>https://paperswithcode.com/paper/arbitrary-scale-video-super-resolution-with</link>
      <description><![CDATA[Arbitrary-scale video super-resolution (AVSR) aims to enhance the resolution of video frames, potentially at various scaling factors, which presents several challenges regarding spatial detail reproduction, temporal consistency, and computational complexity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/arbitrary-scale-video-super-resolution-with</guid>
    </item>
    <item>
      <title>LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders</title>
      <link>https://paperswithcode.com/paper/llm2vec-large-language-models-are-secretly</link>
      <description><![CDATA[We outperform encoder-only models by a large margin on word-level tasks and reach a new unsupervised state-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm2vec-large-language-models-are-secretly</guid>
    </item>
    <item>
      <title>Global Structure-from-Motion Revisited</title>
      <link>https://paperswithcode.com/paper/global-structure-from-motion-revisited</link>
      <description><![CDATA[Recovering 3D structure and camera motion from images has been a long-standing focus of computer vision research and is known as Structure-from-Motion (SfM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/global-structure-from-motion-revisited</guid>
    </item>
    <item>
      <title>"Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models</title>
      <link>https://paperswithcode.com/paper/do-anything-now-characterizing-and-evaluating</link>
      <description><![CDATA[We hope that our study can facilitate the research community and LLM vendors in promoting safer and regulated LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-anything-now-characterizing-and-evaluating</guid>
    </item>
    <item>
      <title>SGLang: Efficient Execution of Structured Language Model Programs</title>
      <link>https://paperswithcode.com/paper/efficiently-programming-large-language-models</link>
      <description><![CDATA[SGLang consists of a frontend language and a runtime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiently-programming-large-language-models</guid>
    </item>
    <item>
      <title>CatVTON: Concatenation Is All You Need for Virtual Try-On with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/catvton-concatenation-is-all-you-need-for</link>
      <description><![CDATA[Virtual try-on methods based on diffusion models achieve realistic try-on effects but often replicate the backbone network as a ReferenceNet or use additional image encoders to process condition inputs, leading to high training and inference costs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/catvton-concatenation-is-all-you-need-for</guid>
    </item>
    <item>
      <title>TorchRL: A data-driven decision-making library for PyTorch</title>
      <link>https://paperswithcode.com/paper/torchrl-a-data-driven-decision-making-library</link>
      <description><![CDATA[PyTorch has ascended as a premier machine learning framework, yet it lacks a native and comprehensive library for decision and control tasks suitable for large development teams dealing with complex real-world data and environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchrl-a-data-driven-decision-making-library</guid>
    </item>
    <item>
      <title>OV-DINO: Unified Open-Vocabulary Detection with Language-Aware Selective Fusion</title>
      <link>https://paperswithcode.com/paper/ov-dino-unified-open-vocabulary-detection</link>
      <description><![CDATA[To address these challenges, we propose a novel unified open-vocabulary detection method called OV-DINO, which is pre-trained on diverse large-scale datasets with language-aware selective fusion in a unified framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ov-dino-unified-open-vocabulary-detection</guid>
    </item>
    <item>
      <title>AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls</title>
      <link>https://paperswithcode.com/paper/anytool-self-reflective-hierarchical-agents</link>
      <description><![CDATA[We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anytool-self-reflective-hierarchical-agents</guid>
    </item>
    <item>
      <title>LLMC: Benchmarking Large Language Model Quantization with a Versatile Compression Toolkit</title>
      <link>https://paperswithcode.com/paper/llm-qbench-a-benchmark-towards-the-best</link>
      <description><![CDATA[Recent advancements in large language models (LLMs) are propelling us toward artificial general intelligence with their remarkable emergent abilities and reasoning capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-qbench-a-benchmark-towards-the-best</guid>
    </item>
    <item>
      <title>Autoregressive Image Generation without Vector Quantization</title>
      <link>https://paperswithcode.com/paper/autoregressive-image-generation-without</link>
      <description><![CDATA[In this work, we propose to model the per-token probability distribution using a diffusion procedure, which allows us to apply autoregressive models in a continuous-valued space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoregressive-image-generation-without</guid>
    </item>
    <item>
      <title>LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control</title>
      <link>https://paperswithcode.com/paper/liveportrait-efficient-portrait-animation</link>
      <description><![CDATA[Instead of following mainstream diffusion-based methods, we explore and extend the potential of the implicit-keypoint-based framework, which effectively balances computational efficiency and controllability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/liveportrait-efficient-portrait-animation</guid>
    </item>
    <item>
      <title>XHand: Real-time Expressive Hand Avatar</title>
      <link>https://paperswithcode.com/paper/xhand-real-time-expressive-hand-avatar</link>
      <description><![CDATA[Hand avatars play a pivotal role in a wide array of digital interfaces, enhancing user immersion and facilitating natural interaction within virtual environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xhand-real-time-expressive-hand-avatar</guid>
    </item>
    <item>
      <title>RouteLLM: Learning to Route LLMs with Preference Data</title>
      <link>https://paperswithcode.com/paper/routellm-learning-to-route-llms-with</link>
      <description><![CDATA[Large language models (LLMs) exhibit impressive capabilities across a wide range of tasks, yet the choice of which model to use often involves a trade-off between performance and cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/routellm-learning-to-route-llms-with</guid>
    </item>
    <item>
      <title>AudioLCM: Text-to-Audio Generation with Latent Consistency Models</title>
      <link>https://paperswithcode.com/paper/audiolcm-text-to-audio-generation-with-latent</link>
      <description><![CDATA[To overcome the convergence issue inherent in LDMs with reduced sample iterations, we propose the Guided Latent Consistency Distillation with a multi-step Ordinary Differential Equation (ODE) solver.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audiolcm-text-to-audio-generation-with-latent</guid>
    </item>
    <item>
      <title>RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text</title>
      <link>https://paperswithcode.com/paper/recurrentgpt-interactive-generation-of</link>
      <description><![CDATA[In addition to producing AI-generated content (AIGC), we also demonstrate the possibility of using RecurrentGPT as an interactive fiction that directly interacts with consumers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recurrentgpt-interactive-generation-of</guid>
    </item>
    <item>
      <title>Very Large-Scale Multi-Agent Simulation in AgentScope</title>
      <link>https://paperswithcode.com/paper/very-large-scale-multi-agent-simulation-in</link>
      <description><![CDATA[Recent advances in large language models (LLMs) have opened new avenues for applying multi-agent systems in very large-scale simulations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/very-large-scale-multi-agent-simulation-in</guid>
    </item>
    <item>
      <title>Winning the Lottery Ahead of Time: Efficient Early Network Pruning</title>
      <link>https://paperswithcode.com/paper/winning-the-lottery-ahead-of-time-efficient</link>
      <description><![CDATA[Pruning, the task of sparsifying deep neural networks, received increasing attention recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/winning-the-lottery-ahead-of-time-efficient</guid>
    </item>
  </channel>
</rss>
