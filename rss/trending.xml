<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 22 Jul 2022 21:07:21 +0000</lastBuildDate>
    <item>
      <title>XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model</title>
      <link>https://paperswithcode.com/paper/xmem-long-term-video-object-segmentation-with</link>
      <description><![CDATA[We present XMem, a video object segmentation architecture for long videos with unified feature memory stores inspired by the Atkinson-Shiffrin memory model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xmem-long-term-video-object-segmentation-with</guid>
    </item>
    <item>
      <title>Towards Grand Unification of Object Tracking</title>
      <link>https://paperswithcode.com/paper/towards-grand-unification-of-object-tracking</link>
      <description><![CDATA[We present a unified method, termed Unicorn, that can simultaneously solve four tracking problems (SOT, MOT, VOS, MOTS) with a single network using the same model parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-grand-unification-of-object-tracking</guid>
    </item>
    <item>
      <title>3D Clothed Human Reconstruction in the Wild</title>
      <link>https://paperswithcode.com/paper/3d-clothed-human-reconstruction-in-the-wild</link>
      <description><![CDATA[Although much progress has been made in 3D clothed human reconstruction, most of the existing methods fail to produce robust results from in-the-wild images, which contain diverse human poses and appearances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-clothed-human-reconstruction-in-the-wild</guid>
    </item>
    <item>
      <title>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</title>
      <link>https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</link>
      <description><![CDATA[YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56. 8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</guid>
    </item>
    <item>
      <title>Ivy: Templated Deep Learning for Inter-Framework Portability</title>
      <link>https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</link>
      <description><![CDATA[We introduce Ivy, a templated Deep Learning (DL) framework which abstracts existing DL frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</guid>
    </item>
    <item>
      <title>Improved Vector Quantized Diffusion Models</title>
      <link>https://paperswithcode.com/paper/improved-vector-quantized-diffusion-models</link>
      <description><![CDATA[When trained on ImageNet, we dramatically improve the FID score from 11. 89 to 4. 83, demonstrating the superiority of our proposed techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-vector-quantized-diffusion-models</guid>
    </item>
    <item>
      <title>Tracking Objects as Pixel-wise Distributions</title>
      <link>https://paperswithcode.com/paper/tracking-objects-as-pixel-wise-distributions</link>
      <description><![CDATA[During inference, a pixel-wise association procedure is proposed to recover object connections through frames based on the pixel-wise prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tracking-objects-as-pixel-wise-distributions</guid>
    </item>
    <item>
      <title>Collaborative Neural Rendering using Anime Character Sheets</title>
      <link>https://paperswithcode.com/paper/collaborative-neural-rendering-using-anime</link>
      <description><![CDATA[Drawing images of characters at desired poses is an essential but laborious task in anime production.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/collaborative-neural-rendering-using-anime</guid>
    </item>
    <item>
      <title>CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers</title>
      <link>https://paperswithcode.com/paper/cogvideo-large-scale-pretraining-for-text-to</link>
      <description><![CDATA[Large-scale pretrained transformers have created milestones in text (GPT-3) and text-to-image (DALL-E and CogView) generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cogvideo-large-scale-pretraining-for-text-to</guid>
    </item>
    <item>
      <title>Open High-Resolution Satellite Imagery: The WorldStrat Dataset -- With Application to Super-Resolution</title>
      <link>https://paperswithcode.com/paper/open-high-resolution-satellite-imagery-the</link>
      <description><![CDATA[We hereby hope to foster broad-spectrum applications of ML to satellite imagery, and possibly develop from free public low-resolution Sentinel2 imagery the same power of analysis allowed by costly private high-resolution imagery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-high-resolution-satellite-imagery-the</guid>
    </item>
    <item>
      <title>POET: Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging</title>
      <link>https://paperswithcode.com/paper/poet-training-neural-networks-on-tiny-devices</link>
      <description><![CDATA[We demonstrate that it is possible to fine-tune both ResNet-18 and BERT within the memory constraints of a Cortex-M class embedded device while outperforming current edge training methods in energy efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poet-training-neural-networks-on-tiny-devices</guid>
    </item>
    <item>
      <title>Rethinking IoU-based Optimization for Single-stage 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/rethinking-iou-based-optimization-for-single</link>
      <description><![CDATA[Since Intersection-over-Union (IoU) based optimization maintains the consistency of the final IoU prediction metric and losses, it has been widely used in both regression and classification branches of single-stage 2D object detectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-iou-based-optimization-for-single</guid>
    </item>
    <item>
      <title>Towards Scale-Aware, Robust, and Generalizable Unsupervised Monocular Depth Estimation by Integrating IMU Motion Dynamics</title>
      <link>https://paperswithcode.com/paper/towards-scale-aware-robust-and-generalizable</link>
      <description><![CDATA[Unsupervised monocular depth and ego-motion estimation has drawn extensive research attention in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-scale-aware-robust-and-generalizable</guid>
    </item>
    <item>
      <title>Language Modelling with Pixels</title>
      <link>https://paperswithcode.com/paper/language-modelling-with-pixels</link>
      <description><![CDATA[Language models are defined over a finite set of inputs, which creates a vocabulary bottleneck when we attempt to scale the number of supported languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-modelling-with-pixels</guid>
    </item>
    <item>
      <title>MaxViT: Multi-Axis Vision Transformer</title>
      <link>https://paperswithcode.com/paper/maxvit-multi-axis-vision-transformer</link>
      <description><![CDATA[We also show that our proposed model expresses strong generative modeling capability on ImageNet, demonstrating the superior potential of MaxViT blocks as a universal vision module.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maxvit-multi-axis-vision-transformer</guid>
    </item>
    <item>
      <title>Out-of-Distribution Detection with Deep Nearest Neighbors</title>
      <link>https://paperswithcode.com/paper/out-of-distribution-detection-with-deep</link>
      <description><![CDATA[In this paper, we explore the efficacy of non-parametric nearest-neighbor distance for OOD detection, which has been largely overlooked in the literature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/out-of-distribution-detection-with-deep</guid>
    </item>
    <item>
      <title>Why do tree-based models still outperform deep learning on tabular data?</title>
      <link>https://paperswithcode.com/paper/why-do-tree-based-models-still-outperform</link>
      <description><![CDATA[While deep learning has enabled tremendous progress on text and image datasets, its superiority on tabular data is not clear.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/why-do-tree-based-models-still-outperform</guid>
    </item>
    <item>
      <title>LF-VIO: A Visual-Inertial-Odometry Framework for Large Field-of-View Cameras with Negative Plane</title>
      <link>https://paperswithcode.com/paper/lf-vio-a-visual-inertial-odometry-framework</link>
      <description><![CDATA[To tackle this issue, we propose LF-VIO, a real-time VIO framework for cameras with extremely large FoV.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lf-vio-a-visual-inertial-odometry-framework</guid>
    </item>
    <item>
      <title>Adversarial Pixel Restoration as a Pretext Task for Transferable Perturbations</title>
      <link>https://paperswithcode.com/paper/adversarial-pixel-restoration-as-a-pretext</link>
      <description><![CDATA[Transferable adversarial attacks optimize adversaries from a pretrained surrogate model and known label space to fool the unknown black-box models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-pixel-restoration-as-a-pretext</guid>
    </item>
    <item>
      <title>PoserNet: Refining Relative Camera Poses Exploiting Object Detections</title>
      <link>https://paperswithcode.com/paper/posernet-refining-relative-camera-poses</link>
      <description><![CDATA[The estimation of the camera poses associated with a set of images commonly relies on feature matches between the images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posernet-refining-relative-camera-poses</guid>
    </item>
  </channel>
</rss>
