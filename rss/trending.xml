<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 16 Mar 2025 09:14:53 +0000</lastBuildDate>
    <item>
      <title>YOLOE: Real-Time Seeing Anything</title>
      <link>https://paperswithcode.com/paper/yoloe-real-time-seeing-anything</link>
      <description><![CDATA[Object detection and segmentation are widely employed in computer vision applications, yet conventional models like YOLO series, while efficient and accurate, are limited by predefined categories, hindering adaptability in open scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yoloe-real-time-seeing-anything</guid>
    </item>
    <item>
      <title>Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens</title>
      <link>https://paperswithcode.com/paper/2503-01710</link>
      <description><![CDATA[Recent advancements in large language models (LLMs) have driven significant progress in zero-shot text-to-speech (TTS) synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2503-01710</guid>
    </item>
    <item>
      <title>Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts</title>
      <link>https://paperswithcode.com/paper/comet-fine-grained-computation-communication</link>
      <description><![CDATA[The inter-device communication of a MoE layer can occupy 47% time of the entire model execution with popular models and frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comet-fine-grained-computation-communication</guid>
    </item>
    <item>
      <title>LBM: Latent Bridge Matching for Fast Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/lbm-latent-bridge-matching-for-fast-image-to</link>
      <description><![CDATA[In this paper, we introduce Latent Bridge Matching (LBM), a new, versatile and scalable method that relies on Bridge Matching in a latent space to achieve fast image-to-image translation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lbm-latent-bridge-matching-for-fast-image-to</guid>
    </item>
    <item>
      <title>FoundationStereo: Zero-Shot Stereo Matching</title>
      <link>https://paperswithcode.com/paper/foundationstereo-zero-shot-stereo-matching</link>
      <description><![CDATA[However, achieving strong zero-shot generalization - a hallmark of foundation models in other computer vision tasks - remains challenging for stereo matching.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundationstereo-zero-shot-stereo-matching</guid>
    </item>
    <item>
      <title>VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play Context Control</title>
      <link>https://paperswithcode.com/paper/videopainter-any-length-video-inpainting-and</link>
      <description><![CDATA[Video inpainting, which aims to restore corrupted video content, has experienced substantial progress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videopainter-any-length-video-inpainting-and</guid>
    </item>
    <item>
      <title>Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/vision-r1-incentivizing-reasoning-capability</link>
      <description><![CDATA[However, direct training with RL struggles to activate complex reasoning capabilities such as questioning and reflection in MLLMs, due to the absence of substantial high-quality multimodal reasoning data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-r1-incentivizing-reasoning-capability</guid>
    </item>
    <item>
      <title>Scaling Synthetic Data Creation with 1,000,000,000 Personas</title>
      <link>https://paperswithcode.com/paper/scaling-synthetic-data-creation-with</link>
      <description><![CDATA[We propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-synthetic-data-creation-with</guid>
    </item>
    <item>
      <title>Learning Efficient Online 3D Bin Packing on Packing Configuration Trees</title>
      <link>https://paperswithcode.com/paper/learning-efficient-online-3d-bin-packing-on</link>
      <description><![CDATA[PCT is a full-fledged description of the state and action space of bin packing which can support packing policy learning based on deep reinforcement learning (DRL).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-efficient-online-3d-bin-packing-on</guid>
    </item>
    <item>
      <title>LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL</title>
      <link>https://paperswithcode.com/paper/lmm-r1-empowering-3b-lmms-with-strong</link>
      <description><![CDATA[Enhancing reasoning in Large Multimodal Models (LMMs) faces unique challenges from the complex interplay between visual perception and logical reasoning, particularly in compact 3B-parameter architectures where architectural constraints limit reasoning capacity and modality alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lmm-r1-empowering-3b-lmms-with-strong</guid>
    </item>
    <item>
      <title>Agent S: An Open Agentic Framework that Uses Computers Like a Human</title>
      <link>https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</link>
      <description><![CDATA[We present Agent S, an open agentic framework that enables autonomous interaction with computers through a Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</guid>
    </item>
    <item>
      <title>Visual-RFT: Visual Reinforcement Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/visual-rft-visual-reinforcement-fine-tuning</link>
      <description><![CDATA[Reinforcement Fine-Tuning (RFT) in Large Reasoning Models like OpenAI o1 learns from feedback on its answers, which is especially useful in applications when fine-tuning data is scarce.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-rft-visual-reinforcement-fine-tuning</guid>
    </item>
    <item>
      <title>Executable Code Actions Elicit Better LLM Agents</title>
      <link>https://paperswithcode.com/paper/executable-code-actions-elicit-better-llm</link>
      <description><![CDATA[LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e. g., the scope of pre-defined tools) and restricted flexibility (e. g., inability to compose multiple tools).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/executable-code-actions-elicit-better-llm</guid>
    </item>
    <item>
      <title>GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera Control</title>
      <link>https://paperswithcode.com/paper/gen3c-3d-informed-world-consistent-video</link>
      <description><![CDATA[Our results demonstrate more precise camera control than prior work, as well as state-of-the-art results in sparse-view novel view synthesis, even in challenging settings such as driving scenes and monocular dynamic video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gen3c-3d-informed-world-consistent-video</guid>
    </item>
    <item>
      <title>Seg-Zero: Reasoning-Chain Guided Segmentation via Cognitive Reinforcement</title>
      <link>https://paperswithcode.com/paper/seg-zero-reasoning-chain-guided-segmentation</link>
      <description><![CDATA[Traditional methods for reasoning segmentation rely on supervised fine-tuning with categorical labels and simple descriptions, limiting its out-of-domain generalization and lacking explicit reasoning processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seg-zero-reasoning-chain-guided-segmentation</guid>
    </item>
    <item>
      <title>Interpreting and Improving Diffusion Models from an Optimization Perspective</title>
      <link>https://paperswithcode.com/paper/interpreting-and-improving-diffusion-models</link>
      <description><![CDATA[Denoising is intuitively related to projection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpreting-and-improving-diffusion-models</guid>
    </item>
    <item>
      <title>AlphaDrive: Unleashing the Power of VLMs in Autonomous Driving via Reinforcement Learning and Reasoning</title>
      <link>https://paperswithcode.com/paper/alphadrive-unleashing-the-power-of-vlms-in</link>
      <description><![CDATA[Some studies integrate vision-language models (VLMs) into autonomous driving, but they typically rely on pre-trained models with simple supervised fine-tuning (SFT) on driving data, without further exploration of training strategies or optimizations specifically tailored for planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alphadrive-unleashing-the-power-of-vlms-in</guid>
    </item>
    <item>
      <title>LLM4AD: A Platform for Algorithm Design with Large Language Model</title>
      <link>https://paperswithcode.com/paper/llm4ad-a-platform-for-algorithm-design-with</link>
      <description><![CDATA[We introduce LLM4AD, a unified Python platform for algorithm design (AD) with large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm4ad-a-platform-for-algorithm-design-with</guid>
    </item>
    <item>
      <title>Self-rewarding correction for mathematical reasoning</title>
      <link>https://paperswithcode.com/paper/self-rewarding-correction-for-mathematical</link>
      <description><![CDATA[We study self-rewarding reasoning large language models (LLMs), which can simultaneously generate step-by-step reasoning and evaluate the correctness of their outputs during the inference time-without external feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-rewarding-correction-for-mathematical</guid>
    </item>
    <item>
      <title>Lanpaint: Training-Free Diffusion Inpainting with Exact and Fast Conditional Inference</title>
      <link>https://paperswithcode.com/paper/lanpaint-training-free-diffusion-inpainting</link>
      <description><![CDATA[Diffusion models generate high-quality images but often lack efficient and universally applicable inpainting capabilities, particularly in community-trained models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lanpaint-training-free-diffusion-inpainting</guid>
    </item>
  </channel>
</rss>
