<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 15 Jan 2024 21:07:43 +0000</lastBuildDate>
    <item>
      <title>LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning</title>
      <link>https://paperswithcode.com/paper/llm-maybe-longlm-self-extend-llm-context</link>
      <description><![CDATA[In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-maybe-longlm-self-extend-llm-context</guid>
    </item>
    <item>
      <title>DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models</title>
      <link>https://paperswithcode.com/paper/deepseekmoe-towards-ultimate-expert</link>
      <description><![CDATA[Subsequently, we scale up DeepSeekMoE to 16B parameters and show that it achieves comparable performance with LLaMA2 7B, with only about 40% of computations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseekmoe-towards-ultimate-expert</guid>
    </item>
    <item>
      <title>Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch</title>
      <link>https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</link>
      <description><![CDATA[Based on this observation, we further sparsify delta parameters of multiple SFT homologous models with DARE and subsequently merge them into a single model by parameter averaging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</guid>
    </item>
    <item>
      <title>TrustLLM: Trustworthiness in Large Language Models</title>
      <link>https://paperswithcode.com/paper/trustllm-trustworthiness-in-large-language</link>
      <description><![CDATA[This paper introduces TrustLLM, a comprehensive study of trustworthiness in LLMs, including principles for different dimensions of trustworthiness, established benchmark, evaluation, and analysis of trustworthiness for mainstream LLMs, and discussion of open challenges and future directions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trustllm-trustworthiness-in-large-language</guid>
    </item>
    <item>
      <title>Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively</title>
      <link>https://paperswithcode.com/paper/open-vocabulary-sam-segment-and-recognize</link>
      <description><![CDATA[The CLIP and Segment Anything Model (SAM) are remarkable vision foundation models (VFMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-vocabulary-sam-segment-and-recognize</guid>
    </item>
    <item>
      <title>LEGO:Language Enhanced Multi-modal Grounding Model</title>
      <link>https://paperswithcode.com/paper/lego-language-enhanced-multi-modal-grounding</link>
      <description><![CDATA[Beyond capturing global information like other multi-modal models, our proposed model excels at tasks demanding a detailed understanding of local information within the input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lego-language-enhanced-multi-modal-grounding</guid>
    </item>
    <item>
      <title>Instruction Tuning with Human Curriculum</title>
      <link>https://paperswithcode.com/paper/instruction-tuning-with-human-curriculum</link>
      <description><![CDATA[The dominant paradigm for instruction tuning is the random-shuffled training of maximally diverse instruction-response pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instruction-tuning-with-human-curriculum</guid>
    </item>
    <item>
      <title>WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia</title>
      <link>https://paperswithcode.com/paper/wikichat-a-few-shot-llm-based-chatbot</link>
      <description><![CDATA[WikiChat generates a response from an LLM, retains only the grounded facts, and combines them with additional information it retrieves from the corpus to form factual and engaging responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wikichat-a-few-shot-llm-based-chatbot</guid>
    </item>
    <item>
      <title>LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression</title>
      <link>https://paperswithcode.com/paper/longllmlingua-accelerating-and-enhancing-llms</link>
      <description><![CDATA[Inspired by these findings, we propose LongLLMLingua for prompt compression towards improving LLMs' perception of the key information to simultaneously address the three challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longllmlingua-accelerating-and-enhancing-llms</guid>
    </item>
    <item>
      <title>From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations</title>
      <link>https://paperswithcode.com/paper/from-audio-to-photoreal-embodiment</link>
      <description><![CDATA[We present a framework for generating full-bodied photorealistic avatars that gesture according to the conversational dynamics of a dyadic interaction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-audio-to-photoreal-embodiment</guid>
    </item>
    <item>
      <title>BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis</title>
      <link>https://paperswithcode.com/paper/bakedavatar-baking-neural-fields-for-real</link>
      <description><![CDATA[Synthesizing photorealistic 4D human head avatars from videos is essential for VR/AR, telepresence, and video game applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bakedavatar-baking-neural-fields-for-real</guid>
    </item>
    <item>
      <title>Machine Mindset: An MBTI Exploration of Large Language Models</title>
      <link>https://paperswithcode.com/paper/machine-mindset-an-mbti-exploration-of-large</link>
      <description><![CDATA[We present a novel approach for integrating Myers-Briggs Type Indicator (MBTI) personality traits into large language models (LLMs), addressing the challenges of personality consistency in personalized AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/machine-mindset-an-mbti-exploration-of-large</guid>
    </item>
    <item>
      <title>OpenVoice: Versatile Instant Voice Cloning</title>
      <link>https://paperswithcode.com/paper/openvoice-versatile-instant-voice-cloning</link>
      <description><![CDATA[The voice styles are not directly copied from and constrained by the style of the reference speaker.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openvoice-versatile-instant-voice-cloning</guid>
    </item>
    <item>
      <title>Improving the Stability of Diffusion Models for Content Consistent Super-Resolution</title>
      <link>https://paperswithcode.com/paper/improving-the-stability-of-diffusion-models</link>
      <description><![CDATA[To improve the stability of diffusion prior-based SR, we propose to employ the diffusion models to refine image structures, while employing the generative adversarial training to enhance image fine details.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-the-stability-of-diffusion-models</guid>
    </item>
    <item>
      <title>Fast Inference of Mixture-of-Experts Language Models with Offloading</title>
      <link>https://paperswithcode.com/paper/fast-inference-of-mixture-of-experts-language</link>
      <description><![CDATA[In this work, we study the problem of running large MoE language models on consumer hardware with limited accelerator memory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-inference-of-mixture-of-experts-language</guid>
    </item>
    <item>
      <title>DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines</title>
      <link>https://paperswithcode.com/paper/dspy-assertions-computational-constraints-for</link>
      <description><![CDATA[Our reference implementation of LM Assertions is integrated into DSPy at https://github. com/stanfordnlp/dspy]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dspy-assertions-computational-constraints-for</guid>
    </item>
    <item>
      <title>AnyText: Multilingual Visual Text Generation And Editing</title>
      <link>https://paperswithcode.com/paper/anytext-multilingual-visual-text-generation</link>
      <description><![CDATA[Based on AnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual text generation accuracy and quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anytext-multilingual-visual-text-generation</guid>
    </item>
    <item>
      <title>GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation</title>
      <link>https://paperswithcode.com/paper/gpt-4v-ision-is-a-human-aligned-evaluator-for</link>
      <description><![CDATA[These metrics lack the flexibility to generalize to different evaluation criteria and might not align well with human preferences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-4v-ision-is-a-human-aligned-evaluator-for</guid>
    </item>
    <item>
      <title>ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/chef-a-comprehensive-evaluation-framework-for</link>
      <description><![CDATA[We will publicly release all the detailed implementations for further analysis, as well as an easy-to-use modular toolkit for the integration of new recipes and models, so that ChEF can be a growing evaluation framework for the MLLM community.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chef-a-comprehensive-evaluation-framework-for</guid>
    </item>
    <item>
      <title>Mistral 7B</title>
      <link>https://paperswithcode.com/paper/mistral-7b</link>
      <description><![CDATA[We introduce Mistral 7B v0. 1, a 7-billion-parameter language model engineered for superior performance and efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mistral-7b</guid>
    </item>
  </channel>
</rss>
