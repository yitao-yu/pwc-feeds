<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 08 Dec 2023 09:12:24 +0000</lastBuildDate>
    <item>
      <title>Mamba: Linear-Time Sequence Modeling with Selective State Spaces</title>
      <link>https://paperswithcode.com/paper/mamba-linear-time-sequence-modeling-with</link>
      <description><![CDATA[Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mamba-linear-time-sequence-modeling-with</guid>
    </item>
    <item>
      <title>Magicoder: Source Code Is All You Need</title>
      <link>https://paperswithcode.com/paper/magicoder-source-code-is-all-you-need</link>
      <description><![CDATA[Magicoder models are trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets to generate high-quality instruction data for code.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magicoder-source-code-is-all-you-need</guid>
    </item>
    <item>
      <title>TaskWeaver: A Code-First Agent Framework</title>
      <link>https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</link>
      <description><![CDATA[TaskWeaver provides support for rich data structures, flexible plugin usage, and dynamic plugin selection, and leverages LLM coding capabilities for complex logic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</guid>
    </item>
    <item>
      <title>Sequential Modeling Enables Scalable Learning for Large Vision Models</title>
      <link>https://paperswithcode.com/paper/sequential-modeling-enables-scalable-learning</link>
      <description><![CDATA[We introduce a novel sequential modeling approach which enables learning a Large Vision Model (LVM) without making use of any linguistic data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sequential-modeling-enables-scalable-learning</guid>
    </item>
    <item>
      <title>HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis</title>
      <link>https://paperswithcode.com/paper/hierspeech-bridging-the-gap-between-semantic</link>
      <description><![CDATA[Furthermore, we significantly improve the naturalness and speaker similarity of synthetic speech even in zero-shot speech synthesis scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierspeech-bridging-the-gap-between-semantic</guid>
    </item>
    <item>
      <title>DeepCache: Accelerating Diffusion Models for Free</title>
      <link>https://paperswithcode.com/paper/deepcache-accelerating-diffusion-models-for</link>
      <description><![CDATA[Diffusion models have recently gained unprecedented attention in the field of image synthesis due to their remarkable generative capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepcache-accelerating-diffusion-models-for</guid>
    </item>
    <item>
      <title>DiffiT: Diffusion Vision Transformers for Image Generation</title>
      <link>https://paperswithcode.com/paper/diffit-diffusion-vision-transformers-for</link>
      <description><![CDATA[We also introduce latent DiffiT which consists of transformer model with the proposed self-attention layers, for high-resolution image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffit-diffusion-vision-transformers-for</guid>
    </item>
    <item>
      <title>Improving Sample Quality of Diffusion Models Using Self-Attention Guidance</title>
      <link>https://paperswithcode.com/paper/improving-sample-quality-of-diffusion-model</link>
      <description><![CDATA[Denoising diffusion models (DDMs) have attracted attention for their exceptional generation quality and diversity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-sample-quality-of-diffusion-model</guid>
    </item>
    <item>
      <title>SeamlessM4T: Massively Multilingual &amp; Multimodal Machine Translation</title>
      <link>https://paperswithcode.com/paper/seamlessm4t-massively-multilingual-multimodal</link>
      <description><![CDATA[What does it take to create the Babel Fish, a tool that can help individuals translate speech between any two languages?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seamlessm4t-massively-multilingual-multimodal</guid>
    </item>
    <item>
      <title>Gaussian Grouping: Segment and Edit Anything in 3D Scenes</title>
      <link>https://paperswithcode.com/paper/gaussian-grouping-segment-and-edit-anything</link>
      <description><![CDATA[To address this issue, we propose Gaussian Grouping, which extends Gaussian Splatting to jointly reconstruct and segment anything in open-world 3D scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaussian-grouping-segment-and-edit-anything</guid>
    </item>
    <item>
      <title>GeoDream: Disentangling 2D and Geometric Priors for High-Fidelity and Consistent 3D Generation</title>
      <link>https://paperswithcode.com/paper/geodream-disentangling-2d-and-geometric</link>
      <description><![CDATA[We justify that the refined 3D geometric priors aid in the 3D-aware capability of 2D diffusion priors, which in turn provides superior guidance for the refinement of 3D geometric priors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geodream-disentangling-2d-and-geometric</guid>
    </item>
    <item>
      <title>MEDITRON-70B: Scaling Medical Pretraining for Large Language Models</title>
      <link>https://paperswithcode.com/paper/meditron-70b-scaling-medical-pretraining-for</link>
      <description><![CDATA[Large language models (LLMs) can potentially democratize access to medical knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meditron-70b-scaling-medical-pretraining-for</guid>
    </item>
    <item>
      <title>RETVec: Resilient and Efficient Text Vectorizer</title>
      <link>https://paperswithcode.com/paper/retvec-resilient-and-efficient-text</link>
      <description><![CDATA[The RETVec embedding model is pre-trained using pair-wise metric learning to be robust against typos and character-level adversarial attacks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retvec-resilient-and-efficient-text</guid>
    </item>
    <item>
      <title>MotionDirector: Motion Customization of Text-to-Video Diffusion Models</title>
      <link>https://paperswithcode.com/paper/motiondirector-motion-customization-of-text</link>
      <description><![CDATA[Given a set of video clips of the same motion concept, the task of Motion Customization is to adapt existing text-to-video diffusion models to generate videos with this motion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motiondirector-motion-customization-of-text</guid>
    </item>
    <item>
      <title>GauHuman: Articulated Gaussian Splatting from Monocular Human Videos</title>
      <link>https://paperswithcode.com/paper/gauhuman-articulated-gaussian-splatting-from</link>
      <description><![CDATA[We present, GauHuman, a 3D human model with Gaussian Splatting for both fast training (1 ~ 2 minutes) and real-time rendering (up to 189 FPS), compared with existing NeRF-based implicit representation modelling frameworks demanding hours of training and seconds of rendering per frame.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gauhuman-articulated-gaussian-splatting-from</guid>
    </item>
    <item>
      <title>NEFTune: Noisy Embeddings Improve Instruction Finetuning</title>
      <link>https://paperswithcode.com/paper/neftune-noisy-embeddings-improve-instruction</link>
      <description><![CDATA[We show that language model finetuning can be improved, sometimes dramatically, with a simple augmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neftune-noisy-embeddings-improve-instruction</guid>
    </item>
    <item>
      <title>DemoFusion: Democratising High-Resolution Image Generation With No $$$</title>
      <link>https://paperswithcode.com/paper/demofusion-democratising-high-resolution</link>
      <description><![CDATA[High-resolution image generation with Generative Artificial Intelligence (GenAI) has immense potential but, due to the enormous capital investment required for training, it is increasingly centralised to a few large corporations, and hidden behind paywalls.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demofusion-democratising-high-resolution</guid>
    </item>
    <item>
      <title>LLaVA-Grounding: Grounded Visual Chat with Large Multimodal Models</title>
      <link>https://paperswithcode.com/paper/llava-grounding-grounded-visual-chat-with</link>
      <description><![CDATA[To address this issue, we have created GVC data that allows for the combination of grounding and chat capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llava-grounding-grounded-visual-chat-with</guid>
    </item>
    <item>
      <title>WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera Driving Scene Generation</title>
      <link>https://paperswithcode.com/paper/wovogen-world-volume-aware-diffusion-for</link>
      <description><![CDATA[Generating multi-camera street-view videos is critical for augmenting autonomous driving datasets, addressing the urgent demand for extensive and varied data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wovogen-world-volume-aware-diffusion-for</guid>
    </item>
    <item>
      <title>Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models</title>
      <link>https://paperswithcode.com/paper/monkey-image-resolution-and-text-label-are</link>
      <description><![CDATA[Additionally, experiments on 18 datasets further demonstrate that Monkey surpasses existing LMMs in many tasks like Image Captioning and various Visual Question Answering formats.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monkey-image-resolution-and-text-label-are</guid>
    </item>
  </channel>
</rss>
