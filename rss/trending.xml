<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 18 Aug 2023 09:11:11 +0000</lastBuildDate>
    <item>
      <title>FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization</title>
      <link>https://paperswithcode.com/paper/fastvit-a-fast-hybrid-vision-transformer</link>
      <description><![CDATA[To this end, we introduce a novel token mixing operator, RepMixer, a building block of FastViT, that uses structural reparameterization to lower the memory access cost by removing skip-connections in the network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fastvit-a-fast-hybrid-vision-transformer</guid>
    </item>
    <item>
      <title>Efficient Guided Generation for Large Language Models</title>
      <link>https://paperswithcode.com/paper/efficient-guided-generation-for-llms</link>
      <description><![CDATA[In this article we show how the problem of neural text generation can be constructively reformulated in terms of transitions between the states of a finite-state machine.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-guided-generation-for-llms</guid>
    </item>
    <item>
      <title>Neuralangelo: High-Fidelity Neural Surface Reconstruction</title>
      <link>https://paperswithcode.com/paper/neuralangelo-high-fidelity-neural-surface-1</link>
      <description><![CDATA[Neural surface reconstruction has been shown to be powerful for recovering dense 3D surfaces via image-based neural rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuralangelo-high-fidelity-neural-surface-1</guid>
    </item>
    <item>
      <title>CoDeF: Content Deformation Fields for Temporally Consistent Video Processing</title>
      <link>https://paperswithcode.com/paper/codef-content-deformation-fields-for</link>
      <description><![CDATA[We present the content deformation field CoDeF as a new type of video representation, which consists of a canonical content field aggregating the static contents in the entire video and a temporal deformation field recording the transformations from the canonical image (i. e., rendered from the canonical content field) to each individual frame along the time axis. Given a target video, these two fields are jointly optimized to reconstruct it through a carefully tailored rendering pipeline. We advisedly introduce some regularizations into the optimization process, urging the canonical content field to inherit semantics (e. g., the object shape) from the video. With such a design, CoDeF naturally supports lifting image algorithms for video processing, in the sense that one can apply an image algorithm to the canonical image and effortlessly propagate the outcomes to the entire video with the aid of the temporal deformation field. We experimentally show that CoDeF is able to lift image-to-image translation to video-to-video translation and lift keypoint detection to keypoint tracking without any training. More importantly, thanks to our lifting strategy that deploys the algorithms on only one image, we achieve superior cross-frame consistency in processed videos compared to existing video-to-video translation approaches, and even manage to track non-rigid objects like water and smog. Project page can be found at https://qiuyu96. github. io/CoDeF/.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codef-content-deformation-fields-for</guid>
    </item>
    <item>
      <title>Generative Agents: Interactive Simulacra of Human Behavior</title>
      <link>https://paperswithcode.com/paper/generative-agents-interactive-simulacra-of</link>
      <description><![CDATA[Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-agents-interactive-simulacra-of</guid>
    </item>
    <item>
      <title>Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction</title>
      <link>https://paperswithcode.com/paper/trafilatura-a-web-scraping-library-and</link>
      <description><![CDATA[The tool performs significantly better than other open-source solutions in this evaluation and in external benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trafilatura-a-web-scraping-library-and</guid>
    </item>
    <item>
      <title>Platypus: Quick, Cheap, and Powerful Refinement of LLMs</title>
      <link>https://paperswithcode.com/paper/platypus-quick-cheap-and-powerful-refinement</link>
      <description><![CDATA[We present $\textbf{Platypus}$, a family of fine-tuned and merged Large Language Models (LLMs) that achieves the strongest performance and currently stands at first place in HuggingFace's Open LLM Leaderboard as of the release date of this work.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/platypus-quick-cheap-and-powerful-refinement</guid>
    </item>
    <item>
      <title>OctoPack: Instruction Tuning Code Large Language Models</title>
      <link>https://paperswithcode.com/paper/octopack-instruction-tuning-code-large</link>
      <description><![CDATA[We benchmark CommitPack against other natural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B parameter StarCoder model, and achieve state-of-the-art performance among models not trained on OpenAI outputs, on the HumanEval Python benchmark (46. 2% pass@1).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/octopack-instruction-tuning-code-large</guid>
    </item>
    <item>
      <title>GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher</title>
      <link>https://paperswithcode.com/paper/gpt-4-is-too-smart-to-be-safe-stealthy-chat</link>
      <description><![CDATA[We propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages -- ciphers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-4-is-too-smart-to-be-safe-stealthy-chat</guid>
    </item>
    <item>
      <title>CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X</title>
      <link>https://paperswithcode.com/paper/codegeex-a-pre-trained-model-for-code</link>
      <description><![CDATA[Large pre-trained code generation models, such as OpenAI Codex, can generate syntax- and function-correct code, making the coding of programmers more productive and our pursuit of artificial general intelligence closer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codegeex-a-pre-trained-model-for-code</guid>
    </item>
    <item>
      <title>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</title>
      <link>https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</link>
      <description><![CDATA[Recently, remarkable progress has been made in automated task-solving through the use of multi-agent driven by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</guid>
    </item>
    <item>
      <title>3D Gaussian Splatting for Real-Time Radiance Field Rendering</title>
      <link>https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</link>
      <description><![CDATA[Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</guid>
    </item>
    <item>
      <title>UniTR: A Unified and Efficient Multi-Modal Transformer for Bird's-Eye-View Representation</title>
      <link>https://paperswithcode.com/paper/unitr-a-unified-and-efficient-multi-modal</link>
      <description><![CDATA[Jointly processing information from multiple sensors is crucial to achieving accurate and robust perception for reliable autonomous driving systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unitr-a-unified-and-efficient-multi-modal</guid>
    </item>
    <item>
      <title>Color-NeuS: Reconstructing Neural Implicit Surfaces with Color</title>
      <link>https://paperswithcode.com/paper/color-neus-reconstructing-neural-implicit</link>
      <description><![CDATA[Mesh is extracted from the signed distance function (SDF) network for the surface, and color for each surface vertex is drawn from the global color network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/color-neus-reconstructing-neural-implicit</guid>
    </item>
    <item>
      <title>DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models</title>
      <link>https://paperswithcode.com/paper/datasetdm-synthesizing-data-with-perception</link>
      <description><![CDATA[To showcase the power of the proposed approach, we generate datasets with rich dense pixel-wise labels for a wide range of downstream tasks, including semantic segmentation, instance segmentation, and depth estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datasetdm-synthesizing-data-with-perception</guid>
    </item>
    <item>
      <title>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</title>
      <link>https://paperswithcode.com/paper/direct-preference-optimization-your-language</link>
      <description><![CDATA[However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct-preference-optimization-your-language</guid>
    </item>
    <item>
      <title>ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</title>
      <link>https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</link>
      <description><![CDATA[We first present ToolBench, an instruction-tuning dataset for tool use, which is created automatically using ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</guid>
    </item>
    <item>
      <title>BundleSDF: Neural 6-DoF Tracking and 3D Reconstruction of Unknown Objects</title>
      <link>https://paperswithcode.com/paper/bundlesdf-neural-6-dof-tracking-and-3d</link>
      <description><![CDATA[We present a near real-time method for 6-DoF tracking of an unknown object from a monocular RGBD video sequence, while simultaneously performing neural 3D reconstruction of the object.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bundlesdf-neural-6-dof-tracking-and-3d</guid>
    </item>
    <item>
      <title>Inst-Inpaint: Instructing to Remove Objects with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/inst-inpaint-instructing-to-remove-objects</link>
      <description><![CDATA[From the application point of view, a user needs to generate the masks for the objects they would like to remove which can be time-consuming and prone to errors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inst-inpaint-instructing-to-remove-objects</guid>
    </item>
    <item>
      <title>AgentBench: Evaluating LLMs as Agents</title>
      <link>https://paperswithcode.com/paper/agentbench-evaluating-llms-as-agents</link>
      <description><![CDATA[Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentbench-evaluating-llms-as-agents</guid>
    </item>
  </channel>
</rss>
