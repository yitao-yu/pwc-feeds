<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 30 Oct 2022 09:15:51 +0000</lastBuildDate>
    <item>
      <title>High Fidelity Neural Audio Compression</title>
      <link>https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</link>
      <description><![CDATA[We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</guid>
    </item>
    <item>
      <title>DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models</title>
      <link>https://paperswithcode.com/paper/diffusiondb-a-large-scale-prompt-gallery</link>
      <description><![CDATA[We analyze prompts in the dataset and discuss key properties of these prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondb-a-large-scale-prompt-gallery</guid>
    </item>
    <item>
      <title>MetaFormer Baselines for Vision</title>
      <link>https://paperswithcode.com/paper/metaformer-baselines-for-vision</link>
      <description><![CDATA[By simply applying depthwise separable convolutions as token mixer in the bottom stages and vanilla self-attention in the top stages, the resulting model CAFormer sets a new record on ImageNet-1K: it achieves an accuracy of 85. 5% at 224x224 resolution, under normal supervised training without external data or distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metaformer-baselines-for-vision</guid>
    </item>
    <item>
      <title>Towards High-Quality Neural TTS for Low-Resource Languages by Learning Compact Speech Representations</title>
      <link>https://paperswithcode.com/paper/towards-high-quality-neural-tts-for-low</link>
      <description><![CDATA[Moreover, we optimize the training strategy by leveraging more audio to learn MSMCRs better for low-resource languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-high-quality-neural-tts-for-low</guid>
    </item>
    <item>
      <title>On the Versatile Uses of Partial Distance Correlation in Deep Learning</title>
      <link>https://paperswithcode.com/paper/on-the-versatile-uses-of-partial-distance</link>
      <description><![CDATA[Comparing the functional behavior of neural network models, whether it is a single network over time or two (or more networks) during or post-training, is an essential step in understanding what they are learning (and what they are not), and for identifying strategies for regularization or efficiency improvements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-versatile-uses-of-partial-distance</guid>
    </item>
    <item>
      <title>TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second</title>
      <link>https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</link>
      <description><![CDATA[We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</guid>
    </item>
    <item>
      <title>Poisson Flow Generative Models</title>
      <link>https://paperswithcode.com/paper/poisson-flow-generative-models</link>
      <description><![CDATA[We interpret the data points as electrical charges on the $z=0$ hyperplane in a space augmented with an additional dimension $z$, generating a high-dimensional electric field (the gradient of the solution to Poisson equation).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poisson-flow-generative-models</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>Structure-based Drug Design with Equivariant Diffusion Models</title>
      <link>https://paperswithcode.com/paper/structure-based-drug-design-with-equivariant</link>
      <description><![CDATA[In this paper, we formulate SBDD as a 3D-conditional generation problem and present DiffSBDD, an E(3)-equivariant 3D-conditional diffusion model that generates novel ligands conditioned on protein pockets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structure-based-drug-design-with-equivariant</guid>
    </item>
    <item>
      <title>S3E: A Large-scale Multimodal Dataset for Collaborative SLAM</title>
      <link>https://paperswithcode.com/paper/s3e-a-large-scale-multimodal-dataset-for</link>
      <description><![CDATA[With the advanced request to employ a team of robots to perform a task collaboratively, the research community has become increasingly interested in collaborative simultaneous localization and mapping.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s3e-a-large-scale-multimodal-dataset-for</guid>
    </item>
    <item>
      <title>FEAR: Fast, Efficient, Accurate and Robust Visual Tracker</title>
      <link>https://paperswithcode.com/paper/fear-fast-efficient-accurate-and-robust</link>
      <description><![CDATA[In addition, we expand the definition of the model efficiency by introducing FEAR benchmark that assesses energy consumption and execution speed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fear-fast-efficient-accurate-and-robust</guid>
    </item>
    <item>
      <title>Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera</title>
      <link>https://paperswithcode.com/paper/neural-surface-reconstruction-of-dynamic</link>
      <description><![CDATA[We propose Neural-DynamicReconstruction (NDR), a template-free method to recover high-fidelity geometry and motions of a dynamic scene from a monocular RGB-D camera.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-surface-reconstruction-of-dynamic</guid>
    </item>
    <item>
      <title>Musika! Fast Infinite Waveform Music Generation</title>
      <link>https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</link>
      <description><![CDATA[We release the source code and pretrained autoencoder weights at github. com/marcoppasini/musika, such that a GAN can be trained on a new music domain with a single GPU in a matter of hours.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</guid>
    </item>
    <item>
      <title>Referring Image Matting</title>
      <link>https://paperswithcode.com/paper/referring-image-matting</link>
      <description><![CDATA[Image matting refers to extracting the accurate foregrounds in the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/referring-image-matting</guid>
    </item>
    <item>
      <title>CORL: Research-oriented Deep Offline Reinforcement Learning Library</title>
      <link>https://paperswithcode.com/paper/corl-research-oriented-deep-offline</link>
      <description><![CDATA[CORL is an open-source library that provides single-file implementations of Deep Offline Reinforcement Learning algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/corl-research-oriented-deep-offline</guid>
    </item>
    <item>
      <title>PDEBENCH: An Extensive Benchmark for Scientific Machine Learning</title>
      <link>https://paperswithcode.com/paper/pdebench-an-extensive-benchmark-for</link>
      <description><![CDATA[With those metrics we identify tasks which are challenging for recent ML methods and propose these tasks as future challenges for the community.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pdebench-an-extensive-benchmark-for</guid>
    </item>
    <item>
      <title>High-Resolution Image Synthesis with Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</link>
      <description><![CDATA[By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</guid>
    </item>
    <item>
      <title>Amos: An Adam-style Optimizer with Adaptive Weight Decay towards Model-Oriented Scale</title>
      <link>https://paperswithcode.com/paper/amos-an-adam-style-optimizer-with-adaptive</link>
      <description><![CDATA[We present Amos, a stochastic gradient-based optimizer designed for training deep neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/amos-an-adam-style-optimizer-with-adaptive</guid>
    </item>
    <item>
      <title>ViTAEv2: Vision Transformer Advanced by Exploring Inductive Bias for Image Recognition and Beyond</title>
      <link>https://paperswithcode.com/paper/vitaev2-vision-transformer-advanced-by</link>
      <description><![CDATA[Vision transformers have shown great potential in various computer vision tasks owing to their strong capability to model long-range dependency using the self-attention mechanism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vitaev2-vision-transformer-advanced-by</guid>
    </item>
    <item>
      <title>VSA: Learning Varied-Size Window Attention in Vision Transformers</title>
      <link>https://paperswithcode.com/paper/vsa-learning-varied-size-window-attention-in</link>
      <description><![CDATA[Attention within windows has been widely explored in vision transformers to balance the performance, computation complexity, and memory footprint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vsa-learning-varied-size-window-attention-in</guid>
    </item>
  </channel>
</rss>
