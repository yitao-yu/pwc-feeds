<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 31 Jul 2023 09:12:52 +0000</lastBuildDate>
    <item>
      <title>Universal and Transferable Adversarial Attacks on Aligned Language Models</title>
      <link>https://paperswithcode.com/paper/universal-and-transferable-adversarial</link>
      <description><![CDATA[Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-and-transferable-adversarial</guid>
    </item>
    <item>
      <title>SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</link>
      <description><![CDATA[We present SDXL, a latent diffusion model for text-to-image synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</guid>
    </item>
    <item>
      <title>Tracking Anything in High Quality</title>
      <link>https://paperswithcode.com/paper/tracking-anything-in-high-quality</link>
      <description><![CDATA[To further improve the quality of tracking masks, a pretrained MR model is employed to refine the tracking results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tracking-anything-in-high-quality</guid>
    </item>
    <item>
      <title>FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios</title>
      <link>https://paperswithcode.com/paper/factool-factuality-detection-in-generative-ai</link>
      <description><![CDATA[With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e. g., ChatGPT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/factool-factuality-detection-in-generative-ai</guid>
    </item>
    <item>
      <title>WavJourney: Compositional Audio Creation with Large Language Models</title>
      <link>https://paperswithcode.com/paper/wavjourney-compositional-audio-creation-with</link>
      <description><![CDATA[We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wavjourney-compositional-audio-creation-with</guid>
    </item>
    <item>
      <title>Meta-Transformer: A Unified Framework for Multimodal Learning</title>
      <link>https://paperswithcode.com/paper/meta-transformer-a-unified-framework-for</link>
      <description><![CDATA[Multimodal learning aims to build models that can process and relate information from multiple modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-transformer-a-unified-framework-for</guid>
    </item>
    <item>
      <title>Foundational Models Defining a New Era in Vision: A Survey and Outlook</title>
      <link>https://paperswithcode.com/paper/foundational-models-defining-a-new-era-in</link>
      <description><![CDATA[Vision systems to see and reason about the compositional nature of visual scenes are fundamental to understanding our world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundational-models-defining-a-new-era-in</guid>
    </item>
    <item>
      <title>LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition</title>
      <link>https://paperswithcode.com/paper/lorahub-efficient-cross-task-generalization</link>
      <description><![CDATA[Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lorahub-efficient-cross-task-generalization</guid>
    </item>
    <item>
      <title>Aligning Large Language Models with Human: A Survey</title>
      <link>https://paperswithcode.com/paper/aligning-large-language-models-with-human-a</link>
      <description><![CDATA[(2) Training methodologies: a detailed review of the prevailing training methods employed for LLM alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-large-language-models-with-human-a</guid>
    </item>
    <item>
      <title>Gorilla: Large Language Model Connected with Massive APIs</title>
      <link>https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</link>
      <description><![CDATA[Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</guid>
    </item>
    <item>
      <title>Large Multimodal Models: Notes on CVPR 2023 Tutorial</title>
      <link>https://paperswithcode.com/paper/large-multimodal-models-notes-on-cvpr-2023</link>
      <description><![CDATA[This tutorial note summarizes the presentation on ``Large Multimodal Models: Towards Building and Surpassing Multimodal GPT-4'', a part of CVPR 2023 tutorial on ``Recent Advances in Vision Foundation Models''.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-multimodal-models-notes-on-cvpr-2023</guid>
    </item>
    <item>
      <title>CoTracker: It is Better to Track Together</title>
      <link>https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</link>
      <description><![CDATA[In this paper, we thus propose CoTracker, an architecture that jointly tracks multiple points throughout an entire video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</guid>
    </item>
    <item>
      <title>NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/nerf-det-learning-geometry-aware-volumetric</link>
      <description><![CDATA[We present NeRF-Det, a novel method for indoor 3D detection with posed RGB images as input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nerf-det-learning-geometry-aware-volumetric</guid>
    </item>
    <item>
      <title>A Length-Extrapolatable Transformer</title>
      <link>https://paperswithcode.com/paper/a-length-extrapolatable-transformer</link>
      <description><![CDATA[Position modeling plays a critical role in Transformers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-length-extrapolatable-transformer</guid>
    </item>
    <item>
      <title>Llama 2: Open Foundation and Fine-Tuned Chat Models</title>
      <link>https://paperswithcode.com/paper/llama-2-open-foundation-and-fine-tuned-chat</link>
      <description><![CDATA[In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-2-open-foundation-and-fine-tuned-chat</guid>
    </item>
    <item>
      <title>AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning</title>
      <link>https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</link>
      <description><![CDATA[With the advance of text-to-image models (e. g., Stable Diffusion) and corresponding personalization techniques such as DreamBooth and LoRA, everyone can manifest their imagination into high-quality images at an affordable cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</guid>
    </item>
    <item>
      <title>LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models</title>
      <link>https://paperswithcode.com/paper/llm-grounded-diffusion-enhancing-prompt</link>
      <description><![CDATA[We validate the superiority of our design by demonstrating its ability to outperform the base diffusion model in accurately generating images according to prompts that necessitate both language and spatial reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-grounded-diffusion-enhancing-prompt</guid>
    </item>
    <item>
      <title>DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing</title>
      <link>https://paperswithcode.com/paper/dragdiffusion-harnessing-diffusion-models-for</link>
      <description><![CDATA[In this work, we extend such an editing framework to diffusion models and propose DragDiffusion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dragdiffusion-harnessing-diffusion-models-for</guid>
    </item>
    <item>
      <title>Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers</title>
      <link>https://paperswithcode.com/paper/neural-codec-language-models-are-zero-shot</link>
      <description><![CDATA[In addition, we find Vall-E could preserve the speaker's emotion and acoustic environment of the acoustic prompt in synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-codec-language-models-are-zero-shot</guid>
    </item>
    <item>
      <title>imitation: Clean Imitation Learning Implementations</title>
      <link>https://paperswithcode.com/paper/imitation-clean-imitation-learning</link>
      <description><![CDATA[imitation provides open-source implementations of imitation and reward learning algorithms in PyTorch.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imitation-clean-imitation-learning</guid>
    </item>
  </channel>
</rss>
