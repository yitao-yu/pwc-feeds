<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 26 Jul 2022 09:20:29 +0000</lastBuildDate>
    <item>
      <title>Multiface: A Dataset for Neural Face Rendering</title>
      <link>https://paperswithcode.com/paper/multiface-a-dataset-for-neural-face-rendering</link>
      <description><![CDATA[Along with the release of the dataset, we conduct ablation studies on the influence of different model architectures toward the model's interpolation capacity of novel viewpoint and expressions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiface-a-dataset-for-neural-face-rendering</guid>
    </item>
    <item>
      <title>Multi-scale Multi-band DenseNets for Audio Source Separation</title>
      <link>https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</link>
      <description><![CDATA[This paper deals with the problem of audio source separation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</guid>
    </item>
    <item>
      <title>DEVIANT: Depth EquiVarIAnt NeTwork for Monocular 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/deviant-depth-equivariant-network-for</link>
      <description><![CDATA[As a result, DEVIANT is equivariant to the depth translations in the projective manifold whereas vanilla networks are not.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deviant-depth-equivariant-network-for</guid>
    </item>
    <item>
      <title>In Defense of Online Models for Video Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/in-defense-of-online-models-for-video</link>
      <description><![CDATA[In recent years, video instance segmentation (VIS) has been largely advanced by offline models, while online models gradually attracted less attention possibly due to their inferior performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/in-defense-of-online-models-for-video</guid>
    </item>
    <item>
      <title>Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild</title>
      <link>https://paperswithcode.com/paper/omni3d-a-large-benchmark-and-model-for-3d</link>
      <description><![CDATA[Omni3D re-purposes and combines existing datasets resulting in 234k images annotated with more than 3 million instances and 97 categories. 3D detection at such scale is challenging due to variations in camera intrinsics and the rich diversity of scene and object types.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omni3d-a-large-benchmark-and-model-for-3d</guid>
    </item>
    <item>
      <title>Generative Multiplane Images: Making a 2D GAN 3D-Aware</title>
      <link>https://paperswithcode.com/paper/generative-multiplane-images-making-a-2d-gan</link>
      <description><![CDATA[What is really needed to make an existing 2D GAN 3D-aware?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-multiplane-images-making-a-2d-gan</guid>
    </item>
    <item>
      <title>XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model</title>
      <link>https://paperswithcode.com/paper/xmem-long-term-video-object-segmentation-with</link>
      <description><![CDATA[We present XMem, a video object segmentation architecture for long videos with unified feature memory stores inspired by the Atkinson-Shiffrin memory model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xmem-long-term-video-object-segmentation-with</guid>
    </item>
    <item>
      <title>AdaNeRF: Adaptive Sampling for Real-time Rendering of Neural Radiance Fields</title>
      <link>https://paperswithcode.com/paper/adanerf-adaptive-sampling-for-real-time</link>
      <description><![CDATA[However, rendering images with this new paradigm is slow due to the fact that an accurate quadrature of the volume rendering equation requires a large number of samples for each ray.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adanerf-adaptive-sampling-for-real-time</guid>
    </item>
    <item>
      <title>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</title>
      <link>https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</link>
      <description><![CDATA[YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56. 8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</guid>
    </item>
    <item>
      <title>RePaint: Inpainting using Denoising Diffusion Probabilistic Models</title>
      <link>https://paperswithcode.com/paper/repaint-inpainting-using-denoising-diffusion</link>
      <description><![CDATA[In this work, we propose RePaint: A Denoising Diffusion Probabilistic Model (DDPM) based inpainting approach that is applicable to even extreme masks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repaint-inpainting-using-denoising-diffusion</guid>
    </item>
    <item>
      <title>Collaborative Neural Rendering using Anime Character Sheets</title>
      <link>https://paperswithcode.com/paper/collaborative-neural-rendering-using-anime</link>
      <description><![CDATA[Drawing images of characters at desired poses is an essential but laborious task in anime production.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/collaborative-neural-rendering-using-anime</guid>
    </item>
    <item>
      <title>SpA-Former: Transformer image shadow detection and removal via spatial attention</title>
      <link>https://paperswithcode.com/paper/spa-former-transformer-image-shadow-detection</link>
      <description><![CDATA[In this paper, we propose an end-to-end SpA-Former to recover a shadow-free image from a single shaded image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spa-former-transformer-image-shadow-detection</guid>
    </item>
    <item>
      <title>OCR-free Document Understanding Transformer</title>
      <link>https://paperswithcode.com/paper/donut-document-understanding-transformer</link>
      <description><![CDATA[Current Visual Document Understanding (VDU) methods outsource the task of reading text to off-the-shelf Optical Character Recognition (OCR) engines and focus on the understanding task with the OCR outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/donut-document-understanding-transformer</guid>
    </item>
    <item>
      <title>Demystifying MMD GANs</title>
      <link>https://paperswithcode.com/paper/demystifying-mmd-gans</link>
      <description><![CDATA[We investigate the training and performance of generative adversarial networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demystifying-mmd-gans</guid>
    </item>
    <item>
      <title>Panoptic Scene Graph Generation</title>
      <link>https://paperswithcode.com/paper/panoptic-scene-graph-generation</link>
      <description><![CDATA[Existing research addresses scene graph generation (SGG) -- a critical technology for scene understanding in images -- from a detection perspective, i. e., objects are detected using bounding boxes followed by prediction of their pairwise relationships.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/panoptic-scene-graph-generation</guid>
    </item>
    <item>
      <title>3D Clothed Human Reconstruction in the Wild</title>
      <link>https://paperswithcode.com/paper/3d-clothed-human-reconstruction-in-the-wild</link>
      <description><![CDATA[Although much progress has been made in 3D clothed human reconstruction, most of the existing methods fail to produce robust results from in-the-wild images, which contain diverse human poses and appearances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-clothed-human-reconstruction-in-the-wild</guid>
    </item>
    <item>
      <title>Ivy: Templated Deep Learning for Inter-Framework Portability</title>
      <link>https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</link>
      <description><![CDATA[We introduce Ivy, a templated Deep Learning (DL) framework which abstracts existing DL frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</guid>
    </item>
    <item>
      <title>Towards Scale-Aware, Robust, and Generalizable Unsupervised Monocular Depth Estimation by Integrating IMU Motion Dynamics</title>
      <link>https://paperswithcode.com/paper/towards-scale-aware-robust-and-generalizable</link>
      <description><![CDATA[Unsupervised monocular depth and ego-motion estimation has drawn extensive research attention in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-scale-aware-robust-and-generalizable</guid>
    </item>
    <item>
      <title>Improved Vector Quantized Diffusion Models</title>
      <link>https://paperswithcode.com/paper/improved-vector-quantized-diffusion-models</link>
      <description><![CDATA[When trained on ImageNet, we dramatically improve the FID score from 11. 89 to 4. 83, demonstrating the superiority of our proposed techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-vector-quantized-diffusion-models</guid>
    </item>
    <item>
      <title>Optimizing Image Compression via Joint Learning with Denoising</title>
      <link>https://paperswithcode.com/paper/optimizing-image-compression-via-joint</link>
      <description><![CDATA[The key is to transform the original noisy images to noise-free bits by eliminating the undesired noise during compression, where the bits are later decompressed as clean images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/optimizing-image-compression-via-joint</guid>
    </item>
  </channel>
</rss>
