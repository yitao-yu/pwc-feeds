<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 09 Apr 2025 09:18:18 +0000</lastBuildDate>
    <item>
      <title>Open Deep Search: Democratizing Search with Open-source Reasoning Agents</title>
      <link>https://paperswithcode.com/paper/open-deep-search-democratizing-search-with</link>
      <description><![CDATA[Open Search Tool is a novel web search tool that outperforms proprietary counterparts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-deep-search-democratizing-search-with</guid>
    </item>
    <item>
      <title>PaperBench: Evaluating AI's Ability to Replicate AI Research</title>
      <link>https://paperswithcode.com/paper/paperbench-evaluating-ai-s-ability-to</link>
      <description><![CDATA[For objective evaluation, we develop rubrics that hierarchically decompose each replication task into smaller sub-tasks with clear grading criteria.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paperbench-evaluating-ai-s-ability-to</guid>
    </item>
    <item>
      <title>FortisAVQA and MAVEN: a Benchmark Dataset and Debiasing Framework for Robust Multimodal Reasoning</title>
      <link>https://paperswithcode.com/paper/fortisavqa-and-maven-a-benchmark-dataset-and</link>
      <description><![CDATA[The first stage expands the test space with greater diversity, while the second enables a refined robustness evaluation across rare, frequent, and overall question distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fortisavqa-and-maven-a-benchmark-dataset-and</guid>
    </item>
    <item>
      <title>TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models</title>
      <link>https://paperswithcode.com/paper/triposg-high-fidelity-3d-shape-synthesis</link>
      <description><![CDATA[Specifically, we propose: 1) A large-scale rectified flow transformer for 3D shape generation, achieving state-of-the-art fidelity through training on extensive, high-quality data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triposg-high-fidelity-3d-shape-synthesis</guid>
    </item>
    <item>
      <title>Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents</title>
      <link>https://paperswithcode.com/paper/agent-s2-a-compositional-generalist</link>
      <description><![CDATA[Computer use agents automate digital tasks by directly interacting with graphical user interfaces (GUIs) on computers and mobile devices, offering significant potential to enhance human productivity by completing an open-ended space of user queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agent-s2-a-compositional-generalist</guid>
    </item>
    <item>
      <title>Easi3R: Estimating Disentangled Motion from DUSt3R Without Training</title>
      <link>https://paperswithcode.com/paper/easi3r-estimating-disentangled-motion-from</link>
      <description><![CDATA[Recent advances in DUSt3R have enabled robust estimation of dense point clouds and camera parameters of static scenes, leveraging Transformer network architectures and direct supervision on large-scale 3D datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easi3r-estimating-disentangled-motion-from</guid>
    </item>
    <item>
      <title>Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages</title>
      <link>https://paperswithcode.com/paper/dolphin-a-large-scale-automatic-speech</link>
      <description><![CDATA[This report introduces Dolphin, a large-scale multilingual automatic speech recognition (ASR) model that extends the Whisper architecture to support a wider range of languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dolphin-a-large-scale-automatic-speech</guid>
    </item>
    <item>
      <title>VGGT: Visual Geometry Grounded Transformer</title>
      <link>https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</link>
      <description><![CDATA[We present VGGT, a feed-forward neural network that directly infers all key 3D attributes of a scene, including camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</guid>
    </item>
    <item>
      <title>Large Language Model Agent: A Survey on Methodology, Applications and Challenges</title>
      <link>https://paperswithcode.com/paper/large-language-model-agent-a-survey-on</link>
      <description><![CDATA[The era of intelligent agents is upon us, driven by revolutionary advancements in large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-model-agent-a-survey-on</guid>
    </item>
    <item>
      <title>InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity</title>
      <link>https://paperswithcode.com/paper/infiniteyou-flexible-photo-recrafting-while</link>
      <description><![CDATA[Achieving flexible and high-fidelity identity-preserved image generation remains formidable, particularly with advanced Diffusion Transformers (DiTs) like FLUX.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infiniteyou-flexible-photo-recrafting-while</guid>
    </item>
    <item>
      <title>KBLaM: Knowledge Base augmented Language Model</title>
      <link>https://paperswithcode.com/paper/kblam-knowledge-base-augmented-language-model</link>
      <description><![CDATA[In this paper, we propose Knowledge Base augmented Language Model (KBLaM), a new method for augmenting Large Language Models (LLMs) with external knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kblam-knowledge-base-augmented-language-model</guid>
    </item>
    <item>
      <title>LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds</title>
      <link>https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</link>
      <description><![CDATA[Animatable 3D human reconstruction from a single image is a challenging problem due to the ambiguity in decoupling geometry, appearance, and deformation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</guid>
    </item>
    <item>
      <title>Zep: A Temporal Knowledge Graph Architecture for Agent Memory</title>
      <link>https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</link>
      <description><![CDATA[We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</guid>
    </item>
    <item>
      <title>Olympus: A Universal Task Router for Computer Vision Tasks</title>
      <link>https://paperswithcode.com/paper/olympus-a-universal-task-router-for-computer</link>
      <description><![CDATA[We introduce Olympus, a new approach that transforms Multimodal Large Language Models (MLLMs) into a unified framework capable of handling a wide array of computer vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/olympus-a-universal-task-router-for-computer</guid>
    </item>
    <item>
      <title>Video-R1: Reinforcing Video Reasoning in MLLMs</title>
      <link>https://paperswithcode.com/paper/video-r1-reinforcing-video-reasoning-in-mllms</link>
      <description><![CDATA[However, directly applying RL training with the GRPO algorithm to video reasoning presents two primary challenges: (i) a lack of temporal modeling for video reasoning, and (ii) the scarcity of high-quality video-reasoning data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-r1-reinforcing-video-reasoning-in-mllms</guid>
    </item>
    <item>
      <title>IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System</title>
      <link>https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</link>
      <description><![CDATA[Recently, large language model (LLM) based text-to-speech (TTS) systems have gradually become the mainstream in the industry due to their high naturalness and powerful zero-shot voice cloning capabilities. Here, we introduce the IndexTTS system, which is mainly based on the XTTS and Tortoise model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</guid>
    </item>
    <item>
      <title>Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/search-r1-training-llms-to-reason-and</link>
      <description><![CDATA[Efficiently acquiring external knowledge and up-to-date information is essential for effective reasoning and text generation in large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/search-r1-training-llms-to-reason-and</guid>
    </item>
    <item>
      <title>Unified Multimodal Discrete Diffusion</title>
      <link>https://paperswithcode.com/paper/unified-multimodal-discrete-diffusion</link>
      <description><![CDATA[Discrete diffusion models offer several advantages over AR models, including improved control over quality versus diversity of generated samples, the ability to perform joint multimodal inpainting (across both text and image domains), and greater controllability in generation through guidance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-multimodal-discrete-diffusion</guid>
    </item>
    <item>
      <title>NeuPAN: Direct Point Robot Navigation with End-to-End Model-based Learning</title>
      <link>https://paperswithcode.com/paper/neupan-direct-point-robot-navigation-with-end</link>
      <description><![CDATA[This paper presents NeuPAN: a real-time, highly accurate, map-free, easy-to-deploy, and environment-invariant robot motion planner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neupan-direct-point-robot-navigation-with-end</guid>
    </item>
    <item>
      <title>OASIS: Open Agent Social Interaction Simulations with One Million Agents</title>
      <link>https://paperswithcode.com/paper/oasis-open-agents-social-interaction</link>
      <description><![CDATA[There has been a growing interest in enhancing rule-based agent-based models (ABMs) for social media platforms (i. e., X, Reddit) with more realistic large language model (LLM) agents, thereby allowing for a more nuanced study of complex systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oasis-open-agents-social-interaction</guid>
    </item>
  </channel>
</rss>
