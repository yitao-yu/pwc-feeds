<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 30 May 2023 09:11:44 +0000</lastBuildDate>
    <item>
      <title>QLoRA: Efficient Finetuning of Quantized LLMs</title>
      <link>https://paperswithcode.com/paper/qlora-efficient-finetuning-of-quantized-llms</link>
      <description><![CDATA[Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99. 3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qlora-efficient-finetuning-of-quantized-llms</guid>
    </item>
    <item>
      <title>Gorilla: Large Language Model Connected with Massive APIs</title>
      <link>https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</link>
      <description><![CDATA[Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</guid>
    </item>
    <item>
      <title>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</title>
      <link>https://paperswithcode.com/paper/drag-your-gan-interactive-point-based</link>
      <description><![CDATA[Synthesizing visual content that meets users' needs often requires flexible and precise controllability of the pose, shape, expression, and layout of the generated objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drag-your-gan-interactive-point-based</guid>
    </item>
    <item>
      <title>VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks</title>
      <link>https://paperswithcode.com/paper/visionllm-large-language-model-is-also-an</link>
      <description><![CDATA[We hope this model can set a new baseline for generalist vision and language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visionllm-large-language-model-is-also-an</guid>
    </item>
    <item>
      <title>Tree of Thoughts: Deliberate Problem Solving with Large Language Models</title>
      <link>https://paperswithcode.com/paper/tree-of-thoughts-deliberate-problem-solving</link>
      <description><![CDATA[Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tree-of-thoughts-deliberate-problem-solving</guid>
    </item>
    <item>
      <title>ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation</title>
      <link>https://paperswithcode.com/paper/prolificdreamer-high-fidelity-and-diverse</link>
      <description><![CDATA[In this work, we propose to model the 3D parameter as a random variable instead of a constant as in SDS and present variational score distillation (VSD), a principled particle-based variational framework to explain and address the aforementioned issues in text-to-3D generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prolificdreamer-high-fidelity-and-diverse</guid>
    </item>
    <item>
      <title>Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training</title>
      <link>https://paperswithcode.com/paper/sophia-a-scalable-stochastic-second-order</link>
      <description><![CDATA[Given the massive cost of language model pre-training, a non-trivial improvement of the optimization algorithm would lead to a material reduction on the time and cost of training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sophia-a-scalable-stochastic-second-order</guid>
    </item>
    <item>
      <title>Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/prompt-free-diffusion-taking-text-out-of-text</link>
      <description><![CDATA[Text-to-image (T2I) research has grown explosively in the past year, owing to the large-scale pre-trained diffusion models and many emerging personalization and editing approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-free-diffusion-taking-text-out-of-text</guid>
    </item>
    <item>
      <title>Generating Sequences With Recurrent Neural Networks</title>
      <link>https://paperswithcode.com/paper/generating-sequences-with-recurrent-neural</link>
      <description><![CDATA[This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-sequences-with-recurrent-neural</guid>
    </item>
    <item>
      <title>OCR-free Document Understanding Transformer</title>
      <link>https://paperswithcode.com/paper/donut-document-understanding-transformer</link>
      <description><![CDATA[Current Visual Document Understanding (VDU) methods outsource the task of reading text to off-the-shelf Optical Character Recognition (OCR) engines and focus on the understanding task with the OCR outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/donut-document-understanding-transformer</guid>
    </item>
    <item>
      <title>Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/uni-controlnet-all-in-one-control-to-text-to</link>
      <description><![CDATA[Text-to-Image diffusion models have made tremendous progress over the past two years, enabling the generation of highly realistic images based on open-domain text descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uni-controlnet-all-in-one-control-to-text-to</guid>
    </item>
    <item>
      <title>EasySpider: A No-Code Visual System for Crawling the Web</title>
      <link>https://paperswithcode.com/paper/easyspider-a-no-code-visual-system-for</link>
      <description><![CDATA[As such, web-crawling is an essential tool for both computational and non-computational scientists to conduct research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyspider-a-no-code-visual-system-for</guid>
    </item>
    <item>
      <title>SoundStorm: Efficient Parallel Audio Generation</title>
      <link>https://paperswithcode.com/paper/soundstorm-efficient-parallel-audio</link>
      <description><![CDATA[We present SoundStorm, a model for efficient, non-autoregressive audio generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/soundstorm-efficient-parallel-audio</guid>
    </item>
    <item>
      <title>VanillaNet: the Power of Minimalism in Deep Learning</title>
      <link>https://paperswithcode.com/paper/vanillanet-the-power-of-minimalism-in-deep</link>
      <description><![CDATA[In this study, we introduce VanillaNet, a neural network architecture that embraces elegance in design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vanillanet-the-power-of-minimalism-in-deep</guid>
    </item>
    <item>
      <title>Any-to-Any Generation via Composable Diffusion</title>
      <link>https://paperswithcode.com/paper/any-to-any-generation-via-composable</link>
      <description><![CDATA[We present Composable Diffusion (CoDi), a novel generative model capable of generating any combination of output modalities, such as language, image, video, or audio, from any combination of input modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/any-to-any-generation-via-composable</guid>
    </item>
    <item>
      <title>Unifying Vision, Text, and Layout for Universal Document Processing</title>
      <link>https://paperswithcode.com/paper/unifying-vision-text-and-layout-for-universal</link>
      <description><![CDATA[UDOP leverages the spatial correlation between textual content and document image to model image, text, and layout modalities with one uniform representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unifying-vision-text-and-layout-for-universal</guid>
    </item>
    <item>
      <title>RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text</title>
      <link>https://paperswithcode.com/paper/recurrentgpt-interactive-generation-of</link>
      <description><![CDATA[In addition to producing AI-generated content (AIGC), we also demonstrate the possibility of using RecurrentGPT as an interactive fiction that directly interacts with consumers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/recurrentgpt-interactive-generation-of</guid>
    </item>
    <item>
      <title>Large Language Models as Tool Makers</title>
      <link>https://paperswithcode.com/paper/large-language-models-as-tool-makers</link>
      <description><![CDATA[Our approach consists of two key phases: 1) tool making: an LLM acts as the tool maker that crafts tools for given tasks, where a tool is implemented as a Python utility function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-as-tool-makers</guid>
    </item>
    <item>
      <title>Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network for Surgical Tools Segmentation</title>
      <link>https://paperswithcode.com/paper/min-max-similarity-a-contrastive-learning</link>
      <description><![CDATA[In contrast to the previous state-of-the-art, we introduce Min-Max Similarity (MMS), a contrastive learning form of dual-view training by employing classifiers and projectors to build all-negative, and positive and negative feature pairs, respectively, to formulate the learning as solving a MMS problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/min-max-similarity-a-contrastive-learning</guid>
    </item>
    <item>
      <title>SwinIR: Image Restoration Using Swin Transformer</title>
      <link>https://paperswithcode.com/paper/swinir-image-restoration-using-swin</link>
      <description><![CDATA[In particular, the deep feature extraction module is composed of several residual Swin Transformer blocks (RSTB), each of which has several Swin Transformer layers together with a residual connection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/swinir-image-restoration-using-swin</guid>
    </item>
  </channel>
</rss>
