<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 11 Nov 2023 21:06:02 +0000</lastBuildDate>
    <item>
      <title>OpenChat: Advancing Open-source Language Models with Mixed-Quality Data</title>
      <link>https://paperswithcode.com/paper/openchat-advancing-open-source-language</link>
      <description><![CDATA[Specifically, we consider the general SFT training data, consisting of a small amount of expert data mixed with a large proportion of sub-optimal data, without any preference labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openchat-advancing-open-source-language</guid>
    </item>
    <item>
      <title>PhoGPT: Generative Pre-training for Vietnamese</title>
      <link>https://paperswithcode.com/paper/phogpt-generative-pre-training-for-vietnamese</link>
      <description><![CDATA[We open-source a state-of-the-art 7. 5B-parameter generative model series named PhoGPT for Vietnamese, which includes the base pre-trained monolingual model PhoGPT-7B5 and its instruction-following variant, PhoGPT-7B5-Instruct.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phogpt-generative-pre-training-for-vietnamese</guid>
    </item>
    <item>
      <title>S-LoRA: Serving Thousands of Concurrent LoRA Adapters</title>
      <link>https://paperswithcode.com/paper/s-lora-serving-thousands-of-concurrent-lora</link>
      <description><![CDATA[To capitalize on these opportunities, we present S-LoRA, a system designed for the scalable serving of many LoRA adapters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s-lora-serving-thousands-of-concurrent-lora</guid>
    </item>
    <item>
      <title>CogVLM: Visual Expert for Pretrained Language Models</title>
      <link>https://paperswithcode.com/paper/cogvlm-visual-expert-for-pretrained-language</link>
      <description><![CDATA[We introduce CogVLM, a powerful open-source visual language foundation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cogvlm-visual-expert-for-pretrained-language</guid>
    </item>
    <item>
      <title>Punica: Multi-Tenant LoRA Serving</title>
      <link>https://paperswithcode.com/paper/punica-multi-tenant-lora-serving</link>
      <description><![CDATA[Our scheduler consolidates multi-tenant LoRA serving workloads in a shared GPU cluster.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/punica-multi-tenant-lora-serving</guid>
    </item>
    <item>
      <title>GLaMM: Pixel Grounding Large Multimodal Model</title>
      <link>https://paperswithcode.com/paper/glamm-pixel-grounding-large-multimodal-model</link>
      <description><![CDATA[In this work, we present Grounding LMM (GLaMM), the first model that can generate natural language responses seamlessly intertwined with corresponding object segmentation masks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glamm-pixel-grounding-large-multimodal-model</guid>
    </item>
    <item>
      <title>GLM-130B: An Open Bilingual Pre-trained Model</title>
      <link>https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</link>
      <description><![CDATA[We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</guid>
    </item>
    <item>
      <title>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</title>
      <link>https://paperswithcode.com/paper/an-image-is-worth-16x16-words-transformers-1</link>
      <description><![CDATA[While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-image-is-worth-16x16-words-transformers-1</guid>
    </item>
    <item>
      <title>QUIK: Towards End-to-End 4-Bit Inference on Generative Large Language Models</title>
      <link>https://paperswithcode.com/paper/towards-end-to-end-4-bit-inference-on</link>
      <description><![CDATA[We show, for the first time, that the majority of inference computations for large generative models such as LLaMA, OPT, and Falcon can be performed with both weights and activations being cast to 4 bits, in a way that leads to practical speedups, while at the same time maintaining good accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-end-to-end-4-bit-inference-on</guid>
    </item>
    <item>
      <title>Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling</title>
      <link>https://paperswithcode.com/paper/distil-whisper-robust-knowledge-distillation</link>
      <description><![CDATA[As the size of pre-trained speech recognition models increases, running these large models in low-latency or resource-constrained environments becomes challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distil-whisper-robust-knowledge-distillation</guid>
    </item>
    <item>
      <title>PP-LiteSeg: A Superior Real-Time Semantic Segmentation Model</title>
      <link>https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</link>
      <description><![CDATA[Real-world applications have high demands for semantic segmentation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</guid>
    </item>
    <item>
      <title>Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V</title>
      <link>https://paperswithcode.com/paper/set-of-mark-prompting-unleashes-extraordinary</link>
      <description><![CDATA[We present Set-of-Mark (SoM), a new visual prompting method, to unleash the visual grounding abilities of large multimodal models (LMMs), such as GPT-4V.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/set-of-mark-prompting-unleashes-extraordinary</guid>
    </item>
    <item>
      <title>VideoCrafter1: Open Diffusion Models for High-Quality Video Generation</title>
      <link>https://paperswithcode.com/paper/videocrafter1-open-diffusion-models-for-high</link>
      <description><![CDATA[The I2V model is designed to produce videos that strictly adhere to the content of the provided reference image, preserving its content, structure, and style.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videocrafter1-open-diffusion-models-for-high</guid>
    </item>
    <item>
      <title>DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors</title>
      <link>https://paperswithcode.com/paper/dynamicrafter-animating-open-domain-images</link>
      <description><![CDATA[To supplement more precise image information, we further feed the full image to the diffusion model by concatenating it with the initial noises.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamicrafter-animating-open-domain-images</guid>
    </item>
    <item>
      <title>VideoReTalking: Audio-based Lip Synchronization for Talking Head Video Editing In the Wild</title>
      <link>https://paperswithcode.com/paper/videoretalking-audio-based-lip</link>
      <description><![CDATA[Our system disentangles this objective into three sequential tasks: (1) face video generation with a canonical expression; (2) audio-driven lip-sync; and (3) face enhancement for improving photo-realism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videoretalking-audio-based-lip</guid>
    </item>
    <item>
      <title>nnMobileNe: Rethinking CNN for Retinopathy Research</title>
      <link>https://paperswithcode.com/paper/nnmobile-net-rethinking-cnn-design-for-deep</link>
      <description><![CDATA[Over the past few decades, convolutional neural networks (CNNs) have been at the forefront of the detection and tracking of various retinal diseases (RD).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nnmobile-net-rethinking-cnn-design-for-deep</guid>
    </item>
    <item>
      <title>On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/on-the-road-with-gpt-4v-ision-early</link>
      <description><![CDATA[This has been a significant bottleneck, particularly in the development of common sense reasoning and nuanced scene understanding necessary for safe and reliable autonomous driving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-road-with-gpt-4v-ision-early</guid>
    </item>
    <item>
      <title>Skywork: A More Open Bilingual Foundation Model</title>
      <link>https://paperswithcode.com/paper/skywork-a-more-open-bilingual-foundation</link>
      <description><![CDATA[In this technical report, we present Skywork-13B, a family of large language models (LLMs) trained on a corpus of over 3. 2 trillion tokens drawn from both English and Chinese texts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/skywork-a-more-open-bilingual-foundation</guid>
    </item>
    <item>
      <title>TopicGPT: A Prompt-based Topic Modeling Framework</title>
      <link>https://paperswithcode.com/paper/topicgpt-a-prompt-based-topic-modeling</link>
      <description><![CDATA[Topic modeling is a well-established technique for exploring text corpora.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/topicgpt-a-prompt-based-topic-modeling</guid>
    </item>
    <item>
      <title>LongQLoRA: Efficient and Effective Method to Extend Context Length of Large Language Models</title>
      <link>https://paperswithcode.com/paper/longqlora-efficient-and-effective-method-to</link>
      <description><![CDATA[We present LongQLoRA, an efficient and effective method to extend context length of large language models with less training resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longqlora-efficient-and-effective-method-to</guid>
    </item>
  </channel>
</rss>
