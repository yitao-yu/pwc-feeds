<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 04 Aug 2022 09:14:13 +0000</lastBuildDate>
    <item>
      <title>Multi-scale Multi-band DenseNets for Audio Source Separation</title>
      <link>https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</link>
      <description><![CDATA[This paper deals with the problem of audio source separation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</guid>
    </item>
    <item>
      <title>An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion</title>
      <link>https://paperswithcode.com/paper/an-image-is-worth-one-word-personalizing-text</link>
      <description><![CDATA[Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-image-is-worth-one-word-personalizing-text</guid>
    </item>
    <item>
      <title>Neural Density-Distance Fields</title>
      <link>https://paperswithcode.com/paper/neural-density-distance-fields</link>
      <description><![CDATA[However, it is difficult to achieve high localization performance by only density fields-based methods such as Neural Radiance Field (NeRF) since they do not provide density gradient in most empty regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-density-distance-fields</guid>
    </item>
    <item>
      <title>GAUDI: A Neural Architect for Immersive 3D Scene Generation</title>
      <link>https://paperswithcode.com/paper/gaudi-a-neural-architect-for-immersive-3d</link>
      <description><![CDATA[We introduce GAUDI, a generative model capable of capturing the distribution of complex and realistic 3D scenes that can be rendered immersively from a moving camera.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaudi-a-neural-architect-for-immersive-3d</guid>
    </item>
    <item>
      <title>Rewriting Geometric Rules of a GAN</title>
      <link>https://paperswithcode.com/paper/rewriting-geometric-rules-of-a-gan</link>
      <description><![CDATA[Our method allows a user to create a model that synthesizes endless objects with defined geometric changes, enabling the creation of a new generative model without the burden of curating a large-scale dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rewriting-geometric-rules-of-a-gan</guid>
    </item>
    <item>
      <title>AvatarPoser: Articulated Full-Body Pose Tracking from Sparse Motion Sensing</title>
      <link>https://paperswithcode.com/paper/avatarposer-articulated-full-body-pose</link>
      <description><![CDATA[In this paper, we present AvatarPoser, the first learning-based method that predicts full-body poses in world coordinates using only motion input from the user's head and hands.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/avatarposer-articulated-full-body-pose</guid>
    </item>
    <item>
      <title>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</title>
      <link>https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</link>
      <description><![CDATA[YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56. 8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</guid>
    </item>
    <item>
      <title>Highly Accurate Dichotomous Image Segmentation</title>
      <link>https://paperswithcode.com/paper/highly-accurate-dichotomous-image</link>
      <description><![CDATA[We present a systematic study on a new task called dichotomous image segmentation (DIS) , which aims to segment highly accurate objects from natural images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/highly-accurate-dichotomous-image</guid>
    </item>
    <item>
      <title>OCR-free Document Understanding Transformer</title>
      <link>https://paperswithcode.com/paper/donut-document-understanding-transformer</link>
      <description><![CDATA[Current Visual Document Understanding (VDU) methods outsource the task of reading text to off-the-shelf Optical Character Recognition (OCR) engines and focus on the understanding task with the OCR outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/donut-document-understanding-transformer</guid>
    </item>
    <item>
      <title>Theseus: A Library for Differentiable Nonlinear Optimization</title>
      <link>https://paperswithcode.com/paper/theseus-a-library-for-differentiable</link>
      <description><![CDATA[We present Theseus, an efficient application-agnostic open source library for differentiable nonlinear least squares (DNLS) optimization built on PyTorch, providing a common framework for end-to-end structured learning in robotics and vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/theseus-a-library-for-differentiable</guid>
    </item>
    <item>
      <title>DoF-NeRF: Depth-of-Field Meets Neural Radiance Fields</title>
      <link>https://paperswithcode.com/paper/dof-nerf-depth-of-field-meets-neural-radiance</link>
      <description><![CDATA[To mitigate this issue, we introduce DoF-NeRF, a novel neural rendering approach that can deal with shallow DoF inputs and can simulate DoF effect.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dof-nerf-depth-of-field-meets-neural-radiance</guid>
    </item>
    <item>
      <title>Towards Real-World Blind Face Restoration with Generative Facial Prior</title>
      <link>https://paperswithcode.com/paper/towards-real-world-blind-face-restoration</link>
      <description><![CDATA[Blind face restoration usually relies on facial priors, such as facial geometry prior or reference prior, to restore realistic and faithful details.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-real-world-blind-face-restoration</guid>
    </item>
    <item>
      <title>DETRs with Hybrid Matching</title>
      <link>https://paperswithcode.com/paper/detrs-with-hybrid-matching</link>
      <description><![CDATA[This end-to-end signature is important for the versatility of DETR, and it has been generalized to a wide range of visual problems, including instance/semantic segmentation, human pose estimation, and point cloud/multi-view-images based detection, etc.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detrs-with-hybrid-matching</guid>
    </item>
    <item>
      <title>fastai: A Layered API for Deep Learning</title>
      <link>https://paperswithcode.com/paper/fastai-a-layered-api-for-deep-learning</link>
      <description><![CDATA[These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fastai-a-layered-api-for-deep-learning</guid>
    </item>
    <item>
      <title>Text2LIVE: Text-Driven Layered Image and Video Editing</title>
      <link>https://paperswithcode.com/paper/text2live-text-driven-layered-image-and-video</link>
      <description><![CDATA[Given an input image or video and a target text prompt, our goal is to edit the appearance of existing objects (e. g., object's texture) or augment the scene with visual effects (e. g., smoke, fire) in a semantically meaningful manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2live-text-driven-layered-image-and-video</guid>
    </item>
    <item>
      <title>MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge</title>
      <link>https://paperswithcode.com/paper/minedojo-building-open-ended-embodied-agents</link>
      <description><![CDATA[Autonomous agents have made great strides in specialist domains like Atari games and Go.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minedojo-building-open-ended-embodied-agents</guid>
    </item>
    <item>
      <title>REALY: Rethinking the Evaluation of 3D Face Reconstruction</title>
      <link>https://paperswithcode.com/paper/realy-rethinking-the-evaluation-of-3d-face</link>
      <description><![CDATA[The evaluation of 3D face reconstruction results typically relies on a rigid shape alignment between the estimated 3D model and the ground-truth scan.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/realy-rethinking-the-evaluation-of-3d-face</guid>
    </item>
    <item>
      <title>ferret: a Framework for Benchmarking Explainers on Transformers</title>
      <link>https://paperswithcode.com/paper/ferret-a-framework-for-benchmarking</link>
      <description><![CDATA[Many interpretability tools allow practitioners and researchers to explain Natural Language Processing systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ferret-a-framework-for-benchmarking</guid>
    </item>
    <item>
      <title>DCT-Net: Domain-Calibrated Translation for Portrait Stylization</title>
      <link>https://paperswithcode.com/paper/dct-net-domain-calibrated-translation-for</link>
      <description><![CDATA[This paper introduces DCT-Net, a novel image translation architecture for few-shot portrait stylization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dct-net-domain-calibrated-translation-for</guid>
    </item>
    <item>
      <title>Toward Understanding WordArt: Corner-Guided Transformer for Scene Text Recognition</title>
      <link>https://paperswithcode.com/paper/toward-understanding-wordart-corner-guided</link>
      <description><![CDATA[Thirdly, we utilize Transformer to learn the global feature on image-level and model the global relationship of the corner points, with the assistance of a corner-query cross-attention mechanism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toward-understanding-wordart-corner-guided</guid>
    </item>
  </channel>
</rss>
