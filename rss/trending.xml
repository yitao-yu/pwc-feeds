<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 01 Dec 2022 09:14:12 +0000</lastBuildDate>
    <item>
      <title>TorchScale: Transformers at Scale</title>
      <link>https://paperswithcode.com/paper/torchscale-transformers-at-scale</link>
      <description><![CDATA[Large Transformers have achieved state-of-the-art performance across many tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchscale-transformers-at-scale</guid>
    </item>
    <item>
      <title>SuperFusion: Multilevel LiDAR-Camera Fusion for Long-Range HD Map Generation and Prediction</title>
      <link>https://paperswithcode.com/paper/superfusion-multilevel-lidar-camera-fusion</link>
      <description><![CDATA[To this end, we propose a novel network named SuperFusion, exploiting the fusion of LiDAR and camera data at multiple levels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/superfusion-multilevel-lidar-camera-fusion</guid>
    </item>
    <item>
      <title>Compressing Volumetric Radiance Fields to 1 MB</title>
      <link>https://paperswithcode.com/paper/compressing-volumetric-radiance-fields-to-1</link>
      <description><![CDATA[Approximating radiance fields with volumetric grids is one of promising directions for improving NeRF, represented by methods like Plenoxels and DVGO, which achieve super-fast training convergence and real-time rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compressing-volumetric-radiance-fields-to-1</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>Fast-SNARF: A Fast Deformer for Articulated Neural Fields</title>
      <link>https://paperswithcode.com/paper/fast-snarf-a-fast-deformer-for-articulated</link>
      <description><![CDATA[A key challenge in making such methods applicable to articulated objects, such as the human body, is to model the deformation of 3D locations between the rest pose (a canonical space) and the deformed space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-snarf-a-fast-deformer-for-articulated</guid>
    </item>
    <item>
      <title>Human-level play in the game of Diplomacy by combining language models with strategic reasoning</title>
      <link>https://paperswithcode.com/paper/human-level-play-in-the-game-of-diplomacy-by</link>
      <description><![CDATA[Despite much progress in training AI systems to imitate human language, building agents that use language to communicate intentionally with humans in interactive environments remains a major challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/human-level-play-in-the-game-of-diplomacy-by</guid>
    </item>
    <item>
      <title>BotSIM: An End-to-End Bot Simulation Toolkit for Commercial Task-Oriented Dialog Systems</title>
      <link>https://paperswithcode.com/paper/botsim-an-end-to-end-bot-simulation-toolkit</link>
      <description><![CDATA[BotSIM adopts a layered design comprising the infrastructure layer, the adaptor layer and the application layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/botsim-an-end-to-end-bot-simulation-toolkit</guid>
    </item>
    <item>
      <title>Medical Image Segmentation Review: The success of U-Net</title>
      <link>https://paperswithcode.com/paper/medical-image-segmentation-review-the-success</link>
      <description><![CDATA[U-Net is the most widespread image segmentation architecture due to its flexibility, optimized modular design, and success in all medical image modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medical-image-segmentation-review-the-success</guid>
    </item>
    <item>
      <title>Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark</title>
      <link>https://paperswithcode.com/paper/roboflow-100-a-rich-multi-domain-object</link>
      <description><![CDATA[The evaluation of object detection models is usually performed by optimizing a single metric, e. g. mAP, on a fixed set of datasets, e. g. Microsoft COCO and Pascal VOC.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/roboflow-100-a-rich-multi-domain-object</guid>
    </item>
    <item>
      <title>FFHQ-UV: Normalized Facial UV-Texture Dataset for 3D Face Reconstruction</title>
      <link>https://paperswithcode.com/paper/ffhq-uv-normalized-facial-uv-texture-dataset</link>
      <description><![CDATA[Our pipeline utilizes the recent advances in StyleGAN-based facial image editing approaches to generate multi-view normalized face images from single-image inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ffhq-uv-normalized-facial-uv-texture-dataset</guid>
    </item>
    <item>
      <title>Versatile Diffusion: Text, Images and Variations All in One Diffusion Model</title>
      <link>https://paperswithcode.com/paper/versatile-diffusion-text-images-and</link>
      <description><![CDATA[Through our experiments, we demonstrate that VD and its underlying framework have the following merits: a) VD handles all subtasks with competitive quality; b) VD initiates novel extensions and applications such as disentanglement of style and semantic, image-text dual-guided generation, etc.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/versatile-diffusion-text-images-and</guid>
    </item>
    <item>
      <title>ZeroEGGS: Zero-shot Example-based Gesture Generation from Speech</title>
      <link>https://paperswithcode.com/paper/zeroeggs-zero-shot-example-based-gesture</link>
      <description><![CDATA[In a series of experiments, we first demonstrate the flexibility and generalizability of our model to new speakers and styles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zeroeggs-zero-shot-example-based-gesture</guid>
    </item>
    <item>
      <title>A Time Series is Worth 64 Words: Long-term Forecasting with Transformers</title>
      <link>https://paperswithcode.com/paper/a-time-series-is-worth-64-words-long-term</link>
      <description><![CDATA[Our channel-independent patch time series Transformer (PatchTST) can improve the long-term forecasting accuracy significantly when compared with that of SOTA Transformer-based models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-time-series-is-worth-64-words-long-term</guid>
    </item>
    <item>
      <title>Conffusion: Confidence Intervals for Diffusion Models</title>
      <link>https://paperswithcode.com/paper/conffusion-confidence-intervals-for-diffusion</link>
      <description><![CDATA[Diffusion models have become the go-to method for many generative tasks, particularly for image-to-image generation tasks such as super-resolution and inpainting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conffusion-confidence-intervals-for-diffusion</guid>
    </item>
    <item>
      <title>H3WB: Human3.6M 3D WholeBody Dataset and Benchmark</title>
      <link>https://paperswithcode.com/paper/h3wb-human3-6m-3d-wholebody-dataset-and</link>
      <description><![CDATA[We also report several baselines from popular methods for these tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h3wb-human3-6m-3d-wholebody-dataset-and</guid>
    </item>
    <item>
      <title>DiffusionDet: Diffusion Model for Object Detection</title>
      <link>https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</link>
      <description><![CDATA[In inference, the model refines a set of randomly generated boxes to the output results in a progressive way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</guid>
    </item>
    <item>
      <title>Language-driven Open-Vocabulary 3D Scene Understanding</title>
      <link>https://paperswithcode.com/paper/language-driven-open-vocabulary-3d-scene</link>
      <description><![CDATA[Open-vocabulary scene understanding aims to localize and recognize unseen categories beyond the annotated label space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-driven-open-vocabulary-3d-scene</guid>
    </item>
    <item>
      <title>Fast Text-Conditional Discrete Denoising on Vector-Quantized Latent Spaces</title>
      <link>https://paperswithcode.com/paper/fast-text-conditional-discrete-denoising-on</link>
      <description><![CDATA[Conditional text-to-image generation has seen countless recent improvements in terms of quality, diversity and fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-text-conditional-discrete-denoising-on</guid>
    </item>
    <item>
      <title>MetaFormer Baselines for Vision</title>
      <link>https://paperswithcode.com/paper/metaformer-baselines-for-vision</link>
      <description><![CDATA[By simply applying depthwise separable convolutions as token mixer in the bottom stages and vanilla self-attention in the top stages, the resulting model CAFormer sets a new record on ImageNet-1K: it achieves an accuracy of 85. 5% at 224x224 resolution, under normal supervised training without external data or distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metaformer-baselines-for-vision</guid>
    </item>
    <item>
      <title>VeLO: Training Versatile Learned Optimizers by Scaling Up</title>
      <link>https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</link>
      <description><![CDATA[While deep learning models have replaced hand-designed features across many domains, these models are still trained with hand-designed optimizers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</guid>
    </item>
  </channel>
</rss>
