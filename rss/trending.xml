<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 26 Jun 2023 21:07:24 +0000</lastBuildDate>
    <item>
      <title>Fast Segment Anything</title>
      <link>https://paperswithcode.com/paper/fast-segment-anything</link>
      <description><![CDATA[In this paper, we propose a speed-up alternative method for this fundamental task with comparable performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-segment-anything</guid>
    </item>
    <item>
      <title>PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360$^{\circ}$</title>
      <link>https://paperswithcode.com/paper/panohead-geometry-aware-3d-full-head</link>
      <description><![CDATA[We propose PanoHead, the first 3D-aware generative model that enables high-quality view-consistent image synthesis of full heads in $360^\circ$ with diverse appearance and detailed geometry using only in-the-wild unstructured images for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/panohead-geometry-aware-3d-full-head</guid>
    </item>
    <item>
      <title>Planning-oriented Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/goal-oriented-autonomous-driving</link>
      <description><![CDATA[Oriented at this, we revisit the key components within perception and prediction, and prioritize the tasks such that all these tasks contribute to planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/goal-oriented-autonomous-driving</guid>
    </item>
    <item>
      <title>Full Parameter Fine-tuning for Large Language Models with Limited Resources</title>
      <link>https://paperswithcode.com/paper/full-parameter-fine-tuning-for-large-language</link>
      <description><![CDATA[Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but demand massive GPU resources for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/full-parameter-fine-tuning-for-large-language</guid>
    </item>
    <item>
      <title>WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences</title>
      <link>https://paperswithcode.com/paper/webglm-towards-an-efficient-web-enhanced</link>
      <description><![CDATA[We present WebGLM, a web-enhanced question-answering system based on the General Language Model (GLM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/webglm-towards-an-efficient-web-enhanced</guid>
    </item>
    <item>
      <title>FinGPT: Open-Source Financial Large Language Models</title>
      <link>https://paperswithcode.com/paper/fingpt-open-source-financial-large-language</link>
      <description><![CDATA[While proprietary models like BloombergGPT have taken advantage of their unique data accumulation, such privileged access calls for an open-source alternative to democratize Internet-scale financial data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fingpt-open-source-financial-large-language</guid>
    </item>
    <item>
      <title>A Simple and Effective Pruning Approach for Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-simple-and-effective-pruning-approach-for</link>
      <description><![CDATA[Motivated by the recent observation of emergent large magnitude features in LLMs, our approach prune weights with the smallest magnitudes multiplied by the corresponding input activations, on a per-output basis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-simple-and-effective-pruning-approach-for</guid>
    </item>
    <item>
      <title>WizardCoder: Empowering Code Large Language Models with Evol-Instruct</title>
      <link>https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language</link>
      <description><![CDATA[Moreover, our model even outperforms the largest closed LLMs, Anthropic's Claude and Google's Bard, on HumanEval and HumanEval+.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language</guid>
    </item>
    <item>
      <title>TAP-Vid: A Benchmark for Tracking Any Point in a Video</title>
      <link>https://paperswithcode.com/paper/tap-vid-a-benchmark-for-tracking-any-point-in</link>
      <description><![CDATA[Generic motion understanding from video involves not only tracking objects, but also perceiving how their surfaces deform and move.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tap-vid-a-benchmark-for-tracking-any-point-in</guid>
    </item>
    <item>
      <title>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</title>
      <link>https://paperswithcode.com/paper/direct-preference-optimization-your-language</link>
      <description><![CDATA[However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct-preference-optimization-your-language</guid>
    </item>
    <item>
      <title>On the Benefits of 3D Pose and Tracking for Human Action Recognition</title>
      <link>https://paperswithcode.com/paper/on-the-benefits-of-3d-pose-and-tracking-for</link>
      <description><![CDATA[Subsequently, we propose a Lagrangian Action Recognition model by fusing 3D pose and contextualized appearance over tracklets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-benefits-of-3d-pose-and-tracking-for</guid>
    </item>
    <item>
      <title>WizMap: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings</title>
      <link>https://paperswithcode.com/paper/wizmap-scalable-interactive-visualization-for</link>
      <description><![CDATA[Machine learning models often learn latent embedding representations that capture the domain semantics of their training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wizmap-scalable-interactive-visualization-for</guid>
    </item>
    <item>
      <title>LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model</title>
      <link>https://paperswithcode.com/paper/llama-adapter-v2-parameter-efficient-visual</link>
      <description><![CDATA[This strategy effectively alleviates the interference between the two tasks of image-text alignment and instruction following and achieves strong multi-modal reasoning with only a small-scale image-text and instruction dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-adapter-v2-parameter-efficient-visual</guid>
    </item>
    <item>
      <title>From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought</title>
      <link>https://paperswithcode.com/paper/from-word-models-to-world-models-translating</link>
      <description><![CDATA[Our architecture integrates two computational tools that have not previously come together: we model thinking with probabilistic programs, an expressive representation for commonsense reasoning; and we model meaning construction with large language models (LLMs), which support broad-coverage translation from natural language utterances to code expressions in a probabilistic programming language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-word-models-to-world-models-translating</guid>
    </item>
    <item>
      <title>PyRCA: A Library for Metric-based Root Cause Analysis</title>
      <link>https://paperswithcode.com/paper/pyrca-a-library-for-metric-based-root-cause</link>
      <description><![CDATA[We introduce PyRCA, an open-source Python machine learning library of Root Cause Analysis (RCA) for Artificial Intelligence for IT Operations (AIOps).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pyrca-a-library-for-metric-based-root-cause</guid>
    </item>
    <item>
      <title>EasySpider: A No-Code Visual System for Crawling the Web</title>
      <link>https://paperswithcode.com/paper/easyspider-a-no-code-visual-system-for</link>
      <description><![CDATA[As such, web-crawling is an essential tool for both computational and non-computational scientists to conduct research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyspider-a-no-code-visual-system-for</guid>
    </item>
    <item>
      <title>BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Models</title>
      <link>https://paperswithcode.com/paper/bayling-bridging-cross-lingual-alignment-and</link>
      <description><![CDATA[To minimize human workload, we propose to transfer the capabilities of language generation and instruction following from English to other languages through an interactive translation task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bayling-bridging-cross-lingual-alignment-and</guid>
    </item>
    <item>
      <title>h2oGPT: Democratizing Large Language Models</title>
      <link>https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models</link>
      <description><![CDATA[Applications built on top of Large Language Models (LLMs) such as GPT-4 represent a revolution in AI due to their human-level capabilities in natural language processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models</guid>
    </item>
    <item>
      <title>Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling</title>
      <link>https://paperswithcode.com/paper/pythia-a-suite-for-analyzing-large-language</link>
      <description><![CDATA[How do large language models (LLMs) develop and evolve over the course of training?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pythia-a-suite-for-analyzing-large-language</guid>
    </item>
    <item>
      <title>MAGVIT: Masked Generative Video Transformer</title>
      <link>https://paperswithcode.com/paper/magvit-masked-generative-video-transformer</link>
      <description><![CDATA[We introduce the MAsked Generative VIdeo Transformer, MAGVIT, to tackle various video synthesis tasks with a single model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magvit-masked-generative-video-transformer</guid>
    </item>
  </channel>
</rss>
