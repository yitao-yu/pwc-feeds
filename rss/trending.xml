<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 23 Nov 2024 21:08:16 +0000</lastBuildDate>
    <item>
      <title>SAMURAI: Adapting Segment Anything Model for Zero-Shot Visual Tracking with Motion-Aware Memory</title>
      <link>https://paperswithcode.com/paper/samurai-adapting-segment-anything-model-for-1</link>
      <description><![CDATA[The Segment Anything Model 2 (SAM 2) has demonstrated strong performance in object segmentation tasks but faces challenges in visual object tracking, particularly when managing crowded scenes with fast-moving or self-occluding objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/samurai-adapting-segment-anything-model-for-1</guid>
    </item>
    <item>
      <title>garak: A Framework for Security Probing Large Language Models</title>
      <link>https://paperswithcode.com/paper/garak-a-framework-for-security-probing-large</link>
      <description><![CDATA[As Large Language Models (LLMs) are deployed and integrated into thousands of applications, the need for scalable evaluation of how models respond to adversarial attacks grows rapidly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/garak-a-framework-for-security-probing-large</guid>
    </item>
    <item>
      <title>When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training</title>
      <link>https://paperswithcode.com/paper/when-precision-meets-position-bfloat16-breaks</link>
      <description><![CDATA[To address this, we develop AnchorAttention, a plug-and-play attention method that alleviates numerical issues caused by BFloat16, improves long-context capabilities, and speeds up training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-precision-meets-position-bfloat16-breaks</guid>
    </item>
    <item>
      <title>JoyVASA: Portrait and Animal Image Animation with Diffusion-Based Audio-Driven Facial Dynamics and Head Motion Generation</title>
      <link>https://paperswithcode.com/paper/joyvasa-portrait-and-animal-image-animation</link>
      <description><![CDATA[Specifically, in the first stage, we introduce a decoupled facial representation framework that separates dynamic facial expressions from static 3D facial representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/joyvasa-portrait-and-animal-image-animation</guid>
    </item>
    <item>
      <title>The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use</title>
      <link>https://paperswithcode.com/paper/the-dawn-of-gui-agent-a-preliminary-case</link>
      <description><![CDATA[The recently released model, Claude 3. 5 Computer Use, stands out as the first frontier AI model to offer computer use in public beta as a graphical user interface (GUI) agent.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-dawn-of-gui-agent-a-preliminary-case</guid>
    </item>
    <item>
      <title>In-Context LoRA for Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/in-context-lora-for-diffusion-transformers</link>
      <description><![CDATA[While task-specific in terms of tuning data, our framework remains task-agnostic in architecture and pipeline, offering a powerful tool for the community and providing valuable insights for further research on product-level task-agnostic generation systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/in-context-lora-for-diffusion-transformers</guid>
    </item>
    <item>
      <title>REDUCIO! Generating 1024$\times$1024 Video within 16 Seconds using Extremely Compressed Motion Latents</title>
      <link>https://paperswithcode.com/paper/reducio-generating-1024-times-1024-video</link>
      <description><![CDATA[Commercial video generation models have exhibited realistic, high-fidelity results but are still restricted to limited access.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reducio-generating-1024-times-1024-video</guid>
    </item>
    <item>
      <title>Qwen2.5-Coder Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-5-coder-technical-report</link>
      <description><![CDATA[In this report, we introduce the Qwen2. 5-Coder series, a significant upgrade from its predecessor, CodeQwen1. 5.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-5-coder-technical-report</guid>
    </item>
    <item>
      <title>TransVIP: Speech to Speech Translation System with Voice and Isochrony Preservation</title>
      <link>https://paperswithcode.com/paper/transvip-speech-to-speech-translation-system</link>
      <description><![CDATA[There is a rising interest and trend in research towards directly translating speech from one language to another, known as end-to-end speech-to-speech translation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transvip-speech-to-speech-translation-system</guid>
    </item>
    <item>
      <title>D-FINE: Redefine Regression Task in DETRs as Fine-grained Distribution Refinement</title>
      <link>https://paperswithcode.com/paper/d-fine-redefine-regression-task-in-detrs-as</link>
      <description><![CDATA[When pretrained on Objects365, D-FINE-L / X attains 57. 1% / 59. 3% AP, surpassing all existing real-time detectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/d-fine-redefine-regression-task-in-detrs-as</guid>
    </item>
    <item>
      <title>Learning to Fly in Seconds</title>
      <link>https://paperswithcode.com/paper/learning-to-fly-in-seconds</link>
      <description><![CDATA[Our framework enables Simulation-to-Reality (Sim2Real) transfer for direct RPM control after only 18 seconds of training on a consumer-grade laptop as well as its deployment on microcontrollers to control a multirotor under real-time guarantees.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-fly-in-seconds</guid>
    </item>
    <item>
      <title>Region-Aware Text-to-Image Generation via Hard Binding and Soft Refinement</title>
      <link>https://paperswithcode.com/paper/region-aware-text-to-image-generation-via</link>
      <description><![CDATA[Regional prompting, or compositional generation, which enables fine-grained spatial control, has gained increasing attention for its practicality in real-world applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/region-aware-text-to-image-generation-via</guid>
    </item>
    <item>
      <title>StableV2V: Stablizing Shape Consistency in Video-to-Video Editing</title>
      <link>https://paperswithcode.com/paper/stablev2v-stablizing-shape-consistency-in</link>
      <description><![CDATA[Recent advancements of generative AI have significantly promoted content creation and editing, where prevailing studies further extend this exciting progress to video editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stablev2v-stablizing-shape-consistency-in</guid>
    </item>
    <item>
      <title>LightRAG: Simple and Fast Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/lightrag-simple-and-fast-retrieval-augmented</link>
      <description><![CDATA[Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by integrating external knowledge sources, enabling more accurate and contextually relevant responses tailored to user needs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightrag-simple-and-fast-retrieval-augmented</guid>
    </item>
    <item>
      <title>LLM2CLIP: Powerful Language Model Unlocks Richer Visual Representation</title>
      <link>https://paperswithcode.com/paper/llm2clip-powerful-language-model-unlock</link>
      <description><![CDATA[In this paper, we propose LLM2CLIP, a novel approach that embraces the power of LLMs to unlock CLIP's potential.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm2clip-powerful-language-model-unlock</guid>
    </item>
    <item>
      <title>WhisperNER: Unified Open Named Entity and Speech Recognition</title>
      <link>https://paperswithcode.com/paper/whisperner-unified-open-named-entity-and</link>
      <description><![CDATA[In this paper, we introduce WhisperNER, a novel model that allows joint speech transcription and entity recognition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/whisperner-unified-open-named-entity-and</guid>
    </item>
    <item>
      <title>PromptFix: You Prompt and We Fix the Photo</title>
      <link>https://paperswithcode.com/paper/promptfix-you-prompt-and-we-fix-the-photo</link>
      <description><![CDATA[To address these limitations, we propose PromptFix, a comprehensive framework that enables diffusion models to follow human instructions to perform a wide variety of image-processing tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/promptfix-you-prompt-and-we-fix-the-photo</guid>
    </item>
    <item>
      <title>SageAttention2 Technical Report: Accurate 4 Bit Attention for Plug-and-play Inference Acceleration</title>
      <link>https://paperswithcode.com/paper/sageattention2-technical-report-accurate-4</link>
      <description><![CDATA[Second, we propose a method to smooth $Q$ and $V$, enhancing the accuracy of attention with INT4 $QK$ and FP8 $PV$.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sageattention2-technical-report-accurate-4</guid>
    </item>
    <item>
      <title>Cut Your Losses in Large-Vocabulary Language Models</title>
      <link>https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</link>
      <description><![CDATA[We implement a custom kernel that performs the matrix multiplications and the log-sum-exp reduction over the vocabulary in flash memory, making global memory consumption for the cross-entropy computation negligible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</guid>
    </item>
    <item>
      <title>SplatFormer: Point Transformer for Robust 3D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/splatformer-point-transformer-for-robust-3d</link>
      <description><![CDATA[To our knowledge, this is the first successful application of point transformers directly on 3DGS sets, surpassing the limitations of previous multi-scene training methods, which could handle only a restricted number of input views during inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/splatformer-point-transformer-for-robust-3d</guid>
    </item>
  </channel>
</rss>
