<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 27 Sep 2024 09:16:46 +0000</lastBuildDate>
    <item>
      <title>QA-MDT: Quality-aware Masked Diffusion Transformer for Enhanced Music Generation</title>
      <link>https://paperswithcode.com/paper/quality-aware-masked-diffusion-transformer</link>
      <description><![CDATA[In recent years, diffusion-based text-to-music (TTM) generation has gained prominence, offering an innovative approach to synthesizing musical content from textual descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quality-aware-masked-diffusion-transformer</guid>
    </item>
    <item>
      <title>StoryMaker: Towards Holistic Consistent Characters in Text-to-image Generation</title>
      <link>https://paperswithcode.com/paper/storymaker-towards-holistic-consistent</link>
      <description><![CDATA[However, the lack of holistic consistency in scenes with multiple characters hampers these methods' ability to create a cohesive narrative.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/storymaker-towards-holistic-consistent</guid>
    </item>
    <item>
      <title>3DTopia-XL: Scaling High-quality 3D Asset Generation via Primitive Diffusion</title>
      <link>https://paperswithcode.com/paper/3dtopia-xl-scaling-high-quality-3d-asset</link>
      <description><![CDATA[The increasing demand for high-quality 3D assets across various industries necessitates efficient and automated 3D content creation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dtopia-xl-scaling-high-quality-3d-asset</guid>
    </item>
    <item>
      <title>LLaMA-Omni: Seamless Speech Interaction with Large Language Models</title>
      <link>https://paperswithcode.com/paper/llama-omni-seamless-speech-interaction-with</link>
      <description><![CDATA[We build our model based on the latest Llama-3. 1-8B-Instruct model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-omni-seamless-speech-interaction-with</guid>
    </item>
    <item>
      <title>Kolmogorov-Arnold Transformer</title>
      <link>https://paperswithcode.com/paper/kolmogorov-arnold-transformer</link>
      <description><![CDATA[In this paper, we introduce the Kolmogorov-Arnold Transformer (KAT), a novel architecture that replaces MLP layers with Kolmogorov-Arnold Network (KAN) layers to enhance the expressiveness and performance of the model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kolmogorov-arnold-transformer</guid>
    </item>
    <item>
      <title>OmniGen: Unified Image Generation</title>
      <link>https://paperswithcode.com/paper/omnigen-unified-image-generation</link>
      <description><![CDATA[In this work, we introduce OmniGen, a new diffusion model for unified image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnigen-unified-image-generation</guid>
    </item>
    <item>
      <title>Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models</title>
      <link>https://paperswithcode.com/paper/assisting-in-writing-wikipedia-like-articles</link>
      <description><![CDATA[We study how to apply large language models to write grounded and organized long-form articles from scratch, with comparable breadth and depth to Wikipedia pages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/assisting-in-writing-wikipedia-like-articles</guid>
    </item>
    <item>
      <title>SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning</title>
      <link>https://paperswithcode.com/paper/sciagents-automating-scientific-discovery</link>
      <description><![CDATA[A key challenge in artificial intelligence is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sciagents-automating-scientific-discovery</guid>
    </item>
    <item>
      <title>Oryx MLLM: On-Demand Spatial-Temporal Understanding at Arbitrary Resolution</title>
      <link>https://paperswithcode.com/paper/oryx-mllm-on-demand-spatial-temporal</link>
      <description><![CDATA[Visual data comes in various forms, ranging from small icons of just a few pixels to long videos spanning hours.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oryx-mllm-on-demand-spatial-temporal</guid>
    </item>
    <item>
      <title>Qwen2 Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-technical-report</link>
      <description><![CDATA[This report introduces the Qwen2 series, the latest addition to our large language models and large multimodal models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-technical-report</guid>
    </item>
    <item>
      <title>On the Diagram of Thought</title>
      <link>https://paperswithcode.com/paper/on-the-diagram-of-thought</link>
      <description><![CDATA[We introduce Diagram of Thought (DoT), a framework that models iterative reasoning in large language models (LLMs) as the construction of a directed acyclic graph (DAG) within a single model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-diagram-of-thought</guid>
    </item>
    <item>
      <title>Internal Consistency and Self-Feedback in Large Language Models: A Survey</title>
      <link>https://paperswithcode.com/paper/internal-consistency-and-self-feedback-in</link>
      <description><![CDATA[In this paper, we use a unified perspective of internal consistency, offering explanations for reasoning deficiencies and hallucinations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internal-consistency-and-self-feedback-in</guid>
    </item>
    <item>
      <title>optillm</title>
      <link>https://github.com/codelion/optillm</link>
      <description><![CDATA[Optimizing inference proxy for LLMs]]></description>
      <guid isPermaLink="true">https://github.com/codelion/optillm</guid>
    </item>
    <item>
      <title>Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution</title>
      <link>https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</link>
      <description><![CDATA[We present the Qwen2-VL Series, an advanced upgrade of the previous Qwen-VL models that redefines the conventional predetermined-resolution approach in visual processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</guid>
    </item>
    <item>
      <title>MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery</title>
      <link>https://paperswithcode.com/paper/memorag-moving-towards-next-gen-rag-via</link>
      <description><![CDATA[Retrieval-Augmented Generation (RAG) leverages retrieval tools to access external databases, thereby enhancing the generation quality of large language models (LLMs) through optimized context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memorag-moving-towards-next-gen-rag-via</guid>
    </item>
    <item>
      <title>Dynamic 2D Gaussians: Geometrically accurate radiance fields for dynamic objects</title>
      <link>https://paperswithcode.com/paper/dynamic-2d-gaussians-geometrically-accurate</link>
      <description><![CDATA[In this paper, we propose a novel representation that can reconstruct accurate meshes from sparse image input, named Dynamic 2D Gaussians (D-2DGS).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-2d-gaussians-geometrically-accurate</guid>
    </item>
    <item>
      <title>Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts</title>
      <link>https://paperswithcode.com/paper/time-moe-billion-scale-time-series-foundation</link>
      <description><![CDATA[However, despite the success of large-scale pre-training in language and vision domains, pre-trained time series models remain limited in scale and operate at a high cost, hindering the development of larger capable forecasting models in real-world applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/time-moe-billion-scale-time-series-foundation</guid>
    </item>
    <item>
      <title>Fine-Tuning Image-Conditional Diffusion Models is Easier than You Think</title>
      <link>https://paperswithcode.com/paper/fine-tuning-image-conditional-diffusion</link>
      <description><![CDATA[Recent work showed that large diffusion models can be reused as highly precise monocular depth estimators by casting depth estimation as an image-conditional image generation task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-image-conditional-diffusion</guid>
    </item>
    <item>
      <title>SoundStorm: Efficient Parallel Audio Generation</title>
      <link>https://paperswithcode.com/paper/soundstorm-efficient-parallel-audio</link>
      <description><![CDATA[We present SoundStorm, a model for efficient, non-autoregressive audio generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/soundstorm-efficient-parallel-audio</guid>
    </item>
    <item>
      <title>3DGS-LM: Faster Gaussian-Splatting Optimization with Levenberg-Marquardt</title>
      <link>https://paperswithcode.com/paper/3dgs-lm-faster-gaussian-splatting</link>
      <description><![CDATA[We present 3DGS-LM, a new method that accelerates the reconstruction of 3D Gaussian Splatting (3DGS) by replacing its ADAM optimizer with a tailored Levenberg-Marquardt (LM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dgs-lm-faster-gaussian-splatting</guid>
    </item>
  </channel>
</rss>
