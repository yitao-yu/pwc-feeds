<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 11 Mar 2024 21:07:32 +0000</lastBuildDate>
    <item>
      <title>TripoSR: Fast 3D Object Reconstruction from a Single Image</title>
      <link>https://paperswithcode.com/paper/triposr-fast-3d-object-reconstruction-from-a</link>
      <description><![CDATA[This technical report introduces TripoSR, a 3D reconstruction model leveraging transformer architecture for fast feed-forward 3D generation, producing 3D mesh from a single image in under 0. 5 seconds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triposr-fast-3d-object-reconstruction-from-a</guid>
    </item>
    <item>
      <title>GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection</title>
      <link>https://paperswithcode.com/paper/galore-memory-efficient-llm-training-by</link>
      <description><![CDATA[Our approach reduces memory usage by up to 65. 5% in optimizer states while maintaining both efficiency and performance for pre-training on LLaMA 1B and 7B architectures with C4 dataset with up to 19. 7B tokens, and on fine-tuning RoBERTa on GLUE tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/galore-memory-efficient-llm-training-by</guid>
    </item>
    <item>
      <title>DUSt3R: Geometric 3D Vision Made Easy</title>
      <link>https://paperswithcode.com/paper/dust3r-geometric-3d-vision-made-easy</link>
      <description><![CDATA[Our formulation directly provides a 3D model of the scene as well as depth information, but interestingly, we can seamlessly recover from it, pixel matches, relative and absolute camera.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dust3r-geometric-3d-vision-made-easy</guid>
    </item>
    <item>
      <title>Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study</title>
      <link>https://paperswithcode.com/paper/towards-general-computer-control-a-multimodal</link>
      <description><![CDATA[Despite the success in specific tasks and scenarios, existing foundation agents, empowered by large models (LMs) and advanced tools, still cannot generalize to different scenarios, mainly due to dramatic differences in the observations and actions across scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-general-computer-control-a-multimodal</guid>
    </item>
    <item>
      <title>MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training</title>
      <link>https://paperswithcode.com/paper/mobileclip-fast-image-text-models-through</link>
      <description><![CDATA[We further demonstrate the effectiveness of our multi-modal reinforced training by training a CLIP model based on ViT-B/16 image backbone and achieving +2. 9% average performance improvement on 38 evaluation benchmarks compared to the previous best.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobileclip-fast-image-text-models-through</guid>
    </item>
    <item>
      <title>Revisiting Feature Prediction for Learning Visual Representations from Video</title>
      <link>https://paperswithcode.com/paper/revisiting-feature-prediction-for-learning</link>
      <description><![CDATA[This paper explores feature prediction as a stand-alone objective for unsupervised learning from video and introduces V-JEPA, a collection of vision models trained solely using a feature prediction objective, without the use of pretrained image encoders, text, negative examples, reconstruction, or other sources of supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-feature-prediction-for-learning</guid>
    </item>
    <item>
      <title>Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People</title>
      <link>https://paperswithcode.com/paper/apollo-lightweight-multilingual-medical-llms</link>
      <description><![CDATA[Despite the vast repository of global medical knowledge predominantly being in English, local languages are crucial for delivering tailored healthcare services, particularly in areas with limited medical resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/apollo-lightweight-multilingual-medical-llms</guid>
    </item>
    <item>
      <title>GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer</title>
      <link>https://paperswithcode.com/paper/gliner-generalist-model-for-named-entity</link>
      <description><![CDATA[Named Entity Recognition (NER) is essential in various Natural Language Processing (NLP) applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gliner-generalist-model-for-named-entity</guid>
    </item>
    <item>
      <title>Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation</title>
      <link>https://paperswithcode.com/paper/learning-to-generate-instruction-tuning</link>
      <description><![CDATA[Overall, we show that learning with synthetic instruction tuning datasets is an effective way to adapt language models to new domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-generate-instruction-tuning</guid>
    </item>
    <item>
      <title>3D Diffusion Policy</title>
      <link>https://paperswithcode.com/paper/3d-diffusion-policy</link>
      <description><![CDATA[Imitation learning provides an efficient way to teach robots dexterous skills; however, learning complex skills robustly and generalizablely usually consumes large amounts of human demonstrations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-diffusion-policy</guid>
    </item>
    <item>
      <title>Feast Your Eyes: Mixture-of-Resolution Adaptation for Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/feast-your-eyes-mixture-of-resolution</link>
      <description><![CDATA[Contrary to previous works, we study this problem from the perspective of image resolution, and reveal that a combination of low- and high-resolution visual features can effectively mitigate this shortcoming.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/feast-your-eyes-mixture-of-resolution</guid>
    </item>
    <item>
      <title>ViewDiff: 3D-Consistent Image Generation with Text-to-Image Models</title>
      <link>https://paperswithcode.com/paper/viewdiff-3d-consistent-image-generation-with</link>
      <description><![CDATA[In this paper, we present a method that leverages pretrained text-to-image models as a prior, and learn to generate multi-view images in a single denoising process from real-world data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/viewdiff-3d-consistent-image-generation-with</guid>
    </item>
    <item>
      <title>LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error</title>
      <link>https://paperswithcode.com/paper/llms-in-the-imaginarium-tool-learning-through</link>
      <description><![CDATA[We find that existing LLMs, including GPT-4 and open-source LLMs specifically fine-tuned for tool use, only reach a correctness rate in the range of 30% to 60%, far from reliable use in practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llms-in-the-imaginarium-tool-learning-through</guid>
    </item>
    <item>
      <title>RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval</title>
      <link>https://paperswithcode.com/paper/raptor-recursive-abstractive-processing-for</link>
      <description><![CDATA[Retrieval-augmented language models can better adapt to changes in world state and incorporate long-tail knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/raptor-recursive-abstractive-processing-for</guid>
    </item>
    <item>
      <title>AgentLite: A Lightweight Library for Building and Advancing Task-Oriented LLM Agent System</title>
      <link>https://paperswithcode.com/paper/agentlite-a-lightweight-library-for-building</link>
      <description><![CDATA[Thus, we open-source a new AI agent library, AgentLite, which simplifies this process by offering a lightweight, user-friendly platform for innovating LLM agent reasoning, architectures, and applications with ease.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentlite-a-lightweight-library-for-building</guid>
    </item>
    <item>
      <title>ResAdapter: Domain Consistent Resolution Adapter for Diffusion Models</title>
      <link>https://paperswithcode.com/paper/resadapter-domain-consistent-resolution</link>
      <description><![CDATA[Especially, after learning a deep understanding of pure resolution priors, ResAdapter trained on the general dataset, generates resolution-free images with personalized diffusion models while preserving their original style domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/resadapter-domain-consistent-resolution</guid>
    </item>
    <item>
      <title>OOTDiffusion: Outfitting Fusion based Latent Diffusion for Controllable Virtual Try-on</title>
      <link>https://paperswithcode.com/paper/ootdiffusion-outfitting-fusion-based-latent</link>
      <description><![CDATA[We present OOTDiffusion, a novel network architecture for realistic and controllable image-based virtual try-on (VTON).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ootdiffusion-outfitting-fusion-based-latent</guid>
    </item>
    <item>
      <title>Retrieval-Augmented Generation for AI-Generated Content: A Survey</title>
      <link>https://paperswithcode.com/paper/retrieval-augmented-generation-for-ai</link>
      <description><![CDATA[Furthermore, we introduce the benchmarks for RAG, discuss the limitations of current RAG systems, and suggest potential directions for future research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retrieval-augmented-generation-for-ai</guid>
    </item>
    <item>
      <title>MedMamba: Vision Mamba for Medical Image Classification</title>
      <link>https://paperswithcode.com/paper/medmamba-vision-mamba-for-medical-image</link>
      <description><![CDATA[Medical image classification is a very fundamental and crucial task in the field of computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medmamba-vision-mamba-for-medical-image</guid>
    </item>
    <item>
      <title>Learning to Decode Collaboratively with Multiple Language Models</title>
      <link>https://paperswithcode.com/paper/learning-to-decode-collaboratively-with</link>
      <description><![CDATA[We propose a method to teach multiple large language models (LLM) to collaborate by interleaving their generations at the token level.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-decode-collaboratively-with</guid>
    </item>
  </channel>
</rss>
