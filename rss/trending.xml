<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 01 Mar 2023 21:07:13 +0000</lastBuildDate>
    <item>
      <title>The Forward-Forward Algorithm: Some Preliminary Investigations</title>
      <link>https://paperswithcode.com/paper/the-forward-forward-algorithm-some-1</link>
      <description><![CDATA[The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth further investigation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-forward-forward-algorithm-some-1</guid>
    </item>
    <item>
      <title>Discovering faster matrix multiplication algorithms with reinforcement learning</title>
      <link>https://paperswithcode.com/paper/discovering-faster-matrix-multiplication</link>
      <description><![CDATA[Particularly relevant is the case of 4 × 4 matrices in a finite field, where AlphaTensor’s algorithm improves on Strassen’s two-level algorithm for the first time, to our knowledge, since its discovery 50 years ago2.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/discovering-faster-matrix-multiplication</guid>
    </item>
    <item>
      <title>Composer: Creative and Controllable Image Synthesis with Composable Conditions</title>
      <link>https://paperswithcode.com/paper/composer-creative-and-controllable-image</link>
      <description><![CDATA[Recent large-scale generative models learned on big data are capable of synthesizing incredible images yet suffer from limited controllability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/composer-creative-and-controllable-image</guid>
    </item>
    <item>
      <title>Adding Conditional Control to Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/adding-conditional-control-to-text-to-image</link>
      <description><![CDATA[Moreover, training a ControlNet is as fast as fine-tuning a diffusion model, and the model can be trained on a personal devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adding-conditional-control-to-text-to-image</guid>
    </item>
    <item>
      <title>ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth</title>
      <link>https://paperswithcode.com/paper/zoedepth-zero-shot-transfer-by-combining</link>
      <description><![CDATA[Finally, ZoeD-M12-NK is the first model that can jointly train on multiple datasets (NYU Depth v2 and KITTI) without a significant drop in performance and achieve unprecedented zero-shot generalization performance to eight unseen datasets from both indoor and outdoor domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zoedepth-zero-shot-transfer-by-combining</guid>
    </item>
    <item>
      <title>VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion</title>
      <link>https://paperswithcode.com/paper/voxformer-sparse-voxel-transformer-for-camera</link>
      <description><![CDATA[To enable such capability in AI systems, we propose VoxFormer, a Transformer-based semantic scene completion framework that can output complete 3D volumetric semantics from only 2D images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/voxformer-sparse-voxel-transformer-for-camera</guid>
    </item>
    <item>
      <title>Multimodal Chain-of-Thought Reasoning in Language Models</title>
      <link>https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</link>
      <description><![CDATA[Large language models (LLMs) have shown impressive performance on complex reasoning by leveraging chain-of-thought (CoT) prompting to generate intermediate reasoning chains as the rationale to infer the answer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</guid>
    </item>
    <item>
      <title>SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/spikegpt-generative-pre-trained-language</link>
      <description><![CDATA[Spiking neural networks (SNNs) have emerged as an energy-efficient approach to deep learning that leverage sparse and event-driven activations to reduce the computational overhead associated with model inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spikegpt-generative-pre-trained-language</guid>
    </item>
    <item>
      <title>AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities</title>
      <link>https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</link>
      <description><![CDATA[In this work, we present a conceptually simple and effective method to train a strong bilingual/multilingual multimodal representation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</guid>
    </item>
    <item>
      <title>OccDepth: A Depth-Aware Method for 3D Semantic Scene Completion</title>
      <link>https://paperswithcode.com/paper/occdepth-a-depth-aware-method-for-3d-semantic</link>
      <description><![CDATA[3D Semantic Scene Completion (SSC) can provide dense geometric and semantic scene representations, which can be applied in the field of autonomous driving and robotic systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/occdepth-a-depth-aware-method-for-3d-semantic</guid>
    </item>
    <item>
      <title>More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models</title>
      <link>https://paperswithcode.com/paper/more-than-you-ve-asked-for-a-comprehensive</link>
      <description><![CDATA[In such attacks, an adversary can prompt the LLM to produce malicious content or override the original instructions and the employed filtering schemes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/more-than-you-ve-asked-for-a-comprehensive</guid>
    </item>
    <item>
      <title>SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</link>
      <description><![CDATA[We propose SmoothQuant, a training-free, accuracy-preserving, and general-purpose post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit activation (W8A8) quantization for LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</guid>
    </item>
    <item>
      <title>Language-Driven Representation Learning for Robotics</title>
      <link>https://paperswithcode.com/paper/language-driven-representation-learning-for</link>
      <description><![CDATA[First, we demonstrate that existing representations yield inconsistent results across these tasks: masked autoencoding approaches pick up on low-level spatial features at the cost of high-level semantics, while contrastive learning approaches capture the opposite.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-driven-representation-learning-for</guid>
    </item>
    <item>
      <title>Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers</title>
      <link>https://paperswithcode.com/paper/why-can-gpt-learn-in-context-language-models</link>
      <description><![CDATA[In order to better understand how ICL works, this paper explains language models as meta-optimizers and understands ICL as a kind of implicit finetuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/why-can-gpt-learn-in-context-language-models</guid>
    </item>
    <item>
      <title>BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining</title>
      <link>https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</link>
      <description><![CDATA[Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</guid>
    </item>
    <item>
      <title>MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation</title>
      <link>https://paperswithcode.com/paper/multidiffusion-fusing-diffusion-paths-for</link>
      <description><![CDATA[In this work, we present MultiDiffusion, a unified framework that enables versatile and controllable image generation, using a pre-trained text-to-image diffusion model, without any further training or finetuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multidiffusion-fusing-diffusion-paths-for</guid>
    </item>
    <item>
      <title>Aligning Bag of Regions for Open-Vocabulary Object Detection</title>
      <link>https://paperswithcode.com/paper/aligning-bag-of-regions-for-open-vocabulary</link>
      <description><![CDATA[The embeddings of regions in a bag are treated as embeddings of words in a sentence, and they are sent to the text encoder of a VLM to obtain the bag-of-regions embedding, which is learned to be aligned to the corresponding features extracted by a frozen VLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-bag-of-regions-for-open-vocabulary</guid>
    </item>
    <item>
      <title>Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models</title>
      <link>https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</link>
      <description><![CDATA[To address these challenges, we introduce a system that can jointly optimize distributed execution and gradient checkpointing plans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>LODE: Locally Conditioned Eikonal Implicit Scene Completion from Sparse LiDAR</title>
      <link>https://paperswithcode.com/paper/lode-locally-conditioned-eikonal-implicit</link>
      <description><![CDATA[In this paper, we propose a novel Eikonal formulation that conditions the implicit representation on localized shape priors which function as dense boundary value constraints, and demonstrate it works on SemanticKITTI and SemanticPOSS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lode-locally-conditioned-eikonal-implicit</guid>
    </item>
  </channel>
</rss>
