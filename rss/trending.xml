<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 28 Jun 2023 09:13:31 +0000</lastBuildDate>
    <item>
      <title>Fast Segment Anything</title>
      <link>https://paperswithcode.com/paper/fast-segment-anything</link>
      <description><![CDATA[In this paper, we propose a speed-up alternative method for this fundamental task with comparable performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-segment-anything</guid>
    </item>
    <item>
      <title>LightGlue: Local Feature Matching at Light Speed</title>
      <link>https://paperswithcode.com/paper/lightglue-local-feature-matching-at-light</link>
      <description><![CDATA[We introduce LightGlue, a deep neural network that learns to match local features across images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightglue-local-feature-matching-at-light</guid>
    </item>
    <item>
      <title>PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360$^{\circ}$</title>
      <link>https://paperswithcode.com/paper/panohead-geometry-aware-3d-full-head</link>
      <description><![CDATA[We propose PanoHead, the first 3D-aware generative model that enables high-quality view-consistent image synthesis of full heads in $360^\circ$ with diverse appearance and detailed geometry using only in-the-wild unstructured images for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/panohead-geometry-aware-3d-full-head</guid>
    </item>
    <item>
      <title>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</title>
      <link>https://paperswithcode.com/paper/drag-your-gan-interactive-point-based</link>
      <description><![CDATA[Synthesizing visual content that meets users' needs often requires flexible and precise controllability of the pose, shape, expression, and layout of the generated objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drag-your-gan-interactive-point-based</guid>
    </item>
    <item>
      <title>Planning-oriented Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/goal-oriented-autonomous-driving</link>
      <description><![CDATA[Oriented at this, we revisit the key components within perception and prediction, and prioritize the tasks such that all these tasks contribute to planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/goal-oriented-autonomous-driving</guid>
    </item>
    <item>
      <title>A Survey on Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-on-multimodal-large-language-models</link>
      <description><![CDATA[Multimodal Large Language Model (MLLM) recently has been a new rising research hotspot, which uses powerful Large Language Models (LLMs) as a brain to perform multimodal tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-multimodal-large-language-models</guid>
    </item>
    <item>
      <title>WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences</title>
      <link>https://paperswithcode.com/paper/webglm-towards-an-efficient-web-enhanced</link>
      <description><![CDATA[We present WebGLM, a web-enhanced question-answering system based on the General Language Model (GLM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/webglm-towards-an-efficient-web-enhanced</guid>
    </item>
    <item>
      <title>WizardCoder: Empowering Code Large Language Models with Evol-Instruct</title>
      <link>https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language</link>
      <description><![CDATA[Moreover, our model even outperforms the largest closed LLMs, Anthropic's Claude and Google's Bard, on HumanEval and HumanEval+.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language</guid>
    </item>
    <item>
      <title>FinGPT: Open-Source Financial Large Language Models</title>
      <link>https://paperswithcode.com/paper/fingpt-open-source-financial-large-language</link>
      <description><![CDATA[While proprietary models like BloombergGPT have taken advantage of their unique data accumulation, such privileged access calls for an open-source alternative to democratize Internet-scale financial data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fingpt-open-source-financial-large-language</guid>
    </item>
    <item>
      <title>WizMap: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings</title>
      <link>https://paperswithcode.com/paper/wizmap-scalable-interactive-visualization-for</link>
      <description><![CDATA[Machine learning models often learn latent embedding representations that capture the domain semantics of their training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wizmap-scalable-interactive-visualization-for</guid>
    </item>
    <item>
      <title>ToolQA: A Dataset for LLM Question Answering with External Tools</title>
      <link>https://paperswithcode.com/paper/toolqa-a-dataset-for-llm-question-answering</link>
      <description><![CDATA[To address this issue, we introduce a new dataset called ToolQA, which is designed to faithfully evaluate LLMs' ability to use external tools for question answering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toolqa-a-dataset-for-llm-question-answering</guid>
    </item>
    <item>
      <title>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</title>
      <link>https://paperswithcode.com/paper/direct-preference-optimization-your-language</link>
      <description><![CDATA[However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct-preference-optimization-your-language</guid>
    </item>
    <item>
      <title>Faster Segment Anything: Towards Lightweight SAM for Mobile Applications</title>
      <link>https://paperswithcode.com/paper/faster-segment-anything-towards-lightweight</link>
      <description><![CDATA[Concretely, we distill the knowledge from the image encoder ViT-H in the original SAM to a lightweight image encoder, which can be automatically compatible with the mask decoder in the original SAM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/faster-segment-anything-towards-lightweight</guid>
    </item>
    <item>
      <title>Bring Your Own Data! Self-Supervised Evaluation for Large Language Models</title>
      <link>https://paperswithcode.com/paper/bring-your-own-data-self-supervised</link>
      <description><![CDATA[With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bring-your-own-data-self-supervised</guid>
    </item>
    <item>
      <title>Enlighten Anything: When Segment Anything Model Meets Low-Light Image Enhancement</title>
      <link>https://paperswithcode.com/paper/enlighten-anything-when-segment-anything</link>
      <description><![CDATA[Image restoration is a low-level visual task, and most CNN methods are designed as black boxes, lacking transparency and intrinsic aesthetics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enlighten-anything-when-segment-anything</guid>
    </item>
    <item>
      <title>Full Parameter Fine-tuning for Large Language Models with Limited Resources</title>
      <link>https://paperswithcode.com/paper/full-parameter-fine-tuning-for-large-language</link>
      <description><![CDATA[Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but demand massive GPU resources for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/full-parameter-fine-tuning-for-large-language</guid>
    </item>
    <item>
      <title>Data-Copilot: Bridging Billions of Data and Humans with Autonomous Workflow</title>
      <link>https://paperswithcode.com/paper/data-copilot-bridging-billions-of-data-and</link>
      <description><![CDATA[Various industries such as finance, meteorology, and energy generate vast amounts of heterogeneous data every day.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-copilot-bridging-billions-of-data-and</guid>
    </item>
    <item>
      <title>From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought</title>
      <link>https://paperswithcode.com/paper/from-word-models-to-world-models-translating</link>
      <description><![CDATA[Our architecture integrates two computational tools that have not previously come together: we model thinking with probabilistic programs, an expressive representation for commonsense reasoning; and we model meaning construction with large language models (LLMs), which support broad-coverage translation from natural language utterances to code expressions in a probabilistic programming language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-word-models-to-world-models-translating</guid>
    </item>
    <item>
      <title>FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</title>
      <link>https://paperswithcode.com/paper/flashattention-fast-and-memory-efficient</link>
      <description><![CDATA[We also extend FlashAttention to block-sparse attention, yielding an approximate attention algorithm that is faster than any existing approximate attention method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flashattention-fast-and-memory-efficient</guid>
    </item>
    <item>
      <title>A Novel Correlation-optimized Deep Learning Method for Wind Speed Forecast</title>
      <link>https://paperswithcode.com/paper/a-novel-deep-knowledge-based-learning-method</link>
      <description><![CDATA[Finally, the effectiveness of the proposed method is verified by three wind prediction cases from a wind farm in Liaoning, China.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-novel-deep-knowledge-based-learning-method</guid>
    </item>
  </channel>
</rss>
