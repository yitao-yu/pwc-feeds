<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 23 Aug 2023 21:06:19 +0000</lastBuildDate>
    <item>
      <title>CoDeF: Content Deformation Fields for Temporally Consistent Video Processing</title>
      <link>https://paperswithcode.com/paper/codef-content-deformation-fields-for</link>
      <description><![CDATA[We present the content deformation field CoDeF as a new type of video representation, which consists of a canonical content field aggregating the static contents in the entire video and a temporal deformation field recording the transformations from the canonical image (i. e., rendered from the canonical content field) to each individual frame along the time axis. Given a target video, these two fields are jointly optimized to reconstruct it through a carefully tailored rendering pipeline. We advisedly introduce some regularizations into the optimization process, urging the canonical content field to inherit semantics (e. g., the object shape) from the video. With such a design, CoDeF naturally supports lifting image algorithms for video processing, in the sense that one can apply an image algorithm to the canonical image and effortlessly propagate the outcomes to the entire video with the aid of the temporal deformation field. We experimentally show that CoDeF is able to lift image-to-image translation to video-to-video translation and lift keypoint detection to keypoint tracking without any training. More importantly, thanks to our lifting strategy that deploys the algorithms on only one image, we achieve superior cross-frame consistency in processed videos compared to existing video-to-video translation approaches, and even manage to track non-rigid objects like water and smog. Project page can be found at https://qiuyu96. github. io/CoDeF/.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codef-content-deformation-fields-for</guid>
    </item>
    <item>
      <title>StableVideo: Text-driven Consistency-aware Diffusion Video Editing</title>
      <link>https://paperswithcode.com/paper/stablevideo-text-driven-consistency-aware</link>
      <description><![CDATA[In this paper, we tackle this problem by introducing temporal dependency to existing text-driven diffusion models, which allows them to generate consistent appearance for the edited objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stablevideo-text-driven-consistency-aware</guid>
    </item>
    <item>
      <title>FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization</title>
      <link>https://paperswithcode.com/paper/fastvit-a-fast-hybrid-vision-transformer</link>
      <description><![CDATA[To this end, we introduce a novel token mixing operator, RepMixer, a building block of FastViT, that uses structural reparameterization to lower the memory access cost by removing skip-connections in the network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fastvit-a-fast-hybrid-vision-transformer</guid>
    </item>
    <item>
      <title>Neuralangelo: High-Fidelity Neural Surface Reconstruction</title>
      <link>https://paperswithcode.com/paper/neuralangelo-high-fidelity-neural-surface-1</link>
      <description><![CDATA[Neural surface reconstruction has been shown to be powerful for recovering dense 3D surfaces via image-based neural rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuralangelo-high-fidelity-neural-surface-1</guid>
    </item>
    <item>
      <title>3D Gaussian Splatting for Real-Time Radiance Field Rendering</title>
      <link>https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</link>
      <description><![CDATA[Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</guid>
    </item>
    <item>
      <title>An Open-Source LoRa Physical Layer Prototype on GNU Radio</title>
      <link>https://paperswithcode.com/paper/an-open-source-lora-physical-layer-prototype</link>
      <description><![CDATA[LoRa is the proprietary physical layer (PHY) of LoRaWAN, which is a popular Internet-of-Things (IoT) protocol enabling low-power devices to communicate over long ranges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-open-source-lora-physical-layer-prototype</guid>
    </item>
    <item>
      <title>ChatHaruhi: Reviving Anime Character in Reality via Large Language Model</title>
      <link>https://paperswithcode.com/paper/chatharuhi-reviving-anime-character-in</link>
      <description><![CDATA[Role-playing chatbots built on large language models have drawn interest, but better techniques are needed to enable mimicking specific fictional characters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatharuhi-reviving-anime-character-in</guid>
    </item>
    <item>
      <title>Platypus: Quick, Cheap, and Powerful Refinement of LLMs</title>
      <link>https://paperswithcode.com/paper/platypus-quick-cheap-and-powerful-refinement</link>
      <description><![CDATA[We present $\textbf{Platypus}$, a family of fine-tuned and merged Large Language Models (LLMs) that achieves the strongest performance and currently stands at first place in HuggingFace's Open LLM Leaderboard as of the release date of this work.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/platypus-quick-cheap-and-powerful-refinement</guid>
    </item>
    <item>
      <title>SpecInfer: Accelerating Generative Large Language Model Serving with Speculative Inference and Token Tree Verification</title>
      <link>https://paperswithcode.com/paper/specinfer-accelerating-generative-llm-serving</link>
      <description><![CDATA[A key insight behind Specinfer is to combine various collectively boost-tuned small language models to jointly predict the LLM's outputs; the predictions are organized as a token tree, whose nodes each represent a candidate token sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/specinfer-accelerating-generative-llm-serving</guid>
    </item>
    <item>
      <title>Graph of Thoughts: Solving Elaborate Problems with Large Language Models</title>
      <link>https://paperswithcode.com/paper/graph-of-thoughts-solving-elaborate-problems</link>
      <description><![CDATA[We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-of-thoughts-solving-elaborate-problems</guid>
    </item>
    <item>
      <title>GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher</title>
      <link>https://paperswithcode.com/paper/gpt-4-is-too-smart-to-be-safe-stealthy-chat</link>
      <description><![CDATA[We propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages -- ciphers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-4-is-too-smart-to-be-safe-stealthy-chat</guid>
    </item>
    <item>
      <title>Effective Whole-body Pose Estimation with Two-stages Distillation</title>
      <link>https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</link>
      <description><![CDATA[Different from the previous self-knowledge distillation, this stage finetunes the student's head with only 20% training time as a plug-and-play training strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</guid>
    </item>
    <item>
      <title>A Method for Animating Children's Drawings of the Human Figure</title>
      <link>https://paperswithcode.com/paper/a-method-for-automatically-animating-children</link>
      <description><![CDATA[Children's drawings have a wonderful inventiveness, creativity, and variety to them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-method-for-automatically-animating-children</guid>
    </item>
    <item>
      <title>Efficient Guided Generation for Large Language Models</title>
      <link>https://paperswithcode.com/paper/efficient-guided-generation-for-llms</link>
      <description><![CDATA[In this article we show how the problem of neural text generation can be constructively reformulated in terms of transitions between the states of a finite-state machine.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-guided-generation-for-llms</guid>
    </item>
    <item>
      <title>CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X</title>
      <link>https://paperswithcode.com/paper/codegeex-a-pre-trained-model-for-code</link>
      <description><![CDATA[Large pre-trained code generation models, such as OpenAI Codex, can generate syntax- and function-correct code, making the coding of programmers more productive and our pursuit of artificial general intelligence closer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codegeex-a-pre-trained-model-for-code</guid>
    </item>
    <item>
      <title>YOLO-MS: Rethinking Multi-Scale Representation Learning for Real-time Object Detection</title>
      <link>https://paperswithcode.com/paper/yolo-ms-rethinking-multi-scale-representation</link>
      <description><![CDATA[We aim at providing the object detection community with an efficient and performant object detector, termed YOLO-MS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-ms-rethinking-multi-scale-representation</guid>
    </item>
    <item>
      <title>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</title>
      <link>https://paperswithcode.com/paper/direct-preference-optimization-your-language</link>
      <description><![CDATA[However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct-preference-optimization-your-language</guid>
    </item>
    <item>
      <title>DeDoDe: Detect, Don't Describe -- Describe, Don't Detect for Local Feature Matching</title>
      <link>https://paperswithcode.com/paper/dedode-detect-don-t-describe-describe-don-t</link>
      <description><![CDATA[To train a descriptor, we maximize the mutual nearest neighbour objective over the keypoints with a separate network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dedode-detect-don-t-describe-describe-don-t</guid>
    </item>
    <item>
      <title>ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</title>
      <link>https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</link>
      <description><![CDATA[We first present ToolBench, an instruction-tuning dataset for tool use, which is created automatically using ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</guid>
    </item>
    <item>
      <title>MolFM: A Multimodal Molecular Foundation Model</title>
      <link>https://paperswithcode.com/paper/molfm-a-multimodal-molecular-foundation-model</link>
      <description><![CDATA[In this study, we introduce MolFM, a multimodal molecular foundation model designed to facilitate joint representation learning from molecular structures, biomedical texts, and knowledge graphs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/molfm-a-multimodal-molecular-foundation-model</guid>
    </item>
  </channel>
</rss>
