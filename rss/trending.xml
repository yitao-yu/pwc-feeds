<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 17 Feb 2025 09:17:39 +0000</lastBuildDate>
    <item>
      <title>Data Formulator 2: Iteratively Creating Rich Visualizations with AI</title>
      <link>https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</link>
      <description><![CDATA[To create rich visualizations, data analysts often need to iterate back and forth among data processing and chart specification to achieve their goals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</guid>
    </item>
    <item>
      <title>LLM4Decompile: Decompiling Binary Code with Large Language Models</title>
      <link>https://paperswithcode.com/paper/llm4decompile-decompiling-binary-code-with</link>
      <description><![CDATA[Decompilation aims to convert binary code to high-level source code, but traditional tools like Ghidra often produce results that are difficult to read and execute.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm4decompile-decompiling-binary-code-with</guid>
    </item>
    <item>
      <title>Cut Your Losses in Large-Vocabulary Language Models</title>
      <link>https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</link>
      <description><![CDATA[We implement a custom kernel that performs the matrix multiplications and the log-sum-exp reduction over the vocabulary in flash memory, making global memory consumption for the cross-entropy computation negligible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</guid>
    </item>
    <item>
      <title>Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach</title>
      <link>https://paperswithcode.com/paper/scaling-up-test-time-compute-with-latent</link>
      <description><![CDATA[We scale a proof-of-concept model to 3. 5 billion parameters and 800 billion tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-up-test-time-compute-with-latent</guid>
    </item>
    <item>
      <title>Light-A-Video: Training-free Video Relighting via Progressive Light Fusion</title>
      <link>https://paperswithcode.com/paper/light-a-video-training-free-video-relighting</link>
      <description><![CDATA[Second, leveraging the physical principle of light transport independence, we apply linear blending between the source video's appearance and the relighted appearance, using a Progressive Light Fusion (PLF) strategy to ensure smooth temporal transitions in illumination.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/light-a-video-training-free-video-relighting</guid>
    </item>
    <item>
      <title>Magic 1-For-1: Generating One Minute Video Clips within One Minute</title>
      <link>https://paperswithcode.com/paper/magic-1-for-1-generating-one-minute-video</link>
      <description><![CDATA[The key idea is simple: factorize the text-to-video generation task into two separate easier tasks for diffusion step distillation, namely text-to-image generation and image-to-video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magic-1-for-1-generating-one-minute-video</guid>
    </item>
    <item>
      <title>OmniParser for Pure Vision Based GUI Agent</title>
      <link>https://paperswithcode.com/paper/omniparser-for-pure-vision-based-gui-agent</link>
      <description><![CDATA[The recent success of large vision language models shows great potential in driving the agent system operating on user interfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omniparser-for-pure-vision-based-gui-agent</guid>
    </item>
    <item>
      <title>PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation</title>
      <link>https://paperswithcode.com/paper/pike-rag-specialized-knowledge-and-rationale</link>
      <description><![CDATA[Despite notable advancements in Retrieval-Augmented Generation (RAG) systems that expand large language model (LLM) capabilities through external retrieval, these systems often struggle to meet the complex and diverse needs of real-world industrial applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pike-rag-specialized-knowledge-and-rationale</guid>
    </item>
    <item>
      <title>Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research</title>
      <link>https://paperswithcode.com/paper/agentic-reasoning-reasoning-llms-with-tools</link>
      <description><![CDATA[We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentic-reasoning-reasoning-llms-with-tools</guid>
    </item>
    <item>
      <title>Flaming-hot Initiation with Regular Execution Sampling for Large Language Models</title>
      <link>https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</link>
      <description><![CDATA[Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</guid>
    </item>
    <item>
      <title>Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback</title>
      <link>https://paperswithcode.com/paper/align-anything-training-all-modality-models</link>
      <description><![CDATA[In this work, we make the first attempt to fine-tune all-modality models (i. e. input and output with any modality, also named any-to-any models) using human preference data across all modalities (including text, image, audio, and video), ensuring its behavior aligns with human intentions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/align-anything-training-all-modality-models</guid>
    </item>
    <item>
      <title>FireRedASR: Open-Source Industrial-Grade Mandarin Speech Recognition Models from Encoder-Decoder to LLM Integration</title>
      <link>https://paperswithcode.com/paper/fireredasr-open-source-industrial-grade</link>
      <description><![CDATA[We present FireRedASR, a family of large-scale automatic speech recognition (ASR) models for Mandarin, designed to meet diverse requirements in superior performance and optimal efficiency across various applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fireredasr-open-source-industrial-grade</guid>
    </item>
    <item>
      <title>On the Emergence of Thinking in LLMs I: Searching for the Right Intuition</title>
      <link>https://paperswithcode.com/paper/on-the-emergence-of-thinking-in-llms-i</link>
      <description><![CDATA[Lastly, we propose a theory as to why RLSP search strategy is more suitable for LLMs inspired by a remarkable result that says CoT provably increases computational power of LLMs, which grows as the number of steps in CoT \cite{li2024chain, merrill2023expresssive}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-emergence-of-thinking-in-llms-i</guid>
    </item>
    <item>
      <title>DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</link>
      <description><![CDATA[We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</guid>
    </item>
    <item>
      <title>LIMO: Less is More for Reasoning</title>
      <link>https://paperswithcode.com/paper/limo-less-is-more-for-reasoning</link>
      <description><![CDATA[While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (>100, 000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/limo-less-is-more-for-reasoning</guid>
    </item>
    <item>
      <title>MedRAX: Medical Reasoning Agent for Chest X-ray</title>
      <link>https://paperswithcode.com/paper/medrax-medical-reasoning-agent-for-chest-x</link>
      <description><![CDATA[Chest X-rays (CXRs) play an integral role in driving critical decisions in disease management and patient care.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medrax-medical-reasoning-agent-for-chest-x</guid>
    </item>
    <item>
      <title>Accelerating Data Processing and Benchmarking of AI Models for Pathology</title>
      <link>https://paperswithcode.com/paper/accelerating-data-processing-and-benchmarking</link>
      <description><![CDATA[Advances in foundation modeling have reshaped computational pathology.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-data-processing-and-benchmarking</guid>
    </item>
    <item>
      <title>Temporal Working Memory: Query-Guided Segment Refinement for Enhanced Multimodal Understanding</title>
      <link>https://paperswithcode.com/paper/temporal-working-memory-query-guided-segment</link>
      <description><![CDATA[To overcome these challenges, we introduce a specialized cognitive module, temporal working memory (TWM), which aims to enhance the temporal modeling capabilities of MFMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-working-memory-query-guided-segment</guid>
    </item>
    <item>
      <title>Meta Audiobox Aesthetics: Unified Automatic Quality Assessment for Speech, Music, and Sound</title>
      <link>https://paperswithcode.com/paper/meta-audiobox-aesthetics-unified-automatic</link>
      <description><![CDATA[The quantification of audio aesthetics remains a complex challenge in audio processing, primarily due to its subjective nature, which is influenced by human perception and cultural context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-audiobox-aesthetics-unified-automatic</guid>
    </item>
    <item>
      <title>MatterGen: a generative model for inorganic materials design</title>
      <link>https://paperswithcode.com/paper/mattergen-a-generative-model-for-inorganic</link>
      <description><![CDATA[We further introduce adapter modules to enable fine-tuning towards any given property constraints with a labeled dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mattergen-a-generative-model-for-inorganic</guid>
    </item>
  </channel>
</rss>
