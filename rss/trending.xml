<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 02 Sep 2023 09:09:59 +0000</lastBuildDate>
    <item>
      <title>Nougat: Neural Optical Understanding for Academic Documents</title>
      <link>https://paperswithcode.com/paper/nougat-neural-optical-understanding-for</link>
      <description><![CDATA[Scientific knowledge is predominantly stored in books and scientific journals, often in the form of PDFs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nougat-neural-optical-understanding-for</guid>
    </item>
    <item>
      <title>CoTracker: It is Better to Track Together</title>
      <link>https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</link>
      <description><![CDATA[In this paper, we thus propose CoTracker, an architecture that jointly tracks multiple points throughout an entire video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</guid>
    </item>
    <item>
      <title>AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/anomalygpt-detecting-industrial-anomalies</link>
      <description><![CDATA[Large Vision-Language Models (LVLMs) such as MiniGPT-4 and LLaVA have demonstrated the capability of understanding images and achieved remarkable performance in various visual tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anomalygpt-detecting-industrial-anomalies</guid>
    </item>
    <item>
      <title>Prompt2Model: Generating Deployable Models from Natural Language Instructions</title>
      <link>https://paperswithcode.com/paper/prompt2model-generating-deployable-models</link>
      <description><![CDATA[In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt2model-generating-deployable-models</guid>
    </item>
    <item>
      <title>Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities</title>
      <link>https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</link>
      <description><![CDATA[We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen-vl-a-frontier-large-vision-language</guid>
    </item>
    <item>
      <title>SeamlessM4T-Massively Multilingual &amp; Multimodal Machine Translation</title>
      <link>https://paperswithcode.com/paper/seamlessm4t-massively-multilingual-multimodal</link>
      <description><![CDATA[What does it take to create the Babel Fish, a tool that can help individuals translate speech between any two languages?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seamlessm4t-massively-multilingual-multimodal</guid>
    </item>
    <item>
      <title>A Survey on Large Language Model based Autonomous Agents</title>
      <link>https://paperswithcode.com/paper/a-survey-on-large-language-model-based</link>
      <description><![CDATA[Based on the previous studies, we also present several challenges and future directions in this field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-large-language-model-based</guid>
    </item>
    <item>
      <title>Code Llama: Open Foundation Models for Code</title>
      <link>https://paperswithcode.com/paper/code-llama-open-foundation-models-for-code</link>
      <description><![CDATA[We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/code-llama-open-foundation-models-for-code</guid>
    </item>
    <item>
      <title>Communicative Agents for Software Development</title>
      <link>https://paperswithcode.com/paper/communicative-agents-for-software-development</link>
      <description><![CDATA[At the core of this paradigm lies ChatDev, a virtual chat-powered software development company that mirrors the established waterfall model, meticulously dividing the development process into four distinct chronological stages: designing, coding, testing, and documenting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/communicative-agents-for-software-development</guid>
    </item>
    <item>
      <title>WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct</title>
      <link>https://paperswithcode.com/paper/wizardmath-empowering-mathematical-reasoning</link>
      <description><![CDATA[Through extensive experiments on two mathematical reasoning benchmarks, namely GSM8k and MATH, we reveal the extraordinary capabilities of our model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wizardmath-empowering-mathematical-reasoning</guid>
    </item>
    <item>
      <title>AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining</title>
      <link>https://paperswithcode.com/paper/audioldm-2-learning-holistic-audio-generation</link>
      <description><![CDATA[Any audio can be translated into LOA based on AudioMAE, a self-supervised pre-trained representation learning model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audioldm-2-learning-holistic-audio-generation</guid>
    </item>
    <item>
      <title>3D Gaussian Splatting for Real-Time Radiance Field Rendering</title>
      <link>https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</link>
      <description><![CDATA[Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</guid>
    </item>
    <item>
      <title>LLaSM: Large Language and Speech Model</title>
      <link>https://paperswithcode.com/paper/llasm-large-language-and-speech-model</link>
      <description><![CDATA[In this work, we propose Large Language and Speech Model (LLaSM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llasm-large-language-and-speech-model</guid>
    </item>
    <item>
      <title>OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/omniquant-omnidirectionally-calibrated</link>
      <description><![CDATA[To tackle this issue, we introduce an Omnidirectionally calibrated Quantization (OmniQuant) technique for LLMs, which achieves good performance in diverse quantization settings while maintaining the computational efficiency of PTQ by efficiently optimizing various quantization parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omniquant-omnidirectionally-calibrated</guid>
    </item>
    <item>
      <title>Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP</title>
      <link>https://paperswithcode.com/paper/demonstrate-search-predict-composing</link>
      <description><![CDATA[Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demonstrate-search-predict-composing</guid>
    </item>
    <item>
      <title>Dense Text-to-Image Generation with Attention Modulation</title>
      <link>https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</link>
      <description><![CDATA[To address this, we propose DenseDiffusion, a training-free method that adapts a pre-trained text-to-image model to handle such dense captions while offering control over the scene layout.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dense-text-to-image-generation-with-attention</guid>
    </item>
    <item>
      <title>Graph of Thoughts: Solving Elaborate Problems with Large Language Models</title>
      <link>https://paperswithcode.com/paper/graph-of-thoughts-solving-elaborate-problems</link>
      <description><![CDATA[We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graph-of-thoughts-solving-elaborate-problems</guid>
    </item>
    <item>
      <title>FaceChain: A Playground for Identity-Preserving Portrait Generation</title>
      <link>https://paperswithcode.com/paper/facechain-a-playground-for-identity</link>
      <description><![CDATA[In this paper, we present FaceChain, a personalized portrait generation framework that combines a series of customized image-generation model and a rich set of face-related perceptual understanding models (\eg, face detection, deep face embedding extraction, and facial attribute recognition), to tackle aforementioned challenges and to generate truthful personalized portraits, with only a handful of portrait images as input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/facechain-a-playground-for-identity</guid>
    </item>
    <item>
      <title>DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior</title>
      <link>https://paperswithcode.com/paper/diffbir-towards-blind-image-restoration-with</link>
      <description><![CDATA[We present DiffBIR, which leverages pretrained text-to-image diffusion models for blind image restoration problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffbir-towards-blind-image-restoration-with</guid>
    </item>
    <item>
      <title>Extending Context Window of Large Language Models via Positional Interpolation</title>
      <link>https://paperswithcode.com/paper/extending-context-window-of-large-language</link>
      <description><![CDATA[We present Position Interpolation (PI) that extends the context window sizes of RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal fine-tuning (within 1000 steps), while demonstrating strong empirical results on various tasks that require long context, including passkey retrieval, language modeling, and long document summarization from LLaMA 7B to 65B.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extending-context-window-of-large-language</guid>
    </item>
  </channel>
</rss>
