<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 07 Dec 2022 09:13:07 +0000</lastBuildDate>
    <item>
      <title>Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation</title>
      <link>https://paperswithcode.com/paper/score-jacobian-chaining-lifting-pretrained-2d</link>
      <description><![CDATA[We propose to apply chain rule on the learned gradients, and back-propagate the score of a diffusion model through the Jacobian of a differentiable renderer, which we instantiate to be a voxel radiance field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/score-jacobian-chaining-lifting-pretrained-2d</guid>
    </item>
    <item>
      <title>Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model</title>
      <link>https://paperswithcode.com/paper/zero-shot-image-restoration-using-denoising</link>
      <description><![CDATA[Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-image-restoration-using-denoising</guid>
    </item>
    <item>
      <title>ExtremeBERT: A Toolkit for Accelerating Pretraining of Customized BERT</title>
      <link>https://paperswithcode.com/paper/extremebert-a-toolkit-for-accelerating</link>
      <description><![CDATA[In this paper, we present ExtremeBERT, a toolkit for accelerating and customizing BERT pretraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extremebert-a-toolkit-for-accelerating</guid>
    </item>
    <item>
      <title>DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/diffusionbert-improving-generative-masked</link>
      <description><![CDATA[We present DiffusionBERT, a new generative masked language model based on discrete diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusionbert-improving-generative-masked</guid>
    </item>
    <item>
      <title>Images Speak in Images: A Generalist Painter for In-Context Visual Learning</title>
      <link>https://paperswithcode.com/paper/images-speak-in-images-a-generalist-painter</link>
      <description><![CDATA[In this work, we present Painter, a generalist model which addresses these obstacles with an "image"-centric solution, that is, to redefine the output of core vision tasks as images, and specify task prompts as also images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/images-speak-in-images-a-generalist-painter</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>Mixed Neural Voxels for Fast Multi-view Video Synthesis</title>
      <link>https://paperswithcode.com/paper/mixed-neural-voxels-for-fast-multi-view-video</link>
      <description><![CDATA[In this paper, we present a novel method named MixVoxels to better represent the dynamic scenes with fast training speed and competitive rendering qualities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixed-neural-voxels-for-fast-multi-view-video</guid>
    </item>
    <item>
      <title>MIC: Masked Image Consistency for Context-Enhanced Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/mic-masked-image-consistency-for-context</link>
      <description><![CDATA[MIC significantly improves the state-of-the-art performance across the different recognition tasks for synthetic-to-real, day-to-nighttime, and clear-to-adverse-weather UDA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mic-masked-image-consistency-for-context</guid>
    </item>
    <item>
      <title>GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images</title>
      <link>https://paperswithcode.com/paper/get3d-a-generative-model-of-high-quality-3d</link>
      <description><![CDATA[As several industries are moving towards modeling massive 3D virtual worlds, the need for content creation tools that can scale in terms of the quantity, quality, and diversity of 3D content is becoming evident.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/get3d-a-generative-model-of-high-quality-3d</guid>
    </item>
    <item>
      <title>Compressing Volumetric Radiance Fields to 1 MB</title>
      <link>https://paperswithcode.com/paper/compressing-volumetric-radiance-fields-to-1</link>
      <description><![CDATA[Approximating radiance fields with volumetric grids is one of promising directions for improving NeRF, represented by methods like Plenoxels and DVGO, which achieve super-fast training convergence and real-time rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compressing-volumetric-radiance-fields-to-1</guid>
    </item>
    <item>
      <title>DI-engine</title>
      <link>https://github.com/opendilab/DI-engine</link>
      <description><![CDATA[OpenDILab Decision AI Engine]]></description>
      <guid isPermaLink="true">https://github.com/opendilab/DI-engine</guid>
    </item>
    <item>
      <title>MeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition</title>
      <link>https://paperswithcode.com/paper/memvit-memory-augmented-multiscale-vision</link>
      <description><![CDATA[Instead of trying to process more frames at once like most existing methods, we propose to process videos in an online fashion and cache "memory" at each iteration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memvit-memory-augmented-multiscale-vision</guid>
    </item>
    <item>
      <title>Training language models to follow instructions with human feedback</title>
      <link>https://paperswithcode.com/paper/training-language-models-to-follow</link>
      <description><![CDATA[In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-language-models-to-follow</guid>
    </item>
    <item>
      <title>Multiresolution Textual Inversion</title>
      <link>https://paperswithcode.com/paper/multiresolution-textual-inversion</link>
      <description><![CDATA[We extend Textual Inversion to learn pseudo-words that represent a concept at different resolutions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiresolution-textual-inversion</guid>
    </item>
    <item>
      <title>TorchScale: Transformers at Scale</title>
      <link>https://paperswithcode.com/paper/torchscale-transformers-at-scale</link>
      <description><![CDATA[Large Transformers have achieved state-of-the-art performance across many tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchscale-transformers-at-scale</guid>
    </item>
    <item>
      <title>mindcv</title>
      <link>https://github.com/mindspore-ecosystem/mindcv</link>
      <description><![CDATA[A toolbox of vision models and algorithms based on MindSpore]]></description>
      <guid isPermaLink="true">https://github.com/mindspore-ecosystem/mindcv</guid>
    </item>
    <item>
      <title>Fast Sampling of Diffusion Models with Exponential Integrator</title>
      <link>https://paperswithcode.com/paper/fast-sampling-of-diffusion-models-with</link>
      <description><![CDATA[Our goal is to develop a fast sampling method for DMs with a much less number of steps while retaining high sample quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-sampling-of-diffusion-models-with</guid>
    </item>
    <item>
      <title>Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations</title>
      <link>https://paperswithcode.com/paper/triton-an-intermediate-language-and-compiler</link>
      <description><![CDATA[The validation and deployment of novel research ideas in the field of Deep Learning is often limited by the availability of efficient compute kernels for certain basic primitives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triton-an-intermediate-language-and-compiler</guid>
    </item>
    <item>
      <title>UIU-Net: U-Net in U-Net for Infrared Small Object Detection</title>
      <link>https://paperswithcode.com/paper/uiu-net-u-net-in-u-net-for-infrared-small</link>
      <description><![CDATA[RM-DS integrates Residual U-blocks into a deep supervision network to generate deep multi-scale resolution-maintenance features while learning global context information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uiu-net-u-net-in-u-net-for-infrared-small</guid>
    </item>
    <item>
      <title>Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection in Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/residual-pattern-learning-for-pixel-wise-out</link>
      <description><![CDATA[Semantic segmentation models classify pixels into a set of known (``in-distribution'') visual classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/residual-pattern-learning-for-pixel-wise-out</guid>
    </item>
  </channel>
</rss>
