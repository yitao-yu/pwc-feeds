<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 19 Jun 2022 21:07:04 +0000</lastBuildDate>
    <item>
      <title>Zero-Shot Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/zero-shot-text-to-image-generation</link>
      <description><![CDATA[Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-text-to-image-generation</guid>
    </item>
    <item>
      <title>CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers</title>
      <link>https://paperswithcode.com/paper/cogview2-faster-and-better-text-to-image</link>
      <description><![CDATA[The development of the transformer-based text-to-image models are impeded by its slow generation and complexity for high-resolution images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cogview2-faster-and-better-text-to-image</guid>
    </item>
    <item>
      <title>Implicit Sample Extension for Unsupervised Person Re-Identification</title>
      <link>https://paperswithcode.com/paper/implicit-sample-extension-for-unsupervised</link>
      <description><![CDATA[Specifically, we generate support samples from actual samples and their neighbouring clusters in the embedding space through a progressive linear interpolation (PLI) strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implicit-sample-extension-for-unsupervised</guid>
    </item>
    <item>
      <title>Multiplying Matrices Without Multiplying</title>
      <link>https://paperswithcode.com/paper/multiplying-matrices-without-multiplying</link>
      <description><![CDATA[Multiplying matrices is among the most fundamental and compute-intensive operations in machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiplying-matrices-without-multiplying</guid>
    </item>
    <item>
      <title>Spatially-Adaptive Multilayer Selection for GAN Inversion and Editing</title>
      <link>https://paperswithcode.com/paper/spatially-adaptive-multilayer-selection-for-1</link>
      <description><![CDATA[We propose a new method to invert and edit such complex images in the latent space of GANs, such as StyleGAN2.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spatially-adaptive-multilayer-selection-for-1</guid>
    </item>
    <item>
      <title>BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers</title>
      <link>https://paperswithcode.com/paper/bevformer-learning-bird-s-eye-view</link>
      <description><![CDATA[In a nutshell, BEVFormer exploits both spatial and temporal information by interacting with spatial and temporal space through predefined grid-shaped BEV queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bevformer-learning-bird-s-eye-view</guid>
    </item>
    <item>
      <title>Scaling Up Models and Data with $\texttt{t5x}$ and $\texttt{seqio}$</title>
      <link>https://paperswithcode.com/paper/scaling-up-models-and-data-with-texttt-t5x</link>
      <description><![CDATA[Recent neural network-based language models have benefited greatly from scaling up the size of training datasets and the number of parameters in the models themselves.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-up-models-and-data-with-texttt-t5x</guid>
    </item>
    <item>
      <title>Pythae: Unifying Generative Autoencoders in Python -- A Benchmarking Use Case</title>
      <link>https://paperswithcode.com/paper/pythae-unifying-generative-autoencoders-in</link>
      <description><![CDATA[In recent years, deep generative models have attracted increasing interest due to their capacity to model complex distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pythae-unifying-generative-autoencoders-in</guid>
    </item>
    <item>
      <title>Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt</title>
      <link>https://paperswithcode.com/paper/prioritized-training-on-points-that-are-1</link>
      <description><![CDATA[But most computation and time is wasted on redundant and noisy points that are already learnt or not learnable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prioritized-training-on-points-that-are-1</guid>
    </item>
    <item>
      <title>Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral Compressive Imaging</title>
      <link>https://paperswithcode.com/paper/degradation-aware-unfolding-half-shuffle</link>
      <description><![CDATA[In coded aperture snapshot spectral compressive imaging (CASSI) systems, hyperspectral image (HSI) reconstruction methods are employed to recover the spatial-spectral signal from a compressed measurement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/degradation-aware-unfolding-half-shuffle</guid>
    </item>
    <item>
      <title>Ivy: Templated Deep Learning for Inter-Framework Portability</title>
      <link>https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</link>
      <description><![CDATA[We introduce Ivy, a templated Deep Learning (DL) framework which abstracts existing DL frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</guid>
    </item>
    <item>
      <title>Variable Bitrate Neural Fields</title>
      <link>https://paperswithcode.com/paper/variable-bitrate-neural-fields</link>
      <description><![CDATA[Neural approximations of scalar and vector fields, such as signed distance functions and radiance fields, have emerged as accurate, high-quality representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/variable-bitrate-neural-fields</guid>
    </item>
    <item>
      <title>General-purpose, long-context autoregressive modeling with Perceiver AR</title>
      <link>https://paperswithcode.com/paper/general-purpose-long-context-autoregressive</link>
      <description><![CDATA[Real-world data is high-dimensional: a book, image, or musical performance can easily contain hundreds of thousands of elements even after compression.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/general-purpose-long-context-autoregressive</guid>
    </item>
    <item>
      <title>Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding</title>
      <link>https://paperswithcode.com/paper/photorealistic-text-to-image-diffusion-models</link>
      <description><![CDATA[We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photorealistic-text-to-image-diffusion-models</guid>
    </item>
    <item>
      <title>Online Segmentation of LiDAR Sequences: Dataset and Algorithm</title>
      <link>https://paperswithcode.com/paper/online-segmentation-of-lidar-sequences</link>
      <description><![CDATA[Helix4D operates on acquisition slices that correspond to a fraction of a full rotation of the sensor, significantly reducing the total latency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/online-segmentation-of-lidar-sequences</guid>
    </item>
    <item>
      <title>PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies</title>
      <link>https://paperswithcode.com/paper/pointnext-revisiting-pointnet-with-improved</link>
      <description><![CDATA[In this work, we revisit the classical PointNet++ through a systematic study of model training and scaling strategies, and offer two major contributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pointnext-revisiting-pointnet-with-improved</guid>
    </item>
    <item>
      <title>PaddleRec</title>
      <link>https://github.com/PaddlePaddle/PaddleRec</link>
      <description><![CDATA[Recommendation AlgorithmLRWide&DeepDSSMTDMMINDWord2VecBert4RecDeepWalkSSRAITMDSINSIGNIPRECGRU4RecYoutube_dnnNCFGNNFMFFMDeepFMDCNDINDIENDLRMMMOEPLEESMMESCMM, MAMLxDeepFMDeepFEFMNFMAFMRALMDMRGateNetNAMLDIFMDeep CrossingPNNBSTAutoIntFGCNNFLENFibinetListWiseDeepRecENSFMTiSASAutoFIScriteo movielens]]></description>
      <guid isPermaLink="true">https://github.com/PaddlePaddle/PaddleRec</guid>
    </item>
    <item>
      <title>SaRNet: A Dataset for Deep Learning Assisted Search and Rescue with Satellite Imagery</title>
      <link>https://paperswithcode.com/paper/sarnet-a-dataset-for-deep-learning-assisted</link>
      <description><![CDATA[Access to high resolution satellite imagery has dramatically increased in recent years as several new constellations have entered service.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sarnet-a-dataset-for-deep-learning-assisted</guid>
    </item>
    <item>
      <title>Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline</title>
      <link>https://paperswithcode.com/paper/trajectory-guided-control-prediction-for-end</link>
      <description><![CDATA[The two branches are connected so that the control branch receives corresponding guidance from the trajectory branch at each time step.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trajectory-guided-control-prediction-for-end</guid>
    </item>
    <item>
      <title>Xplique: A Deep Learning Explainability Toolbox</title>
      <link>https://paperswithcode.com/paper/xplique-a-deep-learning-explainability</link>
      <description><![CDATA[Today's most advanced machine-learning models are hardly scrutable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xplique-a-deep-learning-explainability</guid>
    </item>
  </channel>
</rss>
