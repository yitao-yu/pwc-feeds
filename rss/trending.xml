<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 12 Jan 2025 09:14:11 +0000</lastBuildDate>
    <item>
      <title>Cosmos World Foundation Model Platform for Physical AI</title>
      <link>https://paperswithcode.com/paper/cosmos-world-foundation-model-platform-for</link>
      <description><![CDATA[We position a world foundation model as a general-purpose world model that can be fine-tuned into customized world models for downstream applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cosmos-world-foundation-model-platform-for</guid>
    </item>
    <item>
      <title>TransPixar: Advancing Text-to-Video Generation with Transparency</title>
      <link>https://paperswithcode.com/paper/transpixar-advancing-text-to-video-generation</link>
      <description><![CDATA[Text-to-video generative models have made significant strides, enabling diverse applications in entertainment, advertising, and education.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transpixar-advancing-text-to-video-generation</guid>
    </item>
    <item>
      <title>LatentSync: Audio Conditioned Latent Diffusion Models for Lip Sync</title>
      <link>https://paperswithcode.com/paper/latentsync-audio-conditioned-latent-diffusion</link>
      <description><![CDATA[Since we did not change the overall training framework of SyncNet, our experience can also be applied to other lip sync and audio-driven portrait animation methods that utilize SyncNet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latentsync-audio-conditioned-latent-diffusion</guid>
    </item>
    <item>
      <title>TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second</title>
      <link>https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</link>
      <description><![CDATA[We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</guid>
    </item>
    <item>
      <title>Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks</title>
      <link>https://paperswithcode.com/paper/don-t-do-rag-when-cache-augmented-generation</link>
      <description><![CDATA[With the advent of large language models (LLMs) featuring significantly extended context windows, this paper proposes an alternative paradigm, cache-augmented generation (CAG) that bypasses real-time retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-do-rag-when-cache-augmented-generation</guid>
    </item>
    <item>
      <title>Diffusion as Shader: 3D-aware Video Diffusion for Versatile Video Generation Control</title>
      <link>https://paperswithcode.com/paper/diffusion-as-shader-3d-aware-video-diffusion</link>
      <description><![CDATA[Diffusion models have demonstrated impressive performance in generating high-quality videos from text prompts or images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-as-shader-3d-aware-video-diffusion</guid>
    </item>
    <item>
      <title>VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction</title>
      <link>https://paperswithcode.com/paper/vita-1-5-towards-gpt-4o-level-real-time</link>
      <description><![CDATA[Recent Multimodal Large Language Models (MLLMs) have typically focused on integrating visual and textual modalities, with less emphasis placed on the role of speech in enhancing interaction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vita-1-5-towards-gpt-4o-level-real-time</guid>
    </item>
    <item>
      <title>LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token</title>
      <link>https://paperswithcode.com/paper/llava-mini-efficient-image-and-video-large</link>
      <description><![CDATA[To achieve a high compression ratio of vision tokens while preserving visual information, we first analyze how LMMs understand vision tokens and find that most vision tokens only play a crucial role in the early layers of LLM backbone, where they mainly fuse visual information into text tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llava-mini-efficient-image-and-video-large</guid>
    </item>
    <item>
      <title>KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation</title>
      <link>https://paperswithcode.com/paper/2409-13731</link>
      <description><![CDATA[The recently developed retrieval-augmented generation (RAG) technology has enabled the efficient construction of domain-specific applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2409-13731</guid>
    </item>
    <item>
      <title>NVILA: Efficient Frontier Visual Language Models</title>
      <link>https://paperswithcode.com/paper/nvila-efficient-frontier-visual-language</link>
      <description><![CDATA[This paper introduces NVILA, a family of open VLMs designed to optimize both efficiency and accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nvila-efficient-frontier-visual-language</guid>
    </item>
    <item>
      <title>Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks</title>
      <link>https://paperswithcode.com/paper/hallo3-highly-dynamic-and-realistic-portrait</link>
      <description><![CDATA[Existing methodologies for animating portrait images face significant challenges, particularly in handling non-frontal perspectives, rendering dynamic objects around the portrait, and generating immersive, realistic backgrounds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hallo3-highly-dynamic-and-realistic-portrait</guid>
    </item>
    <item>
      <title>DeepSeek-V3 Technical Report</title>
      <link>https://paperswithcode.com/paper/deepseek-v3-technical-report</link>
      <description><![CDATA[We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-v3-technical-report</guid>
    </item>
    <item>
      <title>SVFR: A Unified Framework for Generalized Video Face Restoration</title>
      <link>https://paperswithcode.com/paper/svfr-a-unified-framework-for-generalized</link>
      <description><![CDATA[In this paper, we propose a novel approach for the Generalized Video Face Restoration (GVFR) task, which integrates video BFR, inpainting, and colorization tasks that we empirically show to benefit each other.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/svfr-a-unified-framework-for-generalized</guid>
    </item>
    <item>
      <title>OpenHands: An Open Platform for AI Software Developers as Generalist Agents</title>
      <link>https://paperswithcode.com/paper/opendevin-an-open-platform-for-ai-software</link>
      <description><![CDATA[OpenDevin), a platform for the development of powerful and flexible AI agents that interact with the world in similar ways to those of a human developer: by writing code, interacting with a command line, and browsing the web.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/opendevin-an-open-platform-for-ai-software</guid>
    </item>
    <item>
      <title>Magic Mirror: ID-Preserved Video Generation in Video Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/magic-mirror-id-preserved-video-generation-in</link>
      <description><![CDATA[We present Magic Mirror, a framework for generating identity-preserved videos with cinematic-level quality and dynamic motion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magic-mirror-id-preserved-video-generation-in</guid>
    </item>
    <item>
      <title>Story-Adapter: A Training-free Iterative Framework for Long Story Visualization</title>
      <link>https://paperswithcode.com/paper/story-adapter-a-training-free-iterative</link>
      <description><![CDATA[Specifically, we propose an iterative paradigm to refine each generated image, leveraging both the text prompt and all generated images from the previous iteration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/story-adapter-a-training-free-iterative</guid>
    </item>
    <item>
      <title>Large Concept Models: Language Modeling in a Sentence Representation Space</title>
      <link>https://paperswithcode.com/paper/large-concept-models-language-modeling-in-a</link>
      <description><![CDATA[In this paper, we present an attempt at an architecture which operates on an explicit higher-level semantic representation, which we name a concept.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-concept-models-language-modeling-in-a</guid>
    </item>
    <item>
      <title>TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization</title>
      <link>https://paperswithcode.com/paper/tangoflux-super-fast-and-faithful-text-to</link>
      <description><![CDATA[We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44. 1kHz audio in just 3. 7 seconds on a single A40 GPU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tangoflux-super-fast-and-faithful-text-to</guid>
    </item>
    <item>
      <title>Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos</title>
      <link>https://paperswithcode.com/paper/sa2va-marrying-sam2-with-llava-for-dense</link>
      <description><![CDATA[This work presents Sa2VA, the first unified model for dense grounded understanding of both images and videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sa2va-marrying-sam2-with-llava-for-dense</guid>
    </item>
    <item>
      <title>PPTAgent: Generating and Evaluating Presentations Beyond Text-to-Slides</title>
      <link>https://paperswithcode.com/paper/pptagent-generating-and-evaluating</link>
      <description><![CDATA[Automatically generating presentations from documents is a challenging task that requires balancing content quality, visual design, and structural coherence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pptagent-generating-and-evaluating</guid>
    </item>
  </channel>
</rss>
