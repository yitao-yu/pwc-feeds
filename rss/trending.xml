<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 06 Mar 2025 09:17:16 +0000</lastBuildDate>
    <item>
      <title>olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models</title>
      <link>https://paperswithcode.com/paper/olmocr-unlocking-trillions-of-tokens-in-pdfs</link>
      <description><![CDATA[PDF documents have the potential to provide trillions of novel, high-quality tokens for training language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/olmocr-unlocking-trillions-of-tokens-in-pdfs</guid>
    </item>
    <item>
      <title>Atom of Thoughts for Markov LLM Test-Time Scaling</title>
      <link>https://paperswithcode.com/paper/atom-of-thoughts-for-markov-llm-test-time</link>
      <description><![CDATA[Based on this observation, we propose Atom of Thoughts (AoT), where each state transition in the reasoning process consists of decomposing the current question into a dependency-based directed acyclic graph and contracting its subquestions, forming a new atomic question state.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/atom-of-thoughts-for-markov-llm-test-time</guid>
    </item>
    <item>
      <title>A-MEM: Agentic Memory for LLM Agents</title>
      <link>https://paperswithcode.com/paper/a-mem-agentic-memory-for-llm-agents</link>
      <description><![CDATA[To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-mem-agentic-memory-for-llm-agents</guid>
    </item>
    <item>
      <title>ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents</title>
      <link>https://paperswithcode.com/paper/vidorag-visual-document-retrieval-augmented</link>
      <description><![CDATA[To bridge this gap, we introduce ViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich documents requiring complex reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vidorag-visual-document-retrieval-augmented</guid>
    </item>
    <item>
      <title>Distill Any Depth: Distillation Creates a Stronger Monocular Depth Estimator</title>
      <link>https://paperswithcode.com/paper/distill-any-depth-distillation-creates-a</link>
      <description><![CDATA[In this paper, we systematically analyze the impact of different depth normalization strategies on pseudo-label distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/distill-any-depth-distillation-creates-a</guid>
    </item>
    <item>
      <title>Merlion: A Machine Learning Library for Time Series</title>
      <link>https://paperswithcode.com/paper/merlion-a-machine-learning-library-for-time</link>
      <description><![CDATA[We introduce Merlion, an open-source machine learning library for time series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/merlion-a-machine-learning-library-for-time</guid>
    </item>
    <item>
      <title>From System 1 to System 2: A Survey of Reasoning Large Language Models</title>
      <link>https://paperswithcode.com/paper/from-system-1-to-system-2-a-survey-of</link>
      <description><![CDATA[Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-system-1-to-system-2-a-survey-of</guid>
    </item>
    <item>
      <title>Self-rewarding correction for mathematical reasoning</title>
      <link>https://paperswithcode.com/paper/self-rewarding-correction-for-mathematical</link>
      <description><![CDATA[We study self-rewarding reasoning large language models (LLMs), which can simultaneously generate step-by-step reasoning and evaluate the correctness of their outputs during the inference time-without external feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-rewarding-correction-for-mathematical</guid>
    </item>
    <item>
      <title>Magma: A Foundation Model for Multimodal AI Agents</title>
      <link>https://paperswithcode.com/paper/magma-a-foundation-model-for-multimodal-ai</link>
      <description><![CDATA[We present Magma, a foundation model that serves multimodal AI agentic tasks in both the digital and physical worlds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magma-a-foundation-model-for-multimodal-ai</guid>
    </item>
    <item>
      <title>Beyond Next-Token: Next-X Prediction for Autoregressive Visual Generation</title>
      <link>https://paperswithcode.com/paper/beyond-next-token-next-x-prediction-for</link>
      <description><![CDATA[In this paper, we propose xAR, a generalized AR framework that extends the notion of a token to an entity X, which can represent an individual patch token, a cell (a $k\times k$ grouping of neighboring patches), a subsample (a non-local grouping of distant patches), a scale (coarse-to-fine resolution), or even a whole image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-next-token-next-x-prediction-for</guid>
    </item>
    <item>
      <title>PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation</title>
      <link>https://paperswithcode.com/paper/pike-rag-specialized-knowledge-and-rationale</link>
      <description><![CDATA[Despite notable advancements in Retrieval-Augmented Generation (RAG) systems that expand large language model (LLM) capabilities through external retrieval, these systems often struggle to meet the complex and diverse needs of real-world industrial applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pike-rag-specialized-knowledge-and-rationale</guid>
    </item>
    <item>
      <title>Pandora3D: A Comprehensive Framework for High-Quality 3D Shape and Texture Generation</title>
      <link>https://paperswithcode.com/paper/pandora3d-a-comprehensive-framework-for-high</link>
      <description><![CDATA[This report presents a comprehensive framework for generating high-quality 3D shapes and textures from diverse input prompts, including single images, multi-view images, and text descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pandora3d-a-comprehensive-framework-for-high</guid>
    </item>
    <item>
      <title>PhotoDoodle: Learning Artistic Image Editing from Few-Shot Pairwise Data</title>
      <link>https://paperswithcode.com/paper/photodoodle-learning-artistic-image-editing</link>
      <description><![CDATA[Subsequently, we fine-tune this model with EditLoRA using a small, artist-curated dataset of before-and-after image pairs to capture distinct editing styles and techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photodoodle-learning-artistic-image-editing</guid>
    </item>
    <item>
      <title>Revisiting Adversarial Training under Long-Tailed Distributions</title>
      <link>https://paperswithcode.com/paper/revisiting-adversarial-training-under-long</link>
      <description><![CDATA[Extensive experiments further corroborate that data augmentation alone can significantly improve robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-adversarial-training-under-long</guid>
    </item>
    <item>
      <title>Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/reconstruction-vs-generation-taming-1</link>
      <description><![CDATA[The integrated system achieves state-of-the-art (SOTA) performance on ImageNet 256x256 generation with an FID score of 1. 35 while demonstrating remarkable training efficiency by reaching an FID score of 2. 11 in just 64 epochs--representing an over 21 times convergence speedup compared to the original DiT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reconstruction-vs-generation-taming-1</guid>
    </item>
    <item>
      <title>MonSter: Marry Monodepth to Stereo Unleashes Power</title>
      <link>https://paperswithcode.com/paper/monster-marry-monodepth-to-stereo-unleashes</link>
      <description><![CDATA[The refined monodepth is in turn guides stereo effectively at ill-posed regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monster-marry-monodepth-to-stereo-unleashes</guid>
    </item>
    <item>
      <title>R1-OnevisionAn Open-Source Multimodal Large Language Model Capable of Deep Reasoning</title>
      <link>https://paperswithcode.com/paper/r1-onevision-an-open-source-multimodal-large</link>
      <description><![CDATA[R1-OneVision is a versatile multimodal reasoning large model, designed to tackle complex visual reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r1-onevision-an-open-source-multimodal-large</guid>
    </item>
    <item>
      <title>UniTok: A Unified Tokenizer for Visual Generation and Understanding</title>
      <link>https://paperswithcode.com/paper/unitok-a-unified-tokenizer-for-visual</link>
      <description><![CDATA[To bridge this gap, we introduce UniTok, a discrete visual tokenizer that encodes fine-grained details for generation while also capturing high-level semantics for understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unitok-a-unified-tokenizer-for-visual</guid>
    </item>
    <item>
      <title>From Hours to Minutes: Lossless Acceleration of Ultra Long Sequence Generation up to 100K Tokens</title>
      <link>https://paperswithcode.com/paper/from-hours-to-minutes-lossless-acceleration</link>
      <description><![CDATA[While traditional speculative decoding methods exist, simply extending their generation limits fails to accelerate the process and can be detrimental.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-hours-to-minutes-lossless-acceleration</guid>
    </item>
    <item>
      <title>shapiq: Shapley Interactions for Machine Learning</title>
      <link>https://paperswithcode.com/paper/shapiq-shapley-interactions-for-machine</link>
      <description><![CDATA[In this work, we introduce shapiq, an open-source Python package that unifies state-of-the-art algorithms to efficiently compute SVs and any-order SIs in an application-agnostic framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shapiq-shapley-interactions-for-machine</guid>
    </item>
  </channel>
</rss>
