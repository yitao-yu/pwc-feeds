<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 13 Apr 2024 09:10:07 +0000</lastBuildDate>
    <item>
      <title>AutoCodeRover: Autonomous Program Improvement</title>
      <link>https://paperswithcode.com/paper/autocoderover-autonomous-program-improvement</link>
      <description><![CDATA[Recent progress in Large Language Models (LLMs) has significantly impacted the development process, where developers can use LLM-based programming assistants to achieve automated coding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autocoderover-autonomous-program-improvement</guid>
    </item>
    <item>
      <title>Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution</title>
      <link>https://paperswithcode.com/paper/patch-n-pack-navit-a-vision-transformer-for</link>
      <description><![CDATA[The ubiquitous and demonstrably suboptimal choice of resizing images to a fixed resolution before processing them with computer vision models has not yet been successfully challenged.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/patch-n-pack-navit-a-vision-transformer-for</guid>
    </item>
    <item>
      <title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title>
      <link>https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</link>
      <description><![CDATA[We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine "next-scale prediction" or "next-resolution prediction", diverging from the standard raster-scan "next-token prediction".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</guid>
    </item>
    <item>
      <title>MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators</title>
      <link>https://paperswithcode.com/paper/magictime-time-lapse-video-generation-models</link>
      <description><![CDATA[Recent advances in Text-to-Video generation (T2V) have achieved remarkable success in synthesizing high-quality general videos from textual descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magictime-time-lapse-video-generation-models</guid>
    </item>
    <item>
      <title>InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/instantstyle-free-lunch-towards-style</link>
      <description><![CDATA[Tuning-free diffusion-based models have demonstrated significant potential in the realm of image personalization and customization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantstyle-free-lunch-towards-style</guid>
    </item>
    <item>
      <title>AIOS: LLM Agent Operating System</title>
      <link>https://paperswithcode.com/paper/llm-agent-operating-system</link>
      <description><![CDATA[Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS) as the brain of the OS, enabling an operating system "with soul" -- an important step towards AGI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-agent-operating-system</guid>
    </item>
    <item>
      <title>InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models</title>
      <link>https://paperswithcode.com/paper/instantmesh-efficient-3d-mesh-generation-from</link>
      <description><![CDATA[We present InstantMesh, a feed-forward framework for instant 3D mesh generation from a single image, featuring state-of-the-art generation quality and significant training scalability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantmesh-efficient-3d-mesh-generation-from</guid>
    </item>
    <item>
      <title>LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders</title>
      <link>https://paperswithcode.com/paper/llm2vec-large-language-models-are-secretly</link>
      <description><![CDATA[We outperform encoder-only models by a large margin on word-level tasks and reach a new unsupervised state-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm2vec-large-language-models-are-secretly</guid>
    </item>
    <item>
      <title>OmniFusion Technical Report</title>
      <link>https://paperswithcode.com/paper/omnifusion-technical-report</link>
      <description><![CDATA[We propose an \textit{OmniFusion} model based on a pretrained LLM and adapters for visual modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnifusion-technical-report</guid>
    </item>
    <item>
      <title>ReFT: Representation Finetuning for Language Models</title>
      <link>https://paperswithcode.com/paper/reft-representation-finetuning-for-language</link>
      <description><![CDATA[LoReFT is a drop-in replacement for existing PEFTs and learns interventions that are 10x-50x more parameter-efficient than prior state-of-the-art PEFTs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reft-representation-finetuning-for-language</guid>
    </item>
    <item>
      <title>Hash3D: Training-free Acceleration for 3D Generation</title>
      <link>https://paperswithcode.com/paper/hash3d-training-free-acceleration-for-3d</link>
      <description><![CDATA[The evolution of 3D generative modeling has been notably propelled by the adoption of 2D diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hash3d-training-free-acceleration-for-3d</guid>
    </item>
    <item>
      <title>HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach</title>
      <link>https://paperswithcode.com/paper/hairfastgan-realistic-and-robust-hair</link>
      <description><![CDATA[Our paper addresses the complex task of transferring a hairstyle from a reference image to an input photo for virtual hair try-on.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hairfastgan-realistic-and-robust-hair</guid>
    </item>
    <item>
      <title>SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System</title>
      <link>https://paperswithcode.com/paper/schurvins-schur-complement-based-lightweight</link>
      <description><![CDATA[To this end, we propose a novel filter-based VINS framework named SchurVINS, which could guarantee both high accuracy by building a complete residual model and low computational complexity with Schur complement.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/schurvins-schur-complement-based-lightweight</guid>
    </item>
    <item>
      <title>AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation</title>
      <link>https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</link>
      <description><![CDATA[In this study, we propose AniPortrait, a novel framework for generating high-quality animation driven by audio and a reference portrait image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</guid>
    </item>
    <item>
      <title>Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/cross-attention-makes-inference-cumbersome-in</link>
      <description><![CDATA[This study explores the role of cross-attention during inference in text-conditional diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-attention-makes-inference-cumbersome-in</guid>
    </item>
    <item>
      <title>StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text</title>
      <link>https://paperswithcode.com/paper/streamingt2v-consistent-dynamic-and</link>
      <description><![CDATA[To overcome these limitations, we introduce StreamingT2V, an autoregressive approach for long video generation of 80, 240, 600, 1200 or more frames with smooth transitions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streamingt2v-consistent-dynamic-and</guid>
    </item>
    <item>
      <title>VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild</title>
      <link>https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</link>
      <description><![CDATA[We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</guid>
    </item>
    <item>
      <title>PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models</title>
      <link>https://paperswithcode.com/paper/pissa-principal-singular-values-and-singular</link>
      <description><![CDATA[However, LoRA approximates Delta W through the product of two matrices, A, initialized with Gaussian noise, and B, initialized with zeros, while PiSSA initializes A and B with principal singular values and vectors of the original matrix W. PiSSA can better approximate the outcomes of full-parameter fine-tuning at the beginning by changing the essential parts while freezing the "noisy" parts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pissa-principal-singular-values-and-singular</guid>
    </item>
    <item>
      <title>AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent</title>
      <link>https://paperswithcode.com/paper/autowebglm-bootstrap-and-reinforce-a-large</link>
      <description><![CDATA[Large language models (LLMs) have fueled many intelligent agent tasks, such as web navigation -- but most existing agents perform far from satisfying in real-world webpages due to three factors: (1) the versatility of actions on webpages, (2) HTML text exceeding model processing capacity, and (3) the complexity of decision-making due to the open-domain nature of web.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autowebglm-bootstrap-and-reinforce-a-large</guid>
    </item>
    <item>
      <title>Policy-Guided Diffusion</title>
      <link>https://paperswithcode.com/paper/policy-guided-diffusion</link>
      <description><![CDATA[Our approach provides an effective alternative to autoregressive offline world models, opening the door to the controllable generation of synthetic training data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/policy-guided-diffusion</guid>
    </item>
  </channel>
</rss>
