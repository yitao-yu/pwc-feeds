<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 26 Sep 2022 21:09:25 +0000</lastBuildDate>
    <item>
      <title>Robust Speech Recognition via Large-Scale Weak Supervision</title>
      <link>https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale</link>
      <description><![CDATA[We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale</guid>
    </item>
    <item>
      <title>VToonify: Controllable High-Resolution Portrait Video Style Transfer</title>
      <link>https://paperswithcode.com/paper/vtoonify-controllable-high-resolution</link>
      <description><![CDATA[Although a series of successful portrait image toonification models built upon the powerful StyleGAN have been proposed, these image-oriented methods have obvious limitations when applied to videos, such as the fixed frame size, the requirement of face alignment, missing non-facial details and temporal inconsistency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vtoonify-controllable-high-resolution</guid>
    </item>
    <item>
      <title>Plenoxels: Radiance Fields without Neural Networks</title>
      <link>https://paperswithcode.com/paper/plenoxels-radiance-fields-without-neural</link>
      <description><![CDATA[We introduce Plenoxels (plenoptic voxels), a system for photorealistic view synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plenoxels-radiance-fields-without-neural</guid>
    </item>
    <item>
      <title>LAVIS: A Library for Language-Vision Intelligence</title>
      <link>https://paperswithcode.com/paper/lavis-a-library-for-language-vision</link>
      <description><![CDATA[We introduce LAVIS, an open-source deep learning library for LAnguage-VISion research and applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lavis-a-library-for-language-vision</guid>
    </item>
    <item>
      <title>DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection</title>
      <link>https://paperswithcode.com/paper/dino-detr-with-improved-denoising-anchor-1</link>
      <description><![CDATA[Compared to other models on the leaderboard, DINO significantly reduces its model size and pre-training data size while achieving better results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dino-detr-with-improved-denoising-anchor-1</guid>
    </item>
    <item>
      <title>Poisson Flow Generative Models</title>
      <link>https://paperswithcode.com/paper/poisson-flow-generative-models</link>
      <description><![CDATA[We interpret the data points as electrical charges on the $z=0$ hyperplane in a space augmented with an additional dimension $z$, generating a high-dimensional electric field (the gradient of the solution to Poisson equation).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poisson-flow-generative-models</guid>
    </item>
    <item>
      <title>Text2Light: Zero-Shot Text-Driven HDR Panorama Generation</title>
      <link>https://paperswithcode.com/paper/text2light-zero-shot-text-driven-hdr-panorama</link>
      <description><![CDATA[To achieve super-resolution inverse tone mapping, we derive a continuous representation of 360-degree imaging from the LDR panorama as a set of structured latent codes anchored to the sphere.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2light-zero-shot-text-driven-hdr-panorama</guid>
    </item>
    <item>
      <title>SegNeXt: Rethinking Convolutional Attention Design for Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/segnext-rethinking-convolutional-attention</link>
      <description><![CDATA[Notably, SegNeXt outperforms EfficientNet-L2 w/ NAS-FPN and achieves 90. 6% mIoU on the Pascal VOC 2012 test leaderboard using only 1/10 parameters of it.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segnext-rethinking-convolutional-attention</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>towhee</title>
      <link>https://github.com/towhee-io/towhee</link>
      <description><![CDATA[Towhee is a framework that is dedicated to making neural data processing pipelines simple and fast.]]></description>
      <guid isPermaLink="true">https://github.com/towhee-io/towhee</guid>
    </item>
    <item>
      <title>USB: A Unified Semi-supervised Learning Benchmark</title>
      <link>https://paperswithcode.com/paper/usb-a-unified-semi-supervised-learning</link>
      <description><![CDATA[Semi-supervised learning (SSL) improves model generalization by leveraging massive unlabeled data to augment limited labeled samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/usb-a-unified-semi-supervised-learning</guid>
    </item>
    <item>
      <title>IoT Data Analytics in Dynamic Environments: From An Automated Machine Learning Perspective</title>
      <link>https://paperswithcode.com/paper/iot-data-analytics-in-dynamic-environments</link>
      <description><![CDATA[Machine Learning (ML) approaches have shown their capacity for IoT data analytics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/iot-data-analytics-in-dynamic-environments</guid>
    </item>
    <item>
      <title>Deep Learning for Medical Image Segmentation: Tricks, Challenges and Future Directions</title>
      <link>https://paperswithcode.com/paper/deep-learning-for-medical-image-segmentation-1</link>
      <description><![CDATA[Over the past few years, the rapid development of deep learning technologies for computer vision has greatly promoted the performance of medical image segmentation (MedISeg).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-learning-for-medical-image-segmentation-1</guid>
    </item>
    <item>
      <title>From data to functa: Your data point is a function and you can treat it like one</title>
      <link>https://paperswithcode.com/paper/from-data-to-functa-your-data-point-is-a</link>
      <description><![CDATA[A powerful continuous alternative is then to represent these measurements using an implicit neural representation, a neural function trained to output the appropriate measurement value for any input spatial location.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-data-to-functa-your-data-point-is-a</guid>
    </item>
    <item>
      <title>High-Resolution Image Synthesis with Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</link>
      <description><![CDATA[By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</guid>
    </item>
    <item>
      <title>Diffusion Models: A Comprehensive Survey of Methods and Applications</title>
      <link>https://paperswithcode.com/paper/diffusion-models-a-comprehensive-survey-of</link>
      <description><![CDATA[Diffusion models are a class of deep generative models that have shown impressive results on various tasks with a solid theoretical foundation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-a-comprehensive-survey-of</guid>
    </item>
    <item>
      <title>Neural Architectures for Named Entity Recognition</title>
      <link>https://paperswithcode.com/paper/neural-architectures-for-named-entity</link>
      <description><![CDATA[State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-architectures-for-named-entity</guid>
    </item>
    <item>
      <title>HiFuse: Hierarchical Multi-Scale Feature Fusion Network for Medical Image Classification</title>
      <link>https://paperswithcode.com/paper/hifuse-hierarchical-multi-scale-feature</link>
      <description><![CDATA[A parallel hierarchy of local and global feature blocks is designed to efficiently extract local features and global representations at various semantic scales, with the flexibility to model at different scales and linear computational complexity relevant to image size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hifuse-hierarchical-multi-scale-feature</guid>
    </item>
    <item>
      <title>Efficient Few-Shot Learning Without Prompts</title>
      <link>https://paperswithcode.com/paper/efficient-few-shot-learning-without-prompts</link>
      <description><![CDATA[This simple framework requires no prompts or verbalizers, and achieves high accuracy with orders of magnitude less parameters than existing techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-few-shot-learning-without-prompts</guid>
    </item>
    <item>
      <title>DI-engine</title>
      <link>https://github.com/opendilab/DI-engine</link>
      <description><![CDATA[OpenDILab Decision AI Engine]]></description>
      <guid isPermaLink="true">https://github.com/opendilab/DI-engine</guid>
    </item>
  </channel>
</rss>
