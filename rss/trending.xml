<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 04 Aug 2023 21:05:48 +0000</lastBuildDate>
    <item>
      <title>ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</title>
      <link>https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</link>
      <description><![CDATA[We first present ToolBench, an instruction-tuning dataset for tool use, which is created automatically using ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</guid>
    </item>
    <item>
      <title>Universal and Transferable Adversarial Attacks on Aligned Language Models</title>
      <link>https://paperswithcode.com/paper/universal-and-transferable-adversarial</link>
      <description><![CDATA[Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-and-transferable-adversarial</guid>
    </item>
    <item>
      <title>Tracking Anything in High Quality</title>
      <link>https://paperswithcode.com/paper/tracking-anything-in-high-quality</link>
      <description><![CDATA[To further improve the quality of tracking masks, a pretrained MR model is employed to refine the tracking results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tracking-anything-in-high-quality</guid>
    </item>
    <item>
      <title>Med-Flamingo: a Multimodal Medical Few-shot Learner</title>
      <link>https://paperswithcode.com/paper/med-flamingo-a-multimodal-medical-few-shot</link>
      <description><![CDATA[However, existing models typically have to be fine-tuned on sizeable down-stream datasets, which poses a significant limitation as in many medical applications data is scarce, necessitating models that are capable of learning from few examples in real-time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/med-flamingo-a-multimodal-medical-few-shot</guid>
    </item>
    <item>
      <title>SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</link>
      <description><![CDATA[We present SDXL, a latent diffusion model for text-to-image synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</guid>
    </item>
    <item>
      <title>Effective Whole-body Pose Estimation with Two-stages Distillation</title>
      <link>https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</link>
      <description><![CDATA[Different from the previous self-knowledge distillation, this stage finetunes the student's head with only 20% training time as a plug-and-play training strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</guid>
    </item>
    <item>
      <title>LISA: Reasoning Segmentation via Large Language Model</title>
      <link>https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</link>
      <description><![CDATA[In this work, we propose a new segmentation task -- reasoning segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</guid>
    </item>
    <item>
      <title>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</title>
      <link>https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</link>
      <description><![CDATA[Recently, remarkable progress has been made in automated task-solving through the use of multi-agents driven by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</guid>
    </item>
    <item>
      <title>Unified Model for Image, Video, Audio and Language Tasks</title>
      <link>https://paperswithcode.com/paper/unified-model-for-image-video-audio-and</link>
      <description><![CDATA[Our model is efficiently pretrained on many tasks, based on task balancing and multimodal curriculum learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unified-model-for-image-video-audio-and</guid>
    </item>
    <item>
      <title>Gorilla: Large Language Model Connected with Massive APIs</title>
      <link>https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</link>
      <description><![CDATA[Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</guid>
    </item>
    <item>
      <title>LP-MusicCaps: LLM-Based Pseudo Music Captioning</title>
      <link>https://paperswithcode.com/paper/lp-musiccaps-llm-based-pseudo-music</link>
      <description><![CDATA[In addition, we trained a transformer-based music captioning model with the dataset and evaluated it under zero-shot and transfer-learning settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lp-musiccaps-llm-based-pseudo-music</guid>
    </item>
    <item>
      <title>Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields</title>
      <link>https://paperswithcode.com/paper/seal-3d-interactive-pixel-level-editing-for</link>
      <description><![CDATA[With the popularity of implicit neural representations, or neural radiance fields (NeRF), there is a pressing need for editing methods to interact with the implicit 3D models for tasks like post-processing reconstructed scenes and 3D content creation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seal-3d-interactive-pixel-level-editing-for</guid>
    </item>
    <item>
      <title>FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios</title>
      <link>https://paperswithcode.com/paper/factool-factuality-detection-in-generative-ai</link>
      <description><![CDATA[With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e. g., ChatGPT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/factool-factuality-detection-in-generative-ai</guid>
    </item>
    <item>
      <title>MARS: An Instance-aware, Modular and Realistic Simulator for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/mars-an-instance-aware-modular-and-realistic</link>
      <description><![CDATA[We expect this modular design to boost academic progress and industrial deployment of NeRF-based autonomous driving simulation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mars-an-instance-aware-modular-and-realistic</guid>
    </item>
    <item>
      <title>Aligning Large Language Models with Human: A Survey</title>
      <link>https://paperswithcode.com/paper/aligning-large-language-models-with-human-a</link>
      <description><![CDATA[(2) Training methodologies: a detailed review of the prevailing training methods employed for LLM alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-large-language-models-with-human-a</guid>
    </item>
    <item>
      <title>MovieChat: From Dense Token to Sparse Memory for Long Video Understanding</title>
      <link>https://paperswithcode.com/paper/moviechat-from-dense-token-to-sparse-memory</link>
      <description><![CDATA[Recently, integrating video foundation models and large language models to build a video understanding system overcoming the limitations of specific pre-defined vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moviechat-from-dense-token-to-sparse-memory</guid>
    </item>
    <item>
      <title>Re-Translation Strategies For Long Form, Simultaneous, Spoken Language Translation</title>
      <link>https://paperswithcode.com/paper/re-translation-strategies-for-long-form</link>
      <description><![CDATA[As this scenario allows for revisions to our incremental translations, we adopt a re-translation approach to simultaneous translation, where the source is repeatedly translated from scratch as it grows.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/re-translation-strategies-for-long-form</guid>
    </item>
    <item>
      <title>NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/nerf-det-learning-geometry-aware-volumetric</link>
      <description><![CDATA[We present NeRF-Det, a novel method for indoor 3D detection with posed RGB images as input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nerf-det-learning-geometry-aware-volumetric</guid>
    </item>
    <item>
      <title>LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition</title>
      <link>https://paperswithcode.com/paper/lorahub-efficient-cross-task-generalization</link>
      <description><![CDATA[Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lorahub-efficient-cross-task-generalization</guid>
    </item>
    <item>
      <title>LimSim: A Long-term Interactive Multi-scenario Traffic Simulator</title>
      <link>https://paperswithcode.com/paper/limsim-a-long-term-interactive-multi-scenario</link>
      <description><![CDATA[With the growing popularity of digital twin and autonomous driving in transportation, the demand for simulation systems capable of generating high-fidelity and reliable scenarios is increasing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/limsim-a-long-term-interactive-multi-scenario</guid>
    </item>
  </channel>
</rss>
