<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 14 Feb 2023 21:06:59 +0000</lastBuildDate>
    <item>
      <title>Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/plug-and-play-diffusion-features-for-text</link>
      <description><![CDATA[Large-scale text-to-image generative models have been a revolutionary breakthrough in the evolution of generative AI, allowing us to synthesize diverse images that convey highly complex visual concepts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plug-and-play-diffusion-features-for-text</guid>
    </item>
    <item>
      <title>BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining</title>
      <link>https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</link>
      <description><![CDATA[Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</guid>
    </item>
    <item>
      <title>Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery</title>
      <link>https://paperswithcode.com/paper/hard-prompts-made-easy-gradient-based</link>
      <description><![CDATA[In the text-to-image setting, the method creates hard prompts for diffusion models, allowing API users to easily generate, discover, and mix and match image concepts without prior knowledge on how to prompt the model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hard-prompts-made-easy-gradient-based</guid>
    </item>
    <item>
      <title>Offsite-Tuning: Transfer Learning without Full Model</title>
      <link>https://paperswithcode.com/paper/offsite-tuning-transfer-learning-without-full</link>
      <description><![CDATA[In this paper, we propose Offsite-Tuning, a privacy-preserving and efficient transfer learning framework that can adapt billion-parameter foundation models to downstream data without access to the full model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/offsite-tuning-transfer-learning-without-full</guid>
    </item>
    <item>
      <title>The Wisdom of Hindsight Makes Language Models Better Instruction Followers</title>
      <link>https://paperswithcode.com/paper/the-wisdom-of-hindsight-makes-language-models</link>
      <description><![CDATA[In this paper, we consider an alternative approach: converting feedback to instruction by relabeling the original one and training the model for better alignment in a supervised manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-wisdom-of-hindsight-makes-language-models</guid>
    </item>
    <item>
      <title>Multimodal Chain-of-Thought Reasoning in Language Models</title>
      <link>https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</link>
      <description><![CDATA[By incorporating the vision features in both stages, the model is able to generate effective rationales that contribute to answer inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</guid>
    </item>
    <item>
      <title>SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</link>
      <description><![CDATA[We propose SmoothQuant, a training-free, accuracy-preserving, and general-purpose post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit activation (W8A8) quantization for LLMs that can be implemented efficiently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</title>
      <link>https://paperswithcode.com/paper/blip-2-bootstrapping-language-image-pre</link>
      <description><![CDATA[The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blip-2-bootstrapping-language-image-pre</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</title>
      <link>https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</link>
      <description><![CDATA[Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</guid>
    </item>
    <item>
      <title>A New Outlier Removal Strategy Based on Reliability of Correspondence Graph for Fast Point Cloud Registration</title>
      <link>https://paperswithcode.com/paper/a-new-outlier-removal-strategy-based-on</link>
      <description><![CDATA[We use a simple and intuitive method to describe the 6-DOF (degree of freedom) curtailment process in point cloud registration and propose an outlier removal strategy based on the reliability of the correspondence graph.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-new-outlier-removal-strategy-based-on</guid>
    </item>
    <item>
      <title>Reversible Vision Transformers</title>
      <link>https://paperswithcode.com/paper/reversible-vision-transformers-1</link>
      <description><![CDATA[Reversible Vision Transformers achieve a reduced memory footprint of up to 15. 5x at roughly identical model complexity, parameters and accuracy, demonstrating the promise of reversible vision transformers as an efficient backbone for hardware resource limited training regimes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reversible-vision-transformers-1</guid>
    </item>
    <item>
      <title>AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities</title>
      <link>https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</link>
      <description><![CDATA[In this work, we present a conceptually simple and effective method to train a strong bilingual/multilingual multimodal representation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</guid>
    </item>
    <item>
      <title>Fine-Tuning Language Models from Human Preferences</title>
      <link>https://paperswithcode.com/paper/fine-tuning-language-models-from-human</link>
      <description><![CDATA[Most work on reward learning has used simulated environments, but complex information about values is often expressed in natural language, and we believe reward learning for language is a key to making RL practical and safe for real-world tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-language-models-from-human</guid>
    </item>
    <item>
      <title>Dual PatchNorm</title>
      <link>https://paperswithcode.com/paper/dual-patchnorm</link>
      <description><![CDATA[We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms), before and after the patch embedding layer in Vision Transformers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-patchnorm</guid>
    </item>
    <item>
      <title>Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling</title>
      <link>https://paperswithcode.com/paper/designing-bert-for-convolutional-networks</link>
      <description><![CDATA[This is the first use of sparse convolution for 2D masked modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/designing-bert-for-convolutional-networks</guid>
    </item>
    <item>
      <title>InstructPix2Pix: Learning to Follow Image Editing Instructions</title>
      <link>https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</link>
      <description><![CDATA[We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</guid>
    </item>
    <item>
      <title>Deep End-to-end Causal Inference</title>
      <link>https://paperswithcode.com/paper/deep-end-to-end-causal-inference</link>
      <description><![CDATA[Causal inference is essential for data-driven decision making across domains such as business engagement, medical treatment and policy making.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-end-to-end-causal-inference</guid>
    </item>
    <item>
      <title>Learning Quality-aware Dynamic Memory for Video Object Segmentation</title>
      <link>https://paperswithcode.com/paper/learning-quality-aware-dynamic-memory-for</link>
      <description><![CDATA[However, they mainly focus on better matching between the current frame and the memory frames without explicitly paying attention to the quality of the memory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-quality-aware-dynamic-memory-for</guid>
    </item>
  </channel>
</rss>
