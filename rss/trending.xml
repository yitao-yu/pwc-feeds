<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 20 Mar 2025 21:09:21 +0000</lastBuildDate>
    <item>
      <title>TxAgent: An AI Agent for Therapeutic Reasoning Across a Universe of Tools</title>
      <link>https://paperswithcode.com/paper/txagent-an-ai-agent-for-therapeutic-reasoning</link>
      <description><![CDATA[It selects tools based on task objectives and executes structured function calls to solve therapeutic tasks that require clinical reasoning and cross-source validation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/txagent-an-ai-agent-for-therapeutic-reasoning</guid>
    </item>
    <item>
      <title>Neural Fields with Thermal Activations for Arbitrary-Scale Super-Resolution</title>
      <link>https://paperswithcode.com/paper/neural-fields-with-thermal-activations-for</link>
      <description><![CDATA[We present a novel way to design neural fields such that points can be queried with an adaptive Gaussian PSF, so as to guarantee correct anti-aliasing at any desired output resolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-fields-with-thermal-activations-for</guid>
    </item>
    <item>
      <title>Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-outperforms-supervised</link>
      <description><![CDATA[Recently, reinforcement learning (RL) has been shown to greatly enhance the reasoning capabilities of large language models (LLMs), and RL-based approaches have been progressively applied to visual multimodal tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-outperforms-supervised</guid>
    </item>
    <item>
      <title>Agent S: An Open Agentic Framework that Uses Computers Like a Human</title>
      <link>https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</link>
      <description><![CDATA[We present Agent S, an open agentic framework that enables autonomous interaction with computers through a Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</guid>
    </item>
    <item>
      <title>Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens</title>
      <link>https://paperswithcode.com/paper/2503-01710</link>
      <description><![CDATA[Recent advancements in large language models (LLMs) have driven significant progress in zero-shot text-to-speech (TTS) synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2503-01710</guid>
    </item>
    <item>
      <title>Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models</title>
      <link>https://paperswithcode.com/paper/block-diffusion-interpolating-between</link>
      <description><![CDATA[Diffusion language models offer unique benefits over autoregressive models due to their potential for parallelized generation and controllability, yet they lag in likelihood modeling and are limited to fixed-length generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/block-diffusion-interpolating-between</guid>
    </item>
    <item>
      <title>YOLOE: Real-Time Seeing Anything</title>
      <link>https://paperswithcode.com/paper/yoloe-real-time-seeing-anything</link>
      <description><![CDATA[Object detection and segmentation are widely employed in computer vision applications, yet conventional models like YOLO series, while efficient and accurate, are limited by predefined categories, hindering adaptability in open scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yoloe-real-time-seeing-anything</guid>
    </item>
    <item>
      <title>FoundationStereo: Zero-Shot Stereo Matching</title>
      <link>https://paperswithcode.com/paper/foundationstereo-zero-shot-stereo-matching</link>
      <description><![CDATA[However, achieving strong zero-shot generalization - a hallmark of foundation models in other computer vision tasks - remains challenging for stereo matching.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundationstereo-zero-shot-stereo-matching</guid>
    </item>
    <item>
      <title>ReasonGraph: Visualisation of Reasoning Paths</title>
      <link>https://paperswithcode.com/paper/reasongraph-visualisation-of-reasoning-paths</link>
      <description><![CDATA[Large Language Models (LLMs) reasoning processes are challenging to analyze due to their complexity and the lack of organized visualization tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reasongraph-visualisation-of-reasoning-paths</guid>
    </item>
    <item>
      <title>Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k</title>
      <link>https://paperswithcode.com/paper/open-sora-2-0-training-a-commercial-level</link>
      <description><![CDATA[With this model, we demonstrate that the cost of training a top-performing video generation model is highly controllable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-sora-2-0-training-a-commercial-level</guid>
    </item>
    <item>
      <title>Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/vision-r1-incentivizing-reasoning-capability</link>
      <description><![CDATA[However, direct training with RL struggles to activate complex reasoning capabilities such as questioning and reflection in MLLMs, due to the absence of substantial high-quality multimodal reasoning data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-r1-incentivizing-reasoning-capability</guid>
    </item>
    <item>
      <title>LBM: Latent Bridge Matching for Fast Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/lbm-latent-bridge-matching-for-fast-image-to</link>
      <description><![CDATA[In this paper, we introduce Latent Bridge Matching (LBM), a new, versatile and scalable method that relies on Bridge Matching in a latent space to achieve fast image-to-image translation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lbm-latent-bridge-matching-for-fast-image-to</guid>
    </item>
    <item>
      <title>Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and Beyond</title>
      <link>https://paperswithcode.com/paper/light-r1-curriculum-sft-dpo-and-rl-for-long</link>
      <description><![CDATA[The Light-R1 series of work validates training long-COT models from scratch, showcases the art in SFT data and releases SOTA models from RL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/light-r1-curriculum-sft-dpo-and-rl-for-long</guid>
    </item>
    <item>
      <title>Zero-shot Voice Conversion with Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/zero-shot-voice-conversion-with-diffusion</link>
      <description><![CDATA[Zero-shot voice conversion aims to transform a source speech utterance to match the timbre of a reference speech from an unseen speaker.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-voice-conversion-with-diffusion</guid>
    </item>
    <item>
      <title>GoT: Unleashing Reasoning Capability of Multimodal Large Language Model for Visual Generation and Editing</title>
      <link>https://paperswithcode.com/paper/got-unleashing-reasoning-capability-of</link>
      <description><![CDATA[We present Generation Chain-of-Thought (GoT), a novel paradigm that enables generation and editing through an explicit language reasoning process before outputting images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/got-unleashing-reasoning-capability-of</guid>
    </item>
    <item>
      <title>Slim attention: cut your context memory in half without loss of accuracy -- K-cache is all you need for MHA</title>
      <link>https://paperswithcode.com/paper/slim-attention-cut-your-context-memory-in</link>
      <description><![CDATA[For encoder-decoder transformers, the context memory size can be reduced even further: For the Whisper models for example, slim attention reduces the context memory by 8x, which can speed up token generation by 5x for batch size 64 for example.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/slim-attention-cut-your-context-memory-in</guid>
    </item>
    <item>
      <title>Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts</title>
      <link>https://paperswithcode.com/paper/comet-fine-grained-computation-communication</link>
      <description><![CDATA[The inter-device communication of a MoE layer can occupy 47% time of the entire model execution with popular models and frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comet-fine-grained-computation-communication</guid>
    </item>
    <item>
      <title>LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL</title>
      <link>https://paperswithcode.com/paper/lmm-r1-empowering-3b-lmms-with-strong</link>
      <description><![CDATA[Enhancing reasoning in Large Multimodal Models (LMMs) faces unique challenges from the complex interplay between visual perception and logical reasoning, particularly in compact 3B-parameter architectures where architectural constraints limit reasoning capacity and modality alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lmm-r1-empowering-3b-lmms-with-strong</guid>
    </item>
    <item>
      <title>2 OLMo 2 Furious</title>
      <link>https://paperswithcode.com/paper/2-olmo-2-furious</link>
      <description><![CDATA[Our modified model architecture and training recipe achieve both better training stability and improved per-token efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2-olmo-2-furious</guid>
    </item>
    <item>
      <title>HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation</title>
      <link>https://paperswithcode.com/paper/healthgpt-a-medical-large-vision-language</link>
      <description><![CDATA[To effectively learn the HealthGPT, we devise a comprehensive medical domain-specific comprehension and generation dataset called VL-Health.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/healthgpt-a-medical-large-vision-language</guid>
    </item>
  </channel>
</rss>
