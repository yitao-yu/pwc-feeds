<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 08 Jun 2025 21:09:06 +0000</lastBuildDate>
    <item>
      <title>Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents</title>
      <link>https://paperswithcode.com/paper/darwin-godel-machine-open-ended-evolution-of</link>
      <description><![CDATA[The G\"odel machine proposed a theoretical alternative: a self-improving AI that repeatedly modifies itself in a provably beneficial manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/darwin-godel-machine-open-ended-evolution-of</guid>
    </item>
    <item>
      <title>AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning</title>
      <link>https://paperswithcode.com/paper/areal-a-large-scale-asynchronous</link>
      <description><![CDATA[Most existing large-scale RL systems for LLMs are synchronous, alternating generation and training in a batch setting where rollouts in each training batch are generated by the same model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/areal-a-large-scale-asynchronous</guid>
    </item>
    <item>
      <title>Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers</title>
      <link>https://paperswithcode.com/paper/paper2poster-towards-multimodal-poster</link>
      <description><![CDATA[To address this challenge, we introduce the first benchmark and metric suite for poster generation, which pairs recent conference papers with author-designed posters and evaluates outputs on (i)Visual Quality-semantic alignment with human posters, (ii)Textual Coherence-language fluency, (iii)Holistic Assessment-six fine-grained aesthetic and informational criteria scored by a VLM-as-judge, and notably (iv)PaperQuiz-the poster's ability to convey core paper content as measured by VLMs answering generated quizzes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paper2poster-towards-multimodal-poster</guid>
    </item>
    <item>
      <title>BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model</title>
      <link>https://paperswithcode.com/paper/bioreason-incentivizing-multimodal-biological</link>
      <description><![CDATA[Unlocking deep, interpretable biological reasoning from complex genomic data is a major AI challenge hindering scientific discovery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bioreason-incentivizing-multimodal-biological</guid>
    </item>
    <item>
      <title>Emerging Properties in Unified Multimodal Pretraining</title>
      <link>https://paperswithcode.com/paper/emerging-properties-in-unified-multimodal</link>
      <description><![CDATA[Unifying multimodal understanding and generation has shown impressive capabilities in cutting-edge proprietary systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emerging-properties-in-unified-multimodal</guid>
    </item>
    <item>
      <title>HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters</title>
      <link>https://paperswithcode.com/paper/hunyuanvideo-avatar-high-fidelity-audio</link>
      <description><![CDATA[This ensures the dynamic motion and strong character consistency; (ii) An Audio Emotion Module (AEM) is introduced to extract and transfer the emotional cues from an emotion reference image to the target generated video, enabling fine-grained and accurate emotion style control; (iii) A Face-Aware Audio Adapter (FAA) is proposed to isolate the audio-driven character with latent-level face mask, enabling independent audio injection via cross-attention for multi-character scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuanvideo-avatar-high-fidelity-audio</guid>
    </item>
    <item>
      <title>Direct3D-S2: Gigascale 3D Generation Made Easy with Spatial Sparse Attention</title>
      <link>https://paperswithcode.com/paper/direct3d-s2-gigascale-3d-generation-made-easy</link>
      <description><![CDATA[Generating high-resolution 3D shapes using volumetric representations such as Signed Distance Functions (SDFs) presents substantial computational and memory challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct3d-s2-gigascale-3d-generation-made-easy</guid>
    </item>
    <item>
      <title>RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination</title>
      <link>https://paperswithcode.com/paper/renderformer-transformer-based-neural</link>
      <description><![CDATA[We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of a scene with full global illumination effects and that does not require per-scene training or fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/renderformer-transformer-based-neural</guid>
    </item>
    <item>
      <title>AlphaEvolve: A Learning Framework to Discover Novel Alphas in Quantitative Investment</title>
      <link>https://paperswithcode.com/paper/alphaevolve-a-learning-framework-to-discover</link>
      <description><![CDATA[In this paper, we introduce a new class of alphas to model scalar, vector, and matrix features which possess the strengths of these two existing classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alphaevolve-a-learning-framework-to-discover</guid>
    </item>
    <item>
      <title>Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution</title>
      <link>https://paperswithcode.com/paper/alita-generalist-agent-enabling-scalable</link>
      <description><![CDATA[For Maximal self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alita-generalist-agent-enabling-scalable</guid>
    </item>
    <item>
      <title>Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models</title>
      <link>https://paperswithcode.com/paper/impromptu-vla-open-weights-and-open-data-for</link>
      <description><![CDATA[Vision-Language-Action (VLA) models for autonomous driving show promise but falter in unstructured corner case scenarios, largely due to a scarcity of targeted benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/impromptu-vla-open-weights-and-open-data-for</guid>
    </item>
    <item>
      <title>WebDancer: Towards Autonomous Information Seeking Agency</title>
      <link>https://paperswithcode.com/paper/webdancer-towards-autonomous-information</link>
      <description><![CDATA[We instantiate this framework in a web agent based on the ReAct, WebDancer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/webdancer-towards-autonomous-information</guid>
    </item>
    <item>
      <title>Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning</title>
      <link>https://paperswithcode.com/paper/paper2code-automating-code-generation-from</link>
      <description><![CDATA[Despite the rapid growth of machine learning research, corresponding code implementations are often unavailable, making it slow and labor-intensive for researchers to reproduce results and build upon prior work.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paper2code-automating-code-generation-from</guid>
    </item>
    <item>
      <title>MoonCast: High-Quality Zero-Shot Podcast Generation</title>
      <link>https://paperswithcode.com/paper/mooncast-high-quality-zero-shot-podcast</link>
      <description><![CDATA[Recent advances in text-to-speech synthesis have achieved notable success in generating high-quality short utterances for individual speakers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mooncast-high-quality-zero-shot-podcast</guid>
    </item>
    <item>
      <title>Reservoir-enhanced Segment Anything Model for Subsurface Diagnosis</title>
      <link>https://paperswithcode.com/paper/reservoir-enhanced-segment-anything-model-for</link>
      <description><![CDATA[Urban roads and infrastructure, vital to city operations, face growing threats from subsurface anomalies like cracks and cavities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reservoir-enhanced-segment-anything-model-for</guid>
    </item>
    <item>
      <title>SoloSpeech: Enhancing Intelligibility and Quality in Target Speech Extraction through a Cascaded Generative Pipeline</title>
      <link>https://paperswithcode.com/paper/solospeech-enhancing-intelligibility-and</link>
      <description><![CDATA[On the other hand, generative models for TSE lag in perceptual quality and intelligibility.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/solospeech-enhancing-intelligibility-and</guid>
    </item>
    <item>
      <title>DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing</title>
      <link>https://paperswithcode.com/paper/docetl-agentic-query-rewriting-and-evaluation</link>
      <description><![CDATA[Our evaluation on four different unstructured document analysis tasks demonstrates that DocETL finds plans with outputs that are 25 to 80% more accurate than well-engineered baselines, addressing a critical gap in unstructured data analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/docetl-agentic-query-rewriting-and-evaluation</guid>
    </item>
    <item>
      <title>CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs</title>
      <link>https://paperswithcode.com/paper/chexgenbench-a-unified-benchmark-for-fidelity</link>
      <description><![CDATA[Additionally, we release a high-quality, synthetic dataset, SynthCheX-75K, comprising 75K radiographs generated by the top-performing model (Sana 0. 6B) in our benchmark to support further research in this critical domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chexgenbench-a-unified-benchmark-for-fidelity</guid>
    </item>
    <item>
      <title>ChartGalaxy: A Dataset for Infographic Chart Understanding and Generation</title>
      <link>https://paperswithcode.com/paper/chartgalaxy-a-dataset-for-infographic-chart</link>
      <description><![CDATA[We showcase the utility of this dataset through: 1) improving infographic chart understanding via fine-tuning, 2) benchmarking code generation for infographic charts, and 3) enabling example-based infographic chart generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chartgalaxy-a-dataset-for-infographic-chart</guid>
    </item>
    <item>
      <title>AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents</title>
      <link>https://paperswithcode.com/paper/autoagent-a-fully-automated-and-zero-code</link>
      <description><![CDATA[To address this challenge, we introduce AutoAgent-a Fully-Automated and highly Self-Developing framework that enables users to create and deploy LLM agents through Natural Language Alone.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoagent-a-fully-automated-and-zero-code</guid>
    </item>
  </channel>
</rss>
