<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 22 Mar 2025 09:16:15 +0000</lastBuildDate>
    <item>
      <title>VGGT: Visual Geometry Grounded Transformer</title>
      <link>https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</link>
      <description><![CDATA[We present VGGT, a feed-forward neural network that directly infers all key 3D attributes of a scene, including camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</guid>
    </item>
    <item>
      <title>Neural Fields with Thermal Activations for Arbitrary-Scale Super-Resolution</title>
      <link>https://paperswithcode.com/paper/neural-fields-with-thermal-activations-for</link>
      <description><![CDATA[We present a novel way to design neural fields such that points can be queried with an adaptive Gaussian PSF, so as to guarantee correct anti-aliasing at any desired output resolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-fields-with-thermal-activations-for</guid>
    </item>
    <item>
      <title>TxAgent: An AI Agent for Therapeutic Reasoning Across a Universe of Tools</title>
      <link>https://paperswithcode.com/paper/txagent-an-ai-agent-for-therapeutic-reasoning</link>
      <description><![CDATA[It selects tools based on task objectives and executes structured function calls to solve therapeutic tasks that require clinical reasoning and cross-source validation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/txagent-an-ai-agent-for-therapeutic-reasoning</guid>
    </item>
    <item>
      <title>ReasonGraph: Visualisation of Reasoning Paths</title>
      <link>https://paperswithcode.com/paper/reasongraph-visualisation-of-reasoning-paths</link>
      <description><![CDATA[Large Language Models (LLMs) reasoning processes are challenging to analyze due to their complexity and the lack of organized visualization tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reasongraph-visualisation-of-reasoning-paths</guid>
    </item>
    <item>
      <title>Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-outperforms-supervised</link>
      <description><![CDATA[Recently, reinforcement learning (RL) has been shown to greatly enhance the reasoning capabilities of large language models (LLMs), and RL-based approaches have been progressively applied to visual multimodal tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-outperforms-supervised</guid>
    </item>
    <item>
      <title>Step-Video-TI2V Technical Report: A State-of-the-Art Text-Driven Image-to-Video Generation Model</title>
      <link>https://paperswithcode.com/paper/step-video-ti2v-technical-report-a-state-of</link>
      <description><![CDATA[We present Step-Video-TI2V, a state-of-the-art text-driven image-to-video generation model with 30B parameters, capable of generating videos up to 102 frames based on both text and image inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/step-video-ti2v-technical-report-a-state-of</guid>
    </item>
    <item>
      <title>KBLaM: Knowledge Base augmented Language Model</title>
      <link>https://paperswithcode.com/paper/kblam-knowledge-base-augmented-language-model</link>
      <description><![CDATA[In this paper, we propose Knowledge Base augmented Language Model (KBLaM), a new method for augmenting Large Language Models (LLMs) with external knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kblam-knowledge-base-augmented-language-model</guid>
    </item>
    <item>
      <title>Data Formulator 2: Iterative Creation of Data Visualizations, with AI Transforming Data Along the Way</title>
      <link>https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</link>
      <description><![CDATA[Data analysts often need to iterate between data transformations and chart designs to create rich visualizations for exploratory data analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</guid>
    </item>
    <item>
      <title>Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens</title>
      <link>https://paperswithcode.com/paper/2503-01710</link>
      <description><![CDATA[Recent advancements in large language models (LLMs) have driven significant progress in zero-shot text-to-speech (TTS) synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2503-01710</guid>
    </item>
    <item>
      <title>LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds</title>
      <link>https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</link>
      <description><![CDATA[Animatable 3D human reconstruction from a single image is a challenging problem due to the ambiguity in decoupling geometry, appearance, and deformation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</guid>
    </item>
    <item>
      <title>Zero-shot Voice Conversion with Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/zero-shot-voice-conversion-with-diffusion</link>
      <description><![CDATA[Zero-shot voice conversion aims to transform a source speech utterance to match the timbre of a reference speech from an unseen speaker.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-voice-conversion-with-diffusion</guid>
    </item>
    <item>
      <title>YOLOE: Real-Time Seeing Anything</title>
      <link>https://paperswithcode.com/paper/yoloe-real-time-seeing-anything</link>
      <description><![CDATA[Object detection and segmentation are widely employed in computer vision applications, yet conventional models like YOLO series, while efficient and accurate, are limited by predefined categories, hindering adaptability in open scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yoloe-real-time-seeing-anything</guid>
    </item>
    <item>
      <title>Niagara: Normal-Integrated Geometric Affine Field for Scene Reconstruction from a Single View</title>
      <link>https://paperswithcode.com/paper/niagara-normal-integrated-geometric-affine</link>
      <description><![CDATA[Recent advances in single-view 3D scene reconstruction have highlighted the challenges in capturing fine geometric details and ensuring structural consistency, particularly in high-fidelity outdoor scene modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/niagara-normal-integrated-geometric-affine</guid>
    </item>
    <item>
      <title>Evaluating Self-Supervised Learning for Molecular Graph Embeddings</title>
      <link>https://paperswithcode.com/paper/evaluating-self-supervised-learning-for</link>
      <description><![CDATA[Graph Self-Supervised Learning (GSSL) provides a robust pathway for acquiring embeddings without expert labelling, a capability that carries profound implications for molecular graphs due to the staggering number of potential molecules and the high cost of obtaining labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-self-supervised-learning-for</guid>
    </item>
    <item>
      <title>Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models</title>
      <link>https://paperswithcode.com/paper/block-diffusion-interpolating-between</link>
      <description><![CDATA[Diffusion language models offer unique benefits over autoregressive models due to their potential for parallelized generation and controllability, yet they lag in likelihood modeling and are limited to fixed-length generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/block-diffusion-interpolating-between</guid>
    </item>
    <item>
      <title>Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/search-r1-training-llms-to-reason-and</link>
      <description><![CDATA[Efficiently acquiring external knowledge and up-to-date information is essential for effective reasoning and text generation in large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/search-r1-training-llms-to-reason-and</guid>
    </item>
    <item>
      <title>LBM: Latent Bridge Matching for Fast Image-to-Image Translation</title>
      <link>https://paperswithcode.com/paper/lbm-latent-bridge-matching-for-fast-image-to</link>
      <description><![CDATA[In this paper, we introduce Latent Bridge Matching (LBM), a new, versatile and scalable method that relies on Bridge Matching in a latent space to achieve fast image-to-image translation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lbm-latent-bridge-matching-for-fast-image-to</guid>
    </item>
    <item>
      <title>FoundationStereo: Zero-Shot Stereo Matching</title>
      <link>https://paperswithcode.com/paper/foundationstereo-zero-shot-stereo-matching</link>
      <description><![CDATA[However, achieving strong zero-shot generalization - a hallmark of foundation models in other computer vision tasks - remains challenging for stereo matching.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundationstereo-zero-shot-stereo-matching</guid>
    </item>
    <item>
      <title>Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation</title>
      <link>https://paperswithcode.com/paper/hunyuan3d-2-0-scaling-diffusion-models-for</link>
      <description><![CDATA[This system includes two foundation components: a large-scale shape generation model -- Hunyuan3D-DiT, and a large-scale texture synthesis model -- Hunyuan3D-Paint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuan3d-2-0-scaling-diffusion-models-for</guid>
    </item>
    <item>
      <title>Agent S: An Open Agentic Framework that Uses Computers Like a Human</title>
      <link>https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</link>
      <description><![CDATA[We present Agent S, an open agentic framework that enables autonomous interaction with computers through a Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</guid>
    </item>
  </channel>
</rss>
