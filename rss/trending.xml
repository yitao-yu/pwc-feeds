<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 09 Oct 2024 09:17:10 +0000</lastBuildDate>
    <item>
      <title>Depth Pro: Sharp Monocular Metric Depth in Less Than a Second</title>
      <link>https://paperswithcode.com/paper/depth-pro-sharp-monocular-metric-depth-in</link>
      <description><![CDATA[We present a foundation model for zero-shot metric monocular depth estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depth-pro-sharp-monocular-metric-depth-in</guid>
    </item>
    <item>
      <title>VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/vptq-extreme-low-bit-vector-post-training</link>
      <description><![CDATA[Due to the redundancy in LLM weights, recent research has focused on pushing weight-only quantization to extremely low-bit (even down to 2 bits).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vptq-extreme-low-bit-vector-post-training</guid>
    </item>
    <item>
      <title>MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages</title>
      <link>https://paperswithcode.com/paper/mosel-950000-hours-of-speech-data-for-open</link>
      <description><![CDATA[The rise of foundation models (FMs), coupled with regulatory efforts addressing their risks and impacts, has sparked significant interest in open-source models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mosel-950000-hours-of-speech-data-for-open</guid>
    </item>
    <item>
      <title>"Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models</title>
      <link>https://paperswithcode.com/paper/do-anything-now-characterizing-and-evaluating</link>
      <description><![CDATA[We hope that our study can facilitate the research community and LLM vendors in promoting safer and regulated LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-anything-now-characterizing-and-evaluating</guid>
    </item>
    <item>
      <title>Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers</title>
      <link>https://paperswithcode.com/paper/scaling-proprioceptive-visual-learning-with</link>
      <description><![CDATA[Previous robot learning methods often collect data to train with one specific embodiment for one task, which is expensive and prone to overfitting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-proprioceptive-visual-learning-with</guid>
    </item>
    <item>
      <title>TPI-LLM: Serving 70B-scale LLMs Efficiently on Low-resource Edge Devices</title>
      <link>https://paperswithcode.com/paper/tpi-llm-serving-70b-scale-llms-efficiently-on</link>
      <description><![CDATA[In this paper, we argue that tensor parallelism can be more effective than pipeline on low-resource devices, and present a compute- and memory-efficient tensor parallel inference system, named TPI-LLM, to serve 70B-scale models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tpi-llm-serving-70b-scale-llms-efficiently-on</guid>
    </item>
    <item>
      <title>Posterior-Mean Rectified Flow: Towards Minimum MSE Photo-Realistic Image Restoration</title>
      <link>https://paperswithcode.com/paper/posterior-mean-rectified-flow-towards-minimum</link>
      <description><![CDATA[Photo-realistic image restoration algorithms are typically evaluated by distortion measures (e. g., PSNR, SSIM) and by perceptual quality measures (e. g., FID, NIQE), where the desire is to attain the lowest possible distortion without compromising on perceptual quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posterior-mean-rectified-flow-towards-minimum</guid>
    </item>
    <item>
      <title>SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration</title>
      <link>https://paperswithcode.com/paper/sageattention-accurate-8-bit-attention-for</link>
      <description><![CDATA[Although quantization has proven to be an effective method for accelerating model inference, existing quantization methods primarily focus on optimizing the linear layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sageattention-accurate-8-bit-attention-for</guid>
    </item>
    <item>
      <title>One Policy to Run Them All: an End-to-end Learning Approach to Multi-Embodiment Locomotion</title>
      <link>https://paperswithcode.com/paper/one-policy-to-run-them-all-an-end-to-end</link>
      <description><![CDATA[Our experiments show that URMA can learn a locomotion policy on multiple embodiments that can be easily transferred to unseen robot platforms in simulation and the real world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-policy-to-run-them-all-an-end-to-end</guid>
    </item>
    <item>
      <title>MinerU: An Open-Source Solution for Precise Document Content Extraction</title>
      <link>https://paperswithcode.com/paper/mineru-an-open-source-solution-for-precise</link>
      <description><![CDATA[Document content analysis has been a crucial research area in computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mineru-an-open-source-solution-for-precise</guid>
    </item>
    <item>
      <title>MiraGe: Editable 2D Images using Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/mirage-editable-2d-images-using-gaussian</link>
      <description><![CDATA[Our approach improves the rendering quality and allows realistic image modifications, including human-inspired perception of photos in the 3D world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mirage-editable-2d-images-using-gaussian</guid>
    </item>
    <item>
      <title>VinePPO: Unlocking RL Potential For LLM Reasoning Through Refined Credit Assignment</title>
      <link>https://paperswithcode.com/paper/vineppo-unlocking-rl-potential-for-llm</link>
      <description><![CDATA[In this work, we systematically evaluate the efficacy of value networks and reveal their significant shortcomings in reasoning-heavy LLM tasks, showing that they barely outperform a random baseline when comparing alternative steps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vineppo-unlocking-rl-potential-for-llm</guid>
    </item>
    <item>
      <title>OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer</title>
      <link>https://paperswithcode.com/paper/omagent-a-multi-modal-agent-framework-for</link>
      <description><![CDATA[Recent advancements in Large Language Models (LLMs) have expanded their capabilities to multimodal contexts, including comprehensive video understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omagent-a-multi-modal-agent-framework-for</guid>
    </item>
    <item>
      <title>Fira: Can We Achieve Full-rank Training of LLMs Under Low-rank Constraint?</title>
      <link>https://paperswithcode.com/paper/fira-can-we-achieve-full-rank-training-of</link>
      <description><![CDATA[In this way, we can preserve the low-rank constraint in the optimizer while achieving full-rank training for better performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fira-can-we-achieve-full-rank-training-of</guid>
    </item>
    <item>
      <title>A Multi-Level Superoptimizer for Tensor Programs</title>
      <link>https://paperswithcode.com/paper/a-multi-level-superoptimizer-for-tensor</link>
      <description><![CDATA[We introduce Mirage, the first multi-level superoptimizer for tensor programs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-multi-level-superoptimizer-for-tensor</guid>
    </item>
    <item>
      <title>3DGS-DET: Empower 3D Gaussian Splatting with Boundary Guidance and Box-Focused Sampling for 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/3dgs-det-empower-3d-gaussian-splatting-with</link>
      <description><![CDATA[Neural Radiance Fields (NeRF) are widely used for novel-view synthesis and have been adapted for 3D Object Detection (3DOD), offering a promising approach to 3DOD through view-synthesis representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dgs-det-empower-3d-gaussian-splatting-with</guid>
    </item>
    <item>
      <title>CAX: Cellular Automata Accelerated in JAX</title>
      <link>https://paperswithcode.com/paper/cax-cellular-automata-accelerated-in-jax</link>
      <description><![CDATA[Cellular automata have become a cornerstone for investigating emergence and self-organization across diverse scientific disciplines, spanning neuroscience, artificial life, and theoretical physics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cax-cellular-automata-accelerated-in-jax</guid>
    </item>
    <item>
      <title>Breaking reCAPTCHAv2</title>
      <link>https://paperswithcode.com/paper/breaking-recaptchav2</link>
      <description><![CDATA[Our work examines the efficacy of employing advanced machine learning methods to solve captchas from Google's reCAPTCHAv2 system.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/breaking-recaptchav2</guid>
    </item>
    <item>
      <title>Dynamic Diffusion Transformer</title>
      <link>https://paperswithcode.com/paper/dynamic-diffusion-transformer</link>
      <description><![CDATA[In addition, we design a Spatial-wise Dynamic Token (SDT) strategy to avoid redundant computation at unnecessary spatial locations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-diffusion-transformer</guid>
    </item>
    <item>
      <title>AWT: Transferring Vision-Language Models via Augmentation, Weighting, and Transportation</title>
      <link>https://paperswithcode.com/paper/awt-transferring-vision-language-models-via</link>
      <description><![CDATA[Pre-trained vision-language models (VLMs) have shown impressive results in various visual classification tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/awt-transferring-vision-language-models-via</guid>
    </item>
  </channel>
</rss>
