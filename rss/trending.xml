<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 28 Dec 2022 09:12:09 +0000</lastBuildDate>
    <item>
      <title>Point-E: A System for Generating 3D Point Clouds from Complex Prompts</title>
      <link>https://paperswithcode.com/paper/point-e-a-system-for-generating-3d-point</link>
      <description><![CDATA[This is in stark contrast to state-of-the-art generative image models, which produce samples in a number of seconds or minutes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/point-e-a-system-for-generating-3d-point</guid>
    </item>
    <item>
      <title>Scalable Diffusion Models with Transformers</title>
      <link>https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</link>
      <description><![CDATA[We explore a new class of diffusion models based on the transformer architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</guid>
    </item>
    <item>
      <title>Generalized Decoding for Pixel, Image, and Language</title>
      <link>https://paperswithcode.com/paper/generalized-decoding-for-pixel-image-and</link>
      <description><![CDATA[We present X-Decoder, a generalized decoding model that can predict pixel-level segmentation and language tokens seamlessly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-decoding-for-pixel-image-and</guid>
    </item>
    <item>
      <title>Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning</title>
      <link>https://paperswithcode.com/paper/alpa-automating-inter-and-intra-operator</link>
      <description><![CDATA[Existing model-parallel training systems either require users to manually create a parallelization plan or automatically generate one from a limited space of model parallelism configurations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alpa-automating-inter-and-intra-operator</guid>
    </item>
    <item>
      <title>OPT: Open Pre-trained Transformer Language Models</title>
      <link>https://paperswithcode.com/paper/opt-open-pre-trained-transformer-language</link>
      <description><![CDATA[Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/opt-open-pre-trained-transformer-language</guid>
    </item>
    <item>
      <title>Deep Architectures for Content Moderation and Movie Content Rating</title>
      <link>https://paperswithcode.com/paper/deep-architectures-for-content-moderation-and</link>
      <description><![CDATA[Rating a video based on its content is an important step for classifying video age categories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-architectures-for-content-moderation-and</guid>
    </item>
    <item>
      <title>Fast DistilBERT on CPUs</title>
      <link>https://paperswithcode.com/paper/fast-distilbert-on-cpus</link>
      <description><![CDATA[In this work, we propose a new pipeline for creating and running Fast Transformer models on CPUs, utilizing hardware-aware pruning, knowledge distillation, quantization, and our own Transformer inference runtime engine with optimized kernels for sparse and quantized operators.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-distilbert-on-cpus</guid>
    </item>
    <item>
      <title>DI-engine</title>
      <link>https://github.com/opendilab/DI-engine</link>
      <description><![CDATA[OpenDILab Decision AI Engine]]></description>
      <guid isPermaLink="true">https://github.com/opendilab/DI-engine</guid>
    </item>
    <item>
      <title>Benchmarking and Analyzing Point Cloud Classification under Corruptions</title>
      <link>https://paperswithcode.com/paper/benchmarking-and-analyzing-point-cloud</link>
      <description><![CDATA[3D perception, especially point cloud classification, has achieved substantial progress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-and-analyzing-point-cloud</guid>
    </item>
    <item>
      <title>MemPrompt: Memory-assisted Prompt Editing with User Feedback</title>
      <link>https://paperswithcode.com/paper/memory-assisted-prompt-editing-to-improve-gpt</link>
      <description><![CDATA[Large LMs such as GPT-3 are powerful, but can commit mistakes that are obvious to humans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memory-assisted-prompt-editing-to-improve-gpt</guid>
    </item>
    <item>
      <title>OpenFE: Automated Feature Generation beyond Expert-level Performance</title>
      <link>https://paperswithcode.com/paper/openfe-automated-feature-generation-beyond</link>
      <description><![CDATA[The major challenge in automated feature generation is to efficiently and accurately identify useful features from a vast pool of candidate features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openfe-automated-feature-generation-beyond</guid>
    </item>
    <item>
      <title>DeepLSD: Line Segment Detection and Refinement with Deep Image Gradients</title>
      <link>https://paperswithcode.com/paper/deeplsd-line-segment-detection-and-refinement</link>
      <description><![CDATA[Their learned counterparts are more repeatable and can handle challenging images, but at the cost of a lower accuracy and a bias towards wireframe lines.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deeplsd-line-segment-detection-and-refinement</guid>
    </item>
    <item>
      <title>Towards Reasoning in Large Language Models: A Survey</title>
      <link>https://paperswithcode.com/paper/towards-reasoning-in-large-language-models-a</link>
      <description><![CDATA[Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-reasoning-in-large-language-models-a</guid>
    </item>
    <item>
      <title>GPT-NeoX-20B: An Open-Source Autoregressive Language Model</title>
      <link>https://paperswithcode.com/paper/gpt-neox-20b-an-open-source-autoregressive-1</link>
      <description><![CDATA[We introduce GPT-NeoX-20B, a 20 billion parameter autoregressive language model trained on the Pile, whose weights will be made freely and openly available to the public through a permissive license.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-neox-20b-an-open-source-autoregressive-1</guid>
    </item>
    <item>
      <title>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</title>
      <link>https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</link>
      <description><![CDATA[Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</guid>
    </item>
    <item>
      <title>The Forward-Forward Algorithm: Some Preliminary Investigations</title>
      <link>https://paperswithcode.com/paper/the-forward-forward-algorithm-some</link>
      <description><![CDATA[The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth serious investigation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-forward-forward-algorithm-some</guid>
    </item>
    <item>
      <title>Self-Instruct: Aligning Language Model with Self Generated Instructions</title>
      <link>https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</link>
      <description><![CDATA[Applying our method to vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT_001, which is trained with private user data and human annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</guid>
    </item>
    <item>
      <title>Active-Learning-as-a-Service: An Automatic and Efficient MLOps System for Data-Centric AI</title>
      <link>https://paperswithcode.com/paper/active-learning-as-a-service-an-efficient</link>
      <description><![CDATA[In data-centric AI, active learning (AL) plays a vital role, but current AL tools 1) require users to manually select AL strategies, and 2) can not perform AL tasks efficiently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/active-learning-as-a-service-an-efficient</guid>
    </item>
    <item>
      <title>Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal</title>
      <link>https://paperswithcode.com/paper/reasoning-over-different-types-of-knowledge</link>
      <description><![CDATA[The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reasoning-over-different-types-of-knowledge</guid>
    </item>
    <item>
      <title>ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via Regularized Domain Concatenation</title>
      <link>https://paperswithcode.com/paper/conda-unsupervised-domain-adaptation-for</link>
      <description><![CDATA[To improve both the network training on the source domain and self-training on the intermediate domain, we propose an anti-aliasing regularizer and an entropy aggregator to reduce the negative effect caused by the aliasing artifacts and noisy pseudo labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conda-unsupervised-domain-adaptation-for</guid>
    </item>
  </channel>
</rss>
