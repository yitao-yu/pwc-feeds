<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 23 Oct 2022 09:19:19 +0000</lastBuildDate>
    <item>
      <title>Prompt-to-Prompt Image Editing with Cross Attention Control</title>
      <link>https://paperswithcode.com/paper/prompt-to-prompt-image-editing-with-cross</link>
      <description><![CDATA[Editing is challenging for these generative models, since an innate property of an editing technique is to preserve most of the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-to-prompt-image-editing-with-cross</guid>
    </item>
    <item>
      <title>Token Merging: Your ViT But Faster</title>
      <link>https://paperswithcode.com/paper/token-merging-your-vit-but-faster</link>
      <description><![CDATA[Off-the-shelf, ToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518 models on images and 2. 2x the throughput of ViT-L on video with only a 0. 2-0. 3% accuracy drop in each case.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/token-merging-your-vit-but-faster</guid>
    </item>
    <item>
      <title>Parametric and Multivariate Uncertainty Calibration for Regression and Object Detection</title>
      <link>https://paperswithcode.com/paper/parametric-and-multivariate-uncertainty</link>
      <description><![CDATA[Our experiments show that common detection models overestimate the spatial uncertainty in comparison to the observed error.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parametric-and-multivariate-uncertainty</guid>
    </item>
    <item>
      <title>TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second</title>
      <link>https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</link>
      <description><![CDATA[We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</guid>
    </item>
    <item>
      <title>Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera</title>
      <link>https://paperswithcode.com/paper/neural-surface-reconstruction-of-dynamic</link>
      <description><![CDATA[We propose Neural-DynamicReconstruction (NDR), a template-free method to recover high-fidelity geometry and motions of a dynamic scene from a monocular RGB-D camera.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-surface-reconstruction-of-dynamic</guid>
    </item>
    <item>
      <title>DreamFusion: Text-to-3D using 2D Diffusion</title>
      <link>https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</link>
      <description><![CDATA[Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</guid>
    </item>
    <item>
      <title>Learning to Discover and Detect Objects</title>
      <link>https://paperswithcode.com/paper/learning-to-discover-and-detect-objects</link>
      <description><![CDATA[To this end, we propose a two-stage object detection network Region-based NCDL (RNCDL), that uses a region proposal network to localize object candidates and is trained to classify each candidate, either as one of the known classes, seen in the source dataset, or one of the extended set of novel classes, with a long-tail distribution constraint on the class assignments, reflecting the natural frequency of classes in the real world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-discover-and-detect-objects</guid>
    </item>
    <item>
      <title>DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/diffuseq-sequence-to-sequence-text-generation</link>
      <description><![CDATA[Recently, diffusion models have emerged as a new paradigm for generative models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffuseq-sequence-to-sequence-text-generation</guid>
    </item>
    <item>
      <title>Automatic Differentiation of Programs with Discrete Randomness</title>
      <link>https://paperswithcode.com/paper/automatic-differentiation-of-programs-with</link>
      <description><![CDATA[Automatic differentiation (AD), a technique for constructing new programs which compute the derivative of an original program, has become ubiquitous throughout scientific computing and deep learning due to the improved performance afforded by gradient-based optimization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automatic-differentiation-of-programs-with</guid>
    </item>
    <item>
      <title>DiffCloth: Differentiable Cloth Simulation with Dry Frictional Contact</title>
      <link>https://paperswithcode.com/paper/diffcloth-differentiable-cloth-simulation</link>
      <description><![CDATA[This work presents a differentiable cloth simulator whose additional gradient information facilitates cloth-related applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffcloth-differentiable-cloth-simulation</guid>
    </item>
    <item>
      <title>Deep Bidirectional Language-Knowledge Graph Pretraining</title>
      <link>https://paperswithcode.com/paper/deep-bidirectional-language-knowledge-graph</link>
      <description><![CDATA[Pretraining a language model (LM) on text has been shown to help various downstream NLP tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-bidirectional-language-knowledge-graph</guid>
    </item>
    <item>
      <title>TOIST: Task Oriented Instance Segmentation Transformer with Noun-Pronoun Distillation</title>
      <link>https://paperswithcode.com/paper/toist-task-oriented-instance-segmentation</link>
      <description><![CDATA[As such, we study the challenging problem of task oriented detection, which aims to find objects that best afford an action indicated by verbs like sit comfortably on.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toist-task-oriented-instance-segmentation</guid>
    </item>
    <item>
      <title>Musika! Fast Infinite Waveform Music Generation</title>
      <link>https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</link>
      <description><![CDATA[We release the source code and pretrained autoencoder weights at github. com/marcoppasini/musika, such that a GAN can be trained on a new music domain with a single GPU in a matter of hours.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</guid>
    </item>
    <item>
      <title>AdaptivePose++: A Powerful Single-Stage Network for Multi-Person Pose Regression</title>
      <link>https://paperswithcode.com/paper/adaptivepose-a-powerful-single-stage-network</link>
      <description><![CDATA[With the proposed body representation, we further deliver a compact single-stage multi-person pose regression network, termed as AdaptivePose.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adaptivepose-a-powerful-single-stage-network</guid>
    </item>
    <item>
      <title>HyperDomainNet: Universal Domain Adaptation for Generative Adversarial Networks</title>
      <link>https://paperswithcode.com/paper/hyperdomainnet-universal-domain-adaptation</link>
      <description><![CDATA[We apply this parameterization to the state-of-art domain adaptation methods and show that it has almost the same expressiveness as the full parameter space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyperdomainnet-universal-domain-adaptation</guid>
    </item>
    <item>
      <title>MTEB: Massive Text Embedding Benchmark</title>
      <link>https://paperswithcode.com/paper/mteb-massive-text-embedding-benchmark</link>
      <description><![CDATA[MTEB spans 8 embedding tasks covering a total of 56 datasets and 112 languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mteb-massive-text-embedding-benchmark</guid>
    </item>
    <item>
      <title>Poisson Flow Generative Models</title>
      <link>https://paperswithcode.com/paper/poisson-flow-generative-models</link>
      <description><![CDATA[We interpret the data points as electrical charges on the $z=0$ hyperplane in a space augmented with an additional dimension $z$, generating a high-dimensional electric field (the gradient of the solution to Poisson equation).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poisson-flow-generative-models</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance</title>
      <link>https://paperswithcode.com/paper/unifying-diffusion-models-latent-space-with</link>
      <description><![CDATA[The commonly-adopted formulation of the latent code of diffusion models is a sequence of gradually denoised samples, as opposed to the simpler (e. g., Gaussian) latent space of GANs, VAEs, and normalizing flows.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unifying-diffusion-models-latent-space-with</guid>
    </item>
    <item>
      <title>Gaussian-Bernoulli RBMs Without Tears</title>
      <link>https://paperswithcode.com/paper/gaussian-bernoulli-rbms-without-tears</link>
      <description><![CDATA[We revisit the challenging problem of training Gaussian-Bernoulli restricted Boltzmann machines (GRBMs), introducing two innovations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaussian-bernoulli-rbms-without-tears</guid>
    </item>
  </channel>
</rss>
