<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 07 Feb 2023 09:13:09 +0000</lastBuildDate>
    <item>
      <title>BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining</title>
      <link>https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</link>
      <description><![CDATA[Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</guid>
    </item>
    <item>
      <title>Multimodal Chain-of-Thought Reasoning in Language Models</title>
      <link>https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</link>
      <description><![CDATA[By incorporating the vision features in both stages, the model is able to generate effective rationales that contribute to answer inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</guid>
    </item>
    <item>
      <title>TEXTure: Text-Guided Texturing of 3D Shapes</title>
      <link>https://paperswithcode.com/paper/texture-text-guided-texturing-of-3d-shapes</link>
      <description><![CDATA[In this paper, we present TEXTure, a novel method for text-guided generation, editing, and transfer of textures for 3D shapes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/texture-text-guided-texturing-of-3d-shapes</guid>
    </item>
    <item>
      <title>BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</title>
      <link>https://paperswithcode.com/paper/blip-2-bootstrapping-language-image-pre</link>
      <description><![CDATA[The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blip-2-bootstrapping-language-image-pre</guid>
    </item>
    <item>
      <title>Open Source Vizier: Distributed Infrastructure and API for Reliable and Flexible Blackbox Optimization</title>
      <link>https://paperswithcode.com/paper/open-source-vizier-distributed-infrastructure</link>
      <description><![CDATA[Vizier is the de-facto blackbox and hyperparameter optimization service across Google, having optimized some of Google's largest products and research efforts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-source-vizier-distributed-infrastructure</guid>
    </item>
    <item>
      <title>NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality</title>
      <link>https://paperswithcode.com/paper/naturalspeech-end-to-end-text-to-speech</link>
      <description><![CDATA[In this paper, we answer these questions by first defining the human-level quality based on the statistical significance of subjective measure and introducing appropriate guidelines to judge it, and then developing a TTS system called NaturalSpeech that achieves human-level quality on a benchmark dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/naturalspeech-end-to-end-text-to-speech</guid>
    </item>
    <item>
      <title>STEPS: Joint Self-supervised Nighttime Image Enhancement and Depth Estimation</title>
      <link>https://paperswithcode.com/paper/steps-joint-self-supervised-nighttime-image</link>
      <description><![CDATA[By fitting a bridge-shaped curve to the illumination map distribution, both regions are suppressed and two tasks are bridged naturally.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/steps-joint-self-supervised-nighttime-image</guid>
    </item>
    <item>
      <title>Learning the Beauty in Songs: Neural Singing Voice Beautifier</title>
      <link>https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</link>
      <description><![CDATA[Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</guid>
    </item>
    <item>
      <title>InstructPix2Pix: Learning to Follow Image Editing Instructions</title>
      <link>https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</link>
      <description><![CDATA[We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>Dual PatchNorm</title>
      <link>https://paperswithcode.com/paper/dual-patchnorm</link>
      <description><![CDATA[We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms), before and after the patch embedding layer in Vision Transformers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-patchnorm</guid>
    </item>
    <item>
      <title>Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/attend-and-excite-attention-based-semantic</link>
      <description><![CDATA[Recent text-to-image generative models have demonstrated an unparalleled ability to generate diverse and creative imagery guided by a target text prompt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attend-and-excite-attention-based-semantic</guid>
    </item>
    <item>
      <title>Salesforce CausalAI Library: A Fast and Scalable Framework for Causal Analysis of Time Series and Tabular Data</title>
      <link>https://paperswithcode.com/paper/salesforce-causalai-library-a-fast-and</link>
      <description><![CDATA[We introduce the Salesforce CausalAI Library, an open-source library for causal analysis using observational data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/salesforce-causalai-library-a-fast-and</guid>
    </item>
    <item>
      <title>OpenSpike: An OpenRAM SNN Accelerator</title>
      <link>https://paperswithcode.com/paper/openspike-an-openram-snn-accelerator</link>
      <description><![CDATA[This paper presents a spiking neural network (SNN) accelerator made using fully open-source EDA tools, process design kit (PDK), and memory macros synthesized using OpenRAM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openspike-an-openram-snn-accelerator</guid>
    </item>
    <item>
      <title>Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline</title>
      <link>https://paperswithcode.com/paper/fast-bev-a-fast-and-strong-bird-s-eye-view</link>
      <description><![CDATA[Our Fast-BEV consists of five parts, We novelly propose (1) a lightweight deployment-friendly view transformation which fast transfers 2D image feature to 3D voxel space, (2) an multi-scale image encoder which leverages multi-scale information for better performance, (3) an efficient BEV encoder which is particularly designed to speed up on-vehicle inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-bev-a-fast-and-strong-bird-s-eye-view</guid>
    </item>
    <item>
      <title>Cut and Learn for Unsupervised Object Detection and Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/cut-and-learn-for-unsupervised-object</link>
      <description><![CDATA[We propose Cut-and-LEaRn (CutLER), a simple approach for training unsupervised object detection and segmentation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cut-and-learn-for-unsupervised-object</guid>
    </item>
    <item>
      <title>Epic-Sounds: A Large-scale Dataset of Actions That Sound</title>
      <link>https://paperswithcode.com/paper/epic-sounds-a-large-scale-dataset-of-actions</link>
      <description><![CDATA[We introduce EPIC-SOUNDS, a large-scale dataset of audio annotations capturing temporal extents and class labels within the audio stream of the egocentric videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/epic-sounds-a-large-scale-dataset-of-actions</guid>
    </item>
    <item>
      <title>LAION-5B: An open large-scale dataset for training next generation image-text models</title>
      <link>https://paperswithcode.com/paper/laion-5b-an-open-large-scale-dataset-for-1</link>
      <description><![CDATA[We show successful replication and fine-tuning of foundational models like CLIP, GLIDE and Stable Diffusion using the dataset, and discuss further experiments enabled with an openly available dataset of this scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/laion-5b-an-open-large-scale-dataset-for-1</guid>
    </item>
    <item>
      <title>ArchiSound: Audio Generation with Diffusion</title>
      <link>https://paperswithcode.com/paper/archisound-audio-generation-with-diffusion</link>
      <description><![CDATA[The recent surge in popularity of diffusion models for image generation has brought new attention to the potential of these models in other areas of media generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/archisound-audio-generation-with-diffusion</guid>
    </item>
  </channel>
</rss>
