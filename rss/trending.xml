<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 22 Dec 2024 09:14:01 +0000</lastBuildDate>
    <item>
      <title>Monolith: Real Time Recommendation System With Collisionless Embedding Table</title>
      <link>https://paperswithcode.com/paper/monolith-real-time-recommendation-system-with</link>
      <description><![CDATA[In this paper, we present Monolith, a system tailored for online training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monolith-real-time-recommendation-system-with</guid>
    </item>
    <item>
      <title>Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference</title>
      <link>https://paperswithcode.com/paper/smarter-better-faster-longer-a-modern</link>
      <description><![CDATA[Encoder-only transformer models such as BERT offer a great performance-size tradeoff for retrieval and classification tasks with respect to larger decoder-only models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smarter-better-faster-longer-a-modern</guid>
    </item>
    <item>
      <title>CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models</title>
      <link>https://paperswithcode.com/paper/cosyvoice-2-scalable-streaming-speech</link>
      <description><![CDATA[By training on a large-scale multilingual dataset, CosyVoice 2 achieves human-parity naturalness, minimal response latency, and virtually lossless synthesis quality in the streaming mode.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cosyvoice-2-scalable-streaming-speech</guid>
    </item>
    <item>
      <title>Byte Latent Transformer: Patches Scale Better Than Tokens</title>
      <link>https://paperswithcode.com/paper/byte-latent-transformer-patches-scale-better</link>
      <description><![CDATA[We introduce the Byte Latent Transformer (BLT), a new byte-level LLM architecture that, for the first time, matches tokenization-based LLM performance at scale with significant improvements in inference efficiency and robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/byte-latent-transformer-patches-scale-better</guid>
    </item>
    <item>
      <title>Semantic Operators: A Declarative Model for Rich, AI-based Analytics Over Text Data</title>
      <link>https://paperswithcode.com/paper/lotus-enabling-semantic-queries-with-llms</link>
      <description><![CDATA[Furthermore, we develop several novel optimizations that take advantage of the declarative nature of semantic operators to accelerate semantic filtering, clustering and join operators by up to $400\times$ while offering statistical accuracy guarantees.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lotus-enabling-semantic-queries-with-llms</guid>
    </item>
    <item>
      <title>Learning Flow Fields in Attention for Controllable Person Image Generation</title>
      <link>https://paperswithcode.com/paper/learning-flow-fields-in-attention-for</link>
      <description><![CDATA[Additionally, we show that our loss is model-agnostic and can be used to improve the performance of other diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-flow-fields-in-attention-for</guid>
    </item>
    <item>
      <title>Autoregressive Video Generation without Vector Quantization</title>
      <link>https://paperswithcode.com/paper/autoregressive-video-generation-without</link>
      <description><![CDATA[This paper presents a novel approach that enables autoregressive video generation with high efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoregressive-video-generation-without</guid>
    </item>
    <item>
      <title>Large Concept Models: Language Modeling in a Sentence Representation Space</title>
      <link>https://paperswithcode.com/paper/large-concept-models-language-modeling-in-a</link>
      <description><![CDATA[In this paper, we present an attempt at an architecture which operates on an explicit higher-level semantic representation, which we name a concept.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-concept-models-language-modeling-in-a</guid>
    </item>
    <item>
      <title>SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos</title>
      <link>https://paperswithcode.com/paper/slam3r-real-time-dense-scene-reconstruction</link>
      <description><![CDATA[In this paper, we introduce SLAM3R, a novel and effective monocular RGB SLAM system for real-time and high-quality dense 3D reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/slam3r-real-time-dense-scene-reconstruction</guid>
    </item>
    <item>
      <title>PsyDraw: A Multi-Agent Multimodal System for Mental Health Screening in Left-Behind Children</title>
      <link>https://paperswithcode.com/paper/psydraw-a-multi-agent-multimodal-system-for</link>
      <description><![CDATA[Left-behind children (LBCs), numbering over 66 million in China, face severe mental health challenges due to parental migration for work.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/psydraw-a-multi-agent-multimodal-system-for</guid>
    </item>
    <item>
      <title>Best-of-N Jailbreaking</title>
      <link>https://paperswithcode.com/paper/best-of-n-jailbreaking</link>
      <description><![CDATA[We find that BoN Jailbreaking achieves high attack success rates (ASRs) on closed-source language models, such as 89% on GPT-4o and 78% on Claude 3. 5 Sonnet when sampling 10, 000 augmented prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/best-of-n-jailbreaking</guid>
    </item>
    <item>
      <title>DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</link>
      <description><![CDATA[We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</guid>
    </item>
    <item>
      <title>LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis</title>
      <link>https://paperswithcode.com/paper/levitor-3d-trajectory-oriented-image-to-video</link>
      <description><![CDATA[The intuitive nature of drag-based interaction has led to its growing adoption for controlling object trajectories in image-to-video synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/levitor-3d-trajectory-oriented-image-to-video</guid>
    </item>
    <item>
      <title>Lyra: An Efficient and Speech-Centric Framework for Omni-Cognition</title>
      <link>https://paperswithcode.com/paper/lyra-an-efficient-and-speech-centric</link>
      <description><![CDATA[As Multi-modal Large Language Models (MLLMs) evolve, expanding beyond single-domain capabilities is essential to meet the demands for more versatile and efficient AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lyra-an-efficient-and-speech-centric</guid>
    </item>
    <item>
      <title>StableAnimator: High-Quality Identity-Preserving Human Image Animation</title>
      <link>https://paperswithcode.com/paper/stableanimator-high-quality-identity</link>
      <description><![CDATA[During inference, we propose a novel Hamilton-Jacobi-Bellman (HJB) equation-based optimization to further enhance the face quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stableanimator-high-quality-identity</guid>
    </item>
    <item>
      <title>OpenEMMA: Open-Source Multimodal Model for End-to-End Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/openemma-open-source-multimodal-model-for-end</link>
      <description><![CDATA[Furthermore, OpenEMMA demonstrates effectiveness, generalizability, and robustness across a variety of challenging driving scenarios, offering a more efficient and effective approach to autonomous driving.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openemma-open-source-multimodal-model-for-end</guid>
    </item>
    <item>
      <title>AnySat: An Earth Observation Model for Any Resolutions, Scales, and Modalities</title>
      <link>https://paperswithcode.com/paper/anysat-an-earth-observation-model-for-any</link>
      <description><![CDATA[Geospatial models must adapt to the diversity of Earth observation data in terms of resolutions, scales, and modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anysat-an-earth-observation-model-for-any</guid>
    </item>
    <item>
      <title>Causal Diffusion Transformers for Generative Modeling</title>
      <link>https://paperswithcode.com/paper/causal-diffusion-transformers-for-generative</link>
      <description><![CDATA[We introduce Causal Diffusion as the autoregressive (AR) counterpart of Diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causal-diffusion-transformers-for-generative</guid>
    </item>
    <item>
      <title>Video Seal: Open and Efficient Video Watermarking</title>
      <link>https://paperswithcode.com/paper/video-seal-open-and-efficient-video</link>
      <description><![CDATA[To reduce these gaps, this paper introduces Video Seal, a comprehensive framework for neural video watermarking and a competitive open-sourced model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-seal-open-and-efficient-video</guid>
    </item>
    <item>
      <title>HunyuanVideo: A Systematic Framework For Large Video Generative Models</title>
      <link>https://paperswithcode.com/paper/hunyuanvideo-a-systematic-framework-for-large</link>
      <description><![CDATA[In this report, we introduce HunyuanVideo, an innovative open-source video foundation model that demonstrates performance in video generation comparable to, or even surpassing, that of leading closed-source models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuanvideo-a-systematic-framework-for-large</guid>
    </item>
  </channel>
</rss>
