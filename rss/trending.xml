<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 12 Mar 2023 21:06:05 +0000</lastBuildDate>
    <item>
      <title>Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models</title>
      <link>https://paperswithcode.com/paper/visual-chatgpt-talking-drawing-and-editing</link>
      <description><![CDATA[To this end, We build a system called \textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-chatgpt-talking-drawing-and-editing</guid>
    </item>
    <item>
      <title>Deep symbolic regression for physics guided by units constraints: toward the automated discovery of physical laws</title>
      <link>https://paperswithcode.com/paper/deep-symbolic-regression-for-physics-guided</link>
      <description><![CDATA[Here we present $\Phi$-SO, a Physical Symbolic Optimization framework for recovering analytical symbolic expressions from physics data using deep reinforcement learning techniques by learning units constraints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-symbolic-regression-for-physics-guided</guid>
    </item>
    <item>
      <title>Prismer: A Vision-Language Model with An Ensemble of Experts</title>
      <link>https://paperswithcode.com/paper/prismer-a-vision-language-model-with-an</link>
      <description><![CDATA[Recent vision-language models have shown impressive multi-modal generation capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prismer-a-vision-language-model-with-an</guid>
    </item>
    <item>
      <title>LLaMA: Open and Efficient Foundation Language Models</title>
      <link>https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</link>
      <description><![CDATA[We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</guid>
    </item>
    <item>
      <title>X-Avatar: Expressive Human Avatars</title>
      <link>https://paperswithcode.com/paper/x-avatar-expressive-human-avatars</link>
      <description><![CDATA[Our method models bodies, hands, facial expressions and appearance in a holistic fashion and can be learned from either full 3D scans or RGB-D data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/x-avatar-expressive-human-avatars</guid>
    </item>
    <item>
      <title>Cones: Concept Neurons in Diffusion Models for Customized Generation</title>
      <link>https://paperswithcode.com/paper/cones-concept-neurons-in-diffusion-models-for</link>
      <description><![CDATA[Concatenating multiple clusters of concept neurons can vividly generate all related concepts in a single image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cones-concept-neurons-in-diffusion-models-for</guid>
    </item>
    <item>
      <title>OpenICL: An Open-Source Framework for In-context Learning</title>
      <link>https://paperswithcode.com/paper/openicl-an-open-source-framework-for-in</link>
      <description><![CDATA[However, the implementation of ICL is sophisticated due to the diverse retrieval and inference methods involved, as well as the varying pre-processing requirements for different models, datasets, and tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openicl-an-open-source-framework-for-in</guid>
    </item>
    <item>
      <title>GLIGEN: Open-Set Grounded Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/gligen-open-set-grounded-text-to-image</link>
      <description><![CDATA[Large-scale text-to-image diffusion models have made amazing advances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gligen-open-set-grounded-text-to-image</guid>
    </item>
    <item>
      <title>Hybrid Symbolic-Numeric Library for Power System Modeling and Analysis</title>
      <link>https://paperswithcode.com/paper/hybrid-symbolic-numeric-library-for-power</link>
      <description><![CDATA[This paper proposes a two-layer hybrid library consisted of a symbolic layer for descriptive modeling and a numeric layer for vector-based numerical computation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hybrid-symbolic-numeric-library-for-power</guid>
    </item>
    <item>
      <title>Discovering faster matrix multiplication algorithms with reinforcement learning</title>
      <link>https://paperswithcode.com/paper/discovering-faster-matrix-multiplication</link>
      <description><![CDATA[Particularly relevant is the case of 4 × 4 matrices in a finite field, where AlphaTensor’s algorithm improves on Strassen’s two-level algorithm for the first time, to our knowledge, since its discovery 50 years ago2.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/discovering-faster-matrix-multiplication</guid>
    </item>
    <item>
      <title>The Forward-Forward Algorithm: Some Preliminary Investigations</title>
      <link>https://paperswithcode.com/paper/the-forward-forward-algorithm-some-1</link>
      <description><![CDATA[The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth further investigation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-forward-forward-algorithm-some-1</guid>
    </item>
    <item>
      <title>DiffusionDepth: Diffusion Denoising Approach for Monocular Depth Estimation</title>
      <link>https://paperswithcode.com/paper/diffusiondepth-diffusion-denoising-approach</link>
      <description><![CDATA[We propose DiffusionDepth, a new approach that reformulates monocular depth estimation as a denoising diffusion process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondepth-diffusion-denoising-approach</guid>
    </item>
    <item>
      <title>Unleashing Text-to-Image Diffusion Models for Visual Perception</title>
      <link>https://paperswithcode.com/paper/unleashing-text-to-image-diffusion-models-for-1</link>
      <description><![CDATA[In this paper, we propose VPD (Visual Perception with a pre-trained Diffusion model), a new framework that exploits the semantic information of a pre-trained text-to-image diffusion model in visual perception tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unleashing-text-to-image-diffusion-models-for-1</guid>
    </item>
    <item>
      <title>Hyena Hierarchy: Towards Larger Convolutional Language Models</title>
      <link>https://paperswithcode.com/paper/hyena-hierarchy-towards-larger-convolutional</link>
      <description><![CDATA[Recent advances in deep learning have relied heavily on the use of large Transformers due to their ability to learn at scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyena-hierarchy-towards-larger-convolutional</guid>
    </item>
    <item>
      <title>StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis</title>
      <link>https://paperswithcode.com/paper/stylegan-t-unlocking-the-power-of-gans-for</link>
      <description><![CDATA[Text-to-image synthesis has recently seen significant progress thanks to large pretrained language models, large-scale training data, and the introduction of scalable model families such as diffusion and autoregressive models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stylegan-t-unlocking-the-power-of-gans-for</guid>
    </item>
    <item>
      <title>OpenOccupancy: A Large Scale Benchmark for Surrounding Semantic Occupancy Perception</title>
      <link>https://paperswithcode.com/paper/openoccupancy-a-large-scale-benchmark-for</link>
      <description><![CDATA[Towards a comprehensive benchmarking of surrounding perception algorithms, we propose OpenOccupancy, which is the first surrounding semantic occupancy perception benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openoccupancy-a-large-scale-benchmark-for</guid>
    </item>
    <item>
      <title>MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition and Robust Speech-to-Text Translation</title>
      <link>https://paperswithcode.com/paper/muavic-a-multilingual-audio-visual-corpus-for</link>
      <description><![CDATA[We introduce MuAViC, a multilingual audio-visual corpus for robust speech recognition and robust speech-to-text translation providing 1200 hours of audio-visual speech in 9 languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/muavic-a-multilingual-audio-visual-corpus-for</guid>
    </item>
    <item>
      <title>T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/t2i-adapter-learning-adapters-to-dig-out-more</link>
      <description><![CDATA[The incredible generative ability of large-scale text-to-image (T2I) models has demonstrated strong power of learning complex structures and meaningful semantics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t2i-adapter-learning-adapters-to-dig-out-more</guid>
    </item>
    <item>
      <title>ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/elite-encoding-visual-concepts-into-textual</link>
      <description><![CDATA[Despite unprecedented ability in imaginary creation, large text-to-image models are further expected to express customized concepts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elite-encoding-visual-concepts-into-textual</guid>
    </item>
    <item>
      <title>Efficient Teacher: Semi-Supervised Object Detection for YOLOv5</title>
      <link>https://paperswithcode.com/paper/efficient-teacher-semi-supervised-object</link>
      <description><![CDATA[The Pseudo Label Assigner prevents the occurrence of bias caused by a large number of low-quality pseudo labels that may interfere with the Dense Detector during the student-teacher mutual learning mechanism, and the Epoch Adaptor utilizes domain and distribution adaptation to allow Dense Detector to learn globally distributed consistent features, making the training independent of the proportion of labeled data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-teacher-semi-supervised-object</guid>
    </item>
  </channel>
</rss>
