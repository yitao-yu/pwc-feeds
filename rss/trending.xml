<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 05 Jan 2023 21:06:45 +0000</lastBuildDate>
    <item>
      <title>ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders</title>
      <link>https://paperswithcode.com/paper/convnext-v2-co-designing-and-scaling-convnets</link>
      <description><![CDATA[This co-design of self-supervised learning techniques and architectural improvement results in a new model family called ConvNeXt V2, which significantly improves the performance of pure ConvNets on various recognition benchmarks, including ImageNet classification, COCO detection, and ADE20K segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/convnext-v2-co-designing-and-scaling-convnets</guid>
    </item>
    <item>
      <title>Cramming: Training a Language Model on a Single GPU in One Day</title>
      <link>https://paperswithcode.com/paper/cramming-training-a-language-model-on-a</link>
      <description><![CDATA[Recent trends in language modeling have focused on increasing performance through scaling, and have resulted in an environment where training language models is out of reach for most researchers and practitioners.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cramming-training-a-language-model-on-a</guid>
    </item>
    <item>
      <title>Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data</title>
      <link>https://paperswithcode.com/paper/diffusion-probabilistic-models-for-scene</link>
      <description><![CDATA[To the best of our knowledge, our work is the first to apply discrete and latent diffusion for 3D categorical data on a scene-scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-probabilistic-models-for-scene</guid>
    </item>
    <item>
      <title>A Survey for In-context Learning</title>
      <link>https://paperswithcode.com/paper/a-survey-for-in-context-learning</link>
      <description><![CDATA[With the increasing ability of large language models (LLMs), in-context learning (ICL) has become a new paradigm for natural language processing (NLP), where LLMs make predictions only based on contexts augmented with a few training examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-for-in-context-learning</guid>
    </item>
    <item>
      <title>Pop2Piano : Pop Audio-based Piano Cover Generation</title>
      <link>https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</link>
      <description><![CDATA[The piano cover of pop music is widely enjoyed by people.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal</title>
      <link>https://paperswithcode.com/paper/reasoning-over-different-types-of-knowledge</link>
      <description><![CDATA[The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reasoning-over-different-types-of-knowledge</guid>
    </item>
    <item>
      <title>GPT Takes the Bar Exam</title>
      <link>https://paperswithcode.com/paper/gpt-takes-the-bar-exam</link>
      <description><![CDATA[Nearly all jurisdictions in the United States require a professional license exam, commonly referred to as "the Bar Exam," as a precondition for law practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-takes-the-bar-exam</guid>
    </item>
    <item>
      <title>TextBox 2.0: A Text Generation Library with Pre-trained Language Models</title>
      <link>https://paperswithcode.com/paper/textbox-2-0-a-text-generation-library-with</link>
      <description><![CDATA[To facilitate research on text generation, this paper presents a comprehensive and unified library, TextBox 2. 0, focusing on the use of pre-trained language models (PLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textbox-2-0-a-text-generation-library-with</guid>
    </item>
    <item>
      <title>Diffusion Models in Vision: A Survey</title>
      <link>https://paperswithcode.com/paper/diffusion-models-in-vision-a-survey</link>
      <description><![CDATA[Denoising diffusion models represent a recent emerging topic in computer vision, demonstrating remarkable results in the area of generative modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-in-vision-a-survey</guid>
    </item>
    <item>
      <title>CausalEGM: a general causal inference framework by encoding generative modeling</title>
      <link>https://paperswithcode.com/paper/causalegm-a-general-causal-inference</link>
      <description><![CDATA[In this article, we develop a general framework $\textit{CausalEGM}$ for estimating causal effects by encoding generative modeling, which can be applied in both binary and continuous treatment settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causalegm-a-general-causal-inference</guid>
    </item>
    <item>
      <title>Point-E: A System for Generating 3D Point Clouds from Complex Prompts</title>
      <link>https://paperswithcode.com/paper/point-e-a-system-for-generating-3d-point</link>
      <description><![CDATA[This is in stark contrast to state-of-the-art generative image models, which produce samples in a number of seconds or minutes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/point-e-a-system-for-generating-3d-point</guid>
    </item>
    <item>
      <title>Tsetlin Machine Embedding: Representing Words Using Logical Expressions</title>
      <link>https://paperswithcode.com/paper/tsetlin-machine-embedding-representing-words</link>
      <description><![CDATA[We also visualize word clusters in vector space, demonstrating how our logical embedding co-locate similar words.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tsetlin-machine-embedding-representing-words</guid>
    </item>
    <item>
      <title>Attention Is All You Need</title>
      <link>https://paperswithcode.com/paper/attention-is-all-you-need</link>
      <description><![CDATA[The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-is-all-you-need</guid>
    </item>
    <item>
      <title>Scalable Diffusion Models with Transformers</title>
      <link>https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</link>
      <description><![CDATA[We explore a new class of diffusion models based on the transformer architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</guid>
    </item>
    <item>
      <title>Box2Mask: Box-supervised Instance Segmentation via Level-set Evolution</title>
      <link>https://paperswithcode.com/paper/box2mask-box-supervised-instance-segmentation</link>
      <description><![CDATA[In contrast to fully supervised methods using pixel-wise mask labels, box-supervised instance segmentation takes advantage of simple box annotations, which has recently attracted increasing research attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/box2mask-box-supervised-instance-segmentation</guid>
    </item>
    <item>
      <title>Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training</title>
      <link>https://paperswithcode.com/paper/colossal-ai-a-unified-deep-learning-system</link>
      <description><![CDATA[The success of Transformer models has pushed the deep learning model scale to billions of parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/colossal-ai-a-unified-deep-learning-system</guid>
    </item>
    <item>
      <title>Multi-scale Multi-band DenseNets for Audio Source Separation</title>
      <link>https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</link>
      <description><![CDATA[This paper deals with the problem of audio source separation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</guid>
    </item>
    <item>
      <title>MetaFormer Baselines for Vision</title>
      <link>https://paperswithcode.com/paper/metaformer-baselines-for-vision</link>
      <description><![CDATA[By simply applying depthwise separable convolutions as token mixer in the bottom stages and vanilla self-attention in the top stages, the resulting model CAFormer sets a new record on ImageNet-1K: it achieves an accuracy of 85. 5% at 224x224 resolution, under normal supervised training without external data or distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metaformer-baselines-for-vision</guid>
    </item>
    <item>
      <title>Multi-Concept Customization of Text-to-Image Diffusion</title>
      <link>https://paperswithcode.com/paper/multi-concept-customization-of-text-to-image</link>
      <description><![CDATA[Can we teach a model to quickly acquire a new concept, given a few examples?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-concept-customization-of-text-to-image</guid>
    </item>
  </channel>
</rss>
