<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 28 Jul 2023 09:11:26 +0000</lastBuildDate>
    <item>
      <title>SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</link>
      <description><![CDATA[We present SDXL, a latent diffusion model for text-to-image synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</guid>
    </item>
    <item>
      <title>Tracking Anything in High Quality</title>
      <link>https://paperswithcode.com/paper/tracking-anything-in-high-quality</link>
      <description><![CDATA[To further improve the quality of tracking masks, a pretrained MR model is employed to refine the tracking results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tracking-anything-in-high-quality</guid>
    </item>
    <item>
      <title>WavJourney: Compositional Audio Creation with Large Language Models</title>
      <link>https://paperswithcode.com/paper/wavjourney-compositional-audio-creation-with</link>
      <description><![CDATA[We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wavjourney-compositional-audio-creation-with</guid>
    </item>
    <item>
      <title>Meta-Transformer: A Unified Framework for Multimodal Learning</title>
      <link>https://paperswithcode.com/paper/meta-transformer-a-unified-framework-for</link>
      <description><![CDATA[Multimodal learning aims to build models that can process and relate information from multiple modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-transformer-a-unified-framework-for</guid>
    </item>
    <item>
      <title>FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios</title>
      <link>https://paperswithcode.com/paper/factool-factuality-detection-in-generative-ai</link>
      <description><![CDATA[With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e. g., ChatGPT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/factool-factuality-detection-in-generative-ai</guid>
    </item>
    <item>
      <title>Foundational Models Defining a New Era in Vision: A Survey and Outlook</title>
      <link>https://paperswithcode.com/paper/foundational-models-defining-a-new-era-in</link>
      <description><![CDATA[Vision systems to see and reason about the compositional nature of visual scenes are fundamental to understanding our world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundational-models-defining-a-new-era-in</guid>
    </item>
    <item>
      <title>LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition</title>
      <link>https://paperswithcode.com/paper/lorahub-efficient-cross-task-generalization</link>
      <description><![CDATA[Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lorahub-efficient-cross-task-generalization</guid>
    </item>
    <item>
      <title>Llama 2: Open Foundation and Fine-Tuned Chat Models</title>
      <link>https://paperswithcode.com/paper/llama-2-open-foundation-and-fine-tuned-chat</link>
      <description><![CDATA[In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-2-open-foundation-and-fine-tuned-chat</guid>
    </item>
    <item>
      <title>DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI</title>
      <link>https://paperswithcode.com/paper/dialogstudio-towards-richest-and-most-diverse</link>
      <description><![CDATA[Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dialogstudio-towards-richest-and-most-diverse</guid>
    </item>
    <item>
      <title>Subject-Diffusion:Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning</title>
      <link>https://paperswithcode.com/paper/subject-diffusion-open-domain-personalized</link>
      <description><![CDATA[In this paper, we propose Subject-Diffusion, a novel open-domain personalized image generation model that, in addition to not requiring test-time fine-tuning, also only requires a single reference image to support personalized generation of single- or multi-subject in any domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/subject-diffusion-open-domain-personalized</guid>
    </item>
    <item>
      <title>Large Multimodal Models: Notes on CVPR 2023 Tutorial</title>
      <link>https://paperswithcode.com/paper/large-multimodal-models-notes-on-cvpr-2023</link>
      <description><![CDATA[This tutorial note summarizes the presentation on ``Large Multimodal Models: Towards Building and Surpassing Multimodal GPT-4'', a part of CVPR 2023 tutorial on ``Recent Advances in Vision Foundation Models''.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-multimodal-models-notes-on-cvpr-2023</guid>
    </item>
    <item>
      <title>AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning</title>
      <link>https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</link>
      <description><![CDATA[With the advance of text-to-image models (e. g., Stable Diffusion) and corresponding personalization techniques such as DreamBooth and LoRA, everyone can manifest their imagination into high-quality images at an affordable cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</guid>
    </item>
    <item>
      <title>Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors</title>
      <link>https://paperswithcode.com/paper/magic123-one-image-to-high-quality-3d-object</link>
      <description><![CDATA[We present Magic123, a two-stage coarse-to-fine approach for high-quality, textured 3D meshes generation from a single unposed image in the wild using both2D and 3D priors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magic123-one-image-to-high-quality-3d-object</guid>
    </item>
    <item>
      <title>CoTracker: It is Better to Track Together</title>
      <link>https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</link>
      <description><![CDATA[In this paper, we thus propose CoTracker, an architecture that jointly tracks multiple points throughout an entire video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</guid>
    </item>
    <item>
      <title>A Length-Extrapolatable Transformer</title>
      <link>https://paperswithcode.com/paper/a-length-extrapolatable-transformer</link>
      <description><![CDATA[Position modeling plays a critical role in Transformers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-length-extrapolatable-transformer</guid>
    </item>
    <item>
      <title>DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing</title>
      <link>https://paperswithcode.com/paper/dragdiffusion-harnessing-diffusion-models-for</link>
      <description><![CDATA[In this work, we extend such an editing framework to diffusion models and propose DragDiffusion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dragdiffusion-harnessing-diffusion-models-for</guid>
    </item>
    <item>
      <title>VIMA: General Robot Manipulation with Multimodal Prompts</title>
      <link>https://paperswithcode.com/paper/vima-general-robot-manipulation-with</link>
      <description><![CDATA[We show that a wide spectrum of robot manipulation tasks can be expressed with multimodal prompts, interleaving textual and visual tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vima-general-robot-manipulation-with</guid>
    </item>
    <item>
      <title>Enhancing Document-level Event Argument Extraction with Contextual Clues and Role Relevance</title>
      <link>https://paperswithcode.com/paper/enhancing-document-level-event-argument</link>
      <description><![CDATA[Document-level event argument extraction poses new challenges of long input and cross-sentence inference compared to its sentence-level counterpart.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/enhancing-document-level-event-argument</guid>
    </item>
    <item>
      <title>Aligning Large Language Models with Human: A Survey</title>
      <link>https://paperswithcode.com/paper/aligning-large-language-models-with-human-a</link>
      <description><![CDATA[(2) Training methodologies: a detailed review of the prevailing training methods employed for LLM alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-large-language-models-with-human-a</guid>
    </item>
    <item>
      <title>ResShift: Efficient Diffusion Model for Image Super-resolution by Residual Shifting</title>
      <link>https://paperswithcode.com/paper/resshift-efficient-diffusion-model-for-image</link>
      <description><![CDATA[Diffusion-based image super-resolution (SR) methods are mainly limited by the low inference speed due to the requirements of hundreds or even thousands of sampling steps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/resshift-efficient-diffusion-model-for-image</guid>
    </item>
  </channel>
</rss>
