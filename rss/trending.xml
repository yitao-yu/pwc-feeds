<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 09 Dec 2024 09:18:49 +0000</lastBuildDate>
    <item>
      <title>HunyuanVideo: A Systematic Framework For Large Video Generative Models</title>
      <link>https://paperswithcode.com/paper/hunyuanvideo-a-systematic-framework-for-large</link>
      <description><![CDATA[In this report, we introduce HunyuanVideo, an innovative open-source video foundation model that demonstrates performance in video generation comparable to, or even surpassing, that of leading closed-source models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuanvideo-a-systematic-framework-for-large</guid>
    </item>
    <item>
      <title>Papers-in-100-Lines-of-Code</title>
      <link>https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code</link>
      <description><![CDATA[Implementation of papers in 100 lines of code.]]></description>
      <guid isPermaLink="true">https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code</guid>
    </item>
    <item>
      <title>MossFormer: Pushing the Performance Limit of Monaural Speech Separation using Gated Single-Head Transformer with Convolution-Augmented Joint Self-Attentions</title>
      <link>https://paperswithcode.com/paper/mossformer-pushing-the-performance-limit-of</link>
      <description><![CDATA[To effectively solve the indirect elemental interactions across chunks in the dual-path architecture, MossFormer employs a joint local and global self-attention architecture that simultaneously performs a full-computation self-attention on local chunks and a linearised low-cost self-attention over the full sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mossformer-pushing-the-performance-limit-of</guid>
    </item>
    <item>
      <title>Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</link>
      <description><![CDATA[We present Infinity, a Bitwise Visual AutoRegressive Modeling capable of generating high-resolution, photorealistic images following language instruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</guid>
    </item>
    <item>
      <title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title>
      <link>https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</link>
      <description><![CDATA[We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine "next-scale prediction" or "next-resolution prediction", diverging from the standard raster-scan "next-token prediction".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</guid>
    </item>
    <item>
      <title>VisionZip: Longer is Better but Not Necessary in Vision Language Models</title>
      <link>https://paperswithcode.com/paper/visionzip-longer-is-better-but-not-necessary</link>
      <description><![CDATA[To address this, we introduce VisionZip, a simple yet effective method that selects a set of informative tokens for input to the language model, reducing visual token redundancy and improving efficiency while maintaining model performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visionzip-longer-is-better-but-not-necessary</guid>
    </item>
    <item>
      <title>Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion</title>
      <link>https://paperswithcode.com/paper/florence-vl-enhancing-vision-language-models</link>
      <description><![CDATA[We present Florence-VL, a new family of multimodal large language models (MLLMs) with enriched visual representations produced by Florence-2, a generative vision foundation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/florence-vl-enhancing-vision-language-models</guid>
    </item>
    <item>
      <title>Stem-leaf segmentation and phenotypic trait extraction of maize shoots from three-dimensional point cloud</title>
      <link>https://paperswithcode.com/paper/stem-leaf-segmentation-and-phenotypic-trait</link>
      <description><![CDATA[However, automatic stem-leaf segmentation of maize shoots from three-dimensional (3D) point clouds remains challenging, especially for new emerging leaves that are very close and wrapped together during the seedling stage.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stem-leaf-segmentation-and-phenotypic-trait</guid>
    </item>
    <item>
      <title>ShowUI: One Vision-Language-Action Model for GUI Visual Agent</title>
      <link>https://paperswithcode.com/paper/showui-one-vision-language-action-model-for</link>
      <description><![CDATA[In this work, we develop a vision-language-action model in digital world, namely ShowUI, which features the following innovations: (i) UI-Guided Visual Token Selection to reduce computational costs by formulating screenshots as an UI connected graph, adaptively identifying their redundant relationship and serve as the criteria for token selection during self-attention blocks; (ii) Interleaved Vision-Language-Action Streaming that flexibly unifies diverse needs within GUI tasks, enabling effective management of visual-action history in navigation or pairing multi-turn query-action sequences per screenshot to enhance training efficiency; (iii) Small-scale High-quality GUI Instruction-following Datasets by careful data curation and employing a resampling strategy to address significant data type imbalances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/showui-one-vision-language-action-model-for</guid>
    </item>
    <item>
      <title>GenCast: Diffusion-based ensemble forecasting for medium-range weather</title>
      <link>https://paperswithcode.com/paper/gencast-diffusion-based-ensemble-forecasting</link>
      <description><![CDATA[Weather forecasts are fundamentally uncertain, so predicting the range of probable weather scenarios is crucial for important decisions, from warning the public about hazardous weather, to planning renewable energy use.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gencast-diffusion-based-ensemble-forecasting</guid>
    </item>
    <item>
      <title>OSDFace: One-Step Diffusion Model for Face Restoration</title>
      <link>https://paperswithcode.com/paper/osdface-one-step-diffusion-model-for-face</link>
      <description><![CDATA[Moreover, existing methods often struggle to generate face images that are harmonious, realistic, and consistent with the subject's identity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/osdface-one-step-diffusion-model-for-face</guid>
    </item>
    <item>
      <title>The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use</title>
      <link>https://paperswithcode.com/paper/the-dawn-of-gui-agent-a-preliminary-case</link>
      <description><![CDATA[The recently released model, Claude 3. 5 Computer Use, stands out as the first frontier AI model to offer computer use in public beta as a graphical user interface (GUI) agent.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-dawn-of-gui-agent-a-preliminary-case</guid>
    </item>
    <item>
      <title>Comprehensive Competition Mechanism in Palmprint Recognition</title>
      <link>https://paperswithcode.com/paper/comprehensive-competition-mechanism-in</link>
      <description><![CDATA[The traditional competition mechanism focuses solely on selecting the winner of different channels without considering the spatial information of the features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comprehensive-competition-mechanism-in</guid>
    </item>
    <item>
      <title>EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation</title>
      <link>https://paperswithcode.com/paper/echomimicv2-towards-striking-simplified-and</link>
      <description><![CDATA[Recent work on human animation usually involves audio, pose, or movement maps conditions, thereby achieves vivid animation quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/echomimicv2-towards-striking-simplified-and</guid>
    </item>
    <item>
      <title>emg2pose: A Large and Diverse Benchmark for Surface Electromyographic Hand Pose Estimation</title>
      <link>https://paperswithcode.com/paper/emg2pose-a-large-and-diverse-benchmark-for</link>
      <description><![CDATA[Hands are the primary means through which humans interact with the world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emg2pose-a-large-and-diverse-benchmark-for</guid>
    </item>
    <item>
      <title>The Well: a Large-Scale Collection of Diverse Physics Simulations for Machine Learning</title>
      <link>https://paperswithcode.com/paper/the-well-a-large-scale-collection-of-diverse</link>
      <description><![CDATA[Machine learning based surrogate models offer researchers powerful tools for accelerating simulation-based workflows.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-well-a-large-scale-collection-of-diverse</guid>
    </item>
    <item>
      <title>MARS: Unleashing the Power of Variance Reduction for Training Large Models</title>
      <link>https://paperswithcode.com/paper/mars-unleashing-the-power-of-variance</link>
      <description><![CDATA[Despite the development of numerous variance reduction algorithms in the past decade aimed at accelerating stochastic optimization in both convex and nonconvex settings, variance reduction has not found widespread success in training deep neural networks or large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mars-unleashing-the-power-of-variance</guid>
    </item>
    <item>
      <title>ReFT: Representation Finetuning for Language Models</title>
      <link>https://paperswithcode.com/paper/reft-representation-finetuning-for-language</link>
      <description><![CDATA[We define a strong instance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT), and we identify an ablation of this method that trades some performance for increased efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reft-representation-finetuning-for-language</guid>
    </item>
    <item>
      <title>Open-Sora Plan: Open-Source Large Video Generation Model</title>
      <link>https://paperswithcode.com/paper/open-sora-plan-open-source-large-video</link>
      <description><![CDATA[We introduce Open-Sora Plan, an open-source project that aims to contribute a large generation model for generating desired high-resolution videos with long durations based on various user inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-sora-plan-open-source-large-video</guid>
    </item>
    <item>
      <title>Scaling Transformers for Low-Bitrate High-Quality Speech Coding</title>
      <link>https://paperswithcode.com/paper/scaling-transformers-for-low-bitrate-high</link>
      <description><![CDATA[The tokenization of speech with neural audio codec models is a vital part of modern AI pipelines for the generation or understanding of speech, alone or in a multimodal context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-transformers-for-low-bitrate-high</guid>
    </item>
  </channel>
</rss>
