<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 20 Apr 2023 09:12:19 +0000</lastBuildDate>
    <item>
      <title>Consistency Models</title>
      <link>https://paperswithcode.com/paper/consistency-models</link>
      <description><![CDATA[To overcome this limitation, we propose consistency models, a new family of generative models that achieve high sample quality without adversarial training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/consistency-models</guid>
    </item>
    <item>
      <title>Inpaint Anything: Segment Anything Meets Image Inpainting</title>
      <link>https://paperswithcode.com/paper/inpaint-anything-segment-anything-meets-image</link>
      <description><![CDATA[We are also very willing to help everyone share and promote new projects based on our Inpaint Anything (IA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inpaint-anything-segment-anything-meets-image</guid>
    </item>
    <item>
      <title>A Method for Animating Children's Drawings of the Human Figure</title>
      <link>https://paperswithcode.com/paper/a-method-for-automatically-animating-children</link>
      <description><![CDATA[Children's drawings have a wonderful inventiveness, creativity, and variety to them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-method-for-automatically-animating-children</guid>
    </item>
    <item>
      <title>Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text</title>
      <link>https://paperswithcode.com/paper/multimodal-c4-an-open-billion-scale-corpus-of</link>
      <description><![CDATA[We release Multimodal C4 (mmc4), an augmentation of the popular text-only c4 corpus with images interleaved.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-c4-an-open-billion-scale-corpus-of</guid>
    </item>
    <item>
      <title>Segment Everything Everywhere All at Once</title>
      <link>https://paperswithcode.com/paper/segment-everything-everywhere-all-at-once</link>
      <description><![CDATA[Inspired by the development of prompt-based universal interfaces for LLMs, this paper presents SEEM, a promptable, interactive model for Segmenting Everything Everywhere all at once in an image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-everything-everywhere-all-at-once</guid>
    </item>
    <item>
      <title>CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society</title>
      <link>https://paperswithcode.com/paper/camel-communicative-agents-for-mind</link>
      <description><![CDATA[To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camel-communicative-agents-for-mind</guid>
    </item>
    <item>
      <title>Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases</title>
      <link>https://paperswithcode.com/paper/understanding-int4-quantization-for</link>
      <description><![CDATA[Improving the deployment efficiency of transformer-based language models has been challenging given their high computation and memory cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-int4-quantization-for</guid>
    </item>
    <item>
      <title>HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge</title>
      <link>https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</link>
      <description><![CDATA[Large Language Models (LLMs), such as the LLaMA model, have demonstrated their effectiveness in various general-domain natural language processing (NLP) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</guid>
    </item>
    <item>
      <title>OpenAssistant Conversations -- Democratizing Large Language Model Alignment</title>
      <link>https://paperswithcode.com/paper/openassistant-conversations-democratizing</link>
      <description><![CDATA[The corpus is a product of a worldwide crowd-sourcing effort involving over 13, 500 volunteers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openassistant-conversations-democratizing</guid>
    </item>
    <item>
      <title>Self-Instruct: Aligning Language Model with Self Generated Instructions</title>
      <link>https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</link>
      <description><![CDATA[Applying our method to vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT_001, which is trained with private user data and human annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</guid>
    </item>
    <item>
      <title>Automatically Bounding the Taylor Remainder Series: Tighter Bounds and New Applications</title>
      <link>https://paperswithcode.com/paper/automatically-bounding-the-taylor-remainder</link>
      <description><![CDATA[We then recursively combine the bounds for the elementary functions using an interval arithmetic variant of Taylor-mode automatic differentiation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automatically-bounding-the-taylor-remainder</guid>
    </item>
    <item>
      <title>SiLK -- Simple Learned Keypoints</title>
      <link>https://paperswithcode.com/paper/silk-simple-learned-keypoints</link>
      <description><![CDATA[Keypoint detection & descriptors are foundational tech-nologies for computer vision tasks like image matching, 3D reconstruction and visual odometry.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/silk-simple-learned-keypoints</guid>
    </item>
    <item>
      <title>OpenAGI: When LLM Meets Domain Experts</title>
      <link>https://paperswithcode.com/paper/openagi-when-llm-meets-domain-experts</link>
      <description><![CDATA[Thus, the LLM is responsible for synthesizing various external models for solving complex tasks, while RLTF provides feedback to improve its task-solving ability, enabling a feedback loop for self-improving AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openagi-when-llm-meets-domain-experts</guid>
    </item>
    <item>
      <title>AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models</title>
      <link>https://paperswithcode.com/paper/agieval-a-human-centric-benchmark-for</link>
      <description><![CDATA[Impressively, GPT-4 surpasses average human performance on SAT, LSAT, and math competitions, attaining a 95% accuracy rate on the SAT Math test and a 92. 5% accuracy on the English test of the Chinese national college entrance exam.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agieval-a-human-centric-benchmark-for</guid>
    </item>
    <item>
      <title>RRHF: Rank Responses to Align Language Models with Human Feedback without tears</title>
      <link>https://paperswithcode.com/paper/rrhf-rank-responses-to-align-language-models</link>
      <description><![CDATA[Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment of large language models with human preferences, significantly enhancing the quality of interactions between humans and these models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rrhf-rank-responses-to-align-language-models</guid>
    </item>
    <item>
      <title>MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing</title>
      <link>https://paperswithcode.com/paper/masactrl-tuning-free-mutual-self-attention</link>
      <description><![CDATA[Despite the success in large-scale text-to-image generation and text-conditioned image editing, existing methods still struggle to produce consistent generation and editing results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/masactrl-tuning-free-mutual-self-attention</guid>
    </item>
    <item>
      <title>HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace</title>
      <link>https://paperswithcode.com/paper/hugginggpt-solving-ai-tasks-with-chatgpt-and</link>
      <description><![CDATA[Solving complicated AI tasks with different domains and modalities is a key step toward advanced artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hugginggpt-solving-ai-tasks-with-chatgpt-and</guid>
    </item>
    <item>
      <title>Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection</title>
      <link>https://paperswithcode.com/paper/grounding-dino-marrying-dino-with-grounded</link>
      <description><![CDATA[To effectively fuse language and vision modalities, we conceptually divide a closed-set detector into three phases and propose a tight fusion solution, which includes a feature enhancer, a language-guided query selection, and a cross-modality decoder for cross-modality fusion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grounding-dino-marrying-dino-with-grounded</guid>
    </item>
    <item>
      <title>A Survey of Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-of-large-language-models</link>
      <description><![CDATA[To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-large-language-models</guid>
    </item>
    <item>
      <title>Instruction Tuning with GPT-4</title>
      <link>https://paperswithcode.com/paper/instruction-tuning-with-gpt-4</link>
      <description><![CDATA[Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instruction-tuning-with-gpt-4</guid>
    </item>
  </channel>
</rss>
