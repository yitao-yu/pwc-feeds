<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 11 Jun 2025 09:19:25 +0000</lastBuildDate>
    <item>
      <title>Representing Long Volumetric Video with Temporal Gaussian Hierarchy</title>
      <link>https://paperswithcode.com/paper/representing-long-volumetric-video-with</link>
      <description><![CDATA[In addition, the tree-like structure of the Gaussian hierarchy allows us to efficiently represent the scene at a particular moment with a subset of Gaussian primitives, leading to nearly constant GPU memory usage during the training or rendering regardless of the video length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/representing-long-volumetric-video-with</guid>
    </item>
    <item>
      <title>self-prompting analogical reasoning for uav object detection</title>
      <link>https://paperswithcode.com/paper/self-prompting-analogical-reasoning-for-uav</link>
      <description><![CDATA[While for analogical reasoningmodule, graph nodes consist of category-level prompt nodes and pixel-level image feature nodes. Analogical inference is based on graph convolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-prompting-analogical-reasoning-for-uav</guid>
    </item>
    <item>
      <title>Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents</title>
      <link>https://paperswithcode.com/paper/darwin-godel-machine-open-ended-evolution-of</link>
      <description><![CDATA[The G\"odel machine proposed a theoretical alternative: a self-improving AI that repeatedly modifies itself in a provably beneficial manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/darwin-godel-machine-open-ended-evolution-of</guid>
    </item>
    <item>
      <title>EasyVolcap: Accelerating Neural Volumetric Video Research</title>
      <link>https://paperswithcode.com/paper/easyvolcap-accelerating-neural-volumetric</link>
      <description><![CDATA[Volumetric video is a technology that digitally records dynamic events such as artistic performances, sporting events, and remote conversations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyvolcap-accelerating-neural-volumetric</guid>
    </item>
    <item>
      <title>Direct3D-S2: Gigascale 3D Generation Made Easy with Spatial Sparse Attention</title>
      <link>https://paperswithcode.com/paper/direct3d-s2-gigascale-3d-generation-made-easy</link>
      <description><![CDATA[Generating high-resolution 3D shapes using volumetric representations such as Signed Distance Functions (SDFs) presents substantial computational and memory challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct3d-s2-gigascale-3d-generation-made-easy</guid>
    </item>
    <item>
      <title>Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers</title>
      <link>https://paperswithcode.com/paper/paper2poster-towards-multimodal-poster</link>
      <description><![CDATA[To address this challenge, we introduce the first benchmark and metric suite for poster generation, which pairs recent conference papers with author-designed posters and evaluates outputs on (i)Visual Quality-semantic alignment with human posters, (ii)Textual Coherence-language fluency, (iii)Holistic Assessment-six fine-grained aesthetic and informational criteria scored by a VLM-as-judge, and notably (iv)PaperQuiz-the poster's ability to convey core paper content as measured by VLMs answering generated quizzes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paper2poster-towards-multimodal-poster</guid>
    </item>
    <item>
      <title>R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration</title>
      <link>https://paperswithcode.com/paper/r-kv-redundancy-aware-kv-cache-compression</link>
      <description><![CDATA[To address this, we propose Redundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel method specifically targeting redundant tokens in reasoning models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r-kv-redundancy-aware-kv-cache-compression</guid>
    </item>
    <item>
      <title>RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination</title>
      <link>https://paperswithcode.com/paper/renderformer-transformer-based-neural</link>
      <description><![CDATA[We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of a scene with full global illumination effects and that does not require per-scene training or fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/renderformer-transformer-based-neural</guid>
    </item>
    <item>
      <title>OmniAudio: Generating Spatial Audio from 360-Degree Video</title>
      <link>https://paperswithcode.com/paper/omniaudio-generating-spatial-audio-from-360</link>
      <description><![CDATA[To generate spatial audio from 360-degree video, we propose a novel framework OmniAudio, which leverages self-supervised pre-training using both spatial audio data (in FOA format) and large-scale non-spatial data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omniaudio-generating-spatial-audio-from-360</guid>
    </item>
    <item>
      <title>Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems</title>
      <link>https://paperswithcode.com/paper/which-agent-causes-task-failures-and-when-on</link>
      <description><![CDATA[In this paper, we propose and formulate a new research area: automated failure attribution for LLM multi-agent systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/which-agent-causes-task-failures-and-when-on</guid>
    </item>
    <item>
      <title>AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning</title>
      <link>https://paperswithcode.com/paper/areal-a-large-scale-asynchronous</link>
      <description><![CDATA[Most existing large-scale RL systems for LLMs are synchronous, alternating generation and training in a batch setting where rollouts in each training batch are generated by the same model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/areal-a-large-scale-asynchronous</guid>
    </item>
    <item>
      <title>Advanced long-term earth system forecasting by learning the small-scale nature</title>
      <link>https://paperswithcode.com/paper/advanced-long-term-earth-system-forecasting</link>
      <description><![CDATA[Reliable long-term forecast of Earth system dynamics is heavily hampered by instabilities in current AI models during extended autoregressive simulations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advanced-long-term-earth-system-forecasting</guid>
    </item>
    <item>
      <title>LLM-AutoDiff: Auto-Differentiate Any LLM Workflow</title>
      <link>https://paperswithcode.com/paper/auto-differentiating-any-llm-workflow-a</link>
      <description><![CDATA[Large Language Models (LLMs) have reshaped natural language processing, powering applications from multi-hop retrieval and question answering to autonomous agent workflows.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/auto-differentiating-any-llm-workflow-a</guid>
    </item>
    <item>
      <title>HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters</title>
      <link>https://paperswithcode.com/paper/hunyuanvideo-avatar-high-fidelity-audio</link>
      <description><![CDATA[This ensures the dynamic motion and strong character consistency; (ii) An Audio Emotion Module (AEM) is introduced to extract and transfer the emotional cues from an emotion reference image to the target generated video, enabling fine-grained and accurate emotion style control; (iii) A Face-Aware Audio Adapter (FAA) is proposed to isolate the audio-driven character with latent-level face mask, enabling independent audio injection via cross-attention for multi-character scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuanvideo-avatar-high-fidelity-audio</guid>
    </item>
    <item>
      <title>Let Them Talk: Audio-Driven Multi-Person Conversational Video Generation</title>
      <link>https://paperswithcode.com/paper/let-them-talk-audio-driven-multi-person</link>
      <description><![CDATA[Audio-driven human animation methods, such as talking head and talking body generation, have made remarkable progress in generating synchronized facial movements and appealing visual quality videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-them-talk-audio-driven-multi-person</guid>
    </item>
    <item>
      <title>Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning</title>
      <link>https://paperswithcode.com/paper/paper2code-automating-code-generation-from</link>
      <description><![CDATA[Despite the rapid growth of machine learning research, corresponding code implementations are often unavailable, making it slow and labor-intensive for researchers to reproduce results and build upon prior work.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paper2code-automating-code-generation-from</guid>
    </item>
    <item>
      <title>Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/unifying-appearance-codes-and-bilateral-grids</link>
      <description><![CDATA[In this paper, we propose a novel multi-scale bilateral grid that unifies appearance codes and bilateral grids.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unifying-appearance-codes-and-bilateral-grids</guid>
    </item>
    <item>
      <title>SkyReels-V2: Infinite-length Film Generative Model</title>
      <link>https://paperswithcode.com/paper/skyreels-v2-infinite-length-film-generative</link>
      <description><![CDATA[Recent advances in video generation have been driven by diffusion models and autoregressive frameworks, yet critical challenges persist in harmonizing prompt adherence, visual quality, motion dynamics, and duration: compromises in motion dynamics to enhance temporal visual quality, constrained video duration (5-10 seconds) to prioritize resolution, and inadequate shot-aware generation stemming from general-purpose MLLMs' inability to interpret cinematic grammar, such as shot composition, actor expressions, and camera motions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/skyreels-v2-infinite-length-film-generative</guid>
    </item>
    <item>
      <title>AlphaEvolve: A Learning Framework to Discover Novel Alphas in Quantitative Investment</title>
      <link>https://paperswithcode.com/paper/alphaevolve-a-learning-framework-to-discover</link>
      <description><![CDATA[In this paper, we introduce a new class of alphas to model scalar, vector, and matrix features which possess the strengths of these two existing classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alphaevolve-a-learning-framework-to-discover</guid>
    </item>
    <item>
      <title>Reservoir-enhanced Segment Anything Model for Subsurface Diagnosis</title>
      <link>https://paperswithcode.com/paper/reservoir-enhanced-segment-anything-model-for</link>
      <description><![CDATA[Urban roads and infrastructure, vital to city operations, face growing threats from subsurface anomalies like cracks and cavities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reservoir-enhanced-segment-anything-model-for</guid>
    </item>
  </channel>
</rss>
