<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 04 Oct 2024 09:16:17 +0000</lastBuildDate>
    <item>
      <title>A visualization method for data domain changes in CNN networks and the optimization method for selecting thresholds in classification tasks</title>
      <link>https://paperswithcode.com/paper/a-visualization-method-for-data-domain</link>
      <description><![CDATA[In recent years, Face Anti-Spoofing (FAS) has played a crucial role in preserving the security of face recognition technology.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-visualization-method-for-data-domain</guid>
    </item>
    <item>
      <title>PyGlove: Efficiently Exchanging ML Ideas as Code</title>
      <link>https://paperswithcode.com/paper/pyglove-efficiently-exchanging-ml-ideas-as</link>
      <description><![CDATA[We also perform a case study of a large codebase where PyGlove led to an 80% reduction in the number of lines of code.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pyglove-efficiently-exchanging-ml-ideas-as</guid>
    </item>
    <item>
      <title>PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation</title>
      <link>https://paperswithcode.com/paper/physgen-rigid-body-physics-grounded-image-to</link>
      <description><![CDATA[We present PhysGen, a novel image-to-video generation method that converts a single image and an input condition (e. g., force and torque applied to an object in the image) to produce a realistic, physically plausible, and temporally consistent video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physgen-rigid-body-physics-grounded-image-to</guid>
    </item>
    <item>
      <title>ABQ-LLM: Arbitrary-Bit Quantized Inference Acceleration for Large Language Models</title>
      <link>https://paperswithcode.com/paper/abq-llm-arbitrary-bit-quantized-inference</link>
      <description><![CDATA[Based on W2*A8 quantization configuration on LLaMA-7B model, it achieved a WikiText2 perplexity of 7. 59 (2. 17$\downarrow $ vs 9. 76 in AffineQuant).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/abq-llm-arbitrary-bit-quantized-inference</guid>
    </item>
    <item>
      <title>Cross-video Identity Correlating for Person Re-identification Pre-training</title>
      <link>https://paperswithcode.com/paper/cross-video-identity-correlating-for-person</link>
      <description><![CDATA[For example, compared with the previous state-of-the-art~\cite{ISR}, CION with the same ResNet50-IBN achieves higher mAP of 93. 3\% and 74. 3\% on Market1501 and MSMT17, while only utilizing 8\% training samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-video-identity-correlating-for-person</guid>
    </item>
    <item>
      <title>WiLoR: End-to-end 3D Hand Localization and Reconstruction in-the-wild</title>
      <link>https://paperswithcode.com/paper/wilor-end-to-end-3d-hand-localization-and</link>
      <description><![CDATA[In recent years, 3D hand pose estimation methods have garnered significant attention due to their extensive applications in human-computer interaction, virtual reality, and robotics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wilor-end-to-end-3d-hand-localization-and</guid>
    </item>
    <item>
      <title>OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer</title>
      <link>https://paperswithcode.com/paper/omagent-a-multi-modal-agent-framework-for</link>
      <description><![CDATA[Recent advancements in Large Language Models (LLMs) have expanded their capabilities to multimodal contexts, including comprehensive video understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omagent-a-multi-modal-agent-framework-for</guid>
    </item>
    <item>
      <title>VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/vptq-extreme-low-bit-vector-post-training</link>
      <description><![CDATA[Due to the redundancy in LLM weights, recent research has focused on pushing weight-only quantization to extremely low-bit (even down to 2 bits).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vptq-extreme-low-bit-vector-post-training</guid>
    </item>
    <item>
      <title>TensorIR: An Abstraction for Automatic Tensorized Program Optimization</title>
      <link>https://paperswithcode.com/paper/tensorir-an-abstraction-for-automatic</link>
      <description><![CDATA[Finally, we build an end-to-end framework on top of our abstraction to automatically optimize deep learning models for given tensor computation primitives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tensorir-an-abstraction-for-automatic</guid>
    </item>
    <item>
      <title>Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers</title>
      <link>https://paperswithcode.com/paper/scaling-proprioceptive-visual-learning-with</link>
      <description><![CDATA[Previous robot learning methods often collect data to train with one specific embodiment for one task, which is expensive and prone to overfitting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-proprioceptive-visual-learning-with</guid>
    </item>
    <item>
      <title>Scalable Pre-training of Large Autoregressive Image Models</title>
      <link>https://paperswithcode.com/paper/scalable-pre-training-of-large-autoregressive</link>
      <description><![CDATA[Specifically, we highlight two key findings: (1) the performance of the visual features scale with both the model capacity and the quantity of data, (2) the value of the objective function correlates with the performance of the model on downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-pre-training-of-large-autoregressive</guid>
    </item>
    <item>
      <title>3DTopia-XL: Scaling High-quality 3D Asset Generation via Primitive Diffusion</title>
      <link>https://paperswithcode.com/paper/3dtopia-xl-scaling-high-quality-3d-asset</link>
      <description><![CDATA[The increasing demand for high-quality 3D assets across various industries necessitates efficient and automated 3D content creation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dtopia-xl-scaling-high-quality-3d-asset</guid>
    </item>
    <item>
      <title>Segment Anything without Supervision</title>
      <link>https://paperswithcode.com/paper/segment-anything-without-supervision</link>
      <description><![CDATA[By integrating our unsupervised pseudo masks into SA-1B's ground-truth masks and training UnSAM with only 1% of SA-1B, a lightly semi-supervised UnSAM can often segment entities overlooked by supervised SAM, exceeding SAM's AR by over 6. 7% and AP by 3. 9% on SA-1B.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-anything-without-supervision</guid>
    </item>
    <item>
      <title>GeoCalib: Learning Single-image Calibration with Geometric Optimization</title>
      <link>https://paperswithcode.com/paper/geocalib-learning-single-image-calibration</link>
      <description><![CDATA[This single-image calibration can benefit various downstream applications like image editing and 3D mapping.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/geocalib-learning-single-image-calibration</guid>
    </item>
    <item>
      <title>Reinforcement Learning Meets Visual Odometry</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-meets-visual-odometry</link>
      <description><![CDATA[Despite recent advances, existing VO methods still rely on heuristic design choices that require several weeks of hyperparameter tuning by human experts, hindering generalizability and robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-meets-visual-odometry</guid>
    </item>
    <item>
      <title>A Survey on the Honesty of Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-on-the-honesty-of-large-language</link>
      <description><![CDATA[Honesty is a fundamental principle for aligning large language models (LLMs) with human values, requiring these models to recognize what they know and don't know and be able to faithfully express their knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-the-honesty-of-large-language</guid>
    </item>
    <item>
      <title>Fast Inference from Transformers via Speculative Decoding</title>
      <link>https://paperswithcode.com/paper/fast-inference-from-transformers-via</link>
      <description><![CDATA[Inference from large autoregressive models like Transformers is slow - decoding K tokens takes K serial runs of the model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-inference-from-transformers-via</guid>
    </item>
    <item>
      <title>LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs</title>
      <link>https://paperswithcode.com/paper/longwriter-unleashing-10000-word-generation</link>
      <description><![CDATA[By incorporating this dataset into model training, we successfully scale the output length of existing models to over 10, 000 words while maintaining output quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longwriter-unleashing-10000-word-generation</guid>
    </item>
    <item>
      <title>Grounding Image Matching in 3D with MASt3R</title>
      <link>https://paperswithcode.com/paper/grounding-image-matching-in-3d-with-mast3r</link>
      <description><![CDATA[Image Matching is a core component of all best-performing algorithms and pipelines in 3D vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grounding-image-matching-in-3d-with-mast3r</guid>
    </item>
    <item>
      <title>LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models</title>
      <link>https://paperswithcode.com/paper/lexeval-a-comprehensive-chinese-legal</link>
      <description><![CDATA[Applying existing LLMs to legal systems without careful evaluation of their potential and limitations could pose significant risks in legal practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lexeval-a-comprehensive-chinese-legal</guid>
    </item>
  </channel>
</rss>
