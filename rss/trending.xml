<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 05 Apr 2023 09:13:28 +0000</lastBuildDate>
    <item>
      <title>Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data</title>
      <link>https://paperswithcode.com/paper/baize-an-open-source-chat-model-with</link>
      <description><![CDATA[The Baize models and data are released for research purposes only at https://github. com/project-baize/baize.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/baize-an-open-source-chat-model-with</guid>
    </item>
    <item>
      <title>HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace</title>
      <link>https://paperswithcode.com/paper/hugginggpt-solving-ai-tasks-with-chatgpt-and</link>
      <description><![CDATA[Solving complicated AI tasks with different domains and modalities is a key step toward advanced artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hugginggpt-solving-ai-tasks-with-chatgpt-and</guid>
    </item>
    <item>
      <title>A Survey of Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-of-large-language-models</link>
      <description><![CDATA[To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-large-language-models</guid>
    </item>
    <item>
      <title>Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free Videos</title>
      <link>https://paperswithcode.com/paper/follow-your-pose-pose-guided-text-to-video</link>
      <description><![CDATA[Generating text-editable and pose-controllable character videos have an imperious demand in creating various digital human.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/follow-your-pose-pose-guided-text-to-video</guid>
    </item>
    <item>
      <title>LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention</title>
      <link>https://paperswithcode.com/paper/llama-adapter-efficient-fine-tuning-of</link>
      <description><![CDATA[We present LLaMA-Adapter, a lightweight adaption method to efficiently fine-tune LLaMA into an instruction-following model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-adapter-efficient-fine-tuning-of</guid>
    </item>
    <item>
      <title>CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society</title>
      <link>https://paperswithcode.com/paper/camel-communicative-agents-for-mind</link>
      <description><![CDATA[To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camel-communicative-agents-for-mind</guid>
    </item>
    <item>
      <title>Token Merging for Fast Stable Diffusion</title>
      <link>https://paperswithcode.com/paper/token-merging-for-fast-stable-diffusion</link>
      <description><![CDATA[In the process, we speed up image generation by up to 2x and reduce memory consumption by up to 5. 6x.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/token-merging-for-fast-stable-diffusion</guid>
    </item>
    <item>
      <title>ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge</title>
      <link>https://paperswithcode.com/paper/chatdoctor-a-medical-chat-model-fine-tuned-on</link>
      <description><![CDATA[Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatdoctor-a-medical-chat-model-fine-tuned-on</guid>
    </item>
    <item>
      <title>LLaMA: Open and Efficient Foundation Language Models</title>
      <link>https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</link>
      <description><![CDATA[We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</guid>
    </item>
    <item>
      <title>Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases</title>
      <link>https://paperswithcode.com/paper/exploring-the-impact-of-instruction-data</link>
      <description><![CDATA[However current research rarely studies the impact of different amounts of instruction data on model performance, especially in the real-world use cases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-impact-of-instruction-data</guid>
    </item>
    <item>
      <title>Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models</title>
      <link>https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</link>
      <description><![CDATA[To address these challenges, we introduce a system that can jointly optimize distributed execution and gradient checkpointing plans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</guid>
    </item>
    <item>
      <title>Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators</title>
      <link>https://paperswithcode.com/paper/text2video-zero-text-to-image-diffusion</link>
      <description><![CDATA[Recent text-to-video generation approaches rely on computationally heavy training and require large-scale video datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2video-zero-text-to-image-diffusion</guid>
    </item>
    <item>
      <title>3D Line Mapping Revisited</title>
      <link>https://paperswithcode.com/paper/3d-line-mapping-revisited</link>
      <description><![CDATA[In contrast to sparse keypoints, a handful of line segments can concisely encode the high-level scene layout, as they often delineate the main structural elements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-line-mapping-revisited</guid>
    </item>
    <item>
      <title>Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation</title>
      <link>https://paperswithcode.com/paper/tune-a-video-one-shot-tuning-of-image</link>
      <description><![CDATA[To replicate the success of text-to-image (T2I) generation, recent works employ large-scale video datasets to train a text-to-video (T2V) generator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tune-a-video-one-shot-tuning-of-image</guid>
    </item>
    <item>
      <title>P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</title>
      <link>https://paperswithcode.com/paper/p-tuning-v2-prompt-tuning-can-be-comparable</link>
      <description><![CDATA[Prompt tuning, which only tunes continuous prompts with a frozen language model, substantially reduces per-task storage and memory usage at training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/p-tuning-v2-prompt-tuning-can-be-comparable</guid>
    </item>
    <item>
      <title>Self-Instruct: Aligning Language Model with Self Generated Instructions</title>
      <link>https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</link>
      <description><![CDATA[Applying our method to vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT_001, which is trained with private user data and human annotations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-instruct-aligning-language-model-with</guid>
    </item>
    <item>
      <title>Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology</title>
      <link>https://paperswithcode.com/paper/ten-quick-tips-for-harnessing-the-power-of</link>
      <description><![CDATA[The rise of advanced chatbots, such as ChatGPT, has sparked curiosity in the scientific community.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ten-quick-tips-for-harnessing-the-power-of</guid>
    </item>
    <item>
      <title>Beyond Appearance: a Semantic Controllable Self-Supervised Learning Framework for Human-Centric Visual Tasks</title>
      <link>https://paperswithcode.com/paper/beyond-appearance-a-semantic-controllable</link>
      <description><![CDATA[Unlike the existing self-supervised learning methods, prior knowledge from human images is utilized in SOLIDER to build pseudo semantic labels and import more semantic information into the learned representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-appearance-a-semantic-controllable</guid>
    </item>
    <item>
      <title>NeRF-Supervised Deep Stereo</title>
      <link>https://paperswithcode.com/paper/nerf-supervised-deep-stereo</link>
      <description><![CDATA[We introduce a novel framework for training deep stereo networks effortlessly and without any ground-truth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nerf-supervised-deep-stereo</guid>
    </item>
    <item>
      <title>TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding</title>
      <link>https://paperswithcode.com/paper/taskprompter-spatial-channel-multi-task</link>
      <description><![CDATA[Each task prompt learns task-specific representation for one task, while all the prompts can jointly contribute to the learning of the shared image token representations, and the interactions between different task prompts model the cross-task relationship.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taskprompter-spatial-channel-multi-task</guid>
    </item>
  </channel>
</rss>
