<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 14 Aug 2022 21:07:29 +0000</lastBuildDate>
    <item>
      <title>Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning</title>
      <link>https://paperswithcode.com/paper/alpa-automating-inter-and-intra-operator</link>
      <description><![CDATA[Existing model-parallel training systems either require users to manually create a parallelization plan or automatically generate one from a limited space of model parallelism configurations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alpa-automating-inter-and-intra-operator</guid>
    </item>
    <item>
      <title>Collaborative Neural Rendering using Anime Character Sheets</title>
      <link>https://paperswithcode.com/paper/collaborative-neural-rendering-using-anime</link>
      <description><![CDATA[Drawing images of characters at desired poses is an essential but laborious task in anime production.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/collaborative-neural-rendering-using-anime</guid>
    </item>
    <item>
      <title>Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios</title>
      <link>https://paperswithcode.com/paper/next-vit-next-generation-vision-transformer</link>
      <description><![CDATA[Then, Next Hybrid Strategy (NHS) is designed to stack NCB and NTB in an efficient hybrid paradigm, which boosts performance in various downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/next-vit-next-generation-vision-transformer</guid>
    </item>
    <item>
      <title>Deep Patch Visual Odometry</title>
      <link>https://paperswithcode.com/paper/deep-patch-visual-odometry</link>
      <description><![CDATA[We propose Deep Patch Visual Odometry (DPVO), a new deep learning system for monocular Visual Odometry (VO).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-patch-visual-odometry</guid>
    </item>
    <item>
      <title>KeypointNeRF: Generalizing Image-based Volumetric Avatars using Relative Spatial Encoding of Keypoints</title>
      <link>https://paperswithcode.com/paper/keypointnerf-generalizing-image-based</link>
      <description><![CDATA[In this work, we investigate common issues with existing spatial encodings and propose a simple yet highly effective approach to modeling high-fidelity volumetric humans from sparse views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/keypointnerf-generalizing-image-based</guid>
    </item>
    <item>
      <title>3D Vision with Transformers: A Survey</title>
      <link>https://paperswithcode.com/paper/3d-vision-with-transformers-a-survey</link>
      <description><![CDATA[The success of the transformer architecture in natural language processing has recently triggered attention in the computer vision field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-vision-with-transformers-a-survey</guid>
    </item>
    <item>
      <title>DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction</title>
      <link>https://paperswithcode.com/paper/dl-traff-survey-and-benchmark-of-deep</link>
      <description><![CDATA[Nowadays, with the rapid development of IoT (Internet of Things) and CPS (Cyber-Physical Systems) technologies, big spatiotemporal data are being generated from mobile phones, car navigation systems, and traffic sensors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dl-traff-survey-and-benchmark-of-deep</guid>
    </item>
    <item>
      <title>Multi-scale Multi-band DenseNets for Audio Source Separation</title>
      <link>https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</link>
      <description><![CDATA[This paper deals with the problem of audio source separation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</guid>
    </item>
    <item>
      <title>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</title>
      <link>https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</link>
      <description><![CDATA[YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56. 8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</guid>
    </item>
    <item>
      <title>Reconstructing 3D Human Pose by Watching Humans in the Mirror</title>
      <link>https://paperswithcode.com/paper/reconstructing-3d-human-pose-by-watching</link>
      <description><![CDATA[In this paper, we introduce the new task of reconstructing 3D human pose from a single image in which we can see the person and the person's image through a mirror.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reconstructing-3d-human-pose-by-watching</guid>
    </item>
    <item>
      <title>GPT-NeoX-20B: An Open-Source Autoregressive Language Model</title>
      <link>https://paperswithcode.com/paper/gpt-neox-20b-an-open-source-autoregressive-1</link>
      <description><![CDATA[We introduce GPT-NeoX-20B, a 20 billion parameter autoregressive language model trained on the Pile, whose weights will be made freely and openly available to the public through a permissive license.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-neox-20b-an-open-source-autoregressive-1</guid>
    </item>
    <item>
      <title>Ivy: Templated Deep Learning for Inter-Framework Portability</title>
      <link>https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</link>
      <description><![CDATA[We introduce Ivy, a templated Deep Learning (DL) framework which abstracts existing DL frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</guid>
    </item>
    <item>
      <title>Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models</title>
      <link>https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</link>
      <description><![CDATA[In RDMs, a set of nearest neighbors is retrieved from an external database during training for each training instance, and the diffusion model is conditioned on these informative samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</guid>
    </item>
    <item>
      <title>OCR-free Document Understanding Transformer</title>
      <link>https://paperswithcode.com/paper/donut-document-understanding-transformer</link>
      <description><![CDATA[Current Visual Document Understanding (VDU) methods outsource the task of reading text to off-the-shelf Optical Character Recognition (OCR) engines and focus on the understanding task with the OCR outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/donut-document-understanding-transformer</guid>
    </item>
    <item>
      <title>Learning the Beauty in Songs: Neural Singing Voice Beautifier</title>
      <link>https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</link>
      <description><![CDATA[Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</guid>
    </item>
    <item>
      <title>Elucidating the Design Space of Diffusion-Based Generative Models</title>
      <link>https://paperswithcode.com/paper/elucidating-the-design-space-of-diffusion</link>
      <description><![CDATA[We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elucidating-the-design-space-of-diffusion</guid>
    </item>
    <item>
      <title>towhee</title>
      <link>https://github.com/towhee-io/towhee</link>
      <description><![CDATA[Towhee is a framework that is dedicated to making neural data processing pipelines simple and fast.]]></description>
      <guid isPermaLink="true">https://github.com/towhee-io/towhee</guid>
    </item>
    <item>
      <title>MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures</title>
      <link>https://paperswithcode.com/paper/mobilenerf-exploiting-the-polygon</link>
      <description><![CDATA[Neural Radiance Fields (NeRFs) have demonstrated amazing ability to synthesize images of 3D scenes from novel views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobilenerf-exploiting-the-polygon</guid>
    </item>
    <item>
      <title>Patch Similarity Aware Data-Free Quantization for Vision Transformers</title>
      <link>https://paperswithcode.com/paper/patch-similarity-aware-data-free-quantization</link>
      <description><![CDATA[Vision transformers have recently gained great success on various computer vision tasks; nevertheless, their high model complexity makes it challenging to deploy on resource-constrained devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/patch-similarity-aware-data-free-quantization</guid>
    </item>
    <item>
      <title>LiT: Zero-Shot Transfer with Locked-image text Tuning</title>
      <link>https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</link>
      <description><![CDATA[This paper presents contrastive-tuning, a simple method employing contrastive training to align image and text models while still taking advantage of their pre-training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</guid>
    </item>
  </channel>
</rss>
