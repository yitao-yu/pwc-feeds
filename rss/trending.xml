<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 26 Sep 2023 21:06:35 +0000</lastBuildDate>
    <item>
      <title>The Rise and Potential of Large Language Model Based Agents: A Survey</title>
      <link>https://paperswithcode.com/paper/the-rise-and-potential-of-large-language</link>
      <description><![CDATA[Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-rise-and-potential-of-large-language</guid>
    </item>
    <item>
      <title>LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models</title>
      <link>https://paperswithcode.com/paper/longlora-efficient-fine-tuning-of-long</link>
      <description><![CDATA[LongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a single 8x A100 machine.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longlora-efficient-fine-tuning-of-long</guid>
    </item>
    <item>
      <title>ProPainter: Improving Propagation and Transformer for Video Inpainting</title>
      <link>https://paperswithcode.com/paper/propainter-improving-propagation-and</link>
      <description><![CDATA[We also propose a mask-guided sparse video Transformer, which achieves high efficiency by discarding unnecessary and redundant tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/propainter-improving-propagation-and</guid>
    </item>
    <item>
      <title>Agents: An Open-source Framework for Autonomous Language Agents</title>
      <link>https://paperswithcode.com/paper/agents-an-open-source-framework-for</link>
      <description><![CDATA[Recent advances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can automatically solve various tasks and interact with environments, humans, and other agents using natural language interfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agents-an-open-source-framework-for</guid>
    </item>
    <item>
      <title>NExT-GPT: Any-to-Any Multimodal LLM</title>
      <link>https://paperswithcode.com/paper/next-gpt-any-to-any-multimodal-llm</link>
      <description><![CDATA[While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/next-gpt-any-to-any-multimodal-llm</guid>
    </item>
    <item>
      <title>Communicative Agents for Software Development</title>
      <link>https://paperswithcode.com/paper/communicative-agents-for-software-development</link>
      <description><![CDATA[At the core of this paradigm lies ChatDev, a virtual chat-powered software development company that mirrors the established waterfall model, meticulously dividing the development process into four distinct chronological stages: designing, coding, testing, and documenting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/communicative-agents-for-software-development</guid>
    </item>
    <item>
      <title>Kani: A Lightweight and Highly Hackable Framework for Building Language Model Applications</title>
      <link>https://paperswithcode.com/paper/kani-a-lightweight-and-highly-hackable</link>
      <description><![CDATA[Language model applications are becoming increasingly popular and complex, often including features like tool usage and retrieval augmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kani-a-lightweight-and-highly-hackable</guid>
    </item>
    <item>
      <title>The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A"</title>
      <link>https://paperswithcode.com/paper/the-reversal-curse-llms-trained-on-a-is-b</link>
      <description><![CDATA[This shows a failure of logical deduction that we hypothesize is caused by the Reversal Curse.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-reversal-curse-llms-trained-on-a-is-b</guid>
    </item>
    <item>
      <title>DreamLLM: Synergistic Multimodal Comprehension and Creation</title>
      <link>https://paperswithcode.com/paper/dreamllm-synergistic-multimodal-comprehension</link>
      <description><![CDATA[This paper presents DreamLLM, a learning framework that first achieves versatile Multimodal Large Language Models (MLLMs) empowered with frequently overlooked synergy between multimodal comprehension and creation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamllm-synergistic-multimodal-comprehension</guid>
    </item>
    <item>
      <title>AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents</title>
      <link>https://paperswithcode.com/paper/agentverse-facilitating-multi-agent</link>
      <description><![CDATA[Autonomous agents empowered by Large Language Models (LLMs) have undergone significant improvements, enabling them to generalize across a broad spectrum of tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentverse-facilitating-multi-agent</guid>
    </item>
    <item>
      <title>Focused Transformer: Contrastive Training for Context Scaling</title>
      <link>https://paperswithcode.com/paper/focused-transformer-contrastive-training-for</link>
      <description><![CDATA[This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/focused-transformer-contrastive-training-for</guid>
    </item>
    <item>
      <title>Baichuan 2: Open Large-scale Language Models</title>
      <link>https://paperswithcode.com/paper/baichuan-2-open-large-scale-language-models</link>
      <description><![CDATA[Large language models (LLMs) have demonstrated remarkable performance on a variety of natural language tasks based on just a few examples of natural language instructions, reducing the need for extensive feature engineering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/baichuan-2-open-large-scale-language-models</guid>
    </item>
    <item>
      <title>Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP</title>
      <link>https://paperswithcode.com/paper/demonstrate-search-predict-composing</link>
      <description><![CDATA[Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demonstrate-search-predict-composing</guid>
    </item>
    <item>
      <title>EfficientViT: Lightweight Multi-Scale Attention for On-Device Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/efficientvit-enhanced-linear-attention-for</link>
      <description><![CDATA[Unlike prior semantic segmentation models that rely on heavy self-attention, hardware-inefficient large-kernel convolution, or complicated topology structure to obtain good performances, our lightweight multi-scale attention achieves a global receptive field and multi-scale learning (two critical features for semantic segmentation models) with only lightweight and hardware-efficient operations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficientvit-enhanced-linear-attention-for</guid>
    </item>
    <item>
      <title>AdaBin: Improving Binary Neural Networks with Adaptive Binary Sets</title>
      <link>https://paperswithcode.com/paper/adabin-improving-binary-neural-networks-with</link>
      <description><![CDATA[Since the modern deep neural networks are of sophisticated design with complex architecture for the accuracy reason, the diversity on distributions of weights and activations is very high.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adabin-improving-binary-neural-networks-with</guid>
    </item>
    <item>
      <title>3D Gaussian Splatting for Real-Time Radiance Field Rendering</title>
      <link>https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</link>
      <description><![CDATA[Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</guid>
    </item>
    <item>
      <title>OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/omniquant-omnidirectionally-calibrated</link>
      <description><![CDATA[To tackle this issue, we introduce an Omnidirectionally calibrated Quantization (OmniQuant) technique for LLMs, which achieves good performance in diverse quantization settings while maintaining the computational efficiency of PTQ by efficiently optimizing various quantization parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omniquant-omnidirectionally-calibrated</guid>
    </item>
    <item>
      <title>MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/mosaicfusion-diffusion-models-as-data</link>
      <description><![CDATA[We present MosaicFusion, a simple yet effective diffusion-based data augmentation approach for large vocabulary instance segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mosaicfusion-diffusion-models-as-data</guid>
    </item>
    <item>
      <title>Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement</title>
      <link>https://paperswithcode.com/paper/retinexformer-one-stage-retinex-based</link>
      <description><![CDATA[When enhancing low-light images, many deep learning algorithms are based on the Retinex theory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retinexformer-one-stage-retinex-based</guid>
    </item>
    <item>
      <title>Code Llama: Open Foundation Models for Code</title>
      <link>https://paperswithcode.com/paper/code-llama-open-foundation-models-for-code</link>
      <description><![CDATA[We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/code-llama-open-foundation-models-for-code</guid>
    </item>
  </channel>
</rss>
