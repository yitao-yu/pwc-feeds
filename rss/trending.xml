<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 10 May 2023 09:12:06 +0000</lastBuildDate>
    <item>
      <title>Shap-E: Generating Conditional 3D Implicit Functions</title>
      <link>https://paperswithcode.com/paper/shap-e-generating-conditional-3d-implicit</link>
      <description><![CDATA[We present Shap-E, a conditional generative model for 3D assets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shap-e-generating-conditional-3d-implicit</guid>
    </item>
    <item>
      <title>U$^2$-Net: Going Deeper with Nested U-Structure for Salient Object Detection</title>
      <link>https://paperswithcode.com/paper/u-2-net-going-deeper-with-nested-u-structure</link>
      <description><![CDATA[In this paper, we design a simple yet powerful deep network architecture, U$^2$-Net, for salient object detection (SOD).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/u-2-net-going-deeper-with-nested-u-structure</guid>
    </item>
    <item>
      <title>HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge</title>
      <link>https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</link>
      <description><![CDATA[Large Language Models (LLMs), such as the LLaMA model, have demonstrated their effectiveness in various general-domain natural language processing (NLP) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</guid>
    </item>
    <item>
      <title>Unlimiformer: Long-Range Transformers with Unlimited Length Input</title>
      <link>https://paperswithcode.com/paper/unlimiformer-long-range-transformers-with</link>
      <description><![CDATA[This way, we can index extremely long input sequences, while every attention head in every decoder layer retrieves its top-$k$ keys, instead of attending to every key.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlimiformer-long-range-transformers-with</guid>
    </item>
    <item>
      <title>PP-LiteSeg: A Superior Real-Time Semantic Segmentation Model</title>
      <link>https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</link>
      <description><![CDATA[Real-world applications have high demands for semantic segmentation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</guid>
    </item>
    <item>
      <title>Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models</title>
      <link>https://paperswithcode.com/paper/panda-llm-training-data-and-evaluation-for</link>
      <description><![CDATA[This project focuses on enhancing open-source large language models through instruction-tuning and providing comprehensive evaluations of their performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/panda-llm-training-data-and-evaluation-for</guid>
    </item>
    <item>
      <title>Personalize Segment Anything Model with One Shot</title>
      <link>https://paperswithcode.com/paper/personalize-segment-anything-model-with-one</link>
      <description><![CDATA[Driven by large-data pre-training, Segment Anything Model (SAM) has been demonstrated as a powerful and promptable framework, revolutionizing the segmentation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalize-segment-anything-model-with-one</guid>
    </item>
    <item>
      <title>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</title>
      <link>https://paperswithcode.com/paper/harnessing-the-power-of-llms-in-practice-a</link>
      <description><![CDATA[This paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream natural language processing (NLP) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/harnessing-the-power-of-llms-in-practice-a</guid>
    </item>
    <item>
      <title>LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention</title>
      <link>https://paperswithcode.com/paper/llama-adapter-efficient-fine-tuning-of</link>
      <description><![CDATA[We present LLaMA-Adapter, a lightweight adaption method to efficiently fine-tune LLaMA into an instruction-following model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-adapter-efficient-fine-tuning-of</guid>
    </item>
    <item>
      <title>mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality</title>
      <link>https://paperswithcode.com/paper/mplug-owl-modularization-empowers-large</link>
      <description><![CDATA[Our code, pre-trained model, instruction-tuned models, and evaluation set are available at https://github. com/X-PLUG/mPLUG-Owl.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mplug-owl-modularization-empowers-large</guid>
    </item>
    <item>
      <title>A Survey of Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-of-large-language-models</link>
      <description><![CDATA[To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-large-language-models</guid>
    </item>
    <item>
      <title>Visual Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/visual-instruction-tuning</link>
      <description><![CDATA[Instruction tuning large language models (LLMs) using machine-generated instruction-following data has improved zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-instruction-tuning</guid>
    </item>
    <item>
      <title>Otter: A Multi-Modal Model with In-Context Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/otter-a-multi-modal-model-with-in-context</link>
      <description><![CDATA[Large language models (LLMs) have demonstrated significant universal capabilities as few/zero-shot learners in various tasks due to their pre-training on vast amounts of text data, as exemplified by GPT-3, which boosted to InstrctGPT and ChatGPT, effectively following natural language instructions to accomplish real-world tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/otter-a-multi-modal-model-with-in-context</guid>
    </item>
    <item>
      <title>Learnable latent embeddings for joint behavioral and neural analysis</title>
      <link>https://paperswithcode.com/paper/learnable-latent-embeddings-for-joint</link>
      <description><![CDATA[Mapping behavioral actions to neural activity is a fundamental goal of neuroscience.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learnable-latent-embeddings-for-joint</guid>
    </item>
    <item>
      <title>Track Anything: Segment Anything Meets Videos</title>
      <link>https://paperswithcode.com/paper/track-anything-segment-anything-meets-videos</link>
      <description><![CDATA[Therefore, in this report, we propose Track Anything Model (TAM), which achieves high-performance interactive tracking and segmentation in videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/track-anything-segment-anything-meets-videos</guid>
    </item>
    <item>
      <title>CodeGen2: Lessons for Training LLMs on Programming and Natural Languages</title>
      <link>https://paperswithcode.com/paper/codegen2-lessons-for-training-llms-on</link>
      <description><![CDATA[In this study, we attempt to render the training of LLMs for program synthesis more efficient by unifying four key components: (1) model architectures, (2) learning methods, (3) infill sampling, and, (4) data distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codegen2-lessons-for-training-llms-on</guid>
    </item>
    <item>
      <title>Disentangling Writer and Character Styles for Handwriting Generation</title>
      <link>https://paperswithcode.com/paper/disentangling-writer-and-character-styles-for</link>
      <description><![CDATA[In light of this, we propose to disentangle the style representations at both writer and character levels from individual handwritings to synthesize realistic stylized online handwritten characters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disentangling-writer-and-character-styles-for</guid>
    </item>
    <item>
      <title>ZipIt! Merging Models from Different Tasks without Training</title>
      <link>https://paperswithcode.com/paper/zipit-merging-models-from-different-tasks</link>
      <description><![CDATA[While this works for models trained on the same task, we find that this fails to account for the differences in models trained on disjoint tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zipit-merging-models-from-different-tasks</guid>
    </item>
    <item>
      <title>Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca</title>
      <link>https://paperswithcode.com/paper/efficient-and-effective-text-encoding-for</link>
      <description><![CDATA[Large Language Models (LLMs), such as ChatGPT and GPT-4, have revolutionized natural language processing research and demonstrated potential in Artificial General Intelligence (AGI).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-and-effective-text-encoding-for</guid>
    </item>
    <item>
      <title>Composite Motion Learning with Task Control</title>
      <link>https://paperswithcode.com/paper/composite-motion-learning-with-task-control</link>
      <description><![CDATA[In contrast to existing data-driven approaches using reinforcement learning that imitate full-body motions, we learn decoupled motions for specific body parts from multiple reference motions simultaneously and directly by leveraging the use of multiple discriminators in a GAN-like setup.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/composite-motion-learning-with-task-control</guid>
    </item>
  </channel>
</rss>
