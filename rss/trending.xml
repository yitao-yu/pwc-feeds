<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 09 Nov 2022 09:15:46 +0000</lastBuildDate>
    <item>
      <title>Real-Time Target Sound Extraction</title>
      <link>https://paperswithcode.com/paper/real-time-target-sound-extraction</link>
      <description><![CDATA[We present the first neural network model to achieve real-time and streaming target sound extraction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-target-sound-extraction</guid>
    </item>
    <item>
      <title>High Fidelity Neural Audio Compression</title>
      <link>https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</link>
      <description><![CDATA[We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</guid>
    </item>
    <item>
      <title>Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models</title>
      <link>https://paperswithcode.com/paper/efficient-spatially-sparse-inference-for</link>
      <description><![CDATA[With 1. 2%-area edited regions, our method reduces the computation of DDIM by 7. 5$\times$ and GauGAN by 18$\times$ while preserving the visual fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-spatially-sparse-inference-for</guid>
    </item>
    <item>
      <title>Music Mixing Style Transfer: A Contrastive Learning Approach to Disentangle Audio Effects</title>
      <link>https://paperswithcode.com/paper/music-mixing-style-transfer-a-contrastive</link>
      <description><![CDATA[We propose an end-to-end music mixing style transfer system that converts the mixing style of an input multitrack to that of a reference song.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/music-mixing-style-transfer-a-contrastive</guid>
    </item>
    <item>
      <title>A Survey of Deep Face Restoration: Denoise, Super-Resolution, Deblur, Artifact Removal</title>
      <link>https://paperswithcode.com/paper/a-survey-of-deep-face-restoration-denoise</link>
      <description><![CDATA[Second, we discuss the challenges of face restoration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-deep-face-restoration-denoise</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>Pop2Piano : Pop Audio-based Piano Cover Generation</title>
      <link>https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</link>
      <description><![CDATA[The piano cover of pop music is widely enjoyed by people.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</guid>
    </item>
    <item>
      <title>Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese</title>
      <link>https://paperswithcode.com/paper/chinese-clip-contrastive-vision-language</link>
      <description><![CDATA[The tremendous success of CLIP (Radford et al., 2021) has promoted the research and application of contrastive learning for vision-language pretraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chinese-clip-contrastive-vision-language</guid>
    </item>
    <item>
      <title>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</title>
      <link>https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</link>
      <description><![CDATA[Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</guid>
    </item>
    <item>
      <title>WeightedSHAP: analyzing and improving Shapley based feature attributions</title>
      <link>https://paperswithcode.com/paper/weightedshap-analyzing-and-improving-shapley</link>
      <description><![CDATA[On several real-world datasets, we demonstrate that the influential features identified by WeightedSHAP are better able to recapitulate the model's predictions compared to the features identified by the Shapley value.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/weightedshap-analyzing-and-improving-shapley</guid>
    </item>
    <item>
      <title>MotionBERT: Unified Pretraining for Human Motion Analysis</title>
      <link>https://paperswithcode.com/paper/motionbert-unified-pretraining-for-human</link>
      <description><![CDATA[We present MotionBERT, a unified pretraining framework, to tackle different sub-tasks of human motion analysis including 3D pose estimation, skeleton-based action recognition, and mesh recovery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motionbert-unified-pretraining-for-human</guid>
    </item>
    <item>
      <title>Large Language Models Are Human-Level Prompt Engineers</title>
      <link>https://paperswithcode.com/paper/large-language-models-are-human-level-prompt</link>
      <description><![CDATA[By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-are-human-level-prompt</guid>
    </item>
    <item>
      <title>Example-Based Named Entity Recognition</title>
      <link>https://paperswithcode.com/paper/example-based-named-entity-recognition</link>
      <description><![CDATA[We present a novel approach to named entity recognition (NER) in the presence of scarce data that we call example-based NER.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/example-based-named-entity-recognition</guid>
    </item>
    <item>
      <title>DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models</title>
      <link>https://paperswithcode.com/paper/dpm-solver-fast-solver-for-guided-sampling-of</link>
      <description><![CDATA[The commonly-used fast sampler for guided sampling is DDIM, a first-order diffusion ODE solver that generally needs 100 to 250 steps for high-quality samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dpm-solver-fast-solver-for-guided-sampling-of</guid>
    </item>
    <item>
      <title>Robust Speech Recognition via Large-Scale Weak Supervision</title>
      <link>https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale</link>
      <description><![CDATA[We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale</guid>
    </item>
    <item>
      <title>OCR-VQGAN: Taming Text-within-Image Generation</title>
      <link>https://paperswithcode.com/paper/ocr-vqgan-taming-text-within-image-generation</link>
      <description><![CDATA[To alleviate this problem, we present OCR-VQGAN, an image encoder, and decoder that leverages OCR pre-trained features to optimize a text perceptual loss, encouraging the architecture to preserve high-fidelity text and diagram structure.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ocr-vqgan-taming-text-within-image-generation</guid>
    </item>
    <item>
      <title>Zero-Shot Learners for Natural Language Understanding via a Unified Multiple Choice Perspective</title>
      <link>https://paperswithcode.com/paper/zero-shot-learners-for-natural-language</link>
      <description><![CDATA[We propose a new paradigm for zero-shot learners that is format agnostic, i. e., it is compatible with any format and applicable to a list of language tasks, such as text classification, commonsense reasoning, coreference resolution, and sentiment analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-learners-for-natural-language</guid>
    </item>
    <item>
      <title>DreamFusion: Text-to-3D using 2D Diffusion</title>
      <link>https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</link>
      <description><![CDATA[Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</guid>
    </item>
    <item>
      <title>Ivy: Templated Deep Learning for Inter-Framework Portability</title>
      <link>https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</link>
      <description><![CDATA[We introduce Ivy, a templated Deep Learning (DL) framework which abstracts existing DL frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</guid>
    </item>
    <item>
      <title>Fast Sampling of Diffusion Models with Exponential Integrator</title>
      <link>https://paperswithcode.com/paper/fast-sampling-of-diffusion-models-with</link>
      <description><![CDATA[Our goal is to develop a fast sampling method for DMs with a much less number of steps while retaining high sample quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-sampling-of-diffusion-models-with</guid>
    </item>
  </channel>
</rss>
