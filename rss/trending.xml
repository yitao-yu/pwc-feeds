<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 10 Aug 2023 21:05:52 +0000</lastBuildDate>
    <item>
      <title>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</title>
      <link>https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</link>
      <description><![CDATA[Recently, remarkable progress has been made in automated task-solving through the use of multi-agent driven by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</guid>
    </item>
    <item>
      <title>AgentBench: Evaluating LLMs as Agents</title>
      <link>https://paperswithcode.com/paper/agentbench-evaluating-llms-as-agents</link>
      <description><![CDATA[Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentbench-evaluating-llms-as-agents</guid>
    </item>
    <item>
      <title>ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</title>
      <link>https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</link>
      <description><![CDATA[We first present ToolBench, an instruction-tuning dataset for tool use, which is created automatically using ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</guid>
    </item>
    <item>
      <title>Effective Whole-body Pose Estimation with Two-stages Distillation</title>
      <link>https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</link>
      <description><![CDATA[Different from the previous self-knowledge distillation, this stage finetunes the student's head with only 20% training time as a plug-and-play training strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</guid>
    </item>
    <item>
      <title>Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors</title>
      <link>https://paperswithcode.com/paper/magic123-one-image-to-high-quality-3d-object</link>
      <description><![CDATA[We present Magic123, a two-stage coarse-to-fine approach for high-quality, textured 3D meshes generation from a single unposed image in the wild using both2D and 3D priors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magic123-one-image-to-high-quality-3d-object</guid>
    </item>
    <item>
      <title>LISA: Reasoning Segmentation via Large Language Model</title>
      <link>https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</link>
      <description><![CDATA[In this work, we propose a new segmentation task -- reasoning segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</guid>
    </item>
    <item>
      <title>Simple and Controllable Music Generation</title>
      <link>https://paperswithcode.com/paper/simple-and-controllable-music-generation</link>
      <description><![CDATA[We tackle the task of conditional music generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simple-and-controllable-music-generation</guid>
    </item>
    <item>
      <title>Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP</title>
      <link>https://paperswithcode.com/paper/convolutions-die-hard-open-vocabulary</link>
      <description><![CDATA[The proposed FC-CLIP, benefits from the following observations: the frozen CLIP backbone maintains the ability of open-vocabulary classification and can also serve as a strong mask generator, and the convolutional CLIP generalizes well to a larger input resolution than the one used during contrastive image-text pretraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/convolutions-die-hard-open-vocabulary</guid>
    </item>
    <item>
      <title>QLoRA: Efficient Finetuning of Quantized LLMs</title>
      <link>https://paperswithcode.com/paper/qlora-efficient-finetuning-of-quantized-llms</link>
      <description><![CDATA[Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99. 3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qlora-efficient-finetuning-of-quantized-llms</guid>
    </item>
    <item>
      <title>Gorilla: Large Language Model Connected with Massive APIs</title>
      <link>https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</link>
      <description><![CDATA[Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</guid>
    </item>
    <item>
      <title>On Architectural Compression of Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/on-architectural-compression-of-text-to-image</link>
      <description><![CDATA[Exceptional text-to-image (T2I) generation results of Stable Diffusion models (SDMs) come with substantial computational demands.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-architectural-compression-of-text-to-image</guid>
    </item>
    <item>
      <title>DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code Collaborated with Mixer</title>
      <link>https://paperswithcode.com/paper/dc-comix-tts-an-end-to-end-expressive-tts</link>
      <description><![CDATA[We demonstrate that the reference encoder learns better speaker-independent prosody when discrete code is utilized as input in the experiments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dc-comix-tts-an-end-to-end-expressive-tts</guid>
    </item>
    <item>
      <title>Universal and Transferable Adversarial Attacks on Aligned Language Models</title>
      <link>https://paperswithcode.com/paper/universal-and-transferable-adversarial</link>
      <description><![CDATA[Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-and-transferable-adversarial</guid>
    </item>
    <item>
      <title>VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design</title>
      <link>https://paperswithcode.com/paper/vits2-improving-quality-and-efficiency-of</link>
      <description><![CDATA[Single-stage text-to-speech models have been actively studied recently, and their results have outperformed two-stage pipeline systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vits2-improving-quality-and-efficiency-of</guid>
    </item>
    <item>
      <title>UniVTG: Towards Unified Video-Language Temporal Grounding</title>
      <link>https://paperswithcode.com/paper/univtg-towards-unified-video-language</link>
      <description><![CDATA[Most methods in this direction develop taskspecific models that are trained with type-specific labels, such as moment retrieval (time interval) and highlight detection (worthiness curve), which limits their abilities to generalize to various VTG tasks and labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/univtg-towards-unified-video-language</guid>
    </item>
    <item>
      <title>The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World</title>
      <link>https://paperswithcode.com/paper/the-all-seeing-project-towards-panoptic</link>
      <description><![CDATA[We present the All-Seeing (AS) project: a large-scale data and model for recognizing and understanding everything in the open world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-all-seeing-project-towards-panoptic</guid>
    </item>
    <item>
      <title>QuIP: 2-Bit Quantization of Large Language Models With Guarantees</title>
      <link>https://paperswithcode.com/paper/quip-2-bit-quantization-of-large-language</link>
      <description><![CDATA[This work studies post-training parameter quantization in large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quip-2-bit-quantization-of-large-language</guid>
    </item>
    <item>
      <title>Generative Agents: Interactive Simulacra of Human Behavior</title>
      <link>https://paperswithcode.com/paper/generative-agents-interactive-simulacra-of</link>
      <description><![CDATA[Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-agents-interactive-simulacra-of</guid>
    </item>
    <item>
      <title>Data-Free Learning of Reduced-Order Kinematics</title>
      <link>https://paperswithcode.com/paper/data-free-learning-of-reduced-order</link>
      <description><![CDATA[Physical systems ranging from elastic bodies to kinematic linkages are defined on high-dimensional configuration spaces, yet their typical low-energy configurations are concentrated on much lower-dimensional subspaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-free-learning-of-reduced-order</guid>
    </item>
    <item>
      <title>Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising</title>
      <link>https://paperswithcode.com/paper/lighting-every-darkness-in-two-pairs-a</link>
      <description><![CDATA[Calibration-based methods have dominated RAW image denoising under extremely low-light environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lighting-every-darkness-in-two-pairs-a</guid>
    </item>
  </channel>
</rss>
