<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 26 Jan 2023 09:12:36 +0000</lastBuildDate>
    <item>
      <title>InstructPix2Pix: Learning to Follow Image Editing Instructions</title>
      <link>https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</link>
      <description><![CDATA[We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</guid>
    </item>
    <item>
      <title>StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis</title>
      <link>https://paperswithcode.com/paper/stylegan-t-unlocking-the-power-of-gans-for</link>
      <description><![CDATA[Text-to-image synthesis has recently seen significant progress thanks to large pretrained language models, large-scale training data, and the introduction of scalable model families such as diffusion and autoregressive models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stylegan-t-unlocking-the-power-of-gans-for</guid>
    </item>
    <item>
      <title>Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP</title>
      <link>https://paperswithcode.com/paper/demonstrate-search-predict-composing</link>
      <description><![CDATA[Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demonstrate-search-predict-composing</guid>
    </item>
    <item>
      <title>Learning the Beauty in Songs: Neural Singing Voice Beautifier</title>
      <link>https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</link>
      <description><![CDATA[Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</guid>
    </item>
    <item>
      <title>K-Planes: Explicit Radiance Fields in Space, Time, and Appearance</title>
      <link>https://paperswithcode.com/paper/k-planes-explicit-radiance-fields-in-space</link>
      <description><![CDATA[We introduce k-planes, a white-box model for radiance fields in arbitrary dimensions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/k-planes-explicit-radiance-fields-in-space</guid>
    </item>
    <item>
      <title>Hungry Hungry Hippos: Towards Language Modeling with State Space Models</title>
      <link>https://paperswithcode.com/paper/hungry-hungry-hippos-towards-language</link>
      <description><![CDATA[First, we use synthetic language modeling tasks to understand the gap between SSMs and attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hungry-hungry-hippos-towards-language</guid>
    </item>
    <item>
      <title>Learning-Rate-Free Learning by D-Adaptation</title>
      <link>https://paperswithcode.com/paper/learning-rate-free-learning-by-d-adaptation</link>
      <description><![CDATA[In this work, we describe a single-loop method, with no back-tracking or line searches, which does not require knowledge of $D$ yet asymptotically achieves the optimal rate of convergence for the complexity class of convex Lipschitz functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-rate-free-learning-by-d-adaptation</guid>
    </item>
    <item>
      <title>Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling</title>
      <link>https://paperswithcode.com/paper/designing-bert-for-convolutional-networks</link>
      <description><![CDATA[This is the first use of sparse convolution for 2D masked modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/designing-bert-for-convolutional-networks</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>Multiview Compressive Coding for 3D Reconstruction</title>
      <link>https://paperswithcode.com/paper/multiview-compressive-coding-for-3d</link>
      <description><![CDATA[We introduce a simple framework that operates on 3D points of single objects or whole scenes coupled with category-agnostic large-scale training from diverse RGB-D videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiview-compressive-coding-for-3d</guid>
    </item>
    <item>
      <title>On the Expressive Power of Geometric Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/on-the-expressive-power-of-geometric-graph</link>
      <description><![CDATA[The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-expressive-power-of-geometric-graph</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations</title>
      <link>https://paperswithcode.com/paper/triton-an-intermediate-language-and-compiler</link>
      <description><![CDATA[The validation and deployment of novel research ideas in the field of Deep Learning is often limited by the availability of efficient compute kernels for certain basic primitives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triton-an-intermediate-language-and-compiler</guid>
    </item>
    <item>
      <title>Multi-scale Multi-band DenseNets for Audio Source Separation</title>
      <link>https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</link>
      <description><![CDATA[This paper deals with the problem of audio source separation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</guid>
    </item>
    <item>
      <title>Is ChatGPT A Good Translator? A Preliminary Study</title>
      <link>https://paperswithcode.com/paper/is-chatgpt-a-good-translator-a-preliminary</link>
      <description><![CDATA[This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-chatgpt-a-good-translator-a-preliminary</guid>
    </item>
    <item>
      <title>GLIGEN: Open-Set Grounded Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/gligen-open-set-grounded-text-to-image</link>
      <description><![CDATA[Large-scale text-to-image diffusion models have made amazing advances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gligen-open-set-grounded-text-to-image</guid>
    </item>
    <item>
      <title>Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers</title>
      <link>https://paperswithcode.com/paper/why-can-gpt-learn-in-context-language-models</link>
      <description><![CDATA[In order to better understand how ICL works, this paper explains language models as meta-optimizers and understands ICL as a kind of implicit finetuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/why-can-gpt-learn-in-context-language-models</guid>
    </item>
    <item>
      <title>DeepMatcher: A Deep Transformer-based Network for Robust and Accurate Local Feature Matching</title>
      <link>https://paperswithcode.com/paper/deepmatcher-a-deep-transformer-based-network</link>
      <description><![CDATA[In this work, we propose DeepMatcher, a deep Transformer-based network built upon our investigation of local feature matching in detector-free methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepmatcher-a-deep-transformer-based-network</guid>
    </item>
    <item>
      <title>GLM-130B: An Open Bilingual Pre-trained Model</title>
      <link>https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</link>
      <description><![CDATA[We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</guid>
    </item>
    <item>
      <title>VToonify: Controllable High-Resolution Portrait Video Style Transfer</title>
      <link>https://paperswithcode.com/paper/vtoonify-controllable-high-resolution</link>
      <description><![CDATA[Although a series of successful portrait image toonification models built upon the powerful StyleGAN have been proposed, these image-oriented methods have obvious limitations when applied to videos, such as the fixed frame size, the requirement of face alignment, missing non-facial details and temporal inconsistency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vtoonify-controllable-high-resolution</guid>
    </item>
  </channel>
</rss>
