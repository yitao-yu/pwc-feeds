<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 29 Aug 2022 09:15:32 +0000</lastBuildDate>
    <item>
      <title>An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion</title>
      <link>https://paperswithcode.com/paper/an-image-is-worth-one-word-personalizing-text</link>
      <description><![CDATA[Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-image-is-worth-one-word-personalizing-text</guid>
    </item>
    <item>
      <title>Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise</title>
      <link>https://paperswithcode.com/paper/cold-diffusion-inverting-arbitrary-image</link>
      <description><![CDATA[We observe that the generative behavior of diffusion models is not strongly dependent on the choice of image degradation, and in fact an entire family of generative models can be constructed by varying this choice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cold-diffusion-inverting-arbitrary-image</guid>
    </item>
    <item>
      <title>PeRFception: Perception using Radiance Fields</title>
      <link>https://paperswithcode.com/paper/perfception-perception-using-radiance-fields</link>
      <description><![CDATA[The recent progress in implicit 3D representation, i. e., Neural Radiance Fields (NeRFs), has made accurate and photorealistic 3D reconstruction possible in a differentiable manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/perfception-perception-using-radiance-fields</guid>
    </item>
    <item>
      <title>NeuMan: Neural Human Radiance Field from a Single Video</title>
      <link>https://paperswithcode.com/paper/neuman-neural-human-radiance-field-from-a</link>
      <description><![CDATA[Photorealistic rendering and reposing of humans is important for enabling augmented reality experiences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuman-neural-human-radiance-field-from-a</guid>
    </item>
    <item>
      <title>Audio-Visual Segmentation</title>
      <link>https://paperswithcode.com/paper/audio-visual-segmentation</link>
      <description><![CDATA[To deal with the AVS problem, we propose a novel method that uses a temporal pixel-wise audio-visual interaction module to inject audio semantics as guidance for the visual segmentation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audio-visual-segmentation</guid>
    </item>
    <item>
      <title>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</title>
      <link>https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</link>
      <description><![CDATA[YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56. 8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</guid>
    </item>
    <item>
      <title>YOLOPv2: Better, Faster, Stronger for Panoptic Driving Perception</title>
      <link>https://paperswithcode.com/paper/yolopv2-better-faster-stronger-for-panoptic</link>
      <description><![CDATA[Over the last decade, multi-tasking learning approaches have achieved promising results in solving panoptic driving perception problems, providing both high-precision and high-efficiency performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolopv2-better-faster-stronger-for-panoptic</guid>
    </item>
    <item>
      <title>In Defense of Online Models for Video Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/in-defense-of-online-models-for-video</link>
      <description><![CDATA[In recent years, video instance segmentation (VIS) has been largely advanced by offline models, while online models gradually attracted less attention possibly due to their inferior performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/in-defense-of-online-models-for-video</guid>
    </item>
    <item>
      <title>Multi-scale Multi-band DenseNets for Audio Source Separation</title>
      <link>https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</link>
      <description><![CDATA[This paper deals with the problem of audio source separation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</guid>
    </item>
    <item>
      <title>Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models</title>
      <link>https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</link>
      <description><![CDATA[In RDMs, a set of nearest neighbors is retrieved from an external database during training for each training instance, and the diffusion model is conditioned on these informative samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</guid>
    </item>
    <item>
      <title>Musika! Fast Infinite Waveform Music Generation</title>
      <link>https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</link>
      <description><![CDATA[We release the source code and pretrained autoencoder weights at github. com/marcoppasini/musika, such that a GAN can be trained on a new music domain with a single GPU in a matter of hours.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</guid>
    </item>
    <item>
      <title>towhee</title>
      <link>https://github.com/towhee-io/towhee</link>
      <description><![CDATA[Towhee is a framework that is dedicated to making neural data processing pipelines simple and fast.]]></description>
      <guid isPermaLink="true">https://github.com/towhee-io/towhee</guid>
    </item>
    <item>
      <title>FedDM: Iterative Distribution Matching for Communication-Efficient Federated Learning</title>
      <link>https://paperswithcode.com/paper/feddm-iterative-distribution-matching-for</link>
      <description><![CDATA[Federated learning~(FL) has recently attracted increasing attention from academia and industry, with the ultimate goal of achieving collaborative training under privacy and communication constraints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/feddm-iterative-distribution-matching-for</guid>
    </item>
    <item>
      <title>Language models enable zero-shot prediction of the effects of mutations on protein function</title>
      <link>https://paperswithcode.com/paper/language-models-enable-zero-shot-prediction</link>
      <description><![CDATA[Modeling the effect of sequence variation on function is a fundamental problem for understanding and designing proteins.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-enable-zero-shot-prediction</guid>
    </item>
    <item>
      <title>PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds</title>
      <link>https://paperswithcode.com/paper/paconv-position-adaptive-convolution-with</link>
      <description><![CDATA[The key of PAConv is to construct the convolution kernel by dynamically assembling basic weight matrices stored in Weight Bank, where the coefficients of these weight matrices are self-adaptively learned from point positions through ScoreNet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paconv-position-adaptive-convolution-with</guid>
    </item>
    <item>
      <title>Federated Learning via Decentralized Dataset Distillation in Resource-Constrained Edge Environments</title>
      <link>https://paperswithcode.com/paper/federated-learning-via-decentralized-dataset</link>
      <description><![CDATA[We introduce a novel federated learning framework, FedD3, which reduces the overall communication volume and with that opens up the concept of federated learning to more application scenarios in network-constrained environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/federated-learning-via-decentralized-dataset</guid>
    </item>
    <item>
      <title>A Walk in the Park: Learning to Walk in 20 Minutes With Model-Free Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/a-walk-in-the-park-learning-to-walk-in-20</link>
      <description><![CDATA[Deep reinforcement learning is a promising approach to learning policies in uncontrolled environments that do not require domain knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-walk-in-the-park-learning-to-walk-in-20</guid>
    </item>
    <item>
      <title>A ConvNet for the 2020s</title>
      <link>https://paperswithcode.com/paper/a-convnet-for-the-2020s</link>
      <description><![CDATA[The "Roaring 20s" of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-convnet-for-the-2020s</guid>
    </item>
    <item>
      <title>YOLOV: Making Still Image Object Detectors Great at Video Object Detection</title>
      <link>https://paperswithcode.com/paper/yolov-making-still-image-object-detectors</link>
      <description><![CDATA[On the positive side, the detection in a certain frame of a video, compared with in a still image, can draw support from other frames.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov-making-still-image-object-detectors</guid>
    </item>
    <item>
      <title>Evaluating Large Language Models Trained on Code</title>
      <link>https://paperswithcode.com/paper/evaluating-large-language-models-trained-on</link>
      <description><![CDATA[We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-large-language-models-trained-on</guid>
    </item>
  </channel>
</rss>
