<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 22 Feb 2024 21:06:29 +0000</lastBuildDate>
    <item>
      <title>World Model on Million-Length Video And Language With RingAttention</title>
      <link>https://paperswithcode.com/paper/world-model-on-million-length-video-and</link>
      <description><![CDATA[This work paves the way for training on massive datasets of long video and language to develop understanding of both human knowledge and the multimodal world, and broader capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/world-model-on-million-length-video-and</guid>
    </item>
    <item>
      <title>UFO: A UI-Focused Agent for Windows OS Interaction</title>
      <link>https://paperswithcode.com/paper/ufo-a-ui-focused-agent-for-windows-os</link>
      <description><![CDATA[We introduce UFO, an innovative UI-Focused agent to fulfill user requests tailored to applications on Windows OS, harnessing the capabilities of GPT-Vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ufo-a-ui-focused-agent-for-windows-os</guid>
    </item>
    <item>
      <title>Scalable Diffusion Models with Transformers</title>
      <link>https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</link>
      <description><![CDATA[We explore a new class of diffusion models based on the transformer architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</guid>
    </item>
    <item>
      <title>Revisiting Feature Prediction for Learning Visual Representations from Video</title>
      <link>https://paperswithcode.com/paper/revisiting-feature-prediction-for-learning</link>
      <description><![CDATA[This paper explores feature prediction as a stand-alone objective for unsupervised learning from video and introduces V-JEPA, a collection of vision models trained solely using a feature prediction objective, without the use of pretrained image encoders, text, negative examples, reconstruction, or other sources of supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-feature-prediction-for-learning</guid>
    </item>
    <item>
      <title>Neural Network Diffusion</title>
      <link>https://paperswithcode.com/paper/neural-network-diffusion</link>
      <description><![CDATA[The autoencoder extracts latent representations of a subset of the trained network parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-network-diffusion</guid>
    </item>
    <item>
      <title>FiT: Flexible Vision Transformer for Diffusion Model</title>
      <link>https://paperswithcode.com/paper/fit-flexible-vision-transformer-for-diffusion</link>
      <description><![CDATA[Nature is infinitely resolution-free.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fit-flexible-vision-transformer-for-diffusion</guid>
    </item>
    <item>
      <title>GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object with Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/gaussianobject-just-taking-four-images-to-get</link>
      <description><![CDATA[Then we construct a Gaussian repair model based on diffusion models to supplement the omitted object information, where Gaussians are further refined.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaussianobject-just-taking-four-images-to-get</guid>
    </item>
    <item>
      <title>YOLO-World: Real-Time Open-Vocabulary Object Detection</title>
      <link>https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</link>
      <description><![CDATA[The You Only Look Once (YOLO) series of detectors have established themselves as efficient and practical tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</guid>
    </item>
    <item>
      <title>DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows</title>
      <link>https://paperswithcode.com/paper/datadreamer-a-tool-for-synthetic-data</link>
      <description><![CDATA[The rapid rise to prominence of these models and these unique challenges has had immediate adverse impacts on open science and on the reproducibility of work that uses them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datadreamer-a-tool-for-synthetic-data</guid>
    </item>
    <item>
      <title>DoRA: Weight-Decomposed Low-Rank Adaptation</title>
      <link>https://paperswithcode.com/paper/dora-weight-decomposed-low-rank-adaptation</link>
      <description><![CDATA[By employing DoRA, we enhance both the learning capacity and training stability of LoRA while avoiding any additional inference overhead.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dora-weight-decomposed-low-rank-adaptation</guid>
    </item>
    <item>
      <title>OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning</title>
      <link>https://paperswithcode.com/paper/openfedllm-training-large-language-models-on</link>
      <description><![CDATA[Trained on massive publicly available data, large language models (LLMs) have demonstrated tremendous success across various fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openfedllm-training-large-language-models-on</guid>
    </item>
    <item>
      <title>GraphCast: Learning skillful medium-range global weather forecasting</title>
      <link>https://paperswithcode.com/paper/graphcast-learning-skillful-medium-range</link>
      <description><![CDATA[Global medium-range weather forecasting is critical to decision-making across many social and economic domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphcast-learning-skillful-medium-range</guid>
    </item>
    <item>
      <title>Generative Representational Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/generative-representational-instruction</link>
      <description><![CDATA[Notably, we find that GRIT matches training on only generative or embedding data, thus we can unify both at no performance loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-representational-instruction</guid>
    </item>
    <item>
      <title>Linear Transformers with Learnable Kernel Functions are Better In-Context Models</title>
      <link>https://paperswithcode.com/paper/linear-transformers-with-learnable-kernel</link>
      <description><![CDATA[Advancing the frontier of subquadratic architectures for Language Models (LMs) is crucial in the rapidly evolving field of natural language processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/linear-transformers-with-learnable-kernel</guid>
    </item>
    <item>
      <title>SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers</title>
      <link>https://paperswithcode.com/paper/sit-exploring-flow-and-diffusion-based</link>
      <description><![CDATA[We present Scalable Interpolant Transformers (SiT), a family of generative models built on the backbone of Diffusion Transformers (DiT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sit-exploring-flow-and-diffusion-based</guid>
    </item>
    <item>
      <title>TorchCP: A Library for Conformal Prediction based on PyTorch</title>
      <link>https://paperswithcode.com/paper/torchcp-a-library-for-conformal-prediction</link>
      <description><![CDATA[TorchCP is a Python toolbox for conformal prediction research on deep learning models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchcp-a-library-for-conformal-prediction</guid>
    </item>
    <item>
      <title>Data Engineering for Scaling Language Models to 128K Context</title>
      <link>https://paperswithcode.com/paper/data-engineering-for-scaling-language-models</link>
      <description><![CDATA[We demonstrate that continual pretraining of the full model on 1B-5B tokens of such data is an effective and affordable strategy for scaling the context length of language models to 128K.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-engineering-for-scaling-language-models</guid>
    </item>
    <item>
      <title>MagicPose: Realistic Human Poses and Facial Expressions Retargeting with Identity-aware Diffusion</title>
      <link>https://paperswithcode.com/paper/magicdance-realistic-human-dance-video</link>
      <description><![CDATA[In this work, we propose MagicPose, a diffusion-based model for 2D human pose and facial expression retargeting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magicdance-realistic-human-dance-video</guid>
    </item>
    <item>
      <title>Extreme Video Compression with Pre-trained Diffusion Models</title>
      <link>https://paperswithcode.com/paper/extreme-video-compression-with-pre-trained</link>
      <description><![CDATA[The results showcase the potential of exploiting the temporal relations in video data using generative models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extreme-video-compression-with-pre-trained</guid>
    </item>
    <item>
      <title>Magic-Me: Identity-Specific Video Customized Diffusion</title>
      <link>https://paperswithcode.com/paper/magic-me-identity-specific-video-customized</link>
      <description><![CDATA[In the field of text-to-image generation (T2I), subject-driven content generation has achieved great progress with the ID in the images controllable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magic-me-identity-specific-video-customized</guid>
    </item>
  </channel>
</rss>
