<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 21 Feb 2025 21:08:41 +0000</lastBuildDate>
    <item>
      <title>Step-Audio: Unified Understanding and Generation in Intelligent Speech Interaction</title>
      <link>https://paperswithcode.com/paper/step-audio-unified-understanding-and</link>
      <description><![CDATA[Based on our new StepEval-Audio-360 evaluation benchmark, Step-Audio achieves state-of-the-art performance in human evaluations, especially in terms of instruction following.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/step-audio-unified-understanding-and</guid>
    </item>
    <item>
      <title>SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?</title>
      <link>https://paperswithcode.com/paper/swe-lancer-can-frontier-llms-earn-1-million</link>
      <description><![CDATA[We introduce SWE-Lancer, a benchmark of over 1, 400 freelance software engineering tasks from Upwork, valued at \$1 million USD total in real-world payouts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/swe-lancer-can-frontier-llms-earn-1-million</guid>
    </item>
    <item>
      <title>OmniParser for Pure Vision Based GUI Agent</title>
      <link>https://paperswithcode.com/paper/omniparser-for-pure-vision-based-gui-agent</link>
      <description><![CDATA[The recent success of large vision language models shows great potential in driving the agent system operating on user interfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omniparser-for-pure-vision-based-gui-agent</guid>
    </item>
    <item>
      <title>Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</title>
      <link>https://paperswithcode.com/paper/step-video-t2v-technical-report-the-practice</link>
      <description><![CDATA[We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained model with 30B parameters and the ability to generate videos up to 204 frames in length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/step-video-t2v-technical-report-the-practice</guid>
    </item>
    <item>
      <title>PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation</title>
      <link>https://paperswithcode.com/paper/pike-rag-specialized-knowledge-and-rationale</link>
      <description><![CDATA[Despite notable advancements in Retrieval-Augmented Generation (RAG) systems that expand large language model (LLM) capabilities through external retrieval, these systems often struggle to meet the complex and diverse needs of real-world industrial applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pike-rag-specialized-knowledge-and-rationale</guid>
    </item>
    <item>
      <title>CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction</title>
      <link>https://paperswithcode.com/paper/codei-o-condensing-reasoning-patterns-via</link>
      <description><![CDATA[Reasoning is a fundamental capability of Large Language Models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codei-o-condensing-reasoning-patterns-via</guid>
    </item>
    <item>
      <title>Data Formulator 2: Iteratively Creating Rich Visualizations with AI</title>
      <link>https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</link>
      <description><![CDATA[To create rich visualizations, data analysts often need to iterate back and forth among data processing and chart specification to achieve their goals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</guid>
    </item>
    <item>
      <title>OSUM: Advancing Open Speech Understanding Models with Limited Resources in Academia</title>
      <link>https://paperswithcode.com/paper/osum-advancing-open-speech-understanding</link>
      <description><![CDATA[Large Language Models (LLMs) have made significant progress in various downstream tasks, inspiring the development of Speech Understanding Language Models (SULMs) to enable comprehensive speech-based interactions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/osum-advancing-open-speech-understanding</guid>
    </item>
    <item>
      <title>Magic 1-For-1: Generating One Minute Video Clips within One Minute</title>
      <link>https://paperswithcode.com/paper/magic-1-for-1-generating-one-minute-video</link>
      <description><![CDATA[The key idea is simple: factorize the text-to-video generation task into two separate easier tasks for diffusion step distillation, namely text-to-image generation and image-to-video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magic-1-for-1-generating-one-minute-video</guid>
    </item>
    <item>
      <title>Zep: A Temporal Knowledge Graph Architecture for Agent Memory</title>
      <link>https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</link>
      <description><![CDATA[We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</guid>
    </item>
    <item>
      <title>Light-A-Video: Training-free Video Relighting via Progressive Light Fusion</title>
      <link>https://paperswithcode.com/paper/light-a-video-training-free-video-relighting</link>
      <description><![CDATA[Second, leveraging the physical principle of light transport independence, we apply linear blending between the source video's appearance and the relighted appearance, using a Progressive Light Fusion (PLF) strategy to ensure smooth temporal transitions in illumination.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/light-a-video-training-free-video-relighting</guid>
    </item>
    <item>
      <title>HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation</title>
      <link>https://paperswithcode.com/paper/healthgpt-a-medical-large-vision-language</link>
      <description><![CDATA[To effectively learn the HealthGPT, we devise a comprehensive medical domain-specific comprehension and generation dataset called VL-Health.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/healthgpt-a-medical-large-vision-language</guid>
    </item>
    <item>
      <title>Flaming-hot Initiation with Regular Execution Sampling for Large Language Models</title>
      <link>https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</link>
      <description><![CDATA[Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</guid>
    </item>
    <item>
      <title>KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for Graph-RAG</title>
      <link>https://paperswithcode.com/paper/ket-rag-a-cost-efficient-multi-granular</link>
      <description><![CDATA[To ensure a good result accuracy while reducing the indexing cost, we propose KET-RAG, a multi-granular indexing framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ket-rag-a-cost-efficient-multi-granular</guid>
    </item>
    <item>
      <title>Diffusion Models without Classifier-free Guidance</title>
      <link>https://paperswithcode.com/paper/diffusion-models-without-classifier-free-1</link>
      <description><![CDATA[This paper presents Model-guidance (MG), a novel objective for training diffusion model that addresses and removes of the commonly used Classifier-free guidance (CFG).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-without-classifier-free-1</guid>
    </item>
    <item>
      <title>Cut Your Losses in Large-Vocabulary Language Models</title>
      <link>https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</link>
      <description><![CDATA[We implement a custom kernel that performs the matrix multiplications and the log-sum-exp reduction over the vocabulary in flash memory, making global memory consumption for the cross-entropy computation negligible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</guid>
    </item>
    <item>
      <title>Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback</title>
      <link>https://paperswithcode.com/paper/align-anything-training-all-modality-models</link>
      <description><![CDATA[In this work, we make the first attempt to fine-tune all-modality models (i. e. input and output with any modality, also named any-to-any models) using human preference data across all modalities (including text, image, audio, and video), ensuring its behavior aligns with human intentions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/align-anything-training-all-modality-models</guid>
    </item>
    <item>
      <title>Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models</title>
      <link>https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</link>
      <description><![CDATA[To address these challenges, we introduce a system that can jointly optimize distributed execution and gradient checkpointing plans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</guid>
    </item>
    <item>
      <title>Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment</title>
      <link>https://paperswithcode.com/paper/ola-pushing-the-frontiers-of-omni-modal</link>
      <description><![CDATA[Our training pipeline begins with the most distinct modalities: image and text, then gradually expands the skill sets of the model using speech data that connects language and audio knowledge, and video data that connects all modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ola-pushing-the-frontiers-of-omni-modal</guid>
    </item>
    <item>
      <title>FinRL-DeepSeek: LLM-Infused Risk-Sensitive Reinforcement Learning for Trading Agents</title>
      <link>https://paperswithcode.com/paper/finrl-deepseek-llm-infused-risk-sensitive</link>
      <description><![CDATA[This paper presents a novel risk-sensitive trading agent combining reinforcement learning and large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/finrl-deepseek-llm-infused-risk-sensitive</guid>
    </item>
  </channel>
</rss>
