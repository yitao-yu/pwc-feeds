<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 09 Dec 2022 21:07:02 +0000</lastBuildDate>
    <item>
      <title>Images Speak in Images: A Generalist Painter for In-Context Visual Learning</title>
      <link>https://paperswithcode.com/paper/images-speak-in-images-a-generalist-painter</link>
      <description><![CDATA[In this work, we present Painter, a generalist model which addresses these obstacles with an "image"-centric solution, that is, to redefine the output of core vision tasks as images, and specify task prompts as also images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/images-speak-in-images-a-generalist-painter</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>DiffusionInst: Diffusion Model for Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/diffusioninst-diffusion-model-for-instance</link>
      <description><![CDATA[This paper proposes DiffusionInst, a novel framework that represents instances as instance-aware filters and formulates instance segmentation as a noise-to-filter denoising process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusioninst-diffusion-model-for-instance</guid>
    </item>
    <item>
      <title>Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model</title>
      <link>https://paperswithcode.com/paper/zero-shot-image-restoration-using-denoising</link>
      <description><![CDATA[Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-image-restoration-using-denoising</guid>
    </item>
    <item>
      <title>SimVTP: Simple Video Text Pre-training with Masked Autoencoders</title>
      <link>https://paperswithcode.com/paper/simvtp-simple-video-text-pre-training-with</link>
      <description><![CDATA[This paper presents SimVTP: a Simple Video-Text Pretraining framework via masked autoencoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simvtp-simple-video-text-pre-training-with</guid>
    </item>
    <item>
      <title>InternVideo: General Video Foundation Models via Generative and Discriminative Learning</title>
      <link>https://paperswithcode.com/paper/internvideo-general-video-foundation-models</link>
      <description><![CDATA[Specifically, InternVideo efficiently explores masked video modeling and video-language contrastive learning as the pretraining objectives, and selectively coordinates video representations of these two complementary frameworks in a learnable manner to boost various video applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internvideo-general-video-foundation-models</guid>
    </item>
    <item>
      <title>Melody transcription via generative pre-training</title>
      <link>https://paperswithcode.com/paper/melody-transcription-via-generative-pre</link>
      <description><![CDATA[The combination of generative pre-training and a new dataset for this task results in $77$% stronger performance on melody transcription relative to the strongest available baseline.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/melody-transcription-via-generative-pre</guid>
    </item>
    <item>
      <title>EVA: Exploring the Limits of Masked Visual Representation Learning at Scale</title>
      <link>https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</link>
      <description><![CDATA[We launch EVA, a vision-centric foundation model to explore the limits of visual representation at scale using only publicly accessible data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</guid>
    </item>
    <item>
      <title>DI-engine</title>
      <link>https://github.com/opendilab/DI-engine</link>
      <description><![CDATA[OpenDILab Decision AI Engine]]></description>
      <guid isPermaLink="true">https://github.com/opendilab/DI-engine</guid>
    </item>
    <item>
      <title>ExtremeBERT: A Toolkit for Accelerating Pretraining of Customized BERT</title>
      <link>https://paperswithcode.com/paper/extremebert-a-toolkit-for-accelerating</link>
      <description><![CDATA[In this paper, we present ExtremeBERT, a toolkit for accelerating and customizing BERT pretraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extremebert-a-toolkit-for-accelerating</guid>
    </item>
    <item>
      <title>ACE: Cooperative Multi-agent Q-learning with Bidirectional Action-Dependency</title>
      <link>https://paperswithcode.com/paper/ace-cooperative-multi-agent-q-learning-with</link>
      <description><![CDATA[In the learning phase, each agent minimizes the TD error that is dependent on how the subsequent agents have reacted to their chosen action.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ace-cooperative-multi-agent-q-learning-with</guid>
    </item>
    <item>
      <title>Compressing Volumetric Radiance Fields to 1 MB</title>
      <link>https://paperswithcode.com/paper/compressing-volumetric-radiance-fields-to-1</link>
      <description><![CDATA[Approximating radiance fields with volumetric grids is one of promising directions for improving NeRF, represented by methods like Plenoxels and DVGO, which achieve super-fast training convergence and real-time rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compressing-volumetric-radiance-fields-to-1</guid>
    </item>
    <item>
      <title>Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation</title>
      <link>https://paperswithcode.com/paper/score-jacobian-chaining-lifting-pretrained-2d</link>
      <description><![CDATA[We propose to apply chain rule on the learned gradients, and back-propagate the score of a diffusion model through the Jacobian of a differentiable renderer, which we instantiate to be a voxel radiance field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/score-jacobian-chaining-lifting-pretrained-2d</guid>
    </item>
    <item>
      <title>Training language models to follow instructions with human feedback</title>
      <link>https://paperswithcode.com/paper/training-language-models-to-follow</link>
      <description><![CDATA[In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-language-models-to-follow</guid>
    </item>
    <item>
      <title>Unifying Vision, Text, and Layout for Universal Document Processing</title>
      <link>https://paperswithcode.com/paper/unifying-vision-text-and-layout-for-universal</link>
      <description><![CDATA[UDOP leverages the spatial correlation between textual content and document image to model image, text, and layout modalities with one uniform representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unifying-vision-text-and-layout-for-universal</guid>
    </item>
    <item>
      <title>Self-Supervised Correspondence Estimation via Multiview Registration</title>
      <link>https://paperswithcode.com/paper/self-supervised-correspondence-estimation-via</link>
      <description><![CDATA[To address this, we propose a self-supervised approach for correspondence estimation that learns from multiview consistency in short RGB-D video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-correspondence-estimation-via</guid>
    </item>
    <item>
      <title>DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/diffusionbert-improving-generative-masked</link>
      <description><![CDATA[We present DiffusionBERT, a new generative masked language model based on discrete diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusionbert-improving-generative-masked</guid>
    </item>
    <item>
      <title>OpenFE: Automated Feature Generation beyond Expert-level Performance</title>
      <link>https://paperswithcode.com/paper/openfe-automated-feature-generation-beyond</link>
      <description><![CDATA[The major challenge in automated feature generation is to efficiently and accurately identify useful features from a vast pool of candidate features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openfe-automated-feature-generation-beyond</guid>
    </item>
    <item>
      <title>SDM: Spatial Diffusion Model for Large Hole Image Inpainting</title>
      <link>https://paperswithcode.com/paper/sdm-spatial-diffusion-model-for-large-hole</link>
      <description><![CDATA[Generative adversarial networks (GANs) have made great success in image inpainting yet still have difficulties tackling large missing regions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdm-spatial-diffusion-model-for-large-hole</guid>
    </item>
    <item>
      <title>GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images</title>
      <link>https://paperswithcode.com/paper/get3d-a-generative-model-of-high-quality-3d</link>
      <description><![CDATA[As several industries are moving towards modeling massive 3D virtual worlds, the need for content creation tools that can scale in terms of the quantity, quality, and diversity of 3D content is becoming evident.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/get3d-a-generative-model-of-high-quality-3d</guid>
    </item>
  </channel>
</rss>
