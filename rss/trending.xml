<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 07 Apr 2024 21:07:48 +0000</lastBuildDate>
    <item>
      <title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title>
      <link>https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</link>
      <description><![CDATA[We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine "next-scale prediction" or "next-resolution prediction", diverging from the standard raster-scan "next-token prediction".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</guid>
    </item>
    <item>
      <title>InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/instantstyle-free-lunch-towards-style</link>
      <description><![CDATA[Tuning-free diffusion-based models have demonstrated significant potential in the realm of image personalization and customization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantstyle-free-lunch-towards-style</guid>
    </item>
    <item>
      <title>ReFT: Representation Finetuning for Language Models</title>
      <link>https://paperswithcode.com/paper/reft-representation-finetuning-for-language</link>
      <description><![CDATA[LoReFT is a drop-in replacement for existing PEFTs and learns interventions that are 10x-50x more parameter-efficient than prior state-of-the-art PEFTs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reft-representation-finetuning-for-language</guid>
    </item>
    <item>
      <title>VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild</title>
      <link>https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</link>
      <description><![CDATA[We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</guid>
    </item>
    <item>
      <title>AIOS: LLM Agent Operating System</title>
      <link>https://paperswithcode.com/paper/llm-agent-operating-system</link>
      <description><![CDATA[Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS) as the brain of the OS, enabling an operating system "with soul" -- an important step towards AGI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-agent-operating-system</guid>
    </item>
    <item>
      <title>Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models</title>
      <link>https://paperswithcode.com/paper/mini-gemini-mining-the-potential-of-multi</link>
      <description><![CDATA[We try to narrow the gap by mining the potential of VLMs for better performance and any-to-any workflow from three aspects, i. e., high-resolution visual tokens, high-quality data, and VLM-guided generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mini-gemini-mining-the-potential-of-multi</guid>
    </item>
    <item>
      <title>AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation</title>
      <link>https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</link>
      <description><![CDATA[In this study, we propose AniPortrait, a novel framework for generating high-quality animation driven by audio and a reference portrait image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</guid>
    </item>
    <item>
      <title>BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion</title>
      <link>https://paperswithcode.com/paper/brushnet-a-plug-and-play-image-inpainting</link>
      <description><![CDATA[Image inpainting, the process of restoring corrupted images, has seen significant advancements with the advent of diffusion models (DMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/brushnet-a-plug-and-play-image-inpainting</guid>
    </item>
    <item>
      <title>mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding</title>
      <link>https://paperswithcode.com/paper/mplug-docowl-1-5-unified-structure-learning</link>
      <description><![CDATA[In this work, we emphasize the importance of structure information in Visual Document Understanding and propose the Unified Structure Learning to boost the performance of MLLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mplug-docowl-1-5-unified-structure-learning</guid>
    </item>
    <item>
      <title>CameraCtrl: Enabling Camera Control for Text-to-Video Generation</title>
      <link>https://paperswithcode.com/paper/cameractrl-enabling-camera-control-for-text</link>
      <description><![CDATA[Controllability plays a crucial role in video generation since it allows users to create desired content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cameractrl-enabling-camera-control-for-text</guid>
    </item>
    <item>
      <title>Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance</title>
      <link>https://paperswithcode.com/paper/champ-controllable-and-consistent-human-image</link>
      <description><![CDATA[In this study, we introduce a methodology for human image animation by leveraging a 3D human parametric model within a latent diffusion framework to enhance shape alignment and motion guidance in curernt human generative techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/champ-controllable-and-consistent-human-image</guid>
    </item>
    <item>
      <title>Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/cross-attention-makes-inference-cumbersome-in</link>
      <description><![CDATA[This study explores the role of cross-attention during inference in text-conditional diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-attention-makes-inference-cumbersome-in</guid>
    </item>
    <item>
      <title>Evalverse: Unified and Accessible Library for Large Language Model Evaluation</title>
      <link>https://paperswithcode.com/paper/evalverse-unified-and-accessible-library-for</link>
      <description><![CDATA[This paper introduces Evalverse, a novel library that streamlines the evaluation of Large Language Models (LLMs) by unifying disparate evaluation tools into a single, user-friendly framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evalverse-unified-and-accessible-library-for</guid>
    </item>
    <item>
      <title>Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians</title>
      <link>https://paperswithcode.com/paper/octree-gs-towards-consistent-real-time</link>
      <description><![CDATA[The recent 3D Gaussian splatting (3D-GS) has shown remarkable rendering fidelity and efficiency compared to NeRF-based neural scene representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/octree-gs-towards-consistent-real-time</guid>
    </item>
    <item>
      <title>Learning Inclusion Matching for Animation Paint Bucket Colorization</title>
      <link>https://paperswithcode.com/paper/learning-inclusion-matching-for-animation</link>
      <description><![CDATA[In this work, we introduce a new learning-based inclusion matching pipeline, which directs the network to comprehend the inclusion relationships between segments rather than relying solely on direct visual correspondences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-inclusion-matching-for-animation</guid>
    </item>
    <item>
      <title>Agent Lumos: Unified and Modular Training for Open-Source Language Agents</title>
      <link>https://paperswithcode.com/paper/lumos-learning-agents-with-unified-data</link>
      <description><![CDATA[To foster generalizable agent learning, we collect large-scale, unified, and high-quality training annotations derived from diverse ground-truth reasoning rationales across various complex interactive tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lumos-learning-agents-with-unified-data</guid>
    </item>
    <item>
      <title>FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects</title>
      <link>https://paperswithcode.com/paper/foundationpose-unified-6d-pose-estimation-and</link>
      <description><![CDATA[We present FoundationPose, a unified foundation model for 6D object pose estimation and tracking, supporting both model-based and model-free setups.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundationpose-unified-6d-pose-estimation-and</guid>
    </item>
    <item>
      <title>Gaussian Head Avatar: Ultra High-fidelity Head Avatar via Dynamic Gaussians</title>
      <link>https://paperswithcode.com/paper/gaussian-head-avatar-ultra-high-fidelity-head</link>
      <description><![CDATA[Creating high-fidelity 3D head avatars has always been a research hotspot, but there remains a great challenge under lightweight sparse view setups.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaussian-head-avatar-ultra-high-fidelity-head</guid>
    </item>
    <item>
      <title>T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy</title>
      <link>https://paperswithcode.com/paper/t-rex2-towards-generic-object-detection-via</link>
      <description><![CDATA[Recognizing the complementary strengths and weaknesses of both text and visual prompts, we introduce T-Rex2 that synergizes both prompts within a single model through contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t-rex2-towards-generic-object-detection-via</guid>
    </item>
    <item>
      <title>UniDepth: Universal Monocular Metric Depth Estimation</title>
      <link>https://paperswithcode.com/paper/unidepth-universal-monocular-metric-depth</link>
      <description><![CDATA[However, the remarkable accuracy of recent MMDE methods is confined to their training domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unidepth-universal-monocular-metric-depth</guid>
    </item>
  </channel>
</rss>
