<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 15 Feb 2025 09:14:59 +0000</lastBuildDate>
    <item>
      <title>Data Formulator 2: Iteratively Creating Rich Visualizations with AI</title>
      <link>https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</link>
      <description><![CDATA[To create rich visualizations, data analysts often need to iterate back and forth among data processing and chart specification to achieve their goals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</guid>
    </item>
    <item>
      <title>LLM4Decompile: Decompiling Binary Code with Large Language Models</title>
      <link>https://paperswithcode.com/paper/llm4decompile-decompiling-binary-code-with</link>
      <description><![CDATA[Decompilation aims to convert binary code to high-level source code, but traditional tools like Ghidra often produce results that are difficult to read and execute.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm4decompile-decompiling-binary-code-with</guid>
    </item>
    <item>
      <title>Cut Your Losses in Large-Vocabulary Language Models</title>
      <link>https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</link>
      <description><![CDATA[We implement a custom kernel that performs the matrix multiplications and the log-sum-exp reduction over the vocabulary in flash memory, making global memory consumption for the cross-entropy computation negligible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</guid>
    </item>
    <item>
      <title>Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach</title>
      <link>https://paperswithcode.com/paper/scaling-up-test-time-compute-with-latent</link>
      <description><![CDATA[We scale a proof-of-concept model to 3. 5 billion parameters and 800 billion tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-up-test-time-compute-with-latent</guid>
    </item>
    <item>
      <title>FireRedASR: Open-Source Industrial-Grade Mandarin Speech Recognition Models from Encoder-Decoder to LLM Integration</title>
      <link>https://paperswithcode.com/paper/fireredasr-open-source-industrial-grade</link>
      <description><![CDATA[We present FireRedASR, a family of large-scale automatic speech recognition (ASR) models for Mandarin, designed to meet diverse requirements in superior performance and optimal efficiency across various applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fireredasr-open-source-industrial-grade</guid>
    </item>
    <item>
      <title>Flaming-hot Initiation with Regular Execution Sampling for Large Language Models</title>
      <link>https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</link>
      <description><![CDATA[Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</guid>
    </item>
    <item>
      <title>s1: Simple test-time scaling</title>
      <link>https://paperswithcode.com/paper/s1-simple-test-time-scaling</link>
      <description><![CDATA[After supervised finetuning the Qwen2. 5-32B-Instruct language model on s1K and equipping it with budget forcing, our model s1-32B exceeds o1-preview on competition math questions by up to 27% (MATH and AIME24).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s1-simple-test-time-scaling</guid>
    </item>
    <item>
      <title>rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking</title>
      <link>https://paperswithcode.com/paper/rstar-math-small-llms-can-master-math</link>
      <description><![CDATA[We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rstar-math-small-llms-can-master-math</guid>
    </item>
    <item>
      <title>Meta Audiobox Aesthetics: Unified Automatic Quality Assessment for Speech, Music, and Sound</title>
      <link>https://paperswithcode.com/paper/meta-audiobox-aesthetics-unified-automatic</link>
      <description><![CDATA[The quantification of audio aesthetics remains a complex challenge in audio processing, primarily due to its subjective nature, which is influenced by human perception and cultural context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-audiobox-aesthetics-unified-automatic</guid>
    </item>
    <item>
      <title>MedRAX: Medical Reasoning Agent for Chest X-ray</title>
      <link>https://paperswithcode.com/paper/medrax-medical-reasoning-agent-for-chest-x</link>
      <description><![CDATA[Chest X-rays (CXRs) play an integral role in driving critical decisions in disease management and patient care.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medrax-medical-reasoning-agent-for-chest-x</guid>
    </item>
    <item>
      <title>DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</link>
      <description><![CDATA[We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</guid>
    </item>
    <item>
      <title>Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research</title>
      <link>https://paperswithcode.com/paper/agentic-reasoning-reasoning-llms-with-tools</link>
      <description><![CDATA[We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentic-reasoning-reasoning-llms-with-tools</guid>
    </item>
    <item>
      <title>Accelerating Data Processing and Benchmarking of AI Models for Pathology</title>
      <link>https://paperswithcode.com/paper/accelerating-data-processing-and-benchmarking</link>
      <description><![CDATA[Advances in foundation modeling have reshaped computational pathology.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-data-processing-and-benchmarking</guid>
    </item>
    <item>
      <title>FlashVideo:Flowing Fidelity to Detail for Efficient High-Resolution Video Generation</title>
      <link>https://paperswithcode.com/paper/flashvideo-flowing-fidelity-to-detail-for</link>
      <description><![CDATA[DiT diffusion models have achieved great success in text-to-video generation, leveraging their scalability in model capacity and data scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flashvideo-flowing-fidelity-to-detail-for</guid>
    </item>
    <item>
      <title>Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback</title>
      <link>https://paperswithcode.com/paper/align-anything-training-all-modality-models</link>
      <description><![CDATA[In this work, we make the first attempt to fine-tune all-modality models (i. e. input and output with any modality, also named any-to-any models) using human preference data across all modalities (including text, image, audio, and video), ensuring its behavior aligns with human intentions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/align-anything-training-all-modality-models</guid>
    </item>
    <item>
      <title>LIMO: Less is More for Reasoning</title>
      <link>https://paperswithcode.com/paper/limo-less-is-more-for-reasoning</link>
      <description><![CDATA[While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (>100, 000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/limo-less-is-more-for-reasoning</guid>
    </item>
    <item>
      <title>On-device Sora: Enabling Diffusion-Based Text-to-Video Generation for Mobile Devices</title>
      <link>https://paperswithcode.com/paper/on-device-sora-enabling-diffusion-based-text</link>
      <description><![CDATA[We present On-device Sora, a first pioneering solution for diffusion-based on-device text-to-video generation that operates efficiently on smartphone-grade devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-device-sora-enabling-diffusion-based-text</guid>
    </item>
    <item>
      <title>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</link>
      <description><![CDATA[We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</guid>
    </item>
    <item>
      <title>On the Emergence of Thinking in LLMs I: Searching for the Right Intuition</title>
      <link>https://paperswithcode.com/paper/on-the-emergence-of-thinking-in-llms-i</link>
      <description><![CDATA[Lastly, we propose a theory as to why RLSP search strategy is more suitable for LLMs inspired by a remarkable result that says CoT provably increases computational power of LLMs, which grows as the number of steps in CoT \cite{li2024chain, merrill2023expresssive}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-emergence-of-thinking-in-llms-i</guid>
    </item>
    <item>
      <title>Aligning Language Models with Offline Learning from Human Feedback</title>
      <link>https://paperswithcode.com/paper/aligning-language-models-with-offline</link>
      <description><![CDATA[Learning from human preferences is crucial for language models (LMs) to effectively cater to human needs and societal values.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-language-models-with-offline</guid>
    </item>
  </channel>
</rss>
