<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 02 Feb 2025 09:13:28 +0000</lastBuildDate>
    <item>
      <title>Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling</title>
      <link>https://paperswithcode.com/paper/janus-pro-unified-multimodal-understanding</link>
      <description><![CDATA[In this work, we introduce Janus-Pro, an advanced version of the previous work Janus.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/janus-pro-unified-multimodal-understanding</guid>
    </item>
    <item>
      <title>DeepSeek LLM: Scaling Open-Source Language Models with Longtermism</title>
      <link>https://paperswithcode.com/paper/deepseek-llm-scaling-open-source-language</link>
      <description><![CDATA[The rapid development of open-source large language models (LLMs) has been truly remarkable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-llm-scaling-open-source-language</guid>
    </item>
    <item>
      <title>DeepSeek-V3 Technical Report</title>
      <link>https://paperswithcode.com/paper/deepseek-v3-technical-report</link>
      <description><![CDATA[We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-v3-technical-report</guid>
    </item>
    <item>
      <title>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</link>
      <description><![CDATA[We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</guid>
    </item>
    <item>
      <title>DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</link>
      <description><![CDATA[We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</guid>
    </item>
    <item>
      <title>DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</title>
      <link>https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</link>
      <description><![CDATA[Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</guid>
    </item>
    <item>
      <title>DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence</title>
      <link>https://paperswithcode.com/paper/deepseek-coder-v2-breaking-the-barrier-of</link>
      <description><![CDATA[Through this continued pre-training, DeepSeek-Coder-V2 substantially enhances the coding and mathematical reasoning capabilities of DeepSeek-V2, while maintaining comparable performance in general language tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-coder-v2-breaking-the-barrier-of</guid>
    </item>
    <item>
      <title>Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation</title>
      <link>https://paperswithcode.com/paper/hunyuan3d-2-0-scaling-diffusion-models-for</link>
      <description><![CDATA[This system includes two foundation components: a large-scale shape generation model -- Hunyuan3D-DiT, and a large-scale texture synthesis model -- Hunyuan3D-Paint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuan3d-2-0-scaling-diffusion-models-for</guid>
    </item>
    <item>
      <title>DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence</title>
      <link>https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</link>
      <description><![CDATA[The rapid development of large language models has revolutionized code intelligence in software development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</guid>
    </item>
    <item>
      <title>DeepSeek-VL: Towards Real-World Vision-Language Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl-towards-real-world-vision</link>
      <description><![CDATA[The DeepSeek-VL family (both 1. 3B and 7B models) showcases superior user experiences as a vision-language chatbot in real-world applications, achieving state-of-the-art or competitive performance across a wide range of visual-language benchmarks at the same model size while maintaining robust performance on language-centric benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl-towards-real-world-vision</guid>
    </item>
    <item>
      <title>UI-TARS: Pioneering Automated GUI Interaction with Native Agents</title>
      <link>https://paperswithcode.com/paper/ui-tars-pioneering-automated-gui-interaction</link>
      <description><![CDATA[This paper introduces UI-TARS, a native GUI agent model that solely perceives the screenshots as input and performs human-like interactions (e. g., keyboard and mouse operations).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ui-tars-pioneering-automated-gui-interaction</guid>
    </item>
    <item>
      <title>DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior</title>
      <link>https://paperswithcode.com/paper/dreamcraft3d-hierarchical-3d-generation-with</link>
      <description><![CDATA[The score distillation from this 3D-aware diffusion prior provides view-consistent guidance for the scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamcraft3d-hierarchical-3d-generation-with</guid>
    </item>
    <item>
      <title>Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models</title>
      <link>https://paperswithcode.com/paper/let-the-expert-stick-to-his-last-expert</link>
      <description><![CDATA[In this work, we study the PEFT method for LLMs with the Mixture-of-Experts (MoE) architecture and the contents of this work are mainly threefold: (1) We investigate the dispersion degree of the activated experts in customized tasks, and found that the routing distribution for a specific task tends to be highly concentrated, while the distribution of activated experts varies significantly across different tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-the-expert-stick-to-his-last-expert</guid>
    </item>
    <item>
      <title>Flaming-hot Initiation with Regular Execution Sampling for Large Language Models</title>
      <link>https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</link>
      <description><![CDATA[Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</guid>
    </item>
    <item>
      <title>Stable Flow: Vital Layers for Training-Free Image Editing</title>
      <link>https://paperswithcode.com/paper/stable-flow-vital-layers-for-training-free</link>
      <description><![CDATA[The main challenge is that, unlike the UNet-based models, DiT lacks a coarse-to-fine synthesis structure, making it unclear in which layers to perform the injection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stable-flow-vital-layers-for-training-free</guid>
    </item>
    <item>
      <title>Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution</title>
      <link>https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</link>
      <description><![CDATA[We present the Qwen2-VL Series, an advanced upgrade of the previous Qwen-VL models that redefines the conventional predetermined-resolution approach in visual processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</guid>
    </item>
    <item>
      <title>DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</title>
      <link>https://paperswithcode.com/paper/deepseek-v2-a-strong-economical-and-efficient</link>
      <description><![CDATA[MLA guarantees efficient inference through significantly compressing the Key-Value (KV) cache into a latent vector, while DeepSeekMoE enables training strong models at an economical cost through sparse computation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-v2-a-strong-economical-and-efficient</guid>
    </item>
    <item>
      <title>PaSa: An LLM Agent for Comprehensive Academic Paper Search</title>
      <link>https://paperswithcode.com/paper/pasa-an-llm-agent-for-comprehensive-academic</link>
      <description><![CDATA[Notably, PaSa-7B surpasses the best Google-based baseline, Google with GPT-4o, by 37. 78% in recall@20 and 39. 90% in recall@50.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pasa-an-llm-agent-for-comprehensive-academic</guid>
    </item>
    <item>
      <title>Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step</title>
      <link>https://paperswithcode.com/paper/can-we-generate-images-with-cot-let-s-verify</link>
      <description><![CDATA[We hope our study provides unique insights and paves a new path for integrating CoT reasoning with autoregressive image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-we-generate-images-with-cot-let-s-verify</guid>
    </item>
    <item>
      <title>A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-of-graph-retrieval-augmented</link>
      <description><![CDATA[Large language models (LLMs) have demonstrated remarkable capabilities in a wide range of tasks, yet their application to specialized domains remains challenging due to the need for deep expertise.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-graph-retrieval-augmented</guid>
    </item>
  </channel>
</rss>
