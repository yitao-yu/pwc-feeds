<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 21 Jul 2025 21:11:26 +0000</lastBuildDate>
    <item>
      <title>PhysX: Physical-Grounded 3D Asset Generation</title>
      <link>https://paperswithcode.com/paper/physx-physical-grounded-3d-asset-generation</link>
      <description><![CDATA[3D modeling is moving from virtual to physical.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/physx-physical-grounded-3d-asset-generation</guid>
    </item>
    <item>
      <title>WebSailor: Navigating Super-human Reasoning for Web Agent</title>
      <link>https://paperswithcode.com/paper/websailor-navigating-super-human-reasoning</link>
      <description><![CDATA[Transcending human cognitive limitations represents a critical frontier in LLM training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/websailor-navigating-super-human-reasoning</guid>
    </item>
    <item>
      <title>REAL: Benchmarking Autonomous Agents on Deterministic Simulations of Real Websites</title>
      <link>https://paperswithcode.com/paper/real-benchmarking-autonomous-agents-on</link>
      <description><![CDATA[We introduce REAL, a benchmark and framework for multi-turn agent evaluations on deterministic simulations of real-world websites.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-benchmarking-autonomous-agents-on</guid>
    </item>
    <item>
      <title>IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System</title>
      <link>https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</link>
      <description><![CDATA[Recently, large language model (LLM) based text-to-speech (TTS) systems have gradually become the mainstream in the industry due to their high naturalness and powerful zero-shot voice cloning capabilities. Here, we introduce the IndexTTS system, which is mainly based on the XTTS and Tortoise model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</guid>
    </item>
    <item>
      <title>Let Them Talk: Audio-Driven Multi-Person Conversational Video Generation</title>
      <link>https://paperswithcode.com/paper/let-them-talk-audio-driven-multi-person</link>
      <description><![CDATA[Audio-driven human animation methods, such as talking head and talking body generation, have made remarkable progress in generating synchronized facial movements and appealing visual quality videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-them-talk-audio-driven-multi-person</guid>
    </item>
    <item>
      <title>No time to train! Training-Free Reference-Based Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/no-time-to-train-training-free-reference</link>
      <description><![CDATA[The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/no-time-to-train-training-free-reference</guid>
    </item>
    <item>
      <title>Zep: A Temporal Knowledge Graph Architecture for Agent Memory</title>
      <link>https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</link>
      <description><![CDATA[We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</guid>
    </item>
    <item>
      <title>Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory</title>
      <link>https://paperswithcode.com/paper/mathematical-introduction-to-deep-learning</link>
      <description><![CDATA[This book aims to provide an introduction to the topic of deep learning algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mathematical-introduction-to-deep-learning</guid>
    </item>
    <item>
      <title>CGVQM+D: Computer Graphics Video Quality Metric and Dataset</title>
      <link>https://paperswithcode.com/paper/cgvqm-d-computer-graphics-video-quality</link>
      <description><![CDATA[While existing video and image quality datasets have extensively studied natural videos and traditional distortions, the perception of synthetic content and modern rendering artifacts remains underexplored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cgvqm-d-computer-graphics-video-quality</guid>
    </item>
    <item>
      <title>MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm</title>
      <link>https://paperswithcode.com/paper/monkeyocr-document-parsing-with-a-structure</link>
      <description><![CDATA[We introduce MonkeyOCR, a vision-language model for document parsing that advances the state of the art by leveraging a Structure-Recognition-Relation (SRR) triplet paradigm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monkeyocr-document-parsing-with-a-structure</guid>
    </item>
    <item>
      <title>Practical Efficiency of Muon for Pretraining</title>
      <link>https://paperswithcode.com/paper/practical-efficiency-of-muon-for-pretraining</link>
      <description><![CDATA[We demonstrate that Muon, the simplest instantiation of a second-order optimizer, explicitly expands the Pareto frontier over AdamW on the compute-time tradeoff.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/practical-efficiency-of-muon-for-pretraining</guid>
    </item>
    <item>
      <title>Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities</title>
      <link>https://paperswithcode.com/paper/audio-flamingo-a-novel-audio-language-model</link>
      <description><![CDATA[Augmenting large language models (LLMs) to understand audio -- including non-speech sounds and non-verbal speech -- is critically important for diverse real-world applications of LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audio-flamingo-a-novel-audio-language-model</guid>
    </item>
    <item>
      <title>TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis</title>
      <link>https://paperswithcode.com/paper/tcsinger-2-customizable-multilingual-zero</link>
      <description><![CDATA[To overcome these challenges, we introduce TCSinger 2, a multi-task multilingual zero-shot SVS model with style transfer and style control based on various prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tcsinger-2-customizable-multilingual-zero</guid>
    </item>
    <item>
      <title>TradingAgents: Multi-Agents LLM Financial Trading Framework</title>
      <link>https://paperswithcode.com/paper/tradingagents-multi-agents-llm-financial</link>
      <description><![CDATA[Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tradingagents-multi-agents-llm-financial</guid>
    </item>
    <item>
      <title>ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing</title>
      <link>https://paperswithcode.com/paper/thinksound-chain-of-thought-reasoning-in</link>
      <description><![CDATA[While end-to-end video-to-audio generation has greatly improved, producing high-fidelity audio that authentically captures the nuances of visual content remains challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/thinksound-chain-of-thought-reasoning-in</guid>
    </item>
    <item>
      <title>SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator</title>
      <link>https://paperswithcode.com/paper/sepllm-accelerate-large-language-models-by</link>
      <description><![CDATA[This observation suggests that information of the segments between these separator tokens can be effectively condensed into the separator tokens themselves without significant information loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sepllm-accelerate-large-language-models-by</guid>
    </item>
    <item>
      <title>R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/r1-reward-training-multimodal-reward-model</link>
      <description><![CDATA[Our reward model, R1-Reward, trained using the StableReinforce algorithm on this dataset, significantly improves performance on multimodal reward modeling benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r1-reward-training-multimodal-reward-model</guid>
    </item>
    <item>
      <title>DiC: Rethinking Conv3x3 Designs in Diffusion Models</title>
      <link>https://paperswithcode.com/paper/dic-rethinking-conv3x3-designs-in-diffusion</link>
      <description><![CDATA[Diffusion models have shown exceptional performance in visual generation tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dic-rethinking-conv3x3-designs-in-diffusion</guid>
    </item>
    <item>
      <title>Set You Straight: Auto-Steering Denoising Trajectories to Sidestep Unwanted Concepts</title>
      <link>https://paperswithcode.com/paper/set-you-straight-auto-steering-denoising</link>
      <description><![CDATA[Anchor-free methods risk disrupting sampling trajectories, leading to visual artifacts, while anchor-based methods rely on the heuristic selection of anchor concepts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/set-you-straight-auto-steering-denoising</guid>
    </item>
    <item>
      <title>LTX-Video: Realtime Video Latent Diffusion</title>
      <link>https://paperswithcode.com/paper/ltx-video-realtime-video-latent-diffusion</link>
      <description><![CDATA[To address this, our VAE decoder is tasked with both latent-to-pixel conversion and the final denoising step, producing the clean result directly in pixel space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ltx-video-realtime-video-latent-diffusion</guid>
    </item>
  </channel>
</rss>
