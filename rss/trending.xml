<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 08 Dec 2022 21:07:40 +0000</lastBuildDate>
    <item>
      <title>Images Speak in Images: A Generalist Painter for In-Context Visual Learning</title>
      <link>https://paperswithcode.com/paper/images-speak-in-images-a-generalist-painter</link>
      <description><![CDATA[In this work, we present Painter, a generalist model which addresses these obstacles with an "image"-centric solution, that is, to redefine the output of core vision tasks as images, and specify task prompts as also images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/images-speak-in-images-a-generalist-painter</guid>
    </item>
    <item>
      <title>Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model</title>
      <link>https://paperswithcode.com/paper/zero-shot-image-restoration-using-denoising</link>
      <description><![CDATA[Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-image-restoration-using-denoising</guid>
    </item>
    <item>
      <title>Melody transcription via generative pre-training</title>
      <link>https://paperswithcode.com/paper/melody-transcription-via-generative-pre</link>
      <description><![CDATA[The combination of generative pre-training and a new dataset for this task results in $77$% stronger performance on melody transcription relative to the strongest available baseline.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/melody-transcription-via-generative-pre</guid>
    </item>
    <item>
      <title>ExtremeBERT: A Toolkit for Accelerating Pretraining of Customized BERT</title>
      <link>https://paperswithcode.com/paper/extremebert-a-toolkit-for-accelerating</link>
      <description><![CDATA[In this paper, we present ExtremeBERT, a toolkit for accelerating and customizing BERT pretraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extremebert-a-toolkit-for-accelerating</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation</title>
      <link>https://paperswithcode.com/paper/score-jacobian-chaining-lifting-pretrained-2d</link>
      <description><![CDATA[We propose to apply chain rule on the learned gradients, and back-propagate the score of a diffusion model through the Jacobian of a differentiable renderer, which we instantiate to be a voxel radiance field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/score-jacobian-chaining-lifting-pretrained-2d</guid>
    </item>
    <item>
      <title>GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images</title>
      <link>https://paperswithcode.com/paper/get3d-a-generative-model-of-high-quality-3d</link>
      <description><![CDATA[As several industries are moving towards modeling massive 3D virtual worlds, the need for content creation tools that can scale in terms of the quantity, quality, and diversity of 3D content is becoming evident.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/get3d-a-generative-model-of-high-quality-3d</guid>
    </item>
    <item>
      <title>DI-engine</title>
      <link>https://github.com/opendilab/DI-engine</link>
      <description><![CDATA[OpenDILab Decision AI Engine]]></description>
      <guid isPermaLink="true">https://github.com/opendilab/DI-engine</guid>
    </item>
    <item>
      <title>DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/diffusionbert-improving-generative-masked</link>
      <description><![CDATA[We present DiffusionBERT, a new generative masked language model based on discrete diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusionbert-improving-generative-masked</guid>
    </item>
    <item>
      <title>Compressing Volumetric Radiance Fields to 1 MB</title>
      <link>https://paperswithcode.com/paper/compressing-volumetric-radiance-fields-to-1</link>
      <description><![CDATA[Approximating radiance fields with volumetric grids is one of promising directions for improving NeRF, represented by methods like Plenoxels and DVGO, which achieve super-fast training convergence and real-time rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compressing-volumetric-radiance-fields-to-1</guid>
    </item>
    <item>
      <title>Training language models to follow instructions with human feedback</title>
      <link>https://paperswithcode.com/paper/training-language-models-to-follow</link>
      <description><![CDATA[In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-language-models-to-follow</guid>
    </item>
    <item>
      <title>MIC: Masked Image Consistency for Context-Enhanced Domain Adaptation</title>
      <link>https://paperswithcode.com/paper/mic-masked-image-consistency-for-context</link>
      <description><![CDATA[MIC significantly improves the state-of-the-art performance across the different recognition tasks for synthetic-to-real, day-to-nighttime, and clear-to-adverse-weather UDA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mic-masked-image-consistency-for-context</guid>
    </item>
    <item>
      <title>Video Swin Transformer</title>
      <link>https://paperswithcode.com/paper/video-swin-transformer</link>
      <description><![CDATA[The vision community is witnessing a modeling shift from CNNs to Transformers, where pure Transformer architectures have attained top accuracy on the major video recognition benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-swin-transformer</guid>
    </item>
    <item>
      <title>Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations</title>
      <link>https://paperswithcode.com/paper/triton-an-intermediate-language-and-compiler</link>
      <description><![CDATA[The validation and deployment of novel research ideas in the field of Deep Learning is often limited by the availability of efficient compute kernels for certain basic primitives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triton-an-intermediate-language-and-compiler</guid>
    </item>
    <item>
      <title>ACE: Cooperative Multi-agent Q-learning with Bidirectional Action-Dependency</title>
      <link>https://paperswithcode.com/paper/ace-cooperative-multi-agent-q-learning-with</link>
      <description><![CDATA[In the learning phase, each agent minimizes the TD error that is dependent on how the subsequent agents have reacted to their chosen action.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ace-cooperative-multi-agent-q-learning-with</guid>
    </item>
    <item>
      <title>Robust Speech Recognition via Large-Scale Weak Supervision</title>
      <link>https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale</link>
      <description><![CDATA[We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale</guid>
    </item>
    <item>
      <title>OpenFE: Automated Feature Generation beyond Expert-level Performance</title>
      <link>https://paperswithcode.com/paper/openfe-automated-feature-generation-beyond</link>
      <description><![CDATA[The major challenge in automated feature generation is to efficiently and accurately identify useful features from a vast pool of candidate features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openfe-automated-feature-generation-beyond</guid>
    </item>
    <item>
      <title>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</title>
      <link>https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</link>
      <description><![CDATA[Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</guid>
    </item>
    <item>
      <title>EVA: Exploring the Limits of Masked Visual Representation Learning at Scale</title>
      <link>https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</link>
      <description><![CDATA[We launch EVA, a vision-centric foundation model to explore the limits of visual representation at scale using only publicly accessible data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</guid>
    </item>
    <item>
      <title>TorchScale: Transformers at Scale</title>
      <link>https://paperswithcode.com/paper/torchscale-transformers-at-scale</link>
      <description><![CDATA[Large Transformers have achieved state-of-the-art performance across many tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchscale-transformers-at-scale</guid>
    </item>
  </channel>
</rss>
