<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 21 Jul 2022 21:08:59 +0000</lastBuildDate>
    <item>
      <title>XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model</title>
      <link>https://paperswithcode.com/paper/xmem-long-term-video-object-segmentation-with</link>
      <description><![CDATA[We present XMem, a video object segmentation architecture for long videos with unified feature memory stores inspired by the Atkinson-Shiffrin memory model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xmem-long-term-video-object-segmentation-with</guid>
    </item>
    <item>
      <title>Towards Grand Unification of Object Tracking</title>
      <link>https://paperswithcode.com/paper/towards-grand-unification-of-object-tracking</link>
      <description><![CDATA[We present a unified method, termed Unicorn, that can simultaneously solve four tracking problems (SOT, MOT, VOS, MOTS) with a single network using the same model parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-grand-unification-of-object-tracking</guid>
    </item>
    <item>
      <title>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</title>
      <link>https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</link>
      <description><![CDATA[YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56. 8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</guid>
    </item>
    <item>
      <title>3D Clothed Human Reconstruction in the Wild</title>
      <link>https://paperswithcode.com/paper/3d-clothed-human-reconstruction-in-the-wild</link>
      <description><![CDATA[Although much progress has been made in 3D clothed human reconstruction, most of the existing methods fail to produce robust results from in-the-wild images, which contain diverse human poses and appearances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-clothed-human-reconstruction-in-the-wild</guid>
    </item>
    <item>
      <title>Ivy: Templated Deep Learning for Inter-Framework Portability</title>
      <link>https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</link>
      <description><![CDATA[We introduce Ivy, a templated Deep Learning (DL) framework which abstracts existing DL frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</guid>
    </item>
    <item>
      <title>Tracking Objects as Pixel-wise Distributions</title>
      <link>https://paperswithcode.com/paper/tracking-objects-as-pixel-wise-distributions</link>
      <description><![CDATA[During inference, a pixel-wise association procedure is proposed to recover object connections through frames based on the pixel-wise prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tracking-objects-as-pixel-wise-distributions</guid>
    </item>
    <item>
      <title>CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers</title>
      <link>https://paperswithcode.com/paper/cogvideo-large-scale-pretraining-for-text-to</link>
      <description><![CDATA[Large-scale pretrained transformers have created milestones in text (GPT-3) and text-to-image (DALL-E and CogView) generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cogvideo-large-scale-pretraining-for-text-to</guid>
    </item>
    <item>
      <title>Open High-Resolution Satellite Imagery: The WorldStrat Dataset -- With Application to Super-Resolution</title>
      <link>https://paperswithcode.com/paper/open-high-resolution-satellite-imagery-the</link>
      <description><![CDATA[We hereby hope to foster broad-spectrum applications of ML to satellite imagery, and possibly develop from free public low-resolution Sentinel2 imagery the same power of analysis allowed by costly private high-resolution imagery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-high-resolution-satellite-imagery-the</guid>
    </item>
    <item>
      <title>POET: Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging</title>
      <link>https://paperswithcode.com/paper/poet-training-neural-networks-on-tiny-devices</link>
      <description><![CDATA[We demonstrate that it is possible to fine-tune both ResNet-18 and BERT within the memory constraints of a Cortex-M class embedded device while outperforming current edge training methods in energy efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poet-training-neural-networks-on-tiny-devices</guid>
    </item>
    <item>
      <title>Out-of-Distribution Detection with Deep Nearest Neighbors</title>
      <link>https://paperswithcode.com/paper/out-of-distribution-detection-with-deep</link>
      <description><![CDATA[In this paper, we explore the efficacy of non-parametric nearest-neighbor distance for OOD detection, which has been largely overlooked in the literature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/out-of-distribution-detection-with-deep</guid>
    </item>
    <item>
      <title>Improved Vector Quantized Diffusion Models</title>
      <link>https://paperswithcode.com/paper/improved-vector-quantized-diffusion-models</link>
      <description><![CDATA[When trained on ImageNet, we dramatically improve the FID score from 11. 89 to 4. 83, demonstrating the superiority of our proposed techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improved-vector-quantized-diffusion-models</guid>
    </item>
    <item>
      <title>Language Modelling with Pixels</title>
      <link>https://paperswithcode.com/paper/language-modelling-with-pixels</link>
      <description><![CDATA[Language models are defined over a finite set of inputs, which creates a vocabulary bottleneck when we attempt to scale the number of supported languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-modelling-with-pixels</guid>
    </item>
    <item>
      <title>Rethinking IoU-based Optimization for Single-stage 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/rethinking-iou-based-optimization-for-single</link>
      <description><![CDATA[Since Intersection-over-Union (IoU) based optimization maintains the consistency of the final IoU prediction metric and losses, it has been widely used in both regression and classification branches of single-stage 2D object detectors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-iou-based-optimization-for-single</guid>
    </item>
    <item>
      <title>Adversarial Pixel Restoration as a Pretext Task for Transferable Perturbations</title>
      <link>https://paperswithcode.com/paper/adversarial-pixel-restoration-as-a-pretext</link>
      <description><![CDATA[Transferable adversarial attacks optimize adversaries from a pretrained surrogate model and known label space to fool the unknown black-box models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-pixel-restoration-as-a-pretext</guid>
    </item>
    <item>
      <title>HiFormer: Hierarchical Multi-scale Representations Using Transformers for Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/hiformer-hierarchical-multi-scale</link>
      <description><![CDATA[In this paper, we propose HiFormer, a novel method that efficiently bridges a CNN and a transformer for medical image segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hiformer-hierarchical-multi-scale</guid>
    </item>
    <item>
      <title>Why do tree-based models still outperform deep learning on tabular data?</title>
      <link>https://paperswithcode.com/paper/why-do-tree-based-models-still-outperform</link>
      <description><![CDATA[While deep learning has enabled tremendous progress on text and image datasets, its superiority on tabular data is not clear.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/why-do-tree-based-models-still-outperform</guid>
    </item>
    <item>
      <title>Gender Classification and Bias Mitigation in Facial Images</title>
      <link>https://paperswithcode.com/paper/gender-classification-and-bias-mitigation-in</link>
      <description><![CDATA[We worked to increase classification accuracy and mitigate algorithmic biases on our baseline model trained on the augmented benchmark database.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gender-classification-and-bias-mitigation-in</guid>
    </item>
    <item>
      <title>TokenMix: Rethinking Image Mixing for Data Augmentation in Vision Transformers</title>
      <link>https://paperswithcode.com/paper/tokenmix-rethinking-image-mixing-for-data</link>
      <description><![CDATA[In this paper, we propose a novel data augmentation technique TokenMix to improve the performance of vision transformers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tokenmix-rethinking-image-mixing-for-data</guid>
    </item>
    <item>
      <title>StudioGAN: A Taxonomy and Benchmark of GANs for Image Synthesis</title>
      <link>https://paperswithcode.com/paper/studiogan-a-taxonomy-and-benchmark-of-gans</link>
      <description><![CDATA[Generative Adversarial Network (GAN) is one of the state-of-the-art generative models for realistic image synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/studiogan-a-taxonomy-and-benchmark-of-gans</guid>
    </item>
    <item>
      <title>Prompting Visual-Language Models for Efficient Video Understanding</title>
      <link>https://paperswithcode.com/paper/prompting-visual-language-models-for</link>
      <description><![CDATA[Image-based visual-language (I-VL) pre-training has shown great success for learning joint visual-textual representations from large-scale web data, revealing remarkable ability for zero-shot generalisation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompting-visual-language-models-for</guid>
    </item>
  </channel>
</rss>
