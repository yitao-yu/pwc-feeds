<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 26 Apr 2023 21:06:25 +0000</lastBuildDate>
    <item>
      <title>Track Anything: Segment Anything Meets Videos</title>
      <link>https://paperswithcode.com/paper/track-anything-segment-anything-meets-videos</link>
      <description><![CDATA[Therefore, in this report, we propose Track Anything Model (TAM), which achieves high-performance interactive tracking and segmentation in videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/track-anything-segment-anything-meets-videos</guid>
    </item>
    <item>
      <title>Robust Speech Recognition via Large-Scale Weak Supervision</title>
      <link>https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale-1</link>
      <description><![CDATA[We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale-1</guid>
    </item>
    <item>
      <title>Adafactor: Adaptive Learning Rates with Sublinear Memory Cost</title>
      <link>https://paperswithcode.com/paper/adafactor-adaptive-learning-rates-with</link>
      <description><![CDATA[In several recently proposed stochastic optimization methods (e. g. RMSProp, Adam, Adadelta), parameter updates are scaled by the inverse square roots of exponential moving averages of squared past gradients.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adafactor-adaptive-learning-rates-with</guid>
    </item>
    <item>
      <title>Segment Anything in Medical Images</title>
      <link>https://paperswithcode.com/paper/segment-anything-in-medical-images</link>
      <description><![CDATA[Comprehensive experiments on 21 3D segmentation tasks and 9 2D segmentation tasks demonstrate that MedSAM outperforms the default SAM model with an average Dice Similarity Coefficient (DSC) of 22. 5% and 17. 6% on 3D and 2D segmentation tasks, respectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-anything-in-medical-images</guid>
    </item>
    <item>
      <title>Inpaint Anything: Segment Anything Meets Image Inpainting</title>
      <link>https://paperswithcode.com/paper/inpaint-anything-segment-anything-meets-image</link>
      <description><![CDATA[We are also very willing to help everyone share and promote new projects based on our Inpaint Anything (IA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inpaint-anything-segment-anything-meets-image</guid>
    </item>
    <item>
      <title>Tool Learning with Foundation Models</title>
      <link>https://paperswithcode.com/paper/tool-learning-with-foundation-models</link>
      <description><![CDATA[Considering the lack of a systematic tool learning evaluation in prior works, we experiment with 17 representative tools and show the potential of current foundation models in skillfully utilizing tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tool-learning-with-foundation-models</guid>
    </item>
    <item>
      <title>MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models</title>
      <link>https://paperswithcode.com/paper/minigpt-4-enhancing-vision-language</link>
      <description><![CDATA[To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen LLM, Vicuna, using just one projection layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minigpt-4-enhancing-vision-language</guid>
    </item>
    <item>
      <title>Segment Everything Everywhere All at Once</title>
      <link>https://paperswithcode.com/paper/segment-everything-everywhere-all-at-once</link>
      <description><![CDATA[Inspired by the development of prompt-based universal interfaces for LLMs, this paper presents SEEM, a promptable, interactive model for Segmenting Everything Everywhere all at once in an image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-everything-everywhere-all-at-once</guid>
    </item>
    <item>
      <title>Anything-3D: Towards Single-view Anything Reconstruction in the Wild</title>
      <link>https://paperswithcode.com/paper/anything-3d-towards-single-view-anything</link>
      <description><![CDATA[3D reconstruction from a single-RGB image in unconstrained real-world scenarios presents numerous challenges due to the inherent diversity and complexity of objects and environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anything-3d-towards-single-view-anything</guid>
    </item>
    <item>
      <title>Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models</title>
      <link>https://paperswithcode.com/paper/chameleon-plug-and-play-compositional</link>
      <description><![CDATA[Large language models (LLMs) have achieved remarkable progress in various natural language processing tasks with emergent abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chameleon-plug-and-play-compositional</guid>
    </item>
    <item>
      <title>Phoenix: Democratizing ChatGPT across Languages</title>
      <link>https://paperswithcode.com/paper/phoenix-democratizing-chatgpt-across</link>
      <description><![CDATA[This paper presents our efforts to democratize ChatGPT across language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phoenix-democratizing-chatgpt-across</guid>
    </item>
    <item>
      <title>DINOv2: Learning Robust Visual Features without Supervision</title>
      <link>https://paperswithcode.com/paper/dinov2-learning-robust-visual-features</link>
      <description><![CDATA[The recent breakthroughs in natural language processing for model pretraining on large quantities of data have opened the way for similar foundation models in computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dinov2-learning-robust-visual-features</guid>
    </item>
    <item>
      <title>F$^{2}$-NeRF: Fast Neural Radiance Field Training with Free Camera Trajectories</title>
      <link>https://paperswithcode.com/paper/f-2-nerf-fast-neural-radiance-field-training</link>
      <description><![CDATA[Based on our analysis, we further propose a novel space-warping method called perspective warping, which allows us to handle arbitrary trajectories in the grid-based NeRF framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/f-2-nerf-fast-neural-radiance-field-training</guid>
    </item>
    <item>
      <title>Evaluating ChatGPT's Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness</title>
      <link>https://paperswithcode.com/paper/evaluating-chatgpt-s-information-extraction</link>
      <description><![CDATA[The capability of Large Language Models (LLMs) like ChatGPT to comprehend user intent and provide reasonable responses has made them extremely popular lately.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-chatgpt-s-information-extraction</guid>
    </item>
    <item>
      <title>Transformer-Based Visual Segmentation: A Survey</title>
      <link>https://paperswithcode.com/paper/transformer-based-visual-segmentation-a</link>
      <description><![CDATA[Recently, transformers, a type of neural network based on self-attention originally designed for natural language processing, have considerably surpassed previous convolutional or recurrent approaches in various vision processing tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-based-visual-segmentation-a</guid>
    </item>
    <item>
      <title>Explicit Correspondence Matching for Generalizable Neural Radiance Fields</title>
      <link>https://paperswithcode.com/paper/explicit-correspondence-matching-for</link>
      <description><![CDATA[The key to our approach lies in the explicitly modeled correspondence matching information, so as to provide the geometry prior to the prediction of NeRF color and density for volume rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/explicit-correspondence-matching-for</guid>
    </item>
    <item>
      <title>A Method for Animating Children's Drawings of the Human Figure</title>
      <link>https://paperswithcode.com/paper/a-method-for-automatically-animating-children</link>
      <description><![CDATA[Children's drawings have a wonderful inventiveness, creativity, and variety to them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-method-for-automatically-animating-children</guid>
    </item>
    <item>
      <title>GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</title>
      <link>https://paperswithcode.com/paper/gptq-accurate-post-training-quantization-for</link>
      <description><![CDATA[In this paper, we address this challenge, and propose GPTQ, a new one-shot weight quantization method based on approximate second-order information, that is both highly-accurate and highly-efficient.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gptq-accurate-post-training-quantization-for</guid>
    </item>
    <item>
      <title>Topological Deep Learning: Going Beyond Graph Data</title>
      <link>https://paperswithcode.com/paper/higher-order-attention-networks</link>
      <description><![CDATA[Topological deep learning is a rapidly growing field that pertains to the development of deep learning models for data supported on topological domains such as simplicial complexes, cell complexes, and hypergraphs, which generalize many domains encountered in scientific computations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/higher-order-attention-networks</guid>
    </item>
    <item>
      <title>VisFusion: Visibility-aware Online 3D Scene Reconstruction from Videos</title>
      <link>https://paperswithcode.com/paper/visfusion-visibility-aware-online-3d-scene</link>
      <description><![CDATA[Different from their works which sparsify voxels globally with a fixed occupancy threshold, we perform the sparsification on a local feature volume along each visual ray to preserve at least one voxel per ray for more fine details.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visfusion-visibility-aware-online-3d-scene</guid>
    </item>
  </channel>
</rss>
