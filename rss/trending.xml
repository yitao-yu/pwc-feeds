<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 04 Jan 2024 21:07:12 +0000</lastBuildDate>
    <item>
      <title>Fast Inference of Mixture-of-Experts Language Models with Offloading</title>
      <link>https://paperswithcode.com/paper/fast-inference-of-mixture-of-experts-language</link>
      <description><![CDATA[In this work, we study the problem of running large MoE language models on consumer hardware with limited accelerator memory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-inference-of-mixture-of-experts-language</guid>
    </item>
    <item>
      <title>KwaiAgents: Generalized Information-seeking Agent System with Large Language Models</title>
      <link>https://paperswithcode.com/paper/kwaiagents-generalized-information-seeking</link>
      <description><![CDATA[Driven by curiosity, humans have continually sought to explore and understand the world around them, leading to the invention of various tools to satiate this inquisitiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kwaiagents-generalized-information-seeking</guid>
    </item>
    <item>
      <title>AnyText: Multilingual Visual Text Generation And Editing</title>
      <link>https://paperswithcode.com/paper/anytext-multilingual-visual-text-generation</link>
      <description><![CDATA[Based on AnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual text generation accuracy and quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anytext-multilingual-visual-text-generation</guid>
    </item>
    <item>
      <title>StreamDiffusion: A Pipeline-level Solution for Real-time Interactive Generation</title>
      <link>https://paperswithcode.com/paper/streamdiffusion-a-pipeline-level-solution-for</link>
      <description><![CDATA[We introduce StreamDiffusion, a real-time diffusion pipeline designed for interactive image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streamdiffusion-a-pipeline-level-solution-for</guid>
    </item>
    <item>
      <title>TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones</title>
      <link>https://paperswithcode.com/paper/tinygpt-v-efficient-multimodal-large-language</link>
      <description><![CDATA[In the era of advanced multimodel learning, multimodal large language models (MLLMs) such as GPT-4V have made remarkable strides towards bridging language and visual elements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tinygpt-v-efficient-multimodal-large-language</guid>
    </item>
    <item>
      <title>Ferret: Refer and Ground Anything Anywhere at Any Granularity</title>
      <link>https://paperswithcode.com/paper/ferret-refer-and-ground-anything-anywhere-at</link>
      <description><![CDATA[We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ferret-refer-and-ground-anything-anywhere-at</guid>
    </item>
    <item>
      <title>Speaker Embedding-aware Neural Diarization for Flexible Number of Speakers with Textual Information</title>
      <link>https://paperswithcode.com/paper/speaker-embedding-aware-neural-diarization</link>
      <description><![CDATA[In this paper, we reformulate this task as a single-label prediction problem by encoding the multi-speaker labels with power set.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/speaker-embedding-aware-neural-diarization</guid>
    </item>
    <item>
      <title>SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability</title>
      <link>https://paperswithcode.com/paper/seaco-paraformer-a-non-autoregressive-asr</link>
      <description><![CDATA[It possesses the advantages of AED-based model's accuracy, NAR model's efficiency, and explicit customization capacity of superior performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seaco-paraformer-a-non-autoregressive-asr</guid>
    </item>
    <item>
      <title>Generative AI for Math: Part I -- MathPile: A Billion-Token-Scale Pretraining Corpus for Math</title>
      <link>https://paperswithcode.com/paper/generative-ai-for-math-part-i-mathpile-a</link>
      <description><![CDATA[Our meticulous data collection and processing efforts included a complex suite of preprocessing, prefiltering, language identification, cleaning, filtering, and deduplication, ensuring the high quality of our corpus.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-ai-for-math-part-i-mathpile-a</guid>
    </item>
    <item>
      <title>PromptBench: A Unified Library for Evaluation of Large Language Models</title>
      <link>https://paperswithcode.com/paper/promptbench-a-unified-library-for-evaluation</link>
      <description><![CDATA[The evaluation of large language models (LLMs) is crucial to assess their performance and mitigate potential security risks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/promptbench-a-unified-library-for-evaluation</guid>
    </item>
    <item>
      <title>Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</title>
      <link>https://paperswithcode.com/paper/principled-instructions-are-all-you-need-for</link>
      <description><![CDATA[This paper introduces 26 guiding principles designed to streamline the process of querying and prompting large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/principled-instructions-are-all-you-need-for</guid>
    </item>
    <item>
      <title>TinySAM: Pushing the Envelope for Efficient Segment Anything Model</title>
      <link>https://paperswithcode.com/paper/tinysam-pushing-the-envelope-for-efficient</link>
      <description><![CDATA[We first propose a full-stage knowledge distillation method with online hard prompt sampling strategy to distill a lightweight student model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tinysam-pushing-the-envelope-for-efficient</guid>
    </item>
    <item>
      <title>UniRef++: Segment Every Reference Object in Spatial and Temporal Spaces</title>
      <link>https://paperswithcode.com/paper/uniref-segment-every-reference-object-in</link>
      <description><![CDATA[We evaluate our unified models on various benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uniref-segment-every-reference-object-in</guid>
    </item>
    <item>
      <title>Generative Multimodal Models are In-Context Learners</title>
      <link>https://paperswithcode.com/paper/generative-multimodal-models-are-in-context</link>
      <description><![CDATA[The human ability to easily solve multimodal tasks in context (i. e., with only a few demonstrations or simple instructions), is what current multimodal systems have largely struggled to imitate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-multimodal-models-are-in-context</guid>
    </item>
    <item>
      <title>DreamGaussian4D: Generative 4D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/dreamgaussian4d-generative-4d-gaussian</link>
      <description><![CDATA[Remarkable progress has been made in 4D content generation recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamgaussian4d-generative-4d-gaussian</guid>
    </item>
    <item>
      <title>Unsupervised Universal Image Segmentation</title>
      <link>https://paperswithcode.com/paper/unsupervised-universal-image-segmentation</link>
      <description><![CDATA[Several unsupervised image segmentation approaches have been proposed which eliminate the need for dense manually-annotated segmentation masks; current models separately handle either semantic segmentation (e. g., STEGO) or class-agnostic instance segmentation (e. g., CutLER), but not both (i. e., panoptic segmentation).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-universal-image-segmentation</guid>
    </item>
    <item>
      <title>What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/what-makes-good-data-for-alignment-a</link>
      <description><![CDATA[We present deita (short for Data-Efficient Instruction Tuning for Alignment), a series of models fine-tuned from LLaMA and Mistral models using data samples automatically selected with our proposed approach.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-makes-good-data-for-alignment-a</guid>
    </item>
    <item>
      <title>Tokenize Anything via Prompting</title>
      <link>https://paperswithcode.com/paper/tokenize-anything-via-prompting</link>
      <description><![CDATA[The semantic token is responsible for learning the semantic priors in a predefined concept space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tokenize-anything-via-prompting</guid>
    </item>
    <item>
      <title>Pixel-Aware Stable Diffusion for Realistic Image Super-resolution and Personalized Stylization</title>
      <link>https://paperswithcode.com/paper/pixel-aware-stable-diffusion-for-realistic</link>
      <description><![CDATA[However, the existing methods along this line either fail to keep faithful pixel-wise image structures or resort to extra skipped connections to reproduce details, which requires additional training in image space and limits their extension to other related tasks in latent space such as image stylization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pixel-aware-stable-diffusion-for-realistic</guid>
    </item>
    <item>
      <title>MobileVLM : A Fast, Strong and Open Vision Language Assistant for Mobile Devices</title>
      <link>https://paperswithcode.com/paper/mobilevlm-a-fast-reproducible-and-strong</link>
      <description><![CDATA[We present MobileVLM, a competent multimodal vision language model (MMVLM) targeted to run on mobile devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobilevlm-a-fast-reproducible-and-strong</guid>
    </item>
  </channel>
</rss>
