<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 21 Oct 2024 21:08:47 +0000</lastBuildDate>
    <item>
      <title>Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation</title>
      <link>https://paperswithcode.com/paper/hallo2-long-duration-and-high-resolution</link>
      <description><![CDATA[To the best of our knowledge, Hallo2, proposed in this paper, is the first method to achieve 4K resolution and generate hour-long, audio-driven portrait image animations enhanced with textual prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hallo2-long-duration-and-high-resolution</guid>
    </item>
    <item>
      <title>LightRAG: Simple and Fast Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/lightrag-simple-and-fast-retrieval-augmented</link>
      <description><![CDATA[Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by integrating external knowledge sources, enabling more accurate and contextually relevant responses tailored to user needs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightrag-simple-and-fast-retrieval-augmented</guid>
    </item>
    <item>
      <title>F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching</title>
      <link>https://paperswithcode.com/paper/f5-tts-a-fairytaler-that-fakes-fluent-and</link>
      <description><![CDATA[This sampling strategy for flow step can be easily applied to existing flow matching based models without retraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/f5-tts-a-fairytaler-that-fakes-fluent-and</guid>
    </item>
    <item>
      <title>Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation</title>
      <link>https://paperswithcode.com/paper/janus-decoupling-visual-encoding-for-unified</link>
      <description><![CDATA[In this paper, we introduce Janus, an autoregressive framework that unifies multimodal understanding and generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/janus-decoupling-visual-encoding-for-unified</guid>
    </item>
    <item>
      <title>TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON</title>
      <link>https://paperswithcode.com/paper/taskgen-a-task-based-memory-infused-agentic</link>
      <description><![CDATA[TaskGen is an open-sourced agentic framework which uses an Agent to solve an arbitrary task by breaking them down into subtasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taskgen-a-task-based-memory-infused-agentic</guid>
    </item>
    <item>
      <title>Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities</title>
      <link>https://paperswithcode.com/paper/mini-omni2-towards-open-source-gpt-4o-model</link>
      <description><![CDATA[It can understand visual, auditory, and textual modalities, directly output audio, and support flexible duplex interaction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mini-omni2-towards-open-source-gpt-4o-model</guid>
    </item>
    <item>
      <title>DepthSplat: Connecting Gaussian Splatting and Depth</title>
      <link>https://paperswithcode.com/paper/depthsplat-connecting-gaussian-splatting-and</link>
      <description><![CDATA[Gaussian splatting and single/multi-view depth estimation are typically studied in isolation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depthsplat-connecting-gaussian-splatting-and</guid>
    </item>
    <item>
      <title>Movie Gen: A Cast of Media Foundation Models</title>
      <link>https://paperswithcode.com/paper/movie-gen-a-cast-of-media-foundation-models</link>
      <description><![CDATA[Our models set a new state-of-the-art on multiple tasks: text-to-video synthesis, video personalization, video editing, video-to-audio generation, and text-to-audio generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/movie-gen-a-cast-of-media-foundation-models</guid>
    </item>
    <item>
      <title>ASFT: Aligned Supervised Fine-Tuning through Absolute Likelihood</title>
      <link>https://paperswithcode.com/paper/asft-aligned-supervised-fine-tuning-through</link>
      <description><![CDATA[Additionally, we compare ASFT to DPO and its latest variants, such as the single-step approach ORPO, using the latest instruction-tuned model Llama3, which has been fine-tuned on UltraFeedback and HH-RLHF.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/asft-aligned-supervised-fine-tuning-through</guid>
    </item>
    <item>
      <title>CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos</title>
      <link>https://paperswithcode.com/paper/cotracker3-simpler-and-better-point-tracking</link>
      <description><![CDATA[Most state-of-the-art point trackers are trained on synthetic data due to the difficulty of annotating real videos for this task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cotracker3-simpler-and-better-point-tracking</guid>
    </item>
    <item>
      <title>One Step Diffusion via Shortcut Models</title>
      <link>https://paperswithcode.com/paper/one-step-diffusion-via-shortcut-models</link>
      <description><![CDATA[We introduce shortcut models, a family of generative models that use a single network and training phase to produce high-quality samples in a single or multiple sampling steps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-step-diffusion-via-shortcut-models</guid>
    </item>
    <item>
      <title>Diffusion for World Modeling: Visual Details Matter in Atari</title>
      <link>https://paperswithcode.com/paper/diffusion-for-world-modeling-visual-details</link>
      <description><![CDATA[Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As a Model Of eNvironment Dreams), a reinforcement learning agent trained in a diffusion world model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-for-world-modeling-visual-details</guid>
    </item>
    <item>
      <title>Depth Pro: Sharp Monocular Metric Depth in Less Than a Second</title>
      <link>https://paperswithcode.com/paper/depth-pro-sharp-monocular-metric-depth-in</link>
      <description><![CDATA[We present a foundation model for zero-shot metric monocular depth estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depth-pro-sharp-monocular-metric-depth-in</guid>
    </item>
    <item>
      <title>Leveraging Self-Supervised Learning for Speaker Diarization</title>
      <link>https://paperswithcode.com/paper/leveraging-self-supervised-learning-for</link>
      <description><![CDATA[In this work, we explore using WavLM to alleviate the problem of data scarcity for neural diarization training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/leveraging-self-supervised-learning-for</guid>
    </item>
    <item>
      <title>From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline</title>
      <link>https://paperswithcode.com/paper/from-crowdsourced-data-to-high-quality</link>
      <description><![CDATA[The rapid evolution of Large Language Models (LLMs) has outpaced the development of model evaluation, highlighting the need for continuous curation of new, challenging benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-crowdsourced-data-to-high-quality</guid>
    </item>
    <item>
      <title>Tora: Trajectory-oriented Diffusion Transformer for Video Generation</title>
      <link>https://paperswithcode.com/paper/tora-trajectory-oriented-diffusion</link>
      <description><![CDATA[The TE encodes arbitrary trajectories into hierarchical spacetime motion patches with a 3D video compression network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tora-trajectory-oriented-diffusion</guid>
    </item>
    <item>
      <title>Agent S: An Open Agentic Framework that Uses Computers Like a Human</title>
      <link>https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</link>
      <description><![CDATA[We present Agent S, an open agentic framework that enables autonomous interaction with computers through a Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agent-s-an-open-agentic-framework-that-uses</guid>
    </item>
    <item>
      <title>Pyramidal Flow Matching for Efficient Video Generative Modeling</title>
      <link>https://paperswithcode.com/paper/pyramidal-flow-matching-for-efficient-video</link>
      <description><![CDATA[Video generation requires modeling a vast spatiotemporal space, which demands significant computational resources and data usage.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pyramidal-flow-matching-for-efficient-video</guid>
    </item>
    <item>
      <title>3DTopia-XL: Scaling High-quality 3D Asset Generation via Primitive Diffusion</title>
      <link>https://paperswithcode.com/paper/3dtopia-xl-scaling-high-quality-3d-asset</link>
      <description><![CDATA[The increasing demand for high-quality 3D assets across various industries necessitates efficient and automated 3D content creation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dtopia-xl-scaling-high-quality-3d-asset</guid>
    </item>
    <item>
      <title>NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing</title>
      <link>https://paperswithcode.com/paper/narcan-natural-refined-canonical-image-with</link>
      <description><![CDATA[We propose a video editing framework, NaRCan, which integrates a hybrid deformation field and diffusion prior to generate high-quality natural canonical images to represent the input video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/narcan-natural-refined-canonical-image-with</guid>
    </item>
  </channel>
</rss>
