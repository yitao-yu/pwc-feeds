<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 11 Feb 2024 09:10:45 +0000</lastBuildDate>
    <item>
      <title>Guiding Instruction-based Image Editing via Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/guiding-instruction-based-image-editing-via</link>
      <description><![CDATA[Extensive experimental results demonstrate that expressive instructions are crucial to instruction-based image editing, and our MGIE can lead to a notable improvement in automatic metrics and human evaluation while maintaining competitive inference efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/guiding-instruction-based-image-editing-via</guid>
    </item>
    <item>
      <title>YOLO-World: Real-Time Open-Vocabulary Object Detection</title>
      <link>https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</link>
      <description><![CDATA[The You Only Look Once (YOLO) series of detectors have established themselves as efficient and practical tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</guid>
    </item>
    <item>
      <title>DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</title>
      <link>https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</link>
      <description><![CDATA[Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</guid>
    </item>
    <item>
      <title>DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors</title>
      <link>https://paperswithcode.com/paper/dynamicrafter-animating-open-domain-images</link>
      <description><![CDATA[Animating a still image offers an engaging visual experience.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamicrafter-animating-open-domain-images</guid>
    </item>
    <item>
      <title>Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception</title>
      <link>https://paperswithcode.com/paper/mobile-agent-autonomous-multi-modal-mobile</link>
      <description><![CDATA[To assess the performance of Mobile-Agent, we introduced Mobile-Eval, a benchmark for evaluating mobile device operations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobile-agent-autonomous-multi-modal-mobile</guid>
    </item>
    <item>
      <title>Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/lag-llama-towards-foundation-models-for-time</link>
      <description><![CDATA[Over the past years, foundation models have caused a paradigm shift in machine learning due to their unprecedented capabilities for zero-shot and few-shot generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lag-llama-towards-foundation-models-for-time</guid>
    </item>
    <item>
      <title>OLMo: Accelerating the Science of Language Models</title>
      <link>https://paperswithcode.com/paper/olmo-accelerating-the-science-of-language</link>
      <description><![CDATA[Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community to have access to powerful, truly open LMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/olmo-accelerating-the-science-of-language</guid>
    </item>
    <item>
      <title>Nomic Embed: Training a Reproducible Long Context Text Embedder</title>
      <link>https://paperswithcode.com/paper/nomic-embed-training-a-reproducible-long</link>
      <description><![CDATA[This technical report describes the training of nomic-embed-text-v1, the first fully reproducible, open-source, open-weights, open-data, 8192 context length English text embedding model that outperforms both OpenAI Ada-002 and OpenAI text-embedding-3-small on short and long-context tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nomic-embed-training-a-reproducible-long</guid>
    </item>
    <item>
      <title>Extreme Compression of Large Language Models via Additive Quantization</title>
      <link>https://paperswithcode.com/paper/extreme-compression-of-large-language-models</link>
      <description><![CDATA[The emergence of accurate open large language models (LLMs) has led to a race towards quantization techniques for such models enabling execution on end-user devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extreme-compression-of-large-language-models</guid>
    </item>
    <item>
      <title>AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning</title>
      <link>https://paperswithcode.com/paper/animatelcm-accelerating-the-animation-of</link>
      <description><![CDATA[We validate the proposed strategy in image-conditioned video generation and layout-conditioned video generation, all achieving top-performing results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatelcm-accelerating-the-animation-of</guid>
    </item>
    <item>
      <title>InstantID: Zero-shot Identity-Preserving Generation in Seconds</title>
      <link>https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</link>
      <description><![CDATA[There has been significant progress in personalized image synthesis with methods such as Textual Inversion, DreamBooth, and LoRA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</guid>
    </item>
    <item>
      <title>A Comprehensive Survey on 3D Content Generation</title>
      <link>https://paperswithcode.com/paper/a-comprehensive-survey-on-3d-content</link>
      <description><![CDATA[Recent years have witnessed remarkable advances in artificial intelligence generated content(AIGC), with diverse input modalities, e. g., text, image, video, audio and 3D.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comprehensive-survey-on-3d-content</guid>
    </item>
    <item>
      <title>Fast Timing-Conditioned Latent Audio Diffusion</title>
      <link>https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</link>
      <description><![CDATA[Generating long-form 44. 1kHz stereo audio from text prompts can be computationally demanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</guid>
    </item>
    <item>
      <title>BiLLM: Pushing the Limit of Post-Training Quantization for LLMs</title>
      <link>https://paperswithcode.com/paper/billm-pushing-the-limit-of-post-training</link>
      <description><![CDATA[Pretrained large language models (LLMs) exhibit exceptional general language processing capabilities but come with significant demands on memory and computational resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/billm-pushing-the-limit-of-post-training</guid>
    </item>
    <item>
      <title>Efficiently Programming Large Language Models using SGLang</title>
      <link>https://paperswithcode.com/paper/efficiently-programming-large-language-models</link>
      <description><![CDATA[SGLang is designed for the efficient programming of LLMs and incorporates primitives for common LLM programming patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiently-programming-large-language-models</guid>
    </item>
    <item>
      <title>Learning to Fly in Seconds</title>
      <link>https://paperswithcode.com/paper/learning-to-fly-in-seconds</link>
      <description><![CDATA[Our framework enables Simulation-to-Reality (Sim2Real) transfer for direct RPM control after only 18 seconds of training on a consumer-grade laptop as well as its deployment on microcontrollers to control a multirotor under real-time guarantees.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-fly-in-seconds</guid>
    </item>
    <item>
      <title>Position Paper: What Can Large Language Models Tell Us about Time Series Analysis</title>
      <link>https://paperswithcode.com/paper/position-paper-what-can-large-language-models</link>
      <description><![CDATA[Time series analysis is essential for comprehending the complexities inherent in various real-world systems and applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/position-paper-what-can-large-language-models</guid>
    </item>
    <item>
      <title>InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions</title>
      <link>https://paperswithcode.com/paper/interactivevideo-user-centric-controllable</link>
      <description><![CDATA[We introduce $\textit{InteractiveVideo}$, a user-centric framework for video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interactivevideo-user-centric-controllable</guid>
    </item>
    <item>
      <title>BlackMamba: Mixture of Experts for State-Space Models</title>
      <link>https://paperswithcode.com/paper/blackmamba-mixture-of-experts-for-state-space</link>
      <description><![CDATA[In this paper, we present BlackMamba, a novel architecture that combines the Mamba SSM with MoE to obtain the benefits of both.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blackmamba-mixture-of-experts-for-state-space</guid>
    </item>
    <item>
      <title>EfficientViT-SAM: Accelerated Segment Anything Model Without Performance Loss</title>
      <link>https://paperswithcode.com/paper/efficientvit-sam-accelerated-segment-anything</link>
      <description><![CDATA[For the training, we begin with the knowledge distillation from the SAM-ViT-H image encoder to EfficientViT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficientvit-sam-accelerated-segment-anything</guid>
    </item>
  </channel>
</rss>
