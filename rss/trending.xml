<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 12 May 2023 09:11:51 +0000</lastBuildDate>
    <item>
      <title>ImageBind: One Embedding Space To Bind Them All</title>
      <link>https://paperswithcode.com/paper/imagebind-one-embedding-space-to-bind-them</link>
      <description><![CDATA[We show that all combinations of paired data are not necessary to train such a joint embedding, and only image-paired data is sufficient to bind the modalities together.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imagebind-one-embedding-space-to-bind-them</guid>
    </item>
    <item>
      <title>Shap-E: Generating Conditional 3D Implicit Functions</title>
      <link>https://paperswithcode.com/paper/shap-e-generating-conditional-3d-implicit</link>
      <description><![CDATA[We present Shap-E, a conditional generative model for 3D assets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shap-e-generating-conditional-3d-implicit</guid>
    </item>
    <item>
      <title>InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language</title>
      <link>https://paperswithcode.com/paper/internchat-solving-vision-centric-tasks-by</link>
      <description><![CDATA[Different from existing interactive systems that rely on pure language, by incorporating pointing instructions, the proposed iGPT significantly improves the efficiency of communication between users and chatbots, as well as the accuracy of chatbots in vision-centric tasks, especially in complicated visual scenarios where the number of objects is greater than 2.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internchat-solving-vision-centric-tasks-by</guid>
    </item>
    <item>
      <title>U$^2$-Net: Going Deeper with Nested U-Structure for Salient Object Detection</title>
      <link>https://paperswithcode.com/paper/u-2-net-going-deeper-with-nested-u-structure</link>
      <description><![CDATA[In this paper, we design a simple yet powerful deep network architecture, U$^2$-Net, for salient object detection (SOD).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/u-2-net-going-deeper-with-nested-u-structure</guid>
    </item>
    <item>
      <title>Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures</title>
      <link>https://paperswithcode.com/paper/latent-nerf-for-shape-guided-generation-of-3d</link>
      <description><![CDATA[This unique combination of text and shape guidance allows for increased control over the generation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-nerf-for-shape-guided-generation-of-3d</guid>
    </item>
    <item>
      <title>MultiModal-GPT: A Vision and Language Model for Dialogue with Humans</title>
      <link>https://paperswithcode.com/paper/multimodal-gpt-a-vision-and-language-model</link>
      <description><![CDATA[To further enhance the ability to chat with humans of the MultiModal-GPT, we utilize language-only instruction-following data to train the MultiModal-GPT jointly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-gpt-a-vision-and-language-model</guid>
    </item>
    <item>
      <title>HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge</title>
      <link>https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</link>
      <description><![CDATA[Large Language Models (LLMs), such as the LLaMA model, have demonstrated their effectiveness in various general-domain natural language processing (NLP) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</guid>
    </item>
    <item>
      <title>Personalize Segment Anything Model with One Shot</title>
      <link>https://paperswithcode.com/paper/personalize-segment-anything-model-with-one</link>
      <description><![CDATA[Driven by large-data pre-training, Segment Anything Model (SAM) has been demonstrated as a powerful and promptable framework, revolutionizing the segmentation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalize-segment-anything-model-with-one</guid>
    </item>
    <item>
      <title>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</title>
      <link>https://paperswithcode.com/paper/harnessing-the-power-of-llms-in-practice-a</link>
      <description><![CDATA[This paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream natural language processing (NLP) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/harnessing-the-power-of-llms-in-practice-a</guid>
    </item>
    <item>
      <title>PET-NeuS: Positional Encoding Tri-Planes for Neural Surfaces</title>
      <link>https://paperswithcode.com/paper/pet-neus-positional-encoding-tri-planes-for</link>
      <description><![CDATA[The first component is to borrow the tri-plane representation from EG3D and represent signed distance fields as a mixture of tri-planes and MLPs instead of representing it with MLPs only.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pet-neus-positional-encoding-tri-planes-for</guid>
    </item>
    <item>
      <title>PP-LiteSeg: A Superior Real-Time Semantic Segmentation Model</title>
      <link>https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</link>
      <description><![CDATA[Real-world applications have high demands for semantic segmentation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</guid>
    </item>
    <item>
      <title>LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention</title>
      <link>https://paperswithcode.com/paper/llama-adapter-efficient-fine-tuning-of</link>
      <description><![CDATA[We present LLaMA-Adapter, a lightweight adaption method to efficiently fine-tune LLaMA into an instruction-following model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-adapter-efficient-fine-tuning-of</guid>
    </item>
    <item>
      <title>Otter: A Multi-Modal Model with In-Context Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/otter-a-multi-modal-model-with-in-context</link>
      <description><![CDATA[Large language models (LLMs) have demonstrated significant universal capabilities as few/zero-shot learners in various tasks due to their pre-training on vast amounts of text data, as exemplified by GPT-3, which boosted to InstrctGPT and ChatGPT, effectively following natural language instructions to accomplish real-world tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/otter-a-multi-modal-model-with-in-context</guid>
    </item>
    <item>
      <title>Unlimiformer: Long-Range Transformers with Unlimited Length Input</title>
      <link>https://paperswithcode.com/paper/unlimiformer-long-range-transformers-with</link>
      <description><![CDATA[This way, we can index extremely long input sequences, while every attention head in every decoder layer retrieves its top-$k$ keys, instead of attending to every key.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unlimiformer-long-range-transformers-with</guid>
    </item>
    <item>
      <title>Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models</title>
      <link>https://paperswithcode.com/paper/plan-and-solve-prompting-improving-zero-shot</link>
      <description><![CDATA[To address the calculation errors and improve the quality of generated reasoning steps, we extend PS prompting with more detailed instructions and derive PS+ prompting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plan-and-solve-prompting-improving-zero-shot</guid>
    </item>
    <item>
      <title>Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca</title>
      <link>https://paperswithcode.com/paper/efficient-and-effective-text-encoding-for</link>
      <description><![CDATA[Large Language Models (LLMs), such as ChatGPT and GPT-4, have revolutionized natural language processing research and demonstrated potential in Artificial General Intelligence (AGI).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-and-effective-text-encoding-for</guid>
    </item>
    <item>
      <title>Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models</title>
      <link>https://paperswithcode.com/paper/panda-llm-training-data-and-evaluation-for</link>
      <description><![CDATA[This project focuses on enhancing open-source large language models through instruction-tuning and providing comprehensive evaluations of their performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/panda-llm-training-data-and-evaluation-for</guid>
    </item>
    <item>
      <title>mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality</title>
      <link>https://paperswithcode.com/paper/mplug-owl-modularization-empowers-large</link>
      <description><![CDATA[Our code, pre-trained model, instruction-tuned models, and evaluation set are available at https://github. com/X-PLUG/mPLUG-Owl.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mplug-owl-modularization-empowers-large</guid>
    </item>
    <item>
      <title>ZipIt! Merging Models from Different Tasks without Training</title>
      <link>https://paperswithcode.com/paper/zipit-merging-models-from-different-tasks</link>
      <description><![CDATA[While this works for models trained on the same task, we find that this fails to account for the differences in models trained on disjoint tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zipit-merging-models-from-different-tasks</guid>
    </item>
    <item>
      <title>Towards Building the Federated GPT: Federated Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/towards-building-the-federated-gpt-federated</link>
      <description><![CDATA[This repository offers a foundational framework for exploring federated fine-tuning of LLMs using heterogeneous instructions across diverse categories.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-building-the-federated-gpt-federated</guid>
    </item>
  </channel>
</rss>
