<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 14 Dec 2024 09:15:11 +0000</lastBuildDate>
    <item>
      <title>MossFormer: Pushing the Performance Limit of Monaural Speech Separation using Gated Single-Head Transformer with Convolution-Augmented Joint Self-Attentions</title>
      <link>https://paperswithcode.com/paper/mossformer-pushing-the-performance-limit-of</link>
      <description><![CDATA[To effectively solve the indirect elemental interactions across chunks in the dual-path architecture, MossFormer employs a joint local and global self-attention architecture that simultaneously performs a full-computation self-attention on local chunks and a linearised low-cost self-attention over the full sequence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mossformer-pushing-the-performance-limit-of</guid>
    </item>
    <item>
      <title>StableAnimator: High-Quality Identity-Preserving Human Image Animation</title>
      <link>https://paperswithcode.com/paper/stableanimator-high-quality-identity</link>
      <description><![CDATA[During inference, we propose a novel Hamilton-Jacobi-Bellman (HJB) equation-based optimization to further enhance the face quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stableanimator-high-quality-identity</guid>
    </item>
    <item>
      <title>SynCamMaster: Synchronizing Multi-Camera Video Generation from Diverse Viewpoints</title>
      <link>https://paperswithcode.com/paper/syncammaster-synchronizing-multi-camera-video</link>
      <description><![CDATA[Recent advancements in video diffusion models have shown exceptional abilities in simulating real-world dynamics and maintaining 3D consistency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/syncammaster-synchronizing-multi-camera-video</guid>
    </item>
    <item>
      <title>LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods</title>
      <link>https://paperswithcode.com/paper/llms-as-judges-a-comprehensive-survey-on-llm</link>
      <description><![CDATA[Finally, we provide a detailed analysis of the limitations of LLM judges and discuss potential future directions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llms-as-judges-a-comprehensive-survey-on-llm</guid>
    </item>
    <item>
      <title>HunyuanVideo: A Systematic Framework For Large Video Generative Models</title>
      <link>https://paperswithcode.com/paper/hunyuanvideo-a-systematic-framework-for-large</link>
      <description><![CDATA[In this report, we introduce HunyuanVideo, an innovative open-source video foundation model that demonstrates performance in video generation comparable to, or even surpassing, that of leading closed-source models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuanvideo-a-systematic-framework-for-large</guid>
    </item>
    <item>
      <title>OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations</title>
      <link>https://paperswithcode.com/paper/omnidocbench-benchmarking-diverse-pdf</link>
      <description><![CDATA[Document content extraction is crucial in computer vision, especially for meeting the high-quality data needs of large language models (LLMs) and retrieval-augmented generation (RAG) technologies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnidocbench-benchmarking-diverse-pdf</guid>
    </item>
    <item>
      <title>SSL4EO-L: Datasets and Foundation Models for Landsat Imagery</title>
      <link>https://paperswithcode.com/paper/ssl4eo-l-datasets-and-foundation-models-for-1</link>
      <description><![CDATA[The Landsat program is the longest-running Earth observation program in history, with 50+ years of data acquisition by 8 satellites.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ssl4eo-l-datasets-and-foundation-models-for-1</guid>
    </item>
    <item>
      <title>Towards Controllable Speech Synthesis in the Era of Large Language Models: A Survey</title>
      <link>https://paperswithcode.com/paper/towards-controllable-speech-synthesis-in-the</link>
      <description><![CDATA[In this paper, we conduct a comprehensive survey of controllable TTS, covering approaches ranging from basic control techniques to methods utilizing natural language prompts, aiming to provide a clear understanding of the current state of research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-controllable-speech-synthesis-in-the</guid>
    </item>
    <item>
      <title>Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</link>
      <description><![CDATA[We present Infinity, a Bitwise Visual AutoRegressive Modeling capable of generating high-resolution, photorealistic images following language instruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</guid>
    </item>
    <item>
      <title>o1-Coder: an o1 Replication for Coding</title>
      <link>https://paperswithcode.com/paper/o1-coder-an-o1-replication-for-coding</link>
      <description><![CDATA[The technical report introduces O1-CODER, an attempt to replicate OpenAI's o1 model with a focus on coding tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/o1-coder-an-o1-replication-for-coding</guid>
    </item>
    <item>
      <title>ReFT: Representation Finetuning for Language Models</title>
      <link>https://paperswithcode.com/paper/reft-representation-finetuning-for-language</link>
      <description><![CDATA[We define a strong instance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT), and we identify an ablation of this method that trades some performance for increased efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reft-representation-finetuning-for-language</guid>
    </item>
    <item>
      <title>One Diffusion to Generate Them All</title>
      <link>https://paperswithcode.com/paper/one-diffusion-to-generate-them-all</link>
      <description><![CDATA[Experimental results demonstrate competitive performance across tasks in both generation and prediction such as text-to-image, multiview generation, ID preservation, depth estimation and camera pose estimation despite relatively small training dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-diffusion-to-generate-them-all</guid>
    </item>
    <item>
      <title>Papers-in-100-Lines-of-Code</title>
      <link>https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code</link>
      <description><![CDATA[Implementation of papers in 100 lines of code.]]></description>
      <guid isPermaLink="true">https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code</guid>
    </item>
    <item>
      <title>[MASK] is All You Need</title>
      <link>https://paperswithcode.com/paper/mask-is-all-you-need</link>
      <description><![CDATA[In summary, by leveraging [MASK] in discrete-state models, we can bridge Masked Generative and Non-autoregressive Diffusion models, as well as generative and discriminative tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mask-is-all-you-need</guid>
    </item>
    <item>
      <title>Momentum-GS: Momentum Gaussian Self-Distillation for High-Quality Large Scene Reconstruction</title>
      <link>https://paperswithcode.com/paper/momentum-gs-momentum-gaussian-self</link>
      <description><![CDATA[To further ensure consistency across the blocks, we incorporate block weighting, dynamically adjusting each block's weight according to its reconstruction accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/momentum-gs-momentum-gaussian-self</guid>
    </item>
    <item>
      <title>mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding</title>
      <link>https://paperswithcode.com/paper/mplug-docowl2-high-resolution-compressing-for</link>
      <description><![CDATA[Multimodel Large Language Models(MLLMs) have achieved promising OCR-free Document Understanding performance by increasing the supported resolution of document images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mplug-docowl2-high-resolution-compressing-for</guid>
    </item>
    <item>
      <title>Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion</title>
      <link>https://paperswithcode.com/paper/florence-vl-enhancing-vision-language-models</link>
      <description><![CDATA[We present Florence-VL, a new family of multimodal large language models (MLLMs) with enriched visual representations produced by Florence-2, a generative vision foundation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/florence-vl-enhancing-vision-language-models</guid>
    </item>
    <item>
      <title>Normalizing Flows are Capable Generative Models</title>
      <link>https://paperswithcode.com/paper/normalizing-flows-are-capable-generative</link>
      <description><![CDATA[Normalizing Flows (NFs) are likelihood-based models for continuous inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/normalizing-flows-are-capable-generative</guid>
    </item>
    <item>
      <title>Agentless: Demystifying LLM-based Software Engineering Agents</title>
      <link>https://paperswithcode.com/paper/agentless-demystifying-llm-based-software</link>
      <description><![CDATA[However, the complexity of these agent-based approaches, together with the limited abilities of current LLMs, raises the following question: Do we really have to employ complex autonomous software agents?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentless-demystifying-llm-based-software</guid>
    </item>
    <item>
      <title>Maya: An Instruction Finetuned Multilingual Multimodal Model</title>
      <link>https://paperswithcode.com/paper/maya-an-instruction-finetuned-multilingual</link>
      <description><![CDATA[The rapid development of large Vision-Language Models (VLMs) has led to impressive results on academic benchmarks, primarily in widely spoken languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maya-an-instruction-finetuned-multilingual</guid>
    </item>
  </channel>
</rss>
