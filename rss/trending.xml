<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 12 Mar 2025 09:17:33 +0000</lastBuildDate>
    <item>
      <title>Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens</title>
      <link>https://paperswithcode.com/paper/2503-01710</link>
      <description><![CDATA[Recent advancements in large language models (LLMs) have driven significant progress in zero-shot text-to-speech (TTS) synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2503-01710</guid>
    </item>
    <item>
      <title>Scaling Synthetic Data Creation with 1,000,000,000 Personas</title>
      <link>https://paperswithcode.com/paper/scaling-synthetic-data-creation-with</link>
      <description><![CDATA[We propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-synthetic-data-creation-with</guid>
    </item>
    <item>
      <title>GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera Control</title>
      <link>https://paperswithcode.com/paper/gen3c-3d-informed-world-consistent-video</link>
      <description><![CDATA[Our results demonstrate more precise camera control than prior work, as well as state-of-the-art results in sparse-view novel view synthesis, even in challenging settings such as driving scenes and monocular dynamic video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gen3c-3d-informed-world-consistent-video</guid>
    </item>
    <item>
      <title>Zero-shot Voice Conversion with Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/zero-shot-voice-conversion-with-diffusion</link>
      <description><![CDATA[Zero-shot voice conversion aims to transform a source speech utterance to match the timbre of a reference speech from an unseen speaker.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-voice-conversion-with-diffusion</guid>
    </item>
    <item>
      <title>Visual-RFT: Visual Reinforcement Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/visual-rft-visual-reinforcement-fine-tuning</link>
      <description><![CDATA[Reinforcement Fine-Tuning (RFT) in Large Reasoning Models like OpenAI o1 learns from feedback on its answers, which is especially useful in applications when fine-tuning data is scarce.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-rft-visual-reinforcement-fine-tuning</guid>
    </item>
    <item>
      <title>olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models</title>
      <link>https://paperswithcode.com/paper/olmocr-unlocking-trillions-of-tokens-in-pdfs</link>
      <description><![CDATA[PDF documents have the potential to provide trillions of novel, high-quality tokens for training language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/olmocr-unlocking-trillions-of-tokens-in-pdfs</guid>
    </item>
    <item>
      <title>Residual Kolmogorov-Arnold Network for Enhanced Deep Learning</title>
      <link>https://paperswithcode.com/paper/residual-kolmogorov-arnold-network-for</link>
      <description><![CDATA[Despite the strong performance in many computer vision tasks, Convolutional Neural Networks (CNNs) can sometimes struggle to efficiently capture long-range, complex non-linear dependencies in deeper layers of the network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/residual-kolmogorov-arnold-network-for</guid>
    </item>
    <item>
      <title>DeepRetrieval: Powerful Query Generation for Information Retrieval with Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/deepretrieval-powerful-query-generation-for</link>
      <description><![CDATA[Information retrieval systems are crucial for enabling effective access to large document collections.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepretrieval-powerful-query-generation-for</guid>
    </item>
    <item>
      <title>Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation</title>
      <link>https://paperswithcode.com/paper/kiss3dgen-repurposing-image-diffusion-models</link>
      <description><![CDATA[The normal maps are then used to reconstruct a 3D mesh, and the multi-view images provide texture mapping, resulting in a complete 3D model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kiss3dgen-repurposing-image-diffusion-models</guid>
    </item>
    <item>
      <title>A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-of-graph-retrieval-augmented</link>
      <description><![CDATA[Large language models (LLMs) have demonstrated remarkable capabilities in a wide range of tasks, yet their application to specialized domains remains challenging due to the need for deep expertise.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-graph-retrieval-augmented</guid>
    </item>
    <item>
      <title>MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents</title>
      <link>https://paperswithcode.com/paper/multiagentbench-evaluating-the-collaboration</link>
      <description><![CDATA[Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents, yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiagentbench-evaluating-the-collaboration</guid>
    </item>
    <item>
      <title>CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents</title>
      <link>https://paperswithcode.com/paper/crab-cross-environment-agent-benchmark-for</link>
      <description><![CDATA[Leveraging Crab, we developed a cross-platform Crab Benchmark-v0 comprising 120 tasks in computer desktop and mobile phone environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/crab-cross-environment-agent-benchmark-for</guid>
    </item>
    <item>
      <title>Self-rewarding correction for mathematical reasoning</title>
      <link>https://paperswithcode.com/paper/self-rewarding-correction-for-mathematical</link>
      <description><![CDATA[We study self-rewarding reasoning large language models (LLMs), which can simultaneously generate step-by-step reasoning and evaluate the correctness of their outputs during the inference time-without external feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-rewarding-correction-for-mathematical</guid>
    </item>
    <item>
      <title>Chain of Draft: Thinking Faster by Writing Less</title>
      <link>https://paperswithcode.com/paper/chain-of-draft-thinking-faster-by-writing</link>
      <description><![CDATA[Large Language Models (LLMs) have demonstrated remarkable performance in solving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT) prompting, which emphasizes verbose, step-by-step reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chain-of-draft-thinking-faster-by-writing</guid>
    </item>
    <item>
      <title>OASIS: Open Agent Social Interaction Simulations with One Million Agents</title>
      <link>https://paperswithcode.com/paper/oasis-open-agents-social-interaction</link>
      <description><![CDATA[There has been a growing interest in enhancing rule-based agent-based models (ABMs) for social media platforms (i. e., X, Reddit) with more realistic large language model (LLM) agents, thereby allowing for a more nuanced study of complex systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oasis-open-agents-social-interaction</guid>
    </item>
    <item>
      <title>Proximal Policy Optimization Algorithms</title>
      <link>https://paperswithcode.com/paper/proximal-policy-optimization-algorithms</link>
      <description><![CDATA[We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proximal-policy-optimization-algorithms</guid>
    </item>
    <item>
      <title>Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</title>
      <link>https://paperswithcode.com/paper/switch-transformers-scaling-to-trillion</link>
      <description><![CDATA[We design models based off T5-Base and T5-Large to obtain up to 7x increases in pre-training speed with the same computational resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/switch-transformers-scaling-to-trillion</guid>
    </item>
    <item>
      <title>HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation</title>
      <link>https://paperswithcode.com/paper/healthgpt-a-medical-large-vision-language</link>
      <description><![CDATA[To effectively learn the HealthGPT, we devise a comprehensive medical domain-specific comprehension and generation dataset called VL-Health.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/healthgpt-a-medical-large-vision-language</guid>
    </item>
    <item>
      <title>Magma: A Foundation Model for Multimodal AI Agents</title>
      <link>https://paperswithcode.com/paper/magma-a-foundation-model-for-multimodal-ai</link>
      <description><![CDATA[We present Magma, a foundation model that serves multimodal AI agentic tasks in both the digital and physical worlds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magma-a-foundation-model-for-multimodal-ai</guid>
    </item>
    <item>
      <title>UnCommon Objects in 3D</title>
      <link>https://paperswithcode.com/paper/uncommon-objects-in-3d</link>
      <description><![CDATA[We introduce Uncommon Objects in 3D (uCO3D), a new object-centric dataset for 3D deep learning and 3D generative AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncommon-objects-in-3d</guid>
    </item>
  </channel>
</rss>
