<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 25 Nov 2023 21:06:00 +0000</lastBuildDate>
    <item>
      <title>StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models</title>
      <link>https://paperswithcode.com/paper/styletts-2-towards-human-level-text-to-speech</link>
      <description><![CDATA[In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that leverages style diffusion and adversarial training with large speech language models (SLMs) to achieve human-level TTS synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/styletts-2-towards-human-level-text-to-speech</guid>
    </item>
    <item>
      <title>Video-LLaVA: Learning United Visual Representation by Alignment Before Projection</title>
      <link>https://paperswithcode.com/paper/video-llava-learning-united-visual-1</link>
      <description><![CDATA[In this work, we unify visual representation into the language feature space to advance the foundational LLM towards a unified LVLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-llava-learning-united-visual-1</guid>
    </item>
    <item>
      <title>Exponentially Faster Language Modelling</title>
      <link>https://paperswithcode.com/paper/exponentially-faster-language-modelling</link>
      <description><![CDATA[Language models only really need to use an exponential fraction of their neurons for individual inferences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exponentially-faster-language-modelling</guid>
    </item>
    <item>
      <title>LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching</title>
      <link>https://paperswithcode.com/paper/luciddreamer-towards-high-fidelity-text-to-3d</link>
      <description><![CDATA[The recent advancements in text-to-3D generation mark a significant milestone in generative models, unlocking new possibilities for creating imaginative 3D assets across various real-world scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/luciddreamer-towards-high-fidelity-text-to-3d</guid>
    </item>
    <item>
      <title>Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models</title>
      <link>https://paperswithcode.com/paper/concept-sliders-lora-adaptors-for-precise</link>
      <description><![CDATA[We present a method to create interpretable concept sliders that enable precise control over attributes in image generations from diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/concept-sliders-lora-adaptors-for-precise</guid>
    </item>
    <item>
      <title>Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion</title>
      <link>https://paperswithcode.com/paper/diffuse-attend-and-segment-unsupervised-zero</link>
      <description><![CDATA[The proposed method does not require any training or language dependency to extract quality segmentation for any images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffuse-attend-and-segment-unsupervised-zero</guid>
    </item>
    <item>
      <title>Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets</title>
      <link>https://paperswithcode.com/paper/stable-video-diffusion-scaling-latent-video</link>
      <description><![CDATA[We present Stable Video Diffusion â€” a latent video diffusion model for high-resolution, state-of-the-art text-to-video and image-to-video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stable-video-diffusion-scaling-latent-video</guid>
    </item>
    <item>
      <title>HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis</title>
      <link>https://paperswithcode.com/paper/hierspeech-bridging-the-gap-between-semantic</link>
      <description><![CDATA[Furthermore, we significantly improve the naturalness and speaker similarity of synthetic speech even in zero-shot speech synthesis scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierspeech-bridging-the-gap-between-semantic</guid>
    </item>
    <item>
      <title>minimax: Efficient Baselines for Autocurricula in JAX</title>
      <link>https://paperswithcode.com/paper/minimax-efficient-baselines-for-autocurricula</link>
      <description><![CDATA[This compute requirement is a major obstacle to rapid innovation for the field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minimax-efficient-baselines-for-autocurricula</guid>
    </item>
    <item>
      <title>Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents</title>
      <link>https://paperswithcode.com/paper/igniting-language-intelligence-the-hitchhiker</link>
      <description><![CDATA[Large language models (LLMs) have dramatically enhanced the field of language intelligence, as demonstrably evidenced by their formidable empirical performance across a spectrum of complex reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/igniting-language-intelligence-the-hitchhiker</guid>
    </item>
    <item>
      <title>Stella Nera: Achieving 161 TOp/s/W with Multiplier-free DNN Acceleration based on Approximate Matrix Multiplication</title>
      <link>https://paperswithcode.com/paper/stella-nera-achieving-161-top-s-w-with</link>
      <description><![CDATA[From classical HPC to deep learning, MatMul is at the heart of today's computing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stella-nera-achieving-161-top-s-w-with</guid>
    </item>
    <item>
      <title>MagicDance: Realistic Human Dance Video Generation with Motions &amp; Facial Expressions Transfer</title>
      <link>https://paperswithcode.com/paper/magicdance-realistic-human-dance-video</link>
      <description><![CDATA[In this work, we propose MagicDance, a diffusion-based model for 2D human motion and facial expression transfer on challenging human dance videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magicdance-realistic-human-dance-video</guid>
    </item>
    <item>
      <title>Improving Sample Quality of Diffusion Models Using Self-Attention Guidance</title>
      <link>https://paperswithcode.com/paper/improving-sample-quality-of-diffusion-model</link>
      <description><![CDATA[Denoising diffusion models (DDMs) have attracted attention for their exceptional generation quality and diversity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-sample-quality-of-diffusion-model</guid>
    </item>
    <item>
      <title>JaxMARL: Multi-Agent RL Environments in JAX</title>
      <link>https://paperswithcode.com/paper/jaxmarl-multi-agent-rl-environments-in-jax</link>
      <description><![CDATA[This not only enables GPU acceleration, but also provides a more flexible MARL environment, unlocking the potential for self-play, meta-learning, and other future applications in MARL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/jaxmarl-multi-agent-rl-environments-in-jax</guid>
    </item>
    <item>
      <title>A Survey on Language Models for Code</title>
      <link>https://paperswithcode.com/paper/a-survey-on-language-models-for-code</link>
      <description><![CDATA[In this work we systematically review the recent advancements in code processing with language models, covering 50+ models, 30+ evaluation tasks, 150+ datasets, and 550 related works.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-language-models-for-code</guid>
    </item>
    <item>
      <title>Saturn: An Optimized Data System for Large Model Deep Learning Workloads</title>
      <link>https://paperswithcode.com/paper/saturn-an-optimized-data-system-for-large</link>
      <description><![CDATA[Such models need multiple GPUs due to both their size and computational load, driving the development of a bevy of "model parallelism" techniques & tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/saturn-an-optimized-data-system-for-large</guid>
    </item>
    <item>
      <title>ShareGPT4V: Improving Large Multi-Modal Models with Better Captions</title>
      <link>https://paperswithcode.com/paper/sharegpt4v-improving-large-multi-modal-models</link>
      <description><![CDATA[In the realm of large multi-modal models (LMMs), efficient modality alignment is crucial yet often constrained by the scarcity of high-quality image-text data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sharegpt4v-improving-large-multi-modal-models</guid>
    </item>
    <item>
      <title>Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey</title>
      <link>https://paperswithcode.com/paper/advancing-transformer-architecture-in-long</link>
      <description><![CDATA[With the bomb ignited by ChatGPT, Transformer-based Large Language Models (LLMs) have paved a revolutionary path toward Artificial General Intelligence (AGI) and have been applied in diverse areas as knowledge bases, human interfaces, and dynamic agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-transformer-architecture-in-long</guid>
    </item>
    <item>
      <title>SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction</title>
      <link>https://paperswithcode.com/paper/selfocc-self-supervised-vision-based-3d</link>
      <description><![CDATA[Our SelfOcc outperforms the previous best method SceneRF by 58. 7% using a single frame as input on SemanticKITTI and is the first self-supervised work that produces reasonable 3D occupancy for surround cameras on Occ3D.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/selfocc-self-supervised-vision-based-3d</guid>
    </item>
    <item>
      <title>LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning</title>
      <link>https://paperswithcode.com/paper/lq-lora-low-rank-plus-quantized-matrix</link>
      <description><![CDATA[Our approach uses an iterative algorithm to decompose each pretrained matrix into a high-precision low-rank component and a memory-efficient quantized component.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lq-lora-low-rank-plus-quantized-matrix</guid>
    </item>
  </channel>
</rss>
