<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 24 Jun 2023 09:12:26 +0000</lastBuildDate>
    <item>
      <title>Fast Segment Anything</title>
      <link>https://paperswithcode.com/paper/fast-segment-anything</link>
      <description><![CDATA[In this paper, we propose a speed-up alternative method for this fundamental task with comparable performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-segment-anything</guid>
    </item>
    <item>
      <title>Full Parameter Fine-tuning for Large Language Models with Limited Resources</title>
      <link>https://paperswithcode.com/paper/full-parameter-fine-tuning-for-large-language</link>
      <description><![CDATA[Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but demand massive GPU resources for training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/full-parameter-fine-tuning-for-large-language</guid>
    </item>
    <item>
      <title>FinGPT: Open-Source Financial Large Language Models</title>
      <link>https://paperswithcode.com/paper/fingpt-open-source-financial-large-language</link>
      <description><![CDATA[While proprietary models like BloombergGPT have taken advantage of their unique data accumulation, such privileged access calls for an open-source alternative to democratize Internet-scale financial data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fingpt-open-source-financial-large-language</guid>
    </item>
    <item>
      <title>A Simple and Effective Pruning Approach for Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-simple-and-effective-pruning-approach-for</link>
      <description><![CDATA[Motivated by the recent observation of emergent large magnitude features in LLMs, our approach prune weights with the smallest magnitudes multiplied by the corresponding input activations, on a per-output basis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-simple-and-effective-pruning-approach-for</guid>
    </item>
    <item>
      <title>Planning-oriented Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/goal-oriented-autonomous-driving</link>
      <description><![CDATA[Oriented at this, we revisit the key components within perception and prediction, and prioritize the tasks such that all these tasks contribute to planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/goal-oriented-autonomous-driving</guid>
    </item>
    <item>
      <title>WizardCoder: Empowering Code Large Language Models with Evol-Instruct</title>
      <link>https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language</link>
      <description><![CDATA[Moreover, our model even outperforms the largest closed LLMs, Anthropic's Claude and Google's Bard, on HumanEval and HumanEval+.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language</guid>
    </item>
    <item>
      <title>On the Benefits of 3D Pose and Tracking for Human Action Recognition</title>
      <link>https://paperswithcode.com/paper/on-the-benefits-of-3d-pose-and-tracking-for</link>
      <description><![CDATA[Subsequently, we propose a Lagrangian Action Recognition model by fusing 3D pose and contextualized appearance over tracklets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-benefits-of-3d-pose-and-tracking-for</guid>
    </item>
    <item>
      <title>PyRCA: A Library for Metric-based Root Cause Analysis</title>
      <link>https://paperswithcode.com/paper/pyrca-a-library-for-metric-based-root-cause</link>
      <description><![CDATA[We introduce PyRCA, an open-source Python machine learning library of Root Cause Analysis (RCA) for Artificial Intelligence for IT Operations (AIOps).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pyrca-a-library-for-metric-based-root-cause</guid>
    </item>
    <item>
      <title>WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences</title>
      <link>https://paperswithcode.com/paper/webglm-towards-an-efficient-web-enhanced</link>
      <description><![CDATA[We present WebGLM, a web-enhanced question-answering system based on the General Language Model (GLM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/webglm-towards-an-efficient-web-enhanced</guid>
    </item>
    <item>
      <title>BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Models</title>
      <link>https://paperswithcode.com/paper/bayling-bridging-cross-lingual-alignment-and</link>
      <description><![CDATA[To minimize human workload, we propose to transfer the capabilities of language generation and instruction following from English to other languages through an interactive translation task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bayling-bridging-cross-lingual-alignment-and</guid>
    </item>
    <item>
      <title>Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture</title>
      <link>https://paperswithcode.com/paper/self-supervised-learning-from-images-with-a</link>
      <description><![CDATA[This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-learning-from-images-with-a</guid>
    </item>
    <item>
      <title>EasySpider: A No-Code Visual System for Crawling the Web</title>
      <link>https://paperswithcode.com/paper/easyspider-a-no-code-visual-system-for</link>
      <description><![CDATA[As such, web-crawling is an essential tool for both computational and non-computational scientists to conduct research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyspider-a-no-code-visual-system-for</guid>
    </item>
    <item>
      <title>ChemCrow: Augmenting large-language models with chemistry tools</title>
      <link>https://paperswithcode.com/paper/chemcrow-augmenting-large-language-models</link>
      <description><![CDATA[Over the last decades, excellent computational chemistry tools have been developed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chemcrow-augmenting-large-language-models</guid>
    </item>
    <item>
      <title>MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing</title>
      <link>https://paperswithcode.com/paper/magicbrush-a-manually-annotated-dataset-for</link>
      <description><![CDATA[To address this issue, we introduce MagicBrush (https://osu-nlp-group. github. io/MagicBrush/), the first large-scale, manually annotated dataset for instruction-guided real image editing that covers diverse scenarios: single-turn, multi-turn, mask-provided, and mask-free editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magicbrush-a-manually-annotated-dataset-for</guid>
    </item>
    <item>
      <title>Fast Training of Diffusion Models with Masked Transformers</title>
      <link>https://paperswithcode.com/paper/fast-training-of-diffusion-models-with-masked</link>
      <description><![CDATA[For masked training, we introduce an asymmetric encoder-decoder architecture consisting of a transformer encoder that operates only on unmasked patches and a lightweight transformer decoder on full patches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-training-of-diffusion-models-with-masked</guid>
    </item>
    <item>
      <title>h2oGPT: Democratizing Large Language Models</title>
      <link>https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models</link>
      <description><![CDATA[Applications built on top of Large Language Models (LLMs) such as GPT-4 represent a revolution in AI due to their human-level capabilities in natural language processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models</guid>
    </item>
    <item>
      <title>PP-LiteSeg: A Superior Real-Time Semantic Segmentation Model</title>
      <link>https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</link>
      <description><![CDATA[Real-world applications have high demands for semantic segmentation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</guid>
    </item>
    <item>
      <title>LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model</title>
      <link>https://paperswithcode.com/paper/llama-adapter-v2-parameter-efficient-visual</link>
      <description><![CDATA[This strategy effectively alleviates the interference between the two tasks of image-text alignment and instruction following and achieves strong multi-modal reasoning with only a small-scale image-text and instruction dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-adapter-v2-parameter-efficient-visual</guid>
    </item>
    <item>
      <title>Simple and Controllable Music Generation</title>
      <link>https://paperswithcode.com/paper/simple-and-controllable-music-generation</link>
      <description><![CDATA[We tackle the task of conditional music generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simple-and-controllable-music-generation</guid>
    </item>
    <item>
      <title>TAP-Vid: A Benchmark for Tracking Any Point in a Video</title>
      <link>https://paperswithcode.com/paper/tap-vid-a-benchmark-for-tracking-any-point-in</link>
      <description><![CDATA[Generic motion understanding from video involves not only tracking objects, but also perceiving how their surfaces deform and move.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tap-vid-a-benchmark-for-tracking-any-point-in</guid>
    </item>
  </channel>
</rss>
