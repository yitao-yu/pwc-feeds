<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 03 Feb 2025 21:08:39 +0000</lastBuildDate>
    <item>
      <title>Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling</title>
      <link>https://paperswithcode.com/paper/janus-pro-unified-multimodal-understanding</link>
      <description><![CDATA[In this work, we introduce Janus-Pro, an advanced version of the previous work Janus.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/janus-pro-unified-multimodal-understanding</guid>
    </item>
    <item>
      <title>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</link>
      <description><![CDATA[We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</guid>
    </item>
    <item>
      <title>Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution</title>
      <link>https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</link>
      <description><![CDATA[We present the Qwen2-VL Series, an advanced upgrade of the previous Qwen-VL models that redefines the conventional predetermined-resolution approach in visual processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</guid>
    </item>
    <item>
      <title>Flaming-hot Initiation with Regular Execution Sampling for Large Language Models</title>
      <link>https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</link>
      <description><![CDATA[Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</guid>
    </item>
    <item>
      <title>DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</link>
      <description><![CDATA[We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</guid>
    </item>
    <item>
      <title>DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence</title>
      <link>https://paperswithcode.com/paper/deepseek-coder-v2-breaking-the-barrier-of</link>
      <description><![CDATA[Through this continued pre-training, DeepSeek-Coder-V2 substantially enhances the coding and mathematical reasoning capabilities of DeepSeek-V2, while maintaining comparable performance in general language tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-coder-v2-breaking-the-barrier-of</guid>
    </item>
    <item>
      <title>DeepSeek-V3 Technical Report</title>
      <link>https://paperswithcode.com/paper/deepseek-v3-technical-report</link>
      <description><![CDATA[We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-v3-technical-report</guid>
    </item>
    <item>
      <title>Qwen2.5 Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-5-technical-report</link>
      <description><![CDATA[In addition, for hosted solutions, the proprietary models currently include two mixture-of-experts (MoE) variants: Qwen2. 5-Turbo and Qwen2. 5-Plus, both available from Alibaba Cloud Model Studio.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-5-technical-report</guid>
    </item>
    <item>
      <title>Qwen2 Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-technical-report</link>
      <description><![CDATA[This report introduces the Qwen2 series, the latest addition to our large language models and large multimodal models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-technical-report</guid>
    </item>
    <item>
      <title>DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</title>
      <link>https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</link>
      <description><![CDATA[Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</guid>
    </item>
    <item>
      <title>DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior</title>
      <link>https://paperswithcode.com/paper/dreamcraft3d-hierarchical-3d-generation-with</link>
      <description><![CDATA[The score distillation from this 3D-aware diffusion prior provides view-consistent guidance for the scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamcraft3d-hierarchical-3d-generation-with</guid>
    </item>
    <item>
      <title>Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation</title>
      <link>https://paperswithcode.com/paper/hunyuan3d-2-0-scaling-diffusion-models-for</link>
      <description><![CDATA[This system includes two foundation components: a large-scale shape generation model -- Hunyuan3D-DiT, and a large-scale texture synthesis model -- Hunyuan3D-Paint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuan3d-2-0-scaling-diffusion-models-for</guid>
    </item>
    <item>
      <title>DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence</title>
      <link>https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</link>
      <description><![CDATA[The rapid development of large language models has revolutionized code intelligence in software development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</guid>
    </item>
    <item>
      <title>Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models</title>
      <link>https://paperswithcode.com/paper/let-the-expert-stick-to-his-last-expert</link>
      <description><![CDATA[In this work, we study the PEFT method for LLMs with the Mixture-of-Experts (MoE) architecture and the contents of this work are mainly threefold: (1) We investigate the dispersion degree of the activated experts in customized tasks, and found that the routing distribution for a specific task tends to be highly concentrated, while the distribution of activated experts varies significantly across different tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-the-expert-stick-to-his-last-expert</guid>
    </item>
    <item>
      <title>Stable Flow: Vital Layers for Training-Free Image Editing</title>
      <link>https://paperswithcode.com/paper/stable-flow-vital-layers-for-training-free</link>
      <description><![CDATA[The main challenge is that, unlike the UNet-based models, DiT lacks a coarse-to-fine synthesis structure, making it unclear in which layers to perform the injection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stable-flow-vital-layers-for-training-free</guid>
    </item>
    <item>
      <title>DeepSeek LLM: Scaling Open-Source Language Models with Longtermism</title>
      <link>https://paperswithcode.com/paper/deepseek-llm-scaling-open-source-language</link>
      <description><![CDATA[The rapid development of open-source large language models (LLMs) has been truly remarkable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-llm-scaling-open-source-language</guid>
    </item>
    <item>
      <title>IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems</title>
      <link>https://paperswithcode.com/paper/intellagent-a-multi-agent-framework-for</link>
      <description><![CDATA[IntellAgent represents a paradigm shift in evaluating conversational AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intellagent-a-multi-agent-framework-for</guid>
    </item>
    <item>
      <title>DeepSeek-VL: Towards Real-World Vision-Language Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl-towards-real-world-vision</link>
      <description><![CDATA[The DeepSeek-VL family (both 1. 3B and 7B models) showcases superior user experiences as a vision-language chatbot in real-world applications, achieving state-of-the-art or competitive performance across a wide range of visual-language benchmarks at the same model size while maintaining robust performance on language-centric benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl-towards-real-world-vision</guid>
    </item>
    <item>
      <title>Qwen2.5-Coder Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-5-coder-technical-report</link>
      <description><![CDATA[In this report, we introduce the Qwen2. 5-Coder series, a significant upgrade from its predecessor, CodeQwen1. 5.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-5-coder-technical-report</guid>
    </item>
    <item>
      <title>PaSa: An LLM Agent for Comprehensive Academic Paper Search</title>
      <link>https://paperswithcode.com/paper/pasa-an-llm-agent-for-comprehensive-academic</link>
      <description><![CDATA[Notably, PaSa-7B surpasses the best Google-based baseline, Google with GPT-4o, by 37. 78% in recall@20 and 39. 90% in recall@50.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pasa-an-llm-agent-for-comprehensive-academic</guid>
    </item>
  </channel>
</rss>
