<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 27 Jan 2024 09:10:38 +0000</lastBuildDate>
    <item>
      <title>Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data</title>
      <link>https://paperswithcode.com/paper/depth-anything-unleashing-the-power-of-large</link>
      <description><![CDATA[To this end, we scale up the dataset by designing a data engine to collect and automatically annotate large-scale unlabeled data (~62M), which significantly enlarges the data coverage and thus is able to reduce the generalization error.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depth-anything-unleashing-the-power-of-large</guid>
    </item>
    <item>
      <title>InstantID: Zero-shot Identity-Preserving Generation in Seconds</title>
      <link>https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</link>
      <description><![CDATA[There has been significant progress in personalized image synthesis with methods such as Textual Inversion, DreamBooth, and LoRA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</guid>
    </item>
    <item>
      <title>Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs</title>
      <link>https://paperswithcode.com/paper/mastering-text-to-image-diffusion</link>
      <description><![CDATA[In this paper, we propose a brand new training-free text-to-image generation/editing framework, namely Recaption, Plan and Generate (RPG), harnessing the powerful chain-of-thought reasoning ability of multimodal LLMs to enhance the compositionality of text-to-image diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mastering-text-to-image-diffusion</guid>
    </item>
    <item>
      <title>Self-Rewarding Language Models</title>
      <link>https://paperswithcode.com/paper/self-rewarding-language-models</link>
      <description><![CDATA[We posit that to achieve superhuman agents, future models require superhuman feedback in order to provide an adequate training signal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-rewarding-language-models</guid>
    </item>
    <item>
      <title>Orion-14B: Open-source Multilingual Large Language Models</title>
      <link>https://paperswithcode.com/paper/orion-14b-open-source-multilingual-large</link>
      <description><![CDATA[In this study, we introduce Orion-14B, a collection of multilingual large language models with 14 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/orion-14b-open-source-multilingual-large</guid>
    </item>
    <item>
      <title>Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering</title>
      <link>https://paperswithcode.com/paper/code-generation-with-alphacodium-from-prompt</link>
      <description><![CDATA[Hence, many of the optimizations and tricks that have been successful in natural language generation may not be effective for code tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/code-generation-with-alphacodium-from-prompt</guid>
    </item>
    <item>
      <title>HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance</title>
      <link>https://paperswithcode.com/paper/huixiangdou-overcoming-group-chat-scenarios</link>
      <description><![CDATA[In this work, we present HuixiangDou, a technical assistant powered by Large Language Models (LLM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huixiangdou-overcoming-group-chat-scenarios</guid>
    </item>
    <item>
      <title>VMamba: Visual State Space Model</title>
      <link>https://paperswithcode.com/paper/vmamba-visual-state-space-model</link>
      <description><![CDATA[Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) stand as the two most popular foundation models for visual representation learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vmamba-visual-state-space-model</guid>
    </item>
    <item>
      <title>Benchmarking LLMs via Uncertainty Quantification</title>
      <link>https://paperswithcode.com/paper/benchmarking-llms-via-uncertainty</link>
      <description><![CDATA[The proliferation of open-source Large Language Models (LLMs) from various institutions has highlighted the urgent need for comprehensive evaluation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-llms-via-uncertainty</guid>
    </item>
    <item>
      <title>Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model</title>
      <link>https://paperswithcode.com/paper/vision-mamba-efficient-visual-representation</link>
      <description><![CDATA[The results demonstrate that Vim is capable of overcoming the computation & memory constraints on performing Transformer-style understanding for high-resolution images and it has great potential to become the next-generation backbone for vision foundation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-mamba-efficient-visual-representation</guid>
    </item>
    <item>
      <title>TaskWeaver: A Code-First Agent Framework</title>
      <link>https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</link>
      <description><![CDATA[TaskWeaver provides support for rich data structures, flexible plugin usage, and dynamic plugin selection, and leverages LLM coding capabilities for complex logic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</guid>
    </item>
    <item>
      <title>DrugAssist: A Large Language Model for Molecule Optimization</title>
      <link>https://paperswithcode.com/paper/drugassist-a-large-language-model-for</link>
      <description><![CDATA[Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drugassist-a-large-language-model-for</guid>
    </item>
    <item>
      <title>AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents</title>
      <link>https://paperswithcode.com/paper/agentboard-an-analytical-evaluation-board-of</link>
      <description><![CDATA[Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentboard-an-analytical-evaluation-board-of</guid>
    </item>
    <item>
      <title>Segment Anything in Medical Images</title>
      <link>https://paperswithcode.com/paper/segment-anything-in-medical-images</link>
      <description><![CDATA[Medical image segmentation is a critical component in clinical practice, facilitating accurate diagnosis, treatment planning, and disease monitoring.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-anything-in-medical-images</guid>
    </item>
    <item>
      <title>TorchRL: A data-driven decision-making library for PyTorch</title>
      <link>https://paperswithcode.com/paper/torchrl-a-data-driven-decision-making-library</link>
      <description><![CDATA[PyTorch has ascended as a premier machine learning framework, yet it lacks a native and comprehensive library for decision and control tasks suitable for large development teams dealing with complex real-world data and environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchrl-a-data-driven-decision-making-library</guid>
    </item>
    <item>
      <title>DiffMoog: a Differentiable Modular Synthesizer for Sound Matching</title>
      <link>https://paperswithcode.com/paper/diffmoog-a-differentiable-modular-synthesizer</link>
      <description><![CDATA[We introduce an open-source platform that comprises DiffMoog and an end-to-end sound matching framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffmoog-a-differentiable-modular-synthesizer</guid>
    </item>
    <item>
      <title>OMG-Seg: Is One Model Good Enough For All Segmentation?</title>
      <link>https://paperswithcode.com/paper/omg-seg-is-one-model-good-enough-for-all</link>
      <description><![CDATA[In this work, we address various segmentation tasks, each traditionally tackled by distinct or partially unified models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omg-seg-is-one-model-good-enough-for-all</guid>
    </item>
    <item>
      <title>PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding</title>
      <link>https://paperswithcode.com/paper/photomaker-customizing-realistic-human-photos</link>
      <description><![CDATA[Recent advances in text-to-image generation have made remarkable progress in synthesizing realistic human photos conditioned on given text prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photomaker-customizing-realistic-human-photos</guid>
    </item>
    <item>
      <title>SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/segmamba-long-range-sequential-modeling-mamba</link>
      <description><![CDATA[Our SegMamba, in contrast to Transformer-based methods, excels in whole volume feature modeling from a state space model standpoint, maintaining superior processing speed, even with volume features at a resolution of {$64\times 64\times 64$}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segmamba-long-range-sequential-modeling-mamba</guid>
    </item>
    <item>
      <title>Elucidating the Design Space of Diffusion-Based Generative Models</title>
      <link>https://paperswithcode.com/paper/elucidating-the-design-space-of-diffusion</link>
      <description><![CDATA[We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elucidating-the-design-space-of-diffusion</guid>
    </item>
  </channel>
</rss>
