<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 01 Dec 2023 09:12:32 +0000</lastBuildDate>
    <item>
      <title>YUAN 2.0: A Large Language Model with Localized Filtering-based Attention</title>
      <link>https://paperswithcode.com/paper/yuan-2-0-a-large-language-model-with</link>
      <description><![CDATA[In this work, the Localized Filtering-based Attention (LFA) is introduced to incorporate prior knowledge of local dependencies of natural language into Attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yuan-2-0-a-large-language-model-with</guid>
    </item>
    <item>
      <title>Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating Video-based Large Language Models</title>
      <link>https://paperswithcode.com/paper/video-bench-a-comprehensive-benchmark-and</link>
      <description><![CDATA[Video-based large language models (Video-LLMs) have been recently introduced, targeting both fundamental improvements in perception and comprehension, and a diverse range of user inquiries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-bench-a-comprehensive-benchmark-and</guid>
    </item>
    <item>
      <title>Scalable AI Safety via Doubly-Efficient Debate</title>
      <link>https://paperswithcode.com/paper/scalable-ai-safety-via-doubly-efficient</link>
      <description><![CDATA[The emergence of pre-trained AI systems with powerful capabilities across a diverse and ever-increasing set of complex domains has raised a critical challenge for AI safety as tasks can become too complicated for humans to judge directly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-ai-safety-via-doubly-efficient</guid>
    </item>
    <item>
      <title>LCM-LoRA: A Universal Stable-Diffusion Acceleration Module</title>
      <link>https://paperswithcode.com/paper/lcm-lora-a-universal-stable-diffusion</link>
      <description><![CDATA[Latent Consistency Models (LCMs) have achieved impressive performance in accelerating text-to-image generative tasks, producing high-quality images with minimal inference steps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lcm-lora-a-universal-stable-diffusion</guid>
    </item>
    <item>
      <title>Adversarial Diffusion Distillation</title>
      <link>https://paperswithcode.com/paper/adversarial-diffusion-distillation</link>
      <description><![CDATA[We introduce Adversarial Diffusion Distillation (ADD), a novel training approach that efficiently samples large-scale foundational image diffusion models in just 1-4 steps while maintaining high image quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-diffusion-distillation</guid>
    </item>
    <item>
      <title>Instruction Tuning with Human Curriculum</title>
      <link>https://paperswithcode.com/paper/instruction-tuning-with-human-curriculum</link>
      <description><![CDATA[The dominant paradigm for instruction tuning is the random-shuffled training of maximally diverse instruction-response pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instruction-tuning-with-human-curriculum</guid>
    </item>
    <item>
      <title>OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/occworld-learning-a-3d-occupancy-world-model</link>
      <description><![CDATA[In this paper, we explore a new framework of learning a world model, OccWorld, in the 3D Occupancy space to simultaneously predict the movement of the ego car and the evolution of the surrounding scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/occworld-learning-a-3d-occupancy-world-model</guid>
    </item>
    <item>
      <title>Animatable Gaussians: Learning Pose-dependent Gaussian Maps for High-fidelity Human Avatar Modeling</title>
      <link>https://paperswithcode.com/paper/animatable-gaussians-learning-pose-dependent</link>
      <description><![CDATA[Overall, our method can create lifelike avatars with dynamic, realistic and generalized appearances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatable-gaussians-learning-pose-dependent</guid>
    </item>
    <item>
      <title>UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio, Video, Point Cloud, Time-Series and Image Recognition</title>
      <link>https://paperswithcode.com/paper/unireplknet-a-universal-perception-large</link>
      <description><![CDATA[1) We propose four architectural guidelines for designing large-kernel ConvNets, the core of which is to exploit the essential characteristics of large kernels that distinguish them from small kernels - they can see wide without going deep.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unireplknet-a-universal-perception-large</guid>
    </item>
    <item>
      <title>Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models</title>
      <link>https://paperswithcode.com/paper/concept-sliders-lora-adaptors-for-precise</link>
      <description><![CDATA[We present a method to create interpretable concept sliders that enable precise control over attributes in image generations from diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/concept-sliders-lora-adaptors-for-precise</guid>
    </item>
    <item>
      <title>Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch</title>
      <link>https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</link>
      <description><![CDATA[Based on this observation, we further sparsify delta parameters of multiple SFT homologous models with DARE and subsequently merge them into a single model by parameter averaging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</guid>
    </item>
    <item>
      <title>Video-LLaVA: Learning United Visual Representation by Alignment Before Projection</title>
      <link>https://paperswithcode.com/paper/video-llava-learning-united-visual-1</link>
      <description><![CDATA[In this work, we unify visual representation into the language feature space to advance the foundational LLM towards a unified LVLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-llava-learning-united-visual-1</guid>
    </item>
    <item>
      <title>Emergence of Segmentation with Minimalistic White-Box Transformers</title>
      <link>https://paperswithcode.com/paper/emergence-of-segmentation-with-minimalistic</link>
      <description><![CDATA[Transformer-like models for vision tasks have recently proven effective for a wide range of downstream applications such as segmentation and detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emergence-of-segmentation-with-minimalistic</guid>
    </item>
    <item>
      <title>GraphCast: Learning skillful medium-range global weather forecasting</title>
      <link>https://paperswithcode.com/paper/graphcast-learning-skillful-medium-range</link>
      <description><![CDATA[Global medium-range weather forecasting is critical to decision-making across many social and economic domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/graphcast-learning-skillful-medium-range</guid>
    </item>
    <item>
      <title>CogVLM: Visual Expert for Pretrained Language Models</title>
      <link>https://paperswithcode.com/paper/cogvlm-visual-expert-for-pretrained-language</link>
      <description><![CDATA[We introduce CogVLM, a powerful open-source visual language foundation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cogvlm-visual-expert-for-pretrained-language</guid>
    </item>
    <item>
      <title>Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents</title>
      <link>https://paperswithcode.com/paper/igniting-language-intelligence-the-hitchhiker</link>
      <description><![CDATA[Large language models (LLMs) have dramatically enhanced the field of language intelligence, as demonstrably evidenced by their formidable empirical performance across a spectrum of complex reasoning tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/igniting-language-intelligence-the-hitchhiker</guid>
    </item>
    <item>
      <title>InRank: Incremental Low-Rank Learning</title>
      <link>https://paperswithcode.com/paper/inrank-incremental-low-rank-learning</link>
      <description><![CDATA[To remedy this, we design a new training algorithm Incremental Low-Rank Learning (InRank), which explicitly expresses cumulative weight updates as low-rank matrices while incrementally augmenting their ranks during training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inrank-incremental-low-rank-learning</guid>
    </item>
    <item>
      <title>OneFormer3D: One Transformer for Unified Point Cloud Segmentation</title>
      <link>https://paperswithcode.com/paper/oneformer3d-one-transformer-for-unified-point</link>
      <description><![CDATA[Semantic, instance, and panoptic segmentation of 3D point clouds have been addressed using task-specific models of distinct design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oneformer3d-one-transformer-for-unified-point</guid>
    </item>
    <item>
      <title>HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis</title>
      <link>https://paperswithcode.com/paper/hierspeech-bridging-the-gap-between-semantic</link>
      <description><![CDATA[Furthermore, we significantly improve the naturalness and speaker similarity of synthetic speech even in zero-shot speech synthesis scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierspeech-bridging-the-gap-between-semantic</guid>
    </item>
    <item>
      <title>SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation</title>
      <link>https://paperswithcode.com/paper/sam-6d-segment-anything-model-meets-zero-shot</link>
      <description><![CDATA[Zero-shot 6D object pose estimation involves the detection of novel objects with their 6D poses in cluttered scenes, presenting significant challenges for model generalizability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sam-6d-segment-anything-model-meets-zero-shot</guid>
    </item>
  </channel>
</rss>
