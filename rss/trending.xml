<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 28 Oct 2023 09:10:49 +0000</lastBuildDate>
    <item>
      <title>Eureka: Human-Level Reward Design via Coding Large Language Models</title>
      <link>https://paperswithcode.com/paper/eureka-human-level-reward-design-via-coding</link>
      <description><![CDATA[The generality of Eureka also enables a new gradient-free in-context learning approach to reinforcement learning from human feedback (RLHF), readily incorporating human inputs to improve the quality and the safety of the generated rewards without model updating.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eureka-human-level-reward-design-via-coding</guid>
    </item>
    <item>
      <title>Zero123++: a Single Image to Consistent Multi-view Diffusion Base Model</title>
      <link>https://paperswithcode.com/paper/zero123-a-single-image-to-consistent-multi</link>
      <description><![CDATA[We report Zero123++, an image-conditioned diffusion model for generating 3D-consistent multi-view images from a single input view.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero123-a-single-image-to-consistent-multi</guid>
    </item>
    <item>
      <title>DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior</title>
      <link>https://paperswithcode.com/paper/dreamcraft3d-hierarchical-3d-generation-with</link>
      <description><![CDATA[The score distillation from this 3D-aware diffusion prior provides view-consistent guidance for the scene.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamcraft3d-hierarchical-3d-generation-with</guid>
    </item>
    <item>
      <title>OpenAgents: An Open Platform for Language Agents in the Wild</title>
      <link>https://paperswithcode.com/paper/openagents-an-open-platform-for-language</link>
      <description><![CDATA[Language agents show potential in being capable of utilizing natural language for varied and intricate tasks in diverse environments, particularly when built upon large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openagents-an-open-platform-for-language</guid>
    </item>
    <item>
      <title>AgentTuning: Enabling Generalized Agent Abilities for LLMs</title>
      <link>https://paperswithcode.com/paper/agenttuning-enabling-generalized-agent</link>
      <description><![CDATA[Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of LLMs themselves without compromising their general abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agenttuning-enabling-generalized-agent</guid>
    </item>
    <item>
      <title>SALMONN: Towards Generic Hearing Abilities for Large Language Models</title>
      <link>https://paperswithcode.com/paper/salmonn-towards-generic-hearing-abilities-for</link>
      <description><![CDATA[Hearing is arguably an essential ability of artificial intelligence (AI) agents in the physical world, which refers to the perception and understanding of general auditory information consisting of at least three types of sounds: speech, audio events, and music.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/salmonn-towards-generic-hearing-abilities-for</guid>
    </item>
    <item>
      <title>DISC-FinLLM: A Chinese Financial Large Language Model based on Multiple Experts Fine-tuning</title>
      <link>https://paperswithcode.com/paper/disc-finllm-a-chinese-financial-large</link>
      <description><![CDATA[We propose Multiple Experts Fine-tuning Framework to build a financial large language model (LLM), DISC-FinLLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disc-finllm-a-chinese-financial-large</guid>
    </item>
    <item>
      <title>PLVS: A SLAM System with Points, Lines, Volumetric Mapping, and 3D Incremental Segmentation</title>
      <link>https://paperswithcode.com/paper/plvs-a-slam-system-with-points-lines</link>
      <description><![CDATA[An incremental and geometric-based segmentation method is implemented and integrated for RGB-D cameras in the PLVS framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plvs-a-slam-system-with-points-lines</guid>
    </item>
    <item>
      <title>FreeNoise: Tuning-Free Longer Video Diffusion Via Noise Rescheduling</title>
      <link>https://paperswithcode.com/paper/freenoise-tuning-free-longer-video-diffusion</link>
      <description><![CDATA[With the availability of large-scale video datasets and the advances of diffusion models, text-driven video generation has achieved substantial progress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/freenoise-tuning-free-longer-video-diffusion</guid>
    </item>
    <item>
      <title>Llemma: An Open Language Model For Mathematics</title>
      <link>https://paperswithcode.com/paper/llemma-an-open-language-model-for-mathematics</link>
      <description><![CDATA[We present Llemma, a large language model for mathematics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llemma-an-open-language-model-for-mathematics</guid>
    </item>
    <item>
      <title>VideoReTalking: Audio-based Lip Synchronization for Talking Head Video Editing In the Wild</title>
      <link>https://paperswithcode.com/paper/videoretalking-audio-based-lip</link>
      <description><![CDATA[Our system disentangles this objective into three sequential tasks: (1) face video generation with a canonical expression; (2) audio-driven lip-sync; and (3) face enhancement for improving photo-realism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videoretalking-audio-based-lip</guid>
    </item>
    <item>
      <title>Sparse Fine-tuning for Inference Acceleration of Large Language Models</title>
      <link>https://paperswithcode.com/paper/sparse-finetuning-for-inference-acceleration</link>
      <description><![CDATA[While the standard approach is to leverage sparsity for computational reduction, we observe that in the case of memory-bound LLMs sparsity can also be leveraged for reducing memory bandwidth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparse-finetuning-for-inference-acceleration</guid>
    </item>
    <item>
      <title>PonderV2: Pave the Way for 3D Foundation Model with A Universal Pre-training Paradigm</title>
      <link>https://paperswithcode.com/paper/ponderv2-pave-the-way-for-3d-foundataion</link>
      <description><![CDATA[In this paper, we introduce a comprehensive 3D pre-training framework designed to facilitate the acquisition of efficient 3D representations, thereby establishing a pathway to 3D foundational models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ponderv2-pave-the-way-for-3d-foundataion</guid>
    </item>
    <item>
      <title>Data-Juicer: A One-Stop Data Processing System for Large Language Models</title>
      <link>https://paperswithcode.com/paper/data-juicer-a-one-stop-data-processing-system</link>
      <description><![CDATA[A data recipe is a mixture of data from different sources for training LLMs, which plays a vital role in LLMs' performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-juicer-a-one-stop-data-processing-system</guid>
    </item>
    <item>
      <title>Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference</title>
      <link>https://paperswithcode.com/paper/latent-consistency-models-synthesizing-high</link>
      <description><![CDATA[Inspired by Consistency Models (song et al.), we propose Latent Consistency Models (LCMs), enabling swift inference with minimal steps on any pre-trained LDMs, including Stable Diffusion (rombach et al).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-consistency-models-synthesizing-high</guid>
    </item>
    <item>
      <title>Exploring OCR Capabilities of GPT-4V(ision) : A Quantitative and In-depth Evaluation</title>
      <link>https://paperswithcode.com/paper/exploring-ocr-capabilities-of-gpt-4v-ision-a</link>
      <description><![CDATA[This paper presents a comprehensive evaluation of the Optical Character Recognition (OCR) capabilities of the recently released GPT-4V(ision), a Large Multimodal Model (LMM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-ocr-capabilities-of-gpt-4v-ision-a</guid>
    </item>
    <item>
      <title>Woodpecker: Hallucination Correction for Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/woodpecker-hallucination-correction-for</link>
      <description><![CDATA[Hallucination is a big shadow hanging over the rapidly evolving Multimodal Large Language Models (MLLMs), referring to the phenomenon that the generated text is inconsistent with the image content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/woodpecker-hallucination-correction-for</guid>
    </item>
    <item>
      <title>SAM-Med3D</title>
      <link>https://paperswithcode.com/paper/sam-med3d</link>
      <description><![CDATA[These issues can hardly be addressed by fine-tuning SAM on medical data because the original 2D structure of SAM neglects 3D spatial information.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sam-med3d</guid>
    </item>
    <item>
      <title>QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models</title>
      <link>https://paperswithcode.com/paper/qmoe-practical-sub-1-bit-compression-of</link>
      <description><![CDATA[Mixture-of-Experts (MoE) architectures offer a general solution to the high inference costs of large language models (LLMs) via sparse routing, bringing faster and more accurate models, at the cost of massive parameter counts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qmoe-practical-sub-1-bit-compression-of</guid>
    </item>
    <item>
      <title>False Negative/Positive Control for SAM on Noisy Medical Images</title>
      <link>https://paperswithcode.com/paper/false-negative-positive-control-for-sam-on</link>
      <description><![CDATA[The method couples multi-box prompt augmentation and an aleatoric uncertainty-based false-negative (FN) and false-positive (FP) correction (FNPC) strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/false-negative-positive-control-for-sam-on</guid>
    </item>
  </channel>
</rss>
