<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 31 Jan 2023 21:06:52 +0000</lastBuildDate>
    <item>
      <title>Cut and Learn for Unsupervised Object Detection and Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/cut-and-learn-for-unsupervised-object</link>
      <description><![CDATA[We propose Cut-and-LEaRn (CutLER), a simple approach for training unsupervised object detection and segmentation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cut-and-learn-for-unsupervised-object</guid>
    </item>
    <item>
      <title>Mo√ªsai: Text-to-Music Generation with Long-Context Latent Diffusion</title>
      <link>https://paperswithcode.com/paper/mousai-text-to-music-generation-with-long</link>
      <description><![CDATA[In our work, we investigate the potential of diffusion models for text-conditional music generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mousai-text-to-music-generation-with-long</guid>
    </item>
    <item>
      <title>On the Expressive Power of Geometric Graph Neural Networks</title>
      <link>https://paperswithcode.com/paper/on-the-expressive-power-of-geometric-graph</link>
      <description><![CDATA[The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-expressive-power-of-geometric-graph</guid>
    </item>
    <item>
      <title>Learning the Beauty in Songs: Neural Singing Voice Beautifier</title>
      <link>https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</link>
      <description><![CDATA[Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</guid>
    </item>
    <item>
      <title>Text2LIVE: Text-Driven Layered Image and Video Editing</title>
      <link>https://paperswithcode.com/paper/text2live-text-driven-layered-image-and-video</link>
      <description><![CDATA[Given an input image or video and a target text prompt, our goal is to edit the appearance of existing objects (e. g., object's texture) or augment the scene with visual effects (e. g., smoke, fire) in a semantically meaningful manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2live-text-driven-layered-image-and-video</guid>
    </item>
    <item>
      <title>InstructPix2Pix: Learning to Follow Image Editing Instructions</title>
      <link>https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</link>
      <description><![CDATA[We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</guid>
    </item>
    <item>
      <title>Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation</title>
      <link>https://paperswithcode.com/paper/tune-a-video-one-shot-tuning-of-image</link>
      <description><![CDATA[To reproduce the success of text-to-image (T2I) generation, recent works in text-to-video (T2V) generation employ large-scale text-video dataset for fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tune-a-video-one-shot-tuning-of-image</guid>
    </item>
    <item>
      <title>SNAKE: Shape-aware Neural 3D Keypoint Field</title>
      <link>https://paperswithcode.com/paper/snake-shape-aware-neural-3d-keypoint-field</link>
      <description><![CDATA[Detecting 3D keypoints from point clouds is important for shape reconstruction, while this work investigates the dual question: can shape reconstruction benefit 3D keypoint detection?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/snake-shape-aware-neural-3d-keypoint-field</guid>
    </item>
    <item>
      <title>VIBUS: Data-efficient 3D Scene Parsing with VIewpoint Bottleneck and Uncertainty-Spectrum Modeling</title>
      <link>https://paperswithcode.com/paper/vibus-data-efficient-3d-scene-parsing-with</link>
      <description><![CDATA[In the first stage, we perform self-supervised representation learning on unlabeled points with the proposed Viewpoint Bottleneck loss function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vibus-data-efficient-3d-scene-parsing-with</guid>
    </item>
    <item>
      <title>Parsel: A (De-)compositional Framework for Algorithmic Reasoning with Language Models</title>
      <link>https://paperswithcode.com/paper/parsel-a-unified-natural-language-framework</link>
      <description><![CDATA[Despite recent success in large language model (LLM) reasoning, LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parsel-a-unified-natural-language-framework</guid>
    </item>
    <item>
      <title>BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining</title>
      <link>https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</link>
      <description><![CDATA[Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</guid>
    </item>
    <item>
      <title>StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis</title>
      <link>https://paperswithcode.com/paper/stylegan-t-unlocking-the-power-of-gans-for</link>
      <description><![CDATA[Text-to-image synthesis has recently seen significant progress thanks to large pretrained language models, large-scale training data, and the introduction of scalable model families such as diffusion and autoregressive models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stylegan-t-unlocking-the-power-of-gans-for</guid>
    </item>
    <item>
      <title>Scaling Language-Image Pre-training via Masking</title>
      <link>https://paperswithcode.com/paper/scaling-language-image-pre-training-via</link>
      <description><![CDATA[We present Fast Language-Image Pre-training (FLIP), a simple and more efficient method for training CLIP.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-language-image-pre-training-via</guid>
    </item>
    <item>
      <title>Fine-Tuning Language Models from Human Preferences</title>
      <link>https://paperswithcode.com/paper/fine-tuning-language-models-from-human</link>
      <description><![CDATA[Most work on reward learning has used simulated environments, but complex information about values is often expressed in natural language, and we believe reward learning for language is a key to making RL practical and safe for real-world tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-language-models-from-human</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>Generating Sequences With Recurrent Neural Networks</title>
      <link>https://paperswithcode.com/paper/generating-sequences-with-recurrent-neural</link>
      <description><![CDATA[This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generating-sequences-with-recurrent-neural</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>MorphMLP: An Efficient MLP-Like Backbone for Spatial-Temporal Representation Learning</title>
      <link>https://paperswithcode.com/paper/morphmlp-a-self-attention-free-mlp-like</link>
      <description><![CDATA[With such multi-dimension and multi-scale factorization, our MorphMLP block can achieve a great accuracy-computation balance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/morphmlp-a-self-attention-free-mlp-like</guid>
    </item>
    <item>
      <title>TencentPretrain: A Scalable and Flexible Toolkit for Pre-training Models of Different Modalities</title>
      <link>https://paperswithcode.com/paper/tencentpretrain-a-scalable-and-flexible</link>
      <description><![CDATA[The proposed pre-training models of different modalities are showing a rising trend of homogeneity in their model structures, which brings the opportunity to implement different pre-training models within a uniform framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tencentpretrain-a-scalable-and-flexible</guid>
    </item>
    <item>
      <title>ProGen2: Exploring the Boundaries of Protein Language Models</title>
      <link>https://paperswithcode.com/paper/progen2-exploring-the-boundaries-of-protein</link>
      <description><![CDATA[Attention-based models trained on protein sequences have demonstrated incredible success at classification and generation tasks relevant for artificial intelligence-driven protein design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/progen2-exploring-the-boundaries-of-protein</guid>
    </item>
  </channel>
</rss>
