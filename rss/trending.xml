<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 02 Aug 2024 09:15:25 +0000</lastBuildDate>
    <item>
      <title>MindSearch: Mimicking Human Minds Elicits Deep AI Searcher</title>
      <link>https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</link>
      <description><![CDATA[Inspired by the cognitive process when humans solve these problems, we introduce MindSearch to mimic the human minds in web information seeking and integration, which can be instantiated by a simple yet effective LLM-based multi-agent framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</guid>
    </item>
    <item>
      <title>Global Structure-from-Motion Revisited</title>
      <link>https://paperswithcode.com/paper/global-structure-from-motion-revisited</link>
      <description><![CDATA[Recovering 3D structure and camera motion from images has been a long-standing focus of computer vision research and is known as Structure-from-Motion (SfM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/global-structure-from-motion-revisited</guid>
    </item>
    <item>
      <title>SGLang: Efficient Execution of Structured Language Model Programs</title>
      <link>https://paperswithcode.com/paper/efficiently-programming-large-language-models</link>
      <description><![CDATA[SGLang consists of a frontend language and a runtime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiently-programming-large-language-models</guid>
    </item>
    <item>
      <title>CatVTON: Concatenation Is All You Need for Virtual Try-On with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/catvton-concatenation-is-all-you-need-for</link>
      <description><![CDATA[Virtual try-on methods based on diffusion models achieve realistic try-on effects but often replicate the backbone network as a ReferenceNet or use additional image encoders to process condition inputs, leading to high training and inference costs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/catvton-concatenation-is-all-you-need-for</guid>
    </item>
    <item>
      <title>Autoregressive Image Generation without Vector Quantization</title>
      <link>https://paperswithcode.com/paper/autoregressive-image-generation-without</link>
      <description><![CDATA[In this work, we propose to model the per-token probability distribution using a diffusion procedure, which allows us to apply autoregressive models in a continuous-valued space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoregressive-image-generation-without</guid>
    </item>
    <item>
      <title>FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs</title>
      <link>https://paperswithcode.com/paper/funaudiollm-voice-understanding-and</link>
      <description><![CDATA[This report introduces FunAudioLLM, a model family designed to enhance natural voice interactions between humans and large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/funaudiollm-voice-understanding-and</guid>
    </item>
    <item>
      <title>Stable-Hair: Real-World Hair Transfer via Diffusion Model</title>
      <link>https://paperswithcode.com/paper/stable-hair-real-world-hair-transfer-via</link>
      <description><![CDATA[In the first stage, we train a Bald Converter alongside stable diffusion to remove hair from the user-provided face images, resulting in bald images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/stable-hair-real-world-hair-transfer-via</guid>
    </item>
    <item>
      <title>Theia: Distilling Diverse Vision Foundation Models for Robot Learning</title>
      <link>https://paperswithcode.com/paper/theia-distilling-diverse-vision-foundation</link>
      <description><![CDATA[Vision-based robot policy learning, which maps visual inputs to actions, necessitates a holistic understanding of diverse visual tasks beyond single-task needs like classification or segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/theia-distilling-diverse-vision-foundation</guid>
    </item>
    <item>
      <title>DataComp-LM: In search of the next generation of training sets for language models</title>
      <link>https://paperswithcode.com/paper/datacomp-lm-in-search-of-the-next-generation</link>
      <description><![CDATA[We introduce DataComp for Language Models (DCLM), a testbed for controlled dataset experiments with the goal of improving language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datacomp-lm-in-search-of-the-next-generation</guid>
    </item>
    <item>
      <title>Very Large-Scale Multi-Agent Simulation in AgentScope</title>
      <link>https://paperswithcode.com/paper/very-large-scale-multi-agent-simulation-in</link>
      <description><![CDATA[Recent advances in large language models (LLMs) have opened new avenues for applying multi-agent systems in very large-scale simulations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/very-large-scale-multi-agent-simulation-in</guid>
    </item>
    <item>
      <title>Deep-TEMPEST: Using Deep Learning to Eavesdrop on HDMI from its Unintended Electromagnetic Emanations</title>
      <link>https://paperswithcode.com/paper/deep-tempest-using-deep-learning-to-eavesdrop</link>
      <description><![CDATA[As a result, eavesdropping systems designed for the analog case obtain unclear and difficult-to-read images when applied to digital video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-tempest-using-deep-learning-to-eavesdrop</guid>
    </item>
    <item>
      <title>MINT-1T: Scaling Open-Source Multimodal Data by 10x: A Multimodal Dataset with One Trillion Tokens</title>
      <link>https://paperswithcode.com/paper/mint-1t-scaling-open-source-multimodal-data</link>
      <description><![CDATA[Multimodal interleaved datasets featuring free-form interleaved sequences of images and text are crucial for training frontier large multimodal models (LMMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mint-1t-scaling-open-source-multimodal-data</guid>
    </item>
    <item>
      <title>Cinemo: Consistent and Controllable Image Animation with Motion Diffusion Models</title>
      <link>https://paperswithcode.com/paper/cinemo-consistent-and-controllable-image</link>
      <description><![CDATA[Diffusion models have achieved great progress in image animation due to powerful generative capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cinemo-consistent-and-controllable-image</guid>
    </item>
    <item>
      <title>LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control</title>
      <link>https://paperswithcode.com/paper/liveportrait-efficient-portrait-animation</link>
      <description><![CDATA[Instead of following mainstream diffusion-based methods, we explore and extend the potential of the implicit-keypoint-based framework, which effectively balances computational efficiency and controllability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/liveportrait-efficient-portrait-animation</guid>
    </item>
    <item>
      <title>Odyssey: Empowering Agents with Open-World Skills</title>
      <link>https://paperswithcode.com/paper/odyssey-empowering-agents-with-open-world</link>
      <description><![CDATA[In this work, we introduce ODYSSEY, a new framework that empowers Large Language Model (LLM)-based agents with open-world skills to explore the vast Minecraft world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/odyssey-empowering-agents-with-open-world</guid>
    </item>
    <item>
      <title>Efficient Matrix Profile Computation Using Different Distance Functions</title>
      <link>https://paperswithcode.com/paper/efficient-matrix-profile-computation-using</link>
      <description><![CDATA[The results also show that the ACAMP algorithm is significantly faster than SCRIMP++ (the state of the art matrix profile algorithm) for the case of z-normalized Euclidean distance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-matrix-profile-computation-using</guid>
    </item>
    <item>
      <title>Prior Knowledge Integration via LLM Encoding and Pseudo Event Regulation for Video Moment Retrieval</title>
      <link>https://paperswithcode.com/paper/prior-knowledge-integration-via-llm-encoding</link>
      <description><![CDATA[Through a feasibility study, we demonstrate that LLM encoders effectively refine inter-concept relations in multimodal embeddings, even without being trained on textual embeddings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prior-knowledge-integration-via-llm-encoding</guid>
    </item>
    <item>
      <title>Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI</title>
      <link>https://paperswithcode.com/paper/aligning-cyber-space-with-physical-world-a</link>
      <description><![CDATA[In this survey, we give a comprehensive exploration of the latest advancements in Embodied AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-cyber-space-with-physical-world-a</guid>
    </item>
    <item>
      <title>Diffree: Text-Guided Shape Free Object Inpainting with Diffusion Model</title>
      <link>https://paperswithcode.com/paper/diffree-text-guided-shape-free-object</link>
      <description><![CDATA[To tackle this challenge, we introduce Diffree, a Text-to-Image (T2I) model that facilitates text-guided object addition with only text control.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffree-text-guided-shape-free-object</guid>
    </item>
    <item>
      <title>GS2Mesh: Surface Reconstruction from Gaussian Splatting via Novel Stereo Views</title>
      <link>https://paperswithcode.com/paper/surface-reconstruction-from-gaussian</link>
      <description><![CDATA[Recently, 3D Gaussian Splatting (3DGS) has emerged as an efficient approach for accurately representing scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surface-reconstruction-from-gaussian</guid>
    </item>
  </channel>
</rss>
