<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 02 Jan 2025 21:08:37 +0000</lastBuildDate>
    <item>
      <title>DeepSeek-V3 Technical Report</title>
      <link>https://paperswithcode.com/paper/deepseek-v3-technical-report</link>
      <description><![CDATA[We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-v3-technical-report</guid>
    </item>
    <item>
      <title>KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation</title>
      <link>https://paperswithcode.com/paper/2409-13731</link>
      <description><![CDATA[The recently developed retrieval-augmented generation (RAG) technology has enabled the efficient construction of domain-specific applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2409-13731</guid>
    </item>
    <item>
      <title>HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs</title>
      <link>https://paperswithcode.com/paper/huatuogpt-o1-towards-medical-complex</link>
      <description><![CDATA[To address this, we propose verifiable medical problems with a medical verifier to check the correctness of model outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huatuogpt-o1-towards-medical-complex</guid>
    </item>
    <item>
      <title>Story-Adapter: A Training-free Iterative Framework for Long Story Visualization</title>
      <link>https://paperswithcode.com/paper/story-adapter-a-training-free-iterative</link>
      <description><![CDATA[Specifically, we propose an iterative paradigm to refine each generated image, leveraging both the text prompt and all generated images from the previous iteration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/story-adapter-a-training-free-iterative</guid>
    </item>
    <item>
      <title>Monolith: Real Time Recommendation System With Collisionless Embedding Table</title>
      <link>https://paperswithcode.com/paper/monolith-real-time-recommendation-system-with</link>
      <description><![CDATA[In this paper, we present Monolith, a system tailored for online training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monolith-real-time-recommendation-system-with</guid>
    </item>
    <item>
      <title>Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey</title>
      <link>https://paperswithcode.com/paper/next-token-prediction-towards-multimodal</link>
      <description><![CDATA[As Large Language Models (LLMs) have advanced to unify understanding and generation tasks within the textual modality, recent research has shown that tasks from different modalities can also be effectively encapsulated within the NTP framework, transforming the multimodal information into tokens and predict the next one given the context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/next-token-prediction-towards-multimodal</guid>
    </item>
    <item>
      <title>TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization</title>
      <link>https://paperswithcode.com/paper/tangoflux-super-fast-and-faithful-text-to</link>
      <description><![CDATA[We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44. 1kHz audio in just 3. 7 seconds on a single A40 GPU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tangoflux-super-fast-and-faithful-text-to</guid>
    </item>
    <item>
      <title>StoryWeaver: A Unified World Model for Knowledge-Enhanced Story Character Customization</title>
      <link>https://paperswithcode.com/paper/storyweaver-a-unified-world-model-for</link>
      <description><![CDATA[Story visualization has gained increasing attention in artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/storyweaver-a-unified-world-model-for</guid>
    </item>
    <item>
      <title>Large Concept Models: Language Modeling in a Sentence Representation Space</title>
      <link>https://paperswithcode.com/paper/large-concept-models-language-modeling-in-a</link>
      <description><![CDATA[In this paper, we present an attempt at an architecture which operates on an explicit higher-level semantic representation, which we name a concept.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-concept-models-language-modeling-in-a</guid>
    </item>
    <item>
      <title>SemiKong: Curating, Training, and Evaluating A Semiconductor Industry-Specific Large Language Model</title>
      <link>https://paperswithcode.com/paper/semikong-curating-training-and-evaluating-a</link>
      <description><![CDATA[Large Language Models (LLMs) have demonstrated the potential to address some issues within the semiconductor industry.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semikong-curating-training-and-evaluating-a</guid>
    </item>
    <item>
      <title>VidTwin: Video VAE with Decoupled Structure and Dynamics</title>
      <link>https://paperswithcode.com/paper/vidtwin-video-vae-with-decoupled-structure</link>
      <description><![CDATA[Recent advancements in video autoencoders (Video AEs) have significantly improved the quality and efficiency of video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vidtwin-video-vae-with-decoupled-structure</guid>
    </item>
    <item>
      <title>Edicho: Consistent Image Editing in the Wild</title>
      <link>https://paperswithcode.com/paper/edicho-consistent-image-editing-in-the-wild</link>
      <description><![CDATA[As a verified need, consistent editing across in-the-wild images remains a technical challenge arising from various unmanageable factors, like object poses, lighting conditions, and photography environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edicho-consistent-image-editing-in-the-wild</guid>
    </item>
    <item>
      <title>Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks</title>
      <link>https://paperswithcode.com/paper/don-t-do-rag-when-cache-augmented-generation</link>
      <description><![CDATA[With the advent of large language models (LLMs) featuring significantly extended context windows, this paper proposes an alternative paradigm, cache-augmented generation (CAG) that bypasses real-time retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-do-rag-when-cache-augmented-generation</guid>
    </item>
    <item>
      <title>MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark</title>
      <link>https://paperswithcode.com/paper/mmlu-cf-a-contamination-free-multi-task</link>
      <description><![CDATA[This benchmark reassesses LLMs' understanding of world knowledge by averting both unintentional and malicious data leakage.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmlu-cf-a-contamination-free-multi-task</guid>
    </item>
    <item>
      <title>CogAgent: A Visual Language Model for GUI Agents</title>
      <link>https://paperswithcode.com/paper/cogagent-a-visual-language-model-for-gui</link>
      <description><![CDATA[People are spending an enormous amount of time on digital devices through graphical user interfaces (GUIs), e. g., computer or smartphone screens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cogagent-a-visual-language-model-for-gui</guid>
    </item>
    <item>
      <title>MINIMA: Modality Invariant Image Matching</title>
      <link>https://paperswithcode.com/paper/minima-modality-invariant-image-matching</link>
      <description><![CDATA[Under this setting, the matching labels and rich diversity of the RGB dataset are well inherited by the generated multimodal data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minima-modality-invariant-image-matching</guid>
    </item>
    <item>
      <title>Foundation Models for Music: A Survey</title>
      <link>https://paperswithcode.com/paper/foundation-models-for-music-a-survey</link>
      <description><![CDATA[In recent years, foundation models (FMs) such as large language models (LLMs) and latent diffusion models (LDMs) have profoundly impacted diverse sectors, including music.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundation-models-for-music-a-survey</guid>
    </item>
    <item>
      <title>DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought</title>
      <link>https://paperswithcode.com/paper/drt-o1-optimized-deep-reasoning-translation</link>
      <description><![CDATA[Using Qwen2. 5 and LLama-3. 1 as the backbones, DRT-o1 models can learn the thought process during machine translation, and outperform vanilla LLMs as well as existing O1-like LLMs, showing their effectiveness The project is available at https://github. com/krystalan/DRT-o1]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drt-o1-optimized-deep-reasoning-translation</guid>
    </item>
    <item>
      <title>PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models</title>
      <link>https://paperswithcode.com/paper/pulse-self-supervised-photo-upsampling-via</link>
      <description><![CDATA[We present an algorithm addressing this problem, PULSE (Photo Upsampling via Latent Space Exploration), which generates high-resolution, realistic images at resolutions previously unseen in the literature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pulse-self-supervised-photo-upsampling-via</guid>
    </item>
    <item>
      <title>Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference</title>
      <link>https://paperswithcode.com/paper/smarter-better-faster-longer-a-modern</link>
      <description><![CDATA[Encoder-only transformer models such as BERT offer a great performance-size tradeoff for retrieval and classification tasks with respect to larger decoder-only models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smarter-better-faster-longer-a-modern</guid>
    </item>
  </channel>
</rss>
