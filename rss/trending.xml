<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 25 Apr 2023 21:06:24 +0000</lastBuildDate>
    <item>
      <title>Robust Speech Recognition via Large-Scale Weak Supervision</title>
      <link>https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale-1</link>
      <description><![CDATA[We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale-1</guid>
    </item>
    <item>
      <title>DINOv2: Learning Robust Visual Features without Supervision</title>
      <link>https://paperswithcode.com/paper/dinov2-learning-robust-visual-features</link>
      <description><![CDATA[The recent breakthroughs in natural language processing for model pretraining on large quantities of data have opened the way for similar foundation models in computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dinov2-learning-robust-visual-features</guid>
    </item>
    <item>
      <title>Inpaint Anything: Segment Anything Meets Image Inpainting</title>
      <link>https://paperswithcode.com/paper/inpaint-anything-segment-anything-meets-image</link>
      <description><![CDATA[We are also very willing to help everyone share and promote new projects based on our Inpaint Anything (IA).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inpaint-anything-segment-anything-meets-image</guid>
    </item>
    <item>
      <title>Anything-3D: Towards Single-view Anything Reconstruction in the Wild</title>
      <link>https://paperswithcode.com/paper/anything-3d-towards-single-view-anything</link>
      <description><![CDATA[3D reconstruction from a single-RGB image in unconstrained real-world scenarios presents numerous challenges due to the inherent diversity and complexity of objects and environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anything-3d-towards-single-view-anything</guid>
    </item>
    <item>
      <title>Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models</title>
      <link>https://paperswithcode.com/paper/chameleon-plug-and-play-compositional</link>
      <description><![CDATA[Large language models (LLMs) have achieved remarkable progress in various natural language processing tasks with emergent abilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chameleon-plug-and-play-compositional</guid>
    </item>
    <item>
      <title>Tool Learning with Foundation Models</title>
      <link>https://paperswithcode.com/paper/tool-learning-with-foundation-models</link>
      <description><![CDATA[Considering the lack of a systematic tool learning evaluation in prior works, we experiment with 17 representative tools and show the potential of current foundation models in skillfully utilizing tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tool-learning-with-foundation-models</guid>
    </item>
    <item>
      <title>Phoenix: Democratizing ChatGPT across Languages</title>
      <link>https://paperswithcode.com/paper/phoenix-democratizing-chatgpt-across</link>
      <description><![CDATA[This paper presents our efforts to democratize ChatGPT across language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phoenix-democratizing-chatgpt-across</guid>
    </item>
    <item>
      <title>Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text</title>
      <link>https://paperswithcode.com/paper/multimodal-c4-an-open-billion-scale-corpus-of</link>
      <description><![CDATA[We release Multimodal C4 (mmc4), an augmentation of the popular text-only c4 corpus with images interleaved.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-c4-an-open-billion-scale-corpus-of</guid>
    </item>
    <item>
      <title>Transformer-Based Visual Segmentation: A Survey</title>
      <link>https://paperswithcode.com/paper/transformer-based-visual-segmentation-a</link>
      <description><![CDATA[Recently, transformers, a type of neural network based on self-attention originally designed for natural language processing, have considerably surpassed previous convolutional or recurrent approaches in various vision processing tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformer-based-visual-segmentation-a</guid>
    </item>
    <item>
      <title>OpenAssistant Conversations -- Democratizing Large Language Model Alignment</title>
      <link>https://paperswithcode.com/paper/openassistant-conversations-democratizing</link>
      <description><![CDATA[The corpus is a product of a worldwide crowd-sourcing effort involving over 13, 500 volunteers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openassistant-conversations-democratizing</guid>
    </item>
    <item>
      <title>HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge</title>
      <link>https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</link>
      <description><![CDATA[Large Language Models (LLMs), such as the LLaMA model, have demonstrated their effectiveness in various general-domain natural language processing (NLP) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</guid>
    </item>
    <item>
      <title>RealFusion: 360Â° Reconstruction of Any Object from a Single Image</title>
      <link>https://paperswithcode.com/paper/realfusion-360deg-reconstruction-of-any</link>
      <description><![CDATA[We consider the problem of reconstructing a full 360{\deg} photographic model of an object from a single image of it.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/realfusion-360deg-reconstruction-of-any</guid>
    </item>
    <item>
      <title>CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society</title>
      <link>https://paperswithcode.com/paper/camel-communicative-agents-for-mind</link>
      <description><![CDATA[To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camel-communicative-agents-for-mind</guid>
    </item>
    <item>
      <title>Mask-Free Video Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/mask-free-video-instance-segmentation</link>
      <description><![CDATA[A consistency loss is then enforced on the found matches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mask-free-video-instance-segmentation</guid>
    </item>
    <item>
      <title>SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation</title>
      <link>https://paperswithcode.com/paper/sadtalker-learning-realistic-3d-motion</link>
      <description><![CDATA[We present SadTalker, which generates 3D motion coefficients (head pose, expression) of the 3DMM from audio and implicitly modulates a novel 3D-aware face render for talking head generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sadtalker-learning-realistic-3d-motion</guid>
    </item>
    <item>
      <title>Text2Performer: Text-Driven Human Video Generation</title>
      <link>https://paperswithcode.com/paper/text2performer-text-driven-human-video</link>
      <description><![CDATA[In this work, we present Text2Performer to generate vivid human videos with articulated motions from texts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2performer-text-driven-human-video</guid>
    </item>
    <item>
      <title>A Method for Animating Children's Drawings of the Human Figure</title>
      <link>https://paperswithcode.com/paper/a-method-for-automatically-animating-children</link>
      <description><![CDATA[Children's drawings have a wonderful inventiveness, creativity, and variety to them.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-method-for-automatically-animating-children</guid>
    </item>
    <item>
      <title>Tetra-NeRF: Representing Neural Radiance Fields Using Tetrahedra</title>
      <link>https://paperswithcode.com/paper/tetra-nerf-representing-neural-radiance</link>
      <description><![CDATA[Neural Radiance Fields (NeRFs) are a very recent and very popular approach for the problems of novel view synthesis and 3D reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tetra-nerf-representing-neural-radiance</guid>
    </item>
    <item>
      <title>A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on Chinese Instruction Data for Instruction Following Large Language Model</title>
      <link>https://paperswithcode.com/paper/a-comparative-study-between-full-parameter</link>
      <description><![CDATA[In this study, we undertook experimental comparisons between full-parameter fine-tuning and LoRA-based tuning methods, utilizing LLaMA as the base model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-comparative-study-between-full-parameter</guid>
    </item>
    <item>
      <title>LongForm: Optimizing Instruction Tuning for Long Text Generation with Corpus Extraction</title>
      <link>https://paperswithcode.com/paper/longform-optimizing-instruction-tuning-for</link>
      <description><![CDATA[Our models outperform 10x larger language models without instruction tuning on various tasks such as story/recipe generation and long-form question answering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longform-optimizing-instruction-tuning-for</guid>
    </item>
  </channel>
</rss>
