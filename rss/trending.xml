<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 30 Jul 2022 21:07:22 +0000</lastBuildDate>
    <item>
      <title>Multi-scale Multi-band DenseNets for Audio Source Separation</title>
      <link>https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</link>
      <description><![CDATA[This paper deals with the problem of audio source separation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-scale-multi-band-densenets-for-audio</guid>
    </item>
    <item>
      <title>Multiface: A Dataset for Neural Face Rendering</title>
      <link>https://paperswithcode.com/paper/multiface-a-dataset-for-neural-face-rendering</link>
      <description><![CDATA[Along with the release of the dataset, we conduct ablation studies on the influence of different model architectures toward the model's interpolation capacity of novel viewpoint and expressions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiface-a-dataset-for-neural-face-rendering</guid>
    </item>
    <item>
      <title>An Improved One millisecond Mobile Backbone</title>
      <link>https://paperswithcode.com/paper/an-improved-one-millisecond-mobile-backbone</link>
      <description><![CDATA[Furthermore, we show that our model generalizes to multiple tasks - image classification, object detection, and semantic segmentation with significant improvements in latency and accuracy as compared to existing efficient architectures when deployed on a mobile device.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-improved-one-millisecond-mobile-backbone</guid>
    </item>
    <item>
      <title>Monocular 3D Object Detection with Depth from Motion</title>
      <link>https://paperswithcode.com/paper/monocular-3d-object-detection-with-depth-from</link>
      <description><![CDATA[Perceiving 3D objects from monocular inputs is crucial for robotic systems, given its economy compared to multi-sensor settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monocular-3d-object-detection-with-depth-from</guid>
    </item>
    <item>
      <title>MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge</title>
      <link>https://paperswithcode.com/paper/minedojo-building-open-ended-embodied-agents</link>
      <description><![CDATA[Autonomous agents have made great strides in specialist domains like Atari games and Go.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minedojo-building-open-ended-embodied-agents</guid>
    </item>
    <item>
      <title>CelebV-HQ: A Large-Scale Video Facial Attributes Dataset</title>
      <link>https://paperswithcode.com/paper/celebv-hq-a-large-scale-video-facial</link>
      <description><![CDATA[Large-scale datasets have played indispensable roles in the recent success of face generation/editing and significantly facilitated the advances of emerging research fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/celebv-hq-a-large-scale-video-facial</guid>
    </item>
    <item>
      <title>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</title>
      <link>https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</link>
      <description><![CDATA[YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56. 8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</guid>
    </item>
    <item>
      <title>DEVIANT: Depth EquiVarIAnt NeTwork for Monocular 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/deviant-depth-equivariant-network-for</link>
      <description><![CDATA[As a result, DEVIANT is equivariant to the depth translations in the projective manifold whereas vanilla networks are not.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deviant-depth-equivariant-network-for</guid>
    </item>
    <item>
      <title>Theseus: A Library for Differentiable Nonlinear Optimization</title>
      <link>https://paperswithcode.com/paper/theseus-a-library-for-differentiable</link>
      <description><![CDATA[We present Theseus, an efficient application-agnostic open source library for differentiable nonlinear least squares (DNLS) optimization built on PyTorch, providing a common framework for end-to-end structured learning in robotics and vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/theseus-a-library-for-differentiable</guid>
    </item>
    <item>
      <title>RePaint: Inpainting using Denoising Diffusion Probabilistic Models</title>
      <link>https://paperswithcode.com/paper/repaint-inpainting-using-denoising-diffusion</link>
      <description><![CDATA[In this work, we propose RePaint: A Denoising Diffusion Probabilistic Model (DDPM) based inpainting approach that is applicable to even extreme masks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repaint-inpainting-using-denoising-diffusion</guid>
    </item>
    <item>
      <title>OCR-free Document Understanding Transformer</title>
      <link>https://paperswithcode.com/paper/donut-document-understanding-transformer</link>
      <description><![CDATA[Current Visual Document Understanding (VDU) methods outsource the task of reading text to off-the-shelf Optical Character Recognition (OCR) engines and focus on the understanding task with the OCR outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/donut-document-understanding-transformer</guid>
    </item>
    <item>
      <title>HierarchicalForecast: A Reference Framework for Hierarchical Forecasting in Python</title>
      <link>https://paperswithcode.com/paper/hierarchicalforecast-a-python-benchmarking</link>
      <description><![CDATA[Large collections of time series data are commonly organized into cross-sectional structures with different levels of aggregation; examples include product and geographical groupings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hierarchicalforecast-a-python-benchmarking</guid>
    </item>
    <item>
      <title>Generative Multiplane Images: Making a 2D GAN 3D-Aware</title>
      <link>https://paperswithcode.com/paper/generative-multiplane-images-making-a-2d-gan</link>
      <description><![CDATA[What is really needed to make an existing 2D GAN 3D-aware?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-multiplane-images-making-a-2d-gan</guid>
    </item>
    <item>
      <title>Generator Knows What Discriminator Should Learn in Unconditional GANs</title>
      <link>https://paperswithcode.com/paper/generator-knows-what-discriminator-should</link>
      <description><![CDATA[Here we explore the efficacy of dense supervision in unconditional generation and find generator feature maps can be an alternative of cost-expensive semantic label maps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generator-knows-what-discriminator-should</guid>
    </item>
    <item>
      <title>NeuriCam: Video Super-Resolution and Colorization Using Key Frames</title>
      <link>https://paperswithcode.com/paper/neuricam-video-super-resolution-and</link>
      <description><![CDATA[Our idea is to design a dual-mode camera system where the first mode is low power (1. 1~mW) but only outputs gray-scale, low resolution and noisy video and the second mode consumes much higher power (100~mW) but outputs color and higher resolution images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuricam-video-super-resolution-and</guid>
    </item>
    <item>
      <title>When Counting Meets HMER: Counting-Aware Network for Handwritten Mathematical Expression Recognition</title>
      <link>https://paperswithcode.com/paper/when-counting-meets-hmer-counting-aware</link>
      <description><![CDATA[Recently, most handwritten mathematical expression recognition (HMER) methods adopt the encoder-decoder networks, which directly predict the markup sequences from formula images with the attention mechanism.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/when-counting-meets-hmer-counting-aware</guid>
    </item>
    <item>
      <title>Ivy: Templated Deep Learning for Inter-Framework Portability</title>
      <link>https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</link>
      <description><![CDATA[We introduce Ivy, a templated Deep Learning (DL) framework which abstracts existing DL frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</guid>
    </item>
    <item>
      <title>Elucidating the Design Space of Diffusion-Based Generative Models</title>
      <link>https://paperswithcode.com/paper/elucidating-the-design-space-of-diffusion</link>
      <description><![CDATA[We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elucidating-the-design-space-of-diffusion</guid>
    </item>
    <item>
      <title>Neural-Sim: Learning to Generate Training Data with NeRF</title>
      <link>https://paperswithcode.com/paper/neural-sim-learning-to-generate-training-data</link>
      <description><![CDATA[However, existing approaches either require human experts to manually tune each scene property or use automatic methods that provide little to no control; this requires rendering large amounts of random data variations, which is slow and is often suboptimal for the target domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-sim-learning-to-generate-training-data</guid>
    </item>
    <item>
      <title>Learning with Combinatorial Optimization Layers: a Probabilistic Approach</title>
      <link>https://paperswithcode.com/paper/learning-with-combinatorial-optimization</link>
      <description><![CDATA[Combinatorial optimization (CO) layers in machine learning (ML) pipelines are a powerful tool to tackle data-driven decision tasks, but they come with two main challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-with-combinatorial-optimization</guid>
    </item>
  </channel>
</rss>
