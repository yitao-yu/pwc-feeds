<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 06 Feb 2024 09:11:59 +0000</lastBuildDate>
    <item>
      <title>OLMo: Accelerating the Science of Language Models</title>
      <link>https://paperswithcode.com/paper/olmo-accelerating-the-science-of-language</link>
      <description><![CDATA[Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community to have access to powerful, truly open LMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/olmo-accelerating-the-science-of-language</guid>
    </item>
    <item>
      <title>MoE-LLaVA: Mixture of Experts for Large Vision-Language Models</title>
      <link>https://paperswithcode.com/paper/moe-llava-mixture-of-experts-for-large-vision</link>
      <description><![CDATA[In this work, we propose a simple yet effective training strategy MoE-Tuning for LVLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moe-llava-mixture-of-experts-for-large-vision</guid>
    </item>
    <item>
      <title>InstantID: Zero-shot Identity-Preserving Generation in Seconds</title>
      <link>https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</link>
      <description><![CDATA[There has been significant progress in personalized image synthesis with methods such as Textual Inversion, DreamBooth, and LoRA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</guid>
    </item>
    <item>
      <title>Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception</title>
      <link>https://paperswithcode.com/paper/mobile-agent-autonomous-multi-modal-mobile</link>
      <description><![CDATA[To assess the performance of Mobile-Agent, we introduced Mobile-Eval, a benchmark for evaluating mobile device operations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobile-agent-autonomous-multi-modal-mobile</guid>
    </item>
    <item>
      <title>YOLO-World: Real-Time Open-Vocabulary Object Detection</title>
      <link>https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</link>
      <description><![CDATA[The You Only Look Once (YOLO) series of detectors have established themselves as efficient and practical tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</guid>
    </item>
    <item>
      <title>Guiding Instruction-based Image Editing via Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/guiding-instruction-based-image-editing-via</link>
      <description><![CDATA[Extensive experimental results demonstrate that expressive instructions are crucial to instruction-based image editing, and our MGIE can lead to a notable improvement in automatic metrics and human evaluation while maintaining competitive inference efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/guiding-instruction-based-image-editing-via</guid>
    </item>
    <item>
      <title>AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning</title>
      <link>https://paperswithcode.com/paper/animatelcm-accelerating-the-animation-of</link>
      <description><![CDATA[We validate the proposed strategy in image-conditioned video generation and layout-conditioned video generation, all achieving top-performing results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatelcm-accelerating-the-animation-of</guid>
    </item>
    <item>
      <title>High-Quality Image Restoration Following Human Instructions</title>
      <link>https://paperswithcode.com/paper/high-quality-image-restoration-following</link>
      <description><![CDATA[All-In-One image restoration models can effectively restore images from various types and levels of degradation using degradation-specific information as prompts to guide the restoration model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-quality-image-restoration-following</guid>
    </item>
    <item>
      <title>DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence</title>
      <link>https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</link>
      <description><![CDATA[The rapid development of large language models has revolutionized code intelligence in software development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</guid>
    </item>
    <item>
      <title>Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research</title>
      <link>https://paperswithcode.com/paper/dolma-an-open-corpus-of-three-trillion-tokens</link>
      <description><![CDATA[Language models have become a critical technology to tackling a wide range of natural language processing tasks, yet many details about how the best-performing language models were developed are not reported.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dolma-an-open-corpus-of-three-trillion-tokens</guid>
    </item>
    <item>
      <title>Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data</title>
      <link>https://paperswithcode.com/paper/depth-anything-unleashing-the-power-of-large</link>
      <description><![CDATA[To this end, we scale up the dataset by designing a data engine to collect and automatically annotate large-scale unlabeled data (~62M), which significantly enlarges the data coverage and thus is able to reduce the generalization error.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depth-anything-unleashing-the-power-of-large</guid>
    </item>
    <item>
      <title>Flexibly Scaling Large Language Models Contexts Through Extensible Tokenization</title>
      <link>https://paperswithcode.com/paper/flexibly-scaling-large-language-models</link>
      <description><![CDATA[Extensible Tokenization stands as a midware in between of the tokenized context and the LLM, which transforms the raw token embeddings into the extensible embeddings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flexibly-scaling-large-language-models</guid>
    </item>
    <item>
      <title>Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook</title>
      <link>https://paperswithcode.com/paper/large-models-for-time-series-and-spatio</link>
      <description><![CDATA[In this survey, we offer a comprehensive and up-to-date review of large models tailored (or adapted) for time series and spatio-temporal data, spanning four key facets: data types, model categories, model scopes, and application areas/tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-models-for-time-series-and-spatio</guid>
    </item>
    <item>
      <title>MMBench: Is Your Multi-modal Model an All-around Player?</title>
      <link>https://paperswithcode.com/paper/mmbench-is-your-multi-modal-model-an-all</link>
      <description><![CDATA[In response to these challenges, we propose MMBench, a novel multi-modality benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmbench-is-your-multi-modal-model-an-all</guid>
    </item>
    <item>
      <title>Efficiently Programming Large Language Models using SGLang</title>
      <link>https://paperswithcode.com/paper/efficiently-programming-large-language-models</link>
      <description><![CDATA[SGLang is designed for the efficient programming of LLMs and incorporates primitives for common LLM programming patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiently-programming-large-language-models</guid>
    </item>
    <item>
      <title>Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2</title>
      <link>https://paperswithcode.com/paper/camels-in-a-changing-climate-enhancing-lm</link>
      <description><![CDATA[Since the release of T\"ULU [Wang et al., 2023b], open resources for instruction tuning have developed quickly, from better base models to new finetuning techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/camels-in-a-changing-climate-enhancing-lm</guid>
    </item>
    <item>
      <title>Hi-SAM: Marrying Segment Anything Model for Hierarchical Text Segmentation</title>
      <link>https://paperswithcode.com/paper/hi-sam-marrying-segment-anything-model-for</link>
      <description><![CDATA[In terms of the AMG mode, Hi-SAM segments text stroke foreground masks initially, then samples foreground points for hierarchical text mask generation and achieves layout analysis in passing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hi-sam-marrying-segment-anything-model-for</guid>
    </item>
    <item>
      <title>Proactive Detection of Voice Cloning with Localized Watermarking</title>
      <link>https://paperswithcode.com/paper/proactive-detection-of-voice-cloning-with</link>
      <description><![CDATA[In the rapidly evolving field of speech generative models, there is a pressing need to ensure audio authenticity against the risks of voice cloning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/proactive-detection-of-voice-cloning-with</guid>
    </item>
    <item>
      <title>SliceGPT: Compress Large Language Models by Deleting Rows and Columns</title>
      <link>https://paperswithcode.com/paper/slicegpt-compress-large-language-models-by</link>
      <description><![CDATA[Large language models have become the cornerstone of natural language processing, but their use comes with substantial costs in terms of compute and memory resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/slicegpt-compress-large-language-models-by</guid>
    </item>
    <item>
      <title>KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization</title>
      <link>https://paperswithcode.com/paper/kvquant-towards-10-million-context-length-llm</link>
      <description><![CDATA[LLMs are seeing growing use for applications such as document analysis and summarization which require large context windows, and with these large context windows KV cache activations surface as the dominant contributor to memory consumption during inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kvquant-towards-10-million-context-length-llm</guid>
    </item>
  </channel>
</rss>
