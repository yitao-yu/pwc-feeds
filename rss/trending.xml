<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 27 Nov 2022 21:06:32 +0000</lastBuildDate>
    <item>
      <title>Human-level play in the game of Diplomacy by combining language models with strategic reasoning</title>
      <link>https://paperswithcode.com/paper/human-level-play-in-the-game-of-diplomacy-by</link>
      <description><![CDATA[Despite much progress in training AI systems to imitate human language, building agents that use language to communicate intentionally with humans in interactive environments remains a major challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/human-level-play-in-the-game-of-diplomacy-by</guid>
    </item>
    <item>
      <title>TorchScale: Transformers at Scale</title>
      <link>https://paperswithcode.com/paper/torchscale-transformers-at-scale</link>
      <description><![CDATA[Large Transformers have achieved state-of-the-art performance across many tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchscale-transformers-at-scale</guid>
    </item>
    <item>
      <title>Paint by Example: Exemplar-based Image Editing with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/paint-by-example-exemplar-based-image-editing</link>
      <description><![CDATA[Language-guided image editing has achieved great success recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paint-by-example-exemplar-based-image-editing</guid>
    </item>
    <item>
      <title>DiffusionDet: Diffusion Model for Object Detection</title>
      <link>https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</link>
      <description><![CDATA[In inference, the model refines a set of randomly generated boxes to the output results in a progressive way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</guid>
    </item>
    <item>
      <title>AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities</title>
      <link>https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</link>
      <description><![CDATA[In this work, we present a conceptually simple and effective method to train a strong bilingual/multilingual multimodal representation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</guid>
    </item>
    <item>
      <title>SinDiffusion: Learning a Diffusion Model from a Single Natural Image</title>
      <link>https://paperswithcode.com/paper/sindiffusion-learning-a-diffusion-model-from</link>
      <description><![CDATA[We present SinDiffusion, leveraging denoising diffusion models to capture internal distribution of patches from a single natural image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sindiffusion-learning-a-diffusion-model-from</guid>
    </item>
    <item>
      <title>EVA: Exploring the Limits of Masked Visual Representation Learning at Scale</title>
      <link>https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</link>
      <description><![CDATA[We launch EVA, a vision-centric foundation model to explore the limits of visual representation at scale using only publicly accessible data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>Galactica: A Large Language Model for Science</title>
      <link>https://paperswithcode.com/paper/galactica-a-large-language-model-for-science-1</link>
      <description><![CDATA[We believe these results demonstrate the potential for language models as a new interface for science.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/galactica-a-large-language-model-for-science-1</guid>
    </item>
    <item>
      <title>Latent Video Diffusion Models for High-Fidelity Video Generation with Arbitrary Lengths</title>
      <link>https://paperswithcode.com/paper/latent-video-diffusion-models-for-high</link>
      <description><![CDATA[Diffusion models (DMs) are another class of deep generative models and have recently achieved remarkable performance on various image synthesis tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-video-diffusion-models-for-high</guid>
    </item>
    <item>
      <title>VeLO: Training Versatile Learned Optimizers by Scaling Up</title>
      <link>https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</link>
      <description><![CDATA[While deep learning models have replaced hand-designed features across many domains, these models are still trained with hand-designed optimizers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</guid>
    </item>
    <item>
      <title>MetaFormer Baselines for Vision</title>
      <link>https://paperswithcode.com/paper/metaformer-baselines-for-vision</link>
      <description><![CDATA[By simply applying depthwise separable convolutions as token mixer in the bottom stages and vanilla self-attention in the top stages, the resulting model CAFormer sets a new record on ImageNet-1K: it achieves an accuracy of 85. 5% at 224x224 resolution, under normal supervised training without external data or distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metaformer-baselines-for-vision</guid>
    </item>
    <item>
      <title>A Closer Look at Learned Optimization: Stability, Robustness, and Inductive Biases</title>
      <link>https://paperswithcode.com/paper/a-closer-look-at-learned-optimization</link>
      <description><![CDATA[We apply the resulting learned optimizer to a variety of neural network training tasks, where it outperforms the current state of the art learned optimizer -- at matched optimizer computational overhead -- with regard to optimization performance and meta-training speed, and is capable of generalization to tasks far different from those it was meta-trained on.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-closer-look-at-learned-optimization</guid>
    </item>
    <item>
      <title>Inversion-Based Creativity Transfer with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/inversion-based-creativity-transfer-with</link>
      <description><![CDATA[In this paper, we introduce the task of "Creativity Transfer".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inversion-based-creativity-transfer-with</guid>
    </item>
    <item>
      <title>TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second</title>
      <link>https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</link>
      <description><![CDATA[We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</guid>
    </item>
    <item>
      <title>LiT: Zero-Shot Transfer with Locked-image text Tuning</title>
      <link>https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</link>
      <description><![CDATA[This paper presents contrastive-tuning, a simple method employing contrastive training to align image and text models while still taking advantage of their pre-training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</guid>
    </item>
    <item>
      <title>RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation</title>
      <link>https://paperswithcode.com/paper/renderdiffusion-image-diffusion-for-3d</link>
      <description><![CDATA[In this paper, we present RenderDiffusion as the first diffusion model for 3D generation and inference that can be trained using only monocular 2D supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/renderdiffusion-image-diffusion-for-3d</guid>
    </item>
    <item>
      <title>Revisiting Image Pyramid Structure for High Resolution Salient Object Detection</title>
      <link>https://paperswithcode.com/paper/revisiting-image-pyramid-structure-for-high</link>
      <description><![CDATA[Salient object detection (SOD) has been in the spotlight recently, yet has been studied less for high-resolution (HR) images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-image-pyramid-structure-for-high</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge</title>
      <link>https://paperswithcode.com/paper/minedojo-building-open-ended-embodied-agents</link>
      <description><![CDATA[Autonomous agents have made great strides in specialist domains like Atari games and Go.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minedojo-building-open-ended-embodied-agents</guid>
    </item>
  </channel>
</rss>
