<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 16 Nov 2022 09:14:49 +0000</lastBuildDate>
    <item>
      <title>OneFormer: One Transformer to Rule Universal Image Segmentation</title>
      <link>https://paperswithcode.com/paper/oneformer-one-transformer-to-rule-universal</link>
      <description><![CDATA[However, such panoptic architectures do not truly unify image segmentation because they need to be trained individually on the semantic, instance, or panoptic segmentation to achieve the best performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oneformer-one-transformer-to-rule-universal</guid>
    </item>
    <item>
      <title>Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures</title>
      <link>https://paperswithcode.com/paper/latent-nerf-for-shape-guided-generation-of-3d</link>
      <description><![CDATA[This unique combination of text and shape guidance allows for increased control over the generation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-nerf-for-shape-guided-generation-of-3d</guid>
    </item>
    <item>
      <title>EVA: Exploring the Limits of Masked Visual Representation Learning at Scale</title>
      <link>https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</link>
      <description><![CDATA[We launch EVA, a vision-centric foundation model to explore the limits of visual representation at scale using only publicly accessible data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</guid>
    </item>
    <item>
      <title>Fast Text-Conditional Discrete Denoising on Vector-Quantized Latent Spaces</title>
      <link>https://paperswithcode.com/paper/fast-text-conditional-discrete-denoising-on</link>
      <description><![CDATA[Conditional text-to-image generation has seen countless recent improvements in terms of quality, diversity and fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-text-conditional-discrete-denoising-on</guid>
    </item>
    <item>
      <title>Unifying Flow, Stereo and Depth Estimation</title>
      <link>https://paperswithcode.com/paper/unifying-flow-stereo-and-depth-estimation</link>
      <description><![CDATA[We present a unified formulation and model for three motion and 3D perception tasks: optical flow, rectified stereo matching and unrectified stereo depth estimation from posed images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unifying-flow-stereo-and-depth-estimation</guid>
    </item>
    <item>
      <title>Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked Modeling for Vision Decoding</title>
      <link>https://paperswithcode.com/paper/seeing-beyond-the-brain-conditional-diffusion</link>
      <description><![CDATA[In this work, we present MinD-Vis: Sparse Masked Brain Modeling with Double-Conditioned Latent Diffusion Model for Human Vision Decoding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seeing-beyond-the-brain-conditional-diffusion</guid>
    </item>
    <item>
      <title>Dungeons and Data: A Large-Scale NetHack Dataset</title>
      <link>https://paperswithcode.com/paper/dungeons-and-data-a-large-scale-nethack</link>
      <description><![CDATA[Recent breakthroughs in the development of agents to solve challenging sequential decision making problems such as Go, StarCraft, or DOTA, have relied on both simulated environments and large-scale datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dungeons-and-data-a-large-scale-nethack</guid>
    </item>
    <item>
      <title>InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions</title>
      <link>https://paperswithcode.com/paper/internimage-exploring-large-scale-vision</link>
      <description><![CDATA[Compared to the great progress of large-scale vision transformers (ViTs) in recent years, large-scale models based on convolutional neural networks (CNNs) are still in an early state.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internimage-exploring-large-scale-vision</guid>
    </item>
    <item>
      <title>Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training</title>
      <link>https://paperswithcode.com/paper/colossal-ai-a-unified-deep-learning-system</link>
      <description><![CDATA[The success of Transformer models has pushed the deep learning model scale to billions of parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/colossal-ai-a-unified-deep-learning-system</guid>
    </item>
    <item>
      <title>RepGhost: A Hardware-Efficient Ghost Module via Re-parameterization</title>
      <link>https://paperswithcode.com/paper/repghost-a-hardware-efficient-ghost-module</link>
      <description><![CDATA[Experiments on ImageNet and COCO benchmarks demonstrate that the proposed RepGhostNet is much more effective and efficient than GhostNet and MobileNetV3 on mobile devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repghost-a-hardware-efficient-ghost-module</guid>
    </item>
    <item>
      <title>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</title>
      <link>https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</link>
      <description><![CDATA[Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</guid>
    </item>
    <item>
      <title>TimberTrek: Exploring and Curating Sparse Decision Trees with Interactive Visualization</title>
      <link>https://paperswithcode.com/paper/timbertrek-exploring-and-curating-sparse</link>
      <description><![CDATA[Given thousands of equally accurate machine learning (ML) models, how can users choose among them?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/timbertrek-exploring-and-curating-sparse</guid>
    </item>
    <item>
      <title>A unified one-shot prosody and speaker conversion system with self-supervised discrete speech units</title>
      <link>https://paperswithcode.com/paper/a-unified-one-shot-prosody-and-speaker</link>
      <description><![CDATA[To address these issues, we devise a cascaded modular system leveraging self-supervised discrete speech units as language representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-unified-one-shot-prosody-and-speaker</guid>
    </item>
    <item>
      <title>DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models</title>
      <link>https://paperswithcode.com/paper/dpm-solver-fast-solver-for-guided-sampling-of</link>
      <description><![CDATA[The commonly-used fast sampler for guided sampling is DDIM, a first-order diffusion ODE solver that generally needs 100 to 250 steps for high-quality samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dpm-solver-fast-solver-for-guided-sampling-of</guid>
    </item>
    <item>
      <title>Focal Modulation Networks</title>
      <link>https://paperswithcode.com/paper/focal-modulation-networks</link>
      <description><![CDATA[For semantic segmentation with UPerNet, FocalNet base at single-scale outperforms Swin by 2. 4, and beats Swin at multi-scale (50. 5 v. s.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/focal-modulation-networks</guid>
    </item>
    <item>
      <title>MedleyVox: An Evaluation Dataset for Multiple Singing Voices Separation</title>
      <link>https://paperswithcode.com/paper/medleyvox-an-evaluation-dataset-for-multiple</link>
      <description><![CDATA[In this paper, we present an evaluation dataset and provide baseline studies for multiple singing voices separation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medleyvox-an-evaluation-dataset-for-multiple</guid>
    </item>
    <item>
      <title>MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation</title>
      <link>https://paperswithcode.com/paper/mmdialog-a-large-scale-multi-turn-dialogue</link>
      <description><![CDATA[First, it is the largest multi-modal conversation dataset by the number of dialogues by 8x.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmdialog-a-large-scale-multi-turn-dialogue</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>What the DAAM: Interpreting Stable Diffusion Using Cross Attention</title>
      <link>https://paperswithcode.com/paper/what-the-daam-interpreting-stable-diffusion</link>
      <description><![CDATA[In this paper, to shine some much-needed light on text-to-image diffusion models, we perform a text-image attribution analysis on Stable Diffusion, a recently open-sourced large diffusion model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-the-daam-interpreting-stable-diffusion</guid>
    </item>
    <item>
      <title>Self-Supervised Image Restoration with Blurry and Noisy Pairs</title>
      <link>https://paperswithcode.com/paper/self-supervised-image-restoration-with-blurry</link>
      <description><![CDATA[By learning in a collaborative manner, the deblurring and denoising tasks in our method can benefit each other.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-supervised-image-restoration-with-blurry</guid>
    </item>
  </channel>
</rss>
