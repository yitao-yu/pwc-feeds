<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 20 Sep 2022 21:08:04 +0000</lastBuildDate>
    <item>
      <title>Diffusion Models: A Comprehensive Survey of Methods and Applications</title>
      <link>https://paperswithcode.com/paper/diffusion-models-a-comprehensive-survey-of</link>
      <description><![CDATA[Diffusion models are a class of deep generative models that have shown impressive results on various tasks with a solid theoretical foundation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-a-comprehensive-survey-of</guid>
    </item>
    <item>
      <title>LiT: Zero-Shot Transfer with Locked-image text Tuning</title>
      <link>https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</link>
      <description><![CDATA[This paper presents contrastive-tuning, a simple method employing contrastive training to align image and text models while still taking advantage of their pre-training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</guid>
    </item>
    <item>
      <title>Robust deep learning based protein sequence design using ProteinMPNN</title>
      <link>https://paperswithcode.com/paper/robust-deep-learning-based-protein-sequence</link>
      <description><![CDATA[While deep learning has revolutionized protein structure prediction, almost all experimentally characterized de novo protein designs have been generated using physically based approaches such as Rosetta.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-deep-learning-based-protein-sequence</guid>
    </item>
    <item>
      <title>StoryDALL-E: Adapting Pretrained Text-to-Image Transformers for Story Continuation</title>
      <link>https://paperswithcode.com/paper/storydall-e-adapting-pretrained-text-to-image</link>
      <description><![CDATA[Hence, we first propose the task of story continuation, where the generated visual story is conditioned on a source image, allowing for better generalization to narratives with new characters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/storydall-e-adapting-pretrained-text-to-image</guid>
    </item>
    <item>
      <title>High-Resolution Image Synthesis with Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</link>
      <description><![CDATA[By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</guid>
    </item>
    <item>
      <title>Audio-Visual Segmentation</title>
      <link>https://paperswithcode.com/paper/audio-visual-segmentation</link>
      <description><![CDATA[To deal with the AVS problem, we propose a novel method that uses a temporal pixel-wise audio-visual interaction module to inject audio semantics as guidance for the visual segmentation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audio-visual-segmentation</guid>
    </item>
    <item>
      <title>ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video</title>
      <link>https://paperswithcode.com/paper/esfpnet-efficient-deep-learning-architecture</link>
      <description><![CDATA[These values are superior to results achieved by other competing architectures that use Mix transformers or CNN-based encoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/esfpnet-efficient-deep-learning-architecture</guid>
    </item>
    <item>
      <title>Label Sleuth: From Unlabeled Text to a Classifier in a Few Hours</title>
      <link>https://paperswithcode.com/paper/label-sleuth-from-unlabeled-text-to-a</link>
      <description><![CDATA[Text classification can be useful in many real-world scenarios, saving a lot of time for end users.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/label-sleuth-from-unlabeled-text-to-a</guid>
    </item>
    <item>
      <title>Git Re-Basin: Merging Models modulo Permutation Symmetries</title>
      <link>https://paperswithcode.com/paper/git-re-basin-merging-models-modulo</link>
      <description><![CDATA[Experimentally, we demonstrate the single basin phenomenon across a variety of model architectures and datasets, including the first (to our knowledge) demonstration of zero-barrier linear mode connectivity between independently trained ResNet models on CIFAR-10 and CIFAR-100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/git-re-basin-merging-models-modulo</guid>
    </item>
    <item>
      <title>Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models</title>
      <link>https://paperswithcode.com/paper/generative-visual-prompt-unifying</link>
      <description><![CDATA[We demonstrate how PromptGen can control several generative models (e. g., StyleGAN2, StyleNeRF, diffusion autoencoder, and NVAE) using various off-the-shelf models: (1) with the CLIP model, PromptGen can sample images guided by text, (2) with image classifiers, PromptGen can de-bias generative models across a set of attributes, and (3) with inverse graphics models, PromptGen can sample images of the same identity in different poses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-visual-prompt-unifying</guid>
    </item>
    <item>
      <title>Fast Approximate Nearest Neighbor Search With The Navigating Spreading-out Graph</title>
      <link>https://paperswithcode.com/paper/fast-approximate-nearest-neighbor-search-with</link>
      <description><![CDATA[In this paper, to further improve the search-efficiency and scalability of graph-based methods, we start by introducing four aspects: (1) ensuring the connectivity of the graph; (2) lowering the average out-degree of the graph for fast traversal; (3) shortening the search path; and (4) reducing the index size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-approximate-nearest-neighbor-search-with</guid>
    </item>
    <item>
      <title>HUMAP: Hierarchical Uniform Manifold Approximation and Projection</title>
      <link>https://paperswithcode.com/paper/humap-hierarchical-uniform-manifold</link>
      <description><![CDATA[Dimensionality reduction (DR) techniques help analysts to understand patterns in high-dimensional spaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/humap-hierarchical-uniform-manifold</guid>
    </item>
    <item>
      <title>USB: A Unified Semi-supervised Learning Benchmark</title>
      <link>https://paperswithcode.com/paper/usb-a-unified-semi-supervised-learning</link>
      <description><![CDATA[Semi-supervised learning (SSL) improves model generalization by leveraging massive unlabeled data to augment limited labeled samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/usb-a-unified-semi-supervised-learning</guid>
    </item>
    <item>
      <title>How Well Do Sparse Imagenet Models Transfer?</title>
      <link>https://paperswithcode.com/paper/how-well-do-sparse-imagenet-models-transfer</link>
      <description><![CDATA[Transfer learning is a classic paradigm by which models pretrained on large "upstream" datasets are adapted to yield good results on "downstream" specialized datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-well-do-sparse-imagenet-models-transfer</guid>
    </item>
    <item>
      <title>GenLoco: Generalized Locomotion Controllers for Quadrupedal Robots</title>
      <link>https://paperswithcode.com/paper/genloco-generalized-locomotion-controllers</link>
      <description><![CDATA[In this work, we introduce a framework for training generalized locomotion (GenLoco) controllers for quadrupedal robots.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/genloco-generalized-locomotion-controllers</guid>
    </item>
    <item>
      <title>Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models</title>
      <link>https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</link>
      <description><![CDATA[In RDMs, a set of nearest neighbors is retrieved from an external database during training for each training instance, and the diffusion model is conditioned on these informative samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</guid>
    </item>
    <item>
      <title>Neural Architectures for Named Entity Recognition</title>
      <link>https://paperswithcode.com/paper/neural-architectures-for-named-entity</link>
      <description><![CDATA[State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-architectures-for-named-entity</guid>
    </item>
    <item>
      <title>A Deep Moving-camera Background Model</title>
      <link>https://paperswithcode.com/paper/a-deep-moving-camera-background-model</link>
      <description><![CDATA[Moreover, existing MCBMs usually model the background either on the domain of a typically-large panoramic image or in an online fashion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-deep-moving-camera-background-model</guid>
    </item>
    <item>
      <title>An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion</title>
      <link>https://paperswithcode.com/paper/an-image-is-worth-one-word-personalizing-text</link>
      <description><![CDATA[Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-image-is-worth-one-word-personalizing-text</guid>
    </item>
    <item>
      <title>FedML: A Research Library and Benchmark for Federated Machine Learning</title>
      <link>https://paperswithcode.com/paper/fedml-a-research-library-and-benchmark-for</link>
      <description><![CDATA[Federated learning (FL) is a rapidly growing research field in machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedml-a-research-library-and-benchmark-for</guid>
    </item>
  </channel>
</rss>
