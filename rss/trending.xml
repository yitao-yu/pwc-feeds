<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 08 May 2024 21:09:58 +0000</lastBuildDate>
    <item>
      <title>KAN: Kolmogorov-Arnold Networks</title>
      <link>https://paperswithcode.com/paper/kan-kolmogorov-arnold-networks</link>
      <description><![CDATA[Inspired by the Kolmogorov-Arnold representation theorem, we propose Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kan-kolmogorov-arnold-networks</guid>
    </item>
    <item>
      <title>StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation</title>
      <link>https://paperswithcode.com/paper/storydiffusion-consistent-self-attention-for</link>
      <description><![CDATA[This module converts the generated sequence of images into videos with smooth transitions and consistent subjects that are significantly more stable than the modules based on latent spaces only, especially in the context of long video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/storydiffusion-consistent-self-attention-for</guid>
    </item>
    <item>
      <title>Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models</title>
      <link>https://paperswithcode.com/paper/prometheus-2-an-open-source-language-model</link>
      <description><![CDATA[Proprietary LMs such as GPT-4 are often employed to assess the quality of responses from various LMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prometheus-2-an-open-source-language-model</guid>
    </item>
    <item>
      <title>AM-RADIO: Agglomerative Vision Foundation Model -- Reduce All Domains Into One</title>
      <link>https://paperswithcode.com/paper/am-radio-agglomerative-model-reduce-all</link>
      <description><![CDATA[A handful of visual foundation models (VFMs) have recently emerged as the backbones for numerous downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/am-radio-agglomerative-model-reduce-all</guid>
    </item>
    <item>
      <title>Improving Diffusion Models for Virtual Try-on</title>
      <link>https://paperswithcode.com/paper/improving-diffusion-models-for-virtual-try-on</link>
      <description><![CDATA[Finally, we present a customization method using a pair of person-garment images, which significantly improves fidelity and authenticity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-diffusion-models-for-virtual-try-on</guid>
    </item>
    <item>
      <title>VILA: On Pre-training for Visual Language Models</title>
      <link>https://paperswithcode.com/paper/vila-on-pre-training-for-visual-language</link>
      <description><![CDATA[Visual language models (VLMs) rapidly progressed with the recent success of large language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vila-on-pre-training-for-visual-language</guid>
    </item>
    <item>
      <title>PuLID: Pure and Lightning ID Customization via Contrastive Alignment</title>
      <link>https://paperswithcode.com/paper/pulid-pure-and-lightning-id-customization-via</link>
      <description><![CDATA[We propose Pure and Lightning ID customization (PuLID), a novel tuning-free ID customization method for text-to-image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pulid-pure-and-lightning-id-customization-via</guid>
    </item>
    <item>
      <title>RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing</title>
      <link>https://paperswithcode.com/paper/rag-and-rau-a-survey-on-retrieval-augmented</link>
      <description><![CDATA[Large Language Models (LLMs) have catalyzed significant advancements in Natural Language Processing (NLP), yet they encounter challenges such as hallucination and the need for domain-specific knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rag-and-rau-a-survey-on-retrieval-augmented</guid>
    </item>
    <item>
      <title>Spectrally Pruned Gaussian Fields with Neural Compensation</title>
      <link>https://paperswithcode.com/paper/spectrally-pruned-gaussian-fields-with-neural</link>
      <description><![CDATA[However, this comes with high memory consumption, e. g., a well-trained Gaussian field may utilize three million Gaussian primitives and over 700 MB of memory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spectrally-pruned-gaussian-fields-with-neural</guid>
    </item>
    <item>
      <title>How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites</title>
      <link>https://paperswithcode.com/paper/how-far-are-we-to-gpt-4v-closing-the-gap-to</link>
      <description><![CDATA[Compared to both open-source and proprietary models, InternVL 1. 5 shows competitive performance, achieving state-of-the-art results in 8 of 18 benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-far-are-we-to-gpt-4v-closing-the-gap-to</guid>
    </item>
    <item>
      <title>DoRA: Weight-Decomposed Low-Rank Adaptation</title>
      <link>https://paperswithcode.com/paper/dora-weight-decomposed-low-rank-adaptation</link>
      <description><![CDATA[By employing DoRA, we enhance both the learning capacity and training stability of LoRA while avoiding any additional inference overhead.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dora-weight-decomposed-low-rank-adaptation</guid>
    </item>
    <item>
      <title>MemGPT: Towards LLMs as Operating Systems</title>
      <link>https://paperswithcode.com/paper/memgpt-towards-llms-as-operating-systems</link>
      <description><![CDATA[Large language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversations and document analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memgpt-towards-llms-as-operating-systems</guid>
    </item>
    <item>
      <title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title>
      <link>https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</link>
      <description><![CDATA[We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine "next-scale prediction" or "next-resolution prediction", diverging from the standard raster-scan "next-token prediction".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</guid>
    </item>
    <item>
      <title>WavCraft: Audio Editing and Generation with Natural Language Prompts</title>
      <link>https://paperswithcode.com/paper/wavcraft-audio-editing-and-generation-with</link>
      <description><![CDATA[We introduce WavCraft, a collective system that leverages large language models (LLMs) to connect diverse task-specific models for audio content creation and editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wavcraft-audio-editing-and-generation-with</guid>
    </item>
    <item>
      <title>TensorIR: An Abstraction for Automatic Tensorized Program Optimization</title>
      <link>https://paperswithcode.com/paper/tensorir-an-abstraction-for-automatic</link>
      <description><![CDATA[Finally, we build an end-to-end framework on top of our abstraction to automatically optimize deep learning models for given tensor computation primitives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tensorir-an-abstraction-for-automatic</guid>
    </item>
    <item>
      <title>SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models</title>
      <link>https://paperswithcode.com/paper/suql-conversational-search-over-structured</link>
      <description><![CDATA[This paper presents the first conversational agent that supports the full generality of hybrid data access for large knowledge corpora, through a language we developed called SUQL (Structured and Unstructured Query Language).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/suql-conversational-search-over-structured</guid>
    </item>
    <item>
      <title>Lightplane: Highly-Scalable Components for Neural 3D Fields</title>
      <link>https://paperswithcode.com/paper/lightplane-highly-scalable-components-for</link>
      <description><![CDATA[Contemporary 3D research, particularly in reconstruction and generation, heavily relies on 2D images for inputs or supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightplane-highly-scalable-components-for</guid>
    </item>
    <item>
      <title>Transcending Forgery Specificity with Latent Space Augmentation for Generalizable Deepfake Detection</title>
      <link>https://paperswithcode.com/paper/transcending-forgery-specificity-with-latent</link>
      <description><![CDATA[Deepfake detection faces a critical generalization hurdle, with performance deteriorating when there is a mismatch between the distributions of training and testing data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transcending-forgery-specificity-with-latent</guid>
    </item>
    <item>
      <title>Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/groma-localized-visual-tokenization-for</link>
      <description><![CDATA[We introduce Groma, a Multimodal Large Language Model (MLLM) with grounded and fine-grained visual perception ability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/groma-localized-visual-tokenization-for</guid>
    </item>
    <item>
      <title>AgentScope: A Flexible yet Robust Multi-Agent Platform</title>
      <link>https://paperswithcode.com/paper/agentscope-a-flexible-yet-robust-multi-agent</link>
      <description><![CDATA[With the rapid advancement of Large Language Models (LLMs), significant progress has been made in multi-agent applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentscope-a-flexible-yet-robust-multi-agent</guid>
    </item>
  </channel>
</rss>
