<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 05 Sep 2022 09:16:36 +0000</lastBuildDate>
    <item>
      <title>Transformers are Sample Efficient World Models</title>
      <link>https://paperswithcode.com/paper/transformers-are-sample-efficient-world</link>
      <description><![CDATA[Deep reinforcement learning agents are notoriously sample inefficient, which considerably limits their application to real-world problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/transformers-are-sample-efficient-world</guid>
    </item>
    <item>
      <title>Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models</title>
      <link>https://paperswithcode.com/paper/adan-adaptive-nesterov-momentum-algorithm-for</link>
      <description><![CDATA[Then Adan adopts NME to estimate the first- and second-order moments of the gradient in adaptive gradient algorithms for convergence acceleration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adan-adaptive-nesterov-momentum-algorithm-for</guid>
    </item>
    <item>
      <title>YOLOX-PAI: An Improved YOLOX, Stronger and Faster than YOLOv6</title>
      <link>https://paperswithcode.com/paper/yolox-pai-an-improved-yolox-version-by-pai</link>
      <description><![CDATA[We develop an all-in-one computer vision toolbox named EasyCV to facilitate the use of various SOTA computer vision methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolox-pai-an-improved-yolox-version-by-pai</guid>
    </item>
    <item>
      <title>FILM: Frame Interpolation for Large Motion</title>
      <link>https://paperswithcode.com/paper/film-frame-interpolation-for-large-motion</link>
      <description><![CDATA[Recent methods use multiple networks to estimate optical flow or depth and a separate network dedicated to frame synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/film-frame-interpolation-for-large-motion</guid>
    </item>
    <item>
      <title>MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction</title>
      <link>https://paperswithcode.com/paper/maptr-structured-modeling-and-learning-for</link>
      <description><![CDATA[We adopt a hierarchical query embedding scheme to flexibly encode structured map information and perform hierarchical bipartite matching for map element learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/maptr-structured-modeling-and-learning-for</guid>
    </item>
    <item>
      <title>Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models</title>
      <link>https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</link>
      <description><![CDATA[In RDMs, a set of nearest neighbors is retrieved from an external database during training for each training instance, and the diffusion model is conditioned on these informative samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</guid>
    </item>
    <item>
      <title>FedBN: Federated Learning on Non-IID Features via Local Batch Normalization</title>
      <link>https://paperswithcode.com/paper/fedbn-federated-learning-on-non-iid-features-1</link>
      <description><![CDATA[The emerging paradigm of federated learning (FL) strives to enable collaborative training of deep models on the network edge without centrally aggregating raw data and hence improving data privacy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedbn-federated-learning-on-non-iid-features-1</guid>
    </item>
    <item>
      <title>Multi-instrument Music Synthesis with Spectrogram Diffusion</title>
      <link>https://paperswithcode.com/paper/multi-instrument-music-synthesis-with</link>
      <description><![CDATA[An ideal music synthesizer should be both interactive and expressive, generating high-fidelity audio in realtime for arbitrary combinations of instruments and notes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multi-instrument-music-synthesis-with</guid>
    </item>
    <item>
      <title>An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion</title>
      <link>https://paperswithcode.com/paper/an-image-is-worth-one-word-personalizing-text</link>
      <description><![CDATA[Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-image-is-worth-one-word-personalizing-text</guid>
    </item>
    <item>
      <title>ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video</title>
      <link>https://paperswithcode.com/paper/esfpnet-efficient-deep-learning-architecture</link>
      <description><![CDATA[These values are superior to results achieved by other competing architectures that use Mix transformers or CNN-based encoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/esfpnet-efficient-deep-learning-architecture</guid>
    </item>
    <item>
      <title>Dual-Space NeRF: Learning Animatable Avatars and Scene Lighting in Separate Spaces</title>
      <link>https://paperswithcode.com/paper/dual-space-nerf-learning-animatable-avatars</link>
      <description><![CDATA[Previous methods alleviate the inconsistency of lighting by learning a per-frame embedding, but this operation does not generalize to unseen poses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-space-nerf-learning-animatable-avatars</guid>
    </item>
    <item>
      <title>PyTorch Image Quality: Metrics for Image Quality Assessment</title>
      <link>https://paperswithcode.com/paper/pytorch-image-quality-metrics-for-image</link>
      <description><![CDATA[Image Quality Assessment (IQA) metrics are widely used to quantitatively estimate the extent of image degradation following some forming, restoring, transforming, or enhancing algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pytorch-image-quality-metrics-for-image</guid>
    </item>
    <item>
      <title>YOLOPv2: Better, Faster, Stronger for Panoptic Driving Perception</title>
      <link>https://paperswithcode.com/paper/yolopv2-better-faster-stronger-for-panoptic</link>
      <description><![CDATA[Over the last decade, multi-tasking learning approaches have achieved promising results in solving panoptic driving perception problems, providing both high-precision and high-efficiency performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolopv2-better-faster-stronger-for-panoptic</guid>
    </item>
    <item>
      <title>LibMTL: A Python Library for Multi-Task Learning</title>
      <link>https://paperswithcode.com/paper/libmtl-a-python-library-for-multi-task</link>
      <description><![CDATA[This paper presents LibMTL, an open-source Python library built on PyTorch, which provides a unified, comprehensive, reproducible, and extensible implementation framework for Multi-Task Learning (MTL).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/libmtl-a-python-library-for-multi-task</guid>
    </item>
    <item>
      <title>Audio-Visual Segmentation</title>
      <link>https://paperswithcode.com/paper/audio-visual-segmentation</link>
      <description><![CDATA[To deal with the AVS problem, we propose a novel method that uses a temporal pixel-wise audio-visual interaction module to inject audio semantics as guidance for the visual segmentation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audio-visual-segmentation</guid>
    </item>
    <item>
      <title>Improving Diffusion Model Efficiency Through Patching</title>
      <link>https://paperswithcode.com/paper/improving-diffusion-model-efficiency-through</link>
      <description><![CDATA[Diffusion models are a powerful class of generative models that iteratively denoise samples to produce data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-diffusion-model-efficiency-through</guid>
    </item>
    <item>
      <title>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</title>
      <link>https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</link>
      <description><![CDATA[YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56. 8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov7-trainable-bag-of-freebies-sets-new</guid>
    </item>
    <item>
      <title>ETSformer: Exponential Smoothing Transformers for Time-series Forecasting</title>
      <link>https://paperswithcode.com/paper/etsformer-exponential-smoothing-transformers</link>
      <description><![CDATA[Transformers have been actively studied for time-series forecasting in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/etsformer-exponential-smoothing-transformers</guid>
    </item>
    <item>
      <title>Reconstructing 3D Human Pose by Watching Humans in the Mirror</title>
      <link>https://paperswithcode.com/paper/reconstructing-3d-human-pose-by-watching</link>
      <description><![CDATA[In this paper, we introduce the new task of reconstructing 3D human pose from a single image in which we can see the person and the person's image through a mirror.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reconstructing-3d-human-pose-by-watching</guid>
    </item>
    <item>
      <title>Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild</title>
      <link>https://paperswithcode.com/paper/gradio-hassle-free-sharing-and-testing-of-ml</link>
      <description><![CDATA[Their feedback identified that Gradio should support a variety of interfaces and frameworks, allow for easy sharing of the interface, allow for input manipulation and interactive inference by the domain expert, as well as allow embedding the interface in iPython notebooks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gradio-hassle-free-sharing-and-testing-of-ml</guid>
    </item>
  </channel>
</rss>
