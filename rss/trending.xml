<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 03 Nov 2022 21:07:47 +0000</lastBuildDate>
    <item>
      <title>High Fidelity Neural Audio Compression</title>
      <link>https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</link>
      <description><![CDATA[We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</guid>
    </item>
    <item>
      <title>Lightweight and High-Fidelity End-to-End Text-to-Speech with Multi-Band Generation and Inverse Short-Time Fourier Transform</title>
      <link>https://paperswithcode.com/paper/lightweight-and-high-fidelity-end-to-end-text</link>
      <description><![CDATA[We propose a lightweight end-to-end text-to-speech model using multi-band generation and inverse short-time Fourier transform.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightweight-and-high-fidelity-end-to-end-text</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>Vox-Fusion: Dense Tracking and Mapping with Voxel-based Neural Implicit Representation</title>
      <link>https://paperswithcode.com/paper/vox-fusion-dense-tracking-and-mapping-with</link>
      <description><![CDATA[In this work, we present a dense tracking and mapping system named Vox-Fusion, which seamlessly fuses neural implicit representations with traditional volumetric fusion methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vox-fusion-dense-tracking-and-mapping-with</guid>
    </item>
    <item>
      <title>DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models</title>
      <link>https://paperswithcode.com/paper/diffusiondb-a-large-scale-prompt-gallery</link>
      <description><![CDATA[We analyze prompts in the dataset and discuss key properties of these prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondb-a-large-scale-prompt-gallery</guid>
    </item>
    <item>
      <title>Elucidating the Design Space of Diffusion-Based Generative Models</title>
      <link>https://paperswithcode.com/paper/elucidating-the-design-space-of-diffusion</link>
      <description><![CDATA[We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/elucidating-the-design-space-of-diffusion</guid>
    </item>
    <item>
      <title>What Makes Convolutional Models Great on Long Sequence Modeling?</title>
      <link>https://paperswithcode.com/paper/what-makes-convolutional-models-great-on-long</link>
      <description><![CDATA[We focus on the structure of the convolution kernel and identify two critical but intuitive principles enjoyed by S4 that are sufficient to make up an effective global convolutional model: 1) The parameterization of the convolutional kernel needs to be efficient in the sense that the number of parameters should scale sub-linearly with sequence length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-makes-convolutional-models-great-on-long</guid>
    </item>
    <item>
      <title>UniInst: Unique Representation for End-to-End Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/uniinst-unique-representation-for-end-to-end</link>
      <description><![CDATA[Existing instance segmentation methods have achieved impressive performance but still suffer from a common dilemma: redundant representations (e. g., multiple boxes, grids, and anchor points) are inferred for one instance, which leads to multiple duplicated predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uniinst-unique-representation-for-end-to-end</guid>
    </item>
    <item>
      <title>Text-Only Training for Image Captioning using Noise-Injected CLIP</title>
      <link>https://paperswithcode.com/paper/text-only-training-for-image-captioning-using</link>
      <description><![CDATA[We consider the task of image-captioning using only the CLIP model and additional text data at training time, and no additional captioned images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-only-training-for-image-captioning-using</guid>
    </item>
    <item>
      <title>Referring Image Matting</title>
      <link>https://paperswithcode.com/paper/referring-image-matting</link>
      <description><![CDATA[Image matting refers to extracting the accurate foregrounds in the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/referring-image-matting</guid>
    </item>
    <item>
      <title>Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models</title>
      <link>https://paperswithcode.com/paper/adan-adaptive-nesterov-momentum-algorithm-for</link>
      <description><![CDATA[Then Adan adopts NME to estimate the first- and second-order moments of the gradient in adaptive gradient algorithms for convergence acceleration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adan-adaptive-nesterov-momentum-algorithm-for</guid>
    </item>
    <item>
      <title>Adapting Pretrained Text-to-Text Models for Long Text Sequences</title>
      <link>https://paperswithcode.com/paper/adapting-pretrained-text-to-text-models-for</link>
      <description><![CDATA[We present an empirical study of adapting an existing pretrained text-to-text model for long-sequence inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adapting-pretrained-text-to-text-models-for</guid>
    </item>
    <item>
      <title>Rethinking Portrait Matting with Privacy Preserving</title>
      <link>https://paperswithcode.com/paper/rethinking-portrait-matting-with-privacy</link>
      <description><![CDATA[We systematically evaluate both trimap-free and trimap-based matting methods on P3M-10k and find that existing matting methods show different generalization abilities under the privacy preserving training setting, i. e., training only on face-blurred images while testing on arbitrary images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-portrait-matting-with-privacy</guid>
    </item>
    <item>
      <title>A Surprising Thing: The Application of Machine Learning Ensembles and Signal Theory to Predict Earnings Surprises</title>
      <link>https://paperswithcode.com/paper/a-surprising-thing-the-application-of-machine</link>
      <description><![CDATA[Nonlinear classification models can predict future earnings surprises with a high accuracy by using pricing and earnings input data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-surprising-thing-the-application-of-machine</guid>
    </item>
    <item>
      <title>VSA: Learning Varied-Size Window Attention in Vision Transformers</title>
      <link>https://paperswithcode.com/paper/vsa-learning-varied-size-window-attention-in</link>
      <description><![CDATA[Attention within windows has been widely explored in vision transformers to balance the performance, computation complexity, and memory footprint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vsa-learning-varied-size-window-attention-in</guid>
    </item>
    <item>
      <title>DreamFusion: Text-to-3D using 2D Diffusion</title>
      <link>https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</link>
      <description><![CDATA[Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</guid>
    </item>
    <item>
      <title>Monocular Dynamic View Synthesis: A Reality Check</title>
      <link>https://paperswithcode.com/paper/monocular-dynamic-view-synthesis-a-reality</link>
      <description><![CDATA[We study the recent progress on dynamic view synthesis (DVS) from monocular video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monocular-dynamic-view-synthesis-a-reality</guid>
    </item>
    <item>
      <title>Human Motion Diffusion Model</title>
      <link>https://paperswithcode.com/paper/human-motion-diffusion-model</link>
      <description><![CDATA[In this paper, we introduce Motion Diffusion Model (MDM), a carefully adapted classifier-free diffusion-based generative model for the human motion domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/human-motion-diffusion-model</guid>
    </item>
    <item>
      <title>Lila: A Unified Benchmark for Mathematical Reasoning</title>
      <link>https://paperswithcode.com/paper/lila-a-unified-benchmark-for-mathematical</link>
      <description><![CDATA[Mathematical reasoning skills are essential for general-purpose intelligent systems to perform tasks from grocery shopping to climate modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lila-a-unified-benchmark-for-mathematical</guid>
    </item>
    <item>
      <title>Advancing Plain Vision Transformer Towards Remote Sensing Foundation Model</title>
      <link>https://paperswithcode.com/paper/advancing-plain-vision-transformer-towards</link>
      <description><![CDATA[In this paper, we resort to plain vision transformers with about 100 million parameters and make the first attempt to propose large vision models customized for RS tasks and explore how such large models perform.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-plain-vision-transformer-towards</guid>
    </item>
  </channel>
</rss>
