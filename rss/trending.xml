<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 06 Jan 2025 21:08:55 +0000</lastBuildDate>
    <item>
      <title>Monolith: Real Time Recommendation System With Collisionless Embedding Table</title>
      <link>https://paperswithcode.com/paper/monolith-real-time-recommendation-system-with</link>
      <description><![CDATA[In this paper, we present Monolith, a system tailored for online training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monolith-real-time-recommendation-system-with</guid>
    </item>
    <item>
      <title>DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence</title>
      <link>https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</link>
      <description><![CDATA[The rapid development of large language models has revolutionized code intelligence in software development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</guid>
    </item>
    <item>
      <title>DeepSeek-V3 Technical Report</title>
      <link>https://paperswithcode.com/paper/deepseek-v3-technical-report</link>
      <description><![CDATA[We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-v3-technical-report</guid>
    </item>
    <item>
      <title>LatentSync: Audio Conditioned Latent Diffusion Models for Lip Sync</title>
      <link>https://paperswithcode.com/paper/latentsync-audio-conditioned-latent-diffusion</link>
      <description><![CDATA[Since we did not change the overall training framework of SyncNet, our experience can also be applied to other lip sync and audio-driven portrait animation methods that utilize SyncNet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latentsync-audio-conditioned-latent-diffusion</guid>
    </item>
    <item>
      <title>Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations</title>
      <link>https://paperswithcode.com/paper/into-the-unknown-unknowns-engaged-human</link>
      <description><![CDATA[While language model (LM)-powered chatbots and generative search engines excel at answering concrete queries, discovering information in the terrain of unknown unknowns remains challenging for users.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/into-the-unknown-unknowns-engaged-human</guid>
    </item>
    <item>
      <title>KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation</title>
      <link>https://paperswithcode.com/paper/2409-13731</link>
      <description><![CDATA[The recently developed retrieval-augmented generation (RAG) technology has enabled the efficient construction of domain-specific applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2409-13731</guid>
    </item>
    <item>
      <title>TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization</title>
      <link>https://paperswithcode.com/paper/tangoflux-super-fast-and-faithful-text-to</link>
      <description><![CDATA[We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44. 1kHz audio in just 3. 7 seconds on a single A40 GPU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tangoflux-super-fast-and-faithful-text-to</guid>
    </item>
    <item>
      <title>Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/reconstruction-vs-generation-taming-1</link>
      <description><![CDATA[The integrated system achieves state-of-the-art (SOTA) performance on ImageNet 256x256 generation with an FID score of 1. 35 while demonstrating remarkable training efficiency by reaching an FID score of 2. 11 in just 64 epochs--representing an over 21 times convergence speedup compared to the original DiT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reconstruction-vs-generation-taming-1</guid>
    </item>
    <item>
      <title>Large Concept Models: Language Modeling in a Sentence Representation Space</title>
      <link>https://paperswithcode.com/paper/large-concept-models-language-modeling-in-a</link>
      <description><![CDATA[In this paper, we present an attempt at an architecture which operates on an explicit higher-level semantic representation, which we name a concept.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-concept-models-language-modeling-in-a</guid>
    </item>
    <item>
      <title>HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs</title>
      <link>https://paperswithcode.com/paper/huatuogpt-o1-towards-medical-complex</link>
      <description><![CDATA[To address this, we propose verifiable medical problems with a medical verifier to check the correctness of model outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huatuogpt-o1-towards-medical-complex</guid>
    </item>
    <item>
      <title>Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</link>
      <description><![CDATA[We present Infinity, a Bitwise Visual AutoRegressive Modeling capable of generating high-resolution, photorealistic images following language instruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infinity-scaling-bitwise-autoregressive</guid>
    </item>
    <item>
      <title>Story-Adapter: A Training-free Iterative Framework for Long Story Visualization</title>
      <link>https://paperswithcode.com/paper/story-adapter-a-training-free-iterative</link>
      <description><![CDATA[Specifically, we propose an iterative paradigm to refine each generated image, leveraging both the text prompt and all generated images from the previous iteration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/story-adapter-a-training-free-iterative</guid>
    </item>
    <item>
      <title>Memory Layers at Scale</title>
      <link>https://paperswithcode.com/paper/memory-layers-at-scale</link>
      <description><![CDATA[We provide a fully parallelizable memory layer implementation, demonstrating scaling laws with up to 128B memory parameters, pretrained to 1 trillion tokens, comparing to base models with up to 8B parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memory-layers-at-scale</guid>
    </item>
    <item>
      <title>TryOffAnyone: Tiled Cloth Generation from a Dressed Person</title>
      <link>https://paperswithcode.com/paper/tryoffanyone-tiled-cloth-generation-from-a</link>
      <description><![CDATA[The fashion industry is increasingly leveraging computer vision and deep learning technologies to enhance online shopping experiences and operational efficiencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tryoffanyone-tiled-cloth-generation-from-a</guid>
    </item>
    <item>
      <title>VMix: Improving Text-to-Image Diffusion Model with Cross-Attention Mixing Control</title>
      <link>https://paperswithcode.com/paper/vmix-improving-text-to-image-diffusion-model</link>
      <description><![CDATA[While diffusion models show extraordinary talents in text-to-image generation, they may still fail to generate highly aesthetic images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vmix-improving-text-to-image-diffusion-model</guid>
    </item>
    <item>
      <title>Edicho: Consistent Image Editing in the Wild</title>
      <link>https://paperswithcode.com/paper/edicho-consistent-image-editing-in-the-wild</link>
      <description><![CDATA[As a verified need, consistent editing across in-the-wild images remains a technical challenge arising from various unmanageable factors, like object poses, lighting conditions, and photography environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edicho-consistent-image-editing-in-the-wild</guid>
    </item>
    <item>
      <title>Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks</title>
      <link>https://paperswithcode.com/paper/don-t-do-rag-when-cache-augmented-generation</link>
      <description><![CDATA[With the advent of large language models (LLMs) featuring significantly extended context windows, this paper proposes an alternative paradigm, cache-augmented generation (CAG) that bypasses real-time retrieval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/don-t-do-rag-when-cache-augmented-generation</guid>
    </item>
    <item>
      <title>Superposition in Transformers: A Novel Way of Building Mixture of Experts</title>
      <link>https://paperswithcode.com/paper/superposition-in-transformers-a-novel-way-of</link>
      <description><![CDATA[Catastrophic forgetting remains a major challenge when adapting large language models (LLMs) to new tasks or domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/superposition-in-transformers-a-novel-way-of</guid>
    </item>
    <item>
      <title>TorchTitan: One-stop PyTorch native solution for production ready LLM pre-training</title>
      <link>https://paperswithcode.com/paper/torchtitan-one-stop-pytorch-native-solution</link>
      <description><![CDATA[By stacking training optimizations, we demonstrate accelerations of 65. 08% with 1D parallelism at the 128-GPU scale (Llama 3. 1 8B), an additional 12. 59% with 2D parallelism at the 256-GPU scale (Llama 3. 1 70B), and an additional 30% with 3D parallelism at the 512-GPU scale (Llama 3. 1 405B) on NVIDIA H100 GPUs over optimized baselines.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchtitan-one-stop-pytorch-native-solution</guid>
    </item>
    <item>
      <title>VidTwin: Video VAE with Decoupled Structure and Dynamics</title>
      <link>https://paperswithcode.com/paper/vidtwin-video-vae-with-decoupled-structure</link>
      <description><![CDATA[Recent advancements in video autoencoders (Video AEs) have significantly improved the quality and efficiency of video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vidtwin-video-vae-with-decoupled-structure</guid>
    </item>
  </channel>
</rss>
