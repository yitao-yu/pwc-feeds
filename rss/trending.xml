<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 25 Sep 2024 21:09:16 +0000</lastBuildDate>
    <item>
      <title>3DTopia-XL: Scaling High-quality 3D Asset Generation via Primitive Diffusion</title>
      <link>https://paperswithcode.com/paper/3dtopia-xl-scaling-high-quality-3d-asset</link>
      <description><![CDATA[The increasing demand for high-quality 3D assets across various industries necessitates efficient and automated 3D content creation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dtopia-xl-scaling-high-quality-3d-asset</guid>
    </item>
    <item>
      <title>MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery</title>
      <link>https://paperswithcode.com/paper/memorag-moving-towards-next-gen-rag-via</link>
      <description><![CDATA[Retrieval-Augmented Generation (RAG) leverages retrieval tools to access external databases, thereby enhancing the generation quality of large language models (LLMs) through optimized context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/memorag-moving-towards-next-gen-rag-via</guid>
    </item>
    <item>
      <title>OmniGen: Unified Image Generation</title>
      <link>https://paperswithcode.com/paper/omnigen-unified-image-generation</link>
      <description><![CDATA[In this work, we introduce OmniGen, a new diffusion model for unified image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnigen-unified-image-generation</guid>
    </item>
    <item>
      <title>StoryMaker: Towards Holistic Consistent Characters in Text-to-image Generation</title>
      <link>https://paperswithcode.com/paper/storymaker-towards-holistic-consistent</link>
      <description><![CDATA[However, the lack of holistic consistency in scenes with multiple characters hampers these methods' ability to create a cohesive narrative.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/storymaker-towards-holistic-consistent</guid>
    </item>
    <item>
      <title>LLaMA-Omni: Seamless Speech Interaction with Large Language Models</title>
      <link>https://paperswithcode.com/paper/llama-omni-seamless-speech-interaction-with</link>
      <description><![CDATA[We build our model based on the latest Llama-3. 1-8B-Instruct model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-omni-seamless-speech-interaction-with</guid>
    </item>
    <item>
      <title>Kolmogorov-Arnold Transformer</title>
      <link>https://paperswithcode.com/paper/kolmogorov-arnold-transformer</link>
      <description><![CDATA[In this paper, we introduce the Kolmogorov-Arnold Transformer (KAT), a novel architecture that replaces MLP layers with Kolmogorov-Arnold Network (KAN) layers to enhance the expressiveness and performance of the model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kolmogorov-arnold-transformer</guid>
    </item>
    <item>
      <title>QA-MDT: Quality-aware Masked Diffusion Transformer for Enhanced Music Generation</title>
      <link>https://paperswithcode.com/paper/quality-aware-masked-diffusion-transformer</link>
      <description><![CDATA[In recent years, diffusion-based text-to-music (TTM) generation has gained prominence, offering an innovative approach to synthesizing musical content from textual descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quality-aware-masked-diffusion-transformer</guid>
    </item>
    <item>
      <title>Oryx MLLM: On-Demand Spatial-Temporal Understanding at Arbitrary Resolution</title>
      <link>https://paperswithcode.com/paper/oryx-mllm-on-demand-spatial-temporal</link>
      <description><![CDATA[Visual data comes in various forms, ranging from small icons of just a few pixels to long videos spanning hours.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oryx-mllm-on-demand-spatial-temporal</guid>
    </item>
    <item>
      <title>Fine-Tuning Image-Conditional Diffusion Models is Easier than You Think</title>
      <link>https://paperswithcode.com/paper/fine-tuning-image-conditional-diffusion</link>
      <description><![CDATA[Recent work showed that large diffusion models can be reused as highly precise monocular depth estimators by casting depth estimation as an image-conditional image generation task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fine-tuning-image-conditional-diffusion</guid>
    </item>
    <item>
      <title>Qwen2 Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-technical-report</link>
      <description><![CDATA[This report introduces the Qwen2 series, the latest addition to our large language models and large multimodal models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-technical-report</guid>
    </item>
    <item>
      <title>3DGS-LM: Faster Gaussian-Splatting Optimization with Levenberg-Marquardt</title>
      <link>https://paperswithcode.com/paper/3dgs-lm-faster-gaussian-splatting</link>
      <description><![CDATA[We present 3DGS-LM, a new method that accelerates the reconstruction of 3D Gaussian Splatting (3DGS) by replacing its ADAM optimizer with a tailored Levenberg-Marquardt (LM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3dgs-lm-faster-gaussian-splatting</guid>
    </item>
    <item>
      <title>SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning</title>
      <link>https://paperswithcode.com/paper/sciagents-automating-scientific-discovery</link>
      <description><![CDATA[A key challenge in artificial intelligence is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sciagents-automating-scientific-discovery</guid>
    </item>
    <item>
      <title>Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution</title>
      <link>https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</link>
      <description><![CDATA[We present the Qwen2-VL Series, an advanced upgrade of the previous Qwen-VL models that redefines the conventional predetermined-resolution approach in visual processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</guid>
    </item>
    <item>
      <title>Wings: Learning Multimodal LLMs without Text-only Forgetting</title>
      <link>https://paperswithcode.com/paper/wings-learning-multimodal-llms-without-text</link>
      <description><![CDATA[Initially, image and text inputs are aligned with visual learners operating alongside the main attention, balancing focus on visual elements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wings-learning-multimodal-llms-without-text</guid>
    </item>
    <item>
      <title>optillm</title>
      <link>https://github.com/codelion/optillm</link>
      <description><![CDATA[Optimizing inference proxy for LLMs]]></description>
      <guid isPermaLink="true">https://github.com/codelion/optillm</guid>
    </item>
    <item>
      <title>On the Diagram of Thought</title>
      <link>https://paperswithcode.com/paper/on-the-diagram-of-thought</link>
      <description><![CDATA[We introduce Diagram of Thought (DoT), a framework that models iterative reasoning in large language models (LLMs) as the construction of a directed acyclic graph (DAG) within a single model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-diagram-of-thought</guid>
    </item>
    <item>
      <title>Internal Consistency and Self-Feedback in Large Language Models: A Survey</title>
      <link>https://paperswithcode.com/paper/internal-consistency-and-self-feedback-in</link>
      <description><![CDATA[In this paper, we use a unified perspective of internal consistency, offering explanations for reasoning deficiencies and hallucinations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internal-consistency-and-self-feedback-in</guid>
    </item>
    <item>
      <title>Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models</title>
      <link>https://paperswithcode.com/paper/assisting-in-writing-wikipedia-like-articles</link>
      <description><![CDATA[We study how to apply large language models to write grounded and organized long-form articles from scratch, with comparable breadth and depth to Wikipedia pages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/assisting-in-writing-wikipedia-like-articles</guid>
    </item>
    <item>
      <title>A Conditional Denoising Diffusion Probabilistic Model for Point Cloud Upsampling</title>
      <link>https://paperswithcode.com/paper/a-conditional-denoising-diffusion-1</link>
      <description><![CDATA[Most of the existing point cloud upsampling methods focus on sparse point cloud feature extraction and upsampling module design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-conditional-denoising-diffusion-1</guid>
    </item>
    <item>
      <title>Training Language Models to Self-Correct via Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/training-language-models-to-self-correct-via</link>
      <description><![CDATA[In particular, we observe that training via SFT either suffers from a distribution mismatch between the training data and the model's own responses or implicitly prefers only a certain mode of correction behavior that is often not effective at test time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-language-models-to-self-correct-via</guid>
    </item>
  </channel>
</rss>
