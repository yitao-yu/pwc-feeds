<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 15 Feb 2024 21:06:37 +0000</lastBuildDate>
    <item>
      <title>Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models</title>
      <link>https://paperswithcode.com/paper/self-play-fine-tuning-converts-weak-language</link>
      <description><![CDATA[In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-play-fine-tuning-converts-weak-language</guid>
    </item>
    <item>
      <title>Guiding Instruction-based Image Editing via Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/guiding-instruction-based-image-editing-via</link>
      <description><![CDATA[Extensive experimental results demonstrate that expressive instructions are crucial to instruction-based image editing, and our MGIE can lead to a notable improvement in automatic metrics and human evaluation while maintaining competitive inference efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/guiding-instruction-based-image-editing-via</guid>
    </item>
    <item>
      <title>GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information</title>
      <link>https://paperswithcode.com/paper/genegpt-teaching-large-language-models-to-use</link>
      <description><![CDATA[In this paper, we present GeneGPT, a novel method for teaching LLMs to use the Web APIs of the National Center for Biotechnology Information (NCBI) for answering genomics questions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/genegpt-teaching-large-language-models-to-use</guid>
    </item>
    <item>
      <title>The boundary of neural network trainability is fractal</title>
      <link>https://paperswithcode.com/paper/the-boundary-of-neural-network-trainability</link>
      <description><![CDATA[Some fractals -- for instance those associated with the Mandelbrot and quadratic Julia sets -- are computed by iterating a function, and identifying the boundary between hyperparameters for which the resulting series diverges or remains bounded.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-boundary-of-neural-network-trainability</guid>
    </item>
    <item>
      <title>UFO: A UI-Focused Agent for Windows OS Interaction</title>
      <link>https://paperswithcode.com/paper/ufo-a-ui-focused-agent-for-windows-os</link>
      <description><![CDATA[We introduce UFO, an innovative UI-Focused agent to fulfill user requests tailored to applications on Windows OS, harnessing the capabilities of GPT-Vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ufo-a-ui-focused-agent-for-windows-os</guid>
    </item>
    <item>
      <title>Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models</title>
      <link>https://paperswithcode.com/paper/fiddler-cpu-gpu-orchestration-for-fast</link>
      <description><![CDATA[Large Language Models (LLMs) based on Mixture-of-Experts (MoE) architecture are showing promising performance on various tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fiddler-cpu-gpu-orchestration-for-fast</guid>
    </item>
    <item>
      <title>Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/lag-llama-towards-foundation-models-for-time</link>
      <description><![CDATA[Over the past years, foundation models have caused a paradigm shift in machine learning due to their unprecedented capabilities for zero-shot and few-shot generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lag-llama-towards-foundation-models-for-time</guid>
    </item>
    <item>
      <title>Learning to Fly in Seconds</title>
      <link>https://paperswithcode.com/paper/learning-to-fly-in-seconds</link>
      <description><![CDATA[Our framework enables Simulation-to-Reality (Sim2Real) transfer for direct RPM control after only 18 seconds of training on a consumer-grade laptop as well as its deployment on microcontrollers to control a multirotor under real-time guarantees.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-fly-in-seconds</guid>
    </item>
    <item>
      <title>Fast Timing-Conditioned Latent Audio Diffusion</title>
      <link>https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</link>
      <description><![CDATA[Generating long-form 44. 1kHz stereo audio from text prompts can be computationally demanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</guid>
    </item>
    <item>
      <title>World Model on Million-Length Video And Language With RingAttention</title>
      <link>https://paperswithcode.com/paper/world-model-on-million-length-video-and</link>
      <description><![CDATA[This work paves the way for training on massive datasets of long video and language to develop understanding of both human knowledge and the multimodal world, and broader capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/world-model-on-million-length-video-and</guid>
    </item>
    <item>
      <title>YOLO-World: Real-Time Open-Vocabulary Object Detection</title>
      <link>https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</link>
      <description><![CDATA[The You Only Look Once (YOLO) series of detectors have established themselves as efficient and practical tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</guid>
    </item>
    <item>
      <title>Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception</title>
      <link>https://paperswithcode.com/paper/mobile-agent-autonomous-multi-modal-mobile</link>
      <description><![CDATA[To assess the performance of Mobile-Agent, we introduced Mobile-Eval, a benchmark for evaluating mobile device operations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobile-agent-autonomous-multi-modal-mobile</guid>
    </item>
    <item>
      <title>GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators</title>
      <link>https://paperswithcode.com/paper/gentranslate-large-language-models-are</link>
      <description><![CDATA[Leveraging the rich linguistic knowledge and strong reasoning abilities of LLMs, our new paradigm can integrate the rich information in N-best candidates to generate a higher-quality translation result.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gentranslate-large-language-models-are</guid>
    </item>
    <item>
      <title>Forgedit: Text Guided Image Editing via Learning and Forgetting</title>
      <link>https://paperswithcode.com/paper/forgedit-text-guided-image-editing-via</link>
      <description><![CDATA[Text guided image editing on real images given only the image and the target text prompt as inputs, is a very general and challenging problem, which requires the editing model to reason by itself which part of the image should be edited, to preserve the characteristics of original image, and also to perform complicated non-rigid editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/forgedit-text-guided-image-editing-via</guid>
    </item>
    <item>
      <title>LESS: Selecting Influential Data for Targeted Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/less-selecting-influential-data-for-targeted</link>
      <description><![CDATA[Instruction tuning has unlocked powerful capabilities in large language models (LLMs), effectively using combined datasets to develop generalpurpose chatbots.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-selecting-influential-data-for-targeted</guid>
    </item>
    <item>
      <title>Self-Discover: Large Language Models Self-Compose Reasoning Structures</title>
      <link>https://paperswithcode.com/paper/self-discover-large-language-models-self</link>
      <description><![CDATA[We introduce SELF-DISCOVER, a general framework for LLMs to self-discover the task-intrinsic reasoning structures to tackle complex reasoning problems that are challenging for typical prompting methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-discover-large-language-models-self</guid>
    </item>
    <item>
      <title>InstantID: Zero-shot Identity-Preserving Generation in Seconds</title>
      <link>https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</link>
      <description><![CDATA[There has been significant progress in personalized image synthesis with methods such as Textual Inversion, DreamBooth, and LoRA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</guid>
    </item>
    <item>
      <title>MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</title>
      <link>https://paperswithcode.com/paper/multihop-rag-benchmarking-retrieval-augmented</link>
      <description><![CDATA[We hope MultiHop-RAG will be a valuable resource for the community in developing effective RAG systems, thereby facilitating greater adoption of LLMs in practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multihop-rag-benchmarking-retrieval-augmented</guid>
    </item>
    <item>
      <title>OLMo: Accelerating the Science of Language Models</title>
      <link>https://paperswithcode.com/paper/olmo-accelerating-the-science-of-language</link>
      <description><![CDATA[Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community to have access to powerful, truly open LMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/olmo-accelerating-the-science-of-language</guid>
    </item>
    <item>
      <title>Executable Code Actions Elicit Better LLM Agents</title>
      <link>https://paperswithcode.com/paper/executable-code-actions-elicit-better-llm</link>
      <description><![CDATA[LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e. g., the scope of pre-defined tools) and restricted flexibility (e. g., inability to compose multiple tools).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/executable-code-actions-elicit-better-llm</guid>
    </item>
  </channel>
</rss>
