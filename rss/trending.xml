<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 20 Jan 2023 09:13:21 +0000</lastBuildDate>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>InstructPix2Pix: Learning to Follow Image Editing Instructions</title>
      <link>https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</link>
      <description><![CDATA[We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</guid>
    </item>
    <item>
      <title>Msanii: High Fidelity Music Synthesis on a Shoestring Budget</title>
      <link>https://paperswithcode.com/paper/msanii-high-fidelity-music-synthesis-on-a</link>
      <description><![CDATA[In this paper, we present Msanii, a novel diffusion-based model for synthesizing long-context, high-fidelity music efficiently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/msanii-high-fidelity-music-synthesis-on-a</guid>
    </item>
    <item>
      <title>VToonify: Controllable High-Resolution Portrait Video Style Transfer</title>
      <link>https://paperswithcode.com/paper/vtoonify-controllable-high-resolution</link>
      <description><![CDATA[Although a series of successful portrait image toonification models built upon the powerful StyleGAN have been proposed, these image-oriented methods have obvious limitations when applied to videos, such as the fixed frame size, the requirement of face alignment, missing non-facial details and temporal inconsistency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vtoonify-controllable-high-resolution</guid>
    </item>
    <item>
      <title>GLIGEN: Open-Set Grounded Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/gligen-open-set-grounded-text-to-image</link>
      <description><![CDATA[Large-scale text-to-image diffusion models have made amazing advances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gligen-open-set-grounded-text-to-image</guid>
    </item>
    <item>
      <title>Utilizing supervised models to infer consensus labels and their quality from data with multiple annotators</title>
      <link>https://paperswithcode.com/paper/utilizing-supervised-models-to-infer</link>
      <description><![CDATA[Many algorithms also rely solely on annotator statistics, ignoring the features of the examples from which the annotations derive.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/utilizing-supervised-models-to-infer</guid>
    </item>
    <item>
      <title>mindcv</title>
      <link>https://github.com/mindlab-ai/mindcv</link>
      <description><![CDATA[A toolbox of vision models and algorithms based on MindSpore]]></description>
      <guid isPermaLink="true">https://github.com/mindlab-ai/mindcv</guid>
    </item>
    <item>
      <title>Ankh: Optimized Protein Language Model Unlocks General-Purpose Modelling</title>
      <link>https://paperswithcode.com/paper/ankh-optimized-protein-language-model-unlocks</link>
      <description><![CDATA[As opposed to scaling-up protein language models (PLMs), we seek improving performance via protein-specific optimization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ankh-optimized-protein-language-model-unlocks</guid>
    </item>
    <item>
      <title>Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling</title>
      <link>https://paperswithcode.com/paper/designing-bert-for-convolutional-networks</link>
      <description><![CDATA[This is the first use of sparse convolution for 2D masked modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/designing-bert-for-convolutional-networks</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis</title>
      <link>https://paperswithcode.com/paper/beat-a-large-scale-semantic-and-emotional</link>
      <description><![CDATA[Achieving realistic, vivid, and human-like synthesized conversational gestures conditioned on multi-modal data is still an unsolved problem due to the lack of available datasets, models and standard evaluation metrics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beat-a-large-scale-semantic-and-emotional</guid>
    </item>
    <item>
      <title>EDICT: Exact Diffusion Inversion via Coupled Transformations</title>
      <link>https://paperswithcode.com/paper/edict-exact-diffusion-inversion-via-coupled</link>
      <description><![CDATA[EDICT enables mathematically exact inversion of real and model-generated images by maintaining two coupled noise vectors which are used to invert each other in an alternating fashion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edict-exact-diffusion-inversion-via-coupled</guid>
    </item>
    <item>
      <title>Observation-Centric SORT: Rethinking SORT for Robust Multi-Object Tracking</title>
      <link>https://paperswithcode.com/paper/observation-centric-sort-rethinking-sort-for</link>
      <description><![CDATA[Multi-Object Tracking (MOT) has rapidly progressed with the development of object detection and re-identification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/observation-centric-sort-rethinking-sort-for</guid>
    </item>
    <item>
      <title>YOLOv4: Optimal Speed and Accuracy of Object Detection</title>
      <link>https://paperswithcode.com/paper/yolov4-optimal-speed-and-accuracy-of-object</link>
      <description><![CDATA[There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolov4-optimal-speed-and-accuracy-of-object</guid>
    </item>
    <item>
      <title>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</title>
      <link>https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</link>
      <description><![CDATA[Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</guid>
    </item>
    <item>
      <title>RTMDet: An Empirical Study of Designing Real-Time Object Detectors</title>
      <link>https://paperswithcode.com/paper/rtmdet-an-empirical-study-of-designing-real</link>
      <description><![CDATA[In this paper, we aim to design an efficient real-time object detector that exceeds the YOLO series and is easily extensible for many object recognition tasks such as instance segmentation and rotated object detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rtmdet-an-empirical-study-of-designing-real</guid>
    </item>
    <item>
      <title>Multimodal Deep Learning</title>
      <link>https://paperswithcode.com/paper/multimodal-deep-learning</link>
      <description><![CDATA[This book is the result of a seminar in which we reviewed multimodal approaches and attempted to create a solid overview of the field, starting with the current state-of-the-art approaches in the two subfields of Deep Learning individually.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-deep-learning</guid>
    </item>
    <item>
      <title>Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations</title>
      <link>https://paperswithcode.com/paper/triton-an-intermediate-language-and-compiler</link>
      <description><![CDATA[The validation and deployment of novel research ideas in the field of Deep Learning is often limited by the availability of efficient compute kernels for certain basic primitives.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triton-an-intermediate-language-and-compiler</guid>
    </item>
    <item>
      <title>Tracr: Compiled Transformers as a Laboratory for Interpretability</title>
      <link>https://paperswithcode.com/paper/tracr-compiled-transformers-as-a-laboratory</link>
      <description><![CDATA[Interpretability research aims to build tools for understanding machine learning (ML) models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tracr-compiled-transformers-as-a-laboratory</guid>
    </item>
    <item>
      <title>$\texttt{tasksource}$: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation</title>
      <link>https://paperswithcode.com/paper/texttt-tasksource-structured-dataset</link>
      <description><![CDATA[We release a dataset annotation framework and dataset annotations for more than 400 English tasks (https://github. com/sileod/tasksource).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/texttt-tasksource-structured-dataset</guid>
    </item>
  </channel>
</rss>
