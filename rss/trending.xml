<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 10 Oct 2022 09:23:49 +0000</lastBuildDate>
    <item>
      <title>Ask Me Anything: A simple strategy for prompting language models</title>
      <link>https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for</link>
      <description><![CDATA[Prompting is a brittle process wherein small modifications to the prompt can cause large variations in the model predictions, and therefore significant effort is dedicated towards designing a painstakingly "perfect prompt" for a task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for</guid>
    </item>
    <item>
      <title>Content-Based Search for Deep Generative Models</title>
      <link>https://paperswithcode.com/paper/content-based-search-for-deep-generative</link>
      <description><![CDATA[The growing proliferation of pretrained generative models has made it infeasible for a user to be fully cognizant of every model in existence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/content-based-search-for-deep-generative</guid>
    </item>
    <item>
      <title>VToonify: Controllable High-Resolution Portrait Video Style Transfer</title>
      <link>https://paperswithcode.com/paper/vtoonify-controllable-high-resolution</link>
      <description><![CDATA[Although a series of successful portrait image toonification models built upon the powerful StyleGAN have been proposed, these image-oriented methods have obvious limitations when applied to videos, such as the fixed frame size, the requirement of face alignment, missing non-facial details and temporal inconsistency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vtoonify-controllable-high-resolution</guid>
    </item>
    <item>
      <title>DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking</title>
      <link>https://paperswithcode.com/paper/diffdock-diffusion-steps-twists-and-turns-for</link>
      <description><![CDATA[Predicting the binding structure of a small molecule ligand to a protein -- a task known as molecular docking -- is critical to drug design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffdock-diffusion-steps-twists-and-turns-for</guid>
    </item>
    <item>
      <title>Human Motion Diffusion Model</title>
      <link>https://paperswithcode.com/paper/human-motion-diffusion-model</link>
      <description><![CDATA[In this paper, we introduce Motion Diffusion Model (MDM), a carefully adapted classifier-free diffusion-based generative model for the human motion domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/human-motion-diffusion-model</guid>
    </item>
    <item>
      <title>Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization</title>
      <link>https://paperswithcode.com/paper/is-reinforcement-learning-not-for-natural</link>
      <description><![CDATA[To help answer this, we first introduce an open-source modular library, RL4LMs (Reinforcement Learning for Language Models), for optimizing language generators with RL.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/is-reinforcement-learning-not-for-natural</guid>
    </item>
    <item>
      <title>An Efficient Person Clustering Algorithm for Open Checkout-free Groceries</title>
      <link>https://paperswithcode.com/paper/an-efficient-person-clustering-algorithm-for</link>
      <description><![CDATA[Then, to ensure that the method adapts to the dynamic and unseen person flow, we propose Graph Convolutional Network (GCN) with a simple Nearest Neighbor (NN) strategy to accurately cluster the instances of CSG.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-efficient-person-clustering-algorithm-for</guid>
    </item>
    <item>
      <title>Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network for Surgical Tools Segmentation</title>
      <link>https://paperswithcode.com/paper/min-max-similarity-a-contrastive-learning</link>
      <description><![CDATA[To address this issue, we proposed a semi-supervised segmentation network based on contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/min-max-similarity-a-contrastive-learning</guid>
    </item>
    <item>
      <title>VICRegL: Self-Supervised Learning of Local Visual Features</title>
      <link>https://paperswithcode.com/paper/vicregl-self-supervised-learning-of-local</link>
      <description><![CDATA[Most recent self-supervised methods for learning image representations focus on either producing a global feature with invariance properties, or producing a set of local features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vicregl-self-supervised-learning-of-local</guid>
    </item>
    <item>
      <title>clip2latent: Text driven sampling of a pre-trained StyleGAN using denoising diffusion and CLIP</title>
      <link>https://paperswithcode.com/paper/clip2latent-text-driven-sampling-of-a-pre</link>
      <description><![CDATA[We introduce a new method to efficiently create text-to-image models from a pre-trained CLIP and StyleGAN.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clip2latent-text-driven-sampling-of-a-pre</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and Denoising</title>
      <link>https://paperswithcode.com/paper/shape-light-material-decomposition-from</link>
      <description><![CDATA[Unfortunately, Monte Carlo integration provides estimates with significant noise, even at large sample counts, which makes gradient-based inverse rendering very challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shape-light-material-decomposition-from</guid>
    </item>
    <item>
      <title>Deep Neural Networks to Detect Weeds from Crops in Agricultural Environments in Real-Time: A Review</title>
      <link>https://paperswithcode.com/paper/deep-neural-networks-to-detect-weeds-from</link>
      <description><![CDATA[Machine vision has wide applications in agriculture, including the detection of weeds and pests in crops.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-neural-networks-to-detect-weeds-from</guid>
    </item>
    <item>
      <title>TEACH: Temporal Action Composition for 3D Humans</title>
      <link>https://paperswithcode.com/paper/teach-temporal-action-composition-for-3d</link>
      <description><![CDATA[In particular, our goal is to enable the synthesis of a series of actions, which we refer to as temporal action composition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teach-temporal-action-composition-for-3d</guid>
    </item>
    <item>
      <title>Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/time-will-tell-new-outlooks-and-a-baseline</link>
      <description><![CDATA[While recent camera-only 3D detection methods leverage multiple timesteps, the limited history they use significantly hampers the extent to which temporal fusion can improve object perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/time-will-tell-new-outlooks-and-a-baseline</guid>
    </item>
    <item>
      <title>Capturing and Animation of Body and Clothing from Monocular Video</title>
      <link>https://paperswithcode.com/paper/capturing-and-animation-of-body-and-clothing</link>
      <description><![CDATA[Building on this insight, we propose SCARF (Segmented Clothed Avatar Radiance Field), a hybrid model combining a mesh-based body with a neural radiance field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/capturing-and-animation-of-body-and-clothing</guid>
    </item>
    <item>
      <title>Protein structure generation via folding diffusion</title>
      <link>https://paperswithcode.com/paper/protein-structure-generation-via-folding</link>
      <description><![CDATA[The ability to computationally generate novel yet physically foldable protein structures could lead to new biological discoveries and new treatments targeting yet incurable diseases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/protein-structure-generation-via-folding</guid>
    </item>
    <item>
      <title>High-Resolution Image Synthesis with Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</link>
      <description><![CDATA[By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</guid>
    </item>
    <item>
      <title>VIMA: General Robot Manipulation with Multimodal Prompts</title>
      <link>https://paperswithcode.com/paper/vima-general-robot-manipulation-with</link>
      <description><![CDATA[This work shows that we can express a wide spectrum of robot manipulation tasks with multimodal prompts, interleaving textual and visual tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vima-general-robot-manipulation-with</guid>
    </item>
    <item>
      <title>GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images</title>
      <link>https://paperswithcode.com/paper/get3d-a-generative-model-of-high-quality-3d</link>
      <description><![CDATA[As several industries are moving towards modeling massive 3D virtual worlds, the need for content creation tools that can scale in terms of the quantity, quality, and diversity of 3D content is becoming evident.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/get3d-a-generative-model-of-high-quality-3d</guid>
    </item>
  </channel>
</rss>
