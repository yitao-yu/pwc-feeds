<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 27 May 2025 21:10:23 +0000</lastBuildDate>
    <item>
      <title>Emerging Properties in Unified Multimodal Pretraining</title>
      <link>https://paperswithcode.com/paper/emerging-properties-in-unified-multimodal</link>
      <description><![CDATA[Unifying multimodal understanding and generation has shown impressive capabilities in cutting-edge proprietary systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emerging-properties-in-unified-multimodal</guid>
    </item>
    <item>
      <title>AlphaEvolve: A Learning Framework to Discover Novel Alphas in Quantitative Investment</title>
      <link>https://paperswithcode.com/paper/alphaevolve-a-learning-framework-to-discover</link>
      <description><![CDATA[In this paper, we introduce a new class of alphas to model scalar, vector, and matrix features which possess the strengths of these two existing classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alphaevolve-a-learning-framework-to-discover</guid>
    </item>
    <item>
      <title>Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting</title>
      <link>https://paperswithcode.com/paper/dolphin-document-image-parsing-via</link>
      <description><![CDATA[Document image parsing is challenging due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dolphin-document-image-parsing-via</guid>
    </item>
    <item>
      <title>MMaDA: Multimodal Large Diffusion Language Models</title>
      <link>https://paperswithcode.com/paper/mmada-multimodal-large-diffusion-language</link>
      <description><![CDATA[We introduce MMaDA, a novel class of multimodal diffusion foundation models designed to achieve superior performance across diverse domains such as textual reasoning, multimodal understanding, and text-to-image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmada-multimodal-large-diffusion-language</guid>
    </item>
    <item>
      <title>qlib</title>
      <link>https://github.com/microsoft/qlib</link>
      <description><![CDATA[Qlib is an AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions.]]></description>
      <guid isPermaLink="true">https://github.com/microsoft/qlib</guid>
    </item>
    <item>
      <title>Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers</title>
      <link>https://paperswithcode.com/paper/uncertainty-quantification-for-language</link>
      <description><![CDATA[This approach enables practitioners to optimize the ensemble for a specific use case for improved performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uncertainty-quantification-for-language</guid>
    </item>
    <item>
      <title>Aligning Anime Video Generation with Human Feedback</title>
      <link>https://paperswithcode.com/paper/aligning-anime-video-generation-with-human</link>
      <description><![CDATA[Existing reward models, designed primarily for real-world videos, fail to capture the unique appearance and consistency requirements of anime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-anime-video-generation-with-human</guid>
    </item>
    <item>
      <title>This Time is Different: An Observability Perspective on Time Series Foundation Models</title>
      <link>https://paperswithcode.com/paper/this-time-is-different-an-observability</link>
      <description><![CDATA[We introduce Toto, a time series forecasting foundation model with 151 million parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/this-time-is-different-an-observability</guid>
    </item>
    <item>
      <title>Reservoir-enhanced Segment Anything Model for Subsurface Diagnosis</title>
      <link>https://paperswithcode.com/paper/reservoir-enhanced-segment-anything-model-for</link>
      <description><![CDATA[Urban roads and infrastructure, vital to city operations, face growing threats from subsurface anomalies like cracks and cavities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reservoir-enhanced-segment-anything-model-for</guid>
    </item>
    <item>
      <title>Task Attribute Distance for Few-Shot Learning: Theoretical Analysis and Applications</title>
      <link>https://paperswithcode.com/paper/task-attribute-distance-for-few-shot-learning</link>
      <description><![CDATA[In this paper, we try to understand FSL by delving into two key questions: (1) How to quantify the relationship between \emph{training} and \emph{novel} tasks?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/task-attribute-distance-for-few-shot-learning</guid>
    </item>
    <item>
      <title>Dynamic Early Exit in Reasoning Models</title>
      <link>https://paperswithcode.com/paper/dynamic-early-exit-in-reasoning-models</link>
      <description><![CDATA[Recent advances in large reasoning language models (LRLMs) rely on test-time scaling, which extends long chain-of-thought (CoT) generation to solve complex tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamic-early-exit-in-reasoning-models</guid>
    </item>
    <item>
      <title>Panda: A pretrained forecast model for universal representation of chaotic dynamics</title>
      <link>https://paperswithcode.com/paper/panda-a-pretrained-forecast-model-for</link>
      <description><![CDATA[We demonstrate a neural scaling law for differential equations, underscoring the potential of pretrained models for probing abstract mathematical domains like nonlinear dynamics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/panda-a-pretrained-forecast-model-for</guid>
    </item>
    <item>
      <title>R&amp;D-Agent: Automating Data-Driven AI Solution Building Through LLM-Powered Automated Research, Development, and Evolution</title>
      <link>https://paperswithcode.com/paper/r-d-agent-automating-data-driven-ai-solution</link>
      <description><![CDATA[Recent advances in AI and ML have transformed data science, yet increasing complexity and expertise requirements continue to hinder progress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r-d-agent-automating-data-driven-ai-solution</guid>
    </item>
    <item>
      <title>Harnessing the Universal Geometry of Embeddings</title>
      <link>https://paperswithcode.com/paper/harnessing-the-universal-geometry-of</link>
      <description><![CDATA[We introduce the first method for translating text embeddings from one vector space to another without any paired data, encoders, or predefined sets of matches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/harnessing-the-universal-geometry-of</guid>
    </item>
    <item>
      <title>Take the aTrain. Introducing an Interface for the Accessible Transcription of Interviews</title>
      <link>https://paperswithcode.com/paper/take-the-atrain-introducing-an-interface-for</link>
      <description><![CDATA[If an entry-level graphics card is available, the transcription speed increases to 20% of the audio duration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/take-the-atrain-introducing-an-interface-for</guid>
    </item>
    <item>
      <title>Visual Agentic Reinforcement Fine-Tuning</title>
      <link>https://paperswithcode.com/paper/visual-agentic-reinforcement-fine-tuning</link>
      <description><![CDATA[A key trend in Large Reasoning Models (e. g., OpenAI's o3) is the native agentic ability to use external tools such as web browsers for searching and writing/executing code for image manipulation to think with images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-agentic-reinforcement-fine-tuning</guid>
    </item>
    <item>
      <title>Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space</title>
      <link>https://paperswithcode.com/paper/soft-thinking-unlocking-the-reasoning</link>
      <description><![CDATA[In this work, we introduce Soft Thinking, a training-free method that emulates human-like "soft" reasoning by generating soft, abstract concept tokens in a continuous concept space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/soft-thinking-unlocking-the-reasoning</guid>
    </item>
    <item>
      <title>BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset</title>
      <link>https://paperswithcode.com/paper/blip3-o-a-family-of-fully-open-unified</link>
      <description><![CDATA[Building on our innovative model design, training recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art unified multimodal models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blip3-o-a-family-of-fully-open-unified</guid>
    </item>
    <item>
      <title>SOAP: Style-Omniscient Animatable Portraits</title>
      <link>https://paperswithcode.com/paper/soap-style-omniscient-animatable-portraits</link>
      <description><![CDATA[Creating animatable 3D avatars from a single image remains challenging due to style limitations (realistic, cartoon, anime) and difficulties in handling accessories or hairstyles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/soap-style-omniscient-animatable-portraits</guid>
    </item>
    <item>
      <title>Exploring the Performance Improvement of Tensor Processing Engines through Transformation in the Bit-weight Dimension of MACs</title>
      <link>https://paperswithcode.com/paper/exploring-the-performance-improvement-of</link>
      <description><![CDATA[Based on this notation and its transformations, we propose four optimization techniques that improve timing, area, and power consumption.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-performance-improvement-of</guid>
    </item>
  </channel>
</rss>
