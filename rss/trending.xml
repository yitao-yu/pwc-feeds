<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 22 Sep 2023 09:11:51 +0000</lastBuildDate>
    <item>
      <title>Agents: An Open-source Framework for Autonomous Language Agents</title>
      <link>https://paperswithcode.com/paper/agents-an-open-source-framework-for</link>
      <description><![CDATA[Recent advances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can automatically solve various tasks and interact with environments, humans, and other agents using natural language interfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agents-an-open-source-framework-for</guid>
    </item>
    <item>
      <title>The Rise and Potential of Large Language Model Based Agents: A Survey</title>
      <link>https://paperswithcode.com/paper/the-rise-and-potential-of-large-language</link>
      <description><![CDATA[Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-rise-and-potential-of-large-language</guid>
    </item>
    <item>
      <title>NExT-GPT: Any-to-Any Multimodal LLM</title>
      <link>https://paperswithcode.com/paper/next-gpt-any-to-any-multimodal-llm</link>
      <description><![CDATA[While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/next-gpt-any-to-any-multimodal-llm</guid>
    </item>
    <item>
      <title>ProPainter: Improving Propagation and Transformer for Video Inpainting</title>
      <link>https://paperswithcode.com/paper/propainter-improving-propagation-and</link>
      <description><![CDATA[We also propose a mask-guided sparse video Transformer, which achieves high efficiency by discarding unnecessary and redundant tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/propainter-improving-propagation-and</guid>
    </item>
    <item>
      <title>OverFlow: Putting flows on top of neural transducers for better TTS</title>
      <link>https://paperswithcode.com/paper/overflow-putting-flows-on-top-of-neural</link>
      <description><![CDATA[Neural HMMs are a type of neural transducer recently proposed for sequence-to-sequence modelling in text-to-speech.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/overflow-putting-flows-on-top-of-neural</guid>
    </item>
    <item>
      <title>AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents</title>
      <link>https://paperswithcode.com/paper/agentverse-facilitating-multi-agent</link>
      <description><![CDATA[Autonomous agents empowered by Large Language Models (LLMs) have undergone significant improvements, enabling them to generalize across a broad spectrum of tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentverse-facilitating-multi-agent</guid>
    </item>
    <item>
      <title>Communicative Agents for Software Development</title>
      <link>https://paperswithcode.com/paper/communicative-agents-for-software-development</link>
      <description><![CDATA[At the core of this paradigm lies ChatDev, a virtual chat-powered software development company that mirrors the established waterfall model, meticulously dividing the development process into four distinct chronological stages: designing, coding, testing, and documenting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/communicative-agents-for-software-development</guid>
    </item>
    <item>
      <title>Baichuan 2: Open Large-scale Language Models</title>
      <link>https://paperswithcode.com/paper/baichuan-2-open-large-scale-language-models</link>
      <description><![CDATA[Large language models (LLMs) have demonstrated remarkable performance on a variety of natural language tasks based on just a few examples of natural language instructions, reducing the need for extensive feature engineering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/baichuan-2-open-large-scale-language-models</guid>
    </item>
    <item>
      <title>Nougat: Neural Optical Understanding for Academic Documents</title>
      <link>https://paperswithcode.com/paper/nougat-neural-optical-understanding-for</link>
      <description><![CDATA[Scientific knowledge is predominantly stored in books and scientific journals, often in the form of PDFs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nougat-neural-optical-understanding-for</guid>
    </item>
    <item>
      <title>GPTFUZZER : Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts</title>
      <link>https://paperswithcode.com/paper/gptfuzzer-red-teaming-large-language-models</link>
      <description><![CDATA[Notably, even starting with suboptimal seed templates, \fuzzer maintains over 90\% attack success rate against ChatGPT and Llama-2 models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gptfuzzer-red-teaming-large-language-models</guid>
    </item>
    <item>
      <title>InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/instaflow-one-step-is-enough-for-high-quality</link>
      <description><![CDATA[Leveraging our new pipeline, we create, to the best of our knowledge, the first one-step diffusion-based text-to-image generator with SD-level image quality, achieving an FID (Frechet Inception Distance) of $23. 3$ on MS COCO 2017-5k, surpassing the previous state-of-the-art technique, progressive distillation, by a significant margin ($37. 2$ $\rightarrow$ $23. 3$ in FID).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instaflow-one-step-is-enough-for-high-quality</guid>
    </item>
    <item>
      <title>OpenBA: An Open-sourced 15B Bilingual Asymmetric seq2seq Model Pre-trained from Scratch</title>
      <link>https://paperswithcode.com/paper/openba-an-open-sourced-15b-bilingual</link>
      <description><![CDATA[This report provides the main details to pre-train an analogous model, including pre-training data processing, Bilingual Flan data collection, the empirical observations that inspire our model architecture design, training objectives of different stages, and other enhancement techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openba-an-open-sourced-15b-bilingual</guid>
    </item>
    <item>
      <title>3D Gaussian Splatting for Real-Time Radiance Field Rendering</title>
      <link>https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</link>
      <description><![CDATA[Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</guid>
    </item>
    <item>
      <title>Kani: A Lightweight and Highly Hackable Framework for Building Language Model Applications</title>
      <link>https://paperswithcode.com/paper/kani-a-lightweight-and-highly-hackable</link>
      <description><![CDATA[Language model applications are becoming increasingly popular and complex, often including features like tool usage and retrieval augmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kani-a-lightweight-and-highly-hackable</guid>
    </item>
    <item>
      <title>DreamLLM: Synergistic Multimodal Comprehension and Creation</title>
      <link>https://paperswithcode.com/paper/dreamllm-synergistic-multimodal-comprehension</link>
      <description><![CDATA[This paper presents DreamLLM, a learning framework that first achieves versatile Multimodal Large Language Models (MLLMs) empowered with frequently overlooked synergy between multimodal comprehension and creation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamllm-synergistic-multimodal-comprehension</guid>
    </item>
    <item>
      <title>LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models</title>
      <link>https://paperswithcode.com/paper/layoutnuwa-revealing-the-hidden-layout</link>
      <description><![CDATA[Graphic layout generation, a growing research field, plays a significant role in user engagement and information perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/layoutnuwa-revealing-the-hidden-layout</guid>
    </item>
    <item>
      <title>GPT Can Solve Mathematical Problems Without a Calculator</title>
      <link>https://paperswithcode.com/paper/gpt-can-solve-mathematical-problems-without-a</link>
      <description><![CDATA[Previous studies have typically assumed that large language models are unable to accurately perform arithmetic operations, particularly multiplication of >8 digits, and operations involving decimals and fractions, without the use of calculator tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-can-solve-mathematical-problems-without-a</guid>
    </item>
    <item>
      <title>MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning</title>
      <link>https://paperswithcode.com/paper/mmicl-empowering-vision-language-model-with</link>
      <description><![CDATA[Specifically, the current VLMs primarily emphasize utilizing multi-modal data with a single image some, rather than multi-modal prompts with interleaved multiple images and text.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mmicl-empowering-vision-language-model-with</guid>
    </item>
    <item>
      <title>EfficientViT: Lightweight Multi-Scale Attention for On-Device Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/efficientvit-enhanced-linear-attention-for</link>
      <description><![CDATA[Unlike prior semantic segmentation models that rely on heavy self-attention, hardware-inefficient large-kernel convolution, or complicated topology structure to obtain good performances, our lightweight multi-scale attention achieves a global receptive field and multi-scale learning (two critical features for semantic segmentation models) with only lightweight and hardware-efficient operations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficientvit-enhanced-linear-attention-for</guid>
    </item>
    <item>
      <title>Petals: Collaborative Inference and Fine-tuning of Large Models</title>
      <link>https://paperswithcode.com/paper/petals-collaborative-inference-and-fine</link>
      <description><![CDATA[However, these techniques have innate limitations: offloading is too slow for interactive inference, while APIs are not flexible enough for research that requires access to weights, attention or logits.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/petals-collaborative-inference-and-fine</guid>
    </item>
  </channel>
</rss>
