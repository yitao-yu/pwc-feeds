<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 31 Mar 2024 21:06:12 +0000</lastBuildDate>
    <item>
      <title>AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation</title>
      <link>https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</link>
      <description><![CDATA[In this study, we propose AniPortrait, a novel framework for generating high-quality animation driven by audio and a reference portrait image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</guid>
    </item>
    <item>
      <title>VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild</title>
      <link>https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</link>
      <description><![CDATA[We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</guid>
    </item>
    <item>
      <title>Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models</title>
      <link>https://paperswithcode.com/paper/mini-gemini-mining-the-potential-of-multi</link>
      <description><![CDATA[We try to narrow the gap by mining the potential of VLMs for better performance and any-to-any workflow from three aspects, i. e., high-resolution visual tokens, high-quality data, and VLM-guided generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mini-gemini-mining-the-potential-of-multi</guid>
    </item>
    <item>
      <title>AIOS: LLM Agent Operating System</title>
      <link>https://paperswithcode.com/paper/llm-agent-operating-system</link>
      <description><![CDATA[Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS) as the brain of the OS, enabling an operating system "with soul" -- an important step towards AGI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-agent-operating-system</guid>
    </item>
    <item>
      <title>Long-form factuality in large language models</title>
      <link>https://paperswithcode.com/paper/long-form-factuality-in-large-language-models</link>
      <description><![CDATA[Empirically, we demonstrate that LLM agents can achieve superhuman rating performance - on a set of ~16k individual facts, SAFE agrees with crowdsourced human annotators 72% of the time, and on a random subset of 100 disagreement cases, SAFE wins 76% of the time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/long-form-factuality-in-large-language-models</guid>
    </item>
    <item>
      <title>T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy</title>
      <link>https://paperswithcode.com/paper/t-rex2-towards-generic-object-detection-via</link>
      <description><![CDATA[Recognizing the complementary strengths and weaknesses of both text and visual prompts, we introduce T-Rex2 that synergizes both prompts within a single model through contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t-rex2-towards-generic-object-detection-via</guid>
    </item>
    <item>
      <title>StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text</title>
      <link>https://paperswithcode.com/paper/streamingt2v-consistent-dynamic-and</link>
      <description><![CDATA[To overcome these limitations, we introduce StreamingT2V, an autoregressive approach for long video generation of 80, 240, 600, 1200 or more frames with smooth transitions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streamingt2v-consistent-dynamic-and</guid>
    </item>
    <item>
      <title>UniDepth: Universal Monocular Metric Depth Estimation</title>
      <link>https://paperswithcode.com/paper/unidepth-universal-monocular-metric-depth</link>
      <description><![CDATA[However, the remarkable accuracy of recent MMDE methods is confined to their training domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unidepth-universal-monocular-metric-depth</guid>
    </item>
    <item>
      <title>SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions</title>
      <link>https://paperswithcode.com/paper/sdxs-real-time-one-step-latent-diffusion</link>
      <description><![CDATA[Recent advancements in diffusion models have positioned them at the forefront of image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdxs-real-time-one-step-latent-diffusion</guid>
    </item>
    <item>
      <title>BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion</title>
      <link>https://paperswithcode.com/paper/brushnet-a-plug-and-play-image-inpainting</link>
      <description><![CDATA[Image inpainting, the process of restoring corrupted images, has seen significant advancements with the advent of diffusion models (DMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/brushnet-a-plug-and-play-image-inpainting</guid>
    </item>
    <item>
      <title>General Object Foundation Model for Images and Videos at Scale</title>
      <link>https://paperswithcode.com/paper/general-object-foundation-model-for-images</link>
      <description><![CDATA[We present GLEE in this work, an object-level foundation model for locating and identifying objects in images and videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/general-object-foundation-model-for-images</guid>
    </item>
    <item>
      <title>Mora: Enabling Generalist Video Generation via A Multi-Agent Framework</title>
      <link>https://paperswithcode.com/paper/mora-enabling-generalist-video-generation-via</link>
      <description><![CDATA[Sora is the first large-scale generalist video generation model that garnered significant attention across society.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mora-enabling-generalist-video-generation-via</guid>
    </item>
    <item>
      <title>Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework</title>
      <link>https://paperswithcode.com/paper/make-your-anchor-a-diffusion-based-2d-avatar</link>
      <description><![CDATA[We adopt a two-stage training strategy for the diffusion model, effectively binding movements with specific appearances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/make-your-anchor-a-diffusion-based-2d-avatar</guid>
    </item>
    <item>
      <title>Long-CLIP: Unlocking the Long-Text Capability of CLIP</title>
      <link>https://paperswithcode.com/paper/long-clip-unlocking-the-long-text-capability</link>
      <description><![CDATA[Contrastive Language-Image Pre-training (CLIP) has been the cornerstone for zero-shot classification, text-image retrieval, and text-image generation by aligning image and text modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/long-clip-unlocking-the-long-text-capability</guid>
    </item>
    <item>
      <title>RSMamba: Remote Sensing Image Classification with State Space Model</title>
      <link>https://paperswithcode.com/paper/rsmamba-remote-sensing-image-classification</link>
      <description><![CDATA[Remote sensing image classification forms the foundation of various understanding tasks, serving a crucial function in remote sensing image interpretation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rsmamba-remote-sensing-image-classification</guid>
    </item>
    <item>
      <title>MegaBlocks: Efficient Sparse Training with Mixture-of-Experts</title>
      <link>https://paperswithcode.com/paper/megablocks-efficient-sparse-training-with</link>
      <description><![CDATA[We present MegaBlocks, a system for efficient Mixture-of-Experts (MoE) training on GPUs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/megablocks-efficient-sparse-training-with</guid>
    </item>
    <item>
      <title>LITA: Language Instructed Temporal-Localization Assistant</title>
      <link>https://paperswithcode.com/paper/lita-language-instructed-temporal</link>
      <description><![CDATA[In addition to leveraging existing video datasets with timestamps, we propose a new task, Reasoning Temporal Localization (RTL), along with the dataset, ActivityNet-RTL, for learning and evaluating this task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lita-language-instructed-temporal</guid>
    </item>
    <item>
      <title>One-Step Image Translation with Text-to-Image Models</title>
      <link>https://paperswithcode.com/paper/one-step-image-translation-with-text-to-image</link>
      <description><![CDATA[In this work, we address two limitations of existing conditional diffusion models: their slow inference speed due to the iterative denoising process and their reliance on paired data for model fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-step-image-translation-with-text-to-image</guid>
    </item>
    <item>
      <title>GauStudio: A Modular Framework for 3D Gaussian Splatting and Beyond</title>
      <link>https://paperswithcode.com/paper/gaustudio-a-modular-framework-for-3d-gaussian</link>
      <description><![CDATA[We present GauStudio, a novel modular framework for modeling 3D Gaussian Splatting (3DGS) to provide standardized, plug-and-play components for users to easily customize and implement a 3DGS pipeline.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaustudio-a-modular-framework-for-3d-gaussian</guid>
    </item>
    <item>
      <title>OpenVoice: Versatile Instant Voice Cloning</title>
      <link>https://paperswithcode.com/paper/openvoice-versatile-instant-voice-cloning</link>
      <description><![CDATA[The voice styles are not directly copied from and constrained by the style of the reference speaker.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openvoice-versatile-instant-voice-cloning</guid>
    </item>
  </channel>
</rss>
