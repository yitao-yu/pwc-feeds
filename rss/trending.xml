<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 16 Aug 2023 09:11:19 +0000</lastBuildDate>
    <item>
      <title>Neuralangelo: High-Fidelity Neural Surface Reconstruction</title>
      <link>https://paperswithcode.com/paper/neuralangelo-high-fidelity-neural-surface-1</link>
      <description><![CDATA[Neural surface reconstruction has been shown to be powerful for recovering dense 3D surfaces via image-based neural rendering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neuralangelo-high-fidelity-neural-surface-1</guid>
    </item>
    <item>
      <title>Efficient Guided Generation for Large Language Models</title>
      <link>https://paperswithcode.com/paper/efficient-guided-generation-for-llms</link>
      <description><![CDATA[In this article we show how the problem of neural text generation can be constructively reformulated in terms of transitions between the states of a finite-state machine.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-guided-generation-for-llms</guid>
    </item>
    <item>
      <title>Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction</title>
      <link>https://paperswithcode.com/paper/trafilatura-a-web-scraping-library-and</link>
      <description><![CDATA[The tool performs significantly better than other open-source solutions in this evaluation and in external benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trafilatura-a-web-scraping-library-and</guid>
    </item>
    <item>
      <title>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</title>
      <link>https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</link>
      <description><![CDATA[Recently, remarkable progress has been made in automated task-solving through the use of multi-agent driven by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</guid>
    </item>
    <item>
      <title>DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models</title>
      <link>https://paperswithcode.com/paper/datasetdm-synthesizing-data-with-perception</link>
      <description><![CDATA[To showcase the power of the proposed approach, we generate datasets with rich dense pixel-wise labels for a wide range of downstream tasks, including semantic segmentation, instance segmentation, and depth estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datasetdm-synthesizing-data-with-perception</guid>
    </item>
    <item>
      <title>OctoPack: Instruction Tuning Code Large Language Models</title>
      <link>https://paperswithcode.com/paper/octopack-instruction-tuning-code-large</link>
      <description><![CDATA[We benchmark CommitPack against other natural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B parameter StarCoder model, and achieve state-of-the-art performance among models not trained on OpenAI outputs, on the HumanEval Python benchmark (46. 2% pass@1).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/octopack-instruction-tuning-code-large</guid>
    </item>
    <item>
      <title>AgentBench: Evaluating LLMs as Agents</title>
      <link>https://paperswithcode.com/paper/agentbench-evaluating-llms-as-agents</link>
      <description><![CDATA[Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentbench-evaluating-llms-as-agents</guid>
    </item>
    <item>
      <title>ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</title>
      <link>https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</link>
      <description><![CDATA[We first present ToolBench, an instruction-tuning dataset for tool use, which is created automatically using ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</guid>
    </item>
    <item>
      <title>Color-NeuS: Reconstructing Neural Implicit Surfaces with Color</title>
      <link>https://paperswithcode.com/paper/color-neus-reconstructing-neural-implicit</link>
      <description><![CDATA[Mesh is extracted from the signed distance function (SDF) network for the surface, and color for each surface vertex is drawn from the global color network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/color-neus-reconstructing-neural-implicit</guid>
    </item>
    <item>
      <title>WizardCoder: Empowering Code Large Language Models with Evol-Instruct</title>
      <link>https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language</link>
      <description><![CDATA[Moreover, our model even outperforms the largest closed LLMs, Anthropic's Claude and Google's Bard, on HumanEval and HumanEval+.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language</guid>
    </item>
    <item>
      <title>LISA: Reasoning Segmentation via Large Language Model</title>
      <link>https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</link>
      <description><![CDATA[In this work, we propose a new segmentation task -- reasoning segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</guid>
    </item>
    <item>
      <title>Follow Anything: Open-set detection, tracking, and following in real-time</title>
      <link>https://paperswithcode.com/paper/follow-anything-open-set-detection-tracking</link>
      <description><![CDATA[We demonstrate FAn on a real-world robotic system (a micro aerial vehicle) and report its ability to seamlessly follow the objects of interest in a real-time control loop.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/follow-anything-open-set-detection-tracking</guid>
    </item>
    <item>
      <title>Separate Anything You Describe</title>
      <link>https://paperswithcode.com/paper/separate-anything-you-describe</link>
      <description><![CDATA[In this work, we introduce AudioSep, a foundation model for open-domain audio source separation with natural language queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/separate-anything-you-describe</guid>
    </item>
    <item>
      <title>3D Gaussian Splatting for Real-Time Radiance Field Rendering</title>
      <link>https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</link>
      <description><![CDATA[Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</guid>
    </item>
    <item>
      <title>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</title>
      <link>https://paperswithcode.com/paper/direct-preference-optimization-your-language</link>
      <description><![CDATA[However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct-preference-optimization-your-language</guid>
    </item>
    <item>
      <title>BundleSDF: Neural 6-DoF Tracking and 3D Reconstruction of Unknown Objects</title>
      <link>https://paperswithcode.com/paper/bundlesdf-neural-6-dof-tracking-and-3d</link>
      <description><![CDATA[We present a near real-time method for 6-DoF tracking of an unknown object from a monocular RGBD video sequence, while simultaneously performing neural 3D reconstruction of the object.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bundlesdf-neural-6-dof-tracking-and-3d</guid>
    </item>
    <item>
      <title>GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher</title>
      <link>https://paperswithcode.com/paper/gpt-4-is-too-smart-to-be-safe-stealthy-chat</link>
      <description><![CDATA[We propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages -- ciphers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-4-is-too-smart-to-be-safe-stealthy-chat</guid>
    </item>
    <item>
      <title>Empowering Vision-Language Models to Follow Interleaved Vision-Language Instructions</title>
      <link>https://paperswithcode.com/paper/empowering-vision-language-models-to-follow</link>
      <description><![CDATA[To address this issue, we propose a generic and lightweight controllable knowledge re-injection module, which utilizes the sophisticated reasoning ability of LLMs to control the VPG to conditionally extract instruction-specific visual information and re-inject it into the LLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/empowering-vision-language-models-to-follow</guid>
    </item>
    <item>
      <title>Revisiting the Minimalist Approach to Offline Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/revisiting-the-minimalist-approach-to-offline</link>
      <description><![CDATA[In this work, we aim to bridge this gap by conducting a retrospective analysis of recent works in offline RL and propose ReBRAC, a minimalistic algorithm that integrates such design elements built on top of the TD3+BC method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-the-minimalist-approach-to-offline</guid>
    </item>
    <item>
      <title>Shepherd: A Critic for Language Model Generation</title>
      <link>https://paperswithcode.com/paper/shepherd-a-critic-for-language-model</link>
      <description><![CDATA[As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shepherd-a-critic-for-language-model</guid>
    </item>
  </channel>
</rss>
