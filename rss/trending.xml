<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 02 Dec 2023 21:05:56 +0000</lastBuildDate>
    <item>
      <title>MEDITRON-70B: Scaling Medical Pretraining for Large Language Models</title>
      <link>https://paperswithcode.com/paper/meditron-70b-scaling-medical-pretraining-for</link>
      <description><![CDATA[Large language models (LLMs) can potentially democratize access to medical knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meditron-70b-scaling-medical-pretraining-for</guid>
    </item>
    <item>
      <title>YUAN 2.0: A Large Language Model with Localized Filtering-based Attention</title>
      <link>https://paperswithcode.com/paper/yuan-2-0-a-large-language-model-with</link>
      <description><![CDATA[In this work, the Localized Filtering-based Attention (LFA) is introduced to incorporate prior knowledge of local dependencies of natural language into Attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yuan-2-0-a-large-language-model-with</guid>
    </item>
    <item>
      <title>On Bringing Robots Home</title>
      <link>https://paperswithcode.com/paper/on-bringing-robots-home</link>
      <description><![CDATA[We use the Stick to collect 13 hours of data in 22 homes of New York City, and train Home Pretrained Representations (HPR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-bringing-robots-home</guid>
    </item>
    <item>
      <title>LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS</title>
      <link>https://paperswithcode.com/paper/lightgaussian-unbounded-3d-gaussian</link>
      <description><![CDATA[Recent advancements in real-time neural rendering using point-based techniques have paved the way for the widespread adoption of 3D representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightgaussian-unbounded-3d-gaussian</guid>
    </item>
    <item>
      <title>GS-IR: 3D Gaussian Splatting for Inverse Rendering</title>
      <link>https://paperswithcode.com/paper/gs-ir-3d-gaussian-splatting-for-inverse</link>
      <description><![CDATA[We propose GS-IR, a novel inverse rendering approach based on 3D Gaussian Splatting (GS) that leverages forward mapping volume rendering to achieve photorealistic novel view synthesis and relighting results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gs-ir-3d-gaussian-splatting-for-inverse</guid>
    </item>
    <item>
      <title>Improving Sample Quality of Diffusion Models Using Self-Attention Guidance</title>
      <link>https://paperswithcode.com/paper/improving-sample-quality-of-diffusion-model</link>
      <description><![CDATA[Denoising diffusion models (DDMs) have attracted attention for their exceptional generation quality and diversity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-sample-quality-of-diffusion-model</guid>
    </item>
    <item>
      <title>LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models</title>
      <link>https://paperswithcode.com/paper/llama-vid-an-image-is-worth-2-tokens-in-large</link>
      <description><![CDATA[Current VLMs, while proficient in tasks like image captioning and visual question answering, face computational burdens when processing long videos due to the excessive visual tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-vid-an-image-is-worth-2-tokens-in-large</guid>
    </item>
    <item>
      <title>OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/occworld-learning-a-3d-occupancy-world-model</link>
      <description><![CDATA[In this paper, we explore a new framework of learning a world model, OccWorld, in the 3D Occupancy space to simultaneously predict the movement of the ego car and the evolution of the surrounding scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/occworld-learning-a-3d-occupancy-world-model</guid>
    </item>
    <item>
      <title>Animatable Gaussians: Learning Pose-dependent Gaussian Maps for High-fidelity Human Avatar Modeling</title>
      <link>https://paperswithcode.com/paper/animatable-gaussians-learning-pose-dependent</link>
      <description><![CDATA[Overall, our method can create lifelike avatars with dynamic, realistic and generalized appearances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatable-gaussians-learning-pose-dependent</guid>
    </item>
    <item>
      <title>UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio, Video, Point Cloud, Time-Series and Image Recognition</title>
      <link>https://paperswithcode.com/paper/unireplknet-a-universal-perception-large</link>
      <description><![CDATA[1) We propose four architectural guidelines for designing large-kernel ConvNets, the core of which is to exploit the essential characteristics of large kernels that distinguish them from small kernels - they can see wide without going deep.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unireplknet-a-universal-perception-large</guid>
    </item>
    <item>
      <title>Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/driving-into-the-future-multiview-visual</link>
      <description><![CDATA[In autonomous driving, predicting future events in advance and evaluating the foreseeable risks empowers autonomous vehicles to better plan their actions, enhancing safety and efficiency on the road.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/driving-into-the-future-multiview-visual</guid>
    </item>
    <item>
      <title>Adversarial Diffusion Distillation</title>
      <link>https://paperswithcode.com/paper/adversarial-diffusion-distillation</link>
      <description><![CDATA[We introduce Adversarial Diffusion Distillation (ADD), a novel training approach that efficiently samples large-scale foundational image diffusion models in just 1-4 steps while maintaining high image quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adversarial-diffusion-distillation</guid>
    </item>
    <item>
      <title>Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch</title>
      <link>https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</link>
      <description><![CDATA[Based on this observation, we further sparsify delta parameters of multiple SFT homologous models with DARE and subsequently merge them into a single model by parameter averaging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</guid>
    </item>
    <item>
      <title>LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching</title>
      <link>https://paperswithcode.com/paper/luciddreamer-towards-high-fidelity-text-to-3d</link>
      <description><![CDATA[The recent advancements in text-to-3D generation mark a significant milestone in generative models, unlocking new possibilities for creating imaginative 3D assets across various real-world scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/luciddreamer-towards-high-fidelity-text-to-3d</guid>
    </item>
    <item>
      <title>Pair then Relation: Pair-Net for Panoptic Scene Graph Generation</title>
      <link>https://paperswithcode.com/paper/pair-then-relation-pair-net-for-panoptic</link>
      <description><![CDATA[Panoptic Scene Graph (PSG) is a challenging task in Scene Graph Generation (SGG) that aims to create a more comprehensive scene graph representation using panoptic segmentation instead of boxes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pair-then-relation-pair-net-for-panoptic</guid>
    </item>
    <item>
      <title>SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis</title>
      <link>https://paperswithcode.com/paper/synctalk-the-devil-is-in-the-synchronization</link>
      <description><![CDATA[A lifelike talking head requires synchronized coordination of subject identity, lip movements, facial expressions, and head poses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/synctalk-the-devil-is-in-the-synchronization</guid>
    </item>
    <item>
      <title>Sketch Video Synthesis</title>
      <link>https://paperswithcode.com/paper/sketch-video-synthesis</link>
      <description><![CDATA[Understanding semantic intricacies and high-level concepts is essential in image sketch generation, and this challenge becomes even more formidable when applied to the domain of videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sketch-video-synthesis</guid>
    </item>
    <item>
      <title>White-Box Transformers via Sparse Rate Reduction</title>
      <link>https://paperswithcode.com/paper/white-box-transformers-via-sparse-rate</link>
      <description><![CDATA[Particularly, we show that the standard transformer block can be derived from alternating optimization on complementary parts of this objective: the multi-head self-attention operator can be viewed as a gradient descent step to compress the token sets by minimizing their lossy coding rate, and the subsequent multi-layer perceptron can be viewed as attempting to sparsify the representation of the tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/white-box-transformers-via-sparse-rate</guid>
    </item>
    <item>
      <title>LoRA: Low-Rank Adaptation of Large Language Models</title>
      <link>https://paperswithcode.com/paper/lora-low-rank-adaptation-of-large-language</link>
      <description><![CDATA[We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lora-low-rank-adaptation-of-large-language</guid>
    </item>
    <item>
      <title>Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating Video-based Large Language Models</title>
      <link>https://paperswithcode.com/paper/video-bench-a-comprehensive-benchmark-and</link>
      <description><![CDATA[Video-based large language models (Video-LLMs) have been recently introduced, targeting both fundamental improvements in perception and comprehension, and a diverse range of user inquiries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/video-bench-a-comprehensive-benchmark-and</guid>
    </item>
  </channel>
</rss>
