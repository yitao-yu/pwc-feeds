<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 12 Oct 2024 09:16:00 +0000</lastBuildDate>
    <item>
      <title>Aria: An Open Multimodal Native Mixture-of-Experts Model</title>
      <link>https://paperswithcode.com/paper/aria-an-open-multimodal-native-mixture-of</link>
      <description><![CDATA[Information comes in diverse modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aria-an-open-multimodal-native-mixture-of</guid>
    </item>
    <item>
      <title>Depth Pro: Sharp Monocular Metric Depth in Less Than a Second</title>
      <link>https://paperswithcode.com/paper/depth-pro-sharp-monocular-metric-depth-in</link>
      <description><![CDATA[We present a foundation model for zero-shot metric monocular depth estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depth-pro-sharp-monocular-metric-depth-in</guid>
    </item>
    <item>
      <title>MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering</title>
      <link>https://paperswithcode.com/paper/mle-bench-evaluating-machine-learning-agents</link>
      <description><![CDATA[We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mle-bench-evaluating-machine-learning-agents</guid>
    </item>
    <item>
      <title>Posterior-Mean Rectified Flow: Towards Minimum MSE Photo-Realistic Image Restoration</title>
      <link>https://paperswithcode.com/paper/posterior-mean-rectified-flow-towards-minimum</link>
      <description><![CDATA[Photo-realistic image restoration algorithms are typically evaluated by distortion measures (e. g., PSNR, SSIM) and by perceptual quality measures (e. g., FID, NIQE), where the desire is to attain the lowest possible distortion without compromising on perceptual quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/posterior-mean-rectified-flow-towards-minimum</guid>
    </item>
    <item>
      <title>Deciphering Cross-Modal Alignment in Large Vision-Language Models with Modality Integration Rate</title>
      <link>https://paperswithcode.com/paper/deciphering-cross-modal-alignment-in-large</link>
      <description><![CDATA[We present the Modality Integration Rate (MIR), an effective, robust, and generalized metric to indicate the multi-modal pre-training quality of Large Vision Language Models (LVLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deciphering-cross-modal-alignment-in-large</guid>
    </item>
    <item>
      <title>LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs</title>
      <link>https://paperswithcode.com/paper/longwriter-unleashing-10000-word-generation</link>
      <description><![CDATA[By incorporating this dataset into model training, we successfully scale the output length of existing models to over 10, 000 words while maintaining output quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longwriter-unleashing-10000-word-generation</guid>
    </item>
    <item>
      <title>Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers</title>
      <link>https://paperswithcode.com/paper/scaling-proprioceptive-visual-learning-with</link>
      <description><![CDATA[Previous robot learning methods often collect data to train with one specific embodiment for one task, which is expensive and prone to overfitting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-proprioceptive-visual-learning-with</guid>
    </item>
    <item>
      <title>"Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models</title>
      <link>https://paperswithcode.com/paper/do-anything-now-characterizing-and-evaluating</link>
      <description><![CDATA[We hope that our study can facilitate the research community and LLM vendors in promoting safer and regulated LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-anything-now-characterizing-and-evaluating</guid>
    </item>
    <item>
      <title>LLaMA-Omni: Seamless Speech Interaction with Large Language Models</title>
      <link>https://paperswithcode.com/paper/llama-omni-seamless-speech-interaction-with</link>
      <description><![CDATA[We build our model based on the latest Llama-3. 1-8B-Instruct model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-omni-seamless-speech-interaction-with</guid>
    </item>
    <item>
      <title>VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/vptq-extreme-low-bit-vector-post-training</link>
      <description><![CDATA[Due to the redundancy in LLM weights, recent research has focused on pushing weight-only quantization to extremely low-bit (even down to 2 bits).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vptq-extreme-low-bit-vector-post-training</guid>
    </item>
    <item>
      <title>AgentKit: Structured LLM Reasoning with Dynamic Graphs</title>
      <link>https://paperswithcode.com/paper/agentkit-flow-engineering-with-graphs-not</link>
      <description><![CDATA[The chains of nodes can be designed to explicitly enforce a naturally structured "thought process".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentkit-flow-engineering-with-graphs-not</guid>
    </item>
    <item>
      <title>IterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/itercomp-iterative-composition-aware-feedback</link>
      <description><![CDATA[IterComp opens new research avenues in reward feedback learning for diffusion models and compositional generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/itercomp-iterative-composition-aware-feedback</guid>
    </item>
    <item>
      <title>A Multi-Level Superoptimizer for Tensor Programs</title>
      <link>https://paperswithcode.com/paper/a-multi-level-superoptimizer-for-tensor</link>
      <description><![CDATA[We introduce Mirage, the first multi-level superoptimizer for tensor programs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-multi-level-superoptimizer-for-tensor</guid>
    </item>
    <item>
      <title>LightRAG: Simple and Fast Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/lightrag-simple-and-fast-retrieval-augmented</link>
      <description><![CDATA[Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by integrating external knowledge sources, enabling more accurate and contextually relevant responses tailored to user needs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lightrag-simple-and-fast-retrieval-augmented</guid>
    </item>
    <item>
      <title>SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration</title>
      <link>https://paperswithcode.com/paper/sageattention-accurate-8-bit-attention-for</link>
      <description><![CDATA[Although quantization has proven to be an effective method for accelerating model inference, existing quantization methods primarily focus on optimizing the linear layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sageattention-accurate-8-bit-attention-for</guid>
    </item>
    <item>
      <title>Towards World Simulator: Crafting Physical Commonsense-Based Benchmark for Video Generation</title>
      <link>https://paperswithcode.com/paper/towards-world-simulator-crafting-physical</link>
      <description><![CDATA[Alongside PhyGenBench, we propose a novel evaluation framework called PhyGenEval.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-world-simulator-crafting-physical</guid>
    </item>
    <item>
      <title>Diffusion Models are Evolutionary Algorithms</title>
      <link>https://paperswithcode.com/paper/diffusion-models-are-evolutionary-algorithms</link>
      <description><![CDATA[In a convergence of machine learning and biology, we reveal that diffusion models are evolutionary algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-are-evolutionary-algorithms</guid>
    </item>
    <item>
      <title>Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale</title>
      <link>https://paperswithcode.com/paper/windows-agent-arena-evaluating-multi-modal-os</link>
      <description><![CDATA[To demonstrate Windows Agent Arena's capabilities, we also introduce a new multi-modal agent, Navi.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/windows-agent-arena-evaluating-multi-modal-os</guid>
    </item>
    <item>
      <title>Text2SQL is Not Enough: Unifying AI and Databases with TAG</title>
      <link>https://paperswithcode.com/paper/text2sql-is-not-enough-unifying-ai-and</link>
      <description><![CDATA[Such systems would allow users to leverage the powerful reasoning and knowledge capabilities of language models (LMs) alongside the scalable computational power of data management systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2sql-is-not-enough-unifying-ai-and</guid>
    </item>
    <item>
      <title>CursorCore: Assist Programming through Aligning Anything</title>
      <link>https://paperswithcode.com/paper/cursorcore-assist-programming-through</link>
      <description><![CDATA[In this work, we propose a new conversational framework that comprehensively integrates these information sources, collect data to train our models and evaluate their performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cursorcore-assist-programming-through</guid>
    </item>
  </channel>
</rss>
