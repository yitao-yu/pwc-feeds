<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 29 Mar 2023 09:13:06 +0000</lastBuildDate>
    <item>
      <title>ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge</title>
      <link>https://paperswithcode.com/paper/chatdoctor-a-medical-chat-model-fine-tuned-on</link>
      <description><![CDATA[Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatdoctor-a-medical-chat-model-fine-tuned-on</guid>
    </item>
    <item>
      <title>PAniC-3D: Stylized Single-view 3D Reconstruction from Portraits of Anime Characters</title>
      <link>https://paperswithcode.com/paper/panic-3d-stylized-single-view-3d</link>
      <description><![CDATA[We propose PAniC-3D, a system to reconstruct stylized 3D character heads directly from illustrated (p)ortraits of (ani)me (c)haracters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/panic-3d-stylized-single-view-3d</guid>
    </item>
    <item>
      <title>Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators</title>
      <link>https://paperswithcode.com/paper/text2video-zero-text-to-image-diffusion</link>
      <description><![CDATA[Recent text-to-video generation approaches rely on computationally heavy training and require large-scale video datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2video-zero-text-to-image-diffusion</guid>
    </item>
    <item>
      <title>Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior</title>
      <link>https://paperswithcode.com/paper/make-it-3d-high-fidelity-3d-creation-from-a</link>
      <description><![CDATA[In this work, we investigate the problem of creating high-fidelity 3D content from only a single image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/make-it-3d-high-fidelity-3d-creation-from-a</guid>
    </item>
    <item>
      <title>Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation</title>
      <link>https://paperswithcode.com/paper/tune-a-video-one-shot-tuning-of-image</link>
      <description><![CDATA[To replicate the success of text-to-image (T2I) generation, recent works employ large-scale video datasets to train a text-to-video (T2V) generator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tune-a-video-one-shot-tuning-of-image</guid>
    </item>
    <item>
      <title>SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</link>
      <description><![CDATA[We propose SmoothQuant, a training-free, accuracy-preserving, and general-purpose post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit activation (W8A8) quantization for LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</guid>
    </item>
    <item>
      <title>Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation</title>
      <link>https://paperswithcode.com/paper/fantasia3d-disentangling-geometry-and</link>
      <description><![CDATA[Key to Fantasia3D is the disentangled modeling and learning of geometry and appearance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fantasia3d-disentangling-geometry-and</guid>
    </item>
    <item>
      <title>Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases</title>
      <link>https://paperswithcode.com/paper/exploring-the-impact-of-instruction-data</link>
      <description><![CDATA[However current research rarely studies the impact of different amounts of instruction data on model performance, especially in the real-world use cases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-impact-of-instruction-data</guid>
    </item>
    <item>
      <title>LoRA: Low-Rank Adaptation of Large Language Models</title>
      <link>https://paperswithcode.com/paper/lora-low-rank-adaptation-of-large-language</link>
      <description><![CDATA[We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lora-low-rank-adaptation-of-large-language</guid>
    </item>
    <item>
      <title>More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models</title>
      <link>https://paperswithcode.com/paper/more-than-you-ve-asked-for-a-comprehensive</link>
      <description><![CDATA[In such attacks, an adversary can prompt the LLM to produce malicious content or override the original instructions and the employed filtering schemes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/more-than-you-ve-asked-for-a-comprehensive</guid>
    </item>
    <item>
      <title>LLaMA: Open and Efficient Foundation Language Models</title>
      <link>https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</link>
      <description><![CDATA[We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</guid>
    </item>
    <item>
      <title>Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models</title>
      <link>https://paperswithcode.com/paper/text2room-extracting-textured-3d-meshes-from</link>
      <description><![CDATA[We present Text2Room, a method for generating room-scale textured 3D meshes from a given text prompt as input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2room-extracting-textured-3d-meshes-from</guid>
    </item>
    <item>
      <title>SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications</title>
      <link>https://paperswithcode.com/paper/swiftformer-efficient-additive-attention-for</link>
      <description><![CDATA[Using our proposed efficient additive attention, we build a series of models called "SwiftFormer" which achieves state-of-the-art performance in terms of both accuracy and mobile inference speed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/swiftformer-efficient-additive-attention-for</guid>
    </item>
    <item>
      <title>Equivariant Similarity for Vision-Language Foundation Models</title>
      <link>https://paperswithcode.com/paper/equivariant-similarity-for-vision-language</link>
      <description><![CDATA[Unlike the existing image-text similarity objective which only categorizes matched pairs as similar and unmatched pairs as dissimilar, equivariance also requires similarity to vary faithfully according to the semantic changes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/equivariant-similarity-for-vision-language</guid>
    </item>
    <item>
      <title>ReVersion: Diffusion-Based Relation Inversion from Images</title>
      <link>https://paperswithcode.com/paper/reversion-diffusion-based-relation-inversion</link>
      <description><![CDATA[Specifically, we propose a novel relation-steering contrastive learning scheme to impose two critical properties of the relation prompt: 1) The relation prompt should capture the interaction between objects, enforced by the preposition prior.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reversion-diffusion-based-relation-inversion</guid>
    </item>
    <item>
      <title>Reflexion: an autonomous agent with dynamic memory and self-reflection</title>
      <link>https://paperswithcode.com/paper/reflexion-an-autonomous-agent-with-dynamic</link>
      <description><![CDATA[To achieve full automation, we introduce a straightforward yet effective heuristic that enables the agent to pinpoint hallucination instances, avoid repetition in action sequences, and, in some environments, construct an internal memory map of the given environment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reflexion-an-autonomous-agent-with-dynamic</guid>
    </item>
    <item>
      <title>ADAPT: Action-aware Driving Caption Transformer</title>
      <link>https://paperswithcode.com/paper/adapt-action-aware-driving-caption</link>
      <description><![CDATA[To bridge the gap, we propose an end-to-end transformer-based architecture, ADAPT (Action-aware Driving cAPtion Transformer), which provides user-friendly natural language narrations and reasoning for each decision making step of autonomous vehicular control and action.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adapt-action-aware-driving-caption</guid>
    </item>
    <item>
      <title>Ref-NPR: Reference-Based Non-Photorealistic Radiance Fields for Controllable Scene Stylization</title>
      <link>https://paperswithcode.com/paper/ref-npr-reference-based-non-photorealistic</link>
      <description><![CDATA[We propose a ray registration process based on the stylized reference view to obtain pseudo-ray supervision in novel views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ref-npr-reference-based-non-photorealistic</guid>
    </item>
    <item>
      <title>Data-centric Artificial Intelligence: A Survey</title>
      <link>https://paperswithcode.com/paper/data-centric-artificial-intelligence-a-survey</link>
      <description><![CDATA[Artificial Intelligence (AI) is making a profound impact in almost every domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-centric-artificial-intelligence-a-survey</guid>
    </item>
    <item>
      <title>GLM-130B: An Open Bilingual Pre-trained Model</title>
      <link>https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</link>
      <description><![CDATA[We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</guid>
    </item>
  </channel>
</rss>
