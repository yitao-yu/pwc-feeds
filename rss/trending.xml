<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 13 May 2023 21:04:53 +0000</lastBuildDate>
    <item>
      <title>ImageBind: One Embedding Space To Bind Them All</title>
      <link>https://paperswithcode.com/paper/imagebind-one-embedding-space-to-bind-them</link>
      <description><![CDATA[We show that all combinations of paired data are not necessary to train such a joint embedding, and only image-paired data is sufficient to bind the modalities together.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imagebind-one-embedding-space-to-bind-them</guid>
    </item>
    <item>
      <title>Shap-E: Generating Conditional 3D Implicit Functions</title>
      <link>https://paperswithcode.com/paper/shap-e-generating-conditional-3d-implicit</link>
      <description><![CDATA[We present Shap-E, a conditional generative model for 3D assets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shap-e-generating-conditional-3d-implicit</guid>
    </item>
    <item>
      <title>HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge</title>
      <link>https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</link>
      <description><![CDATA[Large Language Models (LLMs), such as the LLaMA model, have demonstrated their effectiveness in various general-domain natural language processing (NLP) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese</guid>
    </item>
    <item>
      <title>U$^2$-Net: Going Deeper with Nested U-Structure for Salient Object Detection</title>
      <link>https://paperswithcode.com/paper/u-2-net-going-deeper-with-nested-u-structure</link>
      <description><![CDATA[In this paper, we design a simple yet powerful deep network architecture, U$^2$-Net, for salient object detection (SOD).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/u-2-net-going-deeper-with-nested-u-structure</guid>
    </item>
    <item>
      <title>WebCPM: Interactive Web Search for Chinese Long-form Question Answering</title>
      <link>https://paperswithcode.com/paper/webcpm-interactive-web-search-for-chinese</link>
      <description><![CDATA[We recruit annotators to search for relevant information using our interface and then answer questions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/webcpm-interactive-web-search-for-chinese</guid>
    </item>
    <item>
      <title>InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language</title>
      <link>https://paperswithcode.com/paper/internchat-solving-vision-centric-tasks-by</link>
      <description><![CDATA[Different from existing interactive systems that rely on pure language, by incorporating pointing instructions, the proposed iGPT significantly improves the efficiency of communication between users and chatbots, as well as the accuracy of chatbots in vision-centric tasks, especially in complicated visual scenarios where the number of objects is greater than 2.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internchat-solving-vision-centric-tasks-by</guid>
    </item>
    <item>
      <title>Personalize Segment Anything Model with One Shot</title>
      <link>https://paperswithcode.com/paper/personalize-segment-anything-model-with-one</link>
      <description><![CDATA[Driven by large-data pre-training, Segment Anything Model (SAM) has been demonstrated as a powerful and promptable framework, revolutionizing the segmentation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalize-segment-anything-model-with-one</guid>
    </item>
    <item>
      <title>MultiModal-GPT: A Vision and Language Model for Dialogue with Humans</title>
      <link>https://paperswithcode.com/paper/multimodal-gpt-a-vision-and-language-model</link>
      <description><![CDATA[To further enhance the ability to chat with humans of the MultiModal-GPT, we utilize language-only instruction-following data to train the MultiModal-GPT jointly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-gpt-a-vision-and-language-model</guid>
    </item>
    <item>
      <title>Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures</title>
      <link>https://paperswithcode.com/paper/latent-nerf-for-shape-guided-generation-of-3d</link>
      <description><![CDATA[This unique combination of text and shape guidance allows for increased control over the generation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-nerf-for-shape-guided-generation-of-3d</guid>
    </item>
    <item>
      <title>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</title>
      <link>https://paperswithcode.com/paper/harnessing-the-power-of-llms-in-practice-a</link>
      <description><![CDATA[This paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream natural language processing (NLP) tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/harnessing-the-power-of-llms-in-practice-a</guid>
    </item>
    <item>
      <title>Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision</title>
      <link>https://paperswithcode.com/paper/principle-driven-self-alignment-of-language</link>
      <description><![CDATA[Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/principle-driven-self-alignment-of-language</guid>
    </item>
    <item>
      <title>Otter: A Multi-Modal Model with In-Context Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/otter-a-multi-modal-model-with-in-context</link>
      <description><![CDATA[Large language models (LLMs) have demonstrated significant universal capabilities as few/zero-shot learners in various tasks due to their pre-training on vast amounts of text data, as exemplified by GPT-3, which boosted to InstrctGPT and ChatGPT, effectively following natural language instructions to accomplish real-world tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/otter-a-multi-modal-model-with-in-context</guid>
    </item>
    <item>
      <title>PET-NeuS: Positional Encoding Tri-Planes for Neural Surfaces</title>
      <link>https://paperswithcode.com/paper/pet-neus-positional-encoding-tri-planes-for</link>
      <description><![CDATA[The first component is to borrow the tri-plane representation from EG3D and represent signed distance fields as a mixture of tri-planes and MLPs instead of representing it with MLPs only.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pet-neus-positional-encoding-tri-planes-for</guid>
    </item>
    <item>
      <title>An Inverse Scaling Law for CLIP Training</title>
      <link>https://paperswithcode.com/paper/an-inverse-scaling-law-for-clip-training</link>
      <description><![CDATA[CLIP, the first foundation model that connects images and text, has enabled many recent breakthroughs in computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/an-inverse-scaling-law-for-clip-training</guid>
    </item>
    <item>
      <title>Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models</title>
      <link>https://paperswithcode.com/paper/plan-and-solve-prompting-improving-zero-shot</link>
      <description><![CDATA[To address the calculation errors and improve the quality of generated reasoning steps, we extend PS prompting with more detailed instructions and derive PS+ prompting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plan-and-solve-prompting-improving-zero-shot</guid>
    </item>
    <item>
      <title>iDisc: Internal Discretization for Monocular Depth Estimation</title>
      <link>https://paperswithcode.com/paper/idisc-internal-discretization-for-monocular</link>
      <description><![CDATA[Our method sets the new state of the art with significant improvements on NYU-Depth v2 and KITTI, outperforming all published methods on the official KITTI benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/idisc-internal-discretization-for-monocular</guid>
    </item>
    <item>
      <title>PP-LiteSeg: A Superior Real-Time Semantic Segmentation Model</title>
      <link>https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</link>
      <description><![CDATA[Real-world applications have high demands for semantic segmentation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pp-liteseg-a-superior-real-time-semantic</guid>
    </item>
    <item>
      <title>Think Twice before Driving: Towards Scalable Decoders for End-to-End Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/think-twice-before-driving-towards-scalable</link>
      <description><![CDATA[End-to-end autonomous driving has made impressive progress in recent years.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/think-twice-before-driving-towards-scalable</guid>
    </item>
    <item>
      <title>Active Retrieval Augmented Generation</title>
      <link>https://paperswithcode.com/paper/active-retrieval-augmented-generation</link>
      <description><![CDATA[We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic retrieval-augmented generation method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/active-retrieval-augmented-generation</guid>
    </item>
    <item>
      <title>Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca</title>
      <link>https://paperswithcode.com/paper/efficient-and-effective-text-encoding-for</link>
      <description><![CDATA[Large Language Models (LLMs), such as ChatGPT and GPT-4, have revolutionized natural language processing research and demonstrated potential in Artificial General Intelligence (AGI).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-and-effective-text-encoding-for</guid>
    </item>
  </channel>
</rss>
