<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 30 Nov 2022 09:14:54 +0000</lastBuildDate>
    <item>
      <title>TorchScale: Transformers at Scale</title>
      <link>https://paperswithcode.com/paper/torchscale-transformers-at-scale</link>
      <description><![CDATA[Large Transformers have achieved state-of-the-art performance across many tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchscale-transformers-at-scale</guid>
    </item>
    <item>
      <title>SuperFusion: Multilevel LiDAR-Camera Fusion for Long-Range HD Map Generation and Prediction</title>
      <link>https://paperswithcode.com/paper/superfusion-multilevel-lidar-camera-fusion</link>
      <description><![CDATA[To this end, we propose a novel network named SuperFusion, exploiting the fusion of LiDAR and camera data at multiple levels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/superfusion-multilevel-lidar-camera-fusion</guid>
    </item>
    <item>
      <title>Human-level play in the game of Diplomacy by combining language models with strategic reasoning</title>
      <link>https://paperswithcode.com/paper/human-level-play-in-the-game-of-diplomacy-by</link>
      <description><![CDATA[Despite much progress in training AI systems to imitate human language, building agents that use language to communicate intentionally with humans in interactive environments remains a major challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/human-level-play-in-the-game-of-diplomacy-by</guid>
    </item>
    <item>
      <title>FFHQ-UV: Normalized Facial UV-Texture Dataset for 3D Face Reconstruction</title>
      <link>https://paperswithcode.com/paper/ffhq-uv-normalized-facial-uv-texture-dataset</link>
      <description><![CDATA[Our pipeline utilizes the recent advances in StyleGAN-based facial image editing approaches to generate multi-view normalized face images from single-image inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ffhq-uv-normalized-facial-uv-texture-dataset</guid>
    </item>
    <item>
      <title>Fast-SNARF: A Fast Deformer for Articulated Neural Fields</title>
      <link>https://paperswithcode.com/paper/fast-snarf-a-fast-deformer-for-articulated</link>
      <description><![CDATA[A key challenge in making such methods applicable to articulated objects, such as the human body, is to model the deformation of 3D locations between the rest pose (a canonical space) and the deformed space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-snarf-a-fast-deformer-for-articulated</guid>
    </item>
    <item>
      <title>MetaFormer Baselines for Vision</title>
      <link>https://paperswithcode.com/paper/metaformer-baselines-for-vision</link>
      <description><![CDATA[By simply applying depthwise separable convolutions as token mixer in the bottom stages and vanilla self-attention in the top stages, the resulting model CAFormer sets a new record on ImageNet-1K: it achieves an accuracy of 85. 5% at 224x224 resolution, under normal supervised training without external data or distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metaformer-baselines-for-vision</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>LiT: Zero-Shot Transfer with Locked-image text Tuning</title>
      <link>https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</link>
      <description><![CDATA[This paper presents contrastive-tuning, a simple method employing contrastive training to align image and text models while still taking advantage of their pre-training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</guid>
    </item>
    <item>
      <title>ZeroEGGS: Zero-shot Example-based Gesture Generation from Speech</title>
      <link>https://paperswithcode.com/paper/zeroeggs-zero-shot-example-based-gesture</link>
      <description><![CDATA[In a series of experiments, we first demonstrate the flexibility and generalizability of our model to new speakers and styles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zeroeggs-zero-shot-example-based-gesture</guid>
    </item>
    <item>
      <title>Versatile Diffusion: Text, Images and Variations All in One Diffusion Model</title>
      <link>https://paperswithcode.com/paper/versatile-diffusion-text-images-and</link>
      <description><![CDATA[Through our experiments, we demonstrate that VD and its underlying framework have the following merits: a) VD handles all subtasks with competitive quality; b) VD initiates novel extensions and applications such as disentanglement of style and semantic, image-text dual-guided generation, etc.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/versatile-diffusion-text-images-and</guid>
    </item>
    <item>
      <title>Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark</title>
      <link>https://paperswithcode.com/paper/roboflow-100-a-rich-multi-domain-object</link>
      <description><![CDATA[The evaluation of object detection models is usually performed by optimizing a single metric, e. g. mAP, on a fixed set of datasets, e. g. Microsoft COCO and Pascal VOC.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/roboflow-100-a-rich-multi-domain-object</guid>
    </item>
    <item>
      <title>Paint by Example: Exemplar-based Image Editing with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/paint-by-example-exemplar-based-image-editing</link>
      <description><![CDATA[Language-guided image editing has achieved great success recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paint-by-example-exemplar-based-image-editing</guid>
    </item>
    <item>
      <title>DiffusionDet: Diffusion Model for Object Detection</title>
      <link>https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</link>
      <description><![CDATA[In inference, the model refines a set of randomly generated boxes to the output results in a progressive way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</guid>
    </item>
    <item>
      <title>Fast Text-Conditional Discrete Denoising on Vector-Quantized Latent Spaces</title>
      <link>https://paperswithcode.com/paper/fast-text-conditional-discrete-denoising-on</link>
      <description><![CDATA[Conditional text-to-image generation has seen countless recent improvements in terms of quality, diversity and fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-text-conditional-discrete-denoising-on</guid>
    </item>
    <item>
      <title>A Time Series is Worth 64 Words: Long-term Forecasting with Transformers</title>
      <link>https://paperswithcode.com/paper/a-time-series-is-worth-64-words-long-term</link>
      <description><![CDATA[Our channel-independent patch time series Transformer (PatchTST) can improve the long-term forecasting accuracy significantly when compared with that of SOTA Transformer-based models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-time-series-is-worth-64-words-long-term</guid>
    </item>
    <item>
      <title>Medical Image Segmentation Review: The success of U-Net</title>
      <link>https://paperswithcode.com/paper/medical-image-segmentation-review-the-success</link>
      <description><![CDATA[U-Net is the most widespread image segmentation architecture due to its flexibility, optimized modular design, and success in all medical image modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medical-image-segmentation-review-the-success</guid>
    </item>
    <item>
      <title>SinDiffusion: Learning a Diffusion Model from a Single Natural Image</title>
      <link>https://paperswithcode.com/paper/sindiffusion-learning-a-diffusion-model-from</link>
      <description><![CDATA[We present SinDiffusion, leveraging denoising diffusion models to capture internal distribution of patches from a single natural image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sindiffusion-learning-a-diffusion-model-from</guid>
    </item>
    <item>
      <title>VeLO: Training Versatile Learned Optimizers by Scaling Up</title>
      <link>https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</link>
      <description><![CDATA[While deep learning models have replaced hand-designed features across many domains, these models are still trained with hand-designed optimizers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</guid>
    </item>
    <item>
      <title>A Closer Look at Learned Optimization: Stability, Robustness, and Inductive Biases</title>
      <link>https://paperswithcode.com/paper/a-closer-look-at-learned-optimization</link>
      <description><![CDATA[We apply the resulting learned optimizer to a variety of neural network training tasks, where it outperforms the current state of the art learned optimizer -- at matched optimizer computational overhead -- with regard to optimization performance and meta-training speed, and is capable of generalization to tasks far different from those it was meta-trained on.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-closer-look-at-learned-optimization</guid>
    </item>
    <item>
      <title>DeepPrivacy2: Towards Realistic Full-Body Anonymization</title>
      <link>https://paperswithcode.com/paper/deepprivacy2-towards-realistic-full-body</link>
      <description><![CDATA[Generative Adversarial Networks (GANs) are widely adapted for anonymization of human figures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepprivacy2-towards-realistic-full-body</guid>
    </item>
  </channel>
</rss>
