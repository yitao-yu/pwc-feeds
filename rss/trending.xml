<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 25 Jun 2025 21:10:37 +0000</lastBuildDate>
    <item>
      <title>Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting</title>
      <link>https://paperswithcode.com/paper/dolphin-document-image-parsing-via</link>
      <description><![CDATA[Document image parsing is challenging due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dolphin-document-image-parsing-via</guid>
    </item>
    <item>
      <title>Mean Flows for One-step Generative Modeling</title>
      <link>https://paperswithcode.com/paper/mean-flows-for-one-step-generative-modeling</link>
      <description><![CDATA[We propose a principled and effective framework for one-step generative modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mean-flows-for-one-step-generative-modeling</guid>
    </item>
    <item>
      <title>MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention</title>
      <link>https://paperswithcode.com/paper/minimax-m1-scaling-test-time-compute</link>
      <description><![CDATA[We release two versions of MiniMax-M1 models with 40K and 80K thinking budgets respectively, where the 40K model represents an intermediate phase of the 80K training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minimax-m1-scaling-test-time-compute</guid>
    </item>
    <item>
      <title>Let Them Talk: Audio-Driven Multi-Person Conversational Video Generation</title>
      <link>https://paperswithcode.com/paper/let-them-talk-audio-driven-multi-person</link>
      <description><![CDATA[Audio-driven human animation methods, such as talking head and talking body generation, have made remarkable progress in generating synchronized facial movements and appealing visual quality videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/let-them-talk-audio-driven-multi-person</guid>
    </item>
    <item>
      <title>ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching</title>
      <link>https://paperswithcode.com/paper/zipvoice-fast-and-high-quality-zero-shot-text</link>
      <description><![CDATA[Existing large-scale zero-shot text-to-speech (TTS) models deliver high speech quality but suffer from slow inference speeds due to massive parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zipvoice-fast-and-high-quality-zero-shot-text</guid>
    </item>
    <item>
      <title>TradingAgents: Multi-Agents LLM Financial Trading Framework</title>
      <link>https://paperswithcode.com/paper/tradingagents-multi-agents-llm-financial</link>
      <description><![CDATA[Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tradingagents-multi-agents-llm-financial</guid>
    </item>
    <item>
      <title>Mirage: A Multi-Level Superoptimizer for Tensor Programs</title>
      <link>https://paperswithcode.com/paper/a-multi-level-superoptimizer-for-tensor</link>
      <description><![CDATA[We introduce Mirage, the first multi-level superoptimizer for tensor programs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-multi-level-superoptimizer-for-tensor</guid>
    </item>
    <item>
      <title>Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material</title>
      <link>https://paperswithcode.com/paper/hunyuan3d-2-1-from-images-to-high-fidelity-3d</link>
      <description><![CDATA[3D AI-generated content (AIGC) is a passionate field that has significantly accelerated the creation of 3D models in gaming, film, and design.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuan3d-2-1-from-images-to-high-fidelity-3d</guid>
    </item>
    <item>
      <title>LeVo: High-Quality Song Generation with Multi-Preference Alignment</title>
      <link>https://paperswithcode.com/paper/levo-high-quality-song-generation-with-multi</link>
      <description><![CDATA[To further enhance musicality and instruction following, we introduce a multi-preference alignment method based on Direct Preference Optimization (DPO).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/levo-high-quality-song-generation-with-multi</guid>
    </item>
    <item>
      <title>MEIA: Multimodal Embodied Perception and Interaction in Unknown Environments</title>
      <link>https://paperswithcode.com/paper/multimodal-embodied-interactive-agent-for</link>
      <description><![CDATA[To overcome this limitation, we introduce the Multimodal Embodied Interactive Agent (MEIA), capable of translating high-level tasks expressed in natural language into a sequence of executable actions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-embodied-interactive-agent-for</guid>
    </item>
    <item>
      <title>Visual Causal Scene Refinement for Video Question Answering</title>
      <link>https://paperswithcode.com/paper/visual-causal-scene-refinement-for-video</link>
      <description><![CDATA[Our VCSR involves two essential modules: i) the Question-Guided Refiner (QGR) module, which refines consecutive video frames guided by the question semantics to obtain more representative segment features for causal front-door intervention; ii) the Causal Scene Separator (CSS) module, which discovers a collection of visual causal and non-causal scenes based on the visual-linguistic causal relevance and estimates the causal effect of the scene-separating intervention in a contrastive learning manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-causal-scene-refinement-for-video</guid>
    </item>
    <item>
      <title>MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm</title>
      <link>https://paperswithcode.com/paper/monkeyocr-document-parsing-with-a-structure</link>
      <description><![CDATA[We introduce MonkeyOCR, a vision-language model for document parsing that advances the state of the art by leveraging a Structure-Recognition-Relation (SRR) triplet paradigm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monkeyocr-document-parsing-with-a-structure</guid>
    </item>
    <item>
      <title>PixelsDB: Serverless and NL-Aided Data Analytics with Flexible Service Levels and Prices</title>
      <link>https://paperswithcode.com/paper/pixelsdb-serverless-and-natural-language</link>
      <description><![CDATA[The queries are then executed by a serverless query engine that offers varying prices for different performance service levels (SLAs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pixelsdb-serverless-and-natural-language</guid>
    </item>
    <item>
      <title>DreamGen: Unlocking Generalization in Robot Learning through Video World Models</title>
      <link>https://paperswithcode.com/paper/dreamgen-unlocking-generalization-in-robot</link>
      <description><![CDATA[We introduce DreamGen, a simple yet highly effective 4-stage pipeline for training robot policies that generalize across behaviors and environments through neural trajectories - synthetic robot data generated from video world models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamgen-unlocking-generalization-in-robot</guid>
    </item>
    <item>
      <title>SoundMind: RL-Incentivized Logic Reasoning for Audio-Language Models</title>
      <link>https://paperswithcode.com/paper/soundmind-rl-incentivized-logic-reasoning-for</link>
      <description><![CDATA[While large language models have shown reasoning capabilities, their application to the audio modality, particularly in large audio-language models (ALMs), remains significantly underdeveloped.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/soundmind-rl-incentivized-logic-reasoning-for</guid>
    </item>
    <item>
      <title>Protoformer: Embedding Prototypes for Transformers</title>
      <link>https://paperswithcode.com/paper/protoformer-embedding-prototypes-for-1</link>
      <description><![CDATA[This paper proposes Protoformer, a novel self-learning framework for Transformers that can leverage problematic samples for text classification.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/protoformer-embedding-prototypes-for-1</guid>
    </item>
    <item>
      <title>Overcoming catastrophic forgetting in neural networks</title>
      <link>https://paperswithcode.com/paper/overcoming-catastrophic-forgetting-in-neural</link>
      <description><![CDATA[The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/overcoming-catastrophic-forgetting-in-neural</guid>
    </item>
    <item>
      <title>AquaSignal: An Integrated Framework for Robust Underwater Acoustic Analysis</title>
      <link>https://paperswithcode.com/paper/aquasignal-an-integrated-framework-for-robust</link>
      <description><![CDATA[This paper presents AquaSignal, a modular and scalable pipeline for preprocessing, denoising, classification, and novelty detection of underwater acoustic signals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aquasignal-an-integrated-framework-for-robust</guid>
    </item>
    <item>
      <title>AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents</title>
      <link>https://paperswithcode.com/paper/autoagent-a-fully-automated-and-zero-code</link>
      <description><![CDATA[To address this challenge, we introduce AutoAgent-a Fully-Automated and highly Self-Developing framework that enables users to create and deploy LLM agents through Natural Language Alone.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autoagent-a-fully-automated-and-zero-code</guid>
    </item>
    <item>
      <title>Marrying Autoregressive Transformer and Diffusion with Multi-Reference Autoregression</title>
      <link>https://paperswithcode.com/paper/marrying-autoregressive-transformer-and</link>
      <description><![CDATA[We introduce TransDiff, the first image generation model that marries Autoregressive (AR) Transformer with diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/marrying-autoregressive-transformer-and</guid>
    </item>
  </channel>
</rss>
