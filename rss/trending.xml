<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 17 Jan 2024 09:13:19 +0000</lastBuildDate>
    <item>
      <title>PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding</title>
      <link>https://paperswithcode.com/paper/photomaker-customizing-realistic-human-photos</link>
      <description><![CDATA[Recent advances in text-to-image generation have made remarkable progress in synthesizing realistic human photos conditioned on given text prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photomaker-customizing-realistic-human-photos</guid>
    </item>
    <item>
      <title>Efficient Deformable ConvNets: Rethinking Dynamic and Sparse Operator for Vision Applications</title>
      <link>https://paperswithcode.com/paper/efficient-deformable-convnets-rethinking</link>
      <description><![CDATA[The advancements in speed and efficiency of DCNv4, combined with its robust performance across diverse vision tasks, show its potential as a foundational building block for future vision models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-deformable-convnets-rethinking</guid>
    </item>
    <item>
      <title>DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders</title>
      <link>https://paperswithcode.com/paper/ddcolor-towards-photo-realistic-and-semantic</link>
      <description><![CDATA[Image colorization is a challenging problem due to multi-modal uncertainty and high ill-posedness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ddcolor-towards-photo-realistic-and-semantic</guid>
    </item>
    <item>
      <title>DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models</title>
      <link>https://paperswithcode.com/paper/deepseekmoe-towards-ultimate-expert</link>
      <description><![CDATA[Subsequently, we scale up DeepSeekMoE to 16B parameters and show that it achieves comparable performance with LLaMA2 7B, with only about 40% of computations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseekmoe-towards-ultimate-expert</guid>
    </item>
    <item>
      <title>LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression</title>
      <link>https://paperswithcode.com/paper/longllmlingua-accelerating-and-enhancing-llms</link>
      <description><![CDATA[Inspired by these findings, we propose LongLLMLingua for prompt compression towards improving LLMs' perception of the key information to simultaneously address the three challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longllmlingua-accelerating-and-enhancing-llms</guid>
    </item>
    <item>
      <title>INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/inters-unlocking-the-power-of-large-language</link>
      <description><![CDATA[Despite this, their application to information retrieval (IR) tasks is still challenging due to the infrequent occurrence of many IR-specific concepts in natural language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inters-unlocking-the-power-of-large-language</guid>
    </item>
    <item>
      <title>MI-GAN: A Simple Baseline for Image Inpainting on Mobile Devices</title>
      <link>https://paperswithcode.com/paper/mi-gan-a-simple-baseline-for-image-inpainting</link>
      <description><![CDATA[In this paper we present a simple image inpainting baseline, Mobile Inpainting GAN (MI-GAN), which is approximately one order of magnitude computationally cheaper and smaller than existing state-of-the-art inpainting models, and can be efficiently deployed on mobile devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mi-gan-a-simple-baseline-for-image-inpainting</guid>
    </item>
    <item>
      <title>TrustLLM: Trustworthiness in Large Language Models</title>
      <link>https://paperswithcode.com/paper/trustllm-trustworthiness-in-large-language</link>
      <description><![CDATA[This paper introduces TrustLLM, a comprehensive study of trustworthiness in LLMs, including principles for different dimensions of trustworthiness, established benchmark, evaluation, and analysis of trustworthiness for mainstream LLMs, and discussion of open challenges and future directions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/trustllm-trustworthiness-in-large-language</guid>
    </item>
    <item>
      <title>LEGO:Language Enhanced Multi-modal Grounding Model</title>
      <link>https://paperswithcode.com/paper/lego-language-enhanced-multi-modal-grounding</link>
      <description><![CDATA[Beyond capturing global information like other multi-modal models, our proposed model excels at tasks demanding a detailed understanding of local information within the input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lego-language-enhanced-multi-modal-grounding</guid>
    </item>
    <item>
      <title>Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch</title>
      <link>https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</link>
      <description><![CDATA[Based on this observation, we further sparsify delta parameters of multiple SFT homologous models with DARE and subsequently merge them into a single model by parameter averaging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</guid>
    </item>
    <item>
      <title>LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning</title>
      <link>https://paperswithcode.com/paper/llm-maybe-longlm-self-extend-llm-context</link>
      <description><![CDATA[In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-maybe-longlm-self-extend-llm-context</guid>
    </item>
    <item>
      <title>Mamba: Linear-Time Sequence Modeling with Selective State Spaces</title>
      <link>https://paperswithcode.com/paper/mamba-linear-time-sequence-modeling-with</link>
      <description><![CDATA[Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mamba-linear-time-sequence-modeling-with</guid>
    </item>
    <item>
      <title>NEFTune: Noisy Embeddings Improve Instruction Finetuning</title>
      <link>https://paperswithcode.com/paper/neftune-noisy-embeddings-improve-instruction</link>
      <description><![CDATA[We show that language model finetuning can be improved, sometimes dramatically, with a simple augmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neftune-noisy-embeddings-improve-instruction</guid>
    </item>
    <item>
      <title>Training language models to follow instructions with human feedback</title>
      <link>https://paperswithcode.com/paper/training-language-models-to-follow</link>
      <description><![CDATA[In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/training-language-models-to-follow</guid>
    </item>
    <item>
      <title>DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines</title>
      <link>https://paperswithcode.com/paper/dspy-assertions-computational-constraints-for</link>
      <description><![CDATA[Our reference implementation of LM Assertions is integrated into DSPy at https://github. com/stanfordnlp/dspy]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dspy-assertions-computational-constraints-for</guid>
    </item>
    <item>
      <title>Pheme: Efficient and Conversational Speech Generation</title>
      <link>https://paperswithcode.com/paper/pheme-efficient-and-conversational-speech</link>
      <description><![CDATA[However, certain applications, such as assistive conversational systems, require natural and conversational speech generation tools that also operate efficiently in real time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pheme-efficient-and-conversational-speech</guid>
    </item>
    <item>
      <title>From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations</title>
      <link>https://paperswithcode.com/paper/from-audio-to-photoreal-embodiment</link>
      <description><![CDATA[We present a framework for generating full-bodied photorealistic avatars that gesture according to the conversational dynamics of a dyadic interaction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/from-audio-to-photoreal-embodiment</guid>
    </item>
    <item>
      <title>What Makes Good In-Context Examples for GPT-$3$?</title>
      <link>https://paperswithcode.com/paper/what-makes-good-in-context-examples-for-gpt-3</link>
      <description><![CDATA[Inspired by the recent success of leveraging a retrieval module to augment large-scale neural network models, we propose to retrieve examples that are semantically-similar to a test sample to formulate its corresponding prompt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/what-makes-good-in-context-examples-for-gpt-3</guid>
    </item>
    <item>
      <title>Machine Mindset: An MBTI Exploration of Large Language Models</title>
      <link>https://paperswithcode.com/paper/machine-mindset-an-mbti-exploration-of-large</link>
      <description><![CDATA[We present a novel approach for integrating Myers-Briggs Type Indicator (MBTI) personality traits into large language models (LLMs), addressing the challenges of personality consistency in personalized AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/machine-mindset-an-mbti-exploration-of-large</guid>
    </item>
    <item>
      <title>TaskWeaver: A Code-First Agent Framework</title>
      <link>https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</link>
      <description><![CDATA[TaskWeaver provides support for rich data structures, flexible plugin usage, and dynamic plugin selection, and leverages LLM coding capabilities for complex logic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</guid>
    </item>
  </channel>
</rss>
