<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 19 Jan 2024 21:06:54 +0000</lastBuildDate>
    <item>
      <title>PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding</title>
      <link>https://paperswithcode.com/paper/photomaker-customizing-realistic-human-photos</link>
      <description><![CDATA[Recent advances in text-to-image generation have made remarkable progress in synthesizing realistic human photos conditioned on given text prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photomaker-customizing-realistic-human-photos</guid>
    </item>
    <item>
      <title>Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering</title>
      <link>https://paperswithcode.com/paper/code-generation-with-alphacodium-from-prompt</link>
      <description><![CDATA[Hence, many of the optimizations and tricks that have been successful in natural language generation may not be effective for code tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/code-generation-with-alphacodium-from-prompt</guid>
    </item>
    <item>
      <title>InstantID: Zero-shot Identity-Preserving Generation in Seconds</title>
      <link>https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</link>
      <description><![CDATA[There has been significant progress in personalized image synthesis with methods such as Textual Inversion, DreamBooth, and LoRA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</guid>
    </item>
    <item>
      <title>Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model</title>
      <link>https://paperswithcode.com/paper/vision-mamba-efficient-visual-representation</link>
      <description><![CDATA[The results demonstrate that Vim is capable of overcoming the computation & memory constraints on performing Transformer-style understanding for high-resolution images and it has great potential to become the next-generation backbone for vision foundation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-mamba-efficient-visual-representation</guid>
    </item>
    <item>
      <title>Scalable Pre-training of Large Autoregressive Image Models</title>
      <link>https://paperswithcode.com/paper/scalable-pre-training-of-large-autoregressive</link>
      <description><![CDATA[Specifically, we highlight two key findings: (1) the performance of the visual features scale with both the model capacity and the quantity of data, (2) the value of the objective function correlates with the performance of the model on downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-pre-training-of-large-autoregressive</guid>
    </item>
    <item>
      <title>AesBench: An Expert Benchmark for Multimodal Large Language Models on Image Aesthetics Perception</title>
      <link>https://paperswithcode.com/paper/aesbench-an-expert-benchmark-for-multimodal</link>
      <description><![CDATA[An obvious obstacle lies in the absence of a specific benchmark to evaluate the effectiveness of MLLMs on aesthetic perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aesbench-an-expert-benchmark-for-multimodal</guid>
    </item>
    <item>
      <title>Inferflow: an Efficient and Highly Configurable Inference Engine for Large Language Models</title>
      <link>https://paperswithcode.com/paper/inferflow-an-efficient-and-highly</link>
      <description><![CDATA[We present Inferflow, an efficient and highly configurable inference engine for large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inferflow-an-efficient-and-highly</guid>
    </item>
    <item>
      <title>DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders</title>
      <link>https://paperswithcode.com/paper/ddcolor-towards-photo-realistic-and-semantic</link>
      <description><![CDATA[Image colorization is a challenging problem due to multi-modal uncertainty and high ill-posedness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ddcolor-towards-photo-realistic-and-semantic</guid>
    </item>
    <item>
      <title>Efficient Deformable ConvNets: Rethinking Dynamic and Sparse Operator for Vision Applications</title>
      <link>https://paperswithcode.com/paper/efficient-deformable-convnets-rethinking</link>
      <description><![CDATA[The advancements in speed and efficiency of DCNv4, combined with its robust performance across diverse vision tasks, show its potential as a foundational building block for future vision models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-deformable-convnets-rethinking</guid>
    </item>
    <item>
      <title>LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression</title>
      <link>https://paperswithcode.com/paper/longllmlingua-accelerating-and-enhancing-llms</link>
      <description><![CDATA[Inspired by these findings, we propose LongLLMLingua for prompt compression towards improving LLMs' perception of the key information to simultaneously address the three challenges.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longllmlingua-accelerating-and-enhancing-llms</guid>
    </item>
    <item>
      <title>MI-GAN: A Simple Baseline for Image Inpainting on Mobile Devices</title>
      <link>https://paperswithcode.com/paper/mi-gan-a-simple-baseline-for-image-inpainting</link>
      <description><![CDATA[In this paper we present a simple image inpainting baseline, Mobile Inpainting GAN (MI-GAN), which is approximately one order of magnitude computationally cheaper and smaller than existing state-of-the-art inpainting models, and can be efficiently deployed on mobile devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mi-gan-a-simple-baseline-for-image-inpainting</guid>
    </item>
    <item>
      <title>Forging Vision Foundation Models for Autonomous Driving: Challenges, Methodologies, and Opportunities</title>
      <link>https://paperswithcode.com/paper/forging-vision-foundation-models-for</link>
      <description><![CDATA[The rise of large foundation models, trained on extensive datasets, is revolutionizing the field of AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/forging-vision-foundation-models-for</guid>
    </item>
    <item>
      <title>PIN-SLAM: LiDAR SLAM Using a Point-Based Implicit Neural Representation for Achieving Global Map Consistency</title>
      <link>https://paperswithcode.com/paper/pin-slam-lidar-slam-using-a-point-based</link>
      <description><![CDATA[In this paper, we propose a SLAM system for building globally consistent maps, called PIN-SLAM, that is based on an elastic and compact point-based implicit neural map representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pin-slam-lidar-slam-using-a-point-based</guid>
    </item>
    <item>
      <title>HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance</title>
      <link>https://paperswithcode.com/paper/huixiangdou-overcoming-group-chat-scenarios</link>
      <description><![CDATA[In this work, we present HuixiangDou, a technical assistant powered by Large Language Models (LLM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/huixiangdou-overcoming-group-chat-scenarios</guid>
    </item>
    <item>
      <title>DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models</title>
      <link>https://paperswithcode.com/paper/deepseekmoe-towards-ultimate-expert</link>
      <description><![CDATA[Subsequently, we scale up DeepSeekMoE to 16B parameters and show that it achieves comparable performance with LLaMA2 7B, with only about 40% of computations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseekmoe-towards-ultimate-expert</guid>
    </item>
    <item>
      <title>TaskWeaver: A Code-First Agent Framework</title>
      <link>https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</link>
      <description><![CDATA[TaskWeaver provides support for rich data structures, flexible plugin usage, and dynamic plugin selection, and leverages LLM coding capabilities for complex logic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</guid>
    </item>
    <item>
      <title>Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch</title>
      <link>https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</link>
      <description><![CDATA[Based on this observation, we further sparsify delta parameters of multiple SFT homologous models with DARE and subsequently merge them into a single model by parameter averaging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-are-super-mario-absorbing</guid>
    </item>
    <item>
      <title>INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/inters-unlocking-the-power-of-large-language</link>
      <description><![CDATA[Despite this, their application to information retrieval (IR) tasks is still challenging due to the infrequent occurrence of many IR-specific concepts in natural language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inters-unlocking-the-power-of-large-language</guid>
    </item>
    <item>
      <title>Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs</title>
      <link>https://paperswithcode.com/paper/eyes-wide-shut-exploring-the-visual</link>
      <description><![CDATA[To understand the roots of these errors, we explore the gap between the visual embedding space of CLIP and vision-only self-supervised learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eyes-wide-shut-exploring-the-visual</guid>
    </item>
    <item>
      <title>Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture</title>
      <link>https://paperswithcode.com/paper/monarch-mixer-a-simple-sub-quadratic-gemm-1</link>
      <description><![CDATA[We ask: are there performant architectures that can scale sub-quadratically along sequence length and model dimension?]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monarch-mixer-a-simple-sub-quadratic-gemm-1</guid>
    </item>
  </channel>
</rss>
