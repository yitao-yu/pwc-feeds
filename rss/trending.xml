<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 09 Feb 2023 09:13:37 +0000</lastBuildDate>
    <item>
      <title>BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining</title>
      <link>https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</link>
      <description><![CDATA[Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</guid>
    </item>
    <item>
      <title>TEXTure: Text-Guided Texturing of 3D Shapes</title>
      <link>https://paperswithcode.com/paper/texture-text-guided-texturing-of-3d-shapes</link>
      <description><![CDATA[In this paper, we present TEXTure, a novel method for text-guided generation, editing, and transfer of textures for 3D shapes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/texture-text-guided-texturing-of-3d-shapes</guid>
    </item>
    <item>
      <title>Multimodal Chain-of-Thought Reasoning in Language Models</title>
      <link>https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</link>
      <description><![CDATA[By incorporating the vision features in both stages, the model is able to generate effective rationales that contribute to answer inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</guid>
    </item>
    <item>
      <title>Mixture of Diffusers for scene composition and high resolution image generation</title>
      <link>https://paperswithcode.com/paper/mixture-of-diffusers-for-scene-composition</link>
      <description><![CDATA[Diffusion methods have been proven to be very effective to generate images while conditioning on a text prompt.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mixture-of-diffusers-for-scene-composition</guid>
    </item>
    <item>
      <title>Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery</title>
      <link>https://paperswithcode.com/paper/hard-prompts-made-easy-gradient-based</link>
      <description><![CDATA[In the text-to-image setting, the method creates hard prompts for diffusion models, allowing API users to easily generate, discover, and mix and match image concepts without prior knowledge on how to prompt the model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hard-prompts-made-easy-gradient-based</guid>
    </item>
    <item>
      <title>BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</title>
      <link>https://paperswithcode.com/paper/blip-2-bootstrapping-language-image-pre</link>
      <description><![CDATA[The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/blip-2-bootstrapping-language-image-pre</guid>
    </item>
    <item>
      <title>Discovering Symbolic Models from Deep Learning with Inductive Biases</title>
      <link>https://paperswithcode.com/paper/discovering-symbolic-models-from-deep</link>
      <description><![CDATA[The technique works as follows: we first encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/discovering-symbolic-models-from-deep</guid>
    </item>
    <item>
      <title>Top-Down Beats Bottom-Up in 3D Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/top-down-beats-bottom-up-in-3d-instance</link>
      <description><![CDATA[Most 3D instance segmentation methods exploit a bottom-up strategy, typically including resource-exhaustive post-processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/top-down-beats-bottom-up-in-3d-instance</guid>
    </item>
    <item>
      <title>ClimaX: A foundation model for weather and climate</title>
      <link>https://paperswithcode.com/paper/climax-a-foundation-model-for-weather-and</link>
      <description><![CDATA[Most state-of-the-art approaches for weather and climate modeling are based on physics-informed numerical models of the atmosphere.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/climax-a-foundation-model-for-weather-and</guid>
    </item>
    <item>
      <title>Dual PatchNorm</title>
      <link>https://paperswithcode.com/paper/dual-patchnorm</link>
      <description><![CDATA[We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms), before and after the patch embedding layer in Vision Transformers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dual-patchnorm</guid>
    </item>
    <item>
      <title>MOSE: A New Dataset for Video Object Segmentation in Complex Scenes</title>
      <link>https://paperswithcode.com/paper/mose-a-new-dataset-for-video-object</link>
      <description><![CDATA[However, since the target objects in these existing datasets are usually relatively salient, dominant, and isolated, VOS under complex scenes has rarely been studied.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mose-a-new-dataset-for-video-object</guid>
    </item>
    <item>
      <title>Open Source Vizier: Distributed Infrastructure and API for Reliable and Flexible Blackbox Optimization</title>
      <link>https://paperswithcode.com/paper/open-source-vizier-distributed-infrastructure</link>
      <description><![CDATA[Vizier is the de-facto blackbox and hyperparameter optimization service across Google, having optimized some of Google's largest products and research efforts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-source-vizier-distributed-infrastructure</guid>
    </item>
    <item>
      <title>STEPS: Joint Self-supervised Nighttime Image Enhancement and Depth Estimation</title>
      <link>https://paperswithcode.com/paper/steps-joint-self-supervised-nighttime-image</link>
      <description><![CDATA[By fitting a bridge-shaped curve to the illumination map distribution, both regions are suppressed and two tasks are bridged naturally.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/steps-joint-self-supervised-nighttime-image</guid>
    </item>
    <item>
      <title>Exploring the Benefits of Training Expert Language Models over Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/exploring-the-benefits-of-training-expert</link>
      <description><![CDATA[Recently, Language Models (LMs) instruction-tuned on multiple tasks, also known as multitask-prompted fine-tuning (MT), have shown the capability to generalize to unseen tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploring-the-benefits-of-training-expert</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>Learning the Beauty in Songs: Neural Singing Voice Beautifier</title>
      <link>https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</link>
      <description><![CDATA[Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-the-beauty-in-songs-neural-singing</guid>
    </item>
    <item>
      <title>InstructPix2Pix: Learning to Follow Image Editing Instructions</title>
      <link>https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</link>
      <description><![CDATA[We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instructpix2pix-learning-to-follow-image</guid>
    </item>
    <item>
      <title>SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</link>
      <description><![CDATA[We propose SmoothQuant, a training-free, accuracy-preserving, and general-purpose post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit activation (W8A8) quantization for LLMs that can be implemented efficiently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</guid>
    </item>
    <item>
      <title>DAMO-YOLO : A Report on Real-Time Object Detection Design</title>
      <link>https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</link>
      <description><![CDATA[In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/damo-yolo-a-report-on-real-time-object</guid>
    </item>
    <item>
      <title>TR3D: Towards Real-Time Indoor 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/tr3d-towards-real-time-indoor-3d-object</link>
      <description><![CDATA[Our model with early feature fusion, which we refer to as TR3D+FF, outperforms existing 3D object detection approaches on the SUN RGB-D dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tr3d-towards-real-time-indoor-3d-object</guid>
    </item>
  </channel>
</rss>
