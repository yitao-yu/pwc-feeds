<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 22 Mar 2024 09:13:41 +0000</lastBuildDate>
    <item>
      <title>Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets</title>
      <link>https://paperswithcode.com/paper/grokking-generalization-beyond-overfitting-on</link>
      <description><![CDATA[In this paper we propose to study generalization of neural networks on small algorithmically generated datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grokking-generalization-beyond-overfitting-on</guid>
    </item>
    <item>
      <title>LLM4Decompile: Decompiling Binary Code with Large Language Models</title>
      <link>https://paperswithcode.com/paper/llm4decompile-decompiling-binary-code-with</link>
      <description><![CDATA[Therefore, we release the first open-access decompilation LLMs ranging from 1B to 33B pre-trained on 4 billion tokens of C source code and the corresponding assembly code.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm4decompile-decompiling-binary-code-with</guid>
    </item>
    <item>
      <title>FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation</title>
      <link>https://paperswithcode.com/paper/fresco-spatial-temporal-correspondence-for</link>
      <description><![CDATA[In this paper, we introduce FRESCO, intra-frame correspondence alongside inter-frame correspondence to establish a more robust spatial-temporal constraint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fresco-spatial-temporal-correspondence-for</guid>
    </item>
    <item>
      <title>Evolutionary Optimization of Model Merging Recipes</title>
      <link>https://paperswithcode.com/paper/evolutionary-optimization-of-model-merging</link>
      <description><![CDATA[Surprisingly, our Japanese Math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not being explicitly trained for such tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evolutionary-optimization-of-model-merging</guid>
    </item>
    <item>
      <title>Chronos: Learning the Language of Time Series</title>
      <link>https://paperswithcode.com/paper/chronos-learning-the-language-of-time-series</link>
      <description><![CDATA[We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chronos-learning-the-language-of-time-series</guid>
    </item>
    <item>
      <title>Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models</title>
      <link>https://paperswithcode.com/paper/agent-flan-designing-data-and-methods-of</link>
      <description><![CDATA[Open-sourced Large Language Models (LLMs) have achieved great success in various NLP tasks, however, they are still far inferior to API-based models when acting as agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agent-flan-designing-data-and-methods-of</guid>
    </item>
    <item>
      <title>One-Step Image Translation with Text-to-Image Models</title>
      <link>https://paperswithcode.com/paper/one-step-image-translation-with-text-to-image</link>
      <description><![CDATA[In this work, we address two limitations of existing conditional diffusion models: their slow inference speed due to the iterative denoising process and their reliance on paired data for model fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-step-image-translation-with-text-to-image</guid>
    </item>
    <item>
      <title>FeatUp: A Model-Agnostic Framework for Features at Any Resolution</title>
      <link>https://paperswithcode.com/paper/featup-a-model-agnostic-framework-for</link>
      <description><![CDATA[Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/featup-a-model-agnostic-framework-for</guid>
    </item>
    <item>
      <title>OMG: Occlusion-friendly Personalized Multi-concept Generation in Diffusion Models</title>
      <link>https://paperswithcode.com/paper/omg-occlusion-friendly-personalized-multi</link>
      <description><![CDATA[We also observe that the initiation denoising timestep for noise blending is the key to identity preservation and layout.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omg-occlusion-friendly-personalized-multi</guid>
    </item>
    <item>
      <title>Mora: Enabling Generalist Video Generation via A Multi-Agent Framework</title>
      <link>https://paperswithcode.com/paper/mora-enabling-generalist-video-generation-via</link>
      <description><![CDATA[Sora is the first large-scale generalist video generation model that garnered significant attention across society.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mora-enabling-generalist-video-generation-via</guid>
    </item>
    <item>
      <title>APISR: Anime Production Inspired Real-World Anime Super-Resolution</title>
      <link>https://paperswithcode.com/paper/apisr-anime-production-inspired-real-world</link>
      <description><![CDATA[In addition, we identify two anime-specific challenges of distorted and faint hand-drawn lines and unwanted color artifacts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/apisr-anime-production-inspired-real-world</guid>
    </item>
    <item>
      <title>Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts</title>
      <link>https://paperswithcode.com/paper/follow-your-click-open-domain-regional-image</link>
      <description><![CDATA[Despite recent advances in image-to-video generation, better controllability and local animation are less explored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/follow-your-click-open-domain-regional-image</guid>
    </item>
    <item>
      <title>LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images</title>
      <link>https://paperswithcode.com/paper/llava-uhd-an-lmm-perceiving-any-aspect-ratio</link>
      <description><![CDATA[To address the challenges, we present LLaVA-UHD, a large multimodal model that can efficiently perceive images in any aspect ratio and high resolution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llava-uhd-an-lmm-perceiving-any-aspect-ratio</guid>
    </item>
    <item>
      <title>Less is More: Removing Text-regions Improves CLIP Training Efficiency and Robustness</title>
      <link>https://paperswithcode.com/paper/less-is-more-removing-text-regions-improves</link>
      <description><![CDATA[In this paper, we discuss two effective approaches to improve the efficiency and robustness of CLIP training: (1) augmenting the training dataset while maintaining the same number of optimization steps, and (2) filtering out samples that contain text regions in the image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-is-more-removing-text-regions-improves</guid>
    </item>
    <item>
      <title>StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control</title>
      <link>https://paperswithcode.com/paper/streammultidiffusion-real-time-interactive</link>
      <description><![CDATA[The enormous success of diffusion models in text-to-image synthesis has made them promising candidates for the next generation of end-user applications for image generation and editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streammultidiffusion-real-time-interactive</guid>
    </item>
    <item>
      <title>pyvene: A Library for Understanding and Improving PyTorch Models via Interventions</title>
      <link>https://paperswithcode.com/paper/pyvene-a-library-for-understanding-and</link>
      <description><![CDATA[Interventions on model-internal states are fundamental operations in many areas of AI, including model editing, steering, robustness, and interpretability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pyvene-a-library-for-understanding-and</guid>
    </item>
    <item>
      <title>RewardBench: Evaluating Reward Models for Language Modeling</title>
      <link>https://paperswithcode.com/paper/rewardbench-evaluating-reward-models-for</link>
      <description><![CDATA[In this paper, we present RewardBench, a benchmark dataset and code-base for evaluation, to enhance scientific understanding of reward models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rewardbench-evaluating-reward-models-for</guid>
    </item>
    <item>
      <title>Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small</title>
      <link>https://paperswithcode.com/paper/interpretability-in-the-wild-a-circuit-for</link>
      <description><![CDATA[Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpretability-in-the-wild-a-circuit-for</guid>
    </item>
    <item>
      <title>GSPMD: General and Scalable Parallelization for ML Computation Graphs</title>
      <link>https://paperswithcode.com/paper/gspmd-general-and-scalable-parallelization</link>
      <description><![CDATA[We present GSPMD, an automatic, compiler-based parallelization system for common machine learning computations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gspmd-general-and-scalable-parallelization</guid>
    </item>
    <item>
      <title>DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors</title>
      <link>https://paperswithcode.com/paper/dynamicrafter-animating-open-domain-images</link>
      <description><![CDATA[Animating a still image offers an engaging visual experience.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamicrafter-animating-open-domain-images</guid>
    </item>
  </channel>
</rss>
