<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 10 Sep 2023 09:10:25 +0000</lastBuildDate>
    <item>
      <title>Communicative Agents for Software Development</title>
      <link>https://paperswithcode.com/paper/communicative-agents-for-software-development</link>
      <description><![CDATA[At the core of this paradigm lies ChatDev, a virtual chat-powered software development company that mirrors the established waterfall model, meticulously dividing the development process into four distinct chronological stages: designing, coding, testing, and documenting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/communicative-agents-for-software-development</guid>
    </item>
    <item>
      <title>DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior</title>
      <link>https://paperswithcode.com/paper/diffbir-towards-blind-image-restoration-with</link>
      <description><![CDATA[We present DiffBIR, which leverages pretrained text-to-image diffusion models for blind image restoration problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffbir-towards-blind-image-restoration-with</guid>
    </item>
    <item>
      <title>Nougat: Neural Optical Understanding for Academic Documents</title>
      <link>https://paperswithcode.com/paper/nougat-neural-optical-understanding-for</link>
      <description><![CDATA[Scientific knowledge is predominantly stored in books and scientific journals, often in the form of PDFs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nougat-neural-optical-understanding-for</guid>
    </item>
    <item>
      <title>Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP</title>
      <link>https://paperswithcode.com/paper/demonstrate-search-predict-composing</link>
      <description><![CDATA[Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demonstrate-search-predict-composing</guid>
    </item>
    <item>
      <title>3D Gaussian Splatting for Real-Time Radiance Field Rendering</title>
      <link>https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</link>
      <description><![CDATA[Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</guid>
    </item>
    <item>
      <title>Extending Context Window of Large Language Models via Positional Interpolation</title>
      <link>https://paperswithcode.com/paper/extending-context-window-of-large-language</link>
      <description><![CDATA[We present Position Interpolation (PI) that extends the context window sizes of RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal fine-tuning (within 1000 steps), while demonstrating strong empirical results on various tasks that require long context, including passkey retrieval, language modeling, and long document summarization from LLaMA 7B to 65B.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extending-context-window-of-large-language</guid>
    </item>
    <item>
      <title>All-In-One Metrical And Functional Structure Analysis With Neighborhood Attentions on Demixed Audio</title>
      <link>https://paperswithcode.com/paper/all-in-one-metrical-and-functional-structure</link>
      <description><![CDATA[Music is characterized by complex hierarchical structures.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/all-in-one-metrical-and-functional-structure</guid>
    </item>
    <item>
      <title>Point-Bind &amp; Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following</title>
      <link>https://paperswithcode.com/paper/point-bind-point-llm-aligning-point-cloud</link>
      <description><![CDATA[We introduce Point-Bind, a 3D multi-modality model aligning point clouds with 2D image, language, audio, and video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/point-bind-point-llm-aligning-point-cloud</guid>
    </item>
    <item>
      <title>Prompt2Model: Generating Deployable Models from Natural Language Instructions</title>
      <link>https://paperswithcode.com/paper/prompt2model-generating-deployable-models</link>
      <description><![CDATA[In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt2model-generating-deployable-models</guid>
    </item>
    <item>
      <title>ResFields: Residual Neural Fields for Spatiotemporal Signals</title>
      <link>https://paperswithcode.com/paper/resfields-residual-neural-fields-for-1</link>
      <description><![CDATA[Neural fields, a category of neural networks trained to represent high-frequency signals, have gained significant attention in recent years due to their impressive performance in modeling complex 3D data, especially large neural signed distance (SDFs) or radiance fields (NeRFs) via a single multi-layer perceptron (MLP).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/resfields-residual-neural-fields-for-1</guid>
    </item>
    <item>
      <title>Cognitive Architectures for Language Agents</title>
      <link>https://paperswithcode.com/paper/cognitive-architectures-for-language-agents</link>
      <description><![CDATA[Recent efforts have incorporated large language models (LLMs) with external resources (e. g., the Internet) or internal control flows (e. g., prompt chaining) for tasks requiring grounding or reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cognitive-architectures-for-language-agents</guid>
    </item>
    <item>
      <title>SAM-Med2D</title>
      <link>https://paperswithcode.com/paper/sam-med2d</link>
      <description><![CDATA[To bridge this gap, we introduce SAM-Med2D, the most comprehensive studies on applying SAM to medical 2D images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sam-med2d</guid>
    </item>
    <item>
      <title>CoTracker: It is Better to Track Together</title>
      <link>https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</link>
      <description><![CDATA[In this paper, we thus propose CoTracker, an architecture that jointly tracks multiple points throughout an entire video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</guid>
    </item>
    <item>
      <title>CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X</title>
      <link>https://paperswithcode.com/paper/codegeex-a-pre-trained-model-for-code</link>
      <description><![CDATA[Large pre-trained code generation models, such as OpenAI Codex, can generate syntax- and function-correct code, making the coding of programmers more productive and our pursuit of artificial general intelligence closer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codegeex-a-pre-trained-model-for-code</guid>
    </item>
    <item>
      <title>YaRN: Efficient Context Window Extension of Large Language Models</title>
      <link>https://paperswithcode.com/paper/yarn-efficient-context-window-extension-of</link>
      <description><![CDATA[Rotary Position Embeddings (RoPE) have been shown to effectively encode positional information in transformer-based language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yarn-efficient-context-window-extension-of</guid>
    </item>
    <item>
      <title>GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models</title>
      <link>https://paperswithcode.com/paper/gpt-investar-enhancing-stock-investment</link>
      <description><![CDATA[This paper aims to simplify the process of assessing Annual Reports of all the firms by leveraging the capabilities of Large Language Models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-investar-enhancing-stock-investment</guid>
    </item>
    <item>
      <title>Doppelgangers: Learning to Disambiguate Images of Similar Structures</title>
      <link>https://paperswithcode.com/paper/doppelgangers-learning-to-disambiguate-images</link>
      <description><![CDATA[Our evaluation shows that our method can distinguish illusory matches in difficult cases, and can be integrated into SfM pipelines to produce correct, disambiguated 3D reconstructions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/doppelgangers-learning-to-disambiguate-images</guid>
    </item>
    <item>
      <title>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</title>
      <link>https://paperswithcode.com/paper/direct-preference-optimization-your-language</link>
      <description><![CDATA[However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/direct-preference-optimization-your-language</guid>
    </item>
    <item>
      <title>CoDeF: Content Deformation Fields for Temporally Consistent Video Processing</title>
      <link>https://paperswithcode.com/paper/codef-content-deformation-fields-for</link>
      <description><![CDATA[We present the content deformation field CoDeF as a new type of video representation, which consists of a canonical content field aggregating the static contents in the entire video and a temporal deformation field recording the transformations from the canonical image (i. e., rendered from the canonical content field) to each individual frame along the time axis. Given a target video, these two fields are jointly optimized to reconstruct it through a carefully tailored rendering pipeline. We advisedly introduce some regularizations into the optimization process, urging the canonical content field to inherit semantics (e. g., the object shape) from the video. With such a design, CoDeF naturally supports lifting image algorithms for video processing, in the sense that one can apply an image algorithm to the canonical image and effortlessly propagate the outcomes to the entire video with the aid of the temporal deformation field. We experimentally show that CoDeF is able to lift image-to-image translation to video-to-video translation and lift keypoint detection to keypoint tracking without any training. More importantly, thanks to our lifting strategy that deploys the algorithms on only one image, we achieve superior cross-frame consistency in processed videos compared to existing video-to-video translation approaches, and even manage to track non-rigid objects like water and smog. Project page can be found at https://qiuyu96. github. io/CoDeF/.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codef-content-deformation-fields-for</guid>
    </item>
    <item>
      <title>Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models</title>
      <link>https://paperswithcode.com/paper/plan-and-solve-prompting-improving-zero-shot</link>
      <description><![CDATA[To address the calculation errors and improve the quality of generated reasoning steps, we extend PS prompting with more detailed instructions and derive PS+ prompting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/plan-and-solve-prompting-improving-zero-shot</guid>
    </item>
  </channel>
</rss>
