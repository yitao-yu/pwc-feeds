<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 25 Oct 2022 09:29:19 +0000</lastBuildDate>
    <item>
      <title>TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second</title>
      <link>https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</link>
      <description><![CDATA[We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</guid>
    </item>
    <item>
      <title>Token Merging: Your ViT But Faster</title>
      <link>https://paperswithcode.com/paper/token-merging-your-vit-but-faster</link>
      <description><![CDATA[Off-the-shelf, ToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518 models on images and 2. 2x the throughput of ViT-L on video with only a 0. 2-0. 3% accuracy drop in each case.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/token-merging-your-vit-but-faster</guid>
    </item>
    <item>
      <title>Prompt-to-Prompt Image Editing with Cross Attention Control</title>
      <link>https://paperswithcode.com/paper/prompt-to-prompt-image-editing-with-cross</link>
      <description><![CDATA[Editing is challenging for these generative models, since an innate property of an editing technique is to preserve most of the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-to-prompt-image-editing-with-cross</guid>
    </item>
    <item>
      <title>Musika! Fast Infinite Waveform Music Generation</title>
      <link>https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</link>
      <description><![CDATA[We release the source code and pretrained autoencoder weights at github. com/marcoppasini/musika, such that a GAN can be trained on a new music domain with a single GPU in a matter of hours.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</guid>
    </item>
    <item>
      <title>Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera</title>
      <link>https://paperswithcode.com/paper/neural-surface-reconstruction-of-dynamic</link>
      <description><![CDATA[We propose Neural-DynamicReconstruction (NDR), a template-free method to recover high-fidelity geometry and motions of a dynamic scene from a monocular RGB-D camera.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-surface-reconstruction-of-dynamic</guid>
    </item>
    <item>
      <title>DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/diffuseq-sequence-to-sequence-text-generation</link>
      <description><![CDATA[Recently, diffusion models have emerged as a new paradigm for generative models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffuseq-sequence-to-sequence-text-generation</guid>
    </item>
    <item>
      <title>DreamFusion: Text-to-3D using 2D Diffusion</title>
      <link>https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</link>
      <description><![CDATA[Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</guid>
    </item>
    <item>
      <title>Personalizing Text-to-Image Generation via Aesthetic Gradients</title>
      <link>https://paperswithcode.com/paper/personalizing-text-to-image-generation-via</link>
      <description><![CDATA[This work proposes aesthetic gradients, a method to personalize a CLIP-conditioned diffusion model by guiding the generative process towards custom aesthetics defined by the user from a set of images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalizing-text-to-image-generation-via</guid>
    </item>
    <item>
      <title>Learning to Discover and Detect Objects</title>
      <link>https://paperswithcode.com/paper/learning-to-discover-and-detect-objects</link>
      <description><![CDATA[To this end, we propose a two-stage object detection network Region-based NCDL (RNCDL), that uses a region proposal network to localize object candidates and is trained to classify each candidate, either as one of the known classes, seen in the source dataset, or one of the extended set of novel classes, with a long-tail distribution constraint on the class assignments, reflecting the natural frequency of classes in the real world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-discover-and-detect-objects</guid>
    </item>
    <item>
      <title>Deep Bidirectional Language-Knowledge Graph Pretraining</title>
      <link>https://paperswithcode.com/paper/deep-bidirectional-language-knowledge-graph</link>
      <description><![CDATA[Pretraining a language model (LM) on text has been shown to help various downstream NLP tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-bidirectional-language-knowledge-graph</guid>
    </item>
    <item>
      <title>Poisson Flow Generative Models</title>
      <link>https://paperswithcode.com/paper/poisson-flow-generative-models</link>
      <description><![CDATA[We interpret the data points as electrical charges on the $z=0$ hyperplane in a space augmented with an additional dimension $z$, generating a high-dimensional electric field (the gradient of the solution to Poisson equation).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poisson-flow-generative-models</guid>
    </item>
    <item>
      <title>Gaussian-Bernoulli RBMs Without Tears</title>
      <link>https://paperswithcode.com/paper/gaussian-bernoulli-rbms-without-tears</link>
      <description><![CDATA[We revisit the challenging problem of training Gaussian-Bernoulli restricted Boltzmann machines (GRBMs), introducing two innovations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaussian-bernoulli-rbms-without-tears</guid>
    </item>
    <item>
      <title>Scaling Instruction-Finetuned Language Models</title>
      <link>https://paperswithcode.com/paper/scaling-instruction-finetuned-language-models</link>
      <description><![CDATA[We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-instruction-finetuned-language-models</guid>
    </item>
    <item>
      <title>CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network</title>
      <link>https://paperswithcode.com/paper/clcnet-rethinking-of-ensemble-modeling-with</link>
      <description><![CDATA[Under the same computation requirement, the performance of the system can exceed any model that has identical structure with the model in the system, but different in size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/clcnet-rethinking-of-ensemble-modeling-with</guid>
    </item>
    <item>
      <title>High-Resolution Image Synthesis with Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</link>
      <description><![CDATA[By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</guid>
    </item>
    <item>
      <title>TOIST: Task Oriented Instance Segmentation Transformer with Noun-Pronoun Distillation</title>
      <link>https://paperswithcode.com/paper/toist-task-oriented-instance-segmentation</link>
      <description><![CDATA[As such, we study the challenging problem of task oriented detection, which aims to find objects that best afford an action indicated by verbs like sit comfortably on.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toist-task-oriented-instance-segmentation</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>Advances and Open Problems in Federated Learning</title>
      <link>https://paperswithcode.com/paper/advances-and-open-problems-in-federated</link>
      <description><![CDATA[FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advances-and-open-problems-in-federated</guid>
    </item>
    <item>
      <title>HyperDomainNet: Universal Domain Adaptation for Generative Adversarial Networks</title>
      <link>https://paperswithcode.com/paper/hyperdomainnet-universal-domain-adaptation</link>
      <description><![CDATA[We apply this parameterization to the state-of-art domain adaptation methods and show that it has almost the same expressiveness as the full parameter space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyperdomainnet-universal-domain-adaptation</guid>
    </item>
    <item>
      <title>Deep Neural Networks to Detect Weeds from Crops in Agricultural Environments in Real-Time: A Review</title>
      <link>https://paperswithcode.com/paper/deep-neural-networks-to-detect-weeds-from</link>
      <description><![CDATA[Machine vision has wide applications in agriculture, including the detection of weeds and pests in crops.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-neural-networks-to-detect-weeds-from</guid>
    </item>
  </channel>
</rss>
