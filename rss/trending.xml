<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 06 Feb 2025 09:16:06 +0000</lastBuildDate>
    <item>
      <title>s1: Simple test-time scaling</title>
      <link>https://paperswithcode.com/paper/s1-simple-test-time-scaling</link>
      <description><![CDATA[After supervised finetuning the Qwen2. 5-32B-Instruct language model on s1K and equipping it with budget forcing, our model s1-32B exceeds o1-preview on competition math questions by up to 27% (MATH and AIME24).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s1-simple-test-time-scaling</guid>
    </item>
    <item>
      <title>Flaming-hot Initiation with Regular Execution Sampling for Large Language Models</title>
      <link>https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</link>
      <description><![CDATA[Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</guid>
    </item>
    <item>
      <title>Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution</title>
      <link>https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</link>
      <description><![CDATA[We present the Qwen2-VL Series, an advanced upgrade of the previous Qwen-VL models that redefines the conventional predetermined-resolution approach in visual processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-vl-enhancing-vision-language-model-s</guid>
    </item>
    <item>
      <title>DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</link>
      <description><![CDATA[We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl2-mixture-of-experts-vision</guid>
    </item>
    <item>
      <title>Qwen2.5 Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-5-technical-report</link>
      <description><![CDATA[In addition, for hosted solutions, the proprietary models currently include two mixture-of-experts (MoE) variants: Qwen2. 5-Turbo and Qwen2. 5-Plus, both available from Alibaba Cloud Model Studio.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-5-technical-report</guid>
    </item>
    <item>
      <title>Qwen2 Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-technical-report</link>
      <description><![CDATA[This report introduces the Qwen2 series, the latest addition to our large language models and large multimodal models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-technical-report</guid>
    </item>
    <item>
      <title>DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence</title>
      <link>https://paperswithcode.com/paper/deepseek-coder-v2-breaking-the-barrier-of</link>
      <description><![CDATA[Through this continued pre-training, DeepSeek-Coder-V2 substantially enhances the coding and mathematical reasoning capabilities of DeepSeek-V2, while maintaining comparable performance in general language tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-coder-v2-breaking-the-barrier-of</guid>
    </item>
    <item>
      <title>IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems</title>
      <link>https://paperswithcode.com/paper/intellagent-a-multi-agent-framework-for</link>
      <description><![CDATA[IntellAgent represents a paradigm shift in evaluating conversational AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intellagent-a-multi-agent-framework-for</guid>
    </item>
    <item>
      <title>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</link>
      <description><![CDATA[We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-r1-incentivizing-reasoning</guid>
    </item>
    <item>
      <title>Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling</title>
      <link>https://paperswithcode.com/paper/janus-pro-unified-multimodal-understanding</link>
      <description><![CDATA[In this work, we introduce Janus-Pro, an advanced version of the previous work Janus.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/janus-pro-unified-multimodal-understanding</guid>
    </item>
    <item>
      <title>DeepSeek-V3 Technical Report</title>
      <link>https://paperswithcode.com/paper/deepseek-v3-technical-report</link>
      <description><![CDATA[We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-v3-technical-report</guid>
    </item>
    <item>
      <title>Qwen2.5-Coder Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-5-coder-technical-report</link>
      <description><![CDATA[In this report, we introduce the Qwen2. 5-Coder series, a significant upgrade from its predecessor, CodeQwen1. 5.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-5-coder-technical-report</guid>
    </item>
    <item>
      <title>DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence</title>
      <link>https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</link>
      <description><![CDATA[The rapid development of large language models has revolutionized code intelligence in software development.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-coder-when-the-large-language-model</guid>
    </item>
    <item>
      <title>DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</title>
      <link>https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</link>
      <description><![CDATA[Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</guid>
    </item>
    <item>
      <title>Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback</title>
      <link>https://paperswithcode.com/paper/align-anything-training-all-modality-models</link>
      <description><![CDATA[In this work, we make the first attempt to fine-tune all-modality models (i. e. input and output with any modality, also named any-to-any models) using human preference data across all modalities (including text, image, audio, and video), ensuring its behavior aligns with human intentions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/align-anything-training-all-modality-models</guid>
    </item>
    <item>
      <title>DeepSeek LLM: Scaling Open-Source Language Models with Longtermism</title>
      <link>https://paperswithcode.com/paper/deepseek-llm-scaling-open-source-language</link>
      <description><![CDATA[The rapid development of open-source large language models (LLMs) has been truly remarkable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-llm-scaling-open-source-language</guid>
    </item>
    <item>
      <title>RaySplats: Ray Tracing based Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/raysplats-ray-tracing-based-gaussian</link>
      <description><![CDATA[3D Gaussian Splatting (3DGS) is a process that enables the direct creation of 3D objects from 2D images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/raysplats-ray-tracing-based-gaussian</guid>
    </item>
    <item>
      <title>Tulu 3: Pushing Frontiers in Open Language Model Post-Training</title>
      <link>https://paperswithcode.com/paper/tulu-3-pushing-frontiers-in-open-language</link>
      <description><![CDATA[Language model post-training is applied to refine behaviors and unlock new skills across a wide range of recent language models, but open recipes for applying these techniques lag behind proprietary ones.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tulu-3-pushing-frontiers-in-open-language</guid>
    </item>
    <item>
      <title>LLM-AutoDiff: Auto-Differentiate Any LLM Workflow</title>
      <link>https://paperswithcode.com/paper/auto-differentiating-any-llm-workflow-a</link>
      <description><![CDATA[Large Language Models (LLMs) have reshaped natural language processing, powering applications from multi-hop retrieval and question answering to autonomous agent workflows.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/auto-differentiating-any-llm-workflow-a</guid>
    </item>
    <item>
      <title>Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation</title>
      <link>https://paperswithcode.com/paper/hunyuan3d-2-0-scaling-diffusion-models-for</link>
      <description><![CDATA[This system includes two foundation components: a large-scale shape generation model -- Hunyuan3D-DiT, and a large-scale texture synthesis model -- Hunyuan3D-Paint.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuan3d-2-0-scaling-diffusion-models-for</guid>
    </item>
  </channel>
</rss>
