<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 21 Mar 2023 09:12:48 +0000</lastBuildDate>
    <item>
      <title>GPT-4 Technical Report</title>
      <link>https://paperswithcode.com/paper/gpt-4-technical-report-1</link>
      <description><![CDATA[We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-4-technical-report-1</guid>
    </item>
    <item>
      <title>LLaMA: Open and Efficient Foundation Language Models</title>
      <link>https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</link>
      <description><![CDATA[We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</guid>
    </item>
    <item>
      <title>Deep symbolic regression for physics guided by units constraints: toward the automated discovery of physical laws</title>
      <link>https://paperswithcode.com/paper/deep-symbolic-regression-for-physics-guided</link>
      <description><![CDATA[Here we present $\Phi$-SO, a Physical Symbolic Optimization framework for recovering analytical symbolic expressions from physics data using deep reinforcement learning techniques by learning units constraints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-symbolic-regression-for-physics-guided</guid>
    </item>
    <item>
      <title>FateZero: Fusing Attentions for Zero-shot Text-based Video Editing</title>
      <link>https://paperswithcode.com/paper/fatezero-fusing-attentions-for-zero-shot-text</link>
      <description><![CDATA[We also have a better zero-shot shape-aware editing ability based on the text-to-video model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fatezero-fusing-attentions-for-zero-shot-text</guid>
    </item>
    <item>
      <title>Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models</title>
      <link>https://paperswithcode.com/paper/visual-chatgpt-talking-drawing-and-editing</link>
      <description><![CDATA[To this end, We build a system called \textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-chatgpt-talking-drawing-and-editing</guid>
    </item>
    <item>
      <title>DPE: Disentanglement of Pose and Expression for General Video Portrait Editing</title>
      <link>https://paperswithcode.com/paper/dpe-disentanglement-of-pose-and-expression</link>
      <description><![CDATA[In this paper, we introduce a novel self-supervised disentanglement framework to decouple pose and expression without 3DMMs and paired data, which consists of a motion editing module, a pose generator, and an expression generator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dpe-disentanglement-of-pose-and-expression</guid>
    </item>
    <item>
      <title>SurroundOcc: Multi-Camera 3D Occupancy Prediction for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/surroundocc-multi-camera-3d-occupancy</link>
      <description><![CDATA[Towards a more comprehensive perception of a 3D scene, in this paper, we propose a SurroundOcc method to predict the 3D occupancy with multi-camera images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surroundocc-multi-camera-3d-occupancy</guid>
    </item>
    <item>
      <title>One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale</title>
      <link>https://paperswithcode.com/paper/one-transformer-fits-all-distributions-in</link>
      <description><![CDATA[Inspired by the unified view, UniDiffuser learns all distributions simultaneously with a minimal modification to the original diffusion model -- perturbs data in all modalities instead of a single modality, inputs individual timesteps in different modalities, and predicts the noise of all modalities instead of a single modality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-transformer-fits-all-distributions-in</guid>
    </item>
    <item>
      <title>GLM-130B: An Open Bilingual Pre-trained Model</title>
      <link>https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</link>
      <description><![CDATA[We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</guid>
    </item>
    <item>
      <title>FreeNeRF: Improving Few-shot Neural Rendering with Free Frequency Regularization</title>
      <link>https://paperswithcode.com/paper/freenerf-improving-few-shot-neural-rendering</link>
      <description><![CDATA[One is to regularize the frequency range of NeRF's inputs, while the other is to penalize the near-camera density fields.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/freenerf-improving-few-shot-neural-rendering</guid>
    </item>
    <item>
      <title>DiffBEV: Conditional Diffusion Model for Bird's Eye View Perception</title>
      <link>https://paperswithcode.com/paper/diffbev-conditional-diffusion-model-for-bird</link>
      <description><![CDATA[Diffusion models naturally have the ability to denoise noisy samples to the ideal data, which motivates us to utilize the diffusion model to get a better BEV representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffbev-conditional-diffusion-model-for-bird</guid>
    </item>
    <item>
      <title>FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model</title>
      <link>https://paperswithcode.com/paper/freedom-training-free-energy-guided</link>
      <description><![CDATA[In this work, we propose a training-Free conditional Diffusion Model (FreeDoM) used for various conditions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/freedom-training-free-energy-guided</guid>
    </item>
    <item>
      <title>VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation</title>
      <link>https://paperswithcode.com/paper/decomposed-diffusion-models-for-high-quality</link>
      <description><![CDATA[A diffusion probabilistic model (DPM), which constructs a forward diffusion process by gradually adding noise to data points and learns the reverse denoising process to generate new samples, has been shown to handle complex data distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/decomposed-diffusion-models-for-high-quality</guid>
    </item>
    <item>
      <title>BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View Recognition via Perspective Supervision</title>
      <link>https://paperswithcode.com/paper/bevformer-v2-adapting-modern-image-backbones</link>
      <description><![CDATA[The proposed method is verified with a wide spectrum of traditional and modern image backbones and achieves new SoTA results on the large-scale nuScenes dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bevformer-v2-adapting-modern-image-backbones</guid>
    </item>
    <item>
      <title>ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions</title>
      <link>https://paperswithcode.com/paper/chatgpt-asks-blip-2-answers-automatic</link>
      <description><![CDATA[By keeping acquiring new visual information from BLIP-2's answers, ChatCaptioner is able to generate more enriched image descriptions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatgpt-asks-blip-2-answers-automatic</guid>
    </item>
    <item>
      <title>Effectively Modeling Time Series with Simple Discrete State Spaces</title>
      <link>https://paperswithcode.com/paper/effectively-modeling-time-series-with-simple</link>
      <description><![CDATA[For expressivity, we propose a new SSM parameterization based on the companion matrix -- a canonical representation for discrete-time processes -- which enables SpaceTime's SSM layers to learn desirable autoregressive processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effectively-modeling-time-series-with-simple</guid>
    </item>
    <item>
      <title>Eliciting Latent Predictions from Transformers with the Tuned Lens</title>
      <link>https://paperswithcode.com/paper/eliciting-latent-predictions-from</link>
      <description><![CDATA[We analyze transformers from the perspective of iterative inference, seeking to understand how model predictions are refined layer by layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eliciting-latent-predictions-from</guid>
    </item>
    <item>
      <title>Universal Instance Perception as Object Discovery and Retrieval</title>
      <link>https://paperswithcode.com/paper/universal-instance-perception-as-object</link>
      <description><![CDATA[All instance perception tasks aim at finding certain objects specified by some queries such as category names, language expressions, and target annotations, but this complete field has been split into multiple independent subtasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-instance-perception-as-object</guid>
    </item>
    <item>
      <title>Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis</title>
      <link>https://paperswithcode.com/paper/parameter-is-not-all-you-need-starting-from</link>
      <description><![CDATA[We present a Non-parametric Network for 3D point cloud analysis, Point-NN, which consists of purely non-learnable components: farthest point sampling (FPS), k-nearest neighbors (k-NN), and pooling operations, with trigonometric functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parameter-is-not-all-you-need-starting-from</guid>
    </item>
    <item>
      <title>LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</title>
      <link>https://paperswithcode.com/paper/llm-int8-8-bit-matrix-multiplication-for</link>
      <description><![CDATA[We develop a procedure for Int8 matrix multiplication for feed-forward and attention projection layers in transformers, which cut the memory needed for inference by half while retaining full precision performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-int8-8-bit-matrix-multiplication-for</guid>
    </item>
  </channel>
</rss>
