<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 31 Mar 2024 09:11:47 +0000</lastBuildDate>
    <item>
      <title>AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation</title>
      <link>https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</link>
      <description><![CDATA[In this study, we propose AniPortrait, a novel framework for generating high-quality animation driven by audio and a reference portrait image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</guid>
    </item>
    <item>
      <title>Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models</title>
      <link>https://paperswithcode.com/paper/mini-gemini-mining-the-potential-of-multi</link>
      <description><![CDATA[We try to narrow the gap by mining the potential of VLMs for better performance and any-to-any workflow from three aspects, i. e., high-resolution visual tokens, high-quality data, and VLM-guided generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mini-gemini-mining-the-potential-of-multi</guid>
    </item>
    <item>
      <title>Long-form factuality in large language models</title>
      <link>https://paperswithcode.com/paper/long-form-factuality-in-large-language-models</link>
      <description><![CDATA[Empirically, we demonstrate that LLM agents can achieve superhuman rating performance - on a set of ~16k individual facts, SAFE agrees with crowdsourced human annotators 72% of the time, and on a random subset of 100 disagreement cases, SAFE wins 76% of the time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/long-form-factuality-in-large-language-models</guid>
    </item>
    <item>
      <title>T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy</title>
      <link>https://paperswithcode.com/paper/t-rex2-towards-generic-object-detection-via</link>
      <description><![CDATA[Recognizing the complementary strengths and weaknesses of both text and visual prompts, we introduce T-Rex2 that synergizes both prompts within a single model through contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t-rex2-towards-generic-object-detection-via</guid>
    </item>
    <item>
      <title>AIOS: LLM Agent Operating System</title>
      <link>https://paperswithcode.com/paper/llm-agent-operating-system</link>
      <description><![CDATA[Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS) as the brain of the OS, enabling an operating system "with soul" -- an important step towards AGI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-agent-operating-system</guid>
    </item>
    <item>
      <title>VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild</title>
      <link>https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</link>
      <description><![CDATA[We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</guid>
    </item>
    <item>
      <title>Mora: Enabling Generalist Video Generation via A Multi-Agent Framework</title>
      <link>https://paperswithcode.com/paper/mora-enabling-generalist-video-generation-via</link>
      <description><![CDATA[Sora is the first large-scale generalist video generation model that garnered significant attention across society.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mora-enabling-generalist-video-generation-via</guid>
    </item>
    <item>
      <title>SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions</title>
      <link>https://paperswithcode.com/paper/sdxs-real-time-one-step-latent-diffusion</link>
      <description><![CDATA[Recent advancements in diffusion models have positioned them at the forefront of image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdxs-real-time-one-step-latent-diffusion</guid>
    </item>
    <item>
      <title>StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text</title>
      <link>https://paperswithcode.com/paper/streamingt2v-consistent-dynamic-and</link>
      <description><![CDATA[To overcome these limitations, we introduce StreamingT2V, an autoregressive approach for long video generation of 80, 240, 600, 1200 or more frames with smooth transitions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streamingt2v-consistent-dynamic-and</guid>
    </item>
    <item>
      <title>General Object Foundation Model for Images and Videos at Scale</title>
      <link>https://paperswithcode.com/paper/general-object-foundation-model-for-images</link>
      <description><![CDATA[We present GLEE in this work, an object-level foundation model for locating and identifying objects in images and videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/general-object-foundation-model-for-images</guid>
    </item>
    <item>
      <title>RSMamba: Remote Sensing Image Classification with State Space Model</title>
      <link>https://paperswithcode.com/paper/rsmamba-remote-sensing-image-classification</link>
      <description><![CDATA[Remote sensing image classification forms the foundation of various understanding tasks, serving a crucial function in remote sensing image interpretation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rsmamba-remote-sensing-image-classification</guid>
    </item>
    <item>
      <title>Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework</title>
      <link>https://paperswithcode.com/paper/make-your-anchor-a-diffusion-based-2d-avatar</link>
      <description><![CDATA[We adopt a two-stage training strategy for the diffusion model, effectively binding movements with specific appearances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/make-your-anchor-a-diffusion-based-2d-avatar</guid>
    </item>
    <item>
      <title>BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion</title>
      <link>https://paperswithcode.com/paper/brushnet-a-plug-and-play-image-inpainting</link>
      <description><![CDATA[Image inpainting, the process of restoring corrupted images, has seen significant advancements with the advent of diffusion models (DMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/brushnet-a-plug-and-play-image-inpainting</guid>
    </item>
    <item>
      <title>Long-CLIP: Unlocking the Long-Text Capability of CLIP</title>
      <link>https://paperswithcode.com/paper/long-clip-unlocking-the-long-text-capability</link>
      <description><![CDATA[Contrastive Language-Image Pre-training (CLIP) has been the cornerstone for zero-shot classification, text-image retrieval, and text-image generation by aligning image and text modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/long-clip-unlocking-the-long-text-capability</guid>
    </item>
    <item>
      <title>Evolutionary Optimization of Model Merging Recipes</title>
      <link>https://paperswithcode.com/paper/evolutionary-optimization-of-model-merging</link>
      <description><![CDATA[Surprisingly, our Japanese Math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not being explicitly trained for such tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evolutionary-optimization-of-model-merging</guid>
    </item>
    <item>
      <title>One-Step Image Translation with Text-to-Image Models</title>
      <link>https://paperswithcode.com/paper/one-step-image-translation-with-text-to-image</link>
      <description><![CDATA[In this work, we address two limitations of existing conditional diffusion models: their slow inference speed due to the iterative denoising process and their reliance on paired data for model fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-step-image-translation-with-text-to-image</guid>
    </item>
    <item>
      <title>FeatUp: A Model-Agnostic Framework for Features at Any Resolution</title>
      <link>https://paperswithcode.com/paper/featup-a-model-agnostic-framework-for</link>
      <description><![CDATA[Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/featup-a-model-agnostic-framework-for</guid>
    </item>
    <item>
      <title>MegaBlocks: Efficient Sparse Training with Mixture-of-Experts</title>
      <link>https://paperswithcode.com/paper/megablocks-efficient-sparse-training-with</link>
      <description><![CDATA[We present MegaBlocks, a system for efficient Mixture-of-Experts (MoE) training on GPUs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/megablocks-efficient-sparse-training-with</guid>
    </item>
    <item>
      <title>Logit Standardization in Knowledge Distillation</title>
      <link>https://paperswithcode.com/paper/logit-standardization-in-knowledge</link>
      <description><![CDATA[Knowledge distillation involves transferring soft labels from a teacher to a student using a shared temperature-based softmax function.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/logit-standardization-in-knowledge</guid>
    </item>
    <item>
      <title>LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression</title>
      <link>https://paperswithcode.com/paper/llmlingua-2-data-distillation-for-efficient</link>
      <description><![CDATA[The challenge is that information entropy may be a suboptimal compression metric: (i) it only leverages unidirectional context and may fail to capture all essential information needed for prompt compression; (ii) it is not aligned with the prompt compression objective.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llmlingua-2-data-distillation-for-efficient</guid>
    </item>
  </channel>
</rss>
