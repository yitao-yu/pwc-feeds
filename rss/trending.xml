<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 30 Mar 2025 09:15:21 +0000</lastBuildDate>
    <item>
      <title>VGGT: Visual Geometry Grounded Transformer</title>
      <link>https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</link>
      <description><![CDATA[We present VGGT, a feed-forward neural network that directly infers all key 3D attributes of a scene, including camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vggt-visual-geometry-grounded-transformer</guid>
    </item>
    <item>
      <title>InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity</title>
      <link>https://paperswithcode.com/paper/infiniteyou-flexible-photo-recrafting-while</link>
      <description><![CDATA[Achieving flexible and high-fidelity identity-preserved image generation remains formidable, particularly with advanced Diffusion Transformers (DiTs) like FLUX.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/infiniteyou-flexible-photo-recrafting-while</guid>
    </item>
    <item>
      <title>ImageNet Classification with Deep Convolutional Neural Networks</title>
      <link>https://paperswithcode.com/paper/imagenet-classification-with-deep</link>
      <description><![CDATA[We trained a large, deep convolutional neural network to classify the 1. 3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imagenet-classification-with-deep</guid>
    </item>
    <item>
      <title>KBLaM: Knowledge Base augmented Language Model</title>
      <link>https://paperswithcode.com/paper/kblam-knowledge-base-augmented-language-model</link>
      <description><![CDATA[In this paper, we propose Knowledge Base augmented Language Model (KBLaM), a new method for augmenting Large Language Models (LLMs) with external knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kblam-knowledge-base-augmented-language-model</guid>
    </item>
    <item>
      <title>Open Deep Search: Democratizing Search with Open-source Reasoning Agents</title>
      <link>https://paperswithcode.com/paper/open-deep-search-democratizing-search-with</link>
      <description><![CDATA[Open Search Tool is a novel web search tool that outperforms proprietary counterparts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-deep-search-democratizing-search-with</guid>
    </item>
    <item>
      <title>LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds</title>
      <link>https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</link>
      <description><![CDATA[Animatable 3D human reconstruction from a single image is a challenging problem due to the ambiguity in decoupling geometry, appearance, and deformation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lhm-large-animatable-human-reconstruction</guid>
    </item>
    <item>
      <title>Long-Context Autoregressive Video Modeling with Next-Frame Prediction</title>
      <link>https://paperswithcode.com/paper/long-context-autoregressive-video-modeling-1</link>
      <description><![CDATA[Existing RoPE lacks effective temporal decay for remote context and fails to extrapolate well to long video sequences.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/long-context-autoregressive-video-modeling-1</guid>
    </item>
    <item>
      <title>Fin-R1: A Large Language Model for Financial Reasoning through Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/fin-r1-a-large-language-model-for-financial</link>
      <description><![CDATA[Reasoning large language models are rapidly evolving across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fin-r1-a-large-language-model-for-financial</guid>
    </item>
    <item>
      <title>UniK3D: Universal Camera Monocular 3D Estimation</title>
      <link>https://paperswithcode.com/paper/unik3d-universal-camera-monocular-3d</link>
      <description><![CDATA[Monocular 3D estimation is crucial for visual perception.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unik3d-universal-camera-monocular-3d</guid>
    </item>
    <item>
      <title>Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens</title>
      <link>https://paperswithcode.com/paper/2503-01710</link>
      <description><![CDATA[Recent advancements in large language models (LLMs) have driven significant progress in zero-shot text-to-speech (TTS) synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2503-01710</guid>
    </item>
    <item>
      <title>Reinforcement Learning Enhanced LLMs: A Survey</title>
      <link>https://paperswithcode.com/paper/reinforcement-learning-enhanced-llms-a-survey</link>
      <description><![CDATA[This paper surveys research in the rapidly growing field of enhancing large language models (LLMs) with reinforcement learning (RL), a technique that enables LLMs to improve their performance by receiving feedback in the form of rewards based on the quality of their outputs, allowing them to generate more accurate, coherent, and contextually appropriate responses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reinforcement-learning-enhanced-llms-a-survey</guid>
    </item>
    <item>
      <title>CFG-Zero*: Improved Classifier-Free Guidance for Flow Matching Models</title>
      <link>https://paperswithcode.com/paper/cfg-zero-improved-classifier-free-guidance</link>
      <description><![CDATA[Classifier-Free Guidance (CFG) is a widely adopted technique in diffusion/flow models to improve image fidelity and controllability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cfg-zero-improved-classifier-free-guidance</guid>
    </item>
    <item>
      <title>IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System</title>
      <link>https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</link>
      <description><![CDATA[Recently, large language model (LLM) based text-to-speech (TTS) systems have gradually become the mainstream in the industry due to their high naturalness and powerful zero-shot voice cloning capabilities. Here, we introduce the IndexTTS system, which is mainly based on the XTTS and Tortoise model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</guid>
    </item>
    <item>
      <title>Cube: A Roblox View of 3D Intelligence</title>
      <link>https://paperswithcode.com/paper/cube-a-roblox-view-of-3d-intelligence</link>
      <description><![CDATA[We show how our tokenization scheme can be used in applications for text-to-shape generation, shape-to-text generation and text-to-scene generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cube-a-roblox-view-of-3d-intelligence</guid>
    </item>
    <item>
      <title>Zep: A Temporal Knowledge Graph Architecture for Agent Memory</title>
      <link>https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</link>
      <description><![CDATA[We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</guid>
    </item>
    <item>
      <title>UI-TARS: Pioneering Automated GUI Interaction with Native Agents</title>
      <link>https://paperswithcode.com/paper/ui-tars-pioneering-automated-gui-interaction</link>
      <description><![CDATA[This paper introduces UI-TARS, a native GUI agent model that solely perceives the screenshots as input and performs human-like interactions (e. g., keyboard and mouse operations).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ui-tars-pioneering-automated-gui-interaction</guid>
    </item>
    <item>
      <title>Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/rankify-a-comprehensive-python-toolkit-for</link>
      <description><![CDATA[Retrieval, re-ranking, and retrieval-augmented generation (RAG) are critical components of modern applications in information retrieval, question answering, or knowledge-based text generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rankify-a-comprehensive-python-toolkit-for</guid>
    </item>
    <item>
      <title>Multimodal Chain-of-Thought Reasoning: A Comprehensive Survey</title>
      <link>https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-a</link>
      <description><![CDATA[By extending the advantage of chain-of-thought (CoT) reasoning in human-like step-by-step processes to multimodal contexts, multimodal CoT (MCoT) reasoning has recently garnered significant research attention, especially in the integration with multimodal large language models (MLLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-a</guid>
    </item>
    <item>
      <title>PhysTwin: Physics-Informed Reconstruction and Simulation of Deformable Objects from Videos</title>
      <link>https://paperswithcode.com/paper/phystwin-physics-informed-reconstruction-and</link>
      <description><![CDATA[Creating a physical digital twin of a real-world object has immense potential in robotics, content creation, and XR.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phystwin-physics-informed-reconstruction-and</guid>
    </item>
    <item>
      <title>Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning</title>
      <link>https://paperswithcode.com/paper/cosmos-reason1-from-physical-common-sense-to</link>
      <description><![CDATA[We begin by defining key capabilities for Physical AI reasoning, with a focus on physical common sense and embodied reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cosmos-reason1-from-physical-common-sense-to</guid>
    </item>
  </channel>
</rss>
