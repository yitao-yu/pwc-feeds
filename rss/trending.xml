<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 02 Jan 2023 21:06:19 +0000</lastBuildDate>
    <item>
      <title>Cramming: Training a Language Model on a Single GPU in One Day</title>
      <link>https://paperswithcode.com/paper/cramming-training-a-language-model-on-a</link>
      <description><![CDATA[Recent trends in language modeling have focused on increasing performance through scaling, and have resulted in an environment where training language models is out of reach for most researchers and practitioners.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cramming-training-a-language-model-on-a</guid>
    </item>
    <item>
      <title>Point-E: A System for Generating 3D Point Clouds from Complex Prompts</title>
      <link>https://paperswithcode.com/paper/point-e-a-system-for-generating-3d-point</link>
      <description><![CDATA[This is in stark contrast to state-of-the-art generative image models, which produce samples in a number of seconds or minutes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/point-e-a-system-for-generating-3d-point</guid>
    </item>
    <item>
      <title>Pop2Piano : Pop Audio-based Piano Cover Generation</title>
      <link>https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</link>
      <description><![CDATA[The piano cover of pop music is widely enjoyed by people.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal</title>
      <link>https://paperswithcode.com/paper/reasoning-over-different-types-of-knowledge</link>
      <description><![CDATA[The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reasoning-over-different-types-of-knowledge</guid>
    </item>
    <item>
      <title>TextBox 2.0: A Text Generation Library with Pre-trained Language Models</title>
      <link>https://paperswithcode.com/paper/textbox-2-0-a-text-generation-library-with</link>
      <description><![CDATA[To facilitate research on text generation, this paper presents a comprehensive and unified library, TextBox 2. 0, focusing on the use of pre-trained language models (PLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/textbox-2-0-a-text-generation-library-with</guid>
    </item>
    <item>
      <title>MetaFormer Baselines for Vision</title>
      <link>https://paperswithcode.com/paper/metaformer-baselines-for-vision</link>
      <description><![CDATA[By simply applying depthwise separable convolutions as token mixer in the bottom stages and vanilla self-attention in the top stages, the resulting model CAFormer sets a new record on ImageNet-1K: it achieves an accuracy of 85. 5% at 224x224 resolution, under normal supervised training without external data or distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metaformer-baselines-for-vision</guid>
    </item>
    <item>
      <title>The Forward-Forward Algorithm: Some Preliminary Investigations</title>
      <link>https://paperswithcode.com/paper/the-forward-forward-algorithm-some-1</link>
      <description><![CDATA[The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth further investigation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-forward-forward-algorithm-some-1</guid>
    </item>
    <item>
      <title>OpenFE: Automated Feature Generation beyond Expert-level Performance</title>
      <link>https://paperswithcode.com/paper/openfe-automated-feature-generation-beyond</link>
      <description><![CDATA[The major challenge in automated feature generation is to efficiently and accurately identify useful features from a vast pool of candidate features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openfe-automated-feature-generation-beyond</guid>
    </item>
    <item>
      <title>CausalEGM: a general causal inference framework by encoding generative modeling</title>
      <link>https://paperswithcode.com/paper/causalegm-a-general-causal-inference</link>
      <description><![CDATA[In this article, we develop a general framework $\textit{CausalEGM}$ for estimating causal effects by encoding generative modeling, which can be applied in both binary and continuous treatment settings.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/causalegm-a-general-causal-inference</guid>
    </item>
    <item>
      <title>Scalable Diffusion Models with Transformers</title>
      <link>https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</link>
      <description><![CDATA[We explore a new class of diffusion models based on the transformer architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers</guid>
    </item>
    <item>
      <title>Differentiable Predictive Control with Safety Guarantees: A Control Barrier Function Approach</title>
      <link>https://paperswithcode.com/paper/differentiable-predictive-control-with-safety</link>
      <description><![CDATA[We develop a novel form of differentiable predictive control (DPC) with safety and robustness guarantees based on control barrier functions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/differentiable-predictive-control-with-safety</guid>
    </item>
    <item>
      <title>OPT: Open Pre-trained Transformer Language Models</title>
      <link>https://paperswithcode.com/paper/opt-open-pre-trained-transformer-language</link>
      <description><![CDATA[Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/opt-open-pre-trained-transformer-language</guid>
    </item>
    <item>
      <title>A Generalization of ViT/MLP-Mixer to Graphs</title>
      <link>https://paperswithcode.com/paper/a-generalization-of-vit-mlp-mixer-to-graphs</link>
      <description><![CDATA[Graph Neural Networks (GNNs) have shown great potential in the field of graph representation learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-generalization-of-vit-mlp-mixer-to-graphs</guid>
    </item>
    <item>
      <title>Noise-aware Learning from Web-crawled Image-Text Data for Image Captioning</title>
      <link>https://paperswithcode.com/paper/noise-aware-learning-from-web-crawled-image</link>
      <description><![CDATA[While the filtering strategy can effectively remove noisy data, however, it leads to a decrease in learnable knowledge and sometimes brings about a new problem of data deficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/noise-aware-learning-from-web-crawled-image</guid>
    </item>
    <item>
      <title>Generalized Decoding for Pixel, Image, and Language</title>
      <link>https://paperswithcode.com/paper/generalized-decoding-for-pixel-image-and</link>
      <description><![CDATA[We present X-Decoder, a generalized decoding model that can predict pixel-level segmentation and language tokens seamlessly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generalized-decoding-for-pixel-image-and</guid>
    </item>
    <item>
      <title>DAE-Former: Dual Attention-guided Efficient Transformer for Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/dae-former-dual-attention-guided-efficient</link>
      <description><![CDATA[Transformers have recently gained attention in the computer vision domain due to their ability to model long-range dependencies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dae-former-dual-attention-guided-efficient</guid>
    </item>
    <item>
      <title>Benchmarking and Analyzing Point Cloud Classification under Corruptions</title>
      <link>https://paperswithcode.com/paper/benchmarking-and-analyzing-point-cloud</link>
      <description><![CDATA[3D perception, especially point cloud classification, has achieved substantial progress.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-and-analyzing-point-cloud</guid>
    </item>
    <item>
      <title>Reversible Column Networks</title>
      <link>https://paperswithcode.com/paper/reversible-column-networks</link>
      <description><![CDATA[Such architectural scheme attributes RevCol very different behavior from conventional networks: during forward propagation, features in RevCol are learned to be gradually disentangled when passing through each column, whose total information is maintained rather than compressed or discarded as other network does.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reversible-column-networks</guid>
    </item>
    <item>
      <title>Improving language models by retrieving from trillions of tokens</title>
      <link>https://paperswithcode.com/paper/improving-language-models-by-retrieving-from</link>
      <description><![CDATA[We enhance auto-regressive language models by conditioning on document chunks retrieved from a large corpus, based on local similarity with preceding tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/improving-language-models-by-retrieving-from</guid>
    </item>
  </channel>
</rss>
