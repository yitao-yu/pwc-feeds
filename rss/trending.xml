<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 17 Mar 2024 09:10:47 +0000</lastBuildDate>
    <item>
      <title>Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small</title>
      <link>https://paperswithcode.com/paper/interpretability-in-the-wild-a-circuit-for</link>
      <description><![CDATA[Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpretability-in-the-wild-a-circuit-for</guid>
    </item>
    <item>
      <title>Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts</title>
      <link>https://paperswithcode.com/paper/follow-your-click-open-domain-regional-image</link>
      <description><![CDATA[Despite recent advances in image-to-video generation, better controllability and local animation are less explored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/follow-your-click-open-domain-regional-image</guid>
    </item>
    <item>
      <title>DeepSeek-VL: Towards Real-World Vision-Language Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl-towards-real-world-vision</link>
      <description><![CDATA[The DeepSeek-VL family (both 1. 3B and 7B models) showcases superior user experiences as a vision-language chatbot in real-world applications, achieving state-of-the-art or competitive performance across a wide range of visual-language benchmarks at the same model size while maintaining robust performance on language-centric benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl-towards-real-world-vision</guid>
    </item>
    <item>
      <title>StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control</title>
      <link>https://paperswithcode.com/paper/streammultidiffusion-real-time-interactive</link>
      <description><![CDATA[The enormous success of diffusion models in text-to-image synthesis has made them promising candidates for the next generation of end-user applications for image generation and editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/streammultidiffusion-real-time-interactive</guid>
    </item>
    <item>
      <title>GiT: Towards Generalist Vision Transformer through Universal Language Interface</title>
      <link>https://paperswithcode.com/paper/git-towards-generalist-vision-transformer</link>
      <description><![CDATA[Due to its simple design, this paradigm holds promise for narrowing the architectural gap between vision and language.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/git-towards-generalist-vision-transformer</guid>
    </item>
    <item>
      <title>Chronos: Learning the Language of Time Series</title>
      <link>https://paperswithcode.com/paper/chronos-learning-the-language-of-time-series</link>
      <description><![CDATA[We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chronos-learning-the-language-of-time-series</guid>
    </item>
    <item>
      <title>Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study</title>
      <link>https://paperswithcode.com/paper/towards-general-computer-control-a-multimodal</link>
      <description><![CDATA[Despite the success in specific tasks and scenarios, existing foundation agents, empowered by large models (LMs) and advanced tools, still cannot generalize to different scenarios, mainly due to dramatic differences in the observations and actions across scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-general-computer-control-a-multimodal</guid>
    </item>
    <item>
      <title>V3D: Video Diffusion Models are Effective 3D Generators</title>
      <link>https://paperswithcode.com/paper/v3d-video-diffusion-models-are-effective-3d</link>
      <description><![CDATA[To fully unleash the potential of video diffusion to perceive the 3D world, we further introduce geometrical consistency prior and extend the video diffusion model to a multi-view consistent 3D generator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/v3d-video-diffusion-models-are-effective-3d</guid>
    </item>
    <item>
      <title>DragAnything: Motion Control for Anything using Entity Representation</title>
      <link>https://paperswithcode.com/paper/draganything-motion-control-for-anything</link>
      <description><![CDATA[We introduce DragAnything, which utilizes a entity representation to achieve motion control for any object in controllable video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/draganything-motion-control-for-anything</guid>
    </item>
    <item>
      <title>Fast Inner-Product Algorithms and Architectures for Deep Neural Network Accelerators</title>
      <link>https://paperswithcode.com/paper/fast-inner-product-algorithms-and</link>
      <description><![CDATA[We introduce a new algorithm called the Free-pipeline Fast Inner Product (FFIP) and its hardware architecture that improve an under-explored fast inner-product algorithm (FIP) proposed by Winograd in 1968.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-inner-product-algorithms-and</guid>
    </item>
    <item>
      <title>MoAI: Mixture of All Intelligence for Large Language and Vision Models</title>
      <link>https://paperswithcode.com/paper/moai-mixture-of-all-intelligence-for-large</link>
      <description><![CDATA[Therefore, we present a new LLVM, Mixture of All Intelligence (MoAI), which leverages auxiliary visual information obtained from the outputs of external segmentation, detection, SGG, and OCR models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moai-mixture-of-all-intelligence-for-large</guid>
    </item>
    <item>
      <title>Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/relaxing-accurate-initialization-constraint</link>
      <description><![CDATA[Through extensive analysis of SfM initialization in the frequency domain and analysis of a 1D regression task with multiple 1D Gaussians, we propose a novel optimization strategy dubbed RAIN-GS (Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting), that successfully trains 3D Gaussians from random point clouds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relaxing-accurate-initialization-constraint</guid>
    </item>
    <item>
      <title>Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding</title>
      <link>https://paperswithcode.com/paper/sequoia-scalable-robust-and-hardware-aware</link>
      <description><![CDATA[This paper introduces Sequoia, a scalable, robust, and hardware-aware algorithm for speculative decoding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sequoia-scalable-robust-and-hardware-aware</guid>
    </item>
    <item>
      <title>VideoMamba: State Space Model for Efficient Video Understanding</title>
      <link>https://paperswithcode.com/paper/videomamba-state-space-model-for-efficient</link>
      <description><![CDATA[Addressing the dual challenges of local redundancy and global dependencies in video understanding, this work innovatively adapts the Mamba to the video domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videomamba-state-space-model-for-efficient</guid>
    </item>
    <item>
      <title>GSPMD: General and Scalable Parallelization for ML Computation Graphs</title>
      <link>https://paperswithcode.com/paper/gspmd-general-and-scalable-parallelization</link>
      <description><![CDATA[We present GSPMD, an automatic, compiler-based parallelization system for common machine learning computations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gspmd-general-and-scalable-parallelization</guid>
    </item>
    <item>
      <title>Score-Guided Diffusion for 3D Human Recovery</title>
      <link>https://paperswithcode.com/paper/score-guided-diffusion-for-3d-human-recovery</link>
      <description><![CDATA[We present Score-Guided Human Mesh Recovery (ScoreHMR), an approach for solving inverse problems for 3D human pose and shape reconstruction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/score-guided-diffusion-for-3d-human-recovery</guid>
    </item>
    <item>
      <title>OOTDiffusion: Outfitting Fusion based Latent Diffusion for Controllable Virtual Try-on</title>
      <link>https://paperswithcode.com/paper/ootdiffusion-outfitting-fusion-based-latent</link>
      <description><![CDATA[We present OOTDiffusion, a novel network architecture for realistic and controllable image-based virtual try-on (VTON).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ootdiffusion-outfitting-fusion-based-latent</guid>
    </item>
    <item>
      <title>TripoSR: Fast 3D Object Reconstruction from a Single Image</title>
      <link>https://paperswithcode.com/paper/triposr-fast-3d-object-reconstruction-from-a</link>
      <description><![CDATA[This technical report introduces TripoSR, a 3D reconstruction model leveraging transformer architecture for fast feed-forward 3D generation, producing 3D mesh from a single image in under 0. 5 seconds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triposr-fast-3d-object-reconstruction-from-a</guid>
    </item>
    <item>
      <title>SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection</title>
      <link>https://paperswithcode.com/paper/sardet-100k-towards-open-source-benchmark-and</link>
      <description><![CDATA[To the best of our knowledge, SARDet-100K is the first COCO-level large-scale multi-class SAR object detection dataset ever created.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sardet-100k-towards-open-source-benchmark-and</guid>
    </item>
    <item>
      <title>Scattered Mixture-of-Experts Implementation</title>
      <link>https://paperswithcode.com/paper/scattered-mixture-of-experts-implementation</link>
      <description><![CDATA[We present ScatterMoE, an implementation of Sparse Mixture-of-Experts (SMoE) on GPUs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scattered-mixture-of-experts-implementation</guid>
    </item>
  </channel>
</rss>
