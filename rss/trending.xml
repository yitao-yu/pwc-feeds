<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 22 Aug 2024 21:09:21 +0000</lastBuildDate>
    <item>
      <title>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</title>
      <link>https://paperswithcode.com/paper/the-ai-scientist-towards-fully-automated-open</link>
      <description><![CDATA[This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-ai-scientist-towards-fully-automated-open</guid>
    </item>
    <item>
      <title>Zero-Shot Surgical Tool Segmentation in Monocular Video Using Segment Anything Model 2</title>
      <link>https://paperswithcode.com/paper/2408-01648</link>
      <description><![CDATA[The Segment Anything Model 2 (SAM 2) is the latest generation foundation model for image and video segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2408-01648</guid>
    </item>
    <item>
      <title>LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs</title>
      <link>https://paperswithcode.com/paper/longwriter-unleashing-10000-word-generation</link>
      <description><![CDATA[By incorporating this dataset into model training, we successfully scale the output length of existing models to over 10, 000 words while maintaining output quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longwriter-unleashing-10000-word-generation</guid>
    </item>
    <item>
      <title>DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search</title>
      <link>https://paperswithcode.com/paper/deepseek-prover-v1-5-harnessing-proof</link>
      <description><![CDATA[We introduce DeepSeek-Prover-V1. 5, an open-source language model designed for theorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both training and inference processes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-prover-v1-5-harnessing-proof</guid>
    </item>
    <item>
      <title>Bilateral Reference for High-Resolution Dichotomous Image Segmentation</title>
      <link>https://paperswithcode.com/paper/bilateral-reference-for-high-resolution</link>
      <description><![CDATA[It comprises two essential components: the localization module (LM) and the reconstruction module (RM) with our proposed bilateral reference (BiRef).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bilateral-reference-for-high-resolution</guid>
    </item>
    <item>
      <title>MixTex: Unambiguous Recognition Should Not Rely Solely on Real Data</title>
      <link>https://paperswithcode.com/paper/unambiguous-recognition-should-not-rely</link>
      <description><![CDATA[This paper introduces MixTex, an end-to-end LaTeX OCR model designed for low-bias multilingual recognition, along with its novel data collection method.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unambiguous-recognition-should-not-rely</guid>
    </item>
    <item>
      <title>ControlNeXt: Powerful and Efficient Control for Image and Video Generation</title>
      <link>https://paperswithcode.com/paper/controlnext-powerful-and-efficient-control</link>
      <description><![CDATA[In this paper, we propose ControlNeXt: a powerful and efficient method for controllable image and video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/controlnext-powerful-and-efficient-control</guid>
    </item>
    <item>
      <title>Text-Driven Image Editing via Learnable Regions</title>
      <link>https://paperswithcode.com/paper/text-driven-image-editing-via-learnable</link>
      <description><![CDATA[Language has emerged as a natural interface for image editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-driven-image-editing-via-learnable</guid>
    </item>
    <item>
      <title>LGRNet: Local-Global Reciprocal Network for Uterine Fibroid Segmentation in Ultrasound Videos</title>
      <link>https://paperswithcode.com/paper/lgrnet-local-global-reciprocal-network-for</link>
      <description><![CDATA[To this end, we collect and annotate the first ultrasound video dataset with 100 videos for uterine fibroid segmentation (UFUV).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lgrnet-local-global-reciprocal-network-for</guid>
    </item>
    <item>
      <title>OpenResearcher: Unleashing AI for Accelerated Scientific Research</title>
      <link>https://paperswithcode.com/paper/openresearcher-unleashing-ai-for-accelerated</link>
      <description><![CDATA[The rapid growth of scientific literature imposes significant challenges for researchers endeavoring to stay updated with the latest advancements in their fields and delve into new areas.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/openresearcher-unleashing-ai-for-accelerated</guid>
    </item>
    <item>
      <title>RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation</title>
      <link>https://paperswithcode.com/paper/2408-02545</link>
      <description><![CDATA[We introduce RAG Foundry, an open-source framework for augmenting large language models for RAG use cases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/2408-02545</guid>
    </item>
    <item>
      <title>BMX: Entropy-weighted Similarity and Semantic-enhanced Lexical Search</title>
      <link>https://paperswithcode.com/paper/bmx-entropy-weighted-similarity-and-semantic</link>
      <description><![CDATA[BM25, a widely-used lexical search algorithm, remains crucial in information retrieval despite the rise of pre-trained and large language models (PLMs/LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bmx-entropy-weighted-similarity-and-semantic</guid>
    </item>
    <item>
      <title>T-MAC: CPU Renaissance via Table Lookup for Low-Bit LLM Deployment on Edge</title>
      <link>https://paperswithcode.com/paper/t-mac-cpu-renaissance-via-table-lookup-for</link>
      <description><![CDATA[Weight quantization is crucial for reducing the memory footprint of LLMs on devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t-mac-cpu-renaissance-via-table-lookup-for</guid>
    </item>
    <item>
      <title>FruitNeRF: A Unified Neural Radiance Field based Fruit Counting Framework</title>
      <link>https://paperswithcode.com/paper/fruitnerf-a-unified-neural-radiance-field</link>
      <description><![CDATA[We introduce FruitNeRF, a unified novel fruit counting framework that leverages state-of-the-art view synthesis methods to count any fruit type directly in 3D.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fruitnerf-a-unified-neural-radiance-field</guid>
    </item>
    <item>
      <title>OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer</title>
      <link>https://paperswithcode.com/paper/omagent-a-multi-modal-agent-framework-for</link>
      <description><![CDATA[Recent advancements in Large Language Models (LLMs) have expanded their capabilities to multimodal contexts, including comprehensive video understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omagent-a-multi-modal-agent-framework-for</guid>
    </item>
    <item>
      <title>Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization</title>
      <link>https://paperswithcode.com/paper/accelerating-high-fidelity-waveform</link>
      <description><![CDATA[This paper introduces PeriodWave-Turbo, a high-fidelity and high-efficient waveform generation model via adversarial flow matching optimization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/accelerating-high-fidelity-waveform</guid>
    </item>
    <item>
      <title>MindSearch: Mimicking Human Minds Elicits Deep AI Searcher</title>
      <link>https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</link>
      <description><![CDATA[Inspired by the cognitive process when humans solve these problems, we introduce MindSearch to mimic the human minds in web information seeking and integration, which can be instantiated by a simple yet effective LLM-based multi-agent framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</guid>
    </item>
    <item>
      <title>Comprehensive Assessment of Jailbreak Attacks Against LLMs</title>
      <link>https://paperswithcode.com/paper/comprehensive-assessment-of-jailbreak-attacks</link>
      <description><![CDATA[Some jailbreak prompt datasets, available from the Internet, can also achieve high attack success rates on many LLMs, such as ChatGLM3, GPT-3. 5, and PaLM2.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/comprehensive-assessment-of-jailbreak-attacks</guid>
    </item>
    <item>
      <title>Compressing Context to Enhance Inference Efficiency of Large Language Models</title>
      <link>https://paperswithcode.com/paper/compressing-context-to-enhance-inference</link>
      <description><![CDATA[This paper proposes a method called Selective Context that enhances the inference efficiency of LLMs by identifying and pruning redundancy in the input context to make the input more compact.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/compressing-context-to-enhance-inference</guid>
    </item>
    <item>
      <title>Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective</title>
      <link>https://paperswithcode.com/paper/robust-neural-information-retrieval-an</link>
      <description><![CDATA[Recent advances in neural information retrieval (IR) models have significantly enhanced their effectiveness over various IR tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-neural-information-retrieval-an</guid>
    </item>
  </channel>
</rss>
