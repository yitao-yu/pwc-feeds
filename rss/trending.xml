<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 26 Nov 2022 09:12:41 +0000</lastBuildDate>
    <item>
      <title>TorchScale: Transformers at Scale</title>
      <link>https://paperswithcode.com/paper/torchscale-transformers-at-scale</link>
      <description><![CDATA[Large Transformers have achieved state-of-the-art performance across many tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchscale-transformers-at-scale</guid>
    </item>
    <item>
      <title>Human-level play in the game of Diplomacy by combining language models with strategic reasoning</title>
      <link>https://paperswithcode.com/paper/human-level-play-in-the-game-of-diplomacy-by</link>
      <description><![CDATA[Despite much progress in training AI systems to imitate human language, building agents that use language to communicate intentionally with humans in interactive environments remains a major challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/human-level-play-in-the-game-of-diplomacy-by</guid>
    </item>
    <item>
      <title>DiffusionDet: Diffusion Model for Object Detection</title>
      <link>https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</link>
      <description><![CDATA[In inference, the model refines a set of randomly generated boxes to the output results in a progressive way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</guid>
    </item>
    <item>
      <title>Paint by Example: Exemplar-based Image Editing with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/paint-by-example-exemplar-based-image-editing</link>
      <description><![CDATA[Language-guided image editing has achieved great success recently.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paint-by-example-exemplar-based-image-editing</guid>
    </item>
    <item>
      <title>AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities</title>
      <link>https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</link>
      <description><![CDATA[In this work, we present a conceptually simple and effective method to train a strong bilingual/multilingual multimodal representation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</guid>
    </item>
    <item>
      <title>SinDiffusion: Learning a Diffusion Model from a Single Natural Image</title>
      <link>https://paperswithcode.com/paper/sindiffusion-learning-a-diffusion-model-from</link>
      <description><![CDATA[We present SinDiffusion, leveraging denoising diffusion models to capture internal distribution of patches from a single natural image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sindiffusion-learning-a-diffusion-model-from</guid>
    </item>
    <item>
      <title>Galactica: A Large Language Model for Science</title>
      <link>https://paperswithcode.com/paper/galactica-a-large-language-model-for-science-1</link>
      <description><![CDATA[We believe these results demonstrate the potential for language models as a new interface for science.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/galactica-a-large-language-model-for-science-1</guid>
    </item>
    <item>
      <title>RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation</title>
      <link>https://paperswithcode.com/paper/renderdiffusion-image-diffusion-for-3d</link>
      <description><![CDATA[In this paper, we present RenderDiffusion as the first diffusion model for 3D generation and inference that can be trained using only monocular 2D supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/renderdiffusion-image-diffusion-for-3d</guid>
    </item>
    <item>
      <title>EVA: Exploring the Limits of Masked Visual Representation Learning at Scale</title>
      <link>https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</link>
      <description><![CDATA[We launch EVA, a vision-centric foundation model to explore the limits of visual representation at scale using only publicly accessible data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</guid>
    </item>
    <item>
      <title>Latent Video Diffusion Models for High-Fidelity Video Generation with Arbitrary Lengths</title>
      <link>https://paperswithcode.com/paper/latent-video-diffusion-models-for-high</link>
      <description><![CDATA[Diffusion models (DMs) are another class of deep generative models and have recently achieved remarkable performance on various image synthesis tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/latent-video-diffusion-models-for-high</guid>
    </item>
    <item>
      <title>Versatile Diffusion: Text, Images and Variations All in One Diffusion Model</title>
      <link>https://paperswithcode.com/paper/versatile-diffusion-text-images-and</link>
      <description><![CDATA[Through our experiments, we demonstrate that VD and its underlying framework have the following merits: a) VD handles all subtasks with competitive quality; b) VD initiates novel extensions and applications such as disentanglement of style and semantic, image-text dual-guided generation, etc.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/versatile-diffusion-text-images-and</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>Revisiting Image Pyramid Structure for High Resolution Salient Object Detection</title>
      <link>https://paperswithcode.com/paper/revisiting-image-pyramid-structure-for-high</link>
      <description><![CDATA[Salient object detection (SOD) has been in the spotlight recently, yet has been studied less for high-resolution (HR) images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-image-pyramid-structure-for-high</guid>
    </item>
    <item>
      <title>A Closer Look at Learned Optimization: Stability, Robustness, and Inductive Biases</title>
      <link>https://paperswithcode.com/paper/a-closer-look-at-learned-optimization</link>
      <description><![CDATA[We apply the resulting learned optimizer to a variety of neural network training tasks, where it outperforms the current state of the art learned optimizer -- at matched optimizer computational overhead -- with regard to optimization performance and meta-training speed, and is capable of generalization to tasks far different from those it was meta-trained on.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-closer-look-at-learned-optimization</guid>
    </item>
    <item>
      <title>ComMU: Dataset for Combinatorial Music Generation</title>
      <link>https://paperswithcode.com/paper/commu-dataset-for-combinatorial-music</link>
      <description><![CDATA[Commercial adoption of automatic music composition requires the capability of generating diverse and high-quality music suitable for the desired context (e. g., music for romantic movies, action games, restaurants, etc.).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/commu-dataset-for-combinatorial-music</guid>
    </item>
    <item>
      <title>VeLO: Training Versatile Learned Optimizers by Scaling Up</title>
      <link>https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</link>
      <description><![CDATA[While deep learning models have replaced hand-designed features across many domains, these models are still trained with hand-designed optimizers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</guid>
    </item>
    <item>
      <title>Inversion-Based Creativity Transfer with Diffusion Models</title>
      <link>https://paperswithcode.com/paper/inversion-based-creativity-transfer-with</link>
      <description><![CDATA[In this paper, we introduce the task of "Creativity Transfer".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/inversion-based-creativity-transfer-with</guid>
    </item>
    <item>
      <title>Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks</title>
      <link>https://paperswithcode.com/paper/relative-attributing-propagation-interpreting</link>
      <description><![CDATA[As Deep Neural Networks (DNNs) have demonstrated superhuman performance in a variety of fields, there is an increasing interest in understanding the complex internal mechanisms of DNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relative-attributing-propagation-interpreting</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning</title>
      <link>https://paperswithcode.com/paper/pointclip-v2-adapting-clip-for-powerful-3d</link>
      <description><![CDATA[Contrastive Language-Image Pre-training (CLIP) has shown promising open-world performance on 2D image tasks, while its transferred capacity on 3D point clouds, i. e., PointCLIP, is still far from satisfactory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pointclip-v2-adapting-clip-for-powerful-3d</guid>
    </item>
  </channel>
</rss>
