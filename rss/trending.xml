<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 07 Aug 2023 21:06:02 +0000</lastBuildDate>
    <item>
      <title>Simple and Controllable Music Generation</title>
      <link>https://paperswithcode.com/paper/simple-and-controllable-music-generation</link>
      <description><![CDATA[We tackle the task of conditional music generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/simple-and-controllable-music-generation</guid>
    </item>
    <item>
      <title>ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</title>
      <link>https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</link>
      <description><![CDATA[We first present ToolBench, an instruction-tuning dataset for tool use, which is created automatically using ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to</guid>
    </item>
    <item>
      <title>Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors</title>
      <link>https://paperswithcode.com/paper/magic123-one-image-to-high-quality-3d-object</link>
      <description><![CDATA[We present Magic123, a two-stage coarse-to-fine approach for high-quality, textured 3D meshes generation from a single unposed image in the wild using both2D and 3D priors.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magic123-one-image-to-high-quality-3d-object</guid>
    </item>
    <item>
      <title>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</title>
      <link>https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</link>
      <description><![CDATA[Recently, remarkable progress has been made in automated task-solving through the use of multi-agents driven by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent</guid>
    </item>
    <item>
      <title>The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World</title>
      <link>https://paperswithcode.com/paper/the-all-seeing-project-towards-panoptic</link>
      <description><![CDATA[We present the All-Seeing (AS) project: a large-scale data and model for recognizing and understanding everything in the open world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-all-seeing-project-towards-panoptic</guid>
    </item>
    <item>
      <title>Effective Whole-body Pose Estimation with Two-stages Distillation</title>
      <link>https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</link>
      <description><![CDATA[Different from the previous self-knowledge distillation, this stage finetunes the student's head with only 20% training time as a plug-and-play training strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/effective-whole-body-pose-estimation-with-two</guid>
    </item>
    <item>
      <title>On Architectural Compression of Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/on-architectural-compression-of-text-to-image</link>
      <description><![CDATA[Exceptional text-to-image (T2I) generation results of Stable Diffusion models (SDMs) come with substantial computational demands.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-architectural-compression-of-text-to-image</guid>
    </item>
    <item>
      <title>LISA: Reasoning Segmentation via Large Language Model</title>
      <link>https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</link>
      <description><![CDATA[In this work, we propose a new segmentation task -- reasoning segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lisa-reasoning-segmentation-via-large</guid>
    </item>
    <item>
      <title>Universal and Transferable Adversarial Attacks on Aligned Language Models</title>
      <link>https://paperswithcode.com/paper/universal-and-transferable-adversarial</link>
      <description><![CDATA[Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-and-transferable-adversarial</guid>
    </item>
    <item>
      <title>A Survey of Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-of-large-language-models</link>
      <description><![CDATA[To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-large-language-models</guid>
    </item>
    <item>
      <title>Gorilla: Large Language Model Connected with Massive APIs</title>
      <link>https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</link>
      <description><![CDATA[Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</guid>
    </item>
    <item>
      <title>Scaling Relationship on Learning Mathematical Reasoning with Large Language Models</title>
      <link>https://paperswithcode.com/paper/scaling-relationship-on-learning-mathematical</link>
      <description><![CDATA[We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-relationship-on-learning-mathematical</guid>
    </item>
    <item>
      <title>DETR Doesn't Need Multi-Scale or Locality Design</title>
      <link>https://paperswithcode.com/paper/detr-doesn-t-need-multi-scale-or-locality</link>
      <description><![CDATA[This paper presents an improved DETR detector that maintains a "plain" nature: using a single-scale feature map and global cross-attention calculations without specific locality constraints, in contrast to previous leading DETR-based detectors that reintroduce architectural inductive biases of multi-scale and locality into the decoder.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/detr-doesn-t-need-multi-scale-or-locality</guid>
    </item>
    <item>
      <title>AnyLoc: Towards Universal Visual Place Recognition</title>
      <link>https://paperswithcode.com/paper/anyloc-towards-universal-visual-place</link>
      <description><![CDATA[In this work, we develop a universal solution to VPR -- a technique that works across a broad range of structured and unstructured environments (urban, outdoors, indoors, aerial, underwater, and subterranean environments) without any re-training or fine-tuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anyloc-towards-universal-visual-place</guid>
    </item>
    <item>
      <title>QuIP: 2-Bit Quantization of Large Language Models With Guarantees</title>
      <link>https://paperswithcode.com/paper/quip-2-bit-quantization-of-large-language</link>
      <description><![CDATA[This work studies post-training parameter quantization in large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/quip-2-bit-quantization-of-large-language</guid>
    </item>
    <item>
      <title>MovieChat: From Dense Token to Sparse Memory for Long Video Understanding</title>
      <link>https://paperswithcode.com/paper/moviechat-from-dense-token-to-sparse-memory</link>
      <description><![CDATA[Recently, integrating video foundation models and large language models to build a video understanding system overcoming the limitations of specific pre-defined vision tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moviechat-from-dense-token-to-sparse-memory</guid>
    </item>
    <item>
      <title>EMP-SSL: Towards Self-Supervised Learning in One Training Epoch</title>
      <link>https://paperswithcode.com/paper/emp-ssl-towards-self-supervised-learning-in</link>
      <description><![CDATA[Recently, self-supervised learning (SSL) has achieved tremendous success in learning image representation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/emp-ssl-towards-self-supervised-learning-in</guid>
    </item>
    <item>
      <title>Data-Free Learning of Reduced-Order Kinematics</title>
      <link>https://paperswithcode.com/paper/data-free-learning-of-reduced-order</link>
      <description><![CDATA[Physical systems ranging from elastic bodies to kinematic linkages are defined on high-dimensional configuration spaces, yet their typical low-energy configurations are concentrated on much lower-dimensional subspaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-free-learning-of-reduced-order</guid>
    </item>
    <item>
      <title>Temporally Consistent Online Depth Estimation Using Point-Based Fusion</title>
      <link>https://paperswithcode.com/paper/temporally-consistent-online-depth-estimation-1</link>
      <description><![CDATA[The presence of dynamic objects further complicates the problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporally-consistent-online-depth-estimation-1</guid>
    </item>
    <item>
      <title>VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design</title>
      <link>https://paperswithcode.com/paper/vits2-improving-quality-and-efficiency-of</link>
      <description><![CDATA[Single-stage text-to-speech models have been actively studied recently, and their results have outperformed two-stage pipeline systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vits2-improving-quality-and-efficiency-of</guid>
    </item>
  </channel>
</rss>
