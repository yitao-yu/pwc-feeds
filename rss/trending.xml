<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 30 Jan 2024 21:07:08 +0000</lastBuildDate>
    <item>
      <title>Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data</title>
      <link>https://paperswithcode.com/paper/depth-anything-unleashing-the-power-of-large</link>
      <description><![CDATA[To this end, we scale up the dataset by designing a data engine to collect and automatically annotate large-scale unlabeled data (~62M), which significantly enlarges the data coverage and thus is able to reduce the generalization error.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/depth-anything-unleashing-the-power-of-large</guid>
    </item>
    <item>
      <title>InstantID: Zero-shot Identity-Preserving Generation in Seconds</title>
      <link>https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</link>
      <description><![CDATA[There has been significant progress in personalized image synthesis with methods such as Textual Inversion, DreamBooth, and LoRA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</guid>
    </item>
    <item>
      <title>Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs</title>
      <link>https://paperswithcode.com/paper/mastering-text-to-image-diffusion</link>
      <description><![CDATA[In this paper, we propose a brand new training-free text-to-image generation/editing framework, namely Recaption, Plan and Generate (RPG), harnessing the powerful chain-of-thought reasoning ability of multimodal LLMs to enhance the compositionality of text-to-image diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mastering-text-to-image-diffusion</guid>
    </item>
    <item>
      <title>Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering</title>
      <link>https://paperswithcode.com/paper/code-generation-with-alphacodium-from-prompt</link>
      <description><![CDATA[Hence, many of the optimizations and tricks that have been successful in natural language generation may not be effective for code tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/code-generation-with-alphacodium-from-prompt</guid>
    </item>
    <item>
      <title>Self-Rewarding Language Models</title>
      <link>https://paperswithcode.com/paper/self-rewarding-language-models</link>
      <description><![CDATA[We posit that to achieve superhuman agents, future models require superhuman feedback in order to provide an adequate training signal.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-rewarding-language-models</guid>
    </item>
    <item>
      <title>Benchmarking LLMs via Uncertainty Quantification</title>
      <link>https://paperswithcode.com/paper/benchmarking-llms-via-uncertainty</link>
      <description><![CDATA[The proliferation of open-source Large Language Models (LLMs) from various institutions has highlighted the urgent need for comprehensive evaluation methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/benchmarking-llms-via-uncertainty</guid>
    </item>
    <item>
      <title>VMamba: Visual State Space Model</title>
      <link>https://paperswithcode.com/paper/vmamba-visual-state-space-model</link>
      <description><![CDATA[Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) stand as the two most popular foundation models for visual representation learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vmamba-visual-state-space-model</guid>
    </item>
    <item>
      <title>Orion-14B: Open-source Multilingual Large Language Models</title>
      <link>https://paperswithcode.com/paper/orion-14b-open-source-multilingual-large</link>
      <description><![CDATA[In this study, we introduce Orion-14B, a collection of multilingual large language models with 14 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/orion-14b-open-source-multilingual-large</guid>
    </item>
    <item>
      <title>Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model</title>
      <link>https://paperswithcode.com/paper/vision-mamba-efficient-visual-representation</link>
      <description><![CDATA[The results demonstrate that Vim is capable of overcoming the computation & memory constraints on performing Transformer-style understanding for high-resolution images and it has great potential to become the next-generation backbone for vision foundation models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vision-mamba-efficient-visual-representation</guid>
    </item>
    <item>
      <title>Bag of Tricks for Long-Tailed Visual Recognition with Deep Convolutional Neural Networks</title>
      <link>https://paperswithcode.com/paper/bag-of-tricks-for-long-tailed-visual</link>
      <description><![CDATA[In recent years, visual recognition on challenging long-tailed distributions, where classes often exhibit extremely imbalanced frequencies, has made great progress mostly based on various complex paradigms (e. g., meta learning).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bag-of-tricks-for-long-tailed-visual</guid>
    </item>
    <item>
      <title>Matryoshka Representation Learning</title>
      <link>https://paperswithcode.com/paper/matryoshka-representations-for-adaptive</link>
      <description><![CDATA[The flexibility within the learned Matryoshka Representations offer: (a) up to 14x smaller embedding size for ImageNet-1K classification at the same level of accuracy; (b) up to 14x real-world speed-ups for large-scale retrieval on ImageNet-1K and 4K; and (c) up to 2% accuracy improvements for long-tail few-shot classification, all while being as robust as the original representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/matryoshka-representations-for-adaptive</guid>
    </item>
    <item>
      <title>AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents</title>
      <link>https://paperswithcode.com/paper/agentboard-an-analytical-evaluation-board-of</link>
      <description><![CDATA[Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentboard-an-analytical-evaluation-board-of</guid>
    </item>
    <item>
      <title>AnyText: Multilingual Visual Text Generation And Editing</title>
      <link>https://paperswithcode.com/paper/anytext-multilingual-visual-text-generation</link>
      <description><![CDATA[Based on AnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual text generation accuracy and quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/anytext-multilingual-visual-text-generation</guid>
    </item>
    <item>
      <title>Hawkeye: A PyTorch-based Library for Fine-Grained Image Recognition with Deep Learning</title>
      <link>https://paperswithcode.com/paper/hawkeye-a-pytorch-based-library-for-fine</link>
      <description><![CDATA[However, the absence of a unified open-source software library covering various paradigms in FGIR poses a significant challenge for researchers and practitioners in the field.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hawkeye-a-pytorch-based-library-for-fine</guid>
    </item>
    <item>
      <title>Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively</title>
      <link>https://paperswithcode.com/paper/open-vocabulary-sam-segment-and-recognize</link>
      <description><![CDATA[The CLIP and Segment Anything Model (SAM) are remarkable vision foundation models (VFMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/open-vocabulary-sam-segment-and-recognize</guid>
    </item>
    <item>
      <title>TaskWeaver: A Code-First Agent Framework</title>
      <link>https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</link>
      <description><![CDATA[TaskWeaver provides support for rich data structures, flexible plugin usage, and dynamic plugin selection, and leverages LLM coding capabilities for complex logic.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/taskweaver-a-code-first-agent-framework</guid>
    </item>
    <item>
      <title>SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation</title>
      <link>https://paperswithcode.com/paper/segmamba-long-range-sequential-modeling-mamba</link>
      <description><![CDATA[Our SegMamba, in contrast to Transformer-based methods, excels in whole volume feature modeling from a state space model standpoint, maintaining superior processing speed, even with volume features at a resolution of {$64\times 64\times 64$}.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segmamba-long-range-sequential-modeling-mamba</guid>
    </item>
    <item>
      <title>SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation</title>
      <link>https://paperswithcode.com/paper/speechgpt-gen-scaling-chain-of-information</link>
      <description><![CDATA[It comprises an autoregressive model based on LLM for semantic information modeling and a non-autoregressive model employing flow matching for perceptual information modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/speechgpt-gen-scaling-chain-of-information</guid>
    </item>
    <item>
      <title>PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding</title>
      <link>https://paperswithcode.com/paper/photomaker-customizing-realistic-human-photos</link>
      <description><![CDATA[Recent advances in text-to-image generation have made remarkable progress in synthesizing realistic human photos conditioned on given text prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photomaker-customizing-realistic-human-photos</guid>
    </item>
    <item>
      <title>Deep Regression on Manifolds: A 3D Rotation Case Study</title>
      <link>https://paperswithcode.com/paper/deep-regression-on-manifolds-a-3d-rotation</link>
      <description><![CDATA[Many machine learning problems involve regressing variables on a non-Euclidean manifold -- e. g. a discrete probability distribution, or the 6D pose of an object.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-regression-on-manifolds-a-3d-rotation</guid>
    </item>
  </channel>
</rss>
