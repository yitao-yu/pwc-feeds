<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 17 Jun 2022 21:06:41 +0000</lastBuildDate>
    <item>
      <title>Zero-Shot Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/zero-shot-text-to-image-generation</link>
      <description><![CDATA[Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-text-to-image-generation</guid>
    </item>
    <item>
      <title>CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers</title>
      <link>https://paperswithcode.com/paper/cogview2-faster-and-better-text-to-image</link>
      <description><![CDATA[The development of the transformer-based text-to-image models are impeded by its slow generation and complexity for high-resolution images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cogview2-faster-and-better-text-to-image</guid>
    </item>
    <item>
      <title>Implicit Sample Extension for Unsupervised Person Re-Identification</title>
      <link>https://paperswithcode.com/paper/implicit-sample-extension-for-unsupervised</link>
      <description><![CDATA[Specifically, we generate support samples from actual samples and their neighbouring clusters in the embedding space through a progressive linear interpolation (PLI) strategy.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/implicit-sample-extension-for-unsupervised</guid>
    </item>
    <item>
      <title>Variable Bitrate Neural Fields</title>
      <link>https://paperswithcode.com/paper/variable-bitrate-neural-fields</link>
      <description><![CDATA[Neural approximations of scalar and vector fields, such as signed distance functions and radiance fields, have emerged as accurate, high-quality representations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/variable-bitrate-neural-fields</guid>
    </item>
    <item>
      <title>Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding</title>
      <link>https://paperswithcode.com/paper/photorealistic-text-to-image-diffusion-models</link>
      <description><![CDATA[We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photorealistic-text-to-image-diffusion-models</guid>
    </item>
    <item>
      <title>BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers</title>
      <link>https://paperswithcode.com/paper/bevformer-learning-bird-s-eye-view</link>
      <description><![CDATA[In a nutshell, BEVFormer exploits both spatial and temporal information by interacting with spatial and temporal space through predefined grid-shaped BEV queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bevformer-learning-bird-s-eye-view</guid>
    </item>
    <item>
      <title>Xplique: A Deep Learning Explainability Toolbox</title>
      <link>https://paperswithcode.com/paper/xplique-a-deep-learning-explainability</link>
      <description><![CDATA[Today's most advanced machine-learning models are hardly scrutable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xplique-a-deep-learning-explainability</guid>
    </item>
    <item>
      <title>Scaling Up Models and Data with $\texttt{t5x}$ and $\texttt{seqio}$</title>
      <link>https://paperswithcode.com/paper/scaling-up-models-and-data-with-texttt-t5x</link>
      <description><![CDATA[Recent neural network-based language models have benefited greatly from scaling up the size of training datasets and the number of parameters in the models themselves.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-up-models-and-data-with-texttt-t5x</guid>
    </item>
    <item>
      <title>Ivy: Templated Deep Learning for Inter-Framework Portability</title>
      <link>https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</link>
      <description><![CDATA[We introduce Ivy, a templated Deep Learning (DL) framework which abstracts existing DL frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</guid>
    </item>
    <item>
      <title>OmniXAI: A Library for Explainable AI</title>
      <link>https://paperswithcode.com/paper/omnixai-a-library-for-explainable-ai</link>
      <description><![CDATA[We introduce OmniXAI (short for Omni eXplainable AI), an open-source Python library of eXplainable AI (XAI), which offers omni-way explainable AI capabilities and various interpretable machine learning techniques to address the pain points of understanding and interpreting the decisions made by machine learning (ML) in practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnixai-a-library-for-explainable-ai</guid>
    </item>
    <item>
      <title>PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images</title>
      <link>https://paperswithcode.com/paper/petrv2-a-unified-framework-for-3d-perception</link>
      <description><![CDATA[More specifically, we extend the 3D position embedding (3D PE) in PETR for temporal modeling.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/petrv2-a-unified-framework-for-3d-perception</guid>
    </item>
    <item>
      <title>FedHPO-B: A Benchmark Suite for Federated Hyperparameter Optimization</title>
      <link>https://paperswithcode.com/paper/fedhpo-b-a-benchmark-suite-for-federated</link>
      <description><![CDATA[Due to this uniqueness, existing HPO benchmarks no longer satisfy the need to compare HPO methods in the FL setting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedhpo-b-a-benchmark-suite-for-federated</guid>
    </item>
    <item>
      <title>Meta Optimal Transport</title>
      <link>https://paperswithcode.com/paper/meta-optimal-transport</link>
      <description><![CDATA[We study the use of amortized optimization to predict optimal transport (OT) maps from the input measures, which we call Meta OT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-optimal-transport</guid>
    </item>
    <item>
      <title>PaddleRec</title>
      <link>https://github.com/PaddlePaddle/PaddleRec</link>
      <description><![CDATA[Recommendation AlgorithmLRWide&DeepDSSMTDMMINDWord2VecBert4RecDeepWalkSSRAITMDSINSIGNIPRECGRU4RecYoutube_dnnNCFGNNFMFFMDeepFMDCNDINDIENDLRMMMOEPLEESMMESCMM, MAMLxDeepFMDeepFEFMNFMAFMRALMDMRGateNetNAMLDIFMDeep CrossingPNNBSTAutoIntFGCNNFLENFibinetListWiseDeepRecENSFMTiSASAutoFIScriteo movielens]]></description>
      <guid isPermaLink="true">https://github.com/PaddlePaddle/PaddleRec</guid>
    </item>
    <item>
      <title>Demystifying MMD GANs</title>
      <link>https://paperswithcode.com/paper/demystifying-mmd-gans</link>
      <description><![CDATA[We investigate the training and performance of generative adversarial networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demystifying-mmd-gans</guid>
    </item>
    <item>
      <title>Counterfactual Inference for Text Classification Debiasing</title>
      <link>https://paperswithcode.com/paper/counterfactual-inference-for-text</link>
      <description><![CDATA[In inference, given a factual input document, Corsair imagines its two counterfactual counterparts to distill and mitigate the two biases captured by the poisonous model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/counterfactual-inference-for-text</guid>
    </item>
    <item>
      <title>VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution</title>
      <link>https://paperswithcode.com/paper/videoinr-learning-video-implicit-neural-1</link>
      <description><![CDATA[The learned implicit neural representation can be decoded to videos of arbitrary spatial resolution and frame rate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videoinr-learning-video-implicit-neural-1</guid>
    </item>
    <item>
      <title>BigVGAN: A Universal Neural Vocoder with Large-Scale Training</title>
      <link>https://paperswithcode.com/paper/bigvgan-a-universal-neural-vocoder-with-large</link>
      <description><![CDATA[Despite recent progress in generative adversarial network(GAN)-based vocoders, where the model generates raw waveform conditioned on mel spectrogram, it is still challenging to synthesize high-fidelity audio for numerous speakers across varied recording environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bigvgan-a-universal-neural-vocoder-with-large</guid>
    </item>
    <item>
      <title>Receding Moving Object Segmentation in 3D LiDAR Data Using Sparse 4D Convolutions</title>
      <link>https://paperswithcode.com/paper/receding-moving-object-segmentation-in-3d</link>
      <description><![CDATA[A key challenge for autonomous vehicles is to navigate in unseen dynamic environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/receding-moving-object-segmentation-in-3d</guid>
    </item>
    <item>
      <title>Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</title>
      <link>https://paperswithcode.com/paper/beyond-the-imitation-game-quantifying-and</link>
      <description><![CDATA[BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-the-imitation-game-quantifying-and</guid>
    </item>
  </channel>
</rss>
