<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 11 Nov 2022 09:15:50 +0000</lastBuildDate>
    <item>
      <title>TAP-Vid: A Benchmark for Tracking Any Point in a Video</title>
      <link>https://paperswithcode.com/paper/tap-vid-a-benchmark-for-tracking-any-point-in</link>
      <description><![CDATA[Generic motion understanding from video involves not only tracking objects, but also perceiving how their surfaces deform and move.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tap-vid-a-benchmark-for-tracking-any-point-in</guid>
    </item>
    <item>
      <title>Real-Time Target Sound Extraction</title>
      <link>https://paperswithcode.com/paper/real-time-target-sound-extraction</link>
      <description><![CDATA[We present the first neural network model to achieve real-time and streaming target sound extraction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-target-sound-extraction</guid>
    </item>
    <item>
      <title>High Fidelity Neural Audio Compression</title>
      <link>https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</link>
      <description><![CDATA[We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</guid>
    </item>
    <item>
      <title>Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese</title>
      <link>https://paperswithcode.com/paper/chinese-clip-contrastive-vision-language</link>
      <description><![CDATA[The tremendous success of CLIP (Radford et al., 2021) has promoted the research and application of contrastive learning for vision-language pretraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chinese-clip-contrastive-vision-language</guid>
    </item>
    <item>
      <title>Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training</title>
      <link>https://paperswithcode.com/paper/colossal-ai-a-unified-deep-learning-system</link>
      <description><![CDATA[The success of Transformer models has pushed the deep learning model scale to billions of parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/colossal-ai-a-unified-deep-learning-system</guid>
    </item>
    <item>
      <title>OneFlow: Redesign the Distributed Deep Learning Framework from Scratch</title>
      <link>https://paperswithcode.com/paper/oneflow-redesign-the-distributed-deep</link>
      <description><![CDATA[Aiming at a simple, neat redesign of distributed deep learning frameworks for various parallelism paradigms, we present OneFlow, a novel distributed training framework based on an SBP (split, broadcast and partial-value) abstraction and the actor model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oneflow-redesign-the-distributed-deep</guid>
    </item>
    <item>
      <title>PhaseAug: A Differentiable Augmentation for Speech Synthesis to Simulate One-to-Many Mapping</title>
      <link>https://paperswithcode.com/paper/phaseaug-a-differentiable-augmentation-for</link>
      <description><![CDATA[Previous generative adversarial network (GAN)-based neural vocoders are trained to reconstruct the exact ground truth waveform from the paired mel-spectrogram and do not consider the one-to-many relationship of speech synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/phaseaug-a-differentiable-augmentation-for</guid>
    </item>
    <item>
      <title>Example-Based Named Entity Recognition</title>
      <link>https://paperswithcode.com/paper/example-based-named-entity-recognition</link>
      <description><![CDATA[We present a novel approach to named entity recognition (NER) in the presence of scarce data that we call example-based NER.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/example-based-named-entity-recognition</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>MotionBERT: Unified Pretraining for Human Motion Analysis</title>
      <link>https://paperswithcode.com/paper/motionbert-unified-pretraining-for-human</link>
      <description><![CDATA[We present MotionBERT, a unified pretraining framework, to tackle different sub-tasks of human motion analysis including 3D pose estimation, skeleton-based action recognition, and mesh recovery.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motionbert-unified-pretraining-for-human</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>Pop2Piano : Pop Audio-based Piano Cover Generation</title>
      <link>https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</link>
      <description><![CDATA[The piano cover of pop music is widely enjoyed by people.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</guid>
    </item>
    <item>
      <title>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</title>
      <link>https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</link>
      <description><![CDATA[Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a</guid>
    </item>
    <item>
      <title>Focal Modulation Networks</title>
      <link>https://paperswithcode.com/paper/focal-modulation-networks</link>
      <description><![CDATA[For semantic segmentation with UPerNet, FocalNet base at single-scale outperforms Swin by 2. 4, and beats Swin at multi-scale (50. 5 v. s.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/focal-modulation-networks</guid>
    </item>
    <item>
      <title>Music Mixing Style Transfer: A Contrastive Learning Approach to Disentangle Audio Effects</title>
      <link>https://paperswithcode.com/paper/music-mixing-style-transfer-a-contrastive</link>
      <description><![CDATA[We propose an end-to-end music mixing style transfer system that converts the mixing style of an input multitrack to that of a reference song.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/music-mixing-style-transfer-a-contrastive</guid>
    </item>
    <item>
      <title>A Survey of Deep Face Restoration: Denoise, Super-Resolution, Deblur, Artifact Removal</title>
      <link>https://paperswithcode.com/paper/a-survey-of-deep-face-restoration-denoise</link>
      <description><![CDATA[Second, we discuss the challenges of face restoration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-deep-face-restoration-denoise</guid>
    </item>
    <item>
      <title>Revisiting Sparse Convolutional Model for Visual Recognition</title>
      <link>https://paperswithcode.com/paper/revisiting-sparse-convolutional-model-for</link>
      <description><![CDATA[We show that such models have equally strong empirical performance on CIFAR-10, CIFAR-100, and ImageNet datasets when compared to conventional neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/revisiting-sparse-convolutional-model-for</guid>
    </item>
    <item>
      <title>Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models</title>
      <link>https://paperswithcode.com/paper/efficient-spatially-sparse-inference-for</link>
      <description><![CDATA[With 1. 2%-area edited regions, our method reduces the computation of DDIM by 7. 5$\times$ and GauGAN by 18$\times$ while preserving the visual fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-spatially-sparse-inference-for</guid>
    </item>
    <item>
      <title>Robust Speech Recognition via Large-Scale Weak Supervision</title>
      <link>https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale</link>
      <description><![CDATA[We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-speech-recognition-via-large-scale</guid>
    </item>
    <item>
      <title>WeightedSHAP: analyzing and improving Shapley based feature attributions</title>
      <link>https://paperswithcode.com/paper/weightedshap-analyzing-and-improving-shapley</link>
      <description><![CDATA[On several real-world datasets, we demonstrate that the influential features identified by WeightedSHAP are better able to recapitulate the model's predictions compared to the features identified by the Shapley value.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/weightedshap-analyzing-and-improving-shapley</guid>
    </item>
  </channel>
</rss>
