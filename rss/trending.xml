<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 29 Sep 2023 21:06:06 +0000</lastBuildDate>
    <item>
      <title>ProPainter: Improving Propagation and Transformer for Video Inpainting</title>
      <link>https://paperswithcode.com/paper/propainter-improving-propagation-and</link>
      <description><![CDATA[We also propose a mask-guided sparse video Transformer, which achieves high efficiency by discarding unnecessary and redundant tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/propainter-improving-propagation-and</guid>
    </item>
    <item>
      <title>LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models</title>
      <link>https://paperswithcode.com/paper/longlora-efficient-fine-tuning-of-long</link>
      <description><![CDATA[LongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a single 8x A100 machine.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longlora-efficient-fine-tuning-of-long</guid>
    </item>
    <item>
      <title>Communicative Agents for Software Development</title>
      <link>https://paperswithcode.com/paper/communicative-agents-for-software-development</link>
      <description><![CDATA[At the core of this paradigm lies ChatDev, a virtual chat-powered software development company that mirrors the established waterfall model, meticulously dividing the development process into four distinct chronological stages: designing, coding, testing, and documenting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/communicative-agents-for-software-development</guid>
    </item>
    <item>
      <title>QLoRA: Efficient Finetuning of Quantized LLMs</title>
      <link>https://paperswithcode.com/paper/qlora-efficient-finetuning-of-quantized-llms</link>
      <description><![CDATA[Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99. 3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qlora-efficient-finetuning-of-quantized-llms</guid>
    </item>
    <item>
      <title>InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition</title>
      <link>https://paperswithcode.com/paper/internlm-xcomposer-a-vision-language-large</link>
      <description><![CDATA[We propose InternLM-XComposer, a vision-language large model that enables advanced image-text comprehension and composition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internlm-xcomposer-a-vision-language-large</guid>
    </item>
    <item>
      <title>Agents: An Open-source Framework for Autonomous Language Agents</title>
      <link>https://paperswithcode.com/paper/agents-an-open-source-framework-for</link>
      <description><![CDATA[Recent advances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can automatically solve various tasks and interact with environments, humans, and other agents using natural language interfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agents-an-open-source-framework-for</guid>
    </item>
    <item>
      <title>Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation</title>
      <link>https://paperswithcode.com/paper/show-1-marrying-pixel-and-latent-diffusion</link>
      <description><![CDATA[In this paper, we are the first to propose a hybrid model, dubbed as Show-1, which marries pixel-based and latent-based VDMs for text-to-video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/show-1-marrying-pixel-and-latent-diffusion</guid>
    </item>
    <item>
      <title>FreeU: Free Lunch in Diffusion U-Net</title>
      <link>https://paperswithcode.com/paper/freeu-free-lunch-in-diffusion-u-net</link>
      <description><![CDATA[In this paper, we uncover the untapped potential of diffusion U-Net, which serves as a "free lunch" that substantially improves the generation quality on the fly.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/freeu-free-lunch-in-diffusion-u-net</guid>
    </item>
    <item>
      <title>NExT-GPT: Any-to-Any Multimodal LLM</title>
      <link>https://paperswithcode.com/paper/next-gpt-any-to-any-multimodal-llm</link>
      <description><![CDATA[While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/next-gpt-any-to-any-multimodal-llm</guid>
    </item>
    <item>
      <title>The Rise and Potential of Large Language Model Based Agents: A Survey</title>
      <link>https://paperswithcode.com/paper/the-rise-and-potential-of-large-language</link>
      <description><![CDATA[Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-rise-and-potential-of-large-language</guid>
    </item>
    <item>
      <title>Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement</title>
      <link>https://paperswithcode.com/paper/retinexformer-one-stage-retinex-based</link>
      <description><![CDATA[When enhancing low-light images, many deep learning algorithms are based on the Retinex theory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/retinexformer-one-stage-retinex-based</guid>
    </item>
    <item>
      <title>Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models</title>
      <link>https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</link>
      <description><![CDATA[To address these challenges, we introduce a system that can jointly optimize distributed execution and gradient checkpointing plans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</guid>
    </item>
    <item>
      <title>DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services</title>
      <link>https://paperswithcode.com/paper/disc-lawllm-fine-tuning-large-language-models</link>
      <description><![CDATA[We propose DISC-LawLLM, an intelligent legal system utilizing large language models (LLMs) to provide a wide range of legal services.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/disc-lawllm-fine-tuning-large-language-models</guid>
    </item>
    <item>
      <title>QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models</title>
      <link>https://paperswithcode.com/paper/qa-lora-quantization-aware-low-rank</link>
      <description><![CDATA[Recently years have witnessed a rapid development of large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qa-lora-quantization-aware-low-rank</guid>
    </item>
    <item>
      <title>UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation</title>
      <link>https://paperswithcode.com/paper/unitedhuman-harnessing-multi-source-data-for</link>
      <description><![CDATA[A holistic human dataset inevitably has insufficient and low-resolution information on local parts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unitedhuman-harnessing-multi-source-data-for</guid>
    </item>
    <item>
      <title>Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism</title>
      <link>https://paperswithcode.com/paper/gold-yolo-efficient-object-detector-via</link>
      <description><![CDATA[In the past years, YOLO-series models have emerged as the leading approaches in the area of real-time object detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gold-yolo-efficient-object-detector-via</guid>
    </item>
    <item>
      <title>3D Gaussian Splatting for Real-Time Radiance Field Rendering</title>
      <link>https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</link>
      <description><![CDATA[Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-gaussian-splatting-for-real-time-radiance</guid>
    </item>
    <item>
      <title>AdaBin: Improving Binary Neural Networks with Adaptive Binary Sets</title>
      <link>https://paperswithcode.com/paper/adabin-improving-binary-neural-networks-with</link>
      <description><![CDATA[Since the modern deep neural networks are of sophisticated design with complex architecture for the accuracy reason, the diversity on distributions of weights and activations is very high.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adabin-improving-binary-neural-networks-with</guid>
    </item>
    <item>
      <title>RenderIH: A Large-scale Synthetic Dataset for 3D Interacting Hand Pose Estimation</title>
      <link>https://paperswithcode.com/paper/renderih-a-large-scale-synthetic-dataset-for</link>
      <description><![CDATA[The current interacting hand (IH) datasets are relatively simplistic in terms of background and texture, with hand joints being annotated by a machine annotator, which may result in inaccuracies, and the diversity of pose distribution is limited.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/renderih-a-large-scale-synthetic-dataset-for</guid>
    </item>
    <item>
      <title>GPT4Image: Can Large Pre-trained Models Help Vision Models on Perception Tasks?</title>
      <link>https://paperswithcode.com/paper/can-large-pre-trained-models-help-vision</link>
      <description><![CDATA[We present a new learning paradigm in which the knowledge extracted from large pre-trained models are utilized to help models like CNN and ViT learn enhanced representations and achieve better performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/can-large-pre-trained-models-help-vision</guid>
    </item>
  </channel>
</rss>
