<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 07 Nov 2022 21:08:31 +0000</lastBuildDate>
    <item>
      <title>Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models</title>
      <link>https://paperswithcode.com/paper/efficient-spatially-sparse-inference-for</link>
      <description><![CDATA[With 1. 2%-area edited regions, our method reduces the computation of DDIM by 7. 5$\times$ and GauGAN by 18$\times$ while preserving the visual fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-spatially-sparse-inference-for</guid>
    </item>
    <item>
      <title>Pop2Piano : Pop Audio-based Piano Cover Generation</title>
      <link>https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</link>
      <description><![CDATA[The piano cover of pop music is widely enjoyed by people.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pop2piano-pop-audio-based-piano-cover</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>High Fidelity Neural Audio Compression</title>
      <link>https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</link>
      <description><![CDATA[We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</guid>
    </item>
    <item>
      <title>Large Language Models Are Human-Level Prompt Engineers</title>
      <link>https://paperswithcode.com/paper/large-language-models-are-human-level-prompt</link>
      <description><![CDATA[By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-are-human-level-prompt</guid>
    </item>
    <item>
      <title>Language models enable zero-shot prediction of the effects of mutations on protein function</title>
      <link>https://paperswithcode.com/paper/language-models-enable-zero-shot-prediction</link>
      <description><![CDATA[Modeling the effect of sequence variation on function is a fundamental problem for understanding and designing proteins.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-enable-zero-shot-prediction</guid>
    </item>
    <item>
      <title>Zero-Shot Learners for Natural Language Understanding via a Unified Multiple Choice Perspective</title>
      <link>https://paperswithcode.com/paper/zero-shot-learners-for-natural-language</link>
      <description><![CDATA[We propose a new paradigm for zero-shot learners that is format agnostic, i. e., it is compatible with any format and applicable to a list of language tasks, such as text classification, commonsense reasoning, coreference resolution, and sentiment analysis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-learners-for-natural-language</guid>
    </item>
    <item>
      <title>WeightedSHAP: analyzing and improving Shapley based feature attributions</title>
      <link>https://paperswithcode.com/paper/weightedshap-analyzing-and-improving-shapley</link>
      <description><![CDATA[On several real-world datasets, we demonstrate that the influential features identified by WeightedSHAP are better able to recapitulate the model's predictions compared to the features identified by the Shapley value.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/weightedshap-analyzing-and-improving-shapley</guid>
    </item>
    <item>
      <title>Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese</title>
      <link>https://paperswithcode.com/paper/chinese-clip-contrastive-vision-language</link>
      <description><![CDATA[The tremendous success of CLIP (Radford et al., 2021) has promoted the research and application of contrastive learning for vision-language pretraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chinese-clip-contrastive-vision-language</guid>
    </item>
    <item>
      <title>Text-Only Training for Image Captioning using Noise-Injected CLIP</title>
      <link>https://paperswithcode.com/paper/text-only-training-for-image-captioning-using</link>
      <description><![CDATA[We consider the task of image-captioning using only the CLIP model and additional text data at training time, and no additional captioned images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-only-training-for-image-captioning-using</guid>
    </item>
    <item>
      <title>ShAPO: Implicit Representations for Multi-Object Shape, Appearance, and Pose Optimization</title>
      <link>https://paperswithcode.com/paper/shapo-implicit-representations-for-multi</link>
      <description><![CDATA[A novel disentangled shape and appearance database of priors is first learned to embed objects in their respective shape and appearance space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/shapo-implicit-representations-for-multi</guid>
    </item>
    <item>
      <title>DeepLearningExamples</title>
      <link>https://github.com/NVIDIA/DeepLearningExamples</link>
      <description><![CDATA[Deep Learning Examples]]></description>
      <guid isPermaLink="true">https://github.com/NVIDIA/DeepLearningExamples</guid>
    </item>
    <item>
      <title>DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models</title>
      <link>https://paperswithcode.com/paper/diffusiondb-a-large-scale-prompt-gallery</link>
      <description><![CDATA[We analyze prompts in the dataset and discuss key properties of these prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondb-a-large-scale-prompt-gallery</guid>
    </item>
    <item>
      <title>DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models</title>
      <link>https://paperswithcode.com/paper/dpm-solver-fast-solver-for-guided-sampling-of</link>
      <description><![CDATA[The commonly-used fast sampler for guided sampling is DDIM, a first-order diffusion ODE solver that generally needs 100 to 250 steps for high-quality samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dpm-solver-fast-solver-for-guided-sampling-of</guid>
    </item>
    <item>
      <title>Unsupervised visualization of image datasets using contrastive learning</title>
      <link>https://paperswithcode.com/paper/unsupervised-visualization-of-image-datasets</link>
      <description><![CDATA[This problem can be circumvented by self-supervised approaches based on contrastive learning, such as SimCLR, relying on data augmentation to generate implicit neighbors, but these methods do not produce two-dimensional embeddings suitable for visualization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unsupervised-visualization-of-image-datasets</guid>
    </item>
    <item>
      <title>UniInst: Unique Representation for End-to-End Instance Segmentation</title>
      <link>https://paperswithcode.com/paper/uniinst-unique-representation-for-end-to-end</link>
      <description><![CDATA[Existing instance segmentation methods have achieved impressive performance but still suffer from a common dilemma: redundant representations (e. g., multiple boxes, grids, and anchor points) are inferred for one instance, which leads to multiple duplicated predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/uniinst-unique-representation-for-end-to-end</guid>
    </item>
    <item>
      <title>Contrastive Decoding: Open-ended Text Generation as Optimization</title>
      <link>https://paperswithcode.com/paper/contrastive-decoding-open-ended-text</link>
      <description><![CDATA[We propose contrastive decoding (CD), a more reliable search objective that returns the difference between likelihood under a large LM (called the expert, e. g. OPT-13b) and a small LM (called the amateur, e. g. OPT-125m).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-decoding-open-ended-text</guid>
    </item>
    <item>
      <title>Crosslingual Generalization through Multitask Finetuning</title>
      <link>https://paperswithcode.com/paper/crosslingual-generalization-through-multitask</link>
      <description><![CDATA[We find finetuning large multilingual language models on English tasks with English prompts allows for task generalization to non-English languages that appear only in the pretraining corpus.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/crosslingual-generalization-through-multitask</guid>
    </item>
    <item>
      <title>High-Resolution Image Synthesis with Latent Diffusion Models</title>
      <link>https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</link>
      <description><![CDATA[By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-resolution-image-synthesis-with-latent</guid>
    </item>
    <item>
      <title>To Smooth or Not? When Label Smoothing Meets Noisy Labels</title>
      <link>https://paperswithcode.com/paper/understanding-generalized-label-smoothing</link>
      <description><![CDATA[We provide understandings for the properties of LS and NLS when learning with noisy labels.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/understanding-generalized-label-smoothing</guid>
    </item>
  </channel>
</rss>
