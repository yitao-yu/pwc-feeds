<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 19 Feb 2025 21:09:06 +0000</lastBuildDate>
    <item>
      <title>Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</title>
      <link>https://paperswithcode.com/paper/step-video-t2v-technical-report-the-practice</link>
      <description><![CDATA[We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained model with 30B parameters and the ability to generate videos up to 204 frames in length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/step-video-t2v-technical-report-the-practice</guid>
    </item>
    <item>
      <title>OmniParser for Pure Vision Based GUI Agent</title>
      <link>https://paperswithcode.com/paper/omniparser-for-pure-vision-based-gui-agent</link>
      <description><![CDATA[The recent success of large vision language models shows great potential in driving the agent system operating on user interfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omniparser-for-pure-vision-based-gui-agent</guid>
    </item>
    <item>
      <title>PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation</title>
      <link>https://paperswithcode.com/paper/pike-rag-specialized-knowledge-and-rationale</link>
      <description><![CDATA[Despite notable advancements in Retrieval-Augmented Generation (RAG) systems that expand large language model (LLM) capabilities through external retrieval, these systems often struggle to meet the complex and diverse needs of real-world industrial applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pike-rag-specialized-knowledge-and-rationale</guid>
    </item>
    <item>
      <title>CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction</title>
      <link>https://paperswithcode.com/paper/codei-o-condensing-reasoning-patterns-via</link>
      <description><![CDATA[Reasoning is a fundamental capability of Large Language Models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codei-o-condensing-reasoning-patterns-via</guid>
    </item>
    <item>
      <title>Data Formulator 2: Iteratively Creating Rich Visualizations with AI</title>
      <link>https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</link>
      <description><![CDATA[To create rich visualizations, data analysts often need to iterate back and forth among data processing and chart specification to achieve their goals.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/data-formulator-2-iteratively-creating-rich</guid>
    </item>
    <item>
      <title>Magic 1-For-1: Generating One Minute Video Clips within One Minute</title>
      <link>https://paperswithcode.com/paper/magic-1-for-1-generating-one-minute-video</link>
      <description><![CDATA[The key idea is simple: factorize the text-to-video generation task into two separate easier tasks for diffusion step distillation, namely text-to-image generation and image-to-video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/magic-1-for-1-generating-one-minute-video</guid>
    </item>
    <item>
      <title>Light-A-Video: Training-free Video Relighting via Progressive Light Fusion</title>
      <link>https://paperswithcode.com/paper/light-a-video-training-free-video-relighting</link>
      <description><![CDATA[Second, leveraging the physical principle of light transport independence, we apply linear blending between the source video's appearance and the relighted appearance, using a Progressive Light Fusion (PLF) strategy to ensure smooth temporal transitions in illumination.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/light-a-video-training-free-video-relighting</guid>
    </item>
    <item>
      <title>KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for Graph-RAG</title>
      <link>https://paperswithcode.com/paper/ket-rag-a-cost-efficient-multi-granular</link>
      <description><![CDATA[To ensure a good result accuracy while reducing the indexing cost, we propose KET-RAG, a multi-granular indexing framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ket-rag-a-cost-efficient-multi-granular</guid>
    </item>
    <item>
      <title>Flaming-hot Initiation with Regular Execution Sampling for Large Language Models</title>
      <link>https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</link>
      <description><![CDATA[Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flaming-hot-initiation-with-regular-execution</guid>
    </item>
    <item>
      <title>Diffusion Models without Classifier-free Guidance</title>
      <link>https://paperswithcode.com/paper/diffusion-models-without-classifier-free-1</link>
      <description><![CDATA[This paper presents Model-guidance (MG), a novel objective for training diffusion model that addresses and removes of the commonly used Classifier-free guidance (CFG).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-without-classifier-free-1</guid>
    </item>
    <item>
      <title>OSUM: Advancing Open Speech Understanding Models with Limited Resources in Academia</title>
      <link>https://paperswithcode.com/paper/osum-advancing-open-speech-understanding</link>
      <description><![CDATA[Large Language Models (LLMs) have made significant progress in various downstream tasks, inspiring the development of Speech Understanding Language Models (SULMs) to enable comprehensive speech-based interactions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/osum-advancing-open-speech-understanding</guid>
    </item>
    <item>
      <title>Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research</title>
      <link>https://paperswithcode.com/paper/agentic-reasoning-reasoning-llms-with-tools</link>
      <description><![CDATA[We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/agentic-reasoning-reasoning-llms-with-tools</guid>
    </item>
    <item>
      <title>Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach</title>
      <link>https://paperswithcode.com/paper/scaling-up-test-time-compute-with-latent</link>
      <description><![CDATA[We scale a proof-of-concept model to 3. 5 billion parameters and 800 billion tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-up-test-time-compute-with-latent</guid>
    </item>
    <item>
      <title>FlashVideo:Flowing Fidelity to Detail for Efficient High-Resolution Video Generation</title>
      <link>https://paperswithcode.com/paper/flashvideo-flowing-fidelity-to-detail-for</link>
      <description><![CDATA[DiT diffusion models have achieved great success in text-to-video generation, leveraging their scalability in model capacity and data scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flashvideo-flowing-fidelity-to-detail-for</guid>
    </item>
    <item>
      <title>SCoralDet: Efficient real-time underwater soft coral detection with YOLO</title>
      <link>https://paperswithcode.com/paper/scoraldet-efficient-real-time-underwater-soft</link>
      <description><![CDATA[To address these challenges, we propose SCoralDet, a soft coral detection model based on the YOLO architecture.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scoraldet-efficient-real-time-underwater-soft</guid>
    </item>
    <item>
      <title>Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback</title>
      <link>https://paperswithcode.com/paper/align-anything-training-all-modality-models</link>
      <description><![CDATA[In this work, we make the first attempt to fine-tune all-modality models (i. e. input and output with any modality, also named any-to-any models) using human preference data across all modalities (including text, image, audio, and video), ensuring its behavior aligns with human intentions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/align-anything-training-all-modality-models</guid>
    </item>
    <item>
      <title>Cut Your Losses in Large-Vocabulary Language Models</title>
      <link>https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</link>
      <description><![CDATA[We implement a custom kernel that performs the matrix multiplications and the log-sum-exp reduction over the vocabulary in flash memory, making global memory consumption for the cross-entropy computation negligible.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cut-your-losses-in-large-vocabulary-language</guid>
    </item>
    <item>
      <title>Zep: A Temporal Knowledge Graph Architecture for Agent Memory</title>
      <link>https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</link>
      <description><![CDATA[We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</guid>
    </item>
    <item>
      <title>Temporal Working Memory: Query-Guided Segment Refinement for Enhanced Multimodal Understanding</title>
      <link>https://paperswithcode.com/paper/temporal-working-memory-query-guided-segment</link>
      <description><![CDATA[To overcome these challenges, we introduce a specialized cognitive module, temporal working memory (TWM), which aims to enhance the temporal modeling capabilities of MFMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/temporal-working-memory-query-guided-segment</guid>
    </item>
    <item>
      <title>MedRAX: Medical Reasoning Agent for Chest X-ray</title>
      <link>https://paperswithcode.com/paper/medrax-medical-reasoning-agent-for-chest-x</link>
      <description><![CDATA[Chest X-rays (CXRs) play an integral role in driving critical decisions in disease management and patient care.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/medrax-medical-reasoning-agent-for-chest-x</guid>
    </item>
  </channel>
</rss>
