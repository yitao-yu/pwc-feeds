<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 17 Sep 2022 21:08:03 +0000</lastBuildDate>
    <item>
      <title>Diffusion Models: A Comprehensive Survey of Methods and Applications</title>
      <link>https://paperswithcode.com/paper/diffusion-models-a-comprehensive-survey-of</link>
      <description><![CDATA[Diffusion models are a class of deep generative models that have shown impressive results on various tasks with a solid theoretical foundation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-a-comprehensive-survey-of</guid>
    </item>
    <item>
      <title>StoryDALL-E: Adapting Pretrained Text-to-Image Transformers for Story Continuation</title>
      <link>https://paperswithcode.com/paper/storydall-e-adapting-pretrained-text-to-image</link>
      <description><![CDATA[Hence, we first propose the task of story continuation, where the generated visual story is conditioned on a source image, allowing for better generalization to narratives with new characters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/storydall-e-adapting-pretrained-text-to-image</guid>
    </item>
    <item>
      <title>Parameter-Free Style Projection for Arbitrary Style Transfer</title>
      <link>https://paperswithcode.com/paper/parameter-free-style-projection-for-arbitrary</link>
      <description><![CDATA[This paper further presents a real-time feed-forward model to leverage Style Projection for arbitrary image style transfer, which includes a regularization term for matching the semantics between input contents and stylized outputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/parameter-free-style-projection-for-arbitrary</guid>
    </item>
    <item>
      <title>Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models</title>
      <link>https://paperswithcode.com/paper/generative-visual-prompt-unifying</link>
      <description><![CDATA[We demonstrate how PromptGen can control several generative models (e. g., StyleGAN2, StyleNeRF, diffusion autoencoder, and NVAE) using various off-the-shelf models: (1) with the CLIP model, PromptGen can sample images guided by text, (2) with image classifiers, PromptGen can de-bias generative models across a set of attributes, and (3) with inverse graphics models, PromptGen can sample images of the same identity in different poses.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-visual-prompt-unifying</guid>
    </item>
    <item>
      <title>CenterFormer: Center-based Transformer for 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/centerformer-center-based-transformer-for-3d</link>
      <description><![CDATA[It then uses the feature of the center candidate as the query embedding in the transformer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/centerformer-center-based-transformer-for-3d</guid>
    </item>
    <item>
      <title>Git Re-Basin: Merging Models modulo Permutation Symmetries</title>
      <link>https://paperswithcode.com/paper/git-re-basin-merging-models-modulo</link>
      <description><![CDATA[Experimentally, we demonstrate the single basin phenomenon across a variety of model architectures and datasets, including the first (to our knowledge) demonstration of zero-barrier linear mode connectivity between independently trained ResNet models on CIFAR-10 and CIFAR-100.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/git-re-basin-merging-models-modulo</guid>
    </item>
    <item>
      <title>Thin-Plate Spline Motion Model for Image Animation</title>
      <link>https://paperswithcode.com/paper/thin-plate-spline-motion-model-for-image</link>
      <description><![CDATA[Firstly, we propose thin-plate spline motion estimation to produce a more flexible optical flow, which warps the feature maps of the source image to the feature domain of the driving image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/thin-plate-spline-motion-model-for-image</guid>
    </item>
    <item>
      <title>TEACH: Temporal Action Composition for 3D Humans</title>
      <link>https://paperswithcode.com/paper/teach-temporal-action-composition-for-3d</link>
      <description><![CDATA[In particular, our goal is to enable the synthesis of a series of actions, which we refer to as temporal action composition.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/teach-temporal-action-composition-for-3d</guid>
    </item>
    <item>
      <title>ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video</title>
      <link>https://paperswithcode.com/paper/esfpnet-efficient-deep-learning-architecture</link>
      <description><![CDATA[These values are superior to results achieved by other competing architectures that use Mix transformers or CNN-based encoders.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/esfpnet-efficient-deep-learning-architecture</guid>
    </item>
    <item>
      <title>GenLoco: Generalized Locomotion Controllers for Quadrupedal Robots</title>
      <link>https://paperswithcode.com/paper/genloco-generalized-locomotion-controllers</link>
      <description><![CDATA[In this work, we introduce a framework for training generalized locomotion (GenLoco) controllers for quadrupedal robots.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/genloco-generalized-locomotion-controllers</guid>
    </item>
    <item>
      <title>DI-engine</title>
      <link>https://github.com/opendilab/DI-engine</link>
      <description><![CDATA[OpenDILab Decision AI Engine]]></description>
      <guid isPermaLink="true">https://github.com/opendilab/DI-engine</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>Robust deep learning based protein sequence design using ProteinMPNN</title>
      <link>https://paperswithcode.com/paper/robust-deep-learning-based-protein-sequence</link>
      <description><![CDATA[While deep learning has revolutionized protein structure prediction, almost all experimentally characterized de novo protein designs have been generated using physically based approaches such as Rosetta.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/robust-deep-learning-based-protein-sequence</guid>
    </item>
    <item>
      <title>Zero-Shot Text-Guided Object Generation with Dream Fields</title>
      <link>https://paperswithcode.com/paper/zero-shot-text-guided-object-generation-with</link>
      <description><![CDATA[Our method, Dream Fields, can generate the geometry and color of a wide range of objects without 3D supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-text-guided-object-generation-with</guid>
    </item>
    <item>
      <title>Audio-Visual Segmentation</title>
      <link>https://paperswithcode.com/paper/audio-visual-segmentation</link>
      <description><![CDATA[To deal with the AVS problem, we propose a novel method that uses a temporal pixel-wise audio-visual interaction module to inject audio semantics as guidance for the visual segmentation process.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audio-visual-segmentation</guid>
    </item>
    <item>
      <title>Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models</title>
      <link>https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</link>
      <description><![CDATA[In RDMs, a set of nearest neighbors is retrieved from an external database during training for each training instance, and the diffusion model is conditioned on these informative samples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text-guided-synthesis-of-artistic-images-with</guid>
    </item>
    <item>
      <title>LiT: Zero-Shot Transfer with Locked-image text Tuning</title>
      <link>https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</link>
      <description><![CDATA[This paper presents contrastive-tuning, a simple method employing contrastive training to align image and text models while still taking advantage of their pre-training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lit-zero-shot-transfer-with-locked-image-text</guid>
    </item>
    <item>
      <title>Neural Architectures for Named Entity Recognition</title>
      <link>https://paperswithcode.com/paper/neural-architectures-for-named-entity</link>
      <description><![CDATA[State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-architectures-for-named-entity</guid>
    </item>
    <item>
      <title>FedML: A Research Library and Benchmark for Federated Machine Learning</title>
      <link>https://paperswithcode.com/paper/fedml-a-research-library-and-benchmark-for</link>
      <description><![CDATA[Federated learning (FL) is a rapidly growing research field in machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fedml-a-research-library-and-benchmark-for</guid>
    </item>
    <item>
      <title>Surface Representation for Point Clouds</title>
      <link>https://paperswithcode.com/paper/surface-representation-for-point-clouds</link>
      <description><![CDATA[Based on a simple baseline of PointNet++ (SSG version), Umbrella RepSurf surpasses the previous state-of-the-art by a large margin for classification, segmentation and detection on various benchmarks in terms of performance and efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/surface-representation-for-point-clouds</guid>
    </item>
  </channel>
</rss>
