<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 04 Mar 2023 09:12:27 +0000</lastBuildDate>
    <item>
      <title>The Forward-Forward Algorithm: Some Preliminary Investigations</title>
      <link>https://paperswithcode.com/paper/the-forward-forward-algorithm-some-1</link>
      <description><![CDATA[The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth further investigation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-forward-forward-algorithm-some-1</guid>
    </item>
    <item>
      <title>Discovering faster matrix multiplication algorithms with reinforcement learning</title>
      <link>https://paperswithcode.com/paper/discovering-faster-matrix-multiplication</link>
      <description><![CDATA[Particularly relevant is the case of 4 × 4 matrices in a finite field, where AlphaTensor’s algorithm improves on Strassen’s two-level algorithm for the first time, to our knowledge, since its discovery 50 years ago2.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/discovering-faster-matrix-multiplication</guid>
    </item>
    <item>
      <title>LLaMA: Open and Efficient Foundation Language Models</title>
      <link>https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</link>
      <description><![CDATA[We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-open-and-efficient-foundation-language-1</guid>
    </item>
    <item>
      <title>Composer: Creative and Controllable Image Synthesis with Composable Conditions</title>
      <link>https://paperswithcode.com/paper/composer-creative-and-controllable-image</link>
      <description><![CDATA[Recent large-scale generative models learned on big data are capable of synthesizing incredible images yet suffer from limited controllability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/composer-creative-and-controllable-image</guid>
    </item>
    <item>
      <title>SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks</title>
      <link>https://paperswithcode.com/paper/spikegpt-generative-pre-trained-language</link>
      <description><![CDATA[Spiking neural networks (SNNs) have emerged as an energy-efficient approach to deep learning that leverage sparse and event-driven activations to reduce the computational overhead associated with model inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/spikegpt-generative-pre-trained-language</guid>
    </item>
    <item>
      <title>More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models</title>
      <link>https://paperswithcode.com/paper/more-than-you-ve-asked-for-a-comprehensive</link>
      <description><![CDATA[In such attacks, an adversary can prompt the LLM to produce malicious content or override the original instructions and the employed filtering schemes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/more-than-you-ve-asked-for-a-comprehensive</guid>
    </item>
    <item>
      <title>ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth</title>
      <link>https://paperswithcode.com/paper/zoedepth-zero-shot-transfer-by-combining</link>
      <description><![CDATA[Finally, ZoeD-M12-NK is the first model that can jointly train on multiple datasets (NYU Depth v2 and KITTI) without a significant drop in performance and achieve unprecedented zero-shot generalization performance to eight unseen datasets from both indoor and outdoor domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zoedepth-zero-shot-transfer-by-combining</guid>
    </item>
    <item>
      <title>unilm</title>
      <link>https://github.com/microsoft/unilm</link>
      <description><![CDATA[Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities]]></description>
      <guid isPermaLink="true">https://github.com/microsoft/unilm</guid>
    </item>
    <item>
      <title>Adding Conditional Control to Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/adding-conditional-control-to-text-to-image</link>
      <description><![CDATA[Moreover, training a ControlNet is as fast as fine-tuning a diffusion model, and the model can be trained on a personal devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adding-conditional-control-to-text-to-image</guid>
    </item>
    <item>
      <title>VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion</title>
      <link>https://paperswithcode.com/paper/voxformer-sparse-voxel-transformer-for-camera</link>
      <description><![CDATA[To enable such capability in AI systems, we propose VoxFormer, a Transformer-based semantic scene completion framework that can output complete 3D volumetric semantics from only 2D images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/voxformer-sparse-voxel-transformer-for-camera</guid>
    </item>
    <item>
      <title>Efficient Teacher: Semi-Supervised Object Detection for YOLOv5</title>
      <link>https://paperswithcode.com/paper/efficient-teacher-semi-supervised-object</link>
      <description><![CDATA[The Pseudo Label Assigner prevents the occurrence of bias caused by a large number of low-quality pseudo labels that may interfere with the Dense Detector during the student-teacher mutual learning mechanism, and the Epoch Adaptor utilizes domain and distribution adaptation to allow Dense Detector to learn globally distributed consistent features, making the training independent of the proportion of labeled data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficient-teacher-semi-supervised-object</guid>
    </item>
    <item>
      <title>SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</title>
      <link>https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</link>
      <description><![CDATA[We propose SmoothQuant, a training-free, accuracy-preserving, and general-purpose post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit activation (W8A8) quantization for LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/smoothquant-accurate-and-efficient-post</guid>
    </item>
    <item>
      <title>AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities</title>
      <link>https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</link>
      <description><![CDATA[In this work, we present a conceptually simple and effective method to train a strong bilingual/multilingual multimodal representation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</guid>
    </item>
    <item>
      <title>OccDepth: A Depth-Aware Method for 3D Semantic Scene Completion</title>
      <link>https://paperswithcode.com/paper/occdepth-a-depth-aware-method-for-3d-semantic</link>
      <description><![CDATA[3D Semantic Scene Completion (SSC) can provide dense geometric and semantic scene representations, which can be applied in the field of autonomous driving and robotic systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/occdepth-a-depth-aware-method-for-3d-semantic</guid>
    </item>
    <item>
      <title>In-Context Instruction Learning</title>
      <link>https://paperswithcode.com/paper/in-context-instruction-learning</link>
      <description><![CDATA[Instruction learning of Large Language Models (LLMs) has enabled zero-shot task generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/in-context-instruction-learning</guid>
    </item>
    <item>
      <title>Multimodal Chain-of-Thought Reasoning in Language Models</title>
      <link>https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</link>
      <description><![CDATA[Large language models (LLMs) have shown impressive performance on complex reasoning by leveraging chain-of-thought (CoT) prompting to generate intermediate reasoning chains as the rationale to infer the answer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</guid>
    </item>
    <item>
      <title>Diffusion-based Generation, Optimization, and Planning in 3D Scenes</title>
      <link>https://paperswithcode.com/paper/diffusion-based-generation-optimization-and</link>
      <description><![CDATA[SceneDiffuser provides a unified model for solving scene-conditioned generation, optimization, and planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-based-generation-optimization-and</guid>
    </item>
    <item>
      <title>MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation</title>
      <link>https://paperswithcode.com/paper/multidiffusion-fusing-diffusion-paths-for</link>
      <description><![CDATA[In this work, we present MultiDiffusion, a unified framework that enables versatile and controllable image generation, using a pre-trained text-to-image diffusion model, without any further training or finetuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multidiffusion-fusing-diffusion-paths-for</guid>
    </item>
    <item>
      <title>Internet Explorer: Targeted Representation Learning on the Open Web</title>
      <link>https://paperswithcode.com/paper/internet-explorer-targeted-representation</link>
      <description><![CDATA[Modern vision models typically rely on fine-tuning general-purpose models pre-trained on large, static datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/internet-explorer-targeted-representation</guid>
    </item>
    <item>
      <title>LODE: Locally Conditioned Eikonal Implicit Scene Completion from Sparse LiDAR</title>
      <link>https://paperswithcode.com/paper/lode-locally-conditioned-eikonal-implicit</link>
      <description><![CDATA[In this paper, we propose a novel Eikonal formulation that conditions the implicit representation on localized shape priors which function as dense boundary value constraints, and demonstrate it works on SemanticKITTI and SemanticPOSS.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lode-locally-conditioned-eikonal-implicit</guid>
    </item>
  </channel>
</rss>
