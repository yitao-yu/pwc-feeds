<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 24 Nov 2022 09:13:42 +0000</lastBuildDate>
    <item>
      <title>DiffusionDet: Diffusion Model for Object Detection</title>
      <link>https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</link>
      <description><![CDATA[In inference, the model refines a set of randomly generated boxes to the output results in a progressive way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondet-diffusion-model-for-object</guid>
    </item>
    <item>
      <title>AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities</title>
      <link>https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</link>
      <description><![CDATA[In this work, we present a conceptually simple and effective method to train a strong bilingual/multilingual multimodal representation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</guid>
    </item>
    <item>
      <title>Galactica: A Large Language Model for Science</title>
      <link>https://paperswithcode.com/paper/galactica-a-large-language-model-for-science-1</link>
      <description><![CDATA[We believe these results demonstrate the potential for language models as a new interface for science.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/galactica-a-large-language-model-for-science-1</guid>
    </item>
    <item>
      <title>RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation</title>
      <link>https://paperswithcode.com/paper/renderdiffusion-image-diffusion-for-3d</link>
      <description><![CDATA[In this paper, we present RenderDiffusion as the first diffusion model for 3D generation and inference that can be trained using only monocular 2D supervision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/renderdiffusion-image-diffusion-for-3d</guid>
    </item>
    <item>
      <title>PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning</title>
      <link>https://paperswithcode.com/paper/pointclip-v2-adapting-clip-for-powerful-3d</link>
      <description><![CDATA[Contrastive Language-Image Pre-training (CLIP) has shown promising open-world performance on 2D image tasks, while its transferred capacity on 3D point clouds, i. e., PointCLIP, is still far from satisfactory.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pointclip-v2-adapting-clip-for-powerful-3d</guid>
    </item>
    <item>
      <title>ComMU: Dataset for Combinatorial Music Generation</title>
      <link>https://paperswithcode.com/paper/commu-dataset-for-combinatorial-music</link>
      <description><![CDATA[Commercial adoption of automatic music composition requires the capability of generating diverse and high-quality music suitable for the desired context (e. g., music for romantic movies, action games, restaurants, etc.).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/commu-dataset-for-combinatorial-music</guid>
    </item>
    <item>
      <title>Closed-form Continuous-time Neural Models</title>
      <link>https://paperswithcode.com/paper/closed-form-continuous-depth-models</link>
      <description><![CDATA[To this end, we compute a tightly-bounded approximation of the solution of an integral appearing in LTCs' dynamics, that has had no known closed-form solution so far.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/closed-form-continuous-depth-models</guid>
    </item>
    <item>
      <title>VeLO: Training Versatile Learned Optimizers by Scaling Up</title>
      <link>https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</link>
      <description><![CDATA[While deep learning models have replaced hand-designed features across many domains, these models are still trained with hand-designed optimizers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/velo-training-versatile-learned-optimizers-by</guid>
    </item>
    <item>
      <title>Versatile Diffusion: Text, Images and Variations All in One Diffusion Model</title>
      <link>https://paperswithcode.com/paper/versatile-diffusion-text-images-and</link>
      <description><![CDATA[Through our experiments, we demonstrate that VD and its underlying framework have the following merits: a) VD handles all subtasks with competitive quality; b) VD initiates novel extensions and applications such as disentanglement of style and semantic, image-text dual-guided generation, etc.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/versatile-diffusion-text-images-and</guid>
    </item>
    <item>
      <title>EVA: Exploring the Limits of Masked Visual Representation Learning at Scale</title>
      <link>https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</link>
      <description><![CDATA[We launch EVA, a vision-centric foundation model to explore the limits of visual representation at scale using only publicly accessible data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eva-exploring-the-limits-of-masked-visual</guid>
    </item>
    <item>
      <title>Fast Text-Conditional Discrete Denoising on Vector-Quantized Latent Spaces</title>
      <link>https://paperswithcode.com/paper/fast-text-conditional-discrete-denoising-on</link>
      <description><![CDATA[Conditional text-to-image generation has seen countless recent improvements in terms of quality, diversity and fidelity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-text-conditional-discrete-denoising-on</guid>
    </item>
    <item>
      <title>Diffusion Models for Medical Image Analysis: A Comprehensive Survey</title>
      <link>https://paperswithcode.com/paper/diffusion-models-for-medical-image-analysis-a</link>
      <description><![CDATA[Then, we provide a systematic taxonomy of diffusion models in the medical domain and propose a multi-perspective categorization based on their application, imaging modality, organ of interest, and algorithms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-models-for-medical-image-analysis-a</guid>
    </item>
    <item>
      <title>Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks</title>
      <link>https://paperswithcode.com/paper/relative-attributing-propagation-interpreting</link>
      <description><![CDATA[As Deep Neural Networks (DNNs) have demonstrated superhuman performance in a variety of fields, there is an increasing interest in understanding the complex internal mechanisms of DNNs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/relative-attributing-propagation-interpreting</guid>
    </item>
    <item>
      <title>All are Worth Words: A ViT Backbone for Diffusion Models</title>
      <link>https://paperswithcode.com/paper/all-are-worth-words-a-vit-backbone-for-score</link>
      <description><![CDATA[In particular, a latent diffusion model with a small U-ViT achieves a record-breaking FID of 5. 48 in text-to-image generation on MS-COCO, among methods without accessing large external datasets during the training of generative models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/all-are-worth-words-a-vit-backbone-for-score</guid>
    </item>
    <item>
      <title>BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View Recognition via Perspective Supervision</title>
      <link>https://paperswithcode.com/paper/bevformer-v2-adapting-modern-image-backbones</link>
      <description><![CDATA[The proposed method is verified with a wide spectrum of traditional and modern image backbones and achieves new SoTA results on the large-scale nuScenes dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bevformer-v2-adapting-modern-image-backbones</guid>
    </item>
    <item>
      <title>OneFormer: One Transformer to Rule Universal Image Segmentation</title>
      <link>https://paperswithcode.com/paper/oneformer-one-transformer-to-rule-universal</link>
      <description><![CDATA[However, such panoptic architectures do not truly unify image segmentation because they need to be trained individually on the semantic, instance, or panoptic segmentation to achieve the best performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/oneformer-one-transformer-to-rule-universal</guid>
    </item>
    <item>
      <title>A Closer Look at Learned Optimization: Stability, Robustness, and Inductive Biases</title>
      <link>https://paperswithcode.com/paper/a-closer-look-at-learned-optimization</link>
      <description><![CDATA[We apply the resulting learned optimizer to a variety of neural network training tasks, where it outperforms the current state of the art learned optimizer -- at matched optimizer computational overhead -- with regard to optimization performance and meta-training speed, and is capable of generalization to tasks far different from those it was meta-trained on.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-closer-look-at-learned-optimization</guid>
    </item>
    <item>
      <title>SinDiffusion: Learning a Diffusion Model from a Single Natural Image</title>
      <link>https://paperswithcode.com/paper/sindiffusion-learning-a-diffusion-model-from</link>
      <description><![CDATA[We present SinDiffusion, leveraging denoising diffusion models to capture internal distribution of patches from a single natural image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sindiffusion-learning-a-diffusion-model-from</guid>
    </item>
    <item>
      <title>MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained Object Detectors</title>
      <link>https://paperswithcode.com/paper/motrv2-bootstrapping-end-to-end-multi-object</link>
      <description><![CDATA[In this paper, we propose MOTRv2, a simple yet effective pipeline to bootstrap end-to-end multi-object tracking with a pretrained object detector.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/motrv2-bootstrapping-end-to-end-multi-object</guid>
    </item>
    <item>
      <title>Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked Modeling for Vision Decoding</title>
      <link>https://paperswithcode.com/paper/seeing-beyond-the-brain-conditional-diffusion</link>
      <description><![CDATA[In this work, we present MinD-Vis: Sparse Masked Brain Modeling with Double-Conditioned Latent Diffusion Model for Human Vision Decoding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seeing-beyond-the-brain-conditional-diffusion</guid>
    </item>
  </channel>
</rss>
