<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 12 Jun 2022 09:14:33 +0000</lastBuildDate>
    <item>
      <title>Zero-Shot Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/zero-shot-text-to-image-generation</link>
      <description><![CDATA[Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-text-to-image-generation</guid>
    </item>
    <item>
      <title>BigVGAN: A Universal Neural Vocoder with Large-Scale Training</title>
      <link>https://paperswithcode.com/paper/bigvgan-a-universal-neural-vocoder-with-large</link>
      <description><![CDATA[Despite recent progress in generative adversarial network(GAN)-based vocoders, where the model generates raw waveform conditioned on mel spectrogram, it is still challenging to synthesize high-fidelity audio for numerous speakers across varied recording environments.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bigvgan-a-universal-neural-vocoder-with-large</guid>
    </item>
    <item>
      <title>Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</title>
      <link>https://paperswithcode.com/paper/beyond-the-imitation-game-quantifying-and</link>
      <description><![CDATA[BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-the-imitation-game-quantifying-and</guid>
    </item>
    <item>
      <title>Multi-Scale High-Resolution Vision Transformer for Semantic Segmentation</title>
      <link>https://paperswithcode.com/paper/hrvit-multi-scale-high-resolution-vision</link>
      <description><![CDATA[Therefore, we propose HRViT, which enhances ViTs to learn semantically-rich and spatially-precise multi-scale representations by integrating high-resolution multi-branch architectures with ViTs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hrvit-multi-scale-high-resolution-vision</guid>
    </item>
    <item>
      <title>Demystifying MMD GANs</title>
      <link>https://paperswithcode.com/paper/demystifying-mmd-gans</link>
      <description><![CDATA[We investigate the training and performance of generative adversarial networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demystifying-mmd-gans</guid>
    </item>
    <item>
      <title>Vectorized and performance-portable Quicksort</title>
      <link>https://paperswithcode.com/paper/vectorized-and-performance-portable-quicksort</link>
      <description><![CDATA[Recent works showed that implementations of Quicksort using vector CPU instructions can outperform the non-vectorized algorithms in widespread use.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vectorized-and-performance-portable-quicksort</guid>
    </item>
    <item>
      <title>Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation</title>
      <link>https://paperswithcode.com/paper/mask-dino-towards-a-unified-transformer-based-1</link>
      <description><![CDATA[In this paper we present Mask DINO, a unified object detection and segmentation framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mask-dino-towards-a-unified-transformer-based-1</guid>
    </item>
    <item>
      <title>Towards Layer-wise Image Vectorization</title>
      <link>https://paperswithcode.com/paper/towards-layer-wise-image-vectorization-1</link>
      <description><![CDATA[Image rasterization is a mature technique in computer graphics, while image vectorization, the reverse path of rasterization, remains a major challenge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-layer-wise-image-vectorization-1</guid>
    </item>
    <item>
      <title>Diffusion-LM Improves Controllable Text Generation</title>
      <link>https://paperswithcode.com/paper/diffusion-lm-improves-controllable-text</link>
      <description><![CDATA[Controlling the behavior of language models (LMs) without re-training is a major open problem in natural language generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-lm-improves-controllable-text</guid>
    </item>
    <item>
      <title>Separable Self-attention for Mobile Vision Transformers</title>
      <link>https://paperswithcode.com/paper/separable-self-attention-for-mobile-vision</link>
      <description><![CDATA[The improved model, MobileViTv2, is state-of-the-art on several mobile vision tasks, including ImageNet object classification and MS-COCO object detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/separable-self-attention-for-mobile-vision</guid>
    </item>
    <item>
      <title>Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding</title>
      <link>https://paperswithcode.com/paper/photorealistic-text-to-image-diffusion-models</link>
      <description><![CDATA[We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/photorealistic-text-to-image-diffusion-models</guid>
    </item>
    <item>
      <title>PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies</title>
      <link>https://paperswithcode.com/paper/pointnext-revisiting-pointnet-with-improved</link>
      <description><![CDATA[In this work, we revisit the classical PointNet++ through a systematic study of model training and scaling strategies, and offer two major contributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pointnext-revisiting-pointnet-with-improved</guid>
    </item>
    <item>
      <title>Ivy: Templated Deep Learning for Inter-Framework Portability</title>
      <link>https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</link>
      <description><![CDATA[We introduce Ivy, a templated Deep Learning (DL) framework which abstracts existing DL frameworks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ivy-templated-deep-learning-for-inter</guid>
    </item>
    <item>
      <title>A Lightweight Instrument-Agnostic Model for Polyphonic Note Transcription and Multipitch Estimation</title>
      <link>https://paperswithcode.com/paper/a-lightweight-instrument-agnostic-model-for</link>
      <description><![CDATA[Despite its simplicity, benchmark results show our system's note estimation to be substantially better than a comparable baseline, and its frame-level accuracy to be only marginally below those of specialized state-of-the-art AMT systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-lightweight-instrument-agnostic-model-for</guid>
    </item>
    <item>
      <title>Kaleido-BERT: Vision-Language Pre-training on Fashion Domain</title>
      <link>https://paperswithcode.com/paper/kaleido-bert-vision-language-pre-training-on</link>
      <description><![CDATA[We present a new vision-language (VL) pre-training model dubbed Kaleido-BERT, which introduces a novel kaleido strategy for fashion cross-modality representations from transformers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/kaleido-bert-vision-language-pre-training-on</guid>
    </item>
    <item>
      <title>VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution</title>
      <link>https://paperswithcode.com/paper/videoinr-learning-video-implicit-neural-1</link>
      <description><![CDATA[The learned implicit neural representation can be decoded to videos of arbitrary spatial resolution and frame rate.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videoinr-learning-video-implicit-neural-1</guid>
    </item>
    <item>
      <title>OpenCalib: A Multi-sensor Calibration Toolbox for Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/opencalib-a-multi-sensor-calibration-toolbox</link>
      <description><![CDATA[To this end, we present OpenCalib, a calibration toolbox that contains a rich set of various sensor calibration methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/opencalib-a-multi-sensor-calibration-toolbox</guid>
    </item>
    <item>
      <title>DoWhy: Addressing Challenges in Expressing and Validating Causal Assumptions</title>
      <link>https://paperswithcode.com/paper/dowhy-addressing-challenges-in-expressing-and</link>
      <description><![CDATA[Estimation of causal effects involves crucial assumptions about the data-generating process, such as directionality of effect, presence of instrumental variables or mediators, and whether all relevant confounders are observed.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dowhy-addressing-challenges-in-expressing-and</guid>
    </item>
    <item>
      <title>Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework</title>
      <link>https://paperswithcode.com/paper/zero-and-r2d2-a-large-scale-chinese-cross</link>
      <description><![CDATA[Vision-language pre-training (VLP) on large-scale datasets has shown premier performance on various downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-and-r2d2-a-large-scale-chinese-cross</guid>
    </item>
    <item>
      <title>A ConvNet for the 2020s</title>
      <link>https://paperswithcode.com/paper/a-convnet-for-the-2020s</link>
      <description><![CDATA[The "Roaring 20s" of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-convnet-for-the-2020s</guid>
    </item>
  </channel>
</rss>
