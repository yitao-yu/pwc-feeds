<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 10 Nov 2024 21:07:43 +0000</lastBuildDate>
    <item>
      <title>Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent</title>
      <link>https://paperswithcode.com/paper/hunyuan-large-an-open-source-moe-model-with</link>
      <description><![CDATA[In this paper, we introduce Hunyuan-Large, which is currently the largest open-source Transformer-based mixture of experts model, with a total of 389 billion parameters and 52 billion activation parameters, capable of handling up to 256K tokens.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hunyuan-large-an-open-source-moe-model-with</guid>
    </item>
    <item>
      <title>Docling Technical Report</title>
      <link>https://paperswithcode.com/paper/docling-technical-report</link>
      <description><![CDATA[This technical report introduces Docling, an easy to use, self-contained, MIT-licensed open-source package for PDF document conversion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/docling-technical-report</guid>
    </item>
    <item>
      <title>TableGPT2: A Large Multimodal Model with Tabular Data Integration</title>
      <link>https://paperswithcode.com/paper/tablegpt2-a-large-multimodal-model-with</link>
      <description><![CDATA[In response, we introduce TableGPT2, a model rigorously pre-trained and fine-tuned with over 593. 8K tables and 2. 36M high-quality query-table-output tuples, a scale of table-related data unprecedented in prior research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tablegpt2-a-large-multimodal-model-with</guid>
    </item>
    <item>
      <title>ADOPT: Modified Adam Can Converge with Any $Î²_2$ with the Optimal Rate</title>
      <link>https://paperswithcode.com/paper/adopt-modified-adam-can-converge-with-any-b-2</link>
      <description><![CDATA[Adam is one of the most popular optimization algorithms in deep learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adopt-modified-adam-can-converge-with-any-b-2</guid>
    </item>
    <item>
      <title>HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems</title>
      <link>https://paperswithcode.com/paper/htmlrag-html-is-better-than-plain-text-for</link>
      <description><![CDATA[To alleviate this problem, we propose HtmlRAG, which uses HTML instead of plain text as the format of retrieved knowledge in RAG.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/htmlrag-html-is-better-than-plain-text-for</guid>
    </item>
    <item>
      <title>PromptFix: You Prompt and We Fix the Photo</title>
      <link>https://paperswithcode.com/paper/promptfix-you-prompt-and-we-fix-the-photo</link>
      <description><![CDATA[To address these limitations, we propose PromptFix, a comprehensive framework that enables diffusion models to follow human instructions to perform a wide variety of image-processing tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/promptfix-you-prompt-and-we-fix-the-photo</guid>
    </item>
    <item>
      <title>In-Context LoRA for Diffusion Transformers</title>
      <link>https://paperswithcode.com/paper/in-context-lora-for-diffusion-transformers</link>
      <description><![CDATA[While task-specific in terms of tuning data, our framework remains task-agnostic in architecture and pipeline, offering a powerful tool for the community and providing valuable insights for further research on product-level task-agnostic generation systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/in-context-lora-for-diffusion-transformers</guid>
    </item>
    <item>
      <title>OmniGen: Unified Image Generation</title>
      <link>https://paperswithcode.com/paper/omnigen-unified-image-generation</link>
      <description><![CDATA[In this work, we introduce OmniGen, a new diffusion model for unified image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnigen-unified-image-generation</guid>
    </item>
    <item>
      <title>PiML Toolbox for Interpretable Machine Learning Model Development and Diagnostics</title>
      <link>https://paperswithcode.com/paper/piml-toolbox-for-interpretable-machine</link>
      <description><![CDATA[PiML (read $\pi$-ML, /`pai`em`el/) is an integrated and open-access Python toolbox for interpretable machine learning model development and model diagnostics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/piml-toolbox-for-interpretable-machine</guid>
    </item>
    <item>
      <title>MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views</title>
      <link>https://paperswithcode.com/paper/mvsplat360-feed-forward-360-scene-synthesis</link>
      <description><![CDATA[To evaluate MVSplat360's performance, we introduce a new benchmark using the challenging DL3DV-10K dataset, where MVSplat360 achieves superior visual quality compared to state-of-the-art methods on wide-sweeping or even 360{\deg} NVS tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mvsplat360-feed-forward-360-scene-synthesis</guid>
    </item>
    <item>
      <title>WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/webrl-training-llm-web-agents-via-self</link>
      <description><![CDATA[Specifically, WebRL incorporates 1) a self-evolving curriculum that generates new tasks from unsuccessful attempts, 2) a robust outcome-supervised reward model (ORM), and 3) adaptive reinforcement learning strategies to ensure consistent improvements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/webrl-training-llm-web-agents-via-self</guid>
    </item>
    <item>
      <title>Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant</title>
      <link>https://paperswithcode.com/paper/ichigo-mixed-modal-early-fusion-realtime</link>
      <description><![CDATA[Large Language Models (LLMs) have revolutionized natural language processing, but their application to speech-based tasks remains challenging due to the complexities of integrating audio and text modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ichigo-mixed-modal-early-fusion-realtime</guid>
    </item>
    <item>
      <title>GameGen-X: Interactive Open-world Game Video Generation</title>
      <link>https://paperswithcode.com/paper/gamegen-x-interactive-open-world-game-video</link>
      <description><![CDATA[To realize this vision, we first collected and built an Open-World Video Game Dataset from scratch.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gamegen-x-interactive-open-world-game-video</guid>
    </item>
    <item>
      <title>Classification Done Right for Vision-Language Pre-Training</title>
      <link>https://paperswithcode.com/paper/classification-done-right-for-vision-language</link>
      <description><![CDATA[Due to the absence of the text encoding as contrastive target, SuperClass does not require a text encoder and does not need to maintain a large batch size as CLIP does.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/classification-done-right-for-vision-language</guid>
    </item>
    <item>
      <title>A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale</title>
      <link>https://paperswithcode.com/paper/a-distributed-data-parallel-pytorch</link>
      <description><![CDATA[It constructs a block-diagonal preconditioner where each block consists of a coarse Kronecker product approximation to full-matrix AdaGrad for each parameter of the neural network.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-distributed-data-parallel-pytorch</guid>
    </item>
    <item>
      <title>Addressing Representation Collapse in Vector Quantized Models with One Linear Layer</title>
      <link>https://paperswithcode.com/paper/addressing-representation-collapse-in-vector</link>
      <description><![CDATA[However, VQ models are often hindered by the problem of representation collapse in the latent space, which leads to low codebook utilization and limits the scalability of the codebook for large-scale training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/addressing-representation-collapse-in-vector</guid>
    </item>
    <item>
      <title>AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents</title>
      <link>https://paperswithcode.com/paper/androidlab-training-and-systematic</link>
      <description><![CDATA[It supports both large language models (LLMs) and multimodal models (LMMs) in the same action space.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/androidlab-training-and-systematic</guid>
    </item>
    <item>
      <title>DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation</title>
      <link>https://paperswithcode.com/paper/dreamclear-high-capacity-real-world-image</link>
      <description><![CDATA[Our second contribution, DreamClear, is a DiT-based image restoration model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamclear-high-capacity-real-world-image</guid>
    </item>
    <item>
      <title>No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images</title>
      <link>https://paperswithcode.com/paper/no-pose-no-problem-surprisingly-simple-3d</link>
      <description><![CDATA[We utilize the reconstructed 3D Gaussians for novel view synthesis and pose estimation tasks and propose a two-stage coarse-to-fine pipeline for accurate pose estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/no-pose-no-problem-surprisingly-simple-3d</guid>
    </item>
    <item>
      <title>Domain-Controlled Prompt Learning</title>
      <link>https://paperswithcode.com/paper/domain-controlled-prompt-learning</link>
      <description><![CDATA[Existing prompt learning methods often lack domain-awareness or domain-transfer mechanisms, leading to suboptimal performance due to the misinterpretation of specific images in natural image patterns.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/domain-controlled-prompt-learning</guid>
    </item>
  </channel>
</rss>
