<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 23 May 2023 09:11:58 +0000</lastBuildDate>
    <item>
      <title>Tree of Thoughts: Deliberate Problem Solving with Large Language Models</title>
      <link>https://paperswithcode.com/paper/tree-of-thoughts-deliberate-problem-solving</link>
      <description><![CDATA[Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tree-of-thoughts-deliberate-problem-solving</guid>
    </item>
    <item>
      <title>Sparks of Artificial General Intelligence: Early experiments with GPT-4</title>
      <link>https://paperswithcode.com/paper/sparks-of-artificial-general-intelligence</link>
      <description><![CDATA[We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sparks-of-artificial-general-intelligence</guid>
    </item>
    <item>
      <title>EasySpider: A No-Code Visual System for Crawling the Web</title>
      <link>https://paperswithcode.com/paper/easyspider-a-no-code-visual-system-for</link>
      <description><![CDATA[As such, web-crawling is an essential tool for both computational and non-computational scientists to conduct research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/easyspider-a-no-code-visual-system-for</guid>
    </item>
    <item>
      <title>SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities</title>
      <link>https://paperswithcode.com/paper/speechgpt-empowering-large-language-models</link>
      <description><![CDATA[Multi-modal large language models are regarded as a crucial step towards Artificial General Intelligence (AGI) and have garnered significant interest with the emergence of ChatGPT.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/speechgpt-empowering-large-language-models</guid>
    </item>
    <item>
      <title>CodeT5+: Open Code Large Language Models for Code Understanding and Generation</title>
      <link>https://paperswithcode.com/paper/codet5-open-code-large-language-models-for</link>
      <description><![CDATA[To address these limitations, we propose ``CodeT5+'', a family of encoder-decoder LLMs for code in which component modules can be flexibly combined to suit a wide range of downstream code tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/codet5-open-code-large-language-models-for</guid>
    </item>
    <item>
      <title>FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention</title>
      <link>https://paperswithcode.com/paper/fastcomposer-tuning-free-multi-subject-image</link>
      <description><![CDATA[FastComposer proposes delayed subject conditioning in the denoising step to maintain both identity and editability in subject-driven image generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fastcomposer-tuning-free-multi-subject-image</guid>
    </item>
    <item>
      <title>VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks</title>
      <link>https://paperswithcode.com/paper/visionllm-large-language-model-is-also-an</link>
      <description><![CDATA[We hope this model can set a new baseline for generalist vision and language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visionllm-large-language-model-is-also-an</guid>
    </item>
    <item>
      <title>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</title>
      <link>https://paperswithcode.com/paper/drag-your-gan-interactive-point-based</link>
      <description><![CDATA[Synthesizing visual content that meets users' needs often requires flexible and precise controllability of the pose, shape, expression, and layout of the generated objects.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/drag-your-gan-interactive-point-based</guid>
    </item>
    <item>
      <title>Reflexion: Language Agents with Verbal Reinforcement Learning</title>
      <link>https://paperswithcode.com/paper/reflexion-an-autonomous-agent-with-dynamic</link>
      <description><![CDATA[Large language models (LLMs) have been increasingly used to interact with external environments (e. g., games, compilers, APIs) as goal-driven agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reflexion-an-autonomous-agent-with-dynamic</guid>
    </item>
    <item>
      <title>ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities</title>
      <link>https://paperswithcode.com/paper/one-peace-exploring-one-general</link>
      <description><![CDATA[In this work, we explore a scalable way for building a general representation model toward unlimited modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/one-peace-exploring-one-general</guid>
    </item>
    <item>
      <title>LLM-Pruner: On the Structural Pruning of Large Language Models</title>
      <link>https://paperswithcode.com/paper/llm-pruner-on-the-structural-pruning-of-large</link>
      <description><![CDATA[With LLM being a general-purpose task solver, we explore its compression in a task-agnostic manner, which aims to preserve the multi-task solving and language generation ability of the original LLM.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-pruner-on-the-structural-pruning-of-large</guid>
    </item>
    <item>
      <title>Going Denser with Open-Vocabulary Part Segmentation</title>
      <link>https://paperswithcode.com/paper/going-denser-with-open-vocabulary-part</link>
      <description><![CDATA[In this paper, we propose a detector with the ability to predict both open-vocabulary objects and their part segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/going-denser-with-open-vocabulary-part</guid>
    </item>
    <item>
      <title>User-Controllable Latent Transformer for StyleGAN Image Layout Editing</title>
      <link>https://paperswithcode.com/paper/user-controllable-latent-transformer-for</link>
      <description><![CDATA[In our framework, the user annotates a StyleGAN image with locations they want to move or not and specifies a movement direction by mouse dragging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/user-controllable-latent-transformer-for</guid>
    </item>
    <item>
      <title>WebCPM: Interactive Web Search for Chinese Long-form Question Answering</title>
      <link>https://paperswithcode.com/paper/webcpm-interactive-web-search-for-chinese</link>
      <description><![CDATA[We recruit annotators to search for relevant information using our interface and then answer questions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/webcpm-interactive-web-search-for-chinese</guid>
    </item>
    <item>
      <title>string2string: A Modern Python Library for String-to-String Algorithms</title>
      <link>https://paperswithcode.com/paper/string2string-a-modern-python-library-for</link>
      <description><![CDATA[It includes traditional algorithmic solutions as well as recent advanced neural approaches to tackle various problems in string alignment, distance measurement, lexical and semantic search, and similarity analysis -- along with several helpful visualization tools and metrics to facilitate the interpretation and analysis of these methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/string2string-a-modern-python-library-for</guid>
    </item>
    <item>
      <title>Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network for Surgical Tools Segmentation</title>
      <link>https://paperswithcode.com/paper/min-max-similarity-a-contrastive-learning</link>
      <description><![CDATA[In contrast to the previous state-of-the-art, we introduce Min-Max Similarity (MMS), a contrastive learning form of dual-view training by employing classifiers and projectors to build all-negative, and positive and negative feature pairs, respectively, to formulate the learning as solving a MMS problem.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/min-max-similarity-a-contrastive-learning</guid>
    </item>
    <item>
      <title>C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models</title>
      <link>https://paperswithcode.com/paper/c-eval-a-multi-level-multi-discipline-chinese</link>
      <description><![CDATA[We present C-Eval, the first comprehensive Chinese evaluation suite designed to assess advanced knowledge and reasoning abilities of foundation models in a Chinese context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/c-eval-a-multi-level-multi-discipline-chinese</guid>
    </item>
    <item>
      <title>HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion</title>
      <link>https://paperswithcode.com/paper/humanrf-high-fidelity-neural-radiance-fields</link>
      <description><![CDATA[To close the gap to production-level quality, we introduce HumanRF, a 4D dynamic neural scene representation that captures full-body appearance in motion from multi-view video input, and enables playback from novel, unseen viewpoints.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/humanrf-high-fidelity-neural-radiance-fields</guid>
    </item>
    <item>
      <title>Listen, Think, and Understand</title>
      <link>https://paperswithcode.com/paper/listen-think-and-understand</link>
      <description><![CDATA[In this paper, we propose a novel audio foundation model, called LTU (Listen, Think, and Understand).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/listen-think-and-understand</guid>
    </item>
    <item>
      <title>StructGPT: A General Framework for Large Language Model to Reason over Structured Data</title>
      <link>https://paperswithcode.com/paper/structgpt-a-general-framework-for-large</link>
      <description><![CDATA[Specially, we propose an \emph{invoking-linearization-generation} procedure to support LLMs in reasoning on the structured data with the help of the external interfaces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structgpt-a-general-framework-for-large</guid>
    </item>
  </channel>
</rss>
