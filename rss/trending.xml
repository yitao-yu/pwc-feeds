<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 16 Mar 2024 21:06:02 +0000</lastBuildDate>
    <item>
      <title>Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small</title>
      <link>https://paperswithcode.com/paper/interpretability-in-the-wild-a-circuit-for</link>
      <description><![CDATA[Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/interpretability-in-the-wild-a-circuit-for</guid>
    </item>
    <item>
      <title>DeepSeek-VL: Towards Real-World Vision-Language Understanding</title>
      <link>https://paperswithcode.com/paper/deepseek-vl-towards-real-world-vision</link>
      <description><![CDATA[The DeepSeek-VL family (both 1. 3B and 7B models) showcases superior user experiences as a vision-language chatbot in real-world applications, achieving state-of-the-art or competitive performance across a wide range of visual-language benchmarks at the same model size while maintaining robust performance on language-centric benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseek-vl-towards-real-world-vision</guid>
    </item>
    <item>
      <title>Chronos: Learning the Language of Time Series</title>
      <link>https://paperswithcode.com/paper/chronos-learning-the-language-of-time-series</link>
      <description><![CDATA[We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chronos-learning-the-language-of-time-series</guid>
    </item>
    <item>
      <title>VideoMamba: State Space Model for Efficient Video Understanding</title>
      <link>https://paperswithcode.com/paper/videomamba-state-space-model-for-efficient</link>
      <description><![CDATA[Addressing the dual challenges of local redundancy and global dependencies in video understanding, this work innovatively adapts the Mamba to the video domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/videomamba-state-space-model-for-efficient</guid>
    </item>
    <item>
      <title>V3D: Video Diffusion Models are Effective 3D Generators</title>
      <link>https://paperswithcode.com/paper/v3d-video-diffusion-models-are-effective-3d</link>
      <description><![CDATA[To fully unleash the potential of video diffusion to perceive the 3D world, we further introduce geometrical consistency prior and extend the video diffusion model to a multi-view consistent 3D generator.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/v3d-video-diffusion-models-are-effective-3d</guid>
    </item>
    <item>
      <title>DragAnything: Motion Control for Anything using Entity Representation</title>
      <link>https://paperswithcode.com/paper/draganything-motion-control-for-anything</link>
      <description><![CDATA[We introduce DragAnything, which utilizes a entity representation to achieve motion control for any object in controllable video generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/draganything-motion-control-for-anything</guid>
    </item>
    <item>
      <title>MoAI: Mixture of All Intelligence for Large Language and Vision Models</title>
      <link>https://paperswithcode.com/paper/moai-mixture-of-all-intelligence-for-large</link>
      <description><![CDATA[Therefore, we present a new LLVM, Mixture of All Intelligence (MoAI), which leverages auxiliary visual information obtained from the outputs of external segmentation, detection, SGG, and OCR models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/moai-mixture-of-all-intelligence-for-large</guid>
    </item>
    <item>
      <title>Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study</title>
      <link>https://paperswithcode.com/paper/towards-general-computer-control-a-multimodal</link>
      <description><![CDATA[Despite the success in specific tasks and scenarios, existing foundation agents, empowered by large models (LMs) and advanced tools, still cannot generalize to different scenarios, mainly due to dramatic differences in the observations and actions across scenarios.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-general-computer-control-a-multimodal</guid>
    </item>
    <item>
      <title>Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts</title>
      <link>https://paperswithcode.com/paper/follow-your-click-open-domain-regional-image</link>
      <description><![CDATA[Despite recent advances in image-to-video generation, better controllability and local animation are less explored.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/follow-your-click-open-domain-regional-image</guid>
    </item>
    <item>
      <title>Extreme Compression of Large Language Models via Additive Quantization</title>
      <link>https://paperswithcode.com/paper/extreme-compression-of-large-language-models</link>
      <description><![CDATA[The emergence of accurate open large language models (LLMs) has led to a race towards quantization techniques for such models enabling execution on end-user devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extreme-compression-of-large-language-models</guid>
    </item>
    <item>
      <title>Animatable Gaussians: Learning Pose-dependent Gaussian Maps for High-fidelity Human Avatar Modeling</title>
      <link>https://paperswithcode.com/paper/animatable-gaussians-learning-pose-dependent</link>
      <description><![CDATA[Overall, our method can create lifelike avatars with dynamic, realistic and generalized appearances.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatable-gaussians-learning-pose-dependent</guid>
    </item>
    <item>
      <title>SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection</title>
      <link>https://paperswithcode.com/paper/sardet-100k-towards-open-source-benchmark-and</link>
      <description><![CDATA[To the best of our knowledge, SARDet-100K is the first COCO-level large-scale multi-class SAR object detection dataset ever created.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sardet-100k-towards-open-source-benchmark-and</guid>
    </item>
    <item>
      <title>Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding</title>
      <link>https://paperswithcode.com/paper/sequoia-scalable-robust-and-hardware-aware</link>
      <description><![CDATA[This paper introduces Sequoia, a scalable, robust, and hardware-aware algorithm for speculative decoding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sequoia-scalable-robust-and-hardware-aware</guid>
    </item>
    <item>
      <title>SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/splattingavatar-realistic-real-time-human</link>
      <description><![CDATA[We present SplattingAvatar, a hybrid 3D representation of photorealistic human avatars with Gaussian Splatting embedded on a triangle mesh, which renders over 300 FPS on a modern GPU and 30 FPS on a mobile device.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/splattingavatar-realistic-real-time-human</guid>
    </item>
    <item>
      <title>TripoSR: Fast 3D Object Reconstruction from a Single Image</title>
      <link>https://paperswithcode.com/paper/triposr-fast-3d-object-reconstruction-from-a</link>
      <description><![CDATA[This technical report introduces TripoSR, a 3D reconstruction model leveraging transformer architecture for fast feed-forward 3D generation, producing 3D mesh from a single image in under 0. 5 seconds.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/triposr-fast-3d-object-reconstruction-from-a</guid>
    </item>
    <item>
      <title>OOTDiffusion: Outfitting Fusion based Latent Diffusion for Controllable Virtual Try-on</title>
      <link>https://paperswithcode.com/paper/ootdiffusion-outfitting-fusion-based-latent</link>
      <description><![CDATA[We present OOTDiffusion, a novel network architecture for realistic and controllable image-based virtual try-on (VTON).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ootdiffusion-outfitting-fusion-based-latent</guid>
    </item>
    <item>
      <title>Scattered Mixture-of-Experts Implementation</title>
      <link>https://paperswithcode.com/paper/scattered-mixture-of-experts-implementation</link>
      <description><![CDATA[We present ScatterMoE, an implementation of Sparse Mixture-of-Experts (SMoE) on GPUs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scattered-mixture-of-experts-implementation</guid>
    </item>
    <item>
      <title>Language Agents as Optimizable Graphs</title>
      <link>https://paperswithcode.com/paper/language-agents-as-optimizable-graphs</link>
      <description><![CDATA[Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-agents-as-optimizable-graphs</guid>
    </item>
    <item>
      <title>GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection</title>
      <link>https://paperswithcode.com/paper/galore-memory-efficient-llm-training-by</link>
      <description><![CDATA[Our approach reduces memory usage by up to 65. 5% in optimizer states while maintaining both efficiency and performance for pre-training on LLaMA 1B and 7B architectures with C4 dataset with up to 19. 7B tokens, and on fine-tuning RoBERTa on GLUE tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/galore-memory-efficient-llm-training-by</guid>
    </item>
    <item>
      <title>Language models scale reliably with over-training and on downstream tasks</title>
      <link>https://paperswithcode.com/paper/language-models-scale-reliably-with-over</link>
      <description><![CDATA[We fit scaling laws that extrapolate in both the number of model parameters and the ratio of training tokens to parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/language-models-scale-reliably-with-over</guid>
    </item>
  </channel>
</rss>
