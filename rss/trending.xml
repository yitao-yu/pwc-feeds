<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 14 Feb 2024 21:07:04 +0000</lastBuildDate>
    <item>
      <title>Guiding Instruction-based Image Editing via Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/guiding-instruction-based-image-editing-via</link>
      <description><![CDATA[Extensive experimental results demonstrate that expressive instructions are crucial to instruction-based image editing, and our MGIE can lead to a notable improvement in automatic metrics and human evaluation while maintaining competitive inference efficiency.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/guiding-instruction-based-image-editing-via</guid>
    </item>
    <item>
      <title>Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models</title>
      <link>https://paperswithcode.com/paper/self-play-fine-tuning-converts-weak-language</link>
      <description><![CDATA[In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-play-fine-tuning-converts-weak-language</guid>
    </item>
    <item>
      <title>GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information</title>
      <link>https://paperswithcode.com/paper/genegpt-teaching-large-language-models-to-use</link>
      <description><![CDATA[In this paper, we present GeneGPT, a novel method for teaching LLMs to use the Web APIs of the National Center for Biotechnology Information (NCBI) for answering genomics questions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/genegpt-teaching-large-language-models-to-use</guid>
    </item>
    <item>
      <title>The boundary of neural network trainability is fractal</title>
      <link>https://paperswithcode.com/paper/the-boundary-of-neural-network-trainability</link>
      <description><![CDATA[Some fractals -- for instance those associated with the Mandelbrot and quadratic Julia sets -- are computed by iterating a function, and identifying the boundary between hyperparameters for which the resulting series diverges or remains bounded.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-boundary-of-neural-network-trainability</guid>
    </item>
    <item>
      <title>Learning to Fly in Seconds</title>
      <link>https://paperswithcode.com/paper/learning-to-fly-in-seconds</link>
      <description><![CDATA[Our framework enables Simulation-to-Reality (Sim2Real) transfer for direct RPM control after only 18 seconds of training on a consumer-grade laptop as well as its deployment on microcontrollers to control a multirotor under real-time guarantees.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-fly-in-seconds</guid>
    </item>
    <item>
      <title>Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting</title>
      <link>https://paperswithcode.com/paper/lag-llama-towards-foundation-models-for-time</link>
      <description><![CDATA[Over the past years, foundation models have caused a paradigm shift in machine learning due to their unprecedented capabilities for zero-shot and few-shot generalization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lag-llama-towards-foundation-models-for-time</guid>
    </item>
    <item>
      <title>YOLO-World: Real-Time Open-Vocabulary Object Detection</title>
      <link>https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</link>
      <description><![CDATA[The You Only Look Once (YOLO) series of detectors have established themselves as efficient and practical tools.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/yolo-world-real-time-open-vocabulary-object</guid>
    </item>
    <item>
      <title>Fast Timing-Conditioned Latent Audio Diffusion</title>
      <link>https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</link>
      <description><![CDATA[Generating long-form 44. 1kHz stereo audio from text prompts can be computationally demanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</guid>
    </item>
    <item>
      <title>Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception</title>
      <link>https://paperswithcode.com/paper/mobile-agent-autonomous-multi-modal-mobile</link>
      <description><![CDATA[To assess the performance of Mobile-Agent, we introduced Mobile-Eval, a benchmark for evaluating mobile device operations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mobile-agent-autonomous-multi-modal-mobile</guid>
    </item>
    <item>
      <title>Learning a Decision Tree Algorithm with Transformers</title>
      <link>https://paperswithcode.com/paper/learning-a-decision-tree-algorithm-with</link>
      <description><![CDATA[We then train MetaTree to produce the trees that achieve strong generalization performance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-a-decision-tree-algorithm-with</guid>
    </item>
    <item>
      <title>DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors</title>
      <link>https://paperswithcode.com/paper/dynamicrafter-animating-open-domain-images</link>
      <description><![CDATA[Animating a still image offers an engaging visual experience.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dynamicrafter-animating-open-domain-images</guid>
    </item>
    <item>
      <title>Self-Discover: Large Language Models Self-Compose Reasoning Structures</title>
      <link>https://paperswithcode.com/paper/self-discover-large-language-models-self</link>
      <description><![CDATA[We introduce SELF-DISCOVER, a general framework for LLMs to self-discover the task-intrinsic reasoning structures to tackle complex reasoning problems that are challenging for typical prompting methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/self-discover-large-language-models-self</guid>
    </item>
    <item>
      <title>Forgedit: Text Guided Image Editing via Learning and Forgetting</title>
      <link>https://paperswithcode.com/paper/forgedit-text-guided-image-editing-via</link>
      <description><![CDATA[Text guided image editing on real images given only the image and the target text prompt as inputs, is a very general and challenging problem, which requires the editing model to reason by itself which part of the image should be edited, to preserve the characteristics of original image, and also to perform complicated non-rigid editing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/forgedit-text-guided-image-editing-via</guid>
    </item>
    <item>
      <title>DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</title>
      <link>https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</link>
      <description><![CDATA[Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepseekmath-pushing-the-limits-of</guid>
    </item>
    <item>
      <title>OLMo: Accelerating the Science of Language Models</title>
      <link>https://paperswithcode.com/paper/olmo-accelerating-the-science-of-language</link>
      <description><![CDATA[Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community to have access to powerful, truly open LMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/olmo-accelerating-the-science-of-language</guid>
    </item>
    <item>
      <title>PokéLLMon: A Human-Parity Agent for Pokémon Battles with Large Language Models</title>
      <link>https://paperswithcode.com/paper/pokellmon-a-human-parity-agent-for-pokemon</link>
      <description><![CDATA[We introduce \textsc{Pok\'eLLMon}, the first LLM-embodied agent that achieves human-parity performance in tactical battle games, as demonstrated in Pok\'emon battles.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pokellmon-a-human-parity-agent-for-pokemon</guid>
    </item>
    <item>
      <title>LESS: Selecting Influential Data for Targeted Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/less-selecting-influential-data-for-targeted</link>
      <description><![CDATA[Instruction tuning has unlocked powerful capabilities in large language models (LLMs), effectively using combined datasets to develop generalpurpose chatbots.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/less-selecting-influential-data-for-targeted</guid>
    </item>
    <item>
      <title>InstantID: Zero-shot Identity-Preserving Generation in Seconds</title>
      <link>https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</link>
      <description><![CDATA[There has been significant progress in personalized image synthesis with methods such as Textual Inversion, DreamBooth, and LoRA.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantid-zero-shot-identity-preserving</guid>
    </item>
    <item>
      <title>BiLLM: Pushing the Limit of Post-Training Quantization for LLMs</title>
      <link>https://paperswithcode.com/paper/billm-pushing-the-limit-of-post-training</link>
      <description><![CDATA[Pretrained large language models (LLMs) exhibit exceptional general language processing capabilities but come with significant demands on memory and computational resources.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/billm-pushing-the-limit-of-post-training</guid>
    </item>
    <item>
      <title>MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</title>
      <link>https://paperswithcode.com/paper/multihop-rag-benchmarking-retrieval-augmented</link>
      <description><![CDATA[We hope MultiHop-RAG will be a valuable resource for the community in developing effective RAG systems, thereby facilitating greater adoption of LLMs in practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multihop-rag-benchmarking-retrieval-augmented</guid>
    </item>
  </channel>
</rss>
