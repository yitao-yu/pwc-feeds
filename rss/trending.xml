<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 28 Oct 2022 21:08:24 +0000</lastBuildDate>
    <item>
      <title>High Fidelity Neural Audio Compression</title>
      <link>https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</link>
      <description><![CDATA[We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/high-fidelity-neural-audio-compression</guid>
    </item>
    <item>
      <title>DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models</title>
      <link>https://paperswithcode.com/paper/diffusiondb-a-large-scale-prompt-gallery</link>
      <description><![CDATA[We analyze prompts in the dataset and discuss key properties of these prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusiondb-a-large-scale-prompt-gallery</guid>
    </item>
    <item>
      <title>TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second</title>
      <link>https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</link>
      <description><![CDATA[We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-learning-a-real-time-tabular-automl</guid>
    </item>
    <item>
      <title>MetaFormer Baselines for Vision</title>
      <link>https://paperswithcode.com/paper/metaformer-baselines-for-vision</link>
      <description><![CDATA[By simply applying depthwise separable convolutions as token mixer in the bottom stages and vanilla self-attention in the top stages, the resulting model CAFormer sets a new record on ImageNet-1K: it achieves an accuracy of 85. 5% at 224x224 resolution, under normal supervised training without external data or distillation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/metaformer-baselines-for-vision</guid>
    </item>
    <item>
      <title>S3E: A Large-scale Multimodal Dataset for Collaborative SLAM</title>
      <link>https://paperswithcode.com/paper/s3e-a-large-scale-multimodal-dataset-for</link>
      <description><![CDATA[With the advanced request to employ a team of robots to perform a task collaboratively, the research community has become increasingly interested in collaborative simultaneous localization and mapping.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/s3e-a-large-scale-multimodal-dataset-for</guid>
    </item>
    <item>
      <title>Musika! Fast Infinite Waveform Music Generation</title>
      <link>https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</link>
      <description><![CDATA[We release the source code and pretrained autoencoder weights at github. com/marcoppasini/musika, such that a GAN can be trained on a new music domain with a single GPU in a matter of hours.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/musika-fast-infinite-waveform-music</guid>
    </item>
    <item>
      <title>Poisson Flow Generative Models</title>
      <link>https://paperswithcode.com/paper/poisson-flow-generative-models</link>
      <description><![CDATA[We interpret the data points as electrical charges on the $z=0$ hyperplane in a space augmented with an additional dimension $z$, generating a high-dimensional electric field (the gradient of the solution to Poisson equation).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/poisson-flow-generative-models</guid>
    </item>
    <item>
      <title>Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera</title>
      <link>https://paperswithcode.com/paper/neural-surface-reconstruction-of-dynamic</link>
      <description><![CDATA[We propose Neural-DynamicReconstruction (NDR), a template-free method to recover high-fidelity geometry and motions of a dynamic scene from a monocular RGB-D camera.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-surface-reconstruction-of-dynamic</guid>
    </item>
    <item>
      <title>Structure-based Drug Design with Equivariant Diffusion Models</title>
      <link>https://paperswithcode.com/paper/structure-based-drug-design-with-equivariant</link>
      <description><![CDATA[In this paper, we formulate SBDD as a 3D-conditional generation problem and present DiffSBDD, an E(3)-equivariant 3D-conditional diffusion model that generates novel ligands conditioned on protein pockets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/structure-based-drug-design-with-equivariant</guid>
    </item>
    <item>
      <title>On the Versatile Uses of Partial Distance Correlation in Deep Learning</title>
      <link>https://paperswithcode.com/paper/on-the-versatile-uses-of-partial-distance</link>
      <description><![CDATA[Comparing the functional behavior of neural network models, whether it is a single network over time or two (or more networks) during or post-training, is an essential step in understanding what they are learning (and what they are not), and for identifying strategies for regularization or efficiency improvements.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/on-the-versatile-uses-of-partial-distance</guid>
    </item>
    <item>
      <title>DeepNet: Scaling Transformers to 1,000 Layers</title>
      <link>https://paperswithcode.com/paper/deepnet-scaling-transformers-to-1000-layers</link>
      <description><![CDATA[In this paper, we propose a simple yet effective method to stabilize extremely deep Transformers.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deepnet-scaling-transformers-to-1000-layers</guid>
    </item>
    <item>
      <title>Contrastive Search Is What You Need For Neural Text Generation</title>
      <link>https://paperswithcode.com/paper/contrastive-search-is-what-you-need-for</link>
      <description><![CDATA[Based on our findings, we further assess the contrastive search decoding method using off-the-shelf LMs on four generation tasks across 16 languages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/contrastive-search-is-what-you-need-for</guid>
    </item>
    <item>
      <title>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</title>
      <link>https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</link>
      <description><![CDATA[Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image</guid>
    </item>
    <item>
      <title>Personalizing Text-to-Image Generation via Aesthetic Gradients</title>
      <link>https://paperswithcode.com/paper/personalizing-text-to-image-generation-via</link>
      <description><![CDATA[This work proposes aesthetic gradients, a method to personalize a CLIP-conditioned diffusion model by guiding the generative process towards custom aesthetics defined by the user from a set of images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/personalizing-text-to-image-generation-via</guid>
    </item>
    <item>
      <title>Prompt-to-Prompt Image Editing with Cross Attention Control</title>
      <link>https://paperswithcode.com/paper/prompt-to-prompt-image-editing-with-cross</link>
      <description><![CDATA[Editing is challenging for these generative models, since an innate property of an editing technique is to preserve most of the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prompt-to-prompt-image-editing-with-cross</guid>
    </item>
    <item>
      <title>Evaluating Long-Term Memory in 3D Mazes</title>
      <link>https://paperswithcode.com/paper/evaluating-long-term-memory-in-3d-mazes</link>
      <description><![CDATA[However, most benchmark tasks in reinforcement learning do not test long-term memory in agents, slowing down progress in this important research direction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-long-term-memory-in-3d-mazes</guid>
    </item>
    <item>
      <title>Token Merging: Your ViT But Faster</title>
      <link>https://paperswithcode.com/paper/token-merging-your-vit-but-faster</link>
      <description><![CDATA[Off-the-shelf, ToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518 models on images and 2. 2x the throughput of ViT-L on video with only a 0. 2-0. 3% accuracy drop in each case.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/token-merging-your-vit-but-faster</guid>
    </item>
    <item>
      <title>torchode: A Parallel ODE Solver for PyTorch</title>
      <link>https://paperswithcode.com/paper/torchode-a-parallel-ode-solver-for-pytorch</link>
      <description><![CDATA[We introduce an ODE solver for the PyTorch ecosystem that can solve multiple ODEs in parallel independently from each other while achieving significant performance gains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/torchode-a-parallel-ode-solver-for-pytorch</guid>
    </item>
    <item>
      <title>DreamFusion: Text-to-3D using 2D Diffusion</title>
      <link>https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</link>
      <description><![CDATA[Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dreamfusion-text-to-3d-using-2d-diffusion</guid>
    </item>
    <item>
      <title>G-Rep: Gaussian Representation for Arbitrary-Oriented Object Detection</title>
      <link>https://paperswithcode.com/paper/g-rep-gaussian-representation-for-arbitrary</link>
      <description><![CDATA[Then, three optional Gaussian metrics are explored to optimize the regression loss of the detector because of their excellent parameter optimization mechanisms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/g-rep-gaussian-representation-for-arbitrary</guid>
    </item>
  </channel>
</rss>
