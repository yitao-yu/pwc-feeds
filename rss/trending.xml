<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sun, 08 Jan 2023 21:06:18 +0000</lastBuildDate>
    <item>
      <title>ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders</title>
      <link>https://paperswithcode.com/paper/convnext-v2-co-designing-and-scaling-convnets</link>
      <description><![CDATA[This co-design of self-supervised learning techniques and architectural improvement results in a new model family called ConvNeXt V2, which significantly improves the performance of pure ConvNets on various recognition benchmarks, including ImageNet classification, COCO detection, and ADE20K segmentation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/convnext-v2-co-designing-and-scaling-convnets</guid>
    </item>
    <item>
      <title>Attention Is All You Need</title>
      <link>https://paperswithcode.com/paper/attention-is-all-you-need</link>
      <description><![CDATA[The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/attention-is-all-you-need</guid>
    </item>
    <item>
      <title>Muse: Text-To-Image Generation via Masked Generative Transformers</title>
      <link>https://paperswithcode.com/paper/muse-text-to-image-generation-via-masked</link>
      <description><![CDATA[Compared to pixel-space diffusion models, such as Imagen and DALL-E 2, Muse is significantly more efficient due to the use of discrete tokens and requiring fewer sampling iterations; compared to autoregressive models, such as Parti, Muse is more efficient due to the use of parallel decoding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/muse-text-to-image-generation-via-masked</guid>
    </item>
    <item>
      <title>Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training</title>
      <link>https://paperswithcode.com/paper/colossal-ai-a-unified-deep-learning-system</link>
      <description><![CDATA[The success of Transformer models has pushed the deep learning model scale to billions of parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/colossal-ai-a-unified-deep-learning-system</guid>
    </item>
    <item>
      <title>PACO: Parts and Attributes of Common Objects</title>
      <link>https://paperswithcode.com/paper/paco-parts-and-attributes-of-common-objects</link>
      <description><![CDATA[This motivates the need for large datasets which go beyond traditional object masks and provide richer annotations such as part masks and attributes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/paco-parts-and-attributes-of-common-objects</guid>
    </item>
    <item>
      <title>HyperReel: High-Fidelity 6-DoF Video with Ray-Conditioned Sampling</title>
      <link>https://paperswithcode.com/paper/hyperreel-high-fidelity-6-dof-video-with-ray</link>
      <description><![CDATA[Volumetric scene representations enable photorealistic view synthesis for static scenes and form the basis of several existing 6-DoF video techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hyperreel-high-fidelity-6-dof-video-with-ray</guid>
    </item>
    <item>
      <title>GLM-130B: An Open Bilingual Pre-trained Model</title>
      <link>https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</link>
      <description><![CDATA[We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</guid>
    </item>
    <item>
      <title>Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal</title>
      <link>https://paperswithcode.com/paper/reasoning-over-different-types-of-knowledge</link>
      <description><![CDATA[The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reasoning-over-different-types-of-knowledge</guid>
    </item>
    <item>
      <title>Cramming: Training a Language Model on a Single GPU in One Day</title>
      <link>https://paperswithcode.com/paper/cramming-training-a-language-model-on-a</link>
      <description><![CDATA[Recent trends in language modeling have focused on increasing performance through scaling, and have resulted in an environment where training language models is out of reach for most researchers and practitioners.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cramming-training-a-language-model-on-a</guid>
    </item>
    <item>
      <title>Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data</title>
      <link>https://paperswithcode.com/paper/diffusion-probabilistic-models-for-scene</link>
      <description><![CDATA[To the best of our knowledge, our work is the first to apply discrete and latent diffusion for 3D categorical data on a scene-scale.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/diffusion-probabilistic-models-for-scene</guid>
    </item>
    <item>
      <title>A Survey for In-context Learning</title>
      <link>https://paperswithcode.com/paper/a-survey-for-in-context-learning</link>
      <description><![CDATA[With the increasing ability of large language models (LLMs), in-context learning (ICL) has become a new paradigm for natural language processing (NLP), where LLMs make predictions only based on contexts augmented with a few training examples.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-for-in-context-learning</guid>
    </item>
    <item>
      <title>Cross Modal Transformer via Coordinates Encoding for 3D Object Dectection</title>
      <link>https://paperswithcode.com/paper/cross-modal-transformer-via-coordinates</link>
      <description><![CDATA[In this paper, we propose a robust 3D detector, named Cross Modal Transformer (CMT), for end-to-end 3D multi-modal detection.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-modal-transformer-via-coordinates</guid>
    </item>
    <item>
      <title>ALIKE: Accurate and Lightweight Keypoint Detection and Descriptor Extraction</title>
      <link>https://paperswithcode.com/paper/alike-accurate-and-lightweight-keypoint</link>
      <description><![CDATA[The reprojection loss is then proposed to directly optimize these sub-pixel keypoints, and the dispersity peak loss is presented for accurate keypoints regularization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/alike-accurate-and-lightweight-keypoint</guid>
    </item>
    <item>
      <title>Scaling Language-Image Pre-training via Masking</title>
      <link>https://paperswithcode.com/paper/scaling-language-image-pre-training-via</link>
      <description><![CDATA[We present Fast Language-Image Pre-training (FLIP), a simple and more efficient method for training CLIP.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-language-image-pre-training-via</guid>
    </item>
    <item>
      <title>Point-E: A System for Generating 3D Point Clouds from Complex Prompts</title>
      <link>https://paperswithcode.com/paper/point-e-a-system-for-generating-3d-point</link>
      <description><![CDATA[This is in stark contrast to state-of-the-art generative image models, which produce samples in a number of seconds or minutes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/point-e-a-system-for-generating-3d-point</guid>
    </item>
    <item>
      <title>Goal-oriented Autonomous Driving</title>
      <link>https://paperswithcode.com/paper/goal-oriented-autonomous-driving</link>
      <description><![CDATA[Modern autonomous driving system is characterized as modular tasks in sequential order, i. e., perception, prediction and planning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/goal-oriented-autonomous-driving</guid>
    </item>
    <item>
      <title>Box2Mask: Box-supervised Instance Segmentation via Level-set Evolution</title>
      <link>https://paperswithcode.com/paper/box2mask-box-supervised-instance-segmentation</link>
      <description><![CDATA[In contrast to fully supervised methods using pixel-wise mask labels, box-supervised instance segmentation takes advantage of simple box annotations, which has recently attracted increasing research attention.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/box2mask-box-supervised-instance-segmentation</guid>
    </item>
    <item>
      <title>NeRF-SLAM: Real-Time Dense Monocular SLAM with Neural Radiance Fields</title>
      <link>https://paperswithcode.com/paper/nerf-slam-real-time-dense-monocular-slam-with</link>
      <description><![CDATA[We propose a novel geometric and photometric 3D mapping pipeline for accurate and real-time scene reconstruction from monocular images.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nerf-slam-real-time-dense-monocular-slam-with</guid>
    </item>
    <item>
      <title>CiT: Curation in Training for Effective Vision-Language Data</title>
      <link>https://paperswithcode.com/paper/cit-curation-in-training-for-effective-vision</link>
      <description><![CDATA[Large vision-language models are generally applicable to many downstream tasks, but come at an exorbitant training cost that only large institutions can afford.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cit-curation-in-training-for-effective-vision</guid>
    </item>
    <item>
      <title>Rethinking Mobile Block for Efficient Neural Models</title>
      <link>https://paperswithcode.com/paper/rethinking-mobile-block-for-efficient-neural</link>
      <description><![CDATA[This paper focuses on designing efficient models with low parameters and FLOPs for dense predictions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rethinking-mobile-block-for-efficient-neural</guid>
    </item>
  </channel>
</rss>
