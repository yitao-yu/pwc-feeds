<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 21 Jul 2023 09:11:47 +0000</lastBuildDate>
    <item>
      <title>AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning</title>
      <link>https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</link>
      <description><![CDATA[With the advance of text-to-image models (e. g., Stable Diffusion) and corresponding personalization techniques such as DreamBooth and LoRA, everyone can manifest their imagination into high-quality images at an affordable cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</guid>
    </item>
    <item>
      <title>How is ChatGPT's behavior changing over time?</title>
      <link>https://paperswithcode.com/paper/how-is-chatgpt-s-behavior-changing-over-time</link>
      <description><![CDATA[We find that the performance and behavior of both GPT-3. 5 and GPT-4 can vary greatly over time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/how-is-chatgpt-s-behavior-changing-over-time</guid>
    </item>
    <item>
      <title>Llama 2: Open Foundation and Fine-Tuned Chat Models</title>
      <link>https://paperswithcode.com/paper/llama-2-open-foundation-and-fine-tuned-chat</link>
      <description><![CDATA[In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-2-open-foundation-and-fine-tuned-chat</guid>
    </item>
    <item>
      <title>Semantic-SAM: Segment and Recognize Anything at Any Granularity</title>
      <link>https://paperswithcode.com/paper/semantic-sam-segment-and-recognize-anything</link>
      <description><![CDATA[In this paper, we introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-sam-segment-and-recognize-anything</guid>
    </item>
    <item>
      <title>FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning</title>
      <link>https://paperswithcode.com/paper/flashattention-2-faster-attention-with-better</link>
      <description><![CDATA[We observe that the inefficiency is due to suboptimal work partitioning between different thread blocks and warps on the GPU, causing either low-occupancy or unnecessary shared memory reads/writes.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/flashattention-2-faster-attention-with-better</guid>
    </item>
    <item>
      <title>CoTracker: It is Better to Track Together</title>
      <link>https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</link>
      <description><![CDATA[In this paper, we thus propose CoTracker, an architecture that jointly tracks multiple points throughout an entire video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</guid>
    </item>
    <item>
      <title>Planting a SEED of Vision in Large Language Model</title>
      <link>https://paperswithcode.com/paper/planting-a-seed-of-vision-in-large-language</link>
      <description><![CDATA[Research on image tokenizers has previously reached an impasse, as frameworks employing quantized visual tokens have lost prominence due to subpar performance and convergence in multimodal comprehension (compared to BLIP-2, etc.)]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/planting-a-seed-of-vision-in-large-language</guid>
    </item>
    <item>
      <title>IST-Net: Prior-free Category-level Pose Estimation with Implicit Space Transformation</title>
      <link>https://paperswithcode.com/paper/prior-free-category-level-pose-estimation</link>
      <description><![CDATA[Category-level 6D pose estimation aims to predict the poses and sizes of unseen objects from a specific category.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/prior-free-category-level-pose-estimation</guid>
    </item>
    <item>
      <title>Petals: Collaborative Inference and Fine-tuning of Large Models</title>
      <link>https://paperswithcode.com/paper/petals-collaborative-inference-and-fine</link>
      <description><![CDATA[However, these techniques have innate limitations: offloading is too slow for interactive inference, while APIs are not flexible enough for research that requires access to weights, attention or logits.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/petals-collaborative-inference-and-fine</guid>
    </item>
    <item>
      <title>Exploiting Diffusion Prior for Real-World Image Super-Resolution</title>
      <link>https://paperswithcode.com/paper/exploiting-diffusion-prior-for-real-world</link>
      <description><![CDATA[We present a novel approach to leverage prior knowledge encapsulated in pre-trained text-to-image diffusion models for blind super-resolution (SR).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/exploiting-diffusion-prior-for-real-world</guid>
    </item>
    <item>
      <title>DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion</title>
      <link>https://paperswithcode.com/paper/ds-fusion-artistic-typography-via</link>
      <description><![CDATA[We introduce a novel method to automatically generate an artistic typography by stylizing one or more letter fonts to visually convey the semantics of an input word, while ensuring that the output remains readable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/ds-fusion-artistic-typography-via</guid>
    </item>
    <item>
      <title>h2oGPT: Democratizing Large Language Models</title>
      <link>https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models</link>
      <description><![CDATA[Applications built on top of Large Language Models (LLMs) such as GPT-4 represent a revolution in AI due to their human-level capabilities in natural language processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models</guid>
    </item>
    <item>
      <title>RepViT: Revisiting Mobile CNN From ViT Perspective</title>
      <link>https://paperswithcode.com/paper/repvit-revisiting-mobile-cnn-from-vit</link>
      <description><![CDATA[On ImageNet, RepViT achieves over 80\% top-1 accuracy with nearly 1ms latency on an iPhone 12, which is the first time for a lightweight model, to the best of our knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/repvit-revisiting-mobile-cnn-from-vit</guid>
    </item>
    <item>
      <title>Neural Video Depth Stabilizer</title>
      <link>https://paperswithcode.com/paper/neural-video-depth-stabilizer</link>
      <description><![CDATA[Video depth estimation aims to infer temporally consistent depth.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/neural-video-depth-stabilizer</guid>
    </item>
    <item>
      <title>Copy Is All You Need</title>
      <link>https://paperswithcode.com/paper/copy-is-all-you-need</link>
      <description><![CDATA[The dominant text generation models compose the output by sequentially selecting words from a fixed vocabulary.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/copy-is-all-you-need</guid>
    </item>
    <item>
      <title>GLM-130B: An Open Bilingual Pre-trained Model</title>
      <link>https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</link>
      <description><![CDATA[We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</guid>
    </item>
    <item>
      <title>GPT-NeoX-20B: An Open-Source Autoregressive Language Model</title>
      <link>https://paperswithcode.com/paper/gpt-neox-20b-an-open-source-autoregressive-1</link>
      <description><![CDATA[We introduce GPT-NeoX-20B, a 20 billion parameter autoregressive language model trained on the Pile, whose weights will be made freely and openly available to the public through a permissive license.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt-neox-20b-an-open-source-autoregressive-1</guid>
    </item>
    <item>
      <title>DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI</title>
      <link>https://paperswithcode.com/paper/dialogstudio-towards-richest-and-most-diverse</link>
      <description><![CDATA[Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dialogstudio-towards-richest-and-most-diverse</guid>
    </item>
    <item>
      <title>Secrets of RLHF in Large Language Models Part I: PPO</title>
      <link>https://paperswithcode.com/paper/secrets-of-rlhf-in-large-language-models-part</link>
      <description><![CDATA[Therefore, we explore the PPO-max, an advanced version of PPO algorithm, to efficiently improve the training stability of the policy model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/secrets-of-rlhf-in-large-language-models-part</guid>
    </item>
    <item>
      <title>TOAST: Transfer Learning via Attention Steering</title>
      <link>https://paperswithcode.com/paper/refocusing-is-key-to-transfer-learning</link>
      <description><![CDATA[We introduce Top-Down Attention Steering (TOAST), a novel transfer learning algorithm that keeps the pre-trained backbone frozen, selects task-relevant features in the output, and feeds those features back to the model to steer the attention to the task-specific features.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/refocusing-is-key-to-transfer-learning</guid>
    </item>
  </channel>
</rss>
