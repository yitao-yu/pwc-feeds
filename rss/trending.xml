<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 01 Aug 2023 09:11:50 +0000</lastBuildDate>
    <item>
      <title>SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</link>
      <description><![CDATA[We present SDXL, a latent diffusion model for text-to-image synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</guid>
    </item>
    <item>
      <title>Universal and Transferable Adversarial Attacks on Aligned Language Models</title>
      <link>https://paperswithcode.com/paper/universal-and-transferable-adversarial</link>
      <description><![CDATA[Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-and-transferable-adversarial</guid>
    </item>
    <item>
      <title>Med-Flamingo: a Multimodal Medical Few-shot Learner</title>
      <link>https://paperswithcode.com/paper/med-flamingo-a-multimodal-medical-few-shot</link>
      <description><![CDATA[However, existing models typically have to be fine-tuned on sizeable down-stream datasets, which poses a significant limitation as in many medical applications data is scarce, necessitating models that are capable of learning from few examples in real-time.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/med-flamingo-a-multimodal-medical-few-shot</guid>
    </item>
    <item>
      <title>FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios</title>
      <link>https://paperswithcode.com/paper/factool-factuality-detection-in-generative-ai</link>
      <description><![CDATA[With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e. g., ChatGPT).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/factool-factuality-detection-in-generative-ai</guid>
    </item>
    <item>
      <title>Tracking Anything in High Quality</title>
      <link>https://paperswithcode.com/paper/tracking-anything-in-high-quality</link>
      <description><![CDATA[To further improve the quality of tracking masks, a pretrained MR model is employed to refine the tracking results.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tracking-anything-in-high-quality</guid>
    </item>
    <item>
      <title>Gorilla: Large Language Model Connected with Massive APIs</title>
      <link>https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</link>
      <description><![CDATA[Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gorilla-large-language-model-connected-with</guid>
    </item>
    <item>
      <title>Aligning Large Language Models with Human: A Survey</title>
      <link>https://paperswithcode.com/paper/aligning-large-language-models-with-human-a</link>
      <description><![CDATA[(2) Training methodologies: a detailed review of the prevailing training methods employed for LLM alignment.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aligning-large-language-models-with-human-a</guid>
    </item>
    <item>
      <title>Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields</title>
      <link>https://paperswithcode.com/paper/seal-3d-interactive-pixel-level-editing-for</link>
      <description><![CDATA[With the popularity of implicit neural representations, or neural radiance fields (NeRF), there is a pressing need for editing methods to interact with the implicit 3D models for tasks like post-processing reconstructed scenes and 3D content creation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seal-3d-interactive-pixel-level-editing-for</guid>
    </item>
    <item>
      <title>WavJourney: Compositional Audio Creation with Large Language Models</title>
      <link>https://paperswithcode.com/paper/wavjourney-compositional-audio-creation-with</link>
      <description><![CDATA[We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/wavjourney-compositional-audio-creation-with</guid>
    </item>
    <item>
      <title>Foundational Models Defining a New Era in Vision: A Survey and Outlook</title>
      <link>https://paperswithcode.com/paper/foundational-models-defining-a-new-era-in</link>
      <description><![CDATA[Vision systems to see and reason about the compositional nature of visual scenes are fundamental to understanding our world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundational-models-defining-a-new-era-in</guid>
    </item>
    <item>
      <title>NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection</title>
      <link>https://paperswithcode.com/paper/nerf-det-learning-geometry-aware-volumetric</link>
      <description><![CDATA[We present NeRF-Det, a novel method for indoor 3D detection with posed RGB images as input.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nerf-det-learning-geometry-aware-volumetric</guid>
    </item>
    <item>
      <title>LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition</title>
      <link>https://paperswithcode.com/paper/lorahub-efficient-cross-task-generalization</link>
      <description><![CDATA[Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lorahub-efficient-cross-task-generalization</guid>
    </item>
    <item>
      <title>CoTracker: It is Better to Track Together</title>
      <link>https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</link>
      <description><![CDATA[In this paper, we thus propose CoTracker, an architecture that jointly tracks multiple points throughout an entire video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together</guid>
    </item>
    <item>
      <title>Consensus-Adaptive RANSAC</title>
      <link>https://paperswithcode.com/paper/consensus-adaptive-ransac</link>
      <description><![CDATA[The proposed attention mechanism and one-step transformer provide an adaptive behavior that enhances the performance of RANSAC, making it a more effective tool for robust estimation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/consensus-adaptive-ransac</guid>
    </item>
    <item>
      <title>Meta-Transformer: A Unified Framework for Multimodal Learning</title>
      <link>https://paperswithcode.com/paper/meta-transformer-a-unified-framework-for</link>
      <description><![CDATA[Multimodal learning aims to build models that can process and relate information from multiple modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-transformer-a-unified-framework-for</guid>
    </item>
    <item>
      <title>ResShift: Efficient Diffusion Model for Image Super-resolution by Residual Shifting</title>
      <link>https://paperswithcode.com/paper/resshift-efficient-diffusion-model-for-image</link>
      <description><![CDATA[Diffusion-based image super-resolution (SR) methods are mainly limited by the low inference speed due to the requirements of hundreds or even thousands of sampling steps.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/resshift-efficient-diffusion-model-for-image</guid>
    </item>
    <item>
      <title>Online Clustered Codebook</title>
      <link>https://paperswithcode.com/paper/online-clustered-codebook</link>
      <description><![CDATA[Vector Quantisation (VQ) is experiencing a comeback in machine learning, where it is increasingly used in representation learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/online-clustered-codebook</guid>
    </item>
    <item>
      <title>AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning</title>
      <link>https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</link>
      <description><![CDATA[With the advance of text-to-image models (e. g., Stable Diffusion) and corresponding personalization techniques such as DreamBooth and LoRA, everyone can manifest their imagination into high-quality images at an affordable cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</guid>
    </item>
    <item>
      <title>Re-Translation Strategies For Long Form, Simultaneous, Spoken Language Translation</title>
      <link>https://paperswithcode.com/paper/re-translation-strategies-for-long-form</link>
      <description><![CDATA[As this scenario allows for revisions to our incremental translations, we adopt a re-translation approach to simultaneous translation, where the source is repeatedly translated from scratch as it grows.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/re-translation-strategies-for-long-form</guid>
    </item>
    <item>
      <title>Llama 2: Open Foundation and Fine-Tuned Chat Models</title>
      <link>https://paperswithcode.com/paper/llama-2-open-foundation-and-fine-tuned-chat</link>
      <description><![CDATA[In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llama-2-open-foundation-and-fine-tuned-chat</guid>
    </item>
  </channel>
</rss>
