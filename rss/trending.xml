<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 08 Apr 2024 09:13:34 +0000</lastBuildDate>
    <item>
      <title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title>
      <link>https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</link>
      <description><![CDATA[We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine "next-scale prediction" or "next-resolution prediction", diverging from the standard raster-scan "next-token prediction".]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/visual-autoregressive-modeling-scalable-image</guid>
    </item>
    <item>
      <title>InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/instantstyle-free-lunch-towards-style</link>
      <description><![CDATA[Tuning-free diffusion-based models have demonstrated significant potential in the realm of image personalization and customization.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/instantstyle-free-lunch-towards-style</guid>
    </item>
    <item>
      <title>ReFT: Representation Finetuning for Language Models</title>
      <link>https://paperswithcode.com/paper/reft-representation-finetuning-for-language</link>
      <description><![CDATA[LoReFT is a drop-in replacement for existing PEFTs and learns interventions that are 10x-50x more parameter-efficient than prior state-of-the-art PEFTs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/reft-representation-finetuning-for-language</guid>
    </item>
    <item>
      <title>AIOS: LLM Agent Operating System</title>
      <link>https://paperswithcode.com/paper/llm-agent-operating-system</link>
      <description><![CDATA[Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS) as the brain of the OS, enabling an operating system "with soul" -- an important step towards AGI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/llm-agent-operating-system</guid>
    </item>
    <item>
      <title>VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild</title>
      <link>https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</link>
      <description><![CDATA[We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/voicecraft-zero-shot-speech-editing-and-text</guid>
    </item>
    <item>
      <title>AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent</title>
      <link>https://paperswithcode.com/paper/autowebglm-bootstrap-and-reinforce-a-large</link>
      <description><![CDATA[Large language models (LLMs) have fueled many intelligent agent tasks, such as web navigation -- but most existing agents perform far from satisfying in real-world webpages due to three factors: (1) the versatility of actions on webpages, (2) HTML text exceeding model processing capacity, and (3) the complexity of decision-making due to the open-domain nature of web.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/autowebglm-bootstrap-and-reinforce-a-large</guid>
    </item>
    <item>
      <title>CameraCtrl: Enabling Camera Control for Text-to-Video Generation</title>
      <link>https://paperswithcode.com/paper/cameractrl-enabling-camera-control-for-text</link>
      <description><![CDATA[Controllability plays a crucial role in video generation since it allows users to create desired content.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cameractrl-enabling-camera-control-for-text</guid>
    </item>
    <item>
      <title>AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation</title>
      <link>https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</link>
      <description><![CDATA[In this study, we propose AniPortrait, a novel framework for generating high-quality animation driven by audio and a reference portrait image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aniportrait-audio-driven-synthesis-of</guid>
    </item>
    <item>
      <title>Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/cross-attention-makes-inference-cumbersome-in</link>
      <description><![CDATA[This study explores the role of cross-attention during inference in text-conditional diffusion models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-attention-makes-inference-cumbersome-in</guid>
    </item>
    <item>
      <title>Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance</title>
      <link>https://paperswithcode.com/paper/champ-controllable-and-consistent-human-image</link>
      <description><![CDATA[In this study, we introduce a methodology for human image animation by leveraging a 3D human parametric model within a latent diffusion framework to enhance shape alignment and motion guidance in curernt human generative techniques.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/champ-controllable-and-consistent-human-image</guid>
    </item>
    <item>
      <title>UniDepth: Universal Monocular Metric Depth Estimation</title>
      <link>https://paperswithcode.com/paper/unidepth-universal-monocular-metric-depth</link>
      <description><![CDATA[However, the remarkable accuracy of recent MMDE methods is confined to their training domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/unidepth-universal-monocular-metric-depth</guid>
    </item>
    <item>
      <title>FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects</title>
      <link>https://paperswithcode.com/paper/foundationpose-unified-6d-pose-estimation-and</link>
      <description><![CDATA[We present FoundationPose, a unified foundation model for 6D object pose estimation and tracking, supporting both model-based and model-free setups.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundationpose-unified-6d-pose-estimation-and</guid>
    </item>
    <item>
      <title>Evalverse: Unified and Accessible Library for Large Language Model Evaluation</title>
      <link>https://paperswithcode.com/paper/evalverse-unified-and-accessible-library-for</link>
      <description><![CDATA[This paper introduces Evalverse, a novel library that streamlines the evaluation of Large Language Models (LLMs) by unifying disparate evaluation tools into a single, user-friendly framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evalverse-unified-and-accessible-library-for</guid>
    </item>
    <item>
      <title>mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding</title>
      <link>https://paperswithcode.com/paper/mplug-docowl-1-5-unified-structure-learning</link>
      <description><![CDATA[In this work, we emphasize the importance of structure information in Visual Document Understanding and propose the Unified Structure Learning to boost the performance of MLLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mplug-docowl-1-5-unified-structure-learning</guid>
    </item>
    <item>
      <title>Fast Timing-Conditioned Latent Audio Diffusion</title>
      <link>https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</link>
      <description><![CDATA[Generating long-form 44. 1kHz stereo audio from text prompts can be computationally demanding.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio</guid>
    </item>
    <item>
      <title>QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models</title>
      <link>https://paperswithcode.com/paper/qa-lora-quantization-aware-low-rank</link>
      <description><![CDATA[Recently years have witnessed a rapid development of large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qa-lora-quantization-aware-low-rank</guid>
    </item>
    <item>
      <title>DN-Splatter: Depth and Normal Priors for Gaussian Splatting and Meshing</title>
      <link>https://paperswithcode.com/paper/dn-splatter-depth-and-normal-priors-for</link>
      <description><![CDATA[3D Gaussian splatting, a novel differentiable rendering technique, has achieved state-of-the-art novel view synthesis results with high rendering speeds and relatively low training times.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dn-splatter-depth-and-normal-priors-for</guid>
    </item>
    <item>
      <title>94% on CIFAR-10 in 3.29 Seconds on a Single GPU</title>
      <link>https://paperswithcode.com/paper/94-on-cifar-10-in-3-29-seconds-on-a-single</link>
      <description><![CDATA[CIFAR-10 is among the most widely used datasets in machine learning, facilitating thousands of research projects per year.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/94-on-cifar-10-in-3-29-seconds-on-a-single</guid>
    </item>
    <item>
      <title>T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy</title>
      <link>https://paperswithcode.com/paper/t-rex2-towards-generic-object-detection-via</link>
      <description><![CDATA[Recognizing the complementary strengths and weaknesses of both text and visual prompts, we introduce T-Rex2 that synergizes both prompts within a single model through contrastive learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t-rex2-towards-generic-object-detection-via</guid>
    </item>
    <item>
      <title>Advancing LLM Reasoning Generalists with Preference Trees</title>
      <link>https://paperswithcode.com/paper/advancing-llm-reasoning-generalists-with</link>
      <description><![CDATA[We introduce Eurus, a suite of large language models (LLMs) optimized for reasoning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/advancing-llm-reasoning-generalists-with</guid>
    </item>
  </channel>
</rss>
