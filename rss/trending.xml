<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 13 Jul 2023 21:07:20 +0000</lastBuildDate>
    <item>
      <title>Generative Pretraining in Multimodality</title>
      <link>https://paperswithcode.com/paper/generative-pretraining-in-multimodality</link>
      <description><![CDATA[We present Emu, a Transformer-based multimodal foundation model, which can seamlessly generate images and texts in multimodal context.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/generative-pretraining-in-multimodality</guid>
    </item>
    <item>
      <title>Focused Transformer: Contrastive Training for Context Scaling</title>
      <link>https://paperswithcode.com/paper/focused-transformer-contrastive-training-for</link>
      <description><![CDATA[This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/focused-transformer-contrastive-training-for</guid>
    </item>
    <item>
      <title>Semantic-SAM: Segment and Recognize Anything at Any Granularity</title>
      <link>https://paperswithcode.com/paper/semantic-sam-segment-and-recognize-anything</link>
      <description><![CDATA[In this paper, we introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/semantic-sam-segment-and-recognize-anything</guid>
    </item>
    <item>
      <title>A Survey of Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-of-large-language-models</link>
      <description><![CDATA[To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-of-large-language-models</guid>
    </item>
    <item>
      <title>Secrets of RLHF in Large Language Models Part I: PPO</title>
      <link>https://paperswithcode.com/paper/secrets-of-rlhf-in-large-language-models-part</link>
      <description><![CDATA[Therefore, we explore the PPO-max, an advanced version of PPO algorithm, to efficiently improve the training stability of the policy model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/secrets-of-rlhf-in-large-language-models-part</guid>
    </item>
    <item>
      <title>AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning</title>
      <link>https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</link>
      <description><![CDATA[With the advance of text-to-image models (e. g., Stable Diffusion) and corresponding personalization techniques such as DreamBooth and LoRA, everyone can manifest their imagination into high-quality images at an affordable cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to</guid>
    </item>
    <item>
      <title>h2oGPT: Democratizing Large Language Models</title>
      <link>https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models</link>
      <description><![CDATA[Applications built on top of Large Language Models (LLMs) such as GPT-4 represent a revolution in AI due to their human-level capabilities in natural language processing.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models</guid>
    </item>
    <item>
      <title>DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing</title>
      <link>https://paperswithcode.com/paper/dragdiffusion-harnessing-diffusion-models-for</link>
      <description><![CDATA[In this work, we extend such an editing framework to diffusion models and propose DragDiffusion.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dragdiffusion-harnessing-diffusion-models-for</guid>
    </item>
    <item>
      <title>A Survey on Evaluation of Large Language Models</title>
      <link>https://paperswithcode.com/paper/a-survey-on-evaluation-of-large-language</link>
      <description><![CDATA[Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-evaluation-of-large-language</guid>
    </item>
    <item>
      <title>FreeDrag: Point Tracking is Not You Need for Interactive Point-based Image Editing</title>
      <link>https://paperswithcode.com/paper/freedrag-point-tracking-is-not-you-need-for</link>
      <description><![CDATA[To serve the intricate and varied demands of image editing, precise and flexible manipulation of image content is indispensable.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/freedrag-point-tracking-is-not-you-need-for</guid>
    </item>
    <item>
      <title>ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases</title>
      <link>https://paperswithcode.com/paper/chatlaw-open-source-legal-large-language</link>
      <description><![CDATA[Furthermore, we propose a self-attention method to enhance the ability of large models to overcome errors present in reference data, further optimizing the issue of model hallucinations at the model level and improving the problem-solving capabilities of large models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/chatlaw-open-source-legal-large-language</guid>
    </item>
    <item>
      <title>A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection</title>
      <link>https://paperswithcode.com/paper/a-survey-on-graph-neural-networks-for-time</link>
      <description><![CDATA[In this survey, we provide a comprehensive review of graph neural networks for time series analysis (GNN4TS), encompassing four fundamental dimensions: Forecasting, classification, anomaly detection, and imputation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/a-survey-on-graph-neural-networks-for-time</guid>
    </item>
    <item>
      <title>Segment Anything Meets Point Tracking</title>
      <link>https://paperswithcode.com/paper/segment-anything-meets-point-tracking</link>
      <description><![CDATA[SAM-PT leverages robust and sparse point selection and propagation techniques for mask generation, demonstrating that a SAM-based segmentation tracker can yield strong zero-shot performance across popular video object segmentation benchmarks, including DAVIS, YouTube-VOS, and MOSE.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/segment-anything-meets-point-tracking</guid>
    </item>
    <item>
      <title>GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest</title>
      <link>https://paperswithcode.com/paper/gpt4roi-instruction-tuning-large-language</link>
      <description><![CDATA[The interleaved sequences of visual features extracted by the spatial instruction and the language embedding are input to LLM, and trained on the transformed region-text data in instruction tuning format.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gpt4roi-instruction-tuning-large-language</guid>
    </item>
    <item>
      <title>VampNet: Music Generation via Masked Acoustic Token Modeling</title>
      <link>https://paperswithcode.com/paper/vampnet-music-generation-via-masked-acoustic</link>
      <description><![CDATA[We introduce VampNet, a masked acoustic token modeling approach to music synthesis, compression, inpainting, and variation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vampnet-music-generation-via-masked-acoustic</guid>
    </item>
    <item>
      <title>SVIT: Scaling up Visual Instruction Tuning</title>
      <link>https://paperswithcode.com/paper/svit-scaling-up-visual-instruction-tuning</link>
      <description><![CDATA[Thanks to the emerging of foundation models, the large language and vision models are integrated to acquire the multimodal ability of visual captioning, dialogue, question answering, etc.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/svit-scaling-up-visual-instruction-tuning</guid>
    </item>
    <item>
      <title>RLTF: Reinforcement Learning from Unit Test Feedback</title>
      <link>https://paperswithcode.com/paper/rltf-reinforcement-learning-from-unit-test</link>
      <description><![CDATA[To address these issues, we proposed RLTF, i. e., Reinforcement Learning from Unit Test Feedback, a novel online RL framework with unit test feedback of multi-granularity for refining code LLMs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/rltf-reinforcement-learning-from-unit-test</guid>
    </item>
    <item>
      <title>GLM-130B: An Open Bilingual Pre-trained Model</title>
      <link>https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</link>
      <description><![CDATA[We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/glm-130b-an-open-bilingual-pre-trained-model</guid>
    </item>
    <item>
      <title>SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis</title>
      <link>https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</link>
      <description><![CDATA[We present SDXL, a latent diffusion model for text-to-image synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for</guid>
    </item>
    <item>
      <title>MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/mme-a-comprehensive-evaluation-benchmark-for</link>
      <description><![CDATA[Multimodal Large Language Model (MLLM) relies on the powerful LLM to perform multimodal tasks, showing amazing emergent abilities in recent studies, such as writing poems based on an image.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mme-a-comprehensive-evaluation-benchmark-for</guid>
    </item>
  </channel>
</rss>
