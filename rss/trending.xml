<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 23 Feb 2023 21:07:11 +0000</lastBuildDate>
    <item>
      <title>Adding Conditional Control to Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/adding-conditional-control-to-text-to-image</link>
      <description><![CDATA[Moreover, training a ControlNet is as fast as fine-tuning a diffusion model, and the model can be trained on a personal devices.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/adding-conditional-control-to-text-to-image</guid>
    </item>
    <item>
      <title>Multimodal Chain-of-Thought Reasoning in Language Models</title>
      <link>https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</link>
      <description><![CDATA[Large language models (LLMs) have shown impressive performance on complex reasoning by leveraging chain-of-thought (CoT) prompting to generate intermediate reasoning chains as the rationale to infer the answer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multimodal-chain-of-thought-reasoning-in</guid>
    </item>
    <item>
      <title>3D-aware Conditional Image Synthesis</title>
      <link>https://paperswithcode.com/paper/3d-aware-conditional-image-synthesis</link>
      <description><![CDATA[We propose pix2pix3D, a 3D-aware conditional generative model for controllable photorealistic image synthesis.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/3d-aware-conditional-image-synthesis</guid>
    </item>
    <item>
      <title>BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining</title>
      <link>https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</link>
      <description><![CDATA[Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/biogpt-generative-pre-trained-transformer-for</guid>
    </item>
    <item>
      <title>AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities</title>
      <link>https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</link>
      <description><![CDATA[In this work, we present a conceptually simple and effective method to train a strong bilingual/multilingual multimodal representation model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/altclip-altering-the-language-encoder-in-clip</guid>
    </item>
    <item>
      <title>T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models</title>
      <link>https://paperswithcode.com/paper/t2i-adapter-learning-adapters-to-dig-out-more</link>
      <description><![CDATA[The incredible generative ability of large-scale text-to-image (T2I) models has demonstrated strong power of learning complex structures and meaningful semantics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/t2i-adapter-learning-adapters-to-dig-out-more</guid>
    </item>
    <item>
      <title>MarioGPT: Open-Ended Text2Level Generation through Large Language Models</title>
      <link>https://paperswithcode.com/paper/mariogpt-open-ended-text2level-generation</link>
      <description><![CDATA[Procedural Content Generation (PCG) algorithms provide a technique to generate complex and diverse environments in an automated way.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mariogpt-open-ended-text2level-generation</guid>
    </item>
    <item>
      <title>Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models</title>
      <link>https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</link>
      <description><![CDATA[To address these challenges, we introduce a system that can jointly optimize distributed execution and gradient checkpointing plans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/map-memory-aware-automated-intra-op-parallel</guid>
    </item>
    <item>
      <title>Mastering Diverse Domains through World Models</title>
      <link>https://paperswithcode.com/paper/mastering-diverse-domains-through-world</link>
      <description><![CDATA[General intelligence requires solving tasks across many domains.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mastering-diverse-domains-through-world</guid>
    </item>
    <item>
      <title>Symbolic Discovery of Optimization Algorithms</title>
      <link>https://paperswithcode.com/paper/symbolic-discovery-of-optimization-algorithms</link>
      <description><![CDATA[We present a method to formulate algorithm discovery as program search, and apply it to discover optimization algorithms for deep neural network training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/symbolic-discovery-of-optimization-algorithms</guid>
    </item>
    <item>
      <title>EdgeYOLO: An Edge-Real-Time Object Detector</title>
      <link>https://paperswithcode.com/paper/edgeyolo-an-edge-real-time-object-detector</link>
      <description><![CDATA[This paper proposes an efficient, low-complexity and anchor-free object detector based on the state-of-the-art YOLO framework, which can be implemented in real time on edge computing platforms.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edgeyolo-an-edge-real-time-object-detector</guid>
    </item>
    <item>
      <title>MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation</title>
      <link>https://paperswithcode.com/paper/multidiffusion-fusing-diffusion-paths-for</link>
      <description><![CDATA[In this work, we present MultiDiffusion, a unified framework that enables versatile and controllable image generation, using a pre-trained text-to-image diffusion model, without any further training or finetuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multidiffusion-fusing-diffusion-paths-for</guid>
    </item>
    <item>
      <title>Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP</title>
      <link>https://paperswithcode.com/paper/demonstrate-search-predict-composing</link>
      <description><![CDATA[Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/demonstrate-search-predict-composing</guid>
    </item>
    <item>
      <title>Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers</title>
      <link>https://paperswithcode.com/paper/why-can-gpt-learn-in-context-language-models</link>
      <description><![CDATA[In order to better understand how ICL works, this paper explains language models as meta-optimizers and understands ICL as a kind of implicit finetuning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/why-can-gpt-learn-in-context-language-models</guid>
    </item>
    <item>
      <title>Meta-Learning Triplet Network with Adaptive Margins for Few-Shot Named Entity Recognition</title>
      <link>https://paperswithcode.com/paper/meta-learning-triplet-network-with-adaptive</link>
      <description><![CDATA[We design an improved triplet network to map samples and prototype vectors into a low-dimensional space that is easier to be classified and propose an adaptive margin for each entity type.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/meta-learning-triplet-network-with-adaptive</guid>
    </item>
    <item>
      <title>ByteTransformer: A High-Performance Transformer Boosted for Variable-Length Inputs</title>
      <link>https://paperswithcode.com/paper/bytetransformer-a-high-performance</link>
      <description><![CDATA[In this paper, we present ByteTransformer, a high-performance transformer boosted for variable-length inputs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bytetransformer-a-high-performance</guid>
    </item>
    <item>
      <title>Towards Robust Blind Face Restoration with Codebook Lookup Transformer</title>
      <link>https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</link>
      <description><![CDATA[In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-robust-blind-face-restoration-with</guid>
    </item>
    <item>
      <title>Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction</title>
      <link>https://paperswithcode.com/paper/tri-perspective-view-for-vision-based-3d</link>
      <description><![CDATA[To lift image features to the 3D TPV space, we further propose a transformer-based TPV encoder (TPVFormer) to obtain the TPV features effectively.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tri-perspective-view-for-vision-based-3d</guid>
    </item>
    <item>
      <title>Cross-domain Compositing with Pretrained Diffusion Models</title>
      <link>https://paperswithcode.com/paper/cross-domain-compositing-with-pretrained</link>
      <description><![CDATA[Diffusion models have enabled high-quality, conditional image editing capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cross-domain-compositing-with-pretrained</guid>
    </item>
    <item>
      <title>Pretraining Language Models with Human Preferences</title>
      <link>https://paperswithcode.com/paper/pretraining-language-models-with-human</link>
      <description><![CDATA[Language models (LMs) are pretrained to imitate internet text, including content that would violate human preferences if generated by an LM: falsehoods, offensive comments, personally identifiable information, low-quality or buggy code, and more.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pretraining-language-models-with-human</guid>
    </item>
  </channel>
</rss>
