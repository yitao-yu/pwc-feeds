<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 31 Aug 2024 09:14:23 +0000</lastBuildDate>
    <item>
      <title>Sapiens: Foundation for Human Vision Models</title>
      <link>https://paperswithcode.com/paper/sapiens-foundation-for-human-vision-models</link>
      <description><![CDATA[We present Sapiens, a family of models for four fundamental human-centric vision tasks -- 2D pose estimation, body-part segmentation, depth estimation, and surface normal prediction.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/sapiens-foundation-for-human-vision-models</guid>
    </item>
    <item>
      <title>Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders</title>
      <link>https://paperswithcode.com/paper/eagle-exploring-the-design-space-for</link>
      <description><![CDATA[We discover that simply concatenating visual tokens from a set of complementary vision encoders is as effective as more complex mixing architectures or strategies.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/eagle-exploring-the-design-space-for</guid>
    </item>
    <item>
      <title>Show-o: One Single Transformer to Unify Multimodal Understanding and Generation</title>
      <link>https://paperswithcode.com/paper/show-o-one-single-transformer-to-unify</link>
      <description><![CDATA[We present a unified transformer, i. e., Show-o, that unifies multimodal understanding and generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/show-o-one-single-transformer-to-unify</guid>
    </item>
    <item>
      <title>OctFusion: Octree-based Diffusion Models for 3D Shape Generation</title>
      <link>https://paperswithcode.com/paper/octfusion-octree-based-diffusion-models-for</link>
      <description><![CDATA[Diffusion models have emerged as a popular method for 3D generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/octfusion-octree-based-diffusion-models-for</guid>
    </item>
    <item>
      <title>SGLang: Efficient Execution of Structured Language Model Programs</title>
      <link>https://paperswithcode.com/paper/efficiently-programming-large-language-models</link>
      <description><![CDATA[SGLang consists of a frontend language and a runtime.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/efficiently-programming-large-language-models</guid>
    </item>
    <item>
      <title>The Mamba in the Llama: Distilling and Accelerating Hybrid Models</title>
      <link>https://paperswithcode.com/paper/the-mamba-in-the-llama-distilling-and</link>
      <description><![CDATA[Linear RNN architectures, like Mamba, can be competitive with Transformer models in language modeling while having advantageous deployment characteristics.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-mamba-in-the-llama-distilling-and</guid>
    </item>
    <item>
      <title>Writing in the Margins: Better Inference Pattern for Long Context Retrieval</title>
      <link>https://paperswithcode.com/paper/writing-in-the-margins-better-inference</link>
      <description><![CDATA[In this paper, we introduce Writing in the Margins (WiM), a new inference pattern for Large Language Models designed to optimize the handling of long input sequences in retrieval-oriented tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/writing-in-the-margins-better-inference</guid>
    </item>
    <item>
      <title>Conformal prediction under ambiguous ground truth</title>
      <link>https://paperswithcode.com/paper/conformal-prediction-under-ambiguous-ground</link>
      <description><![CDATA[However, in many real-world scenarios, the labels $Y_1,..., Y_n$ are obtained by aggregating expert opinions using a voting procedure, resulting in a one-hot distribution $\mathbb{P}_{vote}^{Y|X}$.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/conformal-prediction-under-ambiguous-ground</guid>
    </item>
    <item>
      <title>Foundation Models for Music: A Survey</title>
      <link>https://paperswithcode.com/paper/foundation-models-for-music-a-survey</link>
      <description><![CDATA[In recent years, foundation models (FMs) such as large language models (LLMs) and latent diffusion models (LDMs) have profoundly impacted diverse sectors, including music.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/foundation-models-for-music-a-survey</guid>
    </item>
    <item>
      <title>FancyVideo: Towards Dynamic and Consistent Video Generation via Cross-frame Textual Guidance</title>
      <link>https://paperswithcode.com/paper/fancyvideo-towards-dynamic-and-consistent</link>
      <description><![CDATA[Then, TAR refines the correlation matrix between cross-frame textual conditions and latent features along the time dimension.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fancyvideo-towards-dynamic-and-consistent</guid>
    </item>
    <item>
      <title>Text2SQL is Not Enough: Unifying AI and Databases with TAG</title>
      <link>https://paperswithcode.com/paper/text2sql-is-not-enough-unifying-ai-and</link>
      <description><![CDATA[Such systems would allow users to leverage the powerful reasoning and knowledge capabilities of language models (LMs) alongside the scalable computational power of data management systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/text2sql-is-not-enough-unifying-ai-and</guid>
    </item>
    <item>
      <title>RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/raglab-a-modular-and-research-oriented</link>
      <description><![CDATA[Leveraging RAGLAB, we conduct a fair comparison of 6 RAG algorithms across 10 benchmarks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/raglab-a-modular-and-research-oriented</guid>
    </item>
    <item>
      <title>Automated Design of Agentic Systems</title>
      <link>https://paperswithcode.com/paper/automated-design-of-agentic-systems</link>
      <description><![CDATA[Researchers are investing substantial effort in developing powerful general-purpose agents, wherein Foundation Models are used as modules within agentic systems (e. g. Chain-of-Thought, Self-Reflection, Toolformer).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/automated-design-of-agentic-systems</guid>
    </item>
    <item>
      <title>Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation</title>
      <link>https://paperswithcode.com/paper/superposition-prompting-improving-and</link>
      <description><![CDATA[Despite the successes of large language models (LLMs), they exhibit significant drawbacks, particularly when processing long contexts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/superposition-prompting-improving-and</guid>
    </item>
    <item>
      <title>LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs</title>
      <link>https://paperswithcode.com/paper/longwriter-unleashing-10000-word-generation</link>
      <description><![CDATA[By incorporating this dataset into model training, we successfully scale the output length of existing models to over 10, 000 words while maintaining output quality.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/longwriter-unleashing-10000-word-generation</guid>
    </item>
    <item>
      <title>Beyond Alignment: Blind Video Face Restoration via Parsing-Guided Temporal-Coherent Transformer</title>
      <link>https://paperswithcode.com/paper/beyond-alignment-blind-video-face-restoration</link>
      <description><![CDATA[Multiple complex degradations are coupled in low-quality video faces in the real world.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/beyond-alignment-blind-video-face-restoration</guid>
    </item>
    <item>
      <title>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</title>
      <link>https://paperswithcode.com/paper/the-ai-scientist-towards-fully-automated-open</link>
      <description><![CDATA[This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-ai-scientist-towards-fully-automated-open</guid>
    </item>
    <item>
      <title>GaussianOcc: Fully Self-supervised and Efficient 3D Occupancy Estimation with Gaussian Splatting</title>
      <link>https://paperswithcode.com/paper/gaussianocc-fully-self-supervised-and</link>
      <description><![CDATA[We propose Gaussian Splatting from Voxel space (GSV) to leverage the fast rendering properties of Gaussian splatting.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/gaussianocc-fully-self-supervised-and</guid>
    </item>
    <item>
      <title>MindSearch: Mimicking Human Minds Elicits Deep AI Searcher</title>
      <link>https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</link>
      <description><![CDATA[Inspired by the cognitive process when humans solve these problems, we introduce MindSearch to mimic the human minds in web information seeking and integration, which can be instantiated by a simple yet effective LLM-based multi-agent framework.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mindsearch-mimicking-human-minds-elicits-deep</guid>
    </item>
    <item>
      <title>Bilateral Reference for High-Resolution Dichotomous Image Segmentation</title>
      <link>https://paperswithcode.com/paper/bilateral-reference-for-high-resolution</link>
      <description><![CDATA[It comprises two essential components: the localization module (LM) and the reconstruction module (RM) with our proposed bilateral reference (BiRef).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/bilateral-reference-for-high-resolution</guid>
    </item>
  </channel>
</rss>
