<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 16 Jul 2025 21:11:18 +0000</lastBuildDate>
    <item>
      <title>MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm</title>
      <link>https://paperswithcode.com/paper/monkeyocr-document-parsing-with-a-structure</link>
      <description><![CDATA[We introduce MonkeyOCR, a vision-language model for document parsing that advances the state of the art by leveraging a Structure-Recognition-Relation (SRR) triplet paradigm.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/monkeyocr-document-parsing-with-a-structure</guid>
    </item>
    <item>
      <title>WebDancer: Towards Autonomous Information Seeking Agency</title>
      <link>https://paperswithcode.com/paper/webdancer-towards-autonomous-information</link>
      <description><![CDATA[We instantiate this framework in a web agent based on the ReAct, WebDancer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/webdancer-towards-autonomous-information</guid>
    </item>
    <item>
      <title>ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing</title>
      <link>https://paperswithcode.com/paper/thinksound-chain-of-thought-reasoning-in</link>
      <description><![CDATA[While end-to-end video-to-audio generation has greatly improved, producing high-fidelity audio that authentically captures the nuances of visual content remains challenging.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/thinksound-chain-of-thought-reasoning-in</guid>
    </item>
    <item>
      <title>Do Large Language Models Need a Content Delivery Network?</title>
      <link>https://paperswithcode.com/paper/do-large-language-models-need-a-content</link>
      <description><![CDATA[As the use of large language models (LLMs) expands rapidly, so does the range of knowledge needed to supplement various LLM queries.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/do-large-language-models-need-a-content</guid>
    </item>
    <item>
      <title>IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System</title>
      <link>https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</link>
      <description><![CDATA[Recently, large language model (LLM) based text-to-speech (TTS) systems have gradually become the mainstream in the industry due to their high naturalness and powerful zero-shot voice cloning capabilities. Here, we introduce the IndexTTS system, which is mainly based on the XTTS and Tortoise model.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/indextts-an-industrial-level-controllable-and</guid>
    </item>
    <item>
      <title>Universal Segmentation at Arbitrary Granularity with Language Instruction</title>
      <link>https://paperswithcode.com/paper/universal-segmentation-at-arbitrary</link>
      <description><![CDATA[This paper aims to achieve universal segmentation of arbitrary semantic level.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/universal-segmentation-at-arbitrary</guid>
    </item>
    <item>
      <title>Zep: A Temporal Knowledge Graph Architecture for Agent Memory</title>
      <link>https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</link>
      <description><![CDATA[We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zep-a-temporal-knowledge-graph-architecture</guid>
    </item>
    <item>
      <title>TradingAgents: Multi-Agents LLM Financial Trading Framework</title>
      <link>https://paperswithcode.com/paper/tradingagents-multi-agents-llm-financial</link>
      <description><![CDATA[Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tradingagents-multi-agents-llm-financial</guid>
    </item>
    <item>
      <title>Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts</title>
      <link>https://paperswithcode.com/paper/learning-robust-stereo-matching-in-the-wild</link>
      <description><![CDATA[To address this, we propose SMoEStereo, a novel framework that adapts VFMs for stereo matching through a tailored, scene-specific fusion of Low-Rank Adaptation (LoRA) and Mixture-of-Experts (MoE) modules.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-robust-stereo-matching-in-the-wild</guid>
    </item>
    <item>
      <title>Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting</title>
      <link>https://paperswithcode.com/paper/dolphin-document-image-parsing-via</link>
      <description><![CDATA[Document image parsing is challenging due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/dolphin-document-image-parsing-via</guid>
    </item>
    <item>
      <title>Embedding Atlas: Low-Friction, Interactive Embedding Visualization</title>
      <link>https://paperswithcode.com/paper/embedding-atlas-low-friction-interactive</link>
      <description><![CDATA[Embedding projections are popular for visualizing large datasets and models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/embedding-atlas-low-friction-interactive</guid>
    </item>
    <item>
      <title>Practical Efficiency of Muon for Pretraining</title>
      <link>https://paperswithcode.com/paper/practical-efficiency-of-muon-for-pretraining</link>
      <description><![CDATA[We demonstrate that Muon, the simplest instantiation of a second-order optimizer, explicitly expands the Pareto frontier over AdamW on the compute-time tradeoff.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/practical-efficiency-of-muon-for-pretraining</guid>
    </item>
    <item>
      <title>XVerse: Consistent Multi-Subject Control of Identity and Semantic Attributes via DiT Modulation</title>
      <link>https://paperswithcode.com/paper/xverse-consistent-multi-subject-control-of</link>
      <description><![CDATA[Achieving fine-grained control over subject identity and semantic attributes (pose, style, lighting) in text-to-image generation, particularly for multiple subjects, often undermines the editability and coherence of Diffusion Transformers (DiTs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/xverse-consistent-multi-subject-control-of</guid>
    </item>
    <item>
      <title>L0: Reinforcement Learning to Become General Agents</title>
      <link>https://paperswithcode.com/paper/l0-reinforcement-learning-to-become-general</link>
      <description><![CDATA[To address this, we introduce L-Zero (L0), a scalable, end-to-end training pipeline for general-purpose agents.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/l0-reinforcement-learning-to-become-general</guid>
    </item>
    <item>
      <title>R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration</title>
      <link>https://paperswithcode.com/paper/r-kv-redundancy-aware-kv-cache-compression</link>
      <description><![CDATA[To address this, we propose Redundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel method specifically targeting redundant tokens in reasoning models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/r-kv-redundancy-aware-kv-cache-compression</guid>
    </item>
    <item>
      <title>SoundMind: RL-Incentivized Logic Reasoning for Audio-Language Models</title>
      <link>https://paperswithcode.com/paper/soundmind-rl-incentivized-logic-reasoning-for</link>
      <description><![CDATA[While large language models have shown reasoning capabilities, their application to the audio modality, particularly in large audio-language models (ALMs), remains significantly underdeveloped.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/soundmind-rl-incentivized-logic-reasoning-for</guid>
    </item>
    <item>
      <title>MinerU: An Open-Source Solution for Precise Document Content Extraction</title>
      <link>https://paperswithcode.com/paper/mineru-an-open-source-solution-for-precise</link>
      <description><![CDATA[Document content analysis has been a crucial research area in computer vision.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/mineru-an-open-source-solution-for-precise</guid>
    </item>
    <item>
      <title>TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis</title>
      <link>https://paperswithcode.com/paper/tcsinger-2-customizable-multilingual-zero</link>
      <description><![CDATA[To overcome these challenges, we introduce TCSinger 2, a multi-task multilingual zero-shot SVS model with style transfer and style control based on various prompts.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/tcsinger-2-customizable-multilingual-zero</guid>
    </item>
    <item>
      <title>Energy-Based Transformers are Scalable Learners and Thinkers</title>
      <link>https://paperswithcode.com/paper/energy-based-transformers-are-scalable</link>
      <description><![CDATA[Further, we find that EBTs achieve better results than existing models on most downstream tasks given the same or worse pretraining performance, suggesting that EBTs generalize better than existing approaches.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/energy-based-transformers-are-scalable</guid>
    </item>
    <item>
      <title>Cautious Optimizers: Improving Training with One Line of Code</title>
      <link>https://paperswithcode.com/paper/cautious-optimizers-improving-training-with</link>
      <description><![CDATA[AdamW has been the default optimizer for transformer pretraining.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/cautious-optimizers-improving-training-with</guid>
    </item>
  </channel>
</rss>
