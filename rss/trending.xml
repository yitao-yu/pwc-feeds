<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 24 Jul 2024 21:08:45 +0000</lastBuildDate>
    <item>
      <title>IMAGDressing-v1: Customizable Virtual Dressing</title>
      <link>https://paperswithcode.com/paper/imagdressing-v1-customizable-virtual-dressing</link>
      <description><![CDATA[Latest advances have achieved realistic virtual try-on (VTON) through localized garment inpainting using latent diffusion models, significantly enhancing consumers' online shopping experience.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/imagdressing-v1-customizable-virtual-dressing</guid>
    </item>
    <item>
      <title>DataComp-LM: In search of the next generation of training sets for language models</title>
      <link>https://paperswithcode.com/paper/datacomp-lm-in-search-of-the-next-generation</link>
      <description><![CDATA[We introduce DataComp for Language Models (DCLM), a testbed for controlled dataset experiments with the goal of improving language models.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/datacomp-lm-in-search-of-the-next-generation</guid>
    </item>
    <item>
      <title>Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models</title>
      <link>https://paperswithcode.com/paper/assisting-in-writing-wikipedia-like-articles</link>
      <description><![CDATA[We study how to apply large language models to write grounded and organized long-form articles from scratch, with comparable breadth and depth to Wikipedia pages.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/assisting-in-writing-wikipedia-like-articles</guid>
    </item>
    <item>
      <title>E5-V: Universal Embeddings with Multimodal Large Language Models</title>
      <link>https://paperswithcode.com/paper/e5-v-universal-embeddings-with-multimodal</link>
      <description><![CDATA[We propose a single modality training approach for E5-V, where the model is trained exclusively on text pairs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/e5-v-universal-embeddings-with-multimodal</guid>
    </item>
    <item>
      <title>FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs</title>
      <link>https://paperswithcode.com/paper/funaudiollm-voice-understanding-and</link>
      <description><![CDATA[This report introduces FunAudioLLM, a model family designed to enhance natural voice interactions between humans and large language models (LLMs).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/funaudiollm-voice-understanding-and</guid>
    </item>
    <item>
      <title>LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control</title>
      <link>https://paperswithcode.com/paper/liveportrait-efficient-portrait-animation</link>
      <description><![CDATA[Instead of following mainstream diffusion-based methods, we explore and extend the potential of the implicit-keypoint-based framework, which effectively balances computational efficiency and controllability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/liveportrait-efficient-portrait-animation</guid>
    </item>
    <item>
      <title>Qwen2-Audio Technical Report</title>
      <link>https://paperswithcode.com/paper/qwen2-audio-technical-report</link>
      <description><![CDATA[We introduce the latest progress of Qwen-Audio, a large-scale audio-language model called Qwen2-Audio, which is capable of accepting various audio signal inputs and performing audio analysis or direct textual responses with regard to speech instructions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/qwen2-audio-technical-report</guid>
    </item>
    <item>
      <title>VGGSfM: Visual Geometry Grounded Deep Structure From Motion</title>
      <link>https://paperswithcode.com/paper/vggsfm-visual-geometry-grounded-deep</link>
      <description><![CDATA[Finally we optimise the cameras and triangulate 3D points via a differentiable bundle adjustment layer.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/vggsfm-visual-geometry-grounded-deep</guid>
    </item>
    <item>
      <title>Cradle: Empowering Foundation Agents Towards General Computer Control</title>
      <link>https://paperswithcode.com/paper/towards-general-computer-control-a-multimodal</link>
      <description><![CDATA[To handle this issue, we propose the General Computer Control (GCC) setting to restrict foundation agents to interact with software through the most unified and standardized interface, i. e., using screenshots as input and keyboard and mouse actions as output.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/towards-general-computer-control-a-multimodal</guid>
    </item>
    <item>
      <title>Fundus: A Simple-to-Use News Scraper Optimized for High Quality Extractions</title>
      <link>https://paperswithcode.com/paper/fundus-a-simple-to-use-news-scraper-optimized</link>
      <description><![CDATA[This paper introduces Fundus, a user-friendly news scraper that enables users to obtain millions of high-quality news articles with just a few lines of code.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/fundus-a-simple-to-use-news-scraper-optimized</guid>
    </item>
    <item>
      <title>LOTUS: Enabling Semantic Queries with LLMs Over Tables of Unstructured and Structured Data</title>
      <link>https://paperswithcode.com/paper/lotus-enabling-semantic-queries-with-llms</link>
      <description><![CDATA[We introduce semantic operators, a declarative programming interface that extends the relational model with composable AI-based operations for semantic queries over datasets (e. g., sorting or aggregating records using natural language criteria).]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/lotus-enabling-semantic-queries-with-llms</guid>
    </item>
    <item>
      <title>AudioLCM: Text-to-Audio Generation with Latent Consistency Models</title>
      <link>https://paperswithcode.com/paper/audiolcm-text-to-audio-generation-with-latent</link>
      <description><![CDATA[To overcome the convergence issue inherent in LDMs with reduced sample iterations, we propose the Guided Latent Consistency Distillation with a multi-step Ordinary Differential Equation (ODE) solver.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/audiolcm-text-to-audio-generation-with-latent</guid>
    </item>
    <item>
      <title>RouteLLM: Learning to Route LLMs with Preference Data</title>
      <link>https://paperswithcode.com/paper/routellm-learning-to-route-llms-with</link>
      <description><![CDATA[Large language models (LLMs) exhibit impressive capabilities across a wide range of tasks, yet the choice of which model to use often involves a trade-off between performance and cost.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/routellm-learning-to-route-llms-with</guid>
    </item>
    <item>
      <title>Large Language Models for Cyber Security: A Systematic Literature Review</title>
      <link>https://paperswithcode.com/paper/large-language-models-for-cyber-security-a</link>
      <description><![CDATA[Overall, our survey provides a comprehensive overview of the current state-of-the-art in LLM4Security and identifies several promising directions for future research.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/large-language-models-for-cyber-security-a</guid>
    </item>
    <item>
      <title>IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce</title>
      <link>https://paperswithcode.com/paper/intentionqa-a-benchmark-for-evaluating</link>
      <description><![CDATA[Enhancing Language Models' (LMs) ability to understand purchase intentions in E-commerce scenarios is crucial for their effective assistance in various downstream tasks.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/intentionqa-a-benchmark-for-evaluating</guid>
    </item>
    <item>
      <title>Scaling Diffusion Transformers to 16 Billion Parameters</title>
      <link>https://paperswithcode.com/paper/scaling-diffusion-transformers-to-16-billion</link>
      <description><![CDATA[In this paper, we present DiT-MoE, a sparse version of the diffusion Transformer, that is scalable and competitive with dense networks while exhibiting highly optimized inference.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-diffusion-transformers-to-16-billion</guid>
    </item>
    <item>
      <title>SEED-Story: Multimodal Long Story Generation with Large Language Model</title>
      <link>https://paperswithcode.com/paper/seed-story-multimodal-long-story-generation</link>
      <description><![CDATA[We further propose multimodal attention sink mechanism to enable the generation of stories with up to 25 sequences (only 10 for training) in a highly efficient autoregressive manner.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/seed-story-multimodal-long-story-generation</guid>
    </item>
    <item>
      <title>Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head</title>
      <link>https://paperswithcode.com/paper/real-time-transformer-based-open-vocabulary</link>
      <description><![CDATA[End-to-end transformer-based detectors (DETRs) have shown exceptional performance in both closed-set and open-vocabulary object detection (OVD) tasks through the integration of language modalities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/real-time-transformer-based-open-vocabulary</guid>
    </item>
    <item>
      <title>Deep-TEMPEST: Using Deep Learning to Eavesdrop on HDMI from its Unintended Electromagnetic Emanations</title>
      <link>https://paperswithcode.com/paper/deep-tempest-using-deep-learning-to-eavesdrop</link>
      <description><![CDATA[As a result, eavesdropping systems designed for the analog case obtain unclear and difficult-to-read images when applied to digital video.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/deep-tempest-using-deep-learning-to-eavesdrop</guid>
    </item>
    <item>
      <title>GRUtopia: Dream General Robots in a City at Scale</title>
      <link>https://paperswithcode.com/paper/grutopia-dream-general-robots-in-a-city-at</link>
      <description><![CDATA[Recent works have been exploring the scaling laws in the field of Embodied AI.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/grutopia-dream-general-robots-in-a-city-at</guid>
    </item>
  </channel>
</rss>
