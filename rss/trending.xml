<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Papers with Code: Trending (unofficial)</title>
    <link>https://github.com/yitao-yu/pwc-feeds</link>
    <description>As a disclaimer, this is an unofficial feed and has no affiliation with Papers with Code.</description>
    <atom:link href="https://github.com/yitao-yu/pwc-feeds" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 27 Jun 2022 09:14:56 +0000</lastBuildDate>
    <item>
      <title>EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation</title>
      <link>https://paperswithcode.com/paper/epro-pnp-generalized-end-to-end-probabilistic</link>
      <description><![CDATA[The 2D-3D coordinates and corresponding weights are treated as intermediate variables learned by minimizing the KL divergence between the predicted and target pose distribution.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/epro-pnp-generalized-end-to-end-probabilistic</guid>
    </item>
    <item>
      <title>Evaluating Large Language Models Trained on Code</title>
      <link>https://paperswithcode.com/paper/evaluating-large-language-models-trained-on</link>
      <description><![CDATA[We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/evaluating-large-language-models-trained-on</guid>
    </item>
    <item>
      <title>Scaling Autoregressive Models for Content-Rich Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/scaling-autoregressive-models-for-content</link>
      <description><![CDATA[We present the Pathways Autoregressive Text-to-Image (Parti) model, which generates high-fidelity photorealistic images and supports content-rich synthesis involving complex compositions and world knowledge.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/scaling-autoregressive-models-for-content</guid>
    </item>
    <item>
      <title>Free-Form Image Inpainting with Gated Convolution</title>
      <link>https://paperswithcode.com/paper/free-form-image-inpainting-with-gated</link>
      <description><![CDATA[We present a generative image inpainting system to complete images with free-form mask and guidance.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/free-form-image-inpainting-with-gated</guid>
    </item>
    <item>
      <title>The ArtBench Dataset: Benchmarking Generative Models with Artworks</title>
      <link>https://paperswithcode.com/paper/the-artbench-dataset-benchmarking-generative</link>
      <description><![CDATA[We introduce ArtBench-10, the first class-balanced, high-quality, cleanly annotated, and standardized dataset for benchmarking artwork generation.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/the-artbench-dataset-benchmarking-generative</guid>
    </item>
    <item>
      <title>Pythae: Unifying Generative Autoencoders in Python -- A Benchmarking Use Case</title>
      <link>https://paperswithcode.com/paper/pythae-unifying-generative-autoencoders-in</link>
      <description><![CDATA[In recent years, deep generative models have attracted increasing interest due to their capacity to model complex distributions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/pythae-unifying-generative-autoencoders-in</guid>
    </item>
    <item>
      <title>Nocturne: a scalable driving benchmark for bringing multi-agent learning one step closer to the real world</title>
      <link>https://paperswithcode.com/paper/nocturne-a-scalable-driving-benchmark-for</link>
      <description><![CDATA[We introduce \textit{Nocturne}, a new 2D driving simulator for investigating multi-agent coordination under partial observability.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/nocturne-a-scalable-driving-benchmark-for</guid>
    </item>
    <item>
      <title>RegionCLIP: Region-based Language-Image Pretraining</title>
      <link>https://paperswithcode.com/paper/regionclip-region-based-language-image</link>
      <description><![CDATA[However, we show that directly applying such models to recognize image regions for object detection leads to poor performance due to a domain shift: CLIP was trained to match an image as a whole to a text description, without capturing the fine-grained alignment between image regions and text spans.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/regionclip-region-based-language-image</guid>
    </item>
    <item>
      <title>MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge</title>
      <link>https://paperswithcode.com/paper/minedojo-building-open-ended-embodied-agents</link>
      <description><![CDATA[Autonomous agents have made great strides in specialist domains like Atari games and Go.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/minedojo-building-open-ended-embodied-agents</guid>
    </item>
    <item>
      <title>EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications</title>
      <link>https://paperswithcode.com/paper/edgenext-efficiently-amalgamated-cnn</link>
      <description><![CDATA[Our EdgeNeXt model with 1. 3M parameters achieves 71. 2\% top-1 accuracy on ImageNet-1K, outperforming MobileViT with an absolute gain of 2. 2\% with 28\% reduction in FLOPs.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/edgenext-efficiently-amalgamated-cnn</guid>
    </item>
    <item>
      <title>HaGRID -- HAnd Gesture Recognition Image Dataset</title>
      <link>https://paperswithcode.com/paper/hagrid-hand-gesture-recognition-image-dataset</link>
      <description><![CDATA[In this paper, we introduce an enormous dataset HaGRID (HAnd Gesture Recognition Image Dataset) for hand gesture recognition (HGR) systems.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/hagrid-hand-gesture-recognition-image-dataset</guid>
    </item>
    <item>
      <title>OmniXAI: A Library for Explainable AI</title>
      <link>https://paperswithcode.com/paper/omnixai-a-library-for-explainable-ai</link>
      <description><![CDATA[We introduce OmniXAI (short for Omni eXplainable AI), an open-source Python library of eXplainable AI (XAI), which offers omni-way explainable AI capabilities and various interpretable machine learning techniques to address the pain points of understanding and interpreting the decisions made by machine learning (ML) in practice.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/omnixai-a-library-for-explainable-ai</guid>
    </item>
    <item>
      <title>Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds</title>
      <link>https://paperswithcode.com/paper/voxel-mae-masked-autoencoders-for-pre</link>
      <description><![CDATA[In this paper, we propose a mask voxel classification network for large-scale point clouds pre-training.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/voxel-mae-masked-autoencoders-for-pre</guid>
    </item>
    <item>
      <title>AiTLAS: Artificial Intelligence Toolbox for Earth Observation</title>
      <link>https://paperswithcode.com/paper/aitlas-artificial-intelligence-toolbox-for</link>
      <description><![CDATA[The AiTLAS toolbox (Artificial Intelligence Toolbox for Earth Observation) includes state-of-the-art machine learning methods for exploratory and predictive analysis of satellite imagery as well as repository of AI-ready Earth Observation (EO) datasets.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/aitlas-artificial-intelligence-toolbox-for</guid>
    </item>
    <item>
      <title>Extracting Triangular 3D Models, Materials, and Lighting From Images</title>
      <link>https://paperswithcode.com/paper/extracting-triangular-3d-models-materials-and</link>
      <description><![CDATA[We present an efficient method for joint optimization of topology, materials and lighting from multi-view image observations.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/extracting-triangular-3d-models-materials-and</guid>
    </item>
    <item>
      <title>I M Avatar: Implicit Morphable Head Avatars from Videos</title>
      <link>https://paperswithcode.com/paper/i-m-avatar-implicit-morphable-head-avatars</link>
      <description><![CDATA[Traditional 3D morphable face models (3DMMs) provide fine-grained control over expression but cannot easily capture geometric and appearance details.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/i-m-avatar-implicit-morphable-head-avatars</guid>
    </item>
    <item>
      <title>OPT: Open Pre-trained Transformer Language Models</title>
      <link>https://paperswithcode.com/paper/opt-open-pre-trained-transformer-language</link>
      <description><![CDATA[Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/opt-open-pre-trained-transformer-language</guid>
    </item>
    <item>
      <title>Multiplying Matrices Without Multiplying</title>
      <link>https://paperswithcode.com/paper/multiplying-matrices-without-multiplying</link>
      <description><![CDATA[Multiplying matrices is among the most fundamental and compute-intensive operations in machine learning.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/multiplying-matrices-without-multiplying</guid>
    </item>
    <item>
      <title>Learning to Solve Hard Minimal Problems</title>
      <link>https://paperswithcode.com/paper/learning-to-solve-hard-minimal-problems</link>
      <description><![CDATA[The hard minimal problems arise from relaxing the original geometric optimization problem into a minimal problem with many spurious solutions.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/learning-to-solve-hard-minimal-problems</guid>
    </item>
    <item>
      <title>Zero-Shot Text-to-Image Generation</title>
      <link>https://paperswithcode.com/paper/zero-shot-text-to-image-generation</link>
      <description><![CDATA[Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset.]]></description>
      <guid isPermaLink="true">https://paperswithcode.com/paper/zero-shot-text-to-image-generation</guid>
    </item>
  </channel>
</rss>
